quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Performance,atch3/downloads/QuPath/lib/runtime/lib/libawt.so; 7f79429cf000-7f7942bcf000 ---p 0009d000 fd:02 10819064500 /scratch3/downloads/QuPath/lib/runtime/lib/libawt.so; 7f7942bcf000-7f7942bd0000 r--p 0009d000 fd:02 10819064500 /scratch3/downloads/QuPath/lib/runtime/lib/libawt.so; 7f7942bd0000-7f7942bdb000 rw-p 0009e000 fd:02 10819064500 /scratch3/downloads/QuPath/lib/runtime/lib/libawt.so; 7f7942bdb000-7f7942d00000 rw-p 00000000 00:00 0 ; 7f7942d00000-7f7942e00000 rw-p 00000000 00:00 0 ; 7f7942e00000-7f7943100000 rw-p 00000000 00:00 0 ; 7f7943100000-7f79431f0000 rw-p 00000000 00:00 0 ; 7f79431f0000-7f7943200000 ---p 00000000 00:00 0 ; 7f7943200000-7f7943400000 rw-p 00000000 00:00 0 ; 7f794343c000-7f79434ec000 r--p 00000000 fd:03 721040943 /scratch/usr-shr/share/fonts/dejavu/DejaVuSans.ttf; 7f79434ec000-7f79434f0000 r-xp 00000000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79434f0000-7f79436ef000 ---p 00004000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79436ef000-7f79436f0000 r--p 00003000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79436f0000-7f79436f1000 rw-p 00004000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79436f1000-7f79436f6000 r-xp 00000000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79436f6000-7f79438f5000 ---p 00005000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f5000-7f79438f6000 r--p 00004000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f6000-7f79438f7000 rw-p 00005000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f7000-7f79438fa000 r-xp 00000000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f79438fa000-7f7943af9000 ---p 00003000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjav,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018:18127,cache,cache,18127,https://qupath.github.io,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018,1,['cache'],['cache']
Performance,"ated from JTS Geometry objects may not necessarily be valid. If they are not valid, this can cause numerous problems, including:; * Weird visual behavior; * Inability to modify the geometry; * Wrong results (e.g. area or length). Most, if not all, geometries created through normal use in v0.2.0 should be valid - since invalidity is typically caught earlier in the process, before ROIs are created. However, it remains possible that geometries are created by a more obscure process/via scripting. The user should be protected from this as far as possible. **Expected behavior**; Invalid geometries either cannot be converted to ROIs, or at least provide an indication of their invalidity (e.g. by not showing measurements). **Additional context**; Some improvements introduced in v0.2.0-m9 greatly reduce the changes of generating an invalid geometry with the brush/wand tool (the most recent invalid geometry I have seen was generated in m8). There is already a mechanism to perform a validity check when creating a `GeometryROI`, but it is not currently used: https://github.com/qupath/qupath/blob/a03756328188999c0b7f12c290cda0589c50bd4b/qupath-core/src/main/java/qupath/lib/roi/GeometryROI.java#L90. The reason for this is that checking `isValid` can be *very* slow for large or complex geometries - which can problematic in some cases (e.g. when using the brush/wand). The validity check *only* impacts the display of measurements; the geometry is otherwise permitted. Proposed change is to perform validity checks whenever GeometryROIs are created in most circumstances, except for:; * When interactively drawing with the brush or wand; * When performing a simple operation (e.g. translation) that ought not to have any validity implications. Other cases that need consideration are:; * When deserializing an existing geometry (which ought to have been checked upon creation); * When attempting to create a ROI from a heterogeneous `GeometryCollection` (e.g. combination of polygons and lines)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/527:1032,perform,perform,1032,https://qupath.github.io,https://github.com/qupath/qupath/issues/527,3,['perform'],"['perform', 'performing']"
Performance,"ated the dependency, but I'm still seeing the error. As far as I can tell, the right libraries are being loaded. If I run a Groovy script in QuPath to print `Loader.getLoadedLibraries()` I see:. ```; opencv_ml@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_ml.405.dylib; gfortran@.5 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgfortran.dylib; jniopencv_core : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_core.dylib; gfortran@.3 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgfortran.dylib; gfortran@.4 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgfortran.4.dylib; gcc_s@.1 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgcc_s.1.dylib; jniopencv_ml : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_ml.dylib; opencv_imgproc@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_imgproc.405.dylib; jniopencv_dnn : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_dnn.dylib; jnijavacpp : 	/Users/pbankhea/.javacpp/cache/javacpp-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/javacpp/macosx-x86_64/libjnijavacpp.dylib; jniopenblas : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libjniopenblas.dylib; quadmath@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libqu",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980:1145,cache,cache,1145,https://qupath.github.io,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980,1,['cache'],['cache']
Performance,"ath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:536); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:573); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:156); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:120); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:47); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:269); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); ERROR: IOException exception reading file:/Volumes/Storage/Work/SLIDESCANS/190512_OLYMPUS_YKA_Batch/CRUK_YKA_16.1D_tam_2_20190513.vsi#1: x=9728, y=34816, w=512, h=512, z=0, t=0, downsample=1; at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:199); at java.base/sun.nio.ch.FileChannelImpl.endBlocking(FileChannelImpl.java:162); at java.base/sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:816); at java.base/sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:796); at loci.common.NIOByteBufferProvider.allocateDirect(NIOByteBufferProvider.java:127); at loci.common.NIOByteBufferProvider.allocate(NIOByteBufferProvider.java:112); at loci.common.NIOFileHandle.buffer(NIOFileHandle.java:647); at loci.common.NIOFileHandle.<init>(NIOFileHandle.java:133); at loci.common.NIOFileHandle.<init>(NIOFileHandle.java:151); at lo",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:8324,concurren,concurrent,8324,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['concurren'],['concurrent']
Performance,"ath.lib.gui.QuPathGUI - Added extension: /home/bl/ip/QuPath/extensions/jep.jar; OpenJDK 64-Bit Server VM warning: You have loaded library /home/bl/ip/QuPath/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:120); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1092); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:633); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:418); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:59); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$106(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$119(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$117(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$118(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/27#issuecomment-262870405:1852,load,loadNativeLibrary,1852,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405,1,['load'],['loadNativeLibrary']
Performance,ath.lib.plugins.AbstractTaskRunner.awaitCompletion(AbstractTaskRunner.java:147); at qupath.lib.plugins.AbstractTaskRunner.runTasks(AbstractTaskRunner.java:117); at qupath.lib.gui.TaskRunnerFX.runTasks(TaskRunnerFX.java:106); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:147); at qupath.lib.gui.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:177); at java.base/java.lang.Thread.run(Unknown Source); Caused by: java.util.ConcurrentModificationException; at java.base/java.util.ArrayList.checkForComodification(Unknown Source); at java.base/java.util.ArrayList.equals(Unknown Source); at java.base/java.util.WeakHashMap.matchesKey(Unknown Source); at java.base/java.util.WeakHashMap.get(Unknown Source); at java.base/java.util.Collections$SynchronizedMap.get(Unknown Source); at qupath.lib.measurements.NumericMeasurementList$AbstractNumericMeasurementList.getNameMap(NumericMeasurementList.java:142); at qupath.lib.measurements.NumericMeasurementList$AbstractNumericMeasurementList.close(NumericMeasurementList.java:133); at qupath.lib.measurements.NumericMeasurementList$FloatList.close(NumericMeasurementList.java:352); at qupath.opencv.features.DelaunayTriangulation.addClusterMeasurements(DelaunayTriangulation.java:466); at qupath.opencv.features.DelaunayClusteringPlugin$DelaunayRunnable.run(DelaunayClusteringPlugin.java:215); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); ```; I can ask them to share a QuPath project if it's useful to you. . The issue appeared on a built from source linux QuPath if that's of any use. All the best and happy new year,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1182#issuecomment-1876997601:1924,concurren,concurrent,1924,https://qupath.github.io,https://github.com/qupath/qupath/issues/1182#issuecomment-1876997601,6,['concurren'],['concurrent']
Performance,"ath/lib/images/ImageData;Lqupath/lib/regions/RegionRequest;)Ljava/awt/image/BufferedImage;+235; j qupath.lib.classifiers.pixel.PixelClassificationImageServer.readTile(Lqupath/lib/images/servers/TileRequest;)Ljava/awt/image/BufferedImage;+84; J 14172 c1 qupath.lib.images.servers.AbstractTileableImageServer.getTile(Lqupath/lib/images/servers/TileRequest;)Ljava/awt/image/BufferedImage; (133 bytes) @ 0x000001d52232b9dc [0x000001d52232b3e0+0x00000000000005fc]; J 14898 c1 qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(Lqupath/lib/regions/RegionRequest;)Ljava/awt/image/BufferedImage; (1110 bytes) @ 0x000001d522ceb264 [0x000001d522ce2920+0x0000000000008944]; j qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(Lqupath/lib/regions/RegionRequest;)Ljava/lang/Object;+2; j qupath.lib.gui.ml.PixelClassificationOverlay.lambda$requestTile$2(Lqupath/lib/images/servers/TileRequest;Lqupath/lib/images/servers/ImageServer;)V+32; j qupath.lib.gui.ml.PixelClassificationOverlay$$Lambda$1631.run()V+12; J 12931 c1 java.util.concurrent.Executors$RunnableAdapter.call()Ljava/lang/Object; java.base@13.0.1 (14 bytes) @ 0x000001d521d305d4 [0x000001d521d304c0+0x0000000000000114]; J 14612 c1 java.util.concurrent.FutureTask.run()V java.base@13.0.1 (123 bytes) @ 0x000001d52225e6fc [0x000001d52225e020+0x00000000000006dc]; j java.util.concurrent.ThreadPoolExecutor.runWorker(Ljava/util/concurrent/ThreadPoolExecutor$Worker;)V+92 java.base@13.0.1; j java.util.concurrent.ThreadPoolExecutor$Worker.run()V+5 java.base@13.0.1; j java.lang.Thread.run()V+11 java.base@13.0.1; v ~StubRoutines::call_stub. siginfo: EXCEPTION_ACCESS_VIOLATION (0xc0000005), reading address 0xffffffffffffffff. ...; ```; The crash doesn't happen consistently. **Expected behavior**; I want to see a live prediction of the classifier and save it. Then I want to apply the classifier to my images. **Desktop (please complete the following information):**; - OS: Windows 10; - QuPath Version 0.2.0 m8",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/394:4422,concurren,concurrent,4422,https://qupath.github.io,https://github.com/qupath/qupath/issues/394,5,['concurren'],['concurrent']
Performance,"athPrefs - Locale FORMAT set to fr_BE; 12:25:42.714 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale DISPLAY set to en_US; 12:25:42.742 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 4096,00 MB; 12:25:43.922 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Refreshing extensions in /home/joelrv/QuPath/extensions; 12:25:43.923 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Added extension: /home/joelrv/QuPath/extensions/qupath-extension-bioformats.jar; 12:25:43.923 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Added extension: /home/joelrv/QuPath/extensions/bioformats_package.jar; 12:25:43.943 [JavaFX Application Thread] [INFO ] q.l.i.s.BioFormatsOptionsExtension - Bio-Formats version 5.9.2; 12:25:44.261 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Light; 12:25:44.262 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 12:25:44.262 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 12:25:55.878 [JavaFX Application Thread] [ERROR] q.l.i.servers.OpenslideImageServer - Openslide: Property not available: openslide.mpp-x; 12:25:55.879 [JavaFX Application Thread] [ERROR] q.l.i.servers.OpenslideImageServer - Openslide: Property not available: openslide.mpp-y; 12:25:55.879 [JavaFX Application Thread] [ERROR] q.l.i.servers.OpenslideImageServer - Openslide: Property not available: openslide.objective-power; 12:25:55.895 [JavaFX Application Thread] [INFO ] q.l.i.servers.OpenslideImageServer - Test reading thumbnail with openslide: passed (BufferedImage@58da6639: type = 1 DirectColorModel: rmask=ff0000 gmask=ff00 bmask=ff amask=0 IntegerInterleavedRaster: width = 194 height = 200 #Bands = 3 xOff = 0 yOff = 0 dataOffset[0] 0); 12:25:55.896 [JavaFX Application Thread] [INFO ] q.l.i.servers.ImageServerProvider - Returning server: OpenSlide for /",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/279#issuecomment-472813709:1494,Perform,Performing,1494,https://qupath.github.io,https://github.com/qupath/qupath/issues/279#issuecomment-472813709,1,['Perform'],['Performing']
Performance,"attempt , but can't seem to repeat it. . ```; Picked up _JAVA_OPTIONS: -Dawt.useSystemAAFontSettings=on; 12:35:11.253 [JavaFX Application Thread] [WARN ] qupath.lib.gui.QuPathGUI - No directory set for log files! None will be written.; 12:35:11.260 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - QuPath build: Version: 0.2.0-m12; Build time: 2020-05-26, 12:34; 12:35:11.263 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Setting tile cache size to 1981.50 MB (25.0% max memory). (QuPath-0.2.0-m12:49988): Gdk-WARNING **: 12:35:11.652: XSetErrorHandler() called with a GDK error trap pushed. Don't do that. 12:35:12.161 [JavaFX Application Thread] [INFO ] q.l.i.s.b.BioFormatsOptionsExtension - Bio-Formats version 6.5.0; 12:35:12.165 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Bio-Formats server options (Bio-Formats 6.5.0) (12 ms); 12:35:12.166 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Experimental commands (1 ms); 12:35:12.199 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Experimental commands (33 ms); 12:35:12.234 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension ImageJ extension (34 ms); Warning: Could not load Loader: java.lang.UnsatisfiedLinkError: no jnijavacpp in java.library.path: [/home/gordon/src/qupath/build/dist/QuPath-0.2.0-m12/lib/app, /home/gordon/src/qupath/build/dist/QuPath-0.2.0-m12/bin]; 12:35:12.248 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension JPen extension (13 ms); May 26, 2020 12:35:12 PM jpen.provider.NativeLibraryLoader$4 run; INFO: loading JPen 2-150301 JNI library: jpen-2-4-x86_64 ...; May 26, 2020 12:35:12 PM jpen.provider.NativeLibraryLoader$4 run; INFO: jpen-2-4-x86_64 loaded; Warning: Could not load Pointer: java.lang.UnsatisfiedLinkError: no jnijavacpp in java.library.path: [/home/gordon/src/qupath/build/dist/QuPath-0.2.0-m12/lib/app, /home/go",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/484#issuecomment-634101819:1357,Load,Loaded,1357,https://qupath.github.io,https://github.com/qupath/qupath/issues/484#issuecomment-634101819,1,['Load'],['Loaded']
Performance,"ava/lang/String;[BIILjava/security/ProtectionDomain;)Ljava/lang/Class; java.base@16.0.2 (43 bytes) @ 0x00007f593b0f1dc4 [0x00007f593b0f1a80+0x0000000000000344]; J 939 c1 java.security.SecureClassLoader.defineClass(Ljava/lang/String;[BIILjava/security/CodeSource;)Ljava/lang/Class; java.base@16.0.2 (16 bytes) @ 0x00007f593b150c8c [0x00007f593b150bc0+0x00000000000000cc]; J 739 c1 jdk.internal.loader.BuiltinClassLoader.defineClass(Ljava/lang/String;Ljdk/internal/loader/Resource;)Ljava/lang/Class; java.base@16.0.2 (121 bytes) @ 0x00007f593b0e9acc [0x00007f593b0e8c20+0x0000000000000eac]; J 653 c1 jdk.internal.loader.BuiltinClassLoader.findClassOnClassPathOrNull(Ljava/lang/String;)Ljava/lang/Class; java.base@16.0.2 (64 bytes) @ 0x00007f593b0be434 [0x00007f593b0bd460+0x0000000000000fd4]; J 3884 c1 jdk.internal.loader.BuiltinClassLoader.loadClassOrNull(Ljava/lang/String;Z)Ljava/lang/Class; java.base@16.0.2 (143 bytes) @ 0x00007f593b6e8024 [0x00007f593b6e71c0+0x0000000000000e64]; J 632 c1 jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(Ljava/lang/String;Z)Ljava/lang/Class; java.base@16.0.2 (40 bytes) @ 0x00007f593b0b206c [0x00007f593b0b1a60+0x000000000000060c]; J 631 c1 java.lang.ClassLoader.loadClass(Ljava/lang/String;)Ljava/lang/Class; java.base@16.0.2 (7 bytes) @ 0x00007f593b0b1134 [0x00007f593b0b1040+0x00000000000000f4]; v ~StubRoutines::call_stub; j qupath.lib.images.servers.bioformats.BioFormatsImageServer$ReaderPool.openImage(Lqupath/lib/images/servers/TileRequest;IIZLjava/awt/image/ColorModel;)Ljava/awt/image/BufferedImage;+249; j qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(Lqupath/lib/images/servers/TileRequest;)Ljava/awt/image/BufferedImage;+21; ```; This makes it look like something has gone wrong deeper in the bowels of Java, and I don't see how to resolve it from the QuPath side. I'm reluctant to return to the v0.3.0 method of parallelisation, since it had other (more frequent) problems https://github.com/qupath/qupath/issues/865",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/932#issuecomment-1057931302:2265,load,loader,2265,https://qupath.github.io,https://github.com/qupath/qupath/issues/932#issuecomment-1057931302,3,['load'],"['loadClass', 'loader']"
Performance,"b.com/user-attachments/assets/21b82d18-ce97-45c3-9644-7abdf85ab007). 3. If I repeat with **the outer ellipse selected**, I get *no connections at all*.; This is because the ellipse isn't set to be a parent of any of the other objects - this would change if I called *Resolve hierarchy* first. ![3-ellipse](https://github.com/user-attachments/assets/3c39bea5-9a9c-4ae3-bcc9-7ece1e8bae9c). 4. If I repeat with **the inner rectangles selected**, I get connections that don't cross *and I don't get any exception*.; This is because each cell is only handled once, so I don't get the concurrency trouble. ![4-inner rectangles](https://github.com/user-attachments/assets/74edf4a3-05c0-49ea-bd38-f82d327d9564). 5. If I repeat with **only 1 inner rectangle selected**, I get connections within that rectangle only. ![5-single rectangle](https://github.com/user-attachments/assets/492cf523-c58d-4b48-b417-ac44662a7a5a). **Expected behavior**; This isn't obvious... Nevertheless:; 1. The `ConcurrentModificationException` is clearly bad. But it's also kind of helpful here, because 2. and 4. give different results... and when that's the case, if we select all the annotations in 2. and 4. in one go, it's not obvious what *should* happen.; 2. The reliance on hierarchical relationships may not be very intuitive to a user, since measurements like 'Positive %' are dynamically computed using spatial location relative to any selected annotation - not hierarchical relationships. **Desktop (please complete the following information):**; - OS: All; - QuPath Version: v0.5.1 (and earlier). **Additional context**; This relates to:; * #1444; * #1466. The behavior of *Delaunay cluster features 2D* is *in general* not very good for more reasons than these. For example, the display of the connection lines is already a bit of a hack (smuggled into `ImageData` properties) - and showing/hiding these can be unreliable. But fixing #1466 risks swallowing the `ConcurrentModificationException`, meaning we get unexpec",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1590:4072,Concurren,ConcurrentModificationException,4072,https://qupath.github.io,https://github.com/qupath/qupath/issues/1590,1,['Concurren'],['ConcurrentModificationException']
Performance,"back to QuPath's attempt to synchronize the selected within QuPath’s object hierarchy with the objects shown in the JavaFX ```TreeView``` used in the *Hierarchy* tab. Basically, JavaFX’s ```TreeView``` is forced to do a rather slow check along all expanded nodes to look for objects... and if you have a single expanded node containing >~ 10 000 objects expanded within the ```TreeView``` then this can be *extremely slow*. It likely hasn't actually crashed… but it would take an unrealistically long time to become responsive again. The problem is intermittent because expanded nodes with only a few thousand objects in them (e.g. TMA cores) can be handled quite quickly. Additionally, large numbers of objects can be handled so long as the parent objects within the tree aren't expanded, or the objects are contained within multiple smaller annotations rather than a single, very large region. As such, TMA slides and core biopsies likely work (given that the objects are stored within smaller regions), while some whole face sections may be problematic depending on what processing is performed and how. Since the issue appears to be isolated to the display of large numbers of detections within a ```TreeView```, a straightforward fix in a future QuPath release may be to simply exclude detections from the ```TreeView``` by default, showing instead only TMA cores and annotations. In the meantime, hopefully this description of the issue might help anyone encountering it to know the cause, and look for workarounds for their uses. For example, if it is still required to analyze a single large region containing a large number of detections, then *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* has recently received an update to enable the creation of 'annotation tiles'. Using this, the larger annotation can be partitioned into smaller ones, which can then be processed separately. Some additional care is needed to ensure that the correct annotations ar",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/41:1689,perform,performed,1689,https://qupath.github.io,https://github.com/qupath/qupath/issues/41,1,['perform'],['performed']
Performance,bb000 ---p 00000000 00:00 0 ; 7f78a2cbb000-7f78a34bb000 rw-p 00000000 00:00 0 ; 7f78a34bb000-7f78ab4bb000 rw-p 00000000 00:00 0 ; 7f78ab4bb000-7f78ab4bc000 ---p 00000000 00:00 0 ; 7f78ab4bc000-7f78abcbc000 rw-p 00000000 00:00 0 ; 7f78abcbc000-7f78b3cbc000 rw-p 00000000 00:00 0 ; 7f78b3cbc000-7f78b3cbd000 ---p 00000000 00:00 0 ; 7f78b3cbd000-7f78b44bd000 rw-p 00000000 00:00 0 ; 7f78b44bd000-7f78c44bd000 rw-p 00000000 00:00 0 ; 7f78c44bd000-7f78c44be000 ---p 00000000 00:00 0 ; 7f78c44be000-7f78c4cbe000 rw-p 00000000 00:00 0 ; 7f78c4cbe000-7f78c4cbf000 ---p 00000000 00:00 0 ; 7f78c4cbf000-7f78c54bf000 rw-p 00000000 00:00 0 ; 7f78c54bf000-7f78c54c0000 ---p 00000000 00:00 0 ; 7f78c54c0000-7f78c5cc0000 rw-p 00000000 00:00 0 ; 7f78c5cc0000-7f78c79d9000 r-xp 00000000 00:2f 2345794468 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libopenblas.so.0; 7f78c79d9000-7f78c7bd8000 ---p 01d19000 00:2f 2345794468 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libopenblas.so.0; 7f78c7bd8000-7f78c7bde000 r--p 01d18000 00:2f 2345794468 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libopenblas.so.0; 7f78c7bde000-7f78c7bf4000 rw-p 01d1e000 00:2f 2345794468 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libopenblas.so.0; 7f78c7bf4000-7f78c7c20000 rw-p 00000000 00:00 0 ; 7f78c7c20000-7f78c8400000 ---p 00000000 00:00 0 ; 7f78c87f9000-7f78d87f9000 rw-p 00000000 00:00 0 ; 7f78d87f9000-7f78d87fa000 ---p 00000000 00:00 0 ; 7f78d87fa000-7f78d8ffa000 rw-p 00000000 00:00 0 ; 7f78d8ffa000-7f78e0ffa000 rw-p 00000000 00:00 0 ; 7f78e0ffa000-7f78e0ffb000 ---p 00000000 00:00 0 ; 7f78e0ffb000-7f78e17fb000 rw-p 00000000 00:00 0 ; 7f78e17fb000-7f78e97fb000 rw-p 00000000 00:00 0 ; 7f78e97fb000-7f78e97fc000 ---p 00000000 00:00 0 ; 7f78e97fc000-7f78e9ffc000 rw-p 00000000 00:,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018:7863,cache,cache,7863,https://qupath.github.io,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018,1,['cache'],['cache']
Performance,bytedeco/openblas/macosx-x86_64/libgfortran.dylib; gfortran@.4 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgfortran.4.dylib; gcc_s@.1 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgcc_s.1.dylib; jniopencv_ml : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_ml.dylib; opencv_imgproc@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_imgproc.405.dylib; jniopencv_dnn : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_dnn.dylib; jnijavacpp : 	/Users/pbankhea/.javacpp/cache/javacpp-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/javacpp/macosx-x86_64/libjnijavacpp.dylib; jniopenblas : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libjniopenblas.dylib; quadmath@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libquadmath.0.dylib; openblas_nolapack@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libopenblas_nolapack.0.dylib; opencv_core@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_core.405.dylib; jniopenblas_nolapack : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libjniopenblas_nolapack.dylib; jniopencv_imgproc : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_imgproc.dylib; openblas@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macos,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980:1901,cache,cache,1901,https://qupath.github.io,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980,1,['cache'],['cache']
Performance,c(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:55); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:196); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:216); at Script1.run(Script1.groovy:3); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:317); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:155); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:766); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:696); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:676); at qupath.lib.gui.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1033); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by No double parameter with key 'haralickMin' at qupath.lib.plugins.parameters.ParameterList.getDoubleParameterValue(ParameterList.java:386); at qupath.lib.plugins.parameters.ParameterList.getDoubleParameterValue(ParameterList.java:427); at qupath.lib.algorithms.IntensityFeaturesPlugin$HaralickFeaturesComp.updateFeatures(IntensityFeaturesPlugin.java:1056); at qupath.lib.algorithms.IntensityFeaturesPlugin.processObject(IntensityFeaturesPlugin.java:628); at qupath.lib.algorithms.IntensityFeaturesPlugin$IntensityFeatureRunnable.run(IntensityFeaturesPlugin.java:454); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.con,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/358:2119,concurren,concurrent,2119,https://qupath.github.io,https://github.com/qupath/qupath/issues/358,1,['concurren'],['concurrent']
Performance,"c1bb0000)]. Stack: [0x00007f4ec1aaf000,0x00007f4ec1bb0000], sp=0x00007f4ec1bac3d0, free space=1012k; Native frames: (J=compiled Java code, A=aot compiled Java code, j=interpreted, Vv=VM code, C=native code); C [libc.so.6+0x9a23b] __libc_malloc+0x12b. Java frames: (J=compiled Java code, j=interpreted, Vv=VM code); J 758 java.lang.ClassLoader.defineClass1(Ljava/lang/ClassLoader;Ljava/lang/String;[BIILjava/security/ProtectionDomain;Ljava/lang/String;)Ljava/lang/Class; java.base@16.0.2 (0 bytes) @ 0x00007f594243a6f0 [0x00007f594243a640+0x00000000000000b0]; J 754 c1 java.lang.ClassLoader.defineClass(Ljava/lang/String;[BIILjava/security/ProtectionDomain;)Ljava/lang/Class; java.base@16.0.2 (43 bytes) @ 0x00007f593b0f1dc4 [0x00007f593b0f1a80+0x0000000000000344]; J 939 c1 java.security.SecureClassLoader.defineClass(Ljava/lang/String;[BIILjava/security/CodeSource;)Ljava/lang/Class; java.base@16.0.2 (16 bytes) @ 0x00007f593b150c8c [0x00007f593b150bc0+0x00000000000000cc]; J 739 c1 jdk.internal.loader.BuiltinClassLoader.defineClass(Ljava/lang/String;Ljdk/internal/loader/Resource;)Ljava/lang/Class; java.base@16.0.2 (121 bytes) @ 0x00007f593b0e9acc [0x00007f593b0e8c20+0x0000000000000eac]; J 653 c1 jdk.internal.loader.BuiltinClassLoader.findClassOnClassPathOrNull(Ljava/lang/String;)Ljava/lang/Class; java.base@16.0.2 (64 bytes) @ 0x00007f593b0be434 [0x00007f593b0bd460+0x0000000000000fd4]; J 3884 c1 jdk.internal.loader.BuiltinClassLoader.loadClassOrNull(Ljava/lang/String;Z)Ljava/lang/Class; java.base@16.0.2 (143 bytes) @ 0x00007f593b6e8024 [0x00007f593b6e71c0+0x0000000000000e64]; J 632 c1 jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(Ljava/lang/String;Z)Ljava/lang/Class; java.base@16.0.2 (40 bytes) @ 0x00007f593b0b206c [0x00007f593b0b1a60+0x000000000000060c]; J 631 c1 java.lang.ClassLoader.loadClass(Ljava/lang/String;)Ljava/lang/Class; java.base@16.0.2 (7 bytes) @ 0x00007f593b0b1134 [0x00007f593b0b1040+0x00000000000000f4]; v ~StubRoutines::call_stub; j qupath.lib.images.se",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/932#issuecomment-1057931302:1651,load,loader,1651,https://qupath.github.io,https://github.com/qupath/qupath/issues/932#issuecomment-1057931302,1,['load'],['loader']
Performance,callsite.AbstractCallSite.callStatic(AbstractCallSite.java:196); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:216); at Script1.run(Script1.groovy:3); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:317); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:155); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:766); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:696); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:676); at qupath.lib.gui.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1033); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by No double parameter with key 'haralickMin' at qupath.lib.plugins.parameters.ParameterList.getDoubleParameterValue(ParameterList.java:386); at qupath.lib.plugins.parameters.ParameterList.getDoubleParameterValue(ParameterList.java:427); at qupath.lib.algorithms.IntensityFeaturesPlugin$HaralickFeaturesComp.updateFeatures(IntensityFeaturesPlugin.java:1056); at qupath.lib.algorithms.IntensityFeaturesPlugin.processObject(IntensityFeaturesPlugin.java:628); at qupath.lib.algorithms.IntensityFeaturesPlugin$IntensityFeatureRunnable.run(IntensityFeaturesPlugin.java:454); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.c,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/358:2265,concurren,concurrent,2265,https://qupath.github.io,https://github.com/qupath/qupath/issues/358,1,['concurren'],['concurrent']
Performance,"cationException; 	at java.base/java.util.ArrayList$Itr.checkForComodification(Unknown Source); 	at java.base/java.util.ArrayList$Itr.next(Unknown Source); 	at java.base/java.util.Collections$UnmodifiableCollection$1.next(Unknown Source); 	at java.base/java.util.AbstractCollection.addAll(Unknown Source); 	at qupath.lib.objects.PathObjectTools.getAvailableFeatures(PathObjectTools.java:2026); 	at qupath.opencv.features.DelaunayTriangulation.<init>(DelaunayTriangulation.java:86); 	at qupath.opencv.features.DelaunayClusteringPlugin$DelaunayRunnable.run(DelaunayClusteringPlugin.java:208); 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); 	at java.base/java.util.concurrent.FutureTask.run(Unknown Source); 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); 	at java.base/java.util.concurrent.FutureTask.run(Unknown Source); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); 	... 1 more; ```. 2. If I repeat with **the outer rectangle selected**, then I *do* see connections.; This is because the triangulation uses *all descendant detections below the rectangle, based on the object hierarchy*. ![2-rectangle](https://github.com/user-attachments/assets/21b82d18-ce97-45c3-9644-7abdf85ab007). 3. If I repeat with **the outer ellipse selected**, I get *no connections at all*.; This is because the ellipse isn't set to be a parent of any of the other objects - this would change if I called *Resolve hierarchy* first. ![3-ellipse](https://github.com/user-attachments/assets/3c39bea5-9a9c-4ae3-bcc9-7ece1e8bae9c). 4. If I repeat with **the inner rectangles selected**, I get connections that don't cross *and I don't get any exception*.; This is because each cell is only handled once, so I don't get the concurrency trouble. ![4-inner rectangles](https://github.com/user-attachments/assets/74edf4a3-05c0-49ea-bd38-f82d327d95",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1590:2786,concurren,concurrent,2786,https://qupath.github.io,https://github.com/qupath/qupath/issues/1590,1,['concurren'],['concurrent']
Performance,"change in memory usage is occurring when the QuPath project is being loaded, indicating that these images may not be pre-loaded (i.e. cached) during loading of the project itself. My guess is that the thumbnails are being reconstructed each time the QuPath project is loaded (computer must be restarted to reproduce, closing and relaunching QuPath is not sufficient). Given that thumbnail generation was updated in the changelog of the newest unofficial release, I'll build from source now and close the ticket if I can't reproduce the bug. It's a minor inconvenience at best, especially since it's only a delay of two minutes. But keep in mind, the CPU here is a Ryzen 5950X with among the highest single thread speeds of desktop CPUs, and only 1 of the 32 threads is being used during this period. Depending on the root cause and a user's hardware configuration, load times may scale linearly or exponentially as project sizes move into the range of thousands of images. If this is caused by thumbnail generation, then this may only be affecting multiplexed IHC images such as those acquired through IMC or CODEX. **To Reproduce**; Video demonstration: https://www.youtube.com/watch?v=q4Jn9UTKUMw; 1. Create a QuPath project; 2. Load ~300 IMC images. Example IMC images can be found here: https://drive.google.com/file/d/1UcQmiIcjIfYdBVK1v6Phb32FBjHXciuH/view; 3. Close QuPath and restart system; 4. Launch QuPath and open the aforementioned project. Observe relatively long project load times. **Expected behavior**; Loading of a QuPath project should take a few seconds, especially if no measurements are present. **Screenshots**; See video demonstration above. Note, memory usage doesn't change substantially when project is being loaded, however one thread is maxed at 100%, indicating that some kind of non-parallelized process is acting as the rate limiting step. **Desktop (please complete the following information):**; - OS: Windows 10; - QuPath Version: 0.4.0 snapshot built on 2022-01-24",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1154:2090,Load,Load,2090,https://qupath.github.io,https://github.com/qupath/qupath/issues/1154,4,"['Load', 'load']","['Load', 'Loading', 'load', 'loaded']"
Performance,"chy) or overlapping. For 'flat' annotation arrangements the behavior is *mostly ok*, except that it does rely on *hierarchy relationships* rather than *spatial relationships*.; Which is to say, it hasn't really changed since v0.1.2. **To Reproduce**; Create an arrangement of objects similar to that shown below:. ![0-orig](https://github.com/user-attachments/assets/cf1a87fc-c73a-4ac6-be24-d830f0014604). 1. If I run *Delaunay cluster features 2D* with **_all_ annotations selected**, I see triangulation lines which *do not cross the boundary between the annotations containing cells*. ![1-all selected](https://github.com/user-attachments/assets/3309e1e3-76ca-4ec7-bf5c-e0c76b8f2d96). But I **also** get a `ConcurrentModificationException`:; ```; 15:47:01.829	[Plugin thread]	ERROR	qupath.lib.plugins.AbstractTaskRunner	Error running plugin: java.util.ConcurrentModificationException	java.util.concurrent.ExecutionException: java.util.ConcurrentModificationException; 	at java.base/java.util.concurrent.FutureTask.report(Unknown Source); 	at java.base/java.util.concurrent.FutureTask.get(Unknown Source); 	at qupath.lib.plugins.AbstractTaskRunner.awaitCompletion(AbstractTaskRunner.java:147); 	at qupath.lib.plugins.AbstractTaskRunner.runTasks(AbstractTaskRunner.java:117); 	at qupath.lib.gui.TaskRunnerFX.runTasks(TaskRunnerFX.java:106); 	at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:147); 	at qupath.lib.gui.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:177); 	at java.base/java.lang.Thread.run(Unknown Source); Caused by: java.util.ConcurrentModificationException; 	at java.base/java.util.ArrayList$Itr.checkForComodification(Unknown Source); 	at java.base/java.util.ArrayList$Itr.next(Unknown Source); 	at java.base/java.util.Collections$UnmodifiableCollection$1.next(Unknown Source); 	at java.base/java.util.AbstractCollection.addAll(Unknown Source); 	at qupath.lib.objects.PathObjectTools.getAvailableFeatures(PathObjectTools.java:2026); 	at qupath.opencv.fea",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1590:1199,concurren,concurrent,1199,https://qupath.github.io,https://github.com/qupath/qupath/issues/1590,1,['concurren'],['concurrent']
Performance,"compressed, tiled TIFFs do not load on macOS Catalina",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/627:31,load,load,31,https://qupath.github.io,https://github.com/qupath/qupath/issues/627,1,['load'],['load']
Performance,concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.lib.images.servers.CroppedImageServer.readRegion(CroppedImageServer.java:90); at qupath.lib.images.servers.CroppedImageServer.readRegion(CroppedImageServer.java:39); at qupath.lib.images.servers.SparseImageServer.readTile(SparseImageServer.java:265); at qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:863); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:902); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:216); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); ```,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583:4740,concurren,concurrent,4740,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583,6,['concurren'],['concurrent']
Performance,"cs.framework/Versions/A/CoreGraphics (compatibility version 64.0.0, current version 1690.3.3); 	/System/Library/Frameworks/CoreServices.framework/Versions/A/CoreServices (compatibility version 1.0.0, current version 1228.0.0); 	/System/Library/Frameworks/CoreText.framework/Versions/A/CoreText (compatibility version 1.0.0, current version 1.0.0); 	/usr/lib/libobjc.A.dylib (compatibility version 1.0.0, current version 228.0.0); ```; and notably `/usr/local/opt/gettext/lib/libintl.8.dylib` stops him from using it on an x86-64 machine, though this doesn't seem to be a problem on CI machines. ## Linux. The below is out dated; when dynamically linking `glib`, our binaries are fine. > While it's easy enough to get a SO of openslide with minimal dependencies (`libpcre2-8` stubbornly remains dynamically > linked), issues arise when trying to load this alongside JavaFX. Specifically, we get a glib warning followed by an error:; > ```; > (java:71634): GLib-GObject-WARNING **: 14:32:40.458: cannot register existing type 'gchar'; > **; > GLib-GObject:ERROR:../../../meson/subprojects/glib-2.72.0/gobject/gvaluetypes.c:454:_g_value_types_init: assertion failed: (type == G_TYPE_CHAR); > ```; > This is less urgent, as we can just distribute QuPath as `deb`/`rpm` packages, and specify `openslide-tools` as a dependency, as we will no longer depend on `openslide-java`. ## Plan for 0.5.0 release. - Windows will use a JAR of the OpenSlide builds, which we can extract to temp files and then load.; - Linux releases will depend on `openslide-tools`; if this is installed, then `libopenslide.so` should be on the search path.; - Mac builds will require homebrew (or similar) installs of `openslide`. However, if we could resolve the issues with the mac and Linux binaries, then it'd be great to use the same (or at least similar) processes on all platforms. Would appreciate any feedback/advice from @bgilbert and @jcupitt on the best way forward, or if yous have run into some of these issues before.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/629#issuecomment-1723504495:6336,load,load,6336,https://qupath.github.io,https://github.com/qupath/qupath/issues/629#issuecomment-1723504495,1,['load'],['load']
Performance,"ctionDomain;Ljava/lang/String;)Ljava/lang/Class; java.base@16.0.2 (0 bytes) @ 0x00007f594243a6f0 [0x00007f594243a640+0x00000000000000b0]; J 754 c1 java.lang.ClassLoader.defineClass(Ljava/lang/String;[BIILjava/security/ProtectionDomain;)Ljava/lang/Class; java.base@16.0.2 (43 bytes) @ 0x00007f593b0f1dc4 [0x00007f593b0f1a80+0x0000000000000344]; J 939 c1 java.security.SecureClassLoader.defineClass(Ljava/lang/String;[BIILjava/security/CodeSource;)Ljava/lang/Class; java.base@16.0.2 (16 bytes) @ 0x00007f593b150c8c [0x00007f593b150bc0+0x00000000000000cc]; J 739 c1 jdk.internal.loader.BuiltinClassLoader.defineClass(Ljava/lang/String;Ljdk/internal/loader/Resource;)Ljava/lang/Class; java.base@16.0.2 (121 bytes) @ 0x00007f593b0e9acc [0x00007f593b0e8c20+0x0000000000000eac]; J 653 c1 jdk.internal.loader.BuiltinClassLoader.findClassOnClassPathOrNull(Ljava/lang/String;)Ljava/lang/Class; java.base@16.0.2 (64 bytes) @ 0x00007f593b0be434 [0x00007f593b0bd460+0x0000000000000fd4]; J 3884 c1 jdk.internal.loader.BuiltinClassLoader.loadClassOrNull(Ljava/lang/String;Z)Ljava/lang/Class; java.base@16.0.2 (143 bytes) @ 0x00007f593b6e8024 [0x00007f593b6e71c0+0x0000000000000e64]; J 632 c1 jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(Ljava/lang/String;Z)Ljava/lang/Class; java.base@16.0.2 (40 bytes) @ 0x00007f593b0b206c [0x00007f593b0b1a60+0x000000000000060c]; J 631 c1 java.lang.ClassLoader.loadClass(Ljava/lang/String;)Ljava/lang/Class; java.base@16.0.2 (7 bytes) @ 0x00007f593b0b1134 [0x00007f593b0b1040+0x00000000000000f4]; v ~StubRoutines::call_stub; j qupath.lib.images.servers.bioformats.BioFormatsImageServer$ReaderPool.openImage(Lqupath/lib/images/servers/TileRequest;IIZLjava/awt/image/ColorModel;)Ljava/awt/image/BufferedImage;+249; j qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(Lqupath/lib/images/servers/TileRequest;)Ljava/awt/image/BufferedImage;+21; ```; This makes it look like something has gone wrong deeper in the bowels of Java, and I don't see how to res",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/932#issuecomment-1057931302:2072,load,loader,2072,https://qupath.github.io,https://github.com/qupath/qupath/issues/932#issuecomment-1057931302,1,['load'],['loader']
Performance,"ctsForRegion(ImageRegion region); public Collection<PathObject> getAnnotationsForRegion(ImageRegion region); public Collection<PathObject> getAllDetectionsForRegion(ImageRegion region); ```. As the javadocs mention, this is permitted to return *too many objects*.; Its purpose is to act as a fast spatial cache, where returned objects are likely to be filtered further. To help with this, there are new methods in `PathObjectTools`:; ```java; public static <T extends PathObject> Collection<T> filterByROICovers(ROI roi, Collection<T> pathObjects); public static <T extends PathObject> Collection<T> filterByROIIntersects(ROI roi, Collection<T> pathObjects); public static <T extends PathObject> Collection<T> filterByROIContainsCentroid(ROI roi, Collection<T> pathObjects); ```; These can apply filters that normally require some `ROI.getGeometry()` gymnastics, and may be faster through the use of prepared geometries and parallel streams. When cells are involved, one might want to perform the tests using the *nucleus* ROI rather than the main (outer) ROI. This is also what happens internally with the hierarchy checks (i.e. the nucleus centroid is used where possible to check if a cell is inside a ROI). The following methods support that:; ```java; public static <T extends PathObject> Collection<T> filterByROICoversNucleus(ROI roi, Collection<T> pathObjects); public static <T extends PathObject> Collection<T> filterByROIIntersectsNucleus(ROI roi, Collection<T> pathObjects); public static <T extends PathObject> Collection<T> filterByROIContainsNucleusCentroid(ROI roi, Collection<T> pathObjects); ```. In case you just want to check if objects are present quickly - but don't necessarily need the objects themselves - you can use:. ```java; // Old method, deprecated; public boolean hasObjectsForRegion(Class<? extends PathObject> cls, ImageRegion region). // New methods; public boolean hasObjectsForRegion(ImageRegion region); public boolean hasAnnotationsForRegion(ImageRegion region);",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1563:4423,perform,perform,4423,https://qupath.github.io,https://github.com/qupath/qupath/pull/1563,1,['perform'],['perform']
Performance,d3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79436ef000-7f79436f0000 r--p 00003000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79436f0000-7f79436f1000 rw-p 00004000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79436f1000-7f79436f6000 r-xp 00000000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79436f6000-7f79438f5000 ---p 00005000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f5000-7f79438f6000 r--p 00004000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f6000-7f79438f7000 rw-p 00005000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f7000-7f79438fa000 r-xp 00000000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f79438fa000-7f7943af9000 ---p 00003000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f7943af9000-7f7943afa000 r--p 00002000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f7943afa000-7f7943afb000 rw-p 00003000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f7943afb000-7f7943aff000 ---p 00000000 00:00 0 ; 7f7943aff000-7f7943bfc000 rw-p 00000000 00:00 0 ; 7f7943bfc000-7f7943c00000 ---p 00000000 00:00 0 ; 7f7943c00000-7f7943cfd000 rw-p 00000000 00:00 0 ; 7f7943cfd000-7f7943d01000 ---p 00000000 00:00 0 ; 7f7943d01000-7f7943dfe000 rw-p 00000000 00:00 0 ; 7f7943dfe000-7f7943dff000 r-xp 00000000 fd:02 10819064523 /scratch3/downloads/QuPath/lib/runtime/lib/libprefs.so; 7f7943dff000-7f7943ffe000 ---p 00001000 fd:02 10819064523 /scratch3/downloads/QuPath/lib/runtime/lib/libprefs.so; 7f7943ffe000-7f7943fff000 r--p 00000000 fd:02 10819064523 /scratch3/downloads/QuPath/lib/runtime/lib/libprefs.so; 7f7943fff000-7f7944000000 rw-p 00001000 fd:02 10819064523 /scratch3/downloads/QuPath/lib/runtim,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018:19109,cache,cache,19109,https://qupath.github.io,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018,1,['cache'],['cache']
Performance,"dImage(AbstractTileableImageServer.java:166); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:19); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:536); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:573); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:156); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:120); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:47); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:269); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); ERROR: IOException exception reading file:/Volumes/Storage/Work/SLIDESCANS/190512_OLYMPUS_YKA_Batch/CRUK_YKA_16.1D_tam_2_20190513.vsi#1: x=9728, y=34816, w=512, h=512, z=0, t=0, downsample=1; at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:199); at java.base/sun.nio.ch.FileChannelImpl.endBlocking(FileChannelImpl.java:162); at java.base/sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:816); at java.base/sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:796); at loci.common.NIOByteBufferProvider.allocateDirect(NIOByteBufferProvider.java:127); at loci.common.NIOByteBufferProvider.allocate(NIOByteBufferProvider.java:112); at loci.common.NIOFileH",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:8159,concurren,concurrent,8159,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['concurren'],['concurrent']
Performance,de000 r--p 01d18000 00:2f 2345794464 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libopenblas_nolapack.so.0; 7f792bfde000-7f792bff4000 rw-p 01d1e000 00:2f 2345794464 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libopenblas_nolapack.so.0; 7f792bff4000-7f792c000000 rw-p 00000000 00:00 0 ; 7f792c000000-7f792c021000 rw-p 00000000 00:00 0 ; 7f792c021000-7f7930000000 ---p 00000000 00:00 0 ; 7f7930000000-7f7930021000 rw-p 00000000 00:00 0 ; 7f7930021000-7f7934000000 ---p 00000000 00:00 0 ; 7f7934000000-7f79349a9000 rw-p 00000000 00:00 0 ; 7f79349a9000-7f7938000000 ---p 00000000 00:00 0 ; 7f7938000000-7f793850e000 rw-p 00000000 00:00 0 ; 7f793850e000-7f793c000000 ---p 00000000 00:00 0 ; 7f793c000000-7f793c021000 rw-p 00000000 00:00 0 ; 7f793c021000-7f7940000000 ---p 00000000 00:00 0 ; 7f79401bb000-7f7940203000 r-xp 00000000 00:2f 2345794467 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libjniopenblas_nolapack.so; 7f7940203000-7f7940403000 ---p 00048000 00:2f 2345794467 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libjniopenblas_nolapack.so; 7f7940403000-7f7940404000 r--p 00048000 00:2f 2345794467 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libjniopenblas_nolapack.so; 7f7940404000-7f7940405000 rw-p 00049000 00:2f 2345794467 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libjniopenblas_nolapack.so; 7f7940405000-7f7940524000 r-xp 00000000 fd:00 100815288 /usr/lib64/libgfortran.so.3.0.0; 7f7940524000-7f7940724000 ---p 0011f000 fd:00 100815288 /usr/lib64/libgfortran.so.3.0.0; 7f7940724000-7f7940725000 r--p 0011f000 fd:00 100815288 /usr/lib64/libgfortran.so.3.0.0; 7f7940725000-7f7940727000 rw-p 00120000 fd:00 10081528,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018:11373,cache,cache,11373,https://qupath.github.io,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018,1,['cache'],['cache']
Performance,"different keys: `ANNOTATION_DESCRIPTION` ([here](https://github.com/qupath/qupath/blob/75ec9cebe5e3bc5843fc60b07b455ce1215e1fb9/qupath-core/src/main/java/qupath/lib/objects/PathAnnotationObject.java#L74)) and `note` ([here](https://github.com/qupath/qupath/blob/88c7cc45648c1d5b09a840bd1e497ea9a46453aa/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMACommands.java#L122)) respectively. Neither key is ideal for a general purpose.; * I propose introducing a general `text` property. However, it's not totally clear if objects written by previous versions should automatically be updated. If they are, then the data files may not open properly in older QuPath versions.; * One reason for a simple, lower-case property name (e.g. `text`) is that it should be GeoJSON-friendly, and work sensibly as a key. But is there a better key? Via markdown/html, it's possible to smuggle in more than just text.; * Should other object types support text/descriptions?; * **Root objects**: I think yes. It provides a way to append arbitrary text to any image.; * **Detection objects**: Maybe... this would enforce a map being created, which could make each detection considerably more heavyweight. But perhaps it should be permitted, and users simply warned that it's not generally a good idea.; * Consider the sensibleness of the the current implementation, which will:; * Render text as if it's markdown (which shouldn't change anything for most plain text); * Render html directly if the text starts with `<html>`; * Load a web page if the text starts with `https://`. Might be of interest to @yli-hallila especially for https://github.com/yli-hallila/qupath-edu-extension. <img width=""1356"" alt=""Screenshot 2022-07-11 at 16 35 58"" src=""https://user-images.githubusercontent.com/4690904/178302423-15d42432-4af3-40bd-a36c-5f88ac128327.png"">. <img width=""1373"" alt=""Screenshot 2022-07-11 at 16 36 36"" src=""https://user-images.githubusercontent.com/4690904/178302461-a1ab1fb4-b8fa-47a5-94bf-63f89859ced1.png"">",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1005:1870,Load,Load,1870,https://qupath.github.io,https://github.com/qupath/qupath/issues/1005,1,['Load'],['Load']
Performance,"dist script for cell detection, errors are generated before any detections. **Can avoid both by manual annotation** with a polygon tool to follow image boundaries -> so not sure if a crucial bug. Carried over from last release to v5. **To Reproduce**; Steps to reproduce the behavior:; 1. Ctl+Shift+A; 2. Run cell detection as a script:; ```; setImageType('FLUORESCENCE');; selectAnnotations();; runPlugin('qupath.imagej.detect.cells.WatershedCellDetection', '{""detectionImage"":""DAPI"",""requestedPixelSizeMicrons"":0.1,""backgroundRadiusMicrons"":4.0,""backgroundByReconstruction"":true,""medianRadiusMicrons"":1.0,""sigmaMicrons"":2.5,""minAreaMicrons"":11.0,""maxAreaMicrons"":400.0,""threshold"":1000.0,""watershedPostProcess"":true,""cellExpansionMicrons"":5.0,""includeNuclei"":true,""smoothBoundaries"":true,""makeMeasurements"":true}'); ```; 4. Error:; ```; ERROR: Error running plugin: java.lang.NullPointerException: Cannot invoke ""java.awt.image.BufferedImage.getSampleModel()"" because ""img"" is null; java.util.concurrent.ExecutionException: java.lang.NullPointerException: Cannot invoke ""java.awt.image.BufferedImage.getSampleModel()"" because ""img"" is null; at java.base/java.util.concurrent.FutureTask.report(Unknown Source); at java.base/java.util.concurrent.FutureTask.get(Unknown Source); at qupath.lib.plugins.AbstractTaskRunner.awaitCompletion(AbstractTaskRunner.java:147); at qupath.lib.plugins.AbstractTaskRunner.runTasks(AbstractTaskRunner.java:117); at qupath.lib.gui.TaskRunnerFX.runTasks(TaskRunnerFX.java:106); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:147); at qupath.lib.gui.QuPathGUI.runPlugin(QuPathGUI.java:2245); at qupath.lib.gui.scripting.QPEx.runPlugin(QPEx.java:248); at qupath.lib.gui.scripting.QPEx.runPlugin(QPEx.java:270); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript.run(QuPathScript:4); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:331); at org.codehaus.groovy.jsr22",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443:1295,concurren,concurrent,1295,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443,1,['concurren'],['concurrent']
Performance,"do that.; 10:11:48.207 [JavaFX Application Thread] [INFO ] q.l.i.s.b.BioFormatsOptionsExtension - Bio-Formats version 6.2.0; 10:11:48.216 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Bio-Formats server options (Bio-Formats 6.2.0) (20 ms); 10:11:48.235 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Experimental commands (19 ms); 10:11:48.278 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension ImageJ extension (42 ms); 10:11:48.290 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension JPen extension (12 ms); 10:11:48.294 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension OpenCV extensions (3 ms); Oct 13, 2019 10:11:48 AM jpen.provider.NativeLibraryLoader$4 run; INFO: loading JPen 2-150301 JNI library: jpen-2-4-x86_64 ...; Oct 13, 2019 10:11:48 AM jpen.provider.NativeLibraryLoader$4 run; INFO: jpen-2-4-x86_64 loaded; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.codehaus.groovy.vmplugin.v7.Java7$1 (file:/usr/local/src/QuPath-0.2.0-m4/app/groovy-2.5.7.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class,int); WARNING: Please consider reporting this to the maintainers of org.codehaus.groovy.vmplugin.v7.Java7$1; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 10:11:48.594 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Rich script editor extension (300 ms); 10:11:48.603 [JavaFX Application Thread] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1; 10:11:48.698 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: null; 10:11:48.698 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 10:11:48.704 [JavaFX Appli",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/369:2740,load,loaded,2740,https://qupath.github.io,https://github.com/qupath/qupath/issues/369,1,['load'],['loaded']
Performance,"doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$118(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:39:38.754 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Dark; 02:39:38.757 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 02:39:38.781 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 02:39:38.837 [JavaFX Application Thread] [INFO ] q.lib.gui.helpers.DisplayHelpers - QuPath Notice: This is a pre-release version of QuPath; Version: 0.0.6; Build time: 2016-11-16, 15:54; 02:40:13.093 [JavaFX Application Thread] [ERROR] q.l.i.servers.OpenslideServerBuilder - Could not load OpenSlide native library; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopenslide-jni.so: libopenslide.so.0: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at org.openslide.OpenSlideJNI.<clinit>(OpenSlideJNI.java:55); 	at org.openslide.OpenSlide.<clinit>(OpenSlide.java:53); 	at qupath.lib.images.servers.OpenslideImageServer.<init>(OpenslideImageServer.java:91); 	at qupath.lib.images.servers.OpenslideServerBuilder.buildServer(OpenslideServerBuilder.java:47); 	at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:115); 	at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2091); 	at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2015); 	a",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/27#issuecomment-262870405:3597,load,load,3597,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405,1,['load'],['load']
Performance,"e diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's often not entirely clear which are the options you want on a first go. There is no *Undo*, but if you save before running the command, *File &rarr; Revert* can get you back to where you were. The end result is a rather 'blocky' classification, where the size of the blocks depends upon how large the tiles are that you created. But if you need to downsample your image 8 times to get good enough performance with the Weka plugin, then using tiles that are 8x8 pixels gives you just as good a resolution in the end. Furthermore, with QuPath you can add some other kinds of features, particularly Haralick texture features on color-deconvolved images, which can be a better fit for pathology applications compared to some of the Weka features (which may be better for other applications). And you can do other things in QuPath to help with efficiency, such as create a script to find all pixels with high intensity values (background?) and remove them - thereby allowing you to avoid the memory and computational requirements of storing and classifying them. Therefore while there is some overhead involved in QuPath using objects rather than pixels in the way that *ilastik* and *Trainable Weka segmentation* do, QuPath's use of objects is sufficiently efficient and optimized that I think it offers a viable alternative in many cases.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/56#issuecomment-288506877:3070,perform,performance,3070,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877,2,"['optimiz', 'perform']","['optimized', 'performance']"
Performance,"e improvements over relying only on Bio-Formats... but it would _definitely_ be a lot more work to develop and support cross-platform. Option 2 (merging) is 'easiest' if that involves writing a new pyramidal OME-TIFF file... but that rather increases the amount of data involved, and requires knowing the coordinates where each core comes from. A practical issue here is that I have seen a .czi TMA (I believe yours, @arnmayer :) ) that Bio-Formats has several problems with. This thwarts any plan we might develop to resolve this independently of Zeiss or the Bio-Formats team. Specifically:; * Sometimes the co-ordinates defining the TMA core locations accessed through Bio-Formats appears simply to be wrong, so it's not possible to figure out where they _should_ be; * The size of the Bio-Formats reader is astronomically large (> 1 GB), which makes opening files slow. You can see this in the size of the .bfmemo files if they are created. This also means that it's not possible to create multiple readers (which QuPath normally does for performance).; * The low resolution 'overview' image seems to be corrupt. It is somehow interpreted by Bio-Formats as a single-channel non-pyramidal image yet throws an error when one tries to open it directly. However the image itself must be ok, as it looks fine in the Zeiss software. If this image can be shared with the Bio-Formats team, they may be able to address these issues. Finally, one of the delays to m3 is I've been doing the groundwork to make image servers smarter. The relevance here is that it means that an image server is able to dynamically crop and/or reposition parts of an image to generate 'pseudo' whole slide images in QuPath, which might be composed of different pieces. They can also do extra fancy things like apply color transforms or concatenate channels. It will take some time to make this to become a fully-usable part of the software, but it relates to the problem as follows:; * if your cores are as separate images, Qu",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/337#issuecomment-509982536:1615,perform,performance,1615,https://qupath.github.io,https://github.com/qupath/qupath/issues/337#issuecomment-509982536,1,['perform'],['performance']
Performance,"e same approach last week the builds would segfault (I think with the same pointer error balazs described above). I got the that error today on one attempt , but can't seem to repeat it. . ```; Picked up _JAVA_OPTIONS: -Dawt.useSystemAAFontSettings=on; 12:35:11.253 [JavaFX Application Thread] [WARN ] qupath.lib.gui.QuPathGUI - No directory set for log files! None will be written.; 12:35:11.260 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - QuPath build: Version: 0.2.0-m12; Build time: 2020-05-26, 12:34; 12:35:11.263 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Setting tile cache size to 1981.50 MB (25.0% max memory). (QuPath-0.2.0-m12:49988): Gdk-WARNING **: 12:35:11.652: XSetErrorHandler() called with a GDK error trap pushed. Don't do that. 12:35:12.161 [JavaFX Application Thread] [INFO ] q.l.i.s.b.BioFormatsOptionsExtension - Bio-Formats version 6.5.0; 12:35:12.165 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Bio-Formats server options (Bio-Formats 6.5.0) (12 ms); 12:35:12.166 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Experimental commands (1 ms); 12:35:12.199 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Experimental commands (33 ms); 12:35:12.234 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension ImageJ extension (34 ms); Warning: Could not load Loader: java.lang.UnsatisfiedLinkError: no jnijavacpp in java.library.path: [/home/gordon/src/qupath/build/dist/QuPath-0.2.0-m12/lib/app, /home/gordon/src/qupath/build/dist/QuPath-0.2.0-m12/bin]; 12:35:12.248 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension JPen extension (13 ms); May 26, 2020 12:35:12 PM jpen.provider.NativeLibraryLoader$4 run; INFO: loading JPen 2-150301 JNI library: jpen-2-4-x86_64 ...; May 26, 2020 12:35:12 PM jpen.provider.NativeLibraryLoader$4 run; INFO: jpen-2-4-x86_64 loaded; Warning: Could not load ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/484#issuecomment-634101819:1208,Load,Loaded,1208,https://qupath.github.io,https://github.com/qupath/qupath/issues/484#issuecomment-634101819,1,['Load'],['Loaded']
Performance,"e same results. - The software used to generate the OME-TIFF files was through a two-step process of converting MRXS files (written from 3DHISTECH software) into OME-TIFF files through the help of conversion tools from Glencoesoftware:. The first step used a tool called bioformats2raw (https://github.com/glencoesoftware/bioformats2raw) which converts MRXS files into Zarr file-type. . The second step used a tool called raw2ometiff (https://github.com/glencoesoftware/raw2ometiff) which converts the Zarr file into an OME-TIFF file type. - While viewing an image with QuPath-0.3.0 and checking _Show log_, these were the errors reported:. WARN: Unable to obtain full image format info for file:/C:/Users/aj_si/Desktop/poh_mrxs/OME-TIFF/C001110926E04.ome.tiff (class java.util.NoSuchElementException); INFO: Image data set to ImageData: Not set, C001110926E04.ome.tiff - C001110926E04. For QuPath-0.3.2, the result was the same except it did not have the ""WARN"" error. For QuPath-0.3.1 (which also can not cache tiles or load the resolution properly when zooming in), this was reported:. WARN: Unable to obtain full image format info for file:/C:/Users/aj_si/Desktop/poh_mrxs/OME-TIFF/C001110926E04.ome.tiff (class java.util.NoSuchElementException); INFO: Setting max Bio-Formats readers to 4; INFO: Image data set to ImageData: Not set, C001110926E04.ome.tiff - C001110926E04. ### Here is an example of my image while zoomed in using QuPath-0.3.0; <img width=""960"" alt=""QuPath_030_zoomed"" src=""https://user-images.githubusercontent.com/98191884/157751366-613ce0e7-1dc4-4e03-a0f4-8a055db1f3d7.PNG"">. ### Here is an example of my image while zoomed in using QuPath-0.3.2 (looks the same on QuPath-0.3.1); <img width=""960"" alt=""QuPath_032_zoomed"" src=""https://user-images.githubusercontent.com/98191884/157751374-6702bd00-8f17-4005-a56c-7b3a96f6c258.PNG"">. As well, here is a link to download two of my OME-TIFF images, if you would like to try viewing them on QuPath: http://gofile.me/6VSoS/CNJndmlCr",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/904#issuecomment-1064493475:1149,cache,cache,1149,https://qupath.github.io,https://github.com/qupath/qupath/issues/904#issuecomment-1064493475,2,"['cache', 'load']","['cache', 'load']"
Performance,"e the exact images that caused this error to occur. My guess is that this is actually an issue with OpenCV , given the exception `OpenCV(4.5.3) D:\a\javacpp-presets\javacpp-presets\opencv\cppbuild\windows-x86_64\opencv-4.5.3\modules\core\src\channels.cpp:141: error: (-215:Assertion failed) i1 >= 0 && j < ndsts && dst[j].depth() == depth in function 'cv::mixChannels'`. OpenCV's mixChannels: https://docs.opencv.org/3.4/d2/de8/group__core__array.html#ga51d768c270a1cdd3497255017c4504be. For now, I've been reducing the number of channels passed, which gives me a training accuracy of ~88%. But it would be great to train on all available data, and see what the variable importance is of each feature and channel. **To Reproduce**; Steps to reproduce the behavior:; 1. Create a project with ~143 IMC images; 2. Annotate structures within ~38 images with 5 different classifications of annotations; 3. Open a non-annotated image; 4. Attempt to train a pixel classifier using all channels, scales, and features, loading training from other annotated images in the project.; 5. Click ""Live Preview"", note the error at the end of the post. **Expected behavior**; A pixel classifier should be trained, and a preview should be applied to the currently loaded image. **Desktop (please complete the following information):**; - OS: Windows 10, 32-thread processor, 127/128 Gb RAM allocated for QuPath, ~500 Gb SSD storage for tile cache; - QuPath Version 0.3.2. **Additional context**; Error log:; ```; 12:10:44.040 [JavaFX Application Thread] [INFO ] q.p.g.c.ml.PixelClassifierPane - Creating training data from 38 images; 12:10:44.953 [JavaFX Application Thread] [ERROR] q.p.g.c.ml.PixelClassifierTraining - Error requesting features for ImageOp server: ImageData: Other, xxxx___ROI8_ROI_008.ome.tiff - ROI8_ROI_008.ome {""colorTransforms"":[{""channelName"":""Pr(141)_141-SMA""},{""channelName"":""Nd(142)_142Nd-CD19""},{""channelName"":""Nd(143)_143Nd-Vimentin""},{""channelName"":""Nd(144)_144Nd-cd14""},{""channelName"":""Nd",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/947:1526,load,loading,1526,https://qupath.github.io,https://github.com/qupath/qupath/issues/947,1,['load'],['loading']
Performance,e.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:206); at Script30.run(Script30.groovy:10); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ERROR: Error running plugin: java.lang.NullPointerException; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.scripting.QPEx.runPlugin(QPEx.java:266); at qupath.lib.scripting.QPEx.runPlugin(QPEx.java:286); at qupath.lib.scripting.QPEx$runPlugin.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallS,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:8666,concurren,concurrent,8666,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['concurren'],['concurrent']
Performance,e.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:206); at Script30.run(Script30.groovy:10); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ERROR: QuPath exception; at com.sun.glass.ui.Application.checkEventThread(Application.java:443); at com.sun.glass.ui.View.getNativeView(View.java:449); at com.sun.glass.ui.win.WinAccessible.get_HostRawElementProvider(WinAccessible.java:672); at com.sun.glass.ui.win.WinAccessible.UiaRaiseAutomationEvent(Native Method); at com.sun.glass.ui.win.WinAccessible.sendNotification(WinAccessible.java:287); at javafx.scene.Node.notifyAccessibleAttributeChanged(Node.java:9604); at javafx.scene.control.TableView$TableViewSelectionModel.focus(TableView.java:2003); at javafx.scene.control.TableView$TableViewArrayListSelectionModel.updateDefaultSelection(TableView.java:2930); at javafx.scene.control.TableView$TableViewArrayListSelectionModel.updateItemsO,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:5204,concurren,concurrent,5204,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['concurren'],['concurrent']
Performance,e.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:214); at Script30.run(Script30.groovy:12); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by null at qupath.lib.images.servers.BioFormatsImageServer.getTimePoint(BioFormatsImageServer.java:930); at qupath.imagej.images.servers.BufferedImagePlusServer.getTimePoint(BufferedImagePlusServer.java:173); at qupath.imagej.helpers.IJTools.calibrateImagePlus(IJTools.java:220); at qupath.imagej.images.servers.BufferedImagePlusServer.readImagePlusRegion(BufferedImagePlusServer.java:241); at qupath.imagej.detect.tissue.SimpleTissueDetection2$GlobalThresholder.runDetection(SimpleTissueDetection2.java:158); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:120); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:10639,concurren,concurrent,10639,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['concurren'],['concurrent']
Performance,"e.sc/t/feature-suggestion-option-to-revert-to-last-state-on-cancelling-script-run/74486), there could be a quicker way to cancel a running script and regain control of QuPath. Currently, on cancelling a script, QuPath will continue to run the current script until completion for the current image. For complex scripts, this can take a long time, from minutes to hours. I would imagine that for most users, when they cancel a running script, they would expect it to halt immediately and regain control of QuPath. Example scenarios for this would be:; - The user quickly notices some errors or mistakes in the script just after running it and would like to correct it.; - The script is running for an unusually long time and the user would like to investigate why (e.g. too many objects created or manipulating extremely complex ROIs?). At the time of writing, I and other users would just close QuPath or kill its instance and re-open the project to ""cancel"" the script run. It is unclear if this may cause data corruption or any other negative consequences. One small inconvenience for this method is that any unsaved scripts in the Script Editor will be lost, which can be the case when testing or optimising parameters. I have suggested in the image.sc thread if there is a way to revert to the last state just before running the script when trying to cancel the script run. From my naive perspective, it could be like:. For scripts running on the currently open image only, on clicking Run,; 1. Save current state of image before running the script.; 2. Start running the script.; 3. If run is cancelled, load the state saved in step 1. For scripts running in batch, on clicking Run for project,; 1. Start running script as usual.; 2. If run is cancelled, ignore whatever that has been done on the current image being processed and maintain the last saved image data. Any images that had already completed processing the script would have an updated and saved image data (as per normal behaviour).",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1167:1665,load,load,1665,https://qupath.github.io,https://github.com/qupath/qupath/issues/1167,1,['load'],['load']
Performance,eArray.defaultCallStatic(CallSiteArray.java:55); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:196); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:216); at Script1.run(Script1.groovy:3); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:317); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:155); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:766); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:696); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:676); at qupath.lib.gui.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1033); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by No double parameter with key 'haralickMin' at qupath.lib.plugins.parameters.ParameterList.getDoubleParameterValue(ParameterList.java:386); at qupath.lib.plugins.parameters.ParameterList.getDoubleParameterValue(ParameterList.java:427); at qupath.lib.algorithms.IntensityFeaturesPlugin$HaralickFeaturesComp.updateFeatures(IntensityFeaturesPlugin.java:1056); at qupath.lib.algorithms.IntensityFeaturesPlugin.processObject(IntensityFeaturesPlugin.java:628); at qupath.lib.algorithms.IntensityFeaturesPlugin$IntensityFeatureRunnable.run(IntensityFeaturesPlugin.java:454); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.ba,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/358:2185,concurren,concurrent,2185,https://qupath.github.io,https://github.com/qupath/qupath/issues/358,1,['concurren'],['concurrent']
Performance,"eReader initializing C:\Users\617\Desktop\1800164.tif; INFO: Reading IFDs; INFO: Populating metadata; INFO: Checking comment style; INFO: Populating OME metadata; INFO: No memoization file generated for C:\Users\617\Desktop\1800164.tif; ERROR: Error opening image 0 for region java.awt.Rectangle[x=0,y=0,width=23422,height=30978]; at loci.formats.FormatReader.openBytes(FormatReader.java:880); at loci.formats.ImageReader.openBytes(ImageReader.java:444); at loci.formats.ReaderWrapper.openBytes(ReaderWrapper.java:334); at loci.formats.ReaderWrapper.openBytes(ReaderWrapper.java:334); at loci.formats.gui.BufferedImageReader.openImage(BufferedImageReader.java:86); at qupath.lib.images.servers.BioFormatsImageServer.readBufferedImage(BioFormatsImageServer.java:683); at qupath.lib.images.servers.BioFormatsImageServer.readBufferedImage(BioFormatsImageServer.java:95); at qupath.lib.images.stores.AbstractImageRegionStore$DefaultTileWorker$1.call(AbstractImageRegionStore.java:656); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by Array size too large: 23422 x 30978 x 3 x 1 at loci.common.DataTools.safeMultiply32(DataTools.java:1274); at loci.common.DataTools.allocate(DataTools.java:1247); at loci.formats.FormatReader.openBytes(FormatReader.java:877); at loci.formats.ImageReader.openBytes(ImageReader.java:444); at loci.formats.ReaderWrapper.openBytes(ReaderWrapper.java:334); at loci.formats.ReaderWrapper.openBytes(ReaderWrapper.java:334); at loci.formats.gui.BufferedImageReader.openImage(BufferedImageReader.java:86); at qupath.lib.images.servers.BioFormatsImageServer.readBufferedImage(BioFormatsImageServer.java:683); at qupath.lib.images.servers.BioFormatsImageServer.readBufferedImage(BioFormatsImageServer.java:95); at qupath.lib.images.stores.AbstractIma",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/221:20282,concurren,concurrent,20282,https://qupath.github.io,https://github.com/qupath/qupath/issues/221,1,['concurren'],['concurrent']
Performance,"eServer.java:61); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:166); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:19); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:536); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:573); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:156); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:120); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:47); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:269); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); ERROR: IOException exception reading file:/Volumes/Storage/Work/SLIDESCANS/190512_OLYMPUS_YKA_Batch/CRUK_YKA_16.1D_tam_2_20190513.vsi#1: x=9728, y=34816, w=512, h=512, z=0, t=0, downsample=1; at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:199); at java.base/sun.nio.ch.FileChannelImpl.endBlocking(FileChannelImpl.java:162); at java.base/sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:816); at java.base/sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:796); at loci.common.NIOByteBufferProvider.allocateDirect(NIOByteBufferProvider.java:127); at loci.common.N",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:8073,concurren,concurrent,8073,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['concurren'],['concurrent']
Performance,eap space; java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: Java heap space; at java.base/java.util.concurrent.FutureTask.report(Unknown Source); at java.base/java.util.concurrent.FutureTask.get(Unknown Source); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:139); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:107); at qupath.lib.gui.PluginRunnerFX.runTasks(PluginRunnerFX.java:98); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:169); at qupath.lib.gui.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:192); at java.base/java.lang.Thread.run(Unknown Source); Caused by Java heap space at java.base/java.util.ArrayDeque.<init>(Unknown Source); at qupath.imagej.processing.Watershed$WatershedQueueWrapper.<init>(Watershed.java:242); at qupath.imagej.processing.Watershed.doWatershed(Watershed.java:83); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.doDetection(WatershedCellDetection.java:852); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:1063); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:303); at qupath.imagej.detect.cells.PositiveCellDetection$DetectorWrapper.runDetection(PositiveCellDetection.java:140); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); ```,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/828#issuecomment-932330593:1891,concurren,concurrent,1891,https://qupath.github.io,https://github.com/qupath/qupath/issues/828#issuecomment-932330593,6,['concurren'],['concurrent']
Performance,edeco/openblas/macosx-x86_64/libgfortran.4.dylib; gcc_s@.1 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgcc_s.1.dylib; jniopencv_ml : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_ml.dylib; opencv_imgproc@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_imgproc.405.dylib; jniopencv_dnn : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_dnn.dylib; jnijavacpp : 	/Users/pbankhea/.javacpp/cache/javacpp-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/javacpp/macosx-x86_64/libjnijavacpp.dylib; jniopenblas : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libjniopenblas.dylib; quadmath@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libquadmath.0.dylib; openblas_nolapack@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libopenblas_nolapack.0.dylib; opencv_core@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_core.405.dylib; jniopenblas_nolapack : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libjniopenblas_nolapack.dylib; jniopencv_imgproc : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_imgproc.dylib; openblas@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libopenblas.0.dylib; opencv_dnn@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macos,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980:2054,cache,cache,2054,https://qupath.github.io,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980,1,['cache'],['cache']
Performance,efaultSettingsLoader.findSettingsAndLoadIfAppropriate(DefaultSettingsLoader.java:102); at org.gradle.initialization.DefaultSettingsLoader.findAndLoadSettings(DefaultSettingsLoader.java:45); at org.gradle.initialization.SettingsAttachingSettingsLoader.findAndLoadSettings(SettingsAttachingSettingsLoader.java:35); at org.gradle.internal.composite.CommandLineIncludedBuildSettingsLoader.findAndLoadSettings(CommandLineIncludedBuildSettingsLoader.java:34); at org.gradle.internal.composite.ChildBuildRegisteringSettingsLoader.findAndLoadSettings(ChildBuildRegisteringSettingsLoader.java:52); at org.gradle.internal.composite.CompositeBuildSettingsLoader.findAndLoadSettings(CompositeBuildSettingsLoader.java:35); at org.gradle.initialization.DefaultSettingsPreparer.prepareSettings(DefaultSettingsPreparer.java:36); at org.gradle.initialization.BuildOperatingFiringSettingsPreparer$LoadBuild.doLoadBuild(BuildOperatingFiringSettingsPreparer.java:59); at org.gradle.initialization.BuildOperatingFiringSettingsPreparer$LoadBuild.run(BuildOperatingFiringSettingsPreparer.java:54); at org.gradle.internal.operations.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:402); at org.gradle.internal.operations.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:394); at org.gradle.internal.operations.DefaultBuildOperationExecutor$1.execute(DefaultBuildOperationExecutor.java:165); at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:250); at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:158); at org.gradle.internal.operations.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:92); at org.gradle.internal.operations.DelegatingBuildOperationExecutor.run(DelegatingBuildOperationExecutor.java:31); at org.gradle.initialization.BuildOperatingFiringSettingsPreparer.prepareSettin,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/427:4685,Load,LoadBuild,4685,https://qupath.github.io,https://github.com/qupath/qupath/issues/427,1,['Load'],['LoadBuild']
Performance,elated to https://github.com/bytedeco/javacpp/issues/468 and https://github.com/bytedeco/javacpp/issues/516. The errors look like this:. ```; ERROR: Error requesting tile classification: ; java.io.IOException: java.lang.OutOfMemoryError: Physical memory usage is too high: physicalBytes (16451M) > maxPhysicalBytes (16384M); at qupath.lib.classifiers.pixel.PixelClassificationImageServer.readTile(PixelClassificationImageServer.java:314); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:184); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:238); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:56); at qupath.lib.gui.viewer.overlays.PixelClassificationOverlay.lambda$requestTile$5(PixelClassificationOverlay.java:547); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by Physical memory usage is too high: physicalBytes (16451M) > maxPhysicalBytes (16384M) at org.bytedeco.javacpp.Pointer.deallocator(Pointer.java:712); at org.bytedeco.javacpp.Pointer.init(Pointer.java:126); at org.bytedeco.opencv.opencv_core.Mat.allocate(Native Method); at org.bytedeco.opencv.opencv_core.Mat.<init>(Mat.java:241); at qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predictWithLock(OpenCVClassifiers.java:468); at qupath.opencv.ml.OpenCVClassifiers$ANNClassifierCV.predictWithLock(OpenCVClassifiers.java:1425); at qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predict(OpenCVClassifiers.java:442); at qupath.opencv.ops.ImageOps$ML$StatModelOp.apply(ImageOps.java:2812); at qupath.opencv.ops.ImageO,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856:1248,concurren,concurrent,1248,https://qupath.github.io,https://github.com/qupath/qupath/issues/856,1,['concurren'],['concurrent']
Performance,"em, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""s",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/112#issuecomment-343336690:1471,concurren,concurrent,1471,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690,1,['concurren'],['concurrent']
Performance,"enCVExtension.java:116). at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1093). at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:637). at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:429). at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63). at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863). at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326). at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295). at java.security.AccessController.doPrivileged(Native Method). at com.sun.javafx.application.PlatformImpl.lambda$runLater$173(PlatformImpl.java:294). at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95). at com.sun.glass.ui.win.WinApplication._runLoop(Native Method). at com.sun.glass.ui.win.WinApplication.lambda$null$147(WinApplication.java:177). at java.lang.Thread.run(Thread.java:748). INFO: Selected style: Modena Light. INFO: Performing update check... INFO: Starting QuPath with parameters: []. . I deinstalled the other version but there it did work without any problems. Is there any way to deinstall qupath so that I can try to install it again?. . Best,. Marcel. . . Von: Pete [mailto:notifications@github.com] ; Gesendet: Dienstag, 7. August 2018 03:02; An: qupath/qupath; Cc: 2010mars2010; Author; Betreff: Re: [qupath/qupath] touch gestures: zooms when moving up/down (#188). . I only got one problem: QuPath cannot open any *.svs (scanscope virtual slide) images any more. Do you have a solution for that?. I this running on Windows 10, and are there any errors under View → Show log when you try to open an .svs file? Does it work with the other version of QuPath on the same machine (v0.1.2)?. My guess is that OpenSlide isn't loading for you, but it's the same version as in v0.1.2... so it one works, then I'd expect the other to work as well. If you were running QuPath from an IDE (e.g. IntelliJ, eclipse) then paths wou",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/188#issuecomment-411621646:1592,Perform,Performing,1592,https://qupath.github.io,https://github.com/qupath/qupath/issues/188#issuecomment-411621646,1,['Perform'],['Performing']
Performance,enblas/macosx-x86_64/libgfortran.dylib; jniopencv_core : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_core.dylib; gfortran@.3 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgfortran.dylib; gfortran@.4 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgfortran.4.dylib; gcc_s@.1 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgcc_s.1.dylib; jniopencv_ml : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_ml.dylib; opencv_imgproc@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_imgproc.405.dylib; jniopencv_dnn : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_dnn.dylib; jnijavacpp : 	/Users/pbankhea/.javacpp/cache/javacpp-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/javacpp/macosx-x86_64/libjnijavacpp.dylib; jniopenblas : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libjniopenblas.dylib; quadmath@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libquadmath.0.dylib; openblas_nolapack@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libopenblas_nolapack.0.dylib; opencv_core@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_core.405.dylib; jniopenblas_nolapack : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/ope,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980:1609,cache,cache,1609,https://qupath.github.io,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980,1,['cache'],['cache']
Performance,encv/macosx-x86_64/libjniopencv_core.dylib; gfortran@.3 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgfortran.dylib; gfortran@.4 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgfortran.4.dylib; gcc_s@.1 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgcc_s.1.dylib; jniopencv_ml : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_ml.dylib; opencv_imgproc@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_imgproc.405.dylib; jniopencv_dnn : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_dnn.dylib; jnijavacpp : 	/Users/pbankhea/.javacpp/cache/javacpp-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/javacpp/macosx-x86_64/libjnijavacpp.dylib; jniopenblas : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libjniopenblas.dylib; quadmath@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libquadmath.0.dylib; openblas_nolapack@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libopenblas_nolapack.0.dylib; opencv_core@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_core.405.dylib; jniopenblas_nolapack : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libjniopenblas_nolapack.dylib; jniopencv_imgproc : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980:1758,cache,cache,1758,https://qupath.github.io,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980,1,['cache'],['cache']
Performance,"enerated. Then, I launched the QuPath project in 0.4.1, and the load time was nearly instantaneous. Which, while resolving the issue, also means that the issue exists outside of QuPath. So, for some reason, the thumbnail previews are lost after a period of time, and don't seem to coincide with closing the folder or restarting the computer. The first thing I attempted to preserve thumbnails was to ensure ""Always show icons, never thumbnails"" in the folder options was unchecked, however it already was by default:; ![image](https://user-images.githubusercontent.com/52012166/211071879-ac70ef62-925f-4fe5-8ec3-10763d391393.png); Toggling this field didn't seem to have any impact on project loading performance, since in either case, the thumbnails were already generated (just replaced with an icon if the box is checked).; Next, under Windows performance options, I noticed ""save taskbar thumbnail previews"" was unchecked by default. I've checked it, and so far, I don't seem to have trouble loading projects that already have thumbnails generated in explorer. ; ![image](https://user-images.githubusercontent.com/52012166/211072664-c211658b-7aa6-435d-8067-830b4e1620b1.png). I'll continue to test other projects and rebooting my computer, to confirm if this has resolved the issue. TL;DR: **Check ""save taskbar thumbnail previews"" under Windows performance options. Subsequent loads of the project should now be much faster**. EDIT: So far, this fix persists after rebooting the system. EDIT 2: I've opened the project again after a few hours, verifying that the thumbnails exist in Windows Explorer. I'm now getting a long project load time (although anecdotally, it feels a bit faster), which means the above fix might not work as it could be tied to something other than thumbnails generated in Explorer. Currently, the project is located on the OS-installed drive (NVMe SSD), but the images are located on a separate local NVMe SSD. I'll see if moving both the project and images onto the OS ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1154#issuecomment-1373971580:1486,load,loading,1486,https://qupath.github.io,https://github.com/qupath/qupath/issues/1154#issuecomment-1373971580,1,['load'],['loading']
Performance,"ent lists in parallel threads. A related issue is reported at https://github.com/qupath/qupath/pull/1466 but the proposed fix does not solve the problem here. **To Reproduce**; Try running the script below:; ```groovy; // A growing list of objects; def pathObjects = Collections.synchronizedList([]). // Number of iterations; int n = 1000. // Create a thread to continually request all measurement names; def t = new Thread( {; while (pathObjects.size() < n) {; def list = PathObjectTools.getAvailableFeatures(new ArrayList<>(pathObjects)); }; }); t.start(). // Create a parallel stream to add new objects; java.util.stream.IntStream.range(0, n); .parallel(); .forEach(i -> {; // This happens only with detections!; def pathObject = PathObjects.createDetectionObject(ROIs.createEmptyROI()); pathObjects << pathObject; for (int k = 0; k <= i; k++); pathObject.measurementList.put(""M_$k"", i); }); t.join(); ; println ""Done!""; ```. I see an exception; ```; ERROR: null; java.util.ConcurrentModificationException: null; at java.base/java.util.ArrayList$Itr.checkForComodification(Unknown Source); at java.base/java.util.ArrayList$Itr.next(Unknown Source); at java.base/java.util.Collections$UnmodifiableCollection$1.next(Unknown Source); at java.base/java.util.AbstractCollection.addAll(Unknown Source); at qupath.lib.objects.PathObjectTools.getAvailableFeatures(PathObjectTools.java:2026); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript$_run_closure1.doCall(QuPathScript:11); at QuPathScript$_run_closure1.doCall(QuPathScript); at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(Unknown Source); at java.base/java.lang.reflect.Method.invoke(Unknown Source); at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:343); at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:328); at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:279); at groovy.lang.MetaClassImpl.invokeM",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1591:1113,Concurren,ConcurrentModificationException,1113,https://qupath.github.io,https://github.com/qupath/qupath/issues/1591,1,['Concurren'],['ConcurrentModificationException']
Performance,"eport them on GitHub or image.sc - don’t just stick with an older milestone that seemed to work!. And this one under object hierarchy section:. > Things that worked before should still work (if they don’t, please report the bug!). To reproduce:. 1. Create a project in m5, import an image; 2. Copy this qpdata to the project entry: [data.zip](https://github.com/qupath/qupath/files/3857086/data.zip); 3. Open project with m6. I don't recall the version that created this qpdata file, but it works with m5. It contains some non-hierarchical annotations. Stack trace:. > INFO: Bio-Formats version 6.3.0; INFO: Loaded extension Bio-Formats server options (Bio-Formats 6.3.0) (27 ms); INFO: Loaded extension Experimental commands (26 ms); INFO: Loaded extension ImageJ extension (90 ms); INFO: Loaded extension JPen extension (34 ms); INFO: Loaded extension OpenCV extensions (4 ms); INFO: Loaded extension Rich script editor extension (562 ms); INFO: OpenSlide version 3.4.1; INFO: Selected style: null; INFO: Performing update check...; WARN: No changelog found - will not check for updates; INFO: Starting QuPath with parameters: []; INFO: Project set to Project: deneme-project; WARN: Openslide: Property 'openslide.mpp-x' not available, will return default value NaN; WARN: Openslide: Property 'openslide.mpp-y' not available, will return default value NaN; WARN: Openslide: Property 'openslide.objective-power' not available, will return default value NaN; INFO: Image data set to ImageData: Not set, B-11285-15_2.tif; ERROR: QuPath exception: missing initial moveto in path definition; at java.desktop/java.awt.geom.Path2D$Float.needRoom(Unknown Source); at java.desktop/java.awt.geom.Path2D.closePath(Unknown Source); at qupath.lib.roi.ShapeSimplifier.simplifyPath(ShapeSimplifier.java:310); at qupath.lib.gui.viewer.PathHierarchyPaintingHelper$ShapeProvider.simplifyByDownsample(PathHierarchyPaintingHelper.java:542); at qupath.lib.gui.viewer.PathHierarchyPaintingHelper$ShapeProvider.getShape(Pa",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/376#issuecomment-554873027:1218,Perform,Performing,1218,https://qupath.github.io,https://github.com/qupath/qupath/issues/376#issuecomment-554873027,1,['Perform'],['Performing']
Performance,"eproduce**; Steps to reproduce the behavior:; 1. Ctl+Shift+A; 2. Run cell detection as a script:; ```; setImageType('FLUORESCENCE');; selectAnnotations();; runPlugin('qupath.imagej.detect.cells.WatershedCellDetection', '{""detectionImage"":""DAPI"",""requestedPixelSizeMicrons"":0.1,""backgroundRadiusMicrons"":4.0,""backgroundByReconstruction"":true,""medianRadiusMicrons"":1.0,""sigmaMicrons"":2.5,""minAreaMicrons"":11.0,""maxAreaMicrons"":400.0,""threshold"":1000.0,""watershedPostProcess"":true,""cellExpansionMicrons"":5.0,""includeNuclei"":true,""smoothBoundaries"":true,""makeMeasurements"":true}'); ```; 4. Error:; ```; ERROR: Error running plugin: java.lang.NullPointerException: Cannot invoke ""java.awt.image.BufferedImage.getSampleModel()"" because ""img"" is null; java.util.concurrent.ExecutionException: java.lang.NullPointerException: Cannot invoke ""java.awt.image.BufferedImage.getSampleModel()"" because ""img"" is null; at java.base/java.util.concurrent.FutureTask.report(Unknown Source); at java.base/java.util.concurrent.FutureTask.get(Unknown Source); at qupath.lib.plugins.AbstractTaskRunner.awaitCompletion(AbstractTaskRunner.java:147); at qupath.lib.plugins.AbstractTaskRunner.runTasks(AbstractTaskRunner.java:117); at qupath.lib.gui.TaskRunnerFX.runTasks(TaskRunnerFX.java:106); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:147); at qupath.lib.gui.QuPathGUI.runPlugin(QuPathGUI.java:2245); at qupath.lib.gui.scripting.QPEx.runPlugin(QPEx.java:248); at qupath.lib.gui.scripting.QPEx.runPlugin(QPEx.java:270); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript.run(QuPathScript:4); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:331); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:161); at qupath.lib.gui.scripting.languages.DefaultScriptLanguage.execute(DefaultScriptLanguage.java:234); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScript",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443:1535,concurren,concurrent,1535,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443,1,['concurren'],['concurrent']
Performance,eption: Failed to load PyTorch native library; 	at ai.djl.pytorch.engine.PtEngine.newInstance(PtEngine.java:90); 	at ai.djl.pytorch.engine.PtEngineProvider.getEngine(PtEngineProvider.java:41); 	at ai.djl.engine.Engine.getEngine(Engine.java:190); 	at qupath.ext.instanseg.core.PytorchManager.lambda$getEngineOnline$0(PytorchManager.java:28); 	at qupath.ext.instanseg.core.PytorchManager.callWithTempProperty(PytorchManager.java:114); 	at qupath.ext.instanseg.core.PytorchManager.callOnline(PytorchManager.java:106); 	at qupath.ext.instanseg.core.PytorchManager.getEngineOnline(PytorchManager.java:28); 	at qupath.ext.instanseg.ui.InstanSegController.downloadPyTorch(InstanSegController.java:826); 	at qupath.ext.instanseg.ui.InstanSegController.ensurePyTorchAvailable(InstanSegController.java:815); 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(Unknown Source); 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.exec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source); Caused by: java.lang.UnsatisfiedLinkError: C:\Users\username\.djl.ai\pytorch\2.3.1-cu121-win-x86_64\cudnn_cnn_infer64_8.dll: The specified procedure could not be found; 	at java.base/jdk.internal.loader.NativeLibraries.load(Native Method); 	at java.base/jdk.internal.loader.NativeLibraries$NativeLibraryImpl.open(Unknown Source); 	at java.base/jdk.internal.loader.NativeLibraries.loadLibrary(Unknown Source); 	at java.base/jdk.internal.loader.NativeLibraries.loadLibrary(Unknown Source); 	at java.base/java.lang.ClassLoader.loadLibrary(Unknown Source); 	at java.base/java.lang.Runtime.load0(Unknown Source); 	at java.base/java.lang.System.load(Unkn,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1636:1312,concurren,concurrent,1312,https://qupath.github.io,https://github.com/qupath/qupath/issues/1636,1,['concurren'],['concurrent']
Performance,"er cpu, 1 threads per core) family 6 model 158 stepping 10 microcode 0xea, cx8, cmov, fxsr, mmx, 3dnowpref, sse, sse2, sse3, ssse3, sse4.1, sse4.2, popcnt, lzcnt, tsc, tscinvbit, avx, avx2, aes, erms, clmul, bmi1, bmi2, rtm, adx, fma, vzeroupper, clflush, clflushopt; Processor Information for all 6 processors :; Max Mhz: 3000, Current Mhz: 3000, Mhz Limit: 3000. Memory: 4k page, system-wide physical 7966M (772M free); TotalPageFile size 23838M (AvailPageFile size 7045M); current process WorkingSet (physical memory assigned to process): 3284M, peak: 3876M; current process commit charge (""private bytes""): 6219M, peak: 6444M. vm_info: OpenJDK 64-Bit Server VM (17.0.8+7) for windows-amd64 JRE (17.0.8+7), built on Jul 18 2023 21:02:32 by ""admin"" with MS VC++ 16.7 (VS2019). END. From: Pete ***@***.***>; Sent: Thursday, November 2, 2023 2:08 PM; To: qupath/qupath ***@***.***>; Cc: Farias Da Guarda, Suzete Nascimento ***@***.***>; Mention ***@***.***>; Subject: Re: [qupath/qupath] Load training in object classifier -> QuPath crashes (#493). External Email - Use Caution. @suzeteguarda<https://secure-web.cisco.com/15zJZ1AC2HfUFv9L0mLItqMCfEQMcq1aVBJmggNtWQuQ1aMdkxQL4M8DQsziZIjbQclRsiUgnd4btBVr7WmNM9GAmb5IdGegWqzsNoLW7i0t8ZduDtcd418DQ9BIIDpRAJC02UjlE2keamNPfGPyTA13hxoJ6aI6fRjs8P6PPD3ag1gjsZJuHqXh28XIp9ClIy6uiD9WiE2a29pnEogefoBAUSjm8iBfMR0HcxqAtG_TdnAk0f4Y8BA4E5sVwzFhbDhm_alns-l7jx4c65825lN1brlaamgEFYOcr-bx0yB5-ONuFLKVRdD6nCGWcI1iPAsoohE7nnVhyPIYtURWpKQ/https%3A%2F%2Fgithub.com%2Fsuzeteguarda> you could try posting your question on the forum at https://forum.image.sc/tag/qupath<https://secure-web.cisco.com/13_E9lRMQxY8xtZmKYPnw2mmwaiElPiHzTIMUOwQH_-6FzgRz4LkCsf_cFjrfUWLwo9750a0MmRr_eXTVN0eusQkomn-qYLuoCcVIKhtD0lyGLisH8Fxc-WFZwGzOR3GcJ4WLvQ2nVTFF7JEFSGly69C9pq9zGxJ69U6IM5ck9ofp9vkUV14NNMWH0h1u9pMUi3qXwaLEHdnCfRaAU7pipTjdj7etnYxMl6fke2A03VF49uEY6P4XmHIM3ote076fSVZpQqVTzYq0orKjFBwoKIbptcmC4XxHSSCRt900YIULIVQAtzU62qtHv_TEqaLa9vgoz2qhsY9NbYDfMfFPtA/https%3A%2F%2Fforum.image.sc%2Ftag%",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/493#issuecomment-1791396738:1247,Load,Load,1247,https://qupath.github.io,https://github.com/qupath/qupath/issues/493#issuecomment-1791396738,1,['Load'],['Load']
Performance,er.drop(Scene.java:2997); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.lambda$handleDragDrop$2(GlassSceneDnDEventHandler.java:108); at java.base/java.security.AccessController.doPrivileged(Unknown Source); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragDrop(GlassSceneDnDEventHandler.java:104); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragDrop$11(GlassViewEventHandler.java:766); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:412); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragDrop(GlassViewEventHandler.java:765); at com.sun.glass.ui.View.handleDragDrop(View.java:713); at com.sun.glass.ui.View.notifyDragDrop(View.java:1042); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:174); at java.base/java.lang.Thread.run(Unknown Source); Caused by null at qupath.lib.projects.DefaultProject.loadPathClasses(DefaultProject.java:1130); at qupath.lib.projects.DefaultProject.loadProject(DefaultProject.java:1086); at qupath.lib.projects.DefaultProject.loadFromFile(DefaultProject.java:171); at qupath.lib.projects.ProjectIO.loadProject(ProjectIO.java:97); at qupath.lib.gui.viewer.DragDropFileImportListener.handleFileDropImpl(DragDropFileImportListener.java:248); at qupath.lib.gui.viewer.DragDropFileImportListener.handleFileDrop(DragDropFileImportListener.java:158); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:126); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:64); at com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:234); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:191); at com.sun.javafx.event.CompositeEventDispatcher.disp,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/613#issuecomment-708516373:2838,load,loadPathClasses,2838,https://qupath.github.io,https://github.com/qupath/qupath/issues/613#issuecomment-708516373,1,['load'],['loadPathClasses']
Performance,"er.readBufferedImage(AbstractTileableImageServer.java:56); at qupath.lib.images.servers.ServerTools.getPaddedRequest(ServerTools.java:231); at qupath.opencv.ops.ImageOps$DefaultImageDataOp.apply(ImageOps.java:256); at qupath.tensorflow.stardist.StarDist2D.detectObjectsForTile(StarDist2D.java:807); at qupath.tensorflow.stardist.StarDist2D.lambda$detectObjects$5(StarDist2D.java:687); at java.base/java.util.stream.ReferencePipeline$7$1.accept(Unknown Source); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); at java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); at java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); at java.base/java.util.stream.AbstractTask.compute(Unknown Source); at java.base/java.util.concurrent.CountedCompleter.exec(Unknown Source); at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source); at java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source); at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source); at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source); WARN: file deletion failed C:\Users\oburri\AppData\Local\Temp\qupath-memo-15327719930616011555\biop\Image_Processing\User_Projects\Olivier\USERNAME_REDACTED\Sample images - metadata\.MCF7_hPR_OVX_3rd_M6-10_Ki67.vsi.bfmemo; ```. **To Reproduce**; Steps to reproduce the behavior:; 1. On Windows, create a new Project and add an Image that will use BioFormats; 2. Display the image in the Viewer at least once; 3. Close QuPath and restart; 4. Reopen the file; 5. Start a script and run it. **Desktop (please complete the following information):**; - OS: Windows 10 build 20H2; - QuPath Version 0.3.0 SNAPSHOT. Best regards,. Olivier",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/717:6185,concurren,concurrent,6185,https://qupath.github.io,https://github.com/qupath/qupath/issues/717,5,['concurren'],['concurrent']
Performance,"erably, because the command must also be scriptable and then somehow the units need to incorporated into any script. Additionally, QuPath is moving towards greater generality. It is increasingly used for images where µm is an inappropriate unit, so I'm reluctant to add additional code that assumes µm as the only alternative to pixels. And a properly generic system will take a lot more effort to develop (not helped by the fact that Java has no built-in support for converting units... it's a recurring theme, e.g. [here](https://jcp.org/en/jsr/detail?id=385), but as far as I'm aware there are a multiple implementations and it's not clear which, if any, we should use). This also affects the sparse image server: at the point the dialog is shown, we don't know if the pixel size is available in µm for the regions that will be required to generate the server. Furthermore, the dialog itself is [auto-generated from a `ParameterList`](https://github.com/qupath/qupath/blob/main/qupath-extension-processing/src/main/java/qupath/process/gui/commands/CreateTrainingImageCommand.java#L90), which limits the ability to toggle between units. Added to that, I'm not terribly happy with the generation of 'dynamic' training images generally; the code is really complex (since the images can be quite heterogeneous), and performance can be poor whenever many images need to be accessed to create the final result. Therefore I wonder if creating a new command that defaults to writing the image as a new file would be preferable anyway. I'll leave this open for a while in case there are further comments, but my feeling is that the development-and-maintainence-time-to-benefit ratio isn't favorable enough to work on this in the core QuPath software; there are too many higher priorities, and if I'd rather focus efforts on simplicity, maintainability and generalizability in the code. Anyone else can create a new extension to provide an alternative implementation for any of the commands if they want to.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1407#issuecomment-1783782932:1478,perform,performance,1478,https://qupath.github.io,https://github.com/qupath/qupath/issues/1407#issuecomment-1783782932,1,['perform'],['performance']
Performance,"eral\ALL INFECT and INFECT; images\INF 69 DR3 DR4 repeat for Ganesh manuscript Qupath data\dr3 gfap new; 042121\project.qpproj; INFO: Project set to Project: dr3 gfap new 042121-project; INFO: Image data set to ImageData: Brightfield (H-DAB), PR301S1 2021-04-23; 07.49.55.ndpi; WARN: Unable to open file://; undmed-files.med.und.edu/Basic%20Sciences/Kotb%20Lab/General/ALL%20INFECT%20and%20INFECT%20images/INF%2069%20DR3%20DR4%20repeat%20for%20Ganesh%20manuscript%20Qupath%20data/dr3%20gfap%20new%20042121/PR287S8%20-%202021-04-12%2009.52.58.ndpi; with OpenSlide: URI has an authority component; ERROR: Load ImageData: Unable to build ImageServer for file://; undmed-files.med.und.edu/Basic%20Sciences/Kotb%20Lab/General/ALL%20INFECT%20and%20INFECT%20images/INF%2069%20DR3%20DR4%20repeat%20for%20Ganesh%20manuscript%20Qupath%20data/dr3%20gfap%20new%20042121/PR287S8%20-%202021-04-12%2009.52.58.ndpi; (args=[]) with requested provider; qupath.lib.images.servers.openslide.OpenslideServerBuilder; ERROR: Load ImageData; at; qupath.lib.images.servers.ImageServerBuilder$DefaultImageServerBuilder.buildOriginal(ImageServerBuilder.java:341); at; qupath.lib.images.servers.ImageServerBuilder$AbstractServerBuilder.build(ImageServerBuilder.java:152); at; qupath.lib.projects.DefaultProject$DefaultProjectImageEntry.readImageData(DefaultProject.java:718); at qupath.lib.gui.QuPathGUI.openImageEntry(QuPathGUI.java:2695); at; qupath.lib.gui.panes.ProjectBrowser.lambda$new$3(ProjectBrowser.java:190); at; com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86); at; com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:234); at; com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:191); at; com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDispatcher.java:59); at; com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:58); at; com.sun.j",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/396#issuecomment-827610434:2055,Load,Load,2055,https://qupath.github.io,https://github.com/qupath/qupath/issues/396#issuecomment-827610434,1,['Load'],['Load']
Performance,"ers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:19); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:536); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:573); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:156); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:120); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:47); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:269); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); ERROR: IOException exception reading file:/Volumes/Storage/Work/SLIDESCANS/190512_OLYMPUS_YKA_Batch/CRUK_YKA_16.1D_tam_2_20190513.vsi#1: x=9728, y=34816, w=512, h=512, z=0, t=0, downsample=1; at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:199); at java.base/sun.nio.ch.FileChannelImpl.endBlocking(FileChannelImpl.java:162); at java.base/sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:816); at java.base/sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:796); at loci.common.NIOByteBufferProvider.allocateDirect(NIOByteBufferProvider.java:127); at loci.common.NIOByteBufferProvider.allocate(NIOByteBufferProvider.java:112); at loci.common.NIOFileHandle.buffer(NIOFileHandle.java:647); at loci.common.NIOFileHandle.<ini",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:8230,concurren,concurrent,8230,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['concurren'],['concurrent']
Performance,erty.ObjectPropertyBase.fireValueChangedEvent(ObjectPropertyBase.java:105); at javafx.beans.property.ObjectPropertyBase.markInvalid(ObjectPropertyBase.java:112); at javafx.beans.property.ObjectPropertyBase.set(ObjectPropertyBase.java:146); at javafx.scene.control.TreeView.setRoot(TreeView.java:470); at qupath.lib.gui.panels.ProjectBrowser.setProject(ProjectBrowser.java:271); at qupath.lib.gui.QuPathGUI.setProject(QuPathGUI.java:4186); at qupath.lib.gui.QuPathGUI$setProject$0.call(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125); at Script5.run(Script5.groovy:21); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1267); at qupath.lib.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1195); at javafx.concurrent.Task$TaskCallable.call(Task.java:1423); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); `,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/103#issuecomment-332808179:3967,concurren,concurrent,3967,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332808179,6,['concurren'],['concurrent']
Performance,"es 2D* is not well-defined when applying the command to annotations that are nested (in the hierarchy) or overlapping. For 'flat' annotation arrangements the behavior is *mostly ok*, except that it does rely on *hierarchy relationships* rather than *spatial relationships*.; Which is to say, it hasn't really changed since v0.1.2. **To Reproduce**; Create an arrangement of objects similar to that shown below:. ![0-orig](https://github.com/user-attachments/assets/cf1a87fc-c73a-4ac6-be24-d830f0014604). 1. If I run *Delaunay cluster features 2D* with **_all_ annotations selected**, I see triangulation lines which *do not cross the boundary between the annotations containing cells*. ![1-all selected](https://github.com/user-attachments/assets/3309e1e3-76ca-4ec7-bf5c-e0c76b8f2d96). But I **also** get a `ConcurrentModificationException`:; ```; 15:47:01.829	[Plugin thread]	ERROR	qupath.lib.plugins.AbstractTaskRunner	Error running plugin: java.util.ConcurrentModificationException	java.util.concurrent.ExecutionException: java.util.ConcurrentModificationException; 	at java.base/java.util.concurrent.FutureTask.report(Unknown Source); 	at java.base/java.util.concurrent.FutureTask.get(Unknown Source); 	at qupath.lib.plugins.AbstractTaskRunner.awaitCompletion(AbstractTaskRunner.java:147); 	at qupath.lib.plugins.AbstractTaskRunner.runTasks(AbstractTaskRunner.java:117); 	at qupath.lib.gui.TaskRunnerFX.runTasks(TaskRunnerFX.java:106); 	at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:147); 	at qupath.lib.gui.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:177); 	at java.base/java.lang.Thread.run(Unknown Source); Caused by: java.util.ConcurrentModificationException; 	at java.base/java.util.ArrayList$Itr.checkForComodification(Unknown Source); 	at java.base/java.util.ArrayList$Itr.next(Unknown Source); 	at java.base/java.util.Collections$UnmodifiableCollection$1.next(Unknown Source); 	at java.base/java.util.AbstractCollection.addAll(Unknown Source); 	at qupath.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1590:1101,concurren,concurrent,1101,https://qupath.github.io,https://github.com/qupath/qupath/issues/1590,1,['concurren'],['concurrent']
Performance,"es.; If the scripts being run wants to access the images' pixels, it gracefully halts the execution of the all the following project entries too. _example_:; ```groovy; import qupath.imagej.tools.IJTools; import qupath.lib.images.PathImage; import ij.ImagePlus. var server = getCurrentServer(); var downsample = server.getDownsampleForResolution(Math.min(server.nResolutions()-1, 4)); PathImage<ImagePlus> pathImage = IJTools.convertToImagePlus(server, RegionRequest.createInstance(server, downsample)); ```; ""_Run for project (without saving and opening)_"":; ```; INFO: Starting script at Tue Mar 26 15:20:37 CET 2024; ERROR: The script tried to read pixels off an image while also requiring to run the script without accessing the image files.; WARN: Script cancelled with 53 image(s) remaining; INFO: Processed 54 images; INFO: Total processing time: 280 milliseconds; ```. ## HOW; Essentially this works by creating a `ImageServerStub` that extends `AbstractImageServer`. It retrieves metadata from the ProjectImageEntry itself (which in turn, i think, it gets them from the `.qpproj` file) and fails when `readRegion()` is being called. Additionally, it does not provide a server builder. This way, if the resulting image data are to be saved, the original ImageServer won't be overwritten/lost.; You can now pass a `openImage` boolean to `ProjectImageEntry.readImageData()` that, when false, just avoids getting the default image server, but just uses an instance of `ImageServerStub`. When running a `ProjectTask`, it will catch whether the script tried to access the image file. If it did, it stops the execution for the current image and all the following in the queue. ### Minor proposal; Finally, i'd like to discuss whether we could initially run all scripts with `ImageServerStub` by default and, only if they fail because they need to read the image files, run them with the correct ImageServer.; This point, however, is not really important and can be addressed in a future PR as well.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1488:2327,queue,queue,2327,https://qupath.github.io,https://github.com/qupath/qupath/pull/1488,1,['queue'],['queue']
Performance,esCommand - Exception adding Image null; java.io.IOException: Unable to build ImageServer for file:/D:/Random%20for%20core/qupath%20to%20csv/2016-08-11%20%2006_Flattened-Create%20Image%20Subset-01.czi (args=[]); at qupath.lib.images.servers.ImageServerBuilder$DefaultImageServerBuilder.buildOriginal(ImageServerBuilder.java:323); at qupath.lib.images.servers.ImageServerBuilder$AbstractServerBuilder.build(ImageServerBuilder.java:147); at qupath.lib.gui.commands.ProjectImportImagesCommand.initializeEntry(ProjectImportImagesCommand.java:505); at qupath.lib.gui.commands.ProjectImportImagesCommand$1.lambda$call$1(ProjectImportImagesCommand.java:278); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(Unknown Source); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); at java.base/java.util.stream.ForEachOps$ForEachTask.compute(Unknown Source); at java.base/java.util.concurrent.CountedCompleter.exec(Unknown Source); at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); at java.base/java.util.concurrent.ForkJoinTask.doInvoke(Unknown Source); at java.base/java.util.concurrent.ForkJoinTask.invoke(Unknown Source); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateParallel(Unknown Source); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(Unknown Source); at java.base/java.util.stream.AbstractPipeline.evaluate(Unknown Source); at java.base/java.util.stream.ReferencePipeline.forEach(Unknown Source); at java.base/java.util.stream.ReferencePipeline$Head.forEach(Unknown Source); at qupath.lib.gui.commands.ProjectImportImagesCommand$1.call(ProjectImportImagesCommand.java:276); at qupath.lib.gui.commands.ProjectImportImagesCommand$1.call(ProjectImportImagesCommand.java:236); at javafx.concurrent.Task$TaskCallable.call(Task.java:1425); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/jav,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/396:1907,concurren,concurrent,1907,https://qupath.github.io,https://github.com/qupath/qupath/issues/396,1,['concurren'],['concurrent']
Performance,"esult in substantial lag. Ideally it shouldn't, but if it does I wouldn't say it's necessarily a bug... since QuPath is already needing to do a *lot* of stuff to get acceptable performance across a wide range of scenarios. Specifically here:; * For a downsample >= 1, repainting detections caches tiles and multiple resolution levels for performance - this is why QuPath can handle millions of objects.; * For downsample < 1, repainting happens for all detections in the field of view (like for annotations) for improved appearance without nasty bitmap-upsampling artefacts. This is inevitably laggier than using cached tiles, but caching itself has considerable overhead in terms of memory and worse appearance. I think this tradeoff makes sense, since details really matter when viewing the image at high magnification but the number of objects visible should be limited (possibly thousands, but not millions). However it does mean that if you have a large enough monitor, many detections, and a downsample value slightly less than 1, performance there certainly can be a noticeable lag... and object connections make this worse by meaning that thousands more lines need to be rendered. However, investigating this revealed that QuPath was painting all the connections twice, which certainly wasn't helping things :). So the PR fixes the double-painting bug. Along the way, it adds a spatial cache that enables QuPath to be a bit smarter about which connections it paints. The main reason for this change is to overcome an issue with long connections sometimes being broken at some resolutions:. ### Old behavior:; ![connection_bug-1](https://user-images.githubusercontent.com/4690904/194024037-795fceaa-e542-4c67-8fa2-84e6a8aca691.png). ### New behavior:; ![connection_fix-1](https://user-images.githubusercontent.com/4690904/194024122-00080b78-b59b-4b8f-bf0d-aa990683268c.png). Together, I'm not certain whether or not you'll see a substantial improvement in performance - but these changes addres",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1069#issuecomment-1268167189:1238,perform,performance,1238,https://qupath.github.io,https://github.com/qupath/qupath/issues/1069#issuecomment-1268167189,1,['perform'],['performance']
Performance,"ew RenderedImageServer.Builder(imageData); .display(display); .downsamples(downsample); .layers(new HierarchyOverlay(viewer.getImageRegionStore(), viewer.getOverlayOptions(), imageData)); .build(). ```. **Expected behavior**; The above script can run for the whole project without crashing. **Screenshots**; If applicable, add screenshots to help explain your problem. **Desktop (please complete the following information):**; - OS: macOS (MacBook Air, M1); - QuPath Version: 0.5.1-arm64. **Additional context**. Stack trace; ```; ERROR: unable to create native thread: possibly out of memory or process/resource limits reached in thread_leak_repro.groovy at line number 25; java.base/java.lang.Thread.start0(Native Method); java.base/java.lang.Thread.start(Unknown Source); java.base/java.lang.System$2.start(Unknown Source); java.base/jdk.internal.vm.SharedThreadContainer.start(Unknown Source); java.base/java.util.concurrent.ThreadPoolExecutor.addWorker(Unknown Source); java.base/java.util.concurrent.ThreadPoolExecutor.execute(Unknown Source); qupath.lib.gui.images.stores.AbstractImageRegionStore.requestImageTile(AbstractImageRegionStore.java:374); qupath.lib.gui.images.stores.DefaultImageRegionStore.paintRegionCompletely(DefaultImageRegionStore.java:104); qupath.lib.gui.images.servers.RenderedImageServer.readTile(RenderedImageServer.java:363); qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); java.base/java.util.concurrent.FutureTask.run(Unknown Source); qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); qupath.lib.images.writers.AbstractImageIOWriter.writeImage(AbstractImageIOWriter.java:82); qupath.lib.images.writers.PngWriter.writeImage(PngWriter",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1561:2422,concurren,concurrent,2422,https://qupath.github.io,https://github.com/qupath/qupath/issues/1561,1,['concurren'],['concurrent']
Performance,"f display = qupath.lib.display.ImageDisplay.create(imageData); def server = new RenderedImageServer.Builder(imageData); .display(display); .downsamples(downsample); .layers(new HierarchyOverlay(viewer.getImageRegionStore(), viewer.getOverlayOptions(), imageData)); .build(). ```. **Expected behavior**; The above script can run for the whole project without crashing. **Screenshots**; If applicable, add screenshots to help explain your problem. **Desktop (please complete the following information):**; - OS: macOS (MacBook Air, M1); - QuPath Version: 0.5.1-arm64. **Additional context**. Stack trace; ```; ERROR: unable to create native thread: possibly out of memory or process/resource limits reached in thread_leak_repro.groovy at line number 25; java.base/java.lang.Thread.start0(Native Method); java.base/java.lang.Thread.start(Unknown Source); java.base/java.lang.System$2.start(Unknown Source); java.base/jdk.internal.vm.SharedThreadContainer.start(Unknown Source); java.base/java.util.concurrent.ThreadPoolExecutor.addWorker(Unknown Source); java.base/java.util.concurrent.ThreadPoolExecutor.execute(Unknown Source); qupath.lib.gui.images.stores.AbstractImageRegionStore.requestImageTile(AbstractImageRegionStore.java:374); qupath.lib.gui.images.stores.DefaultImageRegionStore.paintRegionCompletely(DefaultImageRegionStore.java:104); qupath.lib.gui.images.servers.RenderedImageServer.readTile(RenderedImageServer.java:363); qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); java.base/java.util.concurrent.FutureTask.run(Unknown Source); qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); qupath.lib.images.writers.AbstractImageIOWriter.writeImage(AbstractIma",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1561:2345,concurren,concurrent,2345,https://qupath.github.io,https://github.com/qupath/qupath/issues/1561,1,['concurren'],['concurrent']
Performance,f7934000000 ---p 00000000 00:00 0 ; 7f7934000000-7f79349a9000 rw-p 00000000 00:00 0 ; 7f79349a9000-7f7938000000 ---p 00000000 00:00 0 ; 7f7938000000-7f793850e000 rw-p 00000000 00:00 0 ; 7f793850e000-7f793c000000 ---p 00000000 00:00 0 ; 7f793c000000-7f793c021000 rw-p 00000000 00:00 0 ; 7f793c021000-7f7940000000 ---p 00000000 00:00 0 ; 7f79401bb000-7f7940203000 r-xp 00000000 00:2f 2345794467 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libjniopenblas_nolapack.so; 7f7940203000-7f7940403000 ---p 00048000 00:2f 2345794467 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libjniopenblas_nolapack.so; 7f7940403000-7f7940404000 r--p 00048000 00:2f 2345794467 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libjniopenblas_nolapack.so; 7f7940404000-7f7940405000 rw-p 00049000 00:2f 2345794467 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libjniopenblas_nolapack.so; 7f7940405000-7f7940524000 r-xp 00000000 fd:00 100815288 /usr/lib64/libgfortran.so.3.0.0; 7f7940524000-7f7940724000 ---p 0011f000 fd:00 100815288 /usr/lib64/libgfortran.so.3.0.0; 7f7940724000-7f7940725000 r--p 0011f000 fd:00 100815288 /usr/lib64/libgfortran.so.3.0.0; 7f7940725000-7f7940727000 rw-p 00120000 fd:00 100815288 /usr/lib64/libgfortran.so.3.0.0; 7f7940727000-7f7940893000 r-xp 00000000 00:2f 2345794462 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libgfortran.so.4; 7f7940893000-7f7940a92000 ---p 0016c000 00:2f 2345794462 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libgfortran.so.4; 7f7940a92000-7f7940a95000 rw-p 0016b000 00:2f 2345794462 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libgfortran.s,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018:11949,cache,cache,11949,https://qupath.github.io,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018,1,['cache'],['cache']
Performance,"for now, I think I'll fix the problem by loading/editing a pre-defined map",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/196#issuecomment-411736903:41,load,loading,41,https://qupath.github.io,https://github.com/qupath/qupath/issues/196#issuecomment-411736903,1,['load'],['loading']
Performance,"formats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:648); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:61); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:166); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:19); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:536); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:573); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:156); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:120); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:47); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:269); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); ERROR: IOException exception reading file:/Volumes/Storage/Work/SLIDESCANS/190512_OLYMPUS_YKA_Batch/CRUK_YKA_16.1D_tam_2_20190513.vsi#1: x=9728, y=34816, w=512, h=512, z=0, t=0, downsample=1; at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:199); at java.base/sun.nio.ch.FileChannelImpl.endBlocking(FileChannelImpl.java:162); at java.base/sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:816); at java.base/sun",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:7916,concurren,concurrent,7916,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['concurren'],['concurrent']
Performance,"g your bug report, please check the following:. * [X] I've definitely found a bug (it you're not sure, please use [image.sc](https://forum.image.sc/tags/qupath) instead); * [X] I've checked https://qupath.github.io for a new release that might already have fixed the issue; * [X] I've checked the [Changelog](https://github.com/qupath/qupath/blob/master/CHANGELOG.md) to see if the bug has already been fixed in the next release; * [X] I've checked for existing GitHub issues describing the same problem. ## Bug report. **Describe the bug**; QuPath projects with several hundred IMC images take a notably longer time to load. Opening the images themselves is comparatively faster, yet are still read into memory. No noticeable change in memory usage is occurring when the QuPath project is being loaded, indicating that these images may not be pre-loaded (i.e. cached) during loading of the project itself. My guess is that the thumbnails are being reconstructed each time the QuPath project is loaded (computer must be restarted to reproduce, closing and relaunching QuPath is not sufficient). Given that thumbnail generation was updated in the changelog of the newest unofficial release, I'll build from source now and close the ticket if I can't reproduce the bug. It's a minor inconvenience at best, especially since it's only a delay of two minutes. But keep in mind, the CPU here is a Ryzen 5950X with among the highest single thread speeds of desktop CPUs, and only 1 of the 32 threads is being used during this period. Depending on the root cause and a user's hardware configuration, load times may scale linearly or exponentially as project sizes move into the range of thousands of images. If this is caused by thumbnail generation, then this may only be affecting multiplexed IHC images such as those acquired through IMC or CODEX. **To Reproduce**; Video demonstration: https://www.youtube.com/watch?v=q4Jn9UTKUMw; 1. Create a QuPath project; 2. Load ~300 IMC images. Example IMC images c",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1154:1127,load,loaded,1127,https://qupath.github.io,https://github.com/qupath/qupath/issues/1154,1,['load'],['loaded']
Performance,"gePlusServerBuilder; > ^; > ; > Script1.groovy: 16: unable to resolve class qupath.imagej.images.servers.ImagePlusServer; > @ line 16, column 1.; > import qupath.imagej.images.servers.ImagePlusServer; > ^; > ; > 2 errors; > ; > ; > ERROR: Script error (MultipleCompilationErrorsException); > at org.codehaus.groovy.control.ErrorCollector.failIfErrors(ErrorCollector.java:311); > at org.codehaus.groovy.control.CompilationUnit.applyToSourceUnits(CompilationUnit.java:975); > at org.codehaus.groovy.control.CompilationUnit.doPhaseOperation(CompilationUnit.java:637); > at org.codehaus.groovy.control.CompilationUnit.compile(CompilationUnit.java:586); > at groovy.lang.GroovyClassLoader.doParseClass(GroovyClassLoader.java:401); > at groovy.lang.GroovyClassLoader.access$300(GroovyClassLoader.java:89); > at groovy.lang.GroovyClassLoader$5.provide(GroovyClassLoader.java:341); > at groovy.lang.GroovyClassLoader$5.provide(GroovyClassLoader.java:338); > at org.codehaus.groovy.runtime.memoize.ConcurrentCommonCache.getAndPut(ConcurrentCommonCache.java:147); > at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:336); > at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:320); > at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:262); > at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.getScriptClass(GroovyScriptEngineImpl.java:331); > at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:153); > at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:800); > at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:734); > at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:714); > at qupath.lib.gui.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1130); > at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); > at java.base/java.util.concurrent.FutureTask.run(Unknown Source)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/404:2170,Concurren,ConcurrentCommonCache,2170,https://qupath.github.io,https://github.com/qupath/qupath/issues/404,1,['Concurren'],['ConcurrentCommonCache']
Performance,gej.tools.IJTools.convertToImagePlus(IJTools.java:902); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:216); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by null at java.base/java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(Unknown Source); at java.base/java.util.concurrent.locks.ReentrantLock.lockInterruptibly(Unknown Source); at java.base/java.util.concurrent.ArrayBlockingQueue.put(Unknown Source); at qupath.lib.images.servers.bioformats.BioFormatsImageServer$ReaderPool.openImage(BioFormatsImageServer.java:1411); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:909); at qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.lib.images.servers.CroppedImageServer.readRegion(CroppedImageServer.java:90); at qupath.lib.images.servers.CroppedImageServer.readRegion(CroppedImageServer.java:39); at qupath.lib.images.servers.SparseImageServer,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583:2812,concurren,concurrent,2812,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583,1,['concurren'],['concurrent']
Performance,gine.java:190); 	at qupath.ext.instanseg.core.PytorchManager.lambda$getEngineOnline$0(PytorchManager.java:28); 	at qupath.ext.instanseg.core.PytorchManager.callWithTempProperty(PytorchManager.java:114); 	at qupath.ext.instanseg.core.PytorchManager.callOnline(PytorchManager.java:106); 	at qupath.ext.instanseg.core.PytorchManager.getEngineOnline(PytorchManager.java:28); 	at qupath.ext.instanseg.ui.InstanSegController.downloadPyTorch(InstanSegController.java:826); 	at qupath.ext.instanseg.ui.InstanSegController.ensurePyTorchAvailable(InstanSegController.java:815); 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(Unknown Source); 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.exec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source); Caused by: java.lang.UnsatisfiedLinkError: C:\Users\username\.djl.ai\pytorch\2.3.1-cu121-win-x86_64\cudnn_cnn_infer64_8.dll: The specified procedure could not be found; 	at java.base/jdk.internal.loader.NativeLibraries.load(Native Method); 	at java.base/jdk.internal.loader.NativeLibraries$NativeLibraryImpl.open(Unknown Source); 	at java.base/jdk.internal.loader.NativeLibraries.loadLibrary(Unknown Source); 	at java.base/jdk.internal.loader.NativeLibraries.loadLibrary(Unknown Source); 	at java.base/java.lang.ClassLoader.loadLibrary(Unknown Source); 	at java.base/java.lang.Runtime.load0(Unknown Source); 	at java.base/java.lang.System.load(Unknown Source); 	at ai.djl.pytorch.jni.LibUtils.loadNativeLibrary(LibUtils.java:379); 	at ai.djl.pytorch.jni.LibUtils.loadLibTorch(LibUtils.java:176); 	at ai.djl.pytorch.jni.LibUtils.loadLibrary(LibUtils.java:82); 	at ai.djl.pytorch.,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1636:1542,concurren,concurrent,1542,https://qupath.github.io,https://github.com/qupath/qupath/issues/1636,1,['concurren'],['concurrent']
Performance,"h/qupath/issues/1444; * https://github.com/qupath/qupath/issues/1591 . and incorporates synchronization from; * https://github.com/qupath/qupath/pull/1466. ---. This substantially updates the `MeasurementList` API, while avoiding any serialization-breaking changes.; It also adds many new tests to help improve the robustness of both the `MeasurementList` directly and any associated `Map` view. Methods that were deprecated since v0.4.0 have now been removed, and there are 2 more deprecations.; The replacement methods have shorter names and should have reliable performance.; `MeasurementList` implementations should also now be threadsafe (if they prove not to be, please report a bug). Several other key changes:; * `getNames()` (previously `getMeasurementNames()`) returns a defensive copy of the measurement. Before, it would sometimes return an unmodifiable list that wrapped a list that could still change - and that was sometimes responsible for #1444 and #1591; * `List<Measurement> getMeasurements()` and `Measurement getByIndex(int)` now provide ways to access a snapshot of one or more measurements. Previously, `getMeasurementName(int)` and `getMeasurementValue(int)` were used - but when requesting these sequentially, there was no way to guarantee that the values were properly in sync.; * `String.intern()` is now used with all `MeasurementList` implementations. Previously, it was only used for the 'general' list used for annotations. It wasn't important if other lists were closed, but if they weren't then we could end up with huge numbers of duplicate strings greatly increasing memory use. In general, the goal of `MeasurementList` is to optimize mostly for memory use and good behavior.; Updating and querying measurements is generally rare enough that small computational costs (e.g. synchronization, defensive copying) shouldn't matter a great deal - but if we are to cope with millions of objects having hundreds of measurements each, we need to keep memory under control.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1592:1700,optimiz,optimize,1700,https://qupath.github.io,https://github.com/qupath/qupath/pull/1592,1,['optimiz'],['optimize']
Performance,"he StarDist extension. This *may* be related to an OpenCV bug, since fixed: https://github.com/opencv/opencv/issues/23183; There's no final JavaCPP release containing the fix though. **To Reproduce**; Steps to reproduce the behavior:; 1. Download the intel (x64) build of v0.5.0-rc2 (or likely v0.5.0-rc1); 2. Run [the StarDist extension](https://github.com/qupath/qupath-extension-stardist), e.g. using CMU-1.svs and the H&E model. This is likely to either throw an exception, or shut down QuPath immediately. This problem does not occur when using the arm64 build. **Expected behavior**; The x64 build should work through Rosetta2 (just a bit slower). **Desktop (please complete the following information):**; - OS: macOS 14; - QuPath Version: v0.5.0-rc2 (and also rc1). **Additional context**; This matters to some users because Bio-Formats doesn't support Apple Silicon:; * https://github.com/ome/bioformats/issues/3756; * https://github.com/glencoesoftware/jxrlib/issues/30. Consequently, some users (particularly those with Axioscan .czi images) are forced to run the x64 builds of QuPath. This can *probably* be addressed by reverting to OpenCV 4.6.0, but that would be unfortunate since OpenCV's DNN's performance should be much improved - at least for Apple Silicon - in v4.7.0 (although that may be the source of the problem...). Timings (in minutes) for one largish region of CMU-2.svs on Apple Silicon are given below:. * v0.5.0-rc2 arm64 - 1:38; * v0.4.4 arm64 - 2:47; * v0.4.4 intel64 - 3:54. So it's a shame to penalize more users by sticking with an older OpenCV because of this bug, which should only affect a *relatively* small number of people for whom the following is true:; * Using Apple Silicon; * Using .czi files; * Using the StarDist extension. Before deciding, one thing to check is whether or not TensorFlow can work via Rosetta2 on the Intel build, since this would give an alternative. Previously it failed, but it's worth checking again with the latest DeepJavaLibrary.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1406:1355,perform,performance,1355,https://qupath.github.io,https://github.com/qupath/qupath/issues/1406,1,['perform'],['performance']
Performance,"hed the QuPath project in 0.4.1, and the load time was nearly instantaneous. Which, while resolving the issue, also means that the issue exists outside of QuPath. So, for some reason, the thumbnail previews are lost after a period of time, and don't seem to coincide with closing the folder or restarting the computer. The first thing I attempted to preserve thumbnails was to ensure ""Always show icons, never thumbnails"" in the folder options was unchecked, however it already was by default:; ![image](https://user-images.githubusercontent.com/52012166/211071879-ac70ef62-925f-4fe5-8ec3-10763d391393.png); Toggling this field didn't seem to have any impact on project loading performance, since in either case, the thumbnails were already generated (just replaced with an icon if the box is checked).; Next, under Windows performance options, I noticed ""save taskbar thumbnail previews"" was unchecked by default. I've checked it, and so far, I don't seem to have trouble loading projects that already have thumbnails generated in explorer. ; ![image](https://user-images.githubusercontent.com/52012166/211072664-c211658b-7aa6-435d-8067-830b4e1620b1.png). I'll continue to test other projects and rebooting my computer, to confirm if this has resolved the issue. TL;DR: **Check ""save taskbar thumbnail previews"" under Windows performance options. Subsequent loads of the project should now be much faster**. EDIT: So far, this fix persists after rebooting the system. EDIT 2: I've opened the project again after a few hours, verifying that the thumbnails exist in Windows Explorer. I'm now getting a long project load time (although anecdotally, it feels a bit faster), which means the above fix might not work as it could be tied to something other than thumbnails generated in Explorer. Currently, the project is located on the OS-installed drive (NVMe SSD), but the images are located on a separate local NVMe SSD. I'll see if moving both the project and images onto the OS drive changes anything",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1154#issuecomment-1373971580:1840,perform,performance,1840,https://qupath.github.io,https://github.com/qupath/qupath/issues/1154#issuecomment-1373971580,3,"['load', 'perform']","['load', 'loads', 'performance']"
Performance,"his case it was not problematic that the green region extended outside of the tissue since there were no cells of interest in this “white space”. But ideally it would also fallow the “cut”. - I always start with lining the tumor border (blue) and then I extend it 500µm to get the green one. After this I perform the cell detection in the green one (but the blue one always disappears) after this I run the classifier and when this is completed I ‘expand’ my green annotation with -500µm to get the blue one again and after this I ‘expand the blue one with -500µm to get the black one. I think it may be better that the green and blue would be hollow rings around the outside of the black one. Since we want to measure cells in three different regions: in the tumor center (500 µm from the tumor border) (black), in the invasive front (area between the green and black annotation) and in the tumor (blue).But as of now I don’t know if it is possible to establish this?. - We want to count every immune cell in the tumor (+ and -) but not the tumor cells. In the beginning I tried “Positive cell detection” but when using this command, the software also counted a lot of cells that weren’t immune cells. That is why I switched to the classifier, I am very pleased with the results the classifier is giving me. We are scoring 7 different staining’s (70 samples per staining) and I would like to train the classifier for each staining but within a staining I would like to apply the same classifier for each sample. - In total it will be around 500 images. - I am just starting and trying some things out. I will try to create the annotations before cell detection, but as I have mentioned above: I start with the blue annotation and then I extend it 500µm to get the green one. But when I want to perform the cell detection the first annotation (blue) disappears. So I thought it was nog possible to perform a cell detection in overlapping annotation, or is there a way I can overcome this?. Thank you!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/198#issuecomment-411026150:2084,perform,perform,2084,https://qupath.github.io,https://github.com/qupath/qupath/issues/198#issuecomment-411026150,2,['perform'],['perform']
Performance,however I do get the following error when starting qupath:. `; [JavaFX Application Thread] [ERROR] q.l.i.s.o.OpenslideServerBuilder - Could not load OpenSlide native libraries; java.lang.UnsatisfiedLinkError: no openslide-jni in java.library.path: /usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib; at java.base/java.lang.ClassLoader.loadLibrary(Unknown Source); at java.base/java.lang.Runtime.loadLibrary0(Unknown Source); at java.base/java.lang.System.loadLibrary(Unknown Source); at org.openslide.OpenSlideJNI.<clinit>(OpenSlideJNI.java:55); at org.openslide.OpenSlide.<clinit>(OpenSlide.java:53); at qupath.lib.images.servers.openslide.OpenslideServerBuilder.<clinit>(OpenslideServerBuilder.java:88); at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source); at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source); at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Unknown Source); at java.base/java.lang.reflect.Constructor.newInstance(Unknown Source); at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(Unknown Source); at java.base/java.util.ServiceLoader$ProviderImpl.get(Unknown Source); at java.base/java.util.ServiceLoader$3.next(Unknown Source); at qupath.lib.images.servers.ImageServerProvider.getInstalledImageServerBuilders(ImageServerProvider.java:104); at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1601); at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:1059); at qupath.lib.gui.QuPathApp.start(QuPathApp.java:60); at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$9(LauncherImpl.java:846); at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$12(PlatformImpl.java:455); at com.sun.javafx.application.PlatformImpl.lambda$runLater$10(PlatformImpl.java:428); at java.base/java.security.AccessController.doPrivileged(Unknown Source); at com.su,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/615#issuecomment-725509556:144,load,load,144,https://qupath.github.io,https://github.com/qupath/qupath/issues/615#issuecomment-725509556,3,['load'],"['load', 'loadLibrary']"
Performance,"i.QuPathGUI - Selected style: Modena Dark; 02:39:38.757 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 02:39:38.781 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 02:39:38.837 [JavaFX Application Thread] [INFO ] q.lib.gui.helpers.DisplayHelpers - QuPath Notice: This is a pre-release version of QuPath; Version: 0.0.6; Build time: 2016-11-16, 15:54; 02:40:13.093 [JavaFX Application Thread] [ERROR] q.l.i.servers.OpenslideServerBuilder - Could not load OpenSlide native library; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopenslide-jni.so: libopenslide.so.0: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at org.openslide.OpenSlideJNI.<clinit>(OpenSlideJNI.java:55); 	at org.openslide.OpenSlide.<clinit>(OpenSlide.java:53); 	at qupath.lib.images.servers.OpenslideImageServer.<init>(OpenslideImageServer.java:91); 	at qupath.lib.images.servers.OpenslideServerBuilder.buildServer(OpenslideServerBuilder.java:47); 	at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:115); 	at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2091); 	at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2015); 	at qupath.lib.gui.commands.OpenCommand.run(OpenCommand.java:51); 	at qupath.lib.gui.QuPathGUI.lambda$43(QuPathGUI.java:2960); 	at org.controlsfx.control.action.Action.handle(Action.java:419); 	at org.controlsfx.control.action.Action.handle(Action.java:64); 	at com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86); 	at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:238); ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/27#issuecomment-262870405:4043,load,loadLibrary,4043,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405,1,['load'],['loadLibrary']
Performance,"ib.gui.TaskRunnerFX.runTasks(TaskRunnerFX.java:106); 	at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:147); 	at qupath.lib.gui.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:177); 	at java.base/java.lang.Thread.run(Unknown Source); Caused by: java.util.ConcurrentModificationException; 	at java.base/java.util.ArrayList$Itr.checkForComodification(Unknown Source); 	at java.base/java.util.ArrayList$Itr.next(Unknown Source); 	at java.base/java.util.Collections$UnmodifiableCollection$1.next(Unknown Source); 	at java.base/java.util.AbstractCollection.addAll(Unknown Source); 	at qupath.lib.objects.PathObjectTools.getAvailableFeatures(PathObjectTools.java:2026); 	at qupath.opencv.features.DelaunayTriangulation.<init>(DelaunayTriangulation.java:86); 	at qupath.opencv.features.DelaunayClusteringPlugin$DelaunayRunnable.run(DelaunayClusteringPlugin.java:208); 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); 	at java.base/java.util.concurrent.FutureTask.run(Unknown Source); 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); 	at java.base/java.util.concurrent.FutureTask.run(Unknown Source); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); 	... 1 more; ```. 2. If I repeat with **the outer rectangle selected**, then I *do* see connections.; This is because the triangulation uses *all descendant detections below the rectangle, based on the object hierarchy*. ![2-rectangle](https://github.com/user-attachments/assets/21b82d18-ce97-45c3-9644-7abdf85ab007). 3. If I repeat with **the outer ellipse selected**, I get *no connections at all*.; This is because the ellipse isn't set to be a parent of any of the other objects - this would change if I called *Resolve hierarchy* first. ![3-ellipse](https://github.com/user-attachments/assets/3c39bea5-9a9c-4ae3-bcc9-7ece1e8bae9c). 4. If I repea",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1590:2488,concurren,concurrent,2488,https://qupath.github.io,https://github.com/qupath/qupath/issues/1590,1,['concurren'],['concurrent']
Performance,"ib.gui.TaskRunnerFX.runTasks(TaskRunnerFX.java:106); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:147); at qupath.lib.gui.QuPathGUI.runPlugin(QuPathGUI.java:2245); at qupath.lib.gui.scripting.QPEx.runPlugin(QPEx.java:248); at qupath.lib.gui.scripting.QPEx.runPlugin(QPEx.java:270); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript.run(QuPathScript:4); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:331); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:161); at qupath.lib.gui.scripting.languages.DefaultScriptLanguage.execute(DefaultScriptLanguage.java:234); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:1166); at qupath.lib.gui.scripting.DefaultScriptEditor$3.run(DefaultScriptEditor.java:1534); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by Cannot invoke ""java.awt.image.BufferedImage.getSampleModel()"" because ""img"" is null at qupath.imagej.tools.IJTools.convertToUncalibratedImagePlus(IJTools.java:791); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:864); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:902); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:216); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443:2751,concurren,concurrent,2751,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443,1,['concurren'],['concurrent']
Performance,ib64/libstdc++.so.6(+0x712e1)[0x7f72686072e1]; /usr/lib64/libstdc++.so.6(_ZNSt6localeC2Ev+0x13)[0x7f7268607323]; /usr/lib64/libstdc++.so.6(_ZNSt8ios_base4InitC2Ev+0xbc)[0x7f726860417c]; /usr/lib64/dri/swrast_dri.so(+0x85930)[0x7f726bbe8930]; /lib64/ld-linux-x86-64.so.2(+0xf973)[0x7fa4aa9f3973]; /lib64/ld-linux-x86-64.so.2(+0x1454e)[0x7fa4aa9f854e]; /lib64/ld-linux-x86-64.so.2(+0xf784)[0x7fa4aa9f3784]; /lib64/ld-linux-x86-64.so.2(+0x13b3b)[0x7fa4aa9f7b3b]; /lib64/libdl.so.2(+0xeeb)[0x7fa4aa7e0eeb]; /lib64/ld-linux-x86-64.so.2(+0xf784)[0x7fa4aa9f3784]; /lib64/libdl.so.2(+0x14ed)[0x7fa4aa7e14ed]; /lib64/libdl.so.2(dlopen+0x31)[0x7fa4aa7e0f81]; /lib64/libGLX_system.so.0(+0x4444c)[0x7f726ecdd44c]; /lib64/libGLX_system.so.0(+0x4374a)[0x7f726ecdc74a]; /lib64/libGLX_system.so.0(+0x1f138)[0x7f726ecb8138]; /lib64/libGLX_system.so.0(+0x1a9d2)[0x7f726ecb39d2]; /lib64/libGLX_system.so.0(+0x1b7c6)[0x7f726ecb47c6]; /lib64/libGLX.so.0(glXChooseFBConfig+0x31)[0x7f726f5df6b1]; /home/xxx/.openjfx/cache/16/libprism_es2.so(Java_com_sun_prism_es2_X11GLFactory_nInitialize+0xa4)[0x7f72d01fb2d4]; [0x7fa492426bbb]; ======= Memory map: ========; 80000000-80020000 rw-p 00000000 00:00 0 ; 80020000-80040000 rw-p 00000000 00:00 0 ; 80040000-800c0000 rw-p 00000000 00:00 0 ; 800c0000-80140000 rw-p 00000000 00:00 0 ; 80140000-801c0000 rw-p 00000000 00:00 0 ; 801c0000-80200000 rw-p 00000000 00:00 0 ; 80200000-80220000 rw-p 00000000 00:00 0 ; 80220000-80240000 ---p 00000000 00:00 0 ; 80240000-80250000 rw-p 00000000 00:00 0 ; 80250000-c0000000 ---p 00000000 00:00 0 ; 55f52014d000-55f52025b000 r-xp 00000000 00:d4 7777221080545788605 /home/xxx/QuPath-0.3/bin/QuPath; 55f52045b000-55f520463000 r--p 0010e000 00:d4 7777221080545788605 /home/xxx/QuPath-0.3/bin/QuPath; 55f520463000-55f520464000 rw-p 00116000 00:d4 7777221080545788605 /home/xxx/QuPath-0.3/bin/QuPath; 55f520464000-55f520467000 rw-p 00000000 00:00 0 ; 55f521999000-55f5219cb000 rw-p 00000000 00:00 0 [heap]; 7f7268380000-7f7268395000 r-xp 00000000 ,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/825:2007,cache,cache,2007,https://qupath.github.io,https://github.com/qupath/qupath/issues/825,1,['cache'],['cache']
Performance,"if the file is loaded just als single file, not within a project, it also crashes QuPath",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/47#issuecomment-276386273:15,load,loaded,15,https://qupath.github.io,https://github.com/qupath/qupath/issues/47#issuecomment-276386273,1,['load'],['loaded']
Performance,"ile are not exactly the same as he described, the logic to extract the pointer are quite different and it takes me a lot of efforts to get all of them out. Indeed I have almost utilized all the file space from Index.dat. . I have a final problem of image alignment between camera positions. In my file I have two camera acquisitions (square A on left and square B on right), each square was indeed 8x8 tiles connected seamless forming a square. However, A and B overlap in the middle by about 146 pixels. I noticed that B was also about 10 pixels higher than A, this indicate that the two images are not perfectly on the same y level. This offset on Y was noticed when I open image either on QuPath or on CaseViewer, they both shows exactly 10 pixels of Y offset on B. To further prove that A and B has Y offset, from the extracted small 302px x 252 px tiles I pick up two tiles that just located on both side of boundary between A and B. I load the two tiles into Imaris Stitcher and stich them together, indeed I found that they have some offset on Y direction. My task was to rebuild the whole slide from the extracted tiles. ( Infact this mrxs file also has a 31-layer Z-stack and I also extracted all z-stack’s tiles, this is what I realy need). Although I can get the camera position for the A and B from extracted meta file, the Y position of camera are the same. So the Y offset should not arise from the camera positions. So how QuPath could show the Y offset exactly the same as CaseViewer? Is there some other information indicate how the Y should be offset?. <scaninfo>; <data>; <scaninfo ; XImagePos=""37"" ; YImagePos=""115"" ; ZImagePos=""14"" ; XMotorPos=""15424"" ; YMotorPos=""53673"" ; ZMotorPos=""1446"" ; FineFocusRange=""1402 - 1466"" ; CoarseFocusRange=""1050 - 2650"" ; ObjectLevel=""none"" ; OpticalFocusLevel=""1446"" ; FocusingType=""OptWholeRange"" ; Neighbours=""none"" ; NeighbourCoarsePoint=""(37;115)""/>; </data>; </scaninfo>; %---------------------; <scaninfo>; <data>; <scaninfo ; XImagePos=""",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/265:1431,load,load,1431,https://qupath.github.io,https://github.com/qupath/qupath/issues/265,1,['load'],['load']
Performance,"ile cache size to 1996.50 MB (25.0% max memory). (QuPath-0.2.0-m4:17581): Gdk-WARNING **: 10:11:47.691: XSetErrorHandler() called with a GDK error trap pushed. Don't do that.; 10:11:48.207 [JavaFX Application Thread] [INFO ] q.l.i.s.b.BioFormatsOptionsExtension - Bio-Formats version 6.2.0; 10:11:48.216 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Bio-Formats server options (Bio-Formats 6.2.0) (20 ms); 10:11:48.235 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Experimental commands (19 ms); 10:11:48.278 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension ImageJ extension (42 ms); 10:11:48.290 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension JPen extension (12 ms); 10:11:48.294 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension OpenCV extensions (3 ms); Oct 13, 2019 10:11:48 AM jpen.provider.NativeLibraryLoader$4 run; INFO: loading JPen 2-150301 JNI library: jpen-2-4-x86_64 ...; Oct 13, 2019 10:11:48 AM jpen.provider.NativeLibraryLoader$4 run; INFO: jpen-2-4-x86_64 loaded; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.codehaus.groovy.vmplugin.v7.Java7$1 (file:/usr/local/src/QuPath-0.2.0-m4/app/groovy-2.5.7.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class,int); WARNING: Please consider reporting this to the maintainers of org.codehaus.groovy.vmplugin.v7.Java7$1; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 10:11:48.594 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Rich script editor extension (300 ms); 10:11:48.603 [JavaFX Application Thread] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1; 10:11:48.698 [JavaFX Application Thread] [INFO ] qupath.lib.gu",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/369:2596,load,loading,2596,https://qupath.github.io,https://github.com/qupath/qupath/issues/369,1,['load'],['loading']
Performance,"images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:61); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:166); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:19); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:536); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:573); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:156); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:120); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:47); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:269); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); ERROR: IOException exception reading file:/Volumes/Storage/Work/SLIDESCANS/190512_OLYMPUS_YKA_Batch/CRUK_YKA_16.1D_tam_2_20190513.vsi#1: x=9728, y=34816, w=512, h=512, z=0, t=0, downsample=1; at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:199); at java.base/sun.nio.ch.FileChannelImpl.endBlocking(FileChannelImpl.java:162); at java.base/sun.nio.ch.FileChannelImpl.readInternal(FileChannelImpl.java:816); at java.base/sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:796); at loci.common.NIOByteBufferPr",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:8002,concurren,concurrent,8002,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['concurren'],['concurrent']
Performance,"in explorer, and set the thumbnail size to ""large icons"" via `view > large icons`. This would generate thumbnails for all files that are currently displayed on screen. After those were generated, I scrolled down, so that the remaining files would also have their thumbnails generated. Then, I launched the QuPath project in 0.4.1, and the load time was nearly instantaneous. Which, while resolving the issue, also means that the issue exists outside of QuPath. So, for some reason, the thumbnail previews are lost after a period of time, and don't seem to coincide with closing the folder or restarting the computer. The first thing I attempted to preserve thumbnails was to ensure ""Always show icons, never thumbnails"" in the folder options was unchecked, however it already was by default:; ![image](https://user-images.githubusercontent.com/52012166/211071879-ac70ef62-925f-4fe5-8ec3-10763d391393.png); Toggling this field didn't seem to have any impact on project loading performance, since in either case, the thumbnails were already generated (just replaced with an icon if the box is checked).; Next, under Windows performance options, I noticed ""save taskbar thumbnail previews"" was unchecked by default. I've checked it, and so far, I don't seem to have trouble loading projects that already have thumbnails generated in explorer. ; ![image](https://user-images.githubusercontent.com/52012166/211072664-c211658b-7aa6-435d-8067-830b4e1620b1.png). I'll continue to test other projects and rebooting my computer, to confirm if this has resolved the issue. TL;DR: **Check ""save taskbar thumbnail previews"" under Windows performance options. Subsequent loads of the project should now be much faster**. EDIT: So far, this fix persists after rebooting the system. EDIT 2: I've opened the project again after a few hours, verifying that the thumbnails exist in Windows Explorer. I'm now getting a long project load time (although anecdotally, it feels a bit faster), which means the above fix might",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1154#issuecomment-1373971580:1183,load,loading,1183,https://qupath.github.io,https://github.com/qupath/qupath/issues/1154#issuecomment-1373971580,2,"['load', 'perform']","['loading', 'performance']"
Performance,"in the *Hierarchy* tab. Basically, JavaFX’s ```TreeView``` is forced to do a rather slow check along all expanded nodes to look for objects... and if you have a single expanded node containing >~ 10 000 objects expanded within the ```TreeView``` then this can be *extremely slow*. It likely hasn't actually crashed… but it would take an unrealistically long time to become responsive again. The problem is intermittent because expanded nodes with only a few thousand objects in them (e.g. TMA cores) can be handled quite quickly. Additionally, large numbers of objects can be handled so long as the parent objects within the tree aren't expanded, or the objects are contained within multiple smaller annotations rather than a single, very large region. As such, TMA slides and core biopsies likely work (given that the objects are stored within smaller regions), while some whole face sections may be problematic depending on what processing is performed and how. Since the issue appears to be isolated to the display of large numbers of detections within a ```TreeView```, a straightforward fix in a future QuPath release may be to simply exclude detections from the ```TreeView``` by default, showing instead only TMA cores and annotations. In the meantime, hopefully this description of the issue might help anyone encountering it to know the cause, and look for workarounds for their uses. For example, if it is still required to analyze a single large region containing a large number of detections, then *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* has recently received an update to enable the creation of 'annotation tiles'. Using this, the larger annotation can be partitioned into smaller ones, which can then be processed separately. Some additional care is needed to ensure that the correct annotations are selected at the appropriate time using this method, but it can be used to avoid the performance issue before a longer term fix is available.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/41:2688,perform,performance,2688,https://qupath.github.io,https://github.com/qupath/qupath/issues/41,1,['perform'],['performance']
Performance,ineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ERROR: Error running plugin: java.lang.NullPointerException; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.scripting.QPEx.runPlugin(QPEx.java:266); at qupath.lib.scripting.QPEx.runPlugin(QPEx.java:286); at qupath.lib.scripting.QPEx$runPlugin.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:214); at Script30.run(Script30.groovy:12); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEng,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:8998,concurren,concurrent,8998,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['concurren'],['concurrent']
Performance,"ing OME metadata; INFO: No memoization file generated for C:\Users\617\Desktop\1800164.tif; ERROR: Error opening image 0 for region java.awt.Rectangle[x=0,y=0,width=23422,height=30978]; at loci.formats.FormatReader.openBytes(FormatReader.java:880); at loci.formats.ImageReader.openBytes(ImageReader.java:444); at loci.formats.ReaderWrapper.openBytes(ReaderWrapper.java:334); at loci.formats.ReaderWrapper.openBytes(ReaderWrapper.java:334); at loci.formats.gui.BufferedImageReader.openImage(BufferedImageReader.java:86); at qupath.lib.images.servers.BioFormatsImageServer.readBufferedImage(BioFormatsImageServer.java:683); at qupath.lib.images.servers.BioFormatsImageServer.readBufferedImage(BioFormatsImageServer.java:95); at qupath.lib.images.stores.AbstractImageRegionStore$DefaultTileWorker$1.call(AbstractImageRegionStore.java:656); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by Array size too large: 23422 x 30978 x 3 x 1 at loci.common.DataTools.safeMultiply32(DataTools.java:1274); at loci.common.DataTools.allocate(DataTools.java:1247); at loci.formats.FormatReader.openBytes(FormatReader.java:877); at loci.formats.ImageReader.openBytes(ImageReader.java:444); at loci.formats.ReaderWrapper.openBytes(ReaderWrapper.java:334); at loci.formats.ReaderWrapper.openBytes(ReaderWrapper.java:334); at loci.formats.gui.BufferedImageReader.openImage(BufferedImageReader.java:86); at qupath.lib.images.servers.BioFormatsImageServer.readBufferedImage(BioFormatsImageServer.java:683); at qupath.lib.images.servers.BioFormatsImageServer.readBufferedImage(BioFormatsImageServer.java:95); at qupath.lib.images.stores.AbstractImageRegionStore$DefaultTileWorker$1.call(AbstractImageRegionStore.java:656); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.u",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/221:20427,concurren,concurrent,20427,https://qupath.github.io,https://github.com/qupath/qupath/issues/221,1,['concurren'],['concurrent']
Performance,"ing the latest version of QuPath; will close ticket if it ends up being fixed. ## Before we begin... Before submitting your bug report, please check the following:. * [X] I've definitely found a bug (it you're not sure, please use [image.sc](https://forum.image.sc/tags/qupath) instead); * [X] I've checked https://qupath.github.io for a new release that might already have fixed the issue; * [X] I've checked the [Changelog](https://github.com/qupath/qupath/blob/master/CHANGELOG.md) to see if the bug has already been fixed in the next release; * [X] I've checked for existing GitHub issues describing the same problem. ## Bug report. **Describe the bug**; QuPath projects with several hundred IMC images take a notably longer time to load. Opening the images themselves is comparatively faster, yet are still read into memory. No noticeable change in memory usage is occurring when the QuPath project is being loaded, indicating that these images may not be pre-loaded (i.e. cached) during loading of the project itself. My guess is that the thumbnails are being reconstructed each time the QuPath project is loaded (computer must be restarted to reproduce, closing and relaunching QuPath is not sufficient). Given that thumbnail generation was updated in the changelog of the newest unofficial release, I'll build from source now and close the ticket if I can't reproduce the bug. It's a minor inconvenience at best, especially since it's only a delay of two minutes. But keep in mind, the CPU here is a Ryzen 5950X with among the highest single thread speeds of desktop CPUs, and only 1 of the 32 threads is being used during this period. Depending on the root cause and a user's hardware configuration, load times may scale linearly or exponentially as project sizes move into the range of thousands of images. If this is caused by thumbnail generation, then this may only be affecting multiplexed IHC images such as those acquired through IMC or CODEX. **To Reproduce**; Video demonstration: h",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1154:993,cache,cached,993,https://qupath.github.io,https://github.com/qupath/qupath/issues/1154,2,"['cache', 'load']","['cached', 'loading']"
Performance,"ion (1 ms); INFO: Loaded extension ImageJ extension (44 ms); INFO: Loaded extension JPen extension (19 ms); INFO: Loaded extension Processing extension (28 ms); INFO: Loaded extension Rich script editor extension (235 ms); INFO: Loaded extension SVG export extension (1 ms); INFO: OpenSlide version 3.4.1; INFO: Starting QuPath with parameters: []; INFO: Trying to load project Z:\Kotb Lab\General\ALL INFECT and INFECT; images\INF 69 DR3 DR4 repeat for Ganesh manuscript Qupath data\dr3 gfap new; 042121\project.qpproj; INFO: Project set to Project: dr3 gfap new 042121-project; INFO: Image data set to ImageData: Brightfield (H-DAB), PR301S1 2021-04-23; 07.49.55.ndpi; WARN: Unable to open file://; undmed-files.med.und.edu/Basic%20Sciences/Kotb%20Lab/General/ALL%20INFECT%20and%20INFECT%20images/INF%2069%20DR3%20DR4%20repeat%20for%20Ganesh%20manuscript%20Qupath%20data/dr3%20gfap%20new%20042121/PR287S8%20-%202021-04-12%2009.52.58.ndpi; with OpenSlide: URI has an authority component; ERROR: Load ImageData: Unable to build ImageServer for file://; undmed-files.med.und.edu/Basic%20Sciences/Kotb%20Lab/General/ALL%20INFECT%20and%20INFECT%20images/INF%2069%20DR3%20DR4%20repeat%20for%20Ganesh%20manuscript%20Qupath%20data/dr3%20gfap%20new%20042121/PR287S8%20-%202021-04-12%2009.52.58.ndpi; (args=[]) with requested provider; qupath.lib.images.servers.openslide.OpenslideServerBuilder; ERROR: Load ImageData; at; qupath.lib.images.servers.ImageServerBuilder$DefaultImageServerBuilder.buildOriginal(ImageServerBuilder.java:341); at; qupath.lib.images.servers.ImageServerBuilder$AbstractServerBuilder.build(ImageServerBuilder.java:152); at; qupath.lib.projects.DefaultProject$DefaultProjectImageEntry.readImageData(DefaultProject.java:718); at qupath.lib.gui.QuPathGUI.openImageEntry(QuPathGUI.java:2695); at; qupath.lib.gui.panes.ProjectBrowser.lambda$new$3(ProjectBrowser.java:190); at; com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86); at; com.sun.jav",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/396#issuecomment-827610434:1656,Load,Load,1656,https://qupath.github.io,https://github.com/qupath/qupath/issues/396#issuecomment-827610434,1,['Load'],['Load']
Performance,"is that I need more memory on my computer for the processing that I am doing (4GB RAM is not enough).; Thanks again,; Chris. From: Pete [mailto:notifications@github.com]; Sent: Monday, 8 January 2018 6:19 AM; To: qupath/qupath <qupath@noreply.github.com>; Cc: Christopher Rowe <Christopher.W.Rowe@uon.edu.au>; Author <author@noreply.github.com>; Subject: Re: [qupath/qupath] PositiveCellDetection and Classifier fails (#130). It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:. // Print the current memory situation. def runtime = Runtime.getRuntime(). double scale = 1.0/1024.0/1024.0. print 'Max memory (MB): ' + (runtime.maxMemory() * scale). print 'Total memory (MB): ' + (runtime.totalMemory() * scale). print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache. javafx.application.Platform.runLater {. getCurrentViewer().getImageRegionStore().cache.clear(). System.gc(). }. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/130#issuecomment-355877016:1333,cache,cache,1333,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355877016,1,['cache'],['cache']
Performance,"is that it makes the sub-class “Tumour: Positive” but not “Stroma: Positive” and I can’t understand how to create this. Many tanks again, I’ll work on the nuclei shape more extensively later on. Lucia. From: Svidro <notifications@github.com>; Reply-To: qupath/qupath <reply@reply.github.com>; Date: Thursday, 18 October 2018 at 19:40; To: qupath/qupath <qupath@noreply.github.com>; Cc: ""Montorsi, Lucia"" <lucia.montorsi@kcl.ac.uk>, Author <author@noreply.github.com>; Subject: Re: [qupath/qupath] Elongated nuclei not correctly detected (#231). For the nuclei, I would recommend starting a thread on the forum where you can post some pictures, that sounds like more of a image analysis problem. 20X might also be challenging with truly thin, elongated nuclei. Even more challenging if the Hamamatsu defaults to saving with JPEG compression (bad for analysis, great for file size). You can both classify regions and cellular populations, so you can subdivide your sample into ""tumor"" and ""stroma"" annotations first, and then perform positive cell detection within each of those (or however many classifications you want). Another option is using derived classes, so that you would first classify by tumor and stroma, then classify the cells as positive or negative within those classifications: https://github.com/qupath/qupath/wiki/Object-classifications<https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fwiki%2FObject-classifications&data=01%7C01%7Clucia.montorsi%40kcl.ac.uk%7Cc0fb04b4d26e44a6d0fa08d63529246a%7C8370cf1416f34c16b83c724071654356%7C0&sdata=UQryuEzaf5zSNRtDGv8hrkp%2FfCUaV5EV%2FABLyh8vxoY%3D&reserved=0>. Either way, you can then ignore the stromal positive cells in the data processing (merge populations) however you want, or create a step that re-classifies any Stroma-positive to Stroma-negative, etc. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://emea01.safelin",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/231#issuecomment-431292156:1156,perform,perform,1156,https://qupath.github.io,https://github.com/qupath/qupath/issues/231#issuecomment-431292156,1,['perform'],['perform']
Performance,"ith an image when it is first added to a project*. This only happens the first time the data file is saved.; * The `ImageServerMetadata` is updated as soon as an image is opened in a project to ensure that the name specified in the project matches that in the server metadata. This triggers the server to be loaded if; * The `ImageServerMetadata` isn't available, or; * The `ImageServerMetadata` is available, but contains the wrong name (e.g. the name was changed in a project, but then the data file wasn't saved afterwards); * *Run for project* will always force the `ImageServer` to be loaded, because it will always save the data - and this act of saving requires the `ImageServer`. So you can only get advantages if you avoid *Run for project*, e.g. by using *Run for project (without save)* instead.; * We can't rely on not saving if there have been no changes, because the script editor now automatically fires a hierarchy change after completion. This means QuPath *always* thinks that the script may have changed the `ImageData`, so `ImageData.isChanged()` returns true. We didn't used to do this, but then we had to keep telling users to add `fireHierarchyUpdate()` at the end of many otherwise simple-looking scripts, and that was a pain for everyone. This basically means that lazy-loading only works if the data for an image has been saved at least once, and the user hasn't messed around too much with image names within their project. The 'easy' way to trigger an image to be saved once is to do a 'Run for project' script - even if the script doesn't do anything. This should be enough to prompt the `ImageServerMetadata` to become embedded within the project. Although it should also usually happen in practice anyway, just through working with the images for some kind of annotation or analysis, so the other solution is... just don't worry about it. If this works properly, you should end up with lazy-loading a lot of the time - just not necessarily quite as often as you'd want.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1489#issuecomment-2273821037:1641,load,loading,1641,https://qupath.github.io,https://github.com/qupath/qupath/pull/1489#issuecomment-2273821037,2,['load'],['loading']
Performance,"itor.java:1033); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by No double parameter with key 'haralickMin' at qupath.lib.plugins.parameters.ParameterList.getDoubleParameterValue(ParameterList.java:386); at qupath.lib.plugins.parameters.ParameterList.getDoubleParameterValue(ParameterList.java:427); at qupath.lib.algorithms.IntensityFeaturesPlugin$HaralickFeaturesComp.updateFeatures(IntensityFeaturesPlugin.java:1056); at qupath.lib.algorithms.IntensityFeaturesPlugin.processObject(IntensityFeaturesPlugin.java:628); at qupath.lib.algorithms.IntensityFeaturesPlugin$IntensityFeatureRunnable.run(IntensityFeaturesPlugin.java:454); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); INFO: Processing complete in 0.01 seconds; INFO: ; qupath.lib.algorithms.IntensityFeaturesPlugin {""pixelSizeMicrons"": 2.0, ""region"": ""ROI"", ""tileSizeMicrons"": 25.0, ""colorOD"": true, ""colorStain1"": true, ""colorStain2"": true, ""colorStain3"": false, ""colorRed"": false, ""colorGreen"": false, ""colorBlue"": false, ""colorHue"": false, ""colorSaturation"": false, ""colorBrightness"": false, ""doMean"": false, ""doStdDev"": false, ""doMinMax"": false, ""doMedian"": false, ""doHaralick"": true, ""haralickDistance"": 1, ""haralickBins"": 32}; INFO: Result: true; ```",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/358:3056,concurren,concurrent,3056,https://qupath.github.io,https://github.com/qupath/qupath/issues/358,5,['concurren'],['concurrent']
Performance,"l context**. Stack trace; ```; ERROR: unable to create native thread: possibly out of memory or process/resource limits reached in thread_leak_repro.groovy at line number 25; java.base/java.lang.Thread.start0(Native Method); java.base/java.lang.Thread.start(Unknown Source); java.base/java.lang.System$2.start(Unknown Source); java.base/jdk.internal.vm.SharedThreadContainer.start(Unknown Source); java.base/java.util.concurrent.ThreadPoolExecutor.addWorker(Unknown Source); java.base/java.util.concurrent.ThreadPoolExecutor.execute(Unknown Source); qupath.lib.gui.images.stores.AbstractImageRegionStore.requestImageTile(AbstractImageRegionStore.java:374); qupath.lib.gui.images.stores.DefaultImageRegionStore.paintRegionCompletely(DefaultImageRegionStore.java:104); qupath.lib.gui.images.servers.RenderedImageServer.readTile(RenderedImageServer.java:363); qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); java.base/java.util.concurrent.FutureTask.run(Unknown Source); qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); qupath.lib.images.writers.AbstractImageIOWriter.writeImage(AbstractImageIOWriter.java:82); qupath.lib.images.writers.PngWriter.writeImage(PngWriter.java:42); qupath.lib.images.writers.AbstractImageIOWriter.writeImage(AbstractImageIOWriter.java:96); qupath.lib.images.writers.PngWriter.writeImage(PngWriter.java:42); qupath.lib.images.writers.ImageWriterTools.writeImage(ImageWriterTools.java:163); qupath.lib.scripting.QP.writeImage(QP.java:3365); ```. `jstack -l` lists 4096 threads of the following kind; ```; ""region-store-1"" #4103 [2125611] prio=5 os_prio=31 cpu=0.27ms elapsed=19.36s tid=0x000000031cc05800 nid=2125611 waiting on condition [0",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1561:2922,concurren,concurrent,2922,https://qupath.github.io,https://github.com/qupath/qupath/issues/1561,1,['concurren'],['concurrent']
Performance,lambda$getEngineOnline$0(PytorchManager.java:28); 	at qupath.ext.instanseg.core.PytorchManager.callWithTempProperty(PytorchManager.java:114); 	at qupath.ext.instanseg.core.PytorchManager.callOnline(PytorchManager.java:106); 	at qupath.ext.instanseg.core.PytorchManager.getEngineOnline(PytorchManager.java:28); 	at qupath.ext.instanseg.ui.InstanSegController.downloadPyTorch(InstanSegController.java:826); 	at qupath.ext.instanseg.ui.InstanSegController.ensurePyTorchAvailable(InstanSegController.java:815); 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(Unknown Source); 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.exec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source); Caused by: java.lang.UnsatisfiedLinkError: C:\Users\username\.djl.ai\pytorch\2.3.1-cu121-win-x86_64\cudnn_cnn_infer64_8.dll: The specified procedure could not be found; 	at java.base/jdk.internal.loader.NativeLibraries.load(Native Method); 	at java.base/jdk.internal.loader.NativeLibraries$NativeLibraryImpl.open(Unknown Source); 	at java.base/jdk.internal.loader.NativeLibraries.loadLibrary(Unknown Source); 	at java.base/jdk.internal.loader.NativeLibraries.loadLibrary(Unknown Source); 	at java.base/java.lang.ClassLoader.loadLibrary(Unknown Source); 	at java.base/java.lang.Runtime.load0(Unknown Source); 	at java.base/java.lang.System.load(Unknown Source); 	at ai.djl.pytorch.jni.LibUtils.loadNativeLibrary(LibUtils.java:379); 	at ai.djl.pytorch.jni.LibUtils.loadLibTorch(LibUtils.java:176); 	at ai.djl.pytorch.jni.LibUtils.loadLibrary(LibUtils.java:82); 	at ai.djl.pytorch.engine.PtEngine.newInstance(PtEngine.java:53); 	... 15 more`,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1636:1617,concurren,concurrent,1617,https://qupath.github.io,https://github.com/qupath/qupath/issues/1636,13,"['concurren', 'load']","['concurrent', 'load', 'loadLibTorch', 'loadLibrary', 'loadNativeLibrary', 'loader']"
Performance,"le file = new File(dirOutput, name); ImageWriterTools.writeImageRegionWithOverlay(imageData, overlayOptions, request, file.getAbsolutePath()). // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); }; catch (Exception e) {; // Check if we have had a sufficient number of errors to just give up; nErrors++;; if (nErrors > maxErrors) {; println(""Maximum number of errors exceeded - aborting...""); return; }; e.printStackTrace(); }; }; }; }. ```. The error is on line 91 when I try to access the ImagePlusServer server, which obviously doesn't exist anymore. . ```; ERROR: Error at line 7: No such property: server for class: Script48. ERROR: Script error; at org.codehaus.groovy.runtime.ScriptBytecodeAdapter.unwrap(ScriptBytecodeAdapter.java:65); at org.codehaus.groovy.runtime.callsite.PogoGetPropertySite.getProperty(PogoGetPropertySite.java:51); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callGroovyObjectGetProperty(AbstractCallSite.java:309); at Script48.run(Script48.groovy:8); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:317); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:155); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:767); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:697); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.gui.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1034); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); ```. Thanks!",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/309:5434,concurren,concurrent,5434,https://qupath.github.io,https://github.com/qupath/qupath/issues/309,4,['concurren'],['concurrent']
Performance,"led:; Script7.groovy: 25: Unknown type: IMPORT at line: 25 column: 1. File: Script7.groovy @ line 25, column 1.; import qupath.imagej.helpers.IJTools; ^. 1 error. ERROR: Script error; at org.codehaus.groovy.control.ErrorCollector.failIfErrors(ErrorCollector.java:311); at org.codehaus.groovy.control.CompilationUnit.applyToSourceUnits(CompilationUnit.java:980); at org.codehaus.groovy.control.CompilationUnit.doPhaseOperation(CompilationUnit.java:647); at org.codehaus.groovy.control.CompilationUnit.processPhaseOperations(CompilationUnit.java:623); at org.codehaus.groovy.control.CompilationUnit.compile(CompilationUnit.java:600); at groovy.lang.GroovyClassLoader.doParseClass(GroovyClassLoader.java:390); at groovy.lang.GroovyClassLoader.access$300(GroovyClassLoader.java:89); at groovy.lang.GroovyClassLoader$5.provide(GroovyClassLoader.java:330); at groovy.lang.GroovyClassLoader$5.provide(GroovyClassLoader.java:327); at org.codehaus.groovy.runtime.memoize.ConcurrentCommonCache.getAndPut(ConcurrentCommonCache.java:147); at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:325); at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:309); at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:251); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.getScriptClass(GroovyScriptEngineImpl.java:331); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:153); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:766); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:696); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:676); at qupath.lib.gui.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1033); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Thre",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/282#issuecomment-473504477:1321,Concurren,ConcurrentCommonCache,1321,https://qupath.github.io,https://github.com/qupath/qupath/issues/282#issuecomment-473504477,1,['Concurren'],['ConcurrentCommonCache']
Performance,lizer.read(FieldSerializer.java:528) ; 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:679) ; 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106) ; 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:528) ; 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:679) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:378) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:289) ; 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:679) ; 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106) ; 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:528) ; 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:657) ; 	at loci.formats.Memoizer$KryoDeser.loadReader(Memoizer.java:163) ; 	at loci.formats.Memoizer.loadMemo(Memoizer.java:888) ; 	at loci.formats.Memoizer.setId(Memoizer.java:666) ; 	at qupath.lib.images.servers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1141) ; 	at qupath.lib.images.servers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1083) ; 	at qupath.lib.images.servers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.getPrimaryReader(BioFormatsImageServer.java:997) ; 	at qupath.lib.images.servers.bioformats.BioFormatsImageServer.<init>(BioFormatsImageServer.java:216) ; 	at qupath.lib.images.servers.bioformats.BioFormatsImageServer.<init>(BioFormatsImageServer.java:179) ; 	at qupath.lib.images.servers.bioformats.BioFormatsServerBuilder.buildServer(BioFormatsServerBuilder.java:53) ; 	at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:166) ; 	at qupath.QuPath.main(QuPath.java:150) ; 16:23:07.721 [main] [WARN ] loci.formats.Memoizer - file delet,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/287:4509,load,loadMemo,4509,https://qupath.github.io,https://github.com/qupath/qupath/issues/287,1,['load'],['loadMemo']
Performance,lizer.read(FieldSerializer.java:528) ; 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:679) ; 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106) ; 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:528) ; 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:679) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:378) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:289) ; 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:679) ; 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106) ; 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:528) ; 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:657) ; 	at loci.formats.Memoizer$KryoDeser.loadReader(Memoizer.java:163) ; 	at loci.formats.Memoizer.loadMemo(Memoizer.java:888) ; 	at loci.formats.Memoizer.setId(Memoizer.java:666) ; 	at qupath.lib.images.servers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1141) ; 	at qupath.lib.images.servers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1083) ; 	at qupath.lib.images.servers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.getPrimaryReader(BioFormatsImageServer.java:997) ; 	at qupath.lib.images.servers.bioformats.BioFormatsImageServer.<init>(BioFormatsImageServer.java:216) ; 	at qupath.lib.images.servers.bioformats.BioFormatsImageServer.<init>(BioFormatsImageServer.java:179) ; 	at qupath.lib.images.servers.bioformats.BioFormatsServerBuilder.buildServer(BioFormatsServerBuilder.java:53) ; 	at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:166) ; 	at qupath.QuPath.main(QuPath.java:150) ; 23:18:19.945 [main] [WARN ] loci.formats.Memoizer - file delet,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/280#issuecomment-472915452:4281,load,loadMemo,4281,https://qupath.github.io,https://github.com/qupath/qupath/issues/280#issuecomment-472915452,1,['load'],['loadMemo']
Performance,lizer.read(FieldSerializer.java:528) ; 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:679) ; 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106) ; 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:528) ; 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:679) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:378) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:289) ; 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:679) ; 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106) ; 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:528) ; 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:657) ; 	at loci.formats.Memoizer$KryoDeser.loadReader(Memoizer.java:163) ; 	at loci.formats.Memoizer.loadMemo(Memoizer.java:888) ; 	at loci.formats.Memoizer.setId(Memoizer.java:666) ; 	at qupath.lib.images.servers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1141) ; 	at qupath.lib.images.servers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1083) ; 	at qupath.lib.images.servers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.getReaderForThread(BioFormatsImageServer.java:966) ; 	at qupath.lib.images.servers.bioformats.BioFormatsImageServer.getBufferedImageReader(BioFormatsImageServer.java:548) ; 	at qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:579) ; 	at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:61) ; 	at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:131) ; 	at qupath.lib.images.servers.AbstractTileableImageServer.readBuffere,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/287:9528,load,loadMemo,9528,https://qupath.github.io,https://github.com/qupath/qupath/issues/287,1,['load'],['loadMemo']
Performance,"ll trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side after already generating the polygon, using [`ShapeSimplifier.simplifyPolygon(PolygonROI polygon, final double altitudeThreshold)`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core/src/main/java/qupath/lib/roi/experimental/ShapeSimplifier.java#L145). Despite all that, I haven't tried doing this exact conversion before and my guess is that you might have a problem with having really really huge text files. If that's the case then it could be the bottleneck... but that can be solved too if necessary.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/81#issuecomment-357045269:1555,cache,cached,1555,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269,2,"['bottleneck', 'cache']","['bottleneck', 'cached']"
Performance,llsite.AbstractCallSite.callStatic(AbstractCallSite.java:216); at Script3.run(Script3.groovy:6); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:317); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:155); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:767); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:697); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.gui.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1288); at qupath.lib.gui.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1237); at javafx.concurrent.Task$TaskCallable.call(Task.java:1425); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); Caused by Java heap space at ij.process.FloatProcessor.snapshot(FloatProcessor.java:240); at ij.process.FloatProcessor.convolve(FloatProcessor.java:1069); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.doDetection(WatershedCellDetection.java:600); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:997); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:362); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.c,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:2511,concurren,concurrent,2511,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['concurren'],['concurrent']
Performance,"lly too high. This has been particularly evident on an M1 MacBook Pro, and seems related to https://github.com/bytedeco/javacpp/issues/468 and https://github.com/bytedeco/javacpp/issues/516. The errors look like this:. ```; ERROR: Error requesting tile classification: ; java.io.IOException: java.lang.OutOfMemoryError: Physical memory usage is too high: physicalBytes (16451M) > maxPhysicalBytes (16384M); at qupath.lib.classifiers.pixel.PixelClassificationImageServer.readTile(PixelClassificationImageServer.java:314); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:184); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:238); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:56); at qupath.lib.gui.viewer.overlays.PixelClassificationOverlay.lambda$requestTile$5(PixelClassificationOverlay.java:547); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by Physical memory usage is too high: physicalBytes (16451M) > maxPhysicalBytes (16384M) at org.bytedeco.javacpp.Pointer.deallocator(Pointer.java:712); at org.bytedeco.javacpp.Pointer.init(Pointer.java:126); at org.bytedeco.opencv.opencv_core.Mat.allocate(Native Method); at org.bytedeco.opencv.opencv_core.Mat.<init>(Mat.java:241); at qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predictWithLock(OpenCVClassifiers.java:468); at qupath.opencv.ml.OpenCVClassifiers$ANNClassifierCV.predictWithLock(OpenCVClassifiers.java:1425); at qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predict(OpenCVClassifiers.java:442); at qupath.opencv.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856:1166,concurren,concurrent,1166,https://qupath.github.io,https://github.com/qupath/qupath/issues/856,1,['concurren'],['concurrent']
Performance,loading classifier error,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:0,load,loading,0,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['load'],['loading']
Performance,loads/QuPath/lib/runtime/lib/libawt.so; 7f7942bcf000-7f7942bd0000 r--p 0009d000 fd:02 10819064500 /scratch3/downloads/QuPath/lib/runtime/lib/libawt.so; 7f7942bd0000-7f7942bdb000 rw-p 0009e000 fd:02 10819064500 /scratch3/downloads/QuPath/lib/runtime/lib/libawt.so; 7f7942bdb000-7f7942d00000 rw-p 00000000 00:00 0 ; 7f7942d00000-7f7942e00000 rw-p 00000000 00:00 0 ; 7f7942e00000-7f7943100000 rw-p 00000000 00:00 0 ; 7f7943100000-7f79431f0000 rw-p 00000000 00:00 0 ; 7f79431f0000-7f7943200000 ---p 00000000 00:00 0 ; 7f7943200000-7f7943400000 rw-p 00000000 00:00 0 ; 7f794343c000-7f79434ec000 r--p 00000000 fd:03 721040943 /scratch/usr-shr/share/fonts/dejavu/DejaVuSans.ttf; 7f79434ec000-7f79434f0000 r-xp 00000000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79434f0000-7f79436ef000 ---p 00004000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79436ef000-7f79436f0000 r--p 00003000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79436f0000-7f79436f1000 rw-p 00004000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79436f1000-7f79436f6000 r-xp 00000000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79436f6000-7f79438f5000 ---p 00005000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f5000-7f79438f6000 r--p 00004000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f6000-7f79438f7000 rw-p 00005000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f7000-7f79438fa000 r-xp 00000000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f79438fa000-7f7943af9000 ---p 00003000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f7943af9000-7f7943afa000 r--p 00002000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_fo,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018:18249,cache,cache,18249,https://qupath.github.io,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018,1,['cache'],['cache']
Performance,"m, This was my; message. Can you advise please? Thank you very much, suba; Hello, I am able to load the images from the Qupath project, however, when; I double-click on the whole slide, I am getting an error message : **Unable; to build Image server: (view log below) for all the images but one that was; added recently to the project. Can anyone please suggest how to restore my; data please? Thank you, Suba; INFO: Initializing type adapters; INFO: Bio-Formats version 6.5.1; INFO: Loaded extension Bio-Formats options (Bio-Formats 6.5.1) (17 ms); INFO: Loaded extension Experimental extension (1 ms); INFO: Loaded extension ImageJ extension (44 ms); INFO: Loaded extension JPen extension (19 ms); INFO: Loaded extension Processing extension (28 ms); INFO: Loaded extension Rich script editor extension (235 ms); INFO: Loaded extension SVG export extension (1 ms); INFO: OpenSlide version 3.4.1; INFO: Starting QuPath with parameters: []; INFO: Trying to load project Z:\Kotb Lab\General\ALL INFECT and INFECT; images\INF 69 DR3 DR4 repeat for Ganesh manuscript Qupath data\dr3 gfap new; 042121\project.qpproj; INFO: Project set to Project: dr3 gfap new 042121-project; INFO: Image data set to ImageData: Brightfield (H-DAB), PR301S1 2021-04-23; 07.49.55.ndpi; WARN: Unable to open file://; undmed-files.med.und.edu/Basic%20Sciences/Kotb%20Lab/General/ALL%20INFECT%20and%20INFECT%20images/INF%2069%20DR3%20DR4%20repeat%20for%20Ganesh%20manuscript%20Qupath%20data/dr3%20gfap%20new%20042121/PR287S8%20-%202021-04-12%2009.52.58.ndpi; with OpenSlide: URI has an authority component; ERROR: Load ImageData: Unable to build ImageServer for file://; undmed-files.med.und.edu/Basic%20Sciences/Kotb%20Lab/General/ALL%20INFECT%20and%20INFECT%20images/INF%2069%20DR3%20DR4%20repeat%20for%20Ganesh%20manuscript%20Qupath%20data/dr3%20gfap%20new%20042121/PR287S8%20-%202021-04-12%2009.52.58.ndpi; (args=[]) with requested provider; qupath.lib.images.servers.openslide.OpenslideServerBuilder; ERROR: Load ImageDat",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/396#issuecomment-827610434:1025,load,load,1025,https://qupath.github.io,https://github.com/qupath/qupath/issues/396#issuecomment-827610434,1,['load'],['load']
Performance,m.GlassViewEventHandler.lambda$handleMouseEvent$2(GlassViewEventHandler.java:450); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:424); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:449); at com.sun.glass.ui.View.handleMouseEvent(View.java:557); at com.sun.glass.ui.View.notifyMouse(View.java:943); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:184); at java.base/java.lang.Thread.run(Unknown Source); Caused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: OpenCV(4.5.3) D:\a\javacpp-presets\javacpp-presets\opencv\cppbuild\windows-x86_64\opencv-4.5.3\modules\core\src\channels.cpp:141: error: (-215:Assertion failed) i1 >= 0 && j < ndsts && dst[j].depth() == depth in function 'cv::mixChannels'. at java.base/java.util.concurrent.FutureTask.report(Unknown Source); at java.base/java.util.concurrent.FutureTask.get(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:222); ... 58 common frames omitted; Caused by: java.lang.RuntimeException: OpenCV(4.5.3) D:\a\javacpp-presets\javacpp-presets\opencv\cppbuild\windows-x86_64\opencv-4.5.3\modules\core\src\channels.cpp:141: error: (-215:Assertion failed) i1 >= 0 && j < ndsts && dst[j].depth() == depth in function 'cv::mixChannels'. at org.bytedeco.opencv.global.opencv_core.mixChannels(Native Method); at qupath.opencv.tools.OpenCVTools.mergeChannels(OpenCVTools.java:413); at qupath.opencv.ops.ImageOps$Core$SplitMergeOp.transformPadded(ImageOps.java:2511); at qupath.opencv.ops.ImageOps$Core$SplitMergeOp.apply(ImageOps.java:2470); at qupath.opencv.ops.ImageOps$ChannelImageDataOp.apply(ImageOps.java:425); at qupath.opencv.ops.ImageOpServer.readTile(ImageOpServer.java:98); at qupath.lib.images.servers.AbstractTileableImageServer.lambda$getTile$0(AbstractTileableImageServer.jav,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/947:10148,concurren,concurrent,10148,https://qupath.github.io,https://github.com/qupath/qupath/issues/947,1,['concurren'],['concurrent']
Performance,"maybe the openslide-winbuild cross compiling script can be used ..... Am Mo., 18. Jan. 2021 um 10:19 Uhr schrieb Pete <notifications@github.com>:. > @kwiechen <https://github.com/kwiechen> As I understand it, MSYS2 is for; > building software on Windows. It might be handy in the future, but it won't; > solve the biggest problem that we need to somehow be able to create; > portable builds on all platforms. Currently, Windows is the least; > problematic because 'official' builds exist; Mac and Linux rely on package; > managers.; >; > Simply rebuilding from source on Mac/Linux isn't sufficient to solve the; > problem either, because of the numerous sub-dependencies that must be; > built, and also the platform-specific way in which these are subsequently; > loaded on different platforms. I can specify exactly which OpenSlide shared; > library to load, but then this results in the sub-dependencies also being; > loaded (e.g. pixman, cairo, libtiff...) and it's here that system-wide; > versions are often picked up. This is very hard (impossible?) to control; > from Java alone because the loading of sub-dependencies doesn't use the; > Java library path.; >; > I can get things to work on Windows/Linux/Mac fine, I just can't get; > things to work in a portable way. Somehow we need a streamlined process of; > building on *all* platforms that packages up all dependencies in a; > self-contained manner.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/629#issuecomment-762108942>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AEG6ZG4EB24ORI5S5CJAQYLS2P4L3ANCNFSM4S6NHNUA>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/629#issuecomment-762412806:764,load,loaded,764,https://qupath.github.io,https://github.com/qupath/qupath/issues/629#issuecomment-762412806,4,['load'],"['load', 'loaded', 'loading']"
Performance,me/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79436f0000-7f79436f1000 rw-p 00004000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79436f1000-7f79436f6000 r-xp 00000000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79436f6000-7f79438f5000 ---p 00005000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f5000-7f79438f6000 r--p 00004000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f6000-7f79438f7000 rw-p 00005000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f7000-7f79438fa000 r-xp 00000000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f79438fa000-7f7943af9000 ---p 00003000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f7943af9000-7f7943afa000 r--p 00002000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f7943afa000-7f7943afb000 rw-p 00003000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f7943afb000-7f7943aff000 ---p 00000000 00:00 0 ; 7f7943aff000-7f7943bfc000 rw-p 00000000 00:00 0 ; 7f7943bfc000-7f7943c00000 ---p 00000000 00:00 0 ; 7f7943c00000-7f7943cfd000 rw-p 00000000 00:00 0 ; 7f7943cfd000-7f7943d01000 ---p 00000000 00:00 0 ; 7f7943d01000-7f7943dfe000 rw-p 00000000 00:00 0 ; 7f7943dfe000-7f7943dff000 r-xp 00000000 fd:02 10819064523 /scratch3/downloads/QuPath/lib/runtime/lib/libprefs.so; 7f7943dff000-7f7943ffe000 ---p 00001000 fd:02 10819064523 /scratch3/downloads/QuPath/lib/runtime/lib/libprefs.so; 7f7943ffe000-7f7943fff000 r--p 00000000 fd:02 10819064523 /scratch3/downloads/QuPath/lib/runtime/lib/libprefs.so; 7f7943fff000-7f7944000000 rw-p 00001000 fd:02 10819064523 /scratch3/downloads/QuPath/lib/runtime/lib/libprefs.so; 7f7944000000-7f7944021000 rw-p 00000000 00:00 0 ; 7f7944021000-7f7948000000 ---p 00000000 00:00 0,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018:19225,cache,cache,19225,https://qupath.github.io,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018,1,['cache'],['cache']
Performance,"meterDialogWrapper$1.run(ParameterDialogWrapper.java:177); 	at java.base/java.lang.Thread.run(Unknown Source); Caused by: java.util.ConcurrentModificationException; 	at java.base/java.util.ArrayList$Itr.checkForComodification(Unknown Source); 	at java.base/java.util.ArrayList$Itr.next(Unknown Source); 	at java.base/java.util.Collections$UnmodifiableCollection$1.next(Unknown Source); 	at java.base/java.util.AbstractCollection.addAll(Unknown Source); 	at qupath.lib.objects.PathObjectTools.getAvailableFeatures(PathObjectTools.java:2026); 	at qupath.opencv.features.DelaunayTriangulation.<init>(DelaunayTriangulation.java:86); 	at qupath.opencv.features.DelaunayClusteringPlugin$DelaunayRunnable.run(DelaunayClusteringPlugin.java:208); 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); 	at java.base/java.util.concurrent.FutureTask.run(Unknown Source); 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); 	at java.base/java.util.concurrent.FutureTask.run(Unknown Source); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); 	... 1 more; ```. 2. If I repeat with **the outer rectangle selected**, then I *do* see connections.; This is because the triangulation uses *all descendant detections below the rectangle, based on the object hierarchy*. ![2-rectangle](https://github.com/user-attachments/assets/21b82d18-ce97-45c3-9644-7abdf85ab007). 3. If I repeat with **the outer ellipse selected**, I get *no connections at all*.; This is because the ellipse isn't set to be a parent of any of the other objects - this would change if I called *Resolve hierarchy* first. ![3-ellipse](https://github.com/user-attachments/assets/3c39bea5-9a9c-4ae3-bcc9-7ece1e8bae9c). 4. If I repeat with **the inner rectangles selected**, I get connections that don't cross *and I don't get any exception*.; This is because each cell is only handl",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1590:2638,concurren,concurrent,2638,https://qupath.github.io,https://github.com/qupath/qupath/issues/1590,1,['concurren'],['concurrent']
Performance,"more importantly, their sub-dependencies - are handled on different platforms. Bug reports such as; * https://github.com/qupath/qupath/issues/355; * https://github.com/qupath/qupath/issues/628; * https://github.com/qupath/qupath/issues/627. along with breakages caused by `jpackage` updates (https://github.com/qupath/qupath/issues/615) show that the (largely manual) process initially used to try to package up the dependencies hasn't worked. For these reasons, **we need a new and maintainable approach to include OpenSlide in QuPath in the future, or else drop support entirely**. Alas, I'm sadly one of those developers who is quite helpless when attempting to build any native libraries with even moderate complexity... spoiled by Java and Python, I haven't been able to figure out a solution. Hence this issue and cry for help. The biggest problem is getting a truly portable way to build OpenSlide on each platform. If we have that, we can potentially use JNI directly or JavaCPP (https://github.com/bytedeco/javacpp) / Gradle JavaCPP (https://github.com/bytedeco/gradle-javacpp). *Ideally* all dependencies would be packaged into a single .jar file and accessed either with JavaCPP / [native-lib-loader](https://github.com/scijava/native-lib-loader). An alternative might be to try outsourcing OpenSlide support on macOS and Linux, *requiring* installation with a package manager (?) and only providing the 'official' pre-built binaries on Windows. In considering this, it is worth asking whether we should be linking to OpenSlide only anyway.; **libvips** (https://github.com/libvips/libvips) is a much more extensive library, is actively maintained, and can also be built with OpenSlide support. Among its many features, libvips has the ability to write pyramidal images extremely fast.... which is a feature we would very much like to have, supplementing our ability to write [pyramidal OME-TIFFs using Bio-Formats](https://qupath.readthedocs.io/en/latest/docs/advanced/command_line.html).",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/629:2152,load,loader,2152,https://qupath.github.io,https://github.com/qupath/qupath/issues/629,2,['load'],['loader']
Performance,"n.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$300(GlassViewEventHandler.java:388); 	at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:387); 	at com.sun.glass.ui.View.handleMouseEvent(View.java:555); 	at com.sun.glass.ui.View.notifyMouse(View.java:937); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:40:13.846 [JavaFX Application Thread] [INFO ] q.l.i.servers.ImageServerProvider - Returning server: ImageJ server for /home/bl/Documents/IMG_5_11_sq.png; 02:40:14.153 [JavaFX Application Thread] [INFO ] qupath.lib.gui.viewer.QuPathViewer - Image data set to ImageData: Fluorescence, IMG_5_11_sq; 02:40:22.852 [JavaFX Application Thread] [INFO ] q.lib.scripting.DefaultScriptEditor - Loading script file /home/bl/ip/QuPath/app/TestJep.groovy; 02:40:28.109 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean red (from Java): 86.81525; 02:40:28.121 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean green (from Java): 72.492275; 02:40:28.124 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean blue (from Java): 68.141675; 02:40:28.624 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Started JEP: jep.Jep@6bc4b2e2; ImportError: numpy.core.multiarray failed to import; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f930536d03f, pid=27357, tid=0x00007f932091e700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-2ubuntu0.16.04.2-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [jep.so+0x1a03f] convert_jndarray_pyndarray+0x5bf; #; # Failed to write cor",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/27#issuecomment-262870405:8835,Load,Loading,8835,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405,1,['Load'],['Loading']
Performance,n.so.4; 7f7940a95000-7f7940ad4000 r-xp 00000000 00:2f 2345794460 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libquadmath.so.0; 7f7940ad4000-7f7940cd3000 ---p 0003f000 00:2f 2345794460 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libquadmath.so.0; 7f7940cd3000-7f7940cd4000 rw-p 0003e000 00:2f 2345794460 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libquadmath.so.0; 7f7940cd4000-7f7940cea000 r-xp 00000000 00:2f 2345794458 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libgcc_s.so.1; 7f7940cea000-7f7940ee9000 ---p 00016000 00:2f 2345794458 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libgcc_s.so.1; 7f7940ee9000-7f7940eea000 rw-p 00015000 00:2f 2345794458 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libgcc_s.so.1; 7f7940eea000-7f7940fd3000 r-xp 00000000 fd:00 100675410 /usr/lib64/libstdc++.so.6.0.19; 7f7940fd3000-7f79411d3000 ---p 000e9000 fd:00 100675410 /usr/lib64/libstdc++.so.6.0.19; 7f79411d3000-7f79411db000 r--p 000e9000 fd:00 100675410 /usr/lib64/libstdc++.so.6.0.19; 7f79411db000-7f79411dd000 rw-p 000f1000 fd:00 100675410 /usr/lib64/libstdc++.so.6.0.19; 7f79411dd000-7f79411f2000 rw-p 00000000 00:00 0 ; 7f79411f2000-7f79411ff000 r-xp 00000000 00:2f 2325151014 /home/grad3/jalal/.javacpp/cache/javacpp-1.5.6-linux-x86_64.jar/org/bytedeco/javacpp/linux-x86_64/libjnijavacpp.so; 7f79411ff000-7f79413fe000 ---p 0000d000 00:2f 2325151014 /home/grad3/jalal/.javacpp/cache/javacpp-1.5.6-linux-x86_64.jar/org/bytedeco/javacpp/linux-x86_64/libjnijavacpp.so; 7f79413fe000-7f79413ff000 r--p 0000c000 00:2f 2325151014 /home/grad3/jalal/.javacpp/cache/javacpp-1.5.6-linux-x86_64.jar/org/bytedeco/javacpp/linux-x86_64/libjnij,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018:13947,cache,cache,13947,https://qupath.github.io,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018,1,['cache'],['cache']
Performance,"nCVClassifiers$AbstractOpenCVClassifierML.predict(OpenCVClassifiers.java:442); at qupath.opencv.ops.ImageOps$ML$StatModelOp.apply(ImageOps.java:2812); at qupath.opencv.ops.ImageOps$Core$SequentialMultiOp.apply(ImageOps.java:2294); at qupath.opencv.ops.ImageOps$ChannelImageDataOp.apply(ImageOps.java:424); at qupath.opencv.ml.pixel.OpenCVPixelClassifier.applyClassification(OpenCVPixelClassifier.java:104); at qupath.lib.classifiers.pixel.PixelClassificationImageServer.readTile(PixelClassificationImageServer.java:299); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:184); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:238); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:56); at qupath.lib.gui.viewer.overlays.PixelClassificationOverlay.lambda$requestTile$5(PixelClassificationOverlay.java:547); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); ```. **To Reproduce**; Steps to reproduce the behavior:; 1. Open OS-1.ndpi on an M1 Mac, set to have a maximum of 4GB RAM for QuPath; 2. Start training a pixel classifier (default resolution and settings); 3. Zoom out to force preview classification across the full image; 4. Open the log & await the error; * If no error appears, adjust training annotations if needed to create a new classifier (it usually doesn't take long); 5. Check Activity Monitor to confirm that QuPath does not seem to be using a particularly large amount of memory. **Expected behavior**; Pixel classification continues without error for as long as its real memory use remains reasonable. **De",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856:3071,concurren,concurrent,3071,https://qupath.github.io,https://github.com/qupath/qupath/issues/856,1,['concurren'],['concurrent']
Performance,nStains$1.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:206); at Script30.run(Script30.groovy:10); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ERROR: Error running plugin: java.lang.NullPointerException; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.scripting.QPEx.runPlugin(QPEx.java:266); at qupath.lib.scripting.QPEx.runPlugin(QPEx.java:286); at qupath.lib.scripting.QPEx$runPlugin.callStatic(Unknown,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:8590,concurren,concurrent,8590,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['concurren'],['concurrent']
Performance,nStains$1.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:206); at Script30.run(Script30.groovy:10); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ERROR: QuPath exception; at com.sun.glass.ui.Application.checkEventThread(Application.java:443); at com.sun.glass.ui.View.getNativeView(View.java:449); at com.sun.glass.ui.win.WinAccessible.get_HostRawElementProvider(WinAccessible.java:672); at com.sun.glass.ui.win.WinAccessible.UiaRaiseAutomationEvent(Native Method); at com.sun.glass.ui.win.WinAccessible.sendNotification(WinAccessible.java:287); at javafx.scene.Node.notifyAccessibleAttributeChanged(Node.java:9604); at javafx.scene.control.TableView$TableViewSelectionModel.focus(TableView.java:2003); at javafx.scene.control.TableView$TableViewArrayListSelectionModel.updateDefaultSelection(TableView.java:2930); at ,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:5128,concurren,concurrent,5128,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['concurren'],['concurrent']
Performance,"ncurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); Caused by Java heap space at ij.process.FloatProcessor.snapshot(FloatProcessor.java:240); at ij.process.FloatProcessor.convolve(FloatProcessor.java:1069); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.doDetection(WatershedCellDetection.java:600); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:997); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:362); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.cells.WatershedCellDetection {""detectionImageFluorescence"": 1, ""requestedPixelSizeMicrons"": 0.1, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 0.9, ""minAreaMicrons"": 6.0, ""maxAreaMicrons"": 150.0, ""threshold"": 2000.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 3.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Training size: org.bytedeco.javacpp.opencv_core$Size[address=0x608000811620,position=0,limit=1,capacity=1,deallocator=org.bytedeco.javacpp.Pointer$NativeDeallocator[ownerAddress=0x608000811620,deallocatorAddress=0x13aaec9c0]]; IN",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:3673,concurren,concurrent,3673,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['concurren'],['concurrent']
Performance,"ncy of `MeasurementList`... if only this was permitted by Java. In practice, `Map<String, Double>` is likely to give adequate performance in Groovy - as long as the values are stored as primitives for efficiency in Java. In fact, to maintain compatibility we could initially implement an `AbstractMap` that wraps around an existing `MeasurementList` - with the latter still used internally. We'd need a method added to `PathObject`. ```java; public Map<String, Double> getMeasurements();; ```. This would help by:. * Providing a standard API, which explicitly doesn't permit duplicate keys; * Fitting well with GeoJSON export; * Permitting `MeasurementList` to be deprecated; * Making scripting a lot more intuitive... and almost pythonic. The last one is the biggest motivating factor, since we can then immediate benefit from some extra Groovy goodness. For example, the following script works:. ```groovy; def allCells = getCellObjects(). // Get an individual measurement for the first cell; def cell = allCells[0]; println cell.measurements['Nucleus: Area']. // Get all the measurement names, values or both; println cell.measurements.keySet(); println cell.measurements.values(); println cell.measurements.entrySet(). // Get all the measurements with a specified name for *all* cells; println allCells.measurements['Nucleus: Area'].sum(). // Get the mean of all the measurements with a specified name for *all* cells; println allCells.measurements['Nucleus: Area'].average(); ```. ### Describe alternatives you've considered. Alternatives include:. * Keep `MeasurementList`, but modify the class; * Use an existing `Map` implementation, either from Java itself or a library. Either way, it's important to maintain serialisation compatibility and good efficiency for large numbers of objects. ### Additional context. I've prototyped this by subclassing `AbstractMap` and confirmed that the second Groovy script works. The tricky thing is likely to be handling mutability and concurrency properly.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1085:4050,concurren,concurrency,4050,https://qupath.github.io,https://github.com/qupath/qupath/issues/1085,1,['concurren'],['concurrency']
Performance,"ned on the binary file found in tar of the QuPath results in this other error:. ```; drwxrwxrwt. 62 root root 20K Apr 11 18:07 ..; -rw-r--r--. 1 jalal cs-grad 152M Apr 11 18:10 gradle-7.4.2-all.zip; drwxr-xr-x. 8 jalal cs-grad 4.0K Apr 11 19:16 .; -rw-r--r--. 1 jalal cs-grad 6.4K Apr 11 19:16 EGFR SSM TCGA LUAD.csv; [jalal@goku downloads]$ cd QuPath/; [jalal@goku QuPath]$ ls; total 4.0K; drwxr-xr-x. 4 jalal cs-grad 66 Jan 17 03:51 lib; drwxr-xr-x. 2 jalal cs-grad 49 Jan 17 03:51 bin; drwxr-xr-x. 4 jalal cs-grad 40 Jan 17 03:51 .; drwxr-xr-x. 8 jalal cs-grad 4.0K Apr 11 19:16 ..; [jalal@goku QuPath]$ cd bin/; [jalal@goku bin]$ JAVA_TOOL_OPTIONS=-Dorg.bytedeco.javacpp.nopointergc=true ./QuPath; Picked up JAVA_TOOL_OPTIONS: -Dorg.bytedeco.javacpp.nopointergc=true; OpenJDK 64-Bit Server VM warning: Option --illegal-access is deprecated and will be removed in a future release.; Apr 11, 2022 8:47:07 PM com.sun.javafx.application.PlatformImpl startup; WARNING: Unsupported JavaFX configuration: classes were loaded from 'unnamed module @60975100'; 20:47:08.384 [JavaFX Application Thread] [INFO ] qupath.lib.common.ThreadTools - Setting parallelism to 11; 20:47:08.673 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - QuPath build: Version: 0.3.2; Build time: 2022-01-17, 08:49; Latest commit tag: '71884c6'; 20:47:08.674 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Setting tile cache size to 8024.00 MB (25.0% max memory). (QuPath:8487): Gdk-WARNING **: 20:47:09.200: XSetErrorHandler() called with a GDK error trap pushed. Don't do that.; 20:47:09.626 [JavaFX Application Thread] [INFO ] qupath.lib.scripting.QP - Initializing type adapters; *** Error in `./QuPath': free(): invalid pointer: 0x00007f79411f0c80 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x81329)[0x7f82287f5329]; /lib64/libstdc++.so.6(_ZNSt6locale5_Impl16_M_install_facetEPKNS_2idEPKNS_5facetE+0x142)[0x7f7940f5a192]; /lib64/libstdc++.so.6(_ZNSt6locale5_ImplC1Em+0x1e3)[0x7f7940f5a5",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018:1161,load,loaded,1161,https://qupath.github.io,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018,1,['load'],['loaded']
Performance,ngine(PtEngineProvider.java:41); 	at ai.djl.engine.Engine.getEngine(Engine.java:190); 	at qupath.ext.instanseg.core.PytorchManager.lambda$getEngineOnline$0(PytorchManager.java:28); 	at qupath.ext.instanseg.core.PytorchManager.callWithTempProperty(PytorchManager.java:114); 	at qupath.ext.instanseg.core.PytorchManager.callOnline(PytorchManager.java:106); 	at qupath.ext.instanseg.core.PytorchManager.getEngineOnline(PytorchManager.java:28); 	at qupath.ext.instanseg.ui.InstanSegController.downloadPyTorch(InstanSegController.java:826); 	at qupath.ext.instanseg.ui.InstanSegController.ensurePyTorchAvailable(InstanSegController.java:815); 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(Unknown Source); 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.exec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source); Caused by: java.lang.UnsatisfiedLinkError: C:\Users\username\.djl.ai\pytorch\2.3.1-cu121-win-x86_64\cudnn_cnn_infer64_8.dll: The specified procedure could not be found; 	at java.base/jdk.internal.loader.NativeLibraries.load(Native Method); 	at java.base/jdk.internal.loader.NativeLibraries$NativeLibraryImpl.open(Unknown Source); 	at java.base/jdk.internal.loader.NativeLibraries.loadLibrary(Unknown Source); 	at java.base/jdk.internal.loader.NativeLibraries.loadLibrary(Unknown Source); 	at java.base/java.lang.ClassLoader.loadLibrary(Unknown Source); 	at java.base/java.lang.Runtime.load0(Unknown Source); 	at java.base/java.lang.System.load(Unknown Source); 	at ai.djl.pytorch.jni.LibUtils.loadNativeLibrary(LibUtils.java:379); 	at ai.djl.pytorch.jni.LibUtils.loadLibTorch(LibUtils.java:176); 	at ai.djl.p,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1636:1472,concurren,concurrent,1472,https://qupath.github.io,https://github.com/qupath/qupath/issues/1636,1,['concurren'],['concurrent']
Performance,"ngleton, i.e. it exists only once. This means that requesting the parent class for `Tumor: Positive` and `Tumor: Negative` should always return the exact same classification object, and that should be identical to what is returned by `QP.getPathClass('Tumor')`. The issue is that whenever a derived classification is *reloaded* in QuPath v0.4.x, a necessary check is missed and this makes it possible for the parent classification of `Tumor: Positive` and `Tumor: Negative` to *not* be identical to the result of `QP.getPathClass('Tumor')`. This could potentially cause confusion when attempting to count objects that share the same classification. **To Reproduce**; The bug is hard to reproduce, and I don't know of any way to reproduce it within a single QuPath session. It requires data to be saved, and then loaded into a new QuPath session (i.e. after closing QuPath and reopening it, or running QuPath on a different computer). Steps to reproduce the behavior:; 1. Perform a workflow that creates derived classifications, e.g. [positive tumor cell classification](https://qupath.readthedocs.io/en/0.4/docs/tutorials/cell_classification.html); 2. Save the data, restart QuPath, reload the data; 3. Run a script such as the following to count the objects with a specified base classification; ```groovy; println getCellObjects().count {; it.getPathClass().getBaseClass() === getPathClass('Tumor')}; ```; 4. Check that the printed count is 0, even if objects can be found with the specified base classification in the image. **Expected behavior**; Classifications should always be singletons. Given a derived classification, requesting the parent classification should always give the same result as if the parent was created separately. **Screenshots**; The screenshot below shows the issue. According to the measurement table, there should be 54700 cells with the base classification `Tumor` - but the script prints 0. <img width=""914"" alt=""Screenshot 2023-08-30 at 10 11 46"" src=""https://github",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1306:2220,Perform,Perform,2220,https://qupath.github.io,https://github.com/qupath/qupath/issues/1306,1,['Perform'],['Perform']
Performance,"nnotations that are nested (in the hierarchy) or overlapping. For 'flat' annotation arrangements the behavior is *mostly ok*, except that it does rely on *hierarchy relationships* rather than *spatial relationships*.; Which is to say, it hasn't really changed since v0.1.2. **To Reproduce**; Create an arrangement of objects similar to that shown below:. ![0-orig](https://github.com/user-attachments/assets/cf1a87fc-c73a-4ac6-be24-d830f0014604). 1. If I run *Delaunay cluster features 2D* with **_all_ annotations selected**, I see triangulation lines which *do not cross the boundary between the annotations containing cells*. ![1-all selected](https://github.com/user-attachments/assets/3309e1e3-76ca-4ec7-bf5c-e0c76b8f2d96). But I **also** get a `ConcurrentModificationException`:; ```; 15:47:01.829	[Plugin thread]	ERROR	qupath.lib.plugins.AbstractTaskRunner	Error running plugin: java.util.ConcurrentModificationException	java.util.concurrent.ExecutionException: java.util.ConcurrentModificationException; 	at java.base/java.util.concurrent.FutureTask.report(Unknown Source); 	at java.base/java.util.concurrent.FutureTask.get(Unknown Source); 	at qupath.lib.plugins.AbstractTaskRunner.awaitCompletion(AbstractTaskRunner.java:147); 	at qupath.lib.plugins.AbstractTaskRunner.runTasks(AbstractTaskRunner.java:117); 	at qupath.lib.gui.TaskRunnerFX.runTasks(TaskRunnerFX.java:106); 	at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:147); 	at qupath.lib.gui.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:177); 	at java.base/java.lang.Thread.run(Unknown Source); Caused by: java.util.ConcurrentModificationException; 	at java.base/java.util.ArrayList$Itr.checkForComodification(Unknown Source); 	at java.base/java.util.ArrayList$Itr.next(Unknown Source); 	at java.base/java.util.Collections$UnmodifiableCollection$1.next(Unknown Source); 	at java.base/java.util.AbstractCollection.addAll(Unknown Source); 	at qupath.lib.objects.PathObjectTools.getAvailableFeatures(PathObj",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1590:1142,Concurren,ConcurrentModificationException,1142,https://qupath.github.io,https://github.com/qupath/qupath/issues/1590,1,['Concurren'],['ConcurrentModificationException']
Performance,o print `Loader.getLoadedLibraries()` I see:. ```; opencv_ml@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_ml.405.dylib; gfortran@.5 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgfortran.dylib; jniopencv_core : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_core.dylib; gfortran@.3 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgfortran.dylib; gfortran@.4 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgfortran.4.dylib; gcc_s@.1 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgcc_s.1.dylib; jniopencv_ml : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_ml.dylib; opencv_imgproc@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_imgproc.405.dylib; jniopencv_dnn : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_dnn.dylib; jnijavacpp : 	/Users/pbankhea/.javacpp/cache/javacpp-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/javacpp/macosx-x86_64/libjnijavacpp.dylib; jniopenblas : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libjniopenblas.dylib; quadmath@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libquadmath.0.dylib; openblas_nolapack@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980:1295,cache,cache,1295,https://qupath.github.io,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980,1,['cache'],['cache']
Performance,o.4; 7f7940a92000-7f7940a95000 rw-p 0016b000 00:2f 2345794462 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libgfortran.so.4; 7f7940a95000-7f7940ad4000 r-xp 00000000 00:2f 2345794460 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libquadmath.so.0; 7f7940ad4000-7f7940cd3000 ---p 0003f000 00:2f 2345794460 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libquadmath.so.0; 7f7940cd3000-7f7940cd4000 rw-p 0003e000 00:2f 2345794460 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libquadmath.so.0; 7f7940cd4000-7f7940cea000 r-xp 00000000 00:2f 2345794458 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libgcc_s.so.1; 7f7940cea000-7f7940ee9000 ---p 00016000 00:2f 2345794458 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libgcc_s.so.1; 7f7940ee9000-7f7940eea000 rw-p 00015000 00:2f 2345794458 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libgcc_s.so.1; 7f7940eea000-7f7940fd3000 r-xp 00000000 fd:00 100675410 /usr/lib64/libstdc++.so.6.0.19; 7f7940fd3000-7f79411d3000 ---p 000e9000 fd:00 100675410 /usr/lib64/libstdc++.so.6.0.19; 7f79411d3000-7f79411db000 r--p 000e9000 fd:00 100675410 /usr/lib64/libstdc++.so.6.0.19; 7f79411db000-7f79411dd000 rw-p 000f1000 fd:00 100675410 /usr/lib64/libstdc++.so.6.0.19; 7f79411dd000-7f79411f2000 rw-p 00000000 00:00 0 ; 7f79411f2000-7f79411ff000 r-xp 00000000 00:2f 2325151014 /home/grad3/jalal/.javacpp/cache/javacpp-1.5.6-linux-x86_64.jar/org/bytedeco/javacpp/linux-x86_64/libjnijavacpp.so; 7f79411ff000-7f79413fe000 ---p 0000d000 00:2f 2325151014 /home/grad3/jalal/.javacpp/cache/javacpp-1.5.6-linux-x86_64.jar/org/bytedeco/javacpp/linux-x86_64/l,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018:13768,cache,cache,13768,https://qupath.github.io,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018,1,['cache'],['cache']
Performance,o.serializers.FieldSerializer.read(FieldSerializer.java:543); at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:731); at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:543); at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:731); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:391); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:302); at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:731); at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:543); at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:709); at loci.formats.Memoizer$KryoDeser.loadReader(Memoizer.java:163); at loci.formats.Memoizer.loadMemo(Memoizer.java:888); at loci.formats.Memoizer.setId(Memoizer.java:666); at qupath.lib.images.servers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1360); at qupath.lib.images.servers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1265); at qupath.lib.images.servers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.getReaderForThread(BioFormatsImageServer.java:1191); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.getReader(BioFormatsImageServer.java:815); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:848); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:184); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:275); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageS,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/717:4203,load,loadMemo,4203,https://qupath.github.io,https://github.com/qupath/qupath/issues/717,1,['load'],['loadMemo']
Performance,o/opencv/macosx-x86_64/libopencv_ml.405.dylib; gfortran@.5 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgfortran.dylib; jniopencv_core : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_core.dylib; gfortran@.3 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgfortran.dylib; gfortran@.4 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgfortran.4.dylib; gcc_s@.1 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libgcc_s.1.dylib; jniopencv_ml : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_ml.dylib; opencv_imgproc@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_imgproc.405.dylib; jniopencv_dnn : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_dnn.dylib; jnijavacpp : 	/Users/pbankhea/.javacpp/cache/javacpp-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/javacpp/macosx-x86_64/libjnijavacpp.dylib; jniopenblas : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libjniopenblas.dylib; quadmath@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libquadmath.0.dylib; openblas_nolapack@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libopenblas_nolapack.0.dylib; opencv_core@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/mac,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980:1452,cache,cache,1452,https://qupath.github.io,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980,1,['cache'],['cache']
Performance,"ode to try that but I still got the following error: . ````; ERROR: Error: startup failed:; Script53.groovy: 45: unable to resolve class ImagePlusServer ; @ line 45, column 17.; ImagePlusServer server = ImagePlusServerBuilder.ensureImagePlusWholeSlideServer(serverOriginal); ^. 1 error. ERROR: Script error; at org.codehaus.groovy.control.ErrorCollector.failIfErrors(ErrorCollector.java:311); at org.codehaus.groovy.control.CompilationUnit.applyToSourceUnits(CompilationUnit.java:980); at org.codehaus.groovy.control.CompilationUnit.doPhaseOperation(CompilationUnit.java:647); at org.codehaus.groovy.control.CompilationUnit.compile(CompilationUnit.java:596); at groovy.lang.GroovyClassLoader.doParseClass(GroovyClassLoader.java:390); at groovy.lang.GroovyClassLoader.access$300(GroovyClassLoader.java:89); at groovy.lang.GroovyClassLoader$5.provide(GroovyClassLoader.java:330); at groovy.lang.GroovyClassLoader$5.provide(GroovyClassLoader.java:327); at org.codehaus.groovy.runtime.memoize.ConcurrentCommonCache.getAndPut(ConcurrentCommonCache.java:147); at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:325); at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:309); at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:251); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.getScriptClass(GroovyScriptEngineImpl.java:331); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:153); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:767); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:697); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.gui.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1034); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.bas",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/309#issuecomment-484643330:1003,Concurren,ConcurrentCommonCache,1003,https://qupath.github.io,https://github.com/qupath/qupath/issues/309#issuecomment-484643330,1,['Concurren'],['ConcurrentCommonCache']
Performance,odeTile(CellSensReader.java:1042); at loci.formats.in.CellSensReader.openBytes(CellSensReader.java:549); at loci.formats.FormatReader.openBytes(FormatReader.java:884); at loci.formats.ImageReader.openBytes(ImageReader.java:444); at loci.formats.ReaderWrapper.openBytes(ReaderWrapper.java:334); at loci.formats.ReaderWrapper.openBytes(ReaderWrapper.java:334); at loci.formats.gui.BufferedImageReader.openImage(BufferedImageReader.java:86); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:648); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:61); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:166); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:19); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:536); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:573); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:156); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:120); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:47); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:269); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); ```,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:11186,concurren,concurrent,11186,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,6,['concurren'],['concurrent']
Performance,"oject opens with the thumbnails but when I try to open an image it says 'sorry can't open file'. I copied a single image to my desktop and tried to open that but still got the error. I tried making a new project but it says unable to import file. The file types are NDPI. I need to get this work complete for my thesis which is due in a month, so please help!!!. INFO: Selected style: Modena Light; INFO: Performing update check...; INFO: Starting QuPath with parameters: []; WARN: Strange 'bits per sample' of 0; WARN: Error opening D:\Rivka\nanozoomer\Scans RL 2\Exp 5 (LI)\A3 LI 03.ndpi with ImageJ: Could not open D:\Rivka\nanozoomer\Scans RL 2\Exp 5 (LI)\A3 LI 03.ndpi with ImageJ; ERROR: Could not load OpenSlide native library; at java.lang.ClassLoader$NativeLibrary.load(Native Method); at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); at java.lang.Runtime.loadLibrary0(Runtime.java:870); at java.lang.System.loadLibrary(System.java:1122); at org.openslide.OpenSlideJNI.<clinit>(OpenSlideJNI.java:55); at org.openslide.OpenSlide.<clinit>(OpenSlide.java:53); at qupath.lib.images.servers.OpenslideImageServer.<init>(OpenslideImageServer.java:91); at qupath.lib.images.servers.OpenslideServerBuilder.buildServer(OpenslideServerBuilder.java:51); at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:115); at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2228); at qupath.lib.gui.viewer.DragDropFileImportListener.handleFileDrop(DragDropFileImportListener.java:253); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:115); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:59); at com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:238); at com.sun.javafx.event.Event",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/351:1223,load,loadLibrary,1223,https://qupath.github.io,https://github.com/qupath/qupath/issues/351,1,['load'],['loadLibrary']
Performance,"on._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:39:38.754 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Dark; 02:39:38.757 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 02:39:38.781 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 02:39:38.837 [JavaFX Application Thread] [INFO ] q.lib.gui.helpers.DisplayHelpers - QuPath Notice: This is a pre-release version of QuPath; Version: 0.0.6; Build time: 2016-11-16, 15:54; 02:40:13.093 [JavaFX Application Thread] [ERROR] q.l.i.servers.OpenslideServerBuilder - Could not load OpenSlide native library; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopenslide-jni.so: libopenslide.so.0: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at org.openslide.OpenSlideJNI.<clinit>(OpenSlideJNI.java:55); 	at org.openslide.OpenSlide.<clinit>(OpenSlide.java:53); 	at qupath.lib.images.servers.OpenslideImageServer.<init>(OpenslideImageServer.java:91); 	at qupath.lib.images.servers.OpenslideServerBuilder.buildServer(OpenslideServerBuilder.java:47); 	at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:115); 	at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2091); 	at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2015); 	at qupath.lib.gui.commands.OpenCommand.run(OpenCommand.java:51); 	at qupath.lib.gui.QuPathGUI.lambda$43(QuPathGUI.java:2960); 	at org.controlsfx.control.action.Action.handle(Action.java:419); 	at org.controlsfx.control.action.Action.handle(",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/27#issuecomment-262870405:3822,load,load,3822,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405,1,['load'],['load']
Performance,"on.groovy at line number -2. ERROR: org.bytedeco.opencv.opencv_dnn.Net.forward(Native Method); qupath.opencv.dnn.OpenCVDnn$OpenCVNetFunction.predict(OpenCVDnn.java:718); qupath.opencv.dnn.OpenCVDnn$OpenCVNetFunction.predict(OpenCVDnn.java:732); qupath.opencv.dnn.DnnModel.convertAndPredict(DnnModel.java:100); qupath.ext.stardist.StarDist2D.detectObjectsForTile(StarDist2D.java:1249); qupath.ext.stardist.StarDist2D.lambda$detectObjects$7(StarDist2D.java:934); java.base/java.util.stream.ReferencePipeline$7$1.accept(Unknown Source); java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); java.base/java.util.stream.AbstractTask.compute(Unknown Source); java.base/java.util.concurrent.CountedCompleter.exec(Unknown Source); java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source); java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source); java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source); java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source). ```. **Expected behavior**; The script should run without any error, yielding cell detections within the annotation. **Desktop (please complete the following information):**; - OS: Windows 10; - QuPath Version: 0.4.0, built from source on 2022-12-07; - StarDist Extension Version: 0.4.0 (reproducible with 0.3.2 as well). **Additional context**; The changelog of 0.4.0 points to two separate issues that were marked as resolved, which could be linked to this issue:; https://github.com/qupath/qupath/issues/841; https://github.com/qupath/qupath-extension-stardist/issues/11. Given that issue #8",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1180:3124,concurren,concurrent,3124,https://qupath.github.io,https://github.com/qupath/qupath/issues/1180,1,['concurren'],['concurrent']
Performance,"on.predict(OpenCVDnn.java:718); qupath.opencv.dnn.OpenCVDnn$OpenCVNetFunction.predict(OpenCVDnn.java:732); qupath.opencv.dnn.DnnModel.convertAndPredict(DnnModel.java:100); qupath.ext.stardist.StarDist2D.detectObjectsForTile(StarDist2D.java:1249); qupath.ext.stardist.StarDist2D.lambda$detectObjects$7(StarDist2D.java:934); java.base/java.util.stream.ReferencePipeline$7$1.accept(Unknown Source); java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); java.base/java.util.stream.AbstractTask.compute(Unknown Source); java.base/java.util.concurrent.CountedCompleter.exec(Unknown Source); java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source); java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source); java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source); java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source). ```. **Expected behavior**; The script should run without any error, yielding cell detections within the annotation. **Desktop (please complete the following information):**; - OS: Windows 10; - QuPath Version: 0.4.0, built from source on 2022-12-07; - StarDist Extension Version: 0.4.0 (reproducible with 0.3.2 as well). **Additional context**; The changelog of 0.4.0 points to two separate issues that were marked as resolved, which could be linked to this issue:; https://github.com/qupath/qupath/issues/841; https://github.com/qupath/qupath-extension-stardist/issues/11. Given that issue #841 was marked as resolved 5 days ago, it could be linked to that. Perhaps there were some changes to the API such that closing of the mode",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1180:3262,concurren,concurrent,3262,https://qupath.github.io,https://github.com/qupath/qupath/issues/1180,1,['concurren'],['concurrent']
Performance,"ong) error message. I can trim this down and get rid of the OpenCV and OpenSlide parts if it's too long. . ```; [bl@QuPath]$ ./QuPath&; [1] 27357; [bl@QuPath]$ 02:39:33.387 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; 02:39:34.264 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 624.00 MB; 02:39:37.713 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Refreshing extensions in /home/bl/ip/QuPath/extensions; 02:39:37.715 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Added extension: /home/bl/ip/QuPath/extensions/jep.jar; OpenJDK 64-Bit Server VM warning: You have loaded library /home/bl/ip/QuPath/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:120); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1092); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:633); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:418); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:59); 	at com.sun.javafx.application.LauncherImpl.lambda$l",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/27#issuecomment-262870405:1341,load,load,1341,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405,1,['load'],['load']
Performance,oppedImageServer.java:39); at qupath.lib.images.servers.SparseImageServer.readTile(SparseImageServer.java:265); at qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:863); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:902); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:216); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by null at java.base/java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(Unknown Source); at java.base/java.util.concurrent.locks.ReentrantLock.lockInterruptibly(Unknown Source); at java.base/java.util.concurrent.ArrayBlockingQueue.put(Unknown Source); at qupath.lib.images.servers.bioformats.BioFormatsImageServer$ReaderPool.openImage(BioFormatsImageServer.java:1411); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:909); at qupath.lib.images.servers,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583:2106,concurren,concurrent,2106,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583,1,['concurren'],['concurrent']
Performance,org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:206); at Script30.run(Script30.groovy:10); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ERROR: Error running plugin: java.lang.NullPointerException; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.scripting.QPEx.runPlugin(QPEx.java:266); at qupath.lib.scripting.QPEx.runPlugin(QPEx.java:286); at qupath.lib.scripting.QPEx$runPlugin.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:8727,concurren,concurrent,8727,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['concurren'],['concurrent']
Performance,org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:206); at Script30.run(Script30.groovy:10); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ERROR: QuPath exception; at com.sun.glass.ui.Application.checkEventThread(Application.java:443); at com.sun.glass.ui.View.getNativeView(View.java:449); at com.sun.glass.ui.win.WinAccessible.get_HostRawElementProvider(WinAccessible.java:672); at com.sun.glass.ui.win.WinAccessible.UiaRaiseAutomationEvent(Native Method); at com.sun.glass.ui.win.WinAccessible.sendNotification(WinAccessible.java:287); at javafx.scene.Node.notifyAccessibleAttributeChanged(Node.java:9604); at javafx.scene.control.TableView$TableViewSelectionModel.focus(TableView.java:2003); at javafx.scene.control.TableView$TableViewArrayListSelectionModel.updateDefaultSelection(TableView.java:2930); at javafx.scene.control.TableView$TableViewArrayListSelectionModel.updateItemsObserver(TableView.java:2907); at javafx.scene.control.TableVi,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:5265,concurren,concurrent,5265,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['concurren'],['concurrent']
Performance,org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:214); at Script30.run(Script30.groovy:12); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by null at qupath.lib.images.servers.BioFormatsImageServer.getTimePoint(BioFormatsImageServer.java:930); at qupath.imagej.images.servers.BufferedImagePlusServer.getTimePoint(BufferedImagePlusServer.java:173); at qupath.imagej.helpers.IJTools.calibrateImagePlus(IJTools.java:220); at qupath.imagej.images.servers.BufferedImagePlusServer.readImagePlusRegion(BufferedImagePlusServer.java:241); at qupath.imagej.detect.tissue.SimpleTissueDetection2$GlobalThresholder.runDetection(SimpleTissueDetection2.java:158); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:120); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Exe,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:10700,concurren,concurrent,10700,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['concurren'],['concurrent']
Performance,"orum.image.sc/t/specifying-the-imageserver-image-provider-server-type>. // Get the URI of the image under consideration; we need to pass this; // to the new server. The image is specified as a commandline parameter; // in the QuPath call.; def currentServer = getCurrentServer(); def uri = currentServer.getURIs()[0]. def server = new qupath.lib.images.servers.bioformats.BioFormatsServerBuilder().buildServer(uri). // Get the current image and image name; def imageData = new ImageData(server); def name = server.getMetadata().getName(). def save_path = ""thumbnail_dir/"" + name + "".png"". def scale_factor = 8.0. // Save the entire image downsampled by a factor of scale_factor; def requestFull = RegionRequest.createInstance(server, scale_factor); writeImageRegion(server, requestFull, save_path); ```. I run it using the command line: . ```; qupath script -i ""31629 HE.bif"" image_thumbnail.groovy; ```. and the output is as follows:. ```; 11:36:08.817 [main] [INFO ] qupath.ScriptCommand - Setting tile cache size to 8030.00 MB (25.0% max memory); 11:36:09.171 [main] [WARN ] q.l.i.s.b.BioFormatsImageServer - Temp memoization directory created at /tmp/qupath-memo-14642445523855977691; 11:36:09.172 [main] [WARN ] q.l.i.s.b.BioFormatsImageServer - If you want to avoid this warning, either disable Bio-Formats memoization in the preferences or specify a directory to use; 11:36:09.363 [main] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1; TIFFReadDirectory: Warning, Unknown field with tag 34677 (0x8775) encountered.; 11:36:09.429 [main] [WARN ] q.l.i.s.o.OpenslideImageServer - Openslide: Property 'openslide.level[0].tile-width' not available, will return default value 256.0; 11:36:09.429 [main] [WARN ] q.l.i.s.o.OpenslideImageServer - Openslide: Property 'openslide.level[0].tile-height' not available, will return default value 256.0; 11:36:09.999 [main] [INFO ] qupath.lib.scripting.QP - Initializing type adapters; ```. Note the `TIFFReadDirectory` warning message in",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/658:1451,cache,cache,1451,https://qupath.github.io,https://github.com/qupath/qupath/issues/658,1,['cache'],['cache']
Performance,"ory requirements for 2D images because the original has not yet been closed. When investigating this, three other issues were noticed:. 1. The performance impact of using virtual stacks is *much* worse than I had expected, particularly for large 2D images that will frequently be cropped/duplicated. Extracting a region - even for a 2D plane - causes the data to be read from disk again.; 2. [`readBufferedImage(request)`](https://github.com/qupath/qupath/blob/75ec9cebe5e3bc5843fc60b07b455ce1215e1fb9/qupath-core-processing/src/main/java/qupath/imagej/images/servers/ImageJServer.java#L298) is synchronized - but the entire method does not need to be. This prevents calls to resize the extracted image being parallelized, even though this should be safe.; 3. Resizing is called once per channel, including for RGB images. However, in ImageJ's world the RGB image is treated as a single channel - and so any resizing is actually performed 3x rather than 1x. The last two operations seem to be entirely unnecessary. **To Reproduce**; The problem should occur when trying to open any large TIFF that has been written by ImageJ. If it is at the bounds of the available memory, this is likely to fail. If enough memory is available, it should succeed but perform badly. **Expected behavior**; `ImageJServer` should fully read 2D images - since using a virtual stack brings no benefits - and most multidimensional images, as long as they are small enough to fit comfortably in memory. Synchronization should be reduced, and resizing limited. It will sometimes still not be possible to open a non-pyramidal image via ImageJ directly. In this case, running `convert-ome` should be able to efficiently generate an OME-TIFF image. **Desktop (please complete the following information):**; - OS: All; - QuPath Version 0.3.0 (and earlier). **Additional context**; It may be preferable to extend `AbstractTileableImageServer` rather than `AbstractImageServer` to take advantage of the tile caching in the former.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/860:2020,perform,perform,2020,https://qupath.github.io,https://github.com/qupath/qupath/issues/860,1,['perform'],['perform']
Performance,"own Source); qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:217); qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:287); qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:60); qupath.lib.analysis.images.ContourTracing.traceGeometriesImpl(ContourTracing.java:1157); qupath.lib.analysis.images.ContourTracing.traceGeometries(ContourTracing.java:1143); qupath.lib.analysis.images.ContourTracing.lambda$traceGeometriesImpl$9(ContourTracing.java:1022); qupath.lib.analysis.images.ContourTracing$$Lambda$2595/0x00000008009b7a18.apply(Unknown Source); qupath.lib.analysis.images.ContourTracing.lambda$invokeAll$8(ContourTracing.java:1000); qupath.lib.analysis.images.ContourTracing$$Lambda$2596/0x00000008009b7c58.call(Unknown Source); java.base/java.util.concurrent.FutureTask.run(Unknown Source); java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); java.base/java.lang.Thread.run(Unknown Source); ``` . ```json; {; ""pixel_classifier_type"": ""OpenCVPixelClassifier"",; ""metadata"": {; ""inputPadding"": 0,; ""inputResolution"": {; ""pixelWidth"": {; ""value"": 1.006,; ""unit"": ""µm""; },; ""pixelHeight"": {; ""value"": 1.006,; ""unit"": ""µm""; },; ""zSpacing"": {; ""value"": 1.0,; ""unit"": ""z-slice""; },; ""timeUnit"": ""SECONDS"",; ""timepoints"": []; },; ""inputWidth"": 512,; ""inputHeight"": 512,; ""inputNumChannels"": 3,; ""outputType"": ""CLASSIFICATION"",; ""outputChannels"": [],; ""classificationLabels"": {; ""0"": {; ""name"": ""Area"",; ""colorRGB"": -6895466; },; ""1"": {; ""colorRGB"": -12566464; }; }; },; ""op"": {; ""type"": ""data.op.channels"",; ""colorTransforms"": [; {; ""channelName"": ""Red""; }; ],; ""op"": {; ""type"": ""op.core.sequential"",; ""ops"": [; {; ""type"": ""op.gaussian"",; ""sigmaX"": 4.0,; ""sigmaY"": 4.0; },; {; ""type"": ""op.constant"",; ""thresholds"": [; 239.0; ]; }; ]; }; }; }; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1322#issuecomment-1719699500:2461,concurren,concurrent,2461,https://qupath.github.io,https://github.com/qupath/qupath/issues/1322#issuecomment-1719699500,1,['concurren'],['concurrent']
Performance,ownloads/QuPath/bin/QuPath; 55d91f2b9000-55d91f2bc000 rw-p 00000000 00:00 0 ; 55d91ffd0000-55d920002000 rw-p 00000000 00:00 0 [heap]; 7f78664d2000-7f78668e6000 r-xp 00000000 00:2f 2318694349 /home/grad3/jalal/.javacpp/cache/opencv-4.5.3-1.5.6-linux-x86_64.jar/org/bytedeco/opencv/linux-x86_64/libopencv_core.so.4.5; 7f78668e6000-7f7866ae5000 ---p 00414000 00:2f 2318694349 /home/grad3/jalal/.javacpp/cache/opencv-4.5.3-1.5.6-linux-x86_64.jar/org/bytedeco/opencv/linux-x86_64/libopencv_core.so.4.5; 7f7866ae5000-7f7866af3000 r--p 00413000 00:2f 2318694349 /home/grad3/jalal/.javacpp/cache/opencv-4.5.3-1.5.6-linux-x86_64.jar/org/bytedeco/opencv/linux-x86_64/libopencv_core.so.4.5; 7f7866af3000-7f7866af9000 rw-p 00421000 00:2f 2318694349 /home/grad3/jalal/.javacpp/cache/opencv-4.5.3-1.5.6-linux-x86_64.jar/org/bytedeco/opencv/linux-x86_64/libopencv_core.so.4.5; 7f7866af9000-7f7866aff000 rw-p 00000000 00:00 0 ; 7f7866aff000-7f78682ab000 r-xp 00000000 00:2f 2345794470 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libjniopenblas.so; 7f78682ab000-7f78684ab000 ---p 017ac000 00:2f 2345794470 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libjniopenblas.so; 7f78684ab000-7f78684ac000 r--p 017ac000 00:2f 2345794470 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libjniopenblas.so; 7f78684ac000-7f78684b4000 rw-p 017ad000 00:2f 2345794470 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libjniopenblas.so; 7f78684b4000-7f78684b5000 rw-p 00000000 00:00 0 ; 7f78684b5000-7f78784b5000 rw-p 00000000 00:00 0 ; 7f78784b5000-7f78784b6000 ---p 00000000 00:00 0 ; 7f78784b6000-7f7878cb6000 rw-p 00000000 00:00 0 ; 7f7878cb6000-7f7880cb6000 rw-p 00000000 00:00 0 ; 7f7880cb6000-7f7880cb7000 ---p 00000000 00:00 0 ; 7f7880cb7000-7f78814b7000 rw-p 00000000 00:00 0 ; 7f78814,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018:5349,cache,cache,5349,https://qupath.github.io,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018,1,['cache'],['cache']
Performance,p 00000000 00:00 0 ; 7f72ac000000-7f72ac021000 rw-p 00000000 00:00 0 ; 7f72ac021000-7f72b0000000 ---p 00000000 00:00 0 ; 7f72b0000000-7f72b0021000 rw-p 00000000 00:00 0 ; 7f72b0021000-7f72b4000000 ---p 00000000 00:00 0 ; 7f72b4000000-7f72b496c000 rw-p 00000000 00:00 0 ; 7f72b496c000-7f72b8000000 ---p 00000000 00:00 0 ; 7f72b8000000-7f72b8021000 rw-p 00000000 00:00 0 ; 7f72b8021000-7f72bc000000 ---p 00000000 00:00 0 ; 7f72bc000000-7f72bc021000 rw-p 00000000 00:00 0 ; 7f72bc021000-7f72c0000000 ---p 00000000 00:00 0 ; 7f72c0000000-7f72c0021000 rw-p 00000000 00:00 0 ; 7f72c0021000-7f72c4000000 ---p 00000000 00:00 0 ; 7f72c4000000-7f72c4021000 rw-p 00000000 00:00 0 ; 7f72c4021000-7f72c8000000 ---p 00000000 00:00 0 ; 7f72c8000000-7f72c8021000 rw-p 00000000 00:00 0 ; 7f72c8021000-7f72cc000000 ---p 00000000 00:00 0 ; 7f72cc000000-7f72cc021000 rw-p 00000000 00:00 0 ; 7f72cc021000-7f72d0000000 ---p 00000000 00:00 0 ; 7f72d01f3000-7f72d01ff000 r-xp 00000000 00:27 484015 /home/xxx/.openjfx/cache/16/libprism_es2.so; 7f72d01ff000-7f72d03fe000 ---p 0000c000 00:27 484015 /home/xxx/.openjfx/cache/16/libprism_es2.so; 7f72d03fe000-7f72d03ff000 r--p 0000b000 00:27 484015 /home/xxx/.openjfx/cache/16/libprism_es2.so; 7f72d03ff000-7f72d0400000 rw-p 0000c000 00:27 484015 /home/xxx/.openjfx/cache/16/libprism_es2.so; 7f72d0400000-7f72d0500000 rw-p 00000000 00:00 0 ; 7f72d0500000-7f72d05a0000 rw-p 00000000 00:00 0 ; 7f72d05a0000-7f72d0600000 ---p 00000000 00:00 0 ; 7f72d0600000-7f72d0630000 rw-p 00000000 00:00 0 ; 7f72d0630000-7f72d0c00000 ---p 00000000 00:00 0 ; 7f72d0cf9000-7f72d0cfd000 ---p 00000000 00:00 0 ; 7f72d0cfd000-7f72d0dfa000 rw-p 00000000 00:00 0 ; 7f72d0dfa000-7f72d0dfe000 ---p 00000000 00:00 0 ; 7f72d0dfe000-7f72d0efb000 rw-p 00000000 00:00 0 ; 7f72d0efb000-7f72d0eff000 ---p 00000000 00:00 0 ; 7f72d0eff000-7f72d0ffc000 rw-p 00000000 00:00 0 ; 7f72d0ffc000-7f72d1000000 ---p 00000000 00:00 0 ; 7f72d1000000-7f72d10fd000 rw-p 00000000 00:00 0 ; 7f72d10fd000-7f72d1101000 ---p 000000,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/825:16572,cache,cache,16572,https://qupath.github.io,https://github.com/qupath/qupath/issues/825,1,['cache'],['cache']
Performance,p 00000000 00:00 0 ; 7f79037ff000-7f790b7ff000 rw-p 00000000 00:00 0 ; 7f790b7ff000-7f790b800000 ---p 00000000 00:00 0 ; 7f790b800000-7f790c000000 rw-p 00000000 00:00 0 ; 7f790c000000-7f7924000000 rw-p 00000000 00:00 0 ; 7f7924000000-7f79244e4000 rw-p 00000000 00:00 0 ; 7f79244e4000-7f7928000000 ---p 00000000 00:00 0 ; 7f79280bc000-7f79280bd000 ---p 00000000 00:00 0 ; 7f79280bd000-7f79288bd000 rw-p 00000000 00:00 0 ; 7f79288bd000-7f79288be000 ---p 00000000 00:00 0 ; 7f79288be000-7f79290be000 rw-p 00000000 00:00 0 ; 7f79290be000-7f79290bf000 ---p 00000000 00:00 0 ; 7f79290bf000-7f79298bf000 rw-p 00000000 00:00 0 ; 7f79298bf000-7f79298c0000 ---p 00000000 00:00 0 ; 7f79298c0000-7f792a0c0000 rw-p 00000000 00:00 0 ; 7f792a0c0000-7f792bdd9000 r-xp 00000000 00:2f 2345794464 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libopenblas_nolapack.so.0; 7f792bdd9000-7f792bfd8000 ---p 01d19000 00:2f 2345794464 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libopenblas_nolapack.so.0; 7f792bfd8000-7f792bfde000 r--p 01d18000 00:2f 2345794464 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libopenblas_nolapack.so.0; 7f792bfde000-7f792bff4000 rw-p 01d1e000 00:2f 2345794464 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libopenblas_nolapack.so.0; 7f792bff4000-7f792c000000 rw-p 00000000 00:00 0 ; 7f792c000000-7f792c021000 rw-p 00000000 00:00 0 ; 7f792c021000-7f7930000000 ---p 00000000 00:00 0 ; 7f7930000000-7f7930021000 rw-p 00000000 00:00 0 ; 7f7930021000-7f7934000000 ---p 00000000 00:00 0 ; 7f7934000000-7f79349a9000 rw-p 00000000 00:00 0 ; 7f79349a9000-7f7938000000 ---p 00000000 00:00 0 ; 7f7938000000-7f793850e000 rw-p 00000000 00:00 0 ; 7f793850e000-7f793c000000 ---p 00000000 00:00 0 ; 7f793c000000-7f793c021000 rw-p 00000000 00:00 0 ; 7f793c021000-7f7,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018:10250,cache,cache,10250,https://qupath.github.io,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018,1,['cache'],['cache']
Performance,p 00000000 00:00 0 ; 80020000-80040000 rw-p 00000000 00:00 0 ; 80040000-800c0000 rw-p 00000000 00:00 0 ; 800c0000-80140000 rw-p 00000000 00:00 0 ; 80140000-801c0000 rw-p 00000000 00:00 0 ; 801c0000-80200000 rw-p 00000000 00:00 0 ; 80200000-80240000 rw-p 00000000 00:00 0 ; 80240000-80280000 rw-p 00000000 00:00 0 ; 80280000-80440000 rw-p 00000000 00:00 0 ; 80440000-80460000 rw-p 00000000 00:00 0 ; 80460000-80480000 ---p 00000000 00:00 0 ; 80480000-805d0000 rw-p 00000000 00:00 0 ; 805d0000-c0000000 ---p 00000000 00:00 0 ; 55d91efa2000-55d91f0b0000 r-xp 00000000 fd:02 35868047 /scratch3/downloads/QuPath/bin/QuPath; 55d91f2b0000-55d91f2b8000 r--p 0010e000 fd:02 35868047 /scratch3/downloads/QuPath/bin/QuPath; 55d91f2b8000-55d91f2b9000 rw-p 00116000 fd:02 35868047 /scratch3/downloads/QuPath/bin/QuPath; 55d91f2b9000-55d91f2bc000 rw-p 00000000 00:00 0 ; 55d91ffd0000-55d920002000 rw-p 00000000 00:00 0 [heap]; 7f78664d2000-7f78668e6000 r-xp 00000000 00:2f 2318694349 /home/grad3/jalal/.javacpp/cache/opencv-4.5.3-1.5.6-linux-x86_64.jar/org/bytedeco/opencv/linux-x86_64/libopencv_core.so.4.5; 7f78668e6000-7f7866ae5000 ---p 00414000 00:2f 2318694349 /home/grad3/jalal/.javacpp/cache/opencv-4.5.3-1.5.6-linux-x86_64.jar/org/bytedeco/opencv/linux-x86_64/libopencv_core.so.4.5; 7f7866ae5000-7f7866af3000 r--p 00413000 00:2f 2318694349 /home/grad3/jalal/.javacpp/cache/opencv-4.5.3-1.5.6-linux-x86_64.jar/org/bytedeco/opencv/linux-x86_64/libopencv_core.so.4.5; 7f7866af3000-7f7866af9000 rw-p 00421000 00:2f 2318694349 /home/grad3/jalal/.javacpp/cache/opencv-4.5.3-1.5.6-linux-x86_64.jar/org/bytedeco/opencv/linux-x86_64/libopencv_core.so.4.5; 7f7866af9000-7f7866aff000 rw-p 00000000 00:00 0 ; 7f7866aff000-7f78682ab000 r-xp 00000000 00:2f 2345794470 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.jar/org/bytedeco/openblas/linux-x86_64/libjniopenblas.so; 7f78682ab000-7f78684ab000 ---p 017ac000 00:2f 2345794470 /home/grad3/jalal/.javacpp/cache/openblas-0.3.17-1.5.6-linux-x86_64.ja,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018:4571,cache,cache,4571,https://qupath.github.io,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018,1,['cache'],['cache']
Performance,"p/QuPath/extensions; 02:39:37.715 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Added extension: /home/bl/ip/QuPath/extensions/jep.jar; OpenJDK 64-Bit Server VM warning: You have loaded library /home/bl/ip/QuPath/app/libopencv_java310.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.; 02:39:37.931 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /home/bl/ip/QuPath/app/libopencv_java310.so: libavcodec-ffmpeg.so.56: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:120); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1092); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:633); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:418); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:59); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$106(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$119(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$117(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$118(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/27#issuecomment-262870405:1787,load,loadLibrary,1787,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405,1,['load'],['loadLibrary']
Performance,"parts have changed in the code. I've attached the whole classifier below (it's just a simple thersholder to filter out the background). I think the original analysis was done with 6 GB or 8 GB of RAM but I also had other scripts with `qupath.imagej.detect.cells.WatershedCellDetection` running and I can't say for 100% certainty whether it was the Pixel Classifier, Cell Counting or both which caused OutOfMemoryErrors. ```; ERROR: OutOfMemoryError: Java heap space. ERROR: qupath.opencv.tools.OpenCVTools.matToBufferedImage(OpenCVTools.java:765); qupath.opencv.ml.pixel.OpenCVPixelClassifier.applyClassification(OpenCVPixelClassifier.java:115); qupath.lib.classifiers.pixel.PixelClassificationImageServer.readTile(PixelClassificationImageServer.java:299); qupath.lib.images.servers.AbstractTileableImageServer.lambda$getTile$0(AbstractTileableImageServer.java:213); qupath.lib.images.servers.AbstractTileableImageServer$$Lambda$1691/0x0000000800796740.call(Unknown Source); java.base/java.util.concurrent.FutureTask.run(Unknown Source); qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:217); qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:287); qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:60); qupath.lib.analysis.images.ContourTracing.traceGeometriesImpl(ContourTracing.java:1157); qupath.lib.analysis.images.ContourTracing.traceGeometries(ContourTracing.java:1143); qupath.lib.analysis.images.ContourTracing.lambda$traceGeometriesImpl$9(ContourTracing.java:1022); qupath.lib.analysis.images.ContourTracing$$Lambda$2595/0x00000008009b7a18.apply(Unknown Source); qupath.lib.analysis.images.ContourTracing.lambda$invokeAll$8(ContourTracing.java:1000); qupath.lib.analysis.images.ContourTracing$$Lambda$2596/0x00000008009b7c58.call(Unknown Source); java.base/java.util.concurrent.FutureTask.run(Unknown Source); java.base/java.util.concu",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1322#issuecomment-1719699500:1383,concurren,concurrent,1383,https://qupath.github.io,https://github.com/qupath/qupath/issues/1322#issuecomment-1719699500,1,['concurren'],['concurrent']
Performance,path.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:863); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:902); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:216); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by null at java.base/java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(Unknown Source); at java.base/java.util.concurrent.locks.ReentrantLock.lockInterruptibly(Unknown Source); at java.base/java.util.concurrent.ArrayBlockingQueue.put(Unknown Source); at qupath.lib.images.servers.bioformats.BioFormatsImageServer$ReaderPool.openImage(BioFormatsImageServer.java:1411); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:909); at qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.lib.images.servers.CroppedIma,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583:2629,concurren,concurrent,2629,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583,1,['concurren'],['concurrent']
Performance,path.lib.images.servers.ImageServerBuilder$DefaultImageServerBuilder.buildOriginal(ImageServerBuilder.java:323); at qupath.lib.images.servers.ImageServerBuilder$AbstractServerBuilder.build(ImageServerBuilder.java:147); at qupath.lib.gui.commands.ProjectImportImagesCommand.initializeEntry(ProjectImportImagesCommand.java:505); at qupath.lib.gui.commands.ProjectImportImagesCommand$1.lambda$call$1(ProjectImportImagesCommand.java:278); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(Unknown Source); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); at java.base/java.util.stream.ForEachOps$ForEachTask.compute(Unknown Source); at java.base/java.util.concurrent.CountedCompleter.exec(Unknown Source); at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); at java.base/java.util.concurrent.ForkJoinTask.doInvoke(Unknown Source); at java.base/java.util.concurrent.ForkJoinTask.invoke(Unknown Source); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateParallel(Unknown Source); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(Unknown Source); at java.base/java.util.stream.AbstractPipeline.evaluate(Unknown Source); at java.base/java.util.stream.ReferencePipeline.forEach(Unknown Source); at java.base/java.util.stream.ReferencePipeline$Head.forEach(Unknown Source); at qupath.lib.gui.commands.ProjectImportImagesCommand$1.call(ProjectImportImagesCommand.java:276); at qupath.lib.gui.commands.ProjectImportImagesCommand$1.call(ProjectImportImagesCommand.java:236); at javafx.concurrent.Task$TaskCallable.call(Task.java:1425); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at ja,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/396:2124,concurren,concurrent,2124,https://qupath.github.io,https://github.com/qupath/qupath/issues/396,1,['concurren'],['concurrent']
Performance,"path.opencv.dnn.OpenCVDnn$OpenCVNetFunction.predict(OpenCVDnn.java:732); qupath.opencv.dnn.DnnModel.convertAndPredict(DnnModel.java:100); qupath.ext.stardist.StarDist2D.detectObjectsForTile(StarDist2D.java:1249); qupath.ext.stardist.StarDist2D.lambda$detectObjects$7(StarDist2D.java:934); java.base/java.util.stream.ReferencePipeline$7$1.accept(Unknown Source); java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); java.base/java.util.stream.AbstractTask.compute(Unknown Source); java.base/java.util.concurrent.CountedCompleter.exec(Unknown Source); java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source); java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source); java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source); java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source). ```. **Expected behavior**; The script should run without any error, yielding cell detections within the annotation. **Desktop (please complete the following information):**; - OS: Windows 10; - QuPath Version: 0.4.0, built from source on 2022-12-07; - StarDist Extension Version: 0.4.0 (reproducible with 0.3.2 as well). **Additional context**; The changelog of 0.4.0 points to two separate issues that were marked as resolved, which could be linked to this issue:; https://github.com/qupath/qupath/issues/841; https://github.com/qupath/qupath-extension-stardist/issues/11. Given that issue #841 was marked as resolved 5 days ago, it could be linked to that. Perhaps there were some changes to the API such that closing of the model should be scripted differently?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1180:3346,concurren,concurrent,3346,https://qupath.github.io,https://github.com/qupath/qupath/issues/1180,3,['concurren'],['concurrent']
Performance,"perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile. Anyway, thanks a lot for your help, I am going to play more with QuPath to test all the other possibilities!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/56#issuecomment-286702227:1562,perform,perform,1562,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227,2,['perform'],['perform']
Performance,"plication Thread] [INFO ] qupath.lib.gui.QuPathGUI - QuPath build: Version: 0.2.0-m12; Build time: 2020-05-26, 12:34; 12:35:11.263 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Setting tile cache size to 1981.50 MB (25.0% max memory). (QuPath-0.2.0-m12:49988): Gdk-WARNING **: 12:35:11.652: XSetErrorHandler() called with a GDK error trap pushed. Don't do that. 12:35:12.161 [JavaFX Application Thread] [INFO ] q.l.i.s.b.BioFormatsOptionsExtension - Bio-Formats version 6.5.0; 12:35:12.165 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Bio-Formats server options (Bio-Formats 6.5.0) (12 ms); 12:35:12.166 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Experimental commands (1 ms); 12:35:12.199 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Experimental commands (33 ms); 12:35:12.234 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension ImageJ extension (34 ms); Warning: Could not load Loader: java.lang.UnsatisfiedLinkError: no jnijavacpp in java.library.path: [/home/gordon/src/qupath/build/dist/QuPath-0.2.0-m12/lib/app, /home/gordon/src/qupath/build/dist/QuPath-0.2.0-m12/bin]; 12:35:12.248 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension JPen extension (13 ms); May 26, 2020 12:35:12 PM jpen.provider.NativeLibraryLoader$4 run; INFO: loading JPen 2-150301 JNI library: jpen-2-4-x86_64 ...; May 26, 2020 12:35:12 PM jpen.provider.NativeLibraryLoader$4 run; INFO: jpen-2-4-x86_64 loaded; Warning: Could not load Pointer: java.lang.UnsatisfiedLinkError: no jnijavacpp in java.library.path: [/home/gordon/src/qupath/build/dist/QuPath-0.2.0-m12/lib/app, /home/gordon/src/qupath/build/dist/QuPath-0.2.0-m12/bin]; #; # A fatal error has been detected by the Java Runtime Environment:; [thread 50032 also had an error]; #; # SIGSEGV (0xb) at pc=0x00007f6271c2df1e, pid=49988, tid=50030; #; # JRE version: OpenJDK Runtime Env",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/484#issuecomment-634101819:1604,Load,Loaded,1604,https://qupath.github.io,https://github.com/qupath/qupath/issues/484#issuecomment-634101819,3,"['Load', 'load']","['Loaded', 'Loader', 'load']"
Performance,"proceed(DaemonCommandExecution.java:104); at org.gradle.launcher.daemon.server.exec.LogAndCheckHealth.execute(LogAndCheckHealth.java:55); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:104); at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:63); at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:37); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:104); at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:82); at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:37); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:104); at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:52); at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:297); at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630); at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); at java.base/java.lang.Thread.run(Thread.java:832). FAILURE: Build failed with an exception. * What went wrong:; Could not initialize class org.codehaus.groovy.reflection.ReflectionCache. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Get more help at https://help.gradle.org. BUILD FAILED in 5s. looking forward for you response ; Brijeshwar,",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/427:13847,concurren,concurrent,13847,https://qupath.github.io,https://github.com/qupath/qupath/issues/427,5,['concurren'],['concurrent']
Performance,processTargetDrop(Scene.java:3159); at javafx.scene.Scene$DnDGesture.access$6400(Scene.java:2909); at javafx.scene.Scene$DropTargetListener.drop(Scene.java:2873); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.lambda$handleDragDrop$309(GlassSceneDnDEventHandler.java:95); at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragDrop(GlassSceneDnDEventHandler.java:92); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragDrop$363(GlassViewEventHandler.java:700); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragDrop(GlassViewEventHandler.java:699); at com.sun.glass.ui.View.handleDragDrop(View.java:712); at com.sun.glass.ui.View.notifyDragDrop(View.java:1037); Caused by loci.formats.FormatException at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at qupath.lib.images.servers.BioFormatsServerBuilder.buildServer(BioFormatsServerBuilder.java:45); at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:115); at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2228); at qupath.lib.gui.viewer.DragDropFileImportListener.handleFileDrop(DragDropFileImportListener.java:253); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:115); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:59); at com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:238); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:191); at com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(Compos,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/191#issuecomment-409140774:4330,load,loadClass,4330,https://qupath.github.io,https://github.com/qupath/qupath/issues/191#issuecomment-409140774,1,['load'],['loadClass']
Performance,processTargetDrop(Scene.java:3159); at javafx.scene.Scene$DnDGesture.access$6400(Scene.java:2909); at javafx.scene.Scene$DropTargetListener.drop(Scene.java:2873); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.lambda$handleDragDrop$309(GlassSceneDnDEventHandler.java:95); at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragDrop(GlassSceneDnDEventHandler.java:92); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragDrop$363(GlassViewEventHandler.java:700); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragDrop(GlassViewEventHandler.java:699); at com.sun.glass.ui.View.handleDragDrop(View.java:712); at com.sun.glass.ui.View.notifyDragDrop(View.java:1037); Caused by loci.formats.FormatException at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at qupath.lib.images.servers.BioFormatsServerBuilder.buildServer(BioFormatsServerBuilder.java:46); at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:115); at qupath.lib.gui.QuPathGUI.openImage(QuPathGUI.java:2228); at qupath.lib.gui.viewer.DragDropFileImportListener.handleFileDrop(DragDropFileImportListener.java:253); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:115); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:59); at com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:238); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:191); at com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(Compos,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/191#issuecomment-409021767:3941,load,loadClass,3941,https://qupath.github.io,https://github.com/qupath/qupath/issues/191#issuecomment-409021767,3,['load'],['loadClass']
Performance,"ps://github.com/qupath/qupath/blob/v0.3.2/qupath-core/src/main/java/qupath/lib/awt/common/BufferedImageTools.java#L416); * [Type adaptors for Gson](https://github.com/qupath/qupath/blob/v0.3.2/qupath-core/src/main/java/qupath/lib/io/OpenCVTypeAdapters.java). ## Required change. I think (hope) type adaptors can be shifted to `qupath-core-processing` without too much trouble.; Although since the change was introduced in https://github.com/qupath/qupath/commit/0f0229fc1a6de6312bf3a2e914e9da79cf1f4bd9 the commit message hints that there was a reason to including it in `qupath-core` that might resurface in the future. I expect that the main effort would go into reimplementing image resizing. Ideally, we'd do this without introducing any new dependency (including ImageJ) to retain full control over the code and not have it subject to change with dependency updates. I expect that will be a very fiddly task, requiring some very good unit tests. ## Additional context. Resizing is performed whenever tiles are requested, e.g. https://github.com/qupath/qupath/blob/48dfb82400fb8289fa57242b08effe1977749a51/qupath-core/src/main/java/qupath/lib/images/servers/AbstractTileableImageServer.java#L436-L442. In this case, it is almost always downsampling. We need to support both a 'smooth' and a 'nearest neighbor' implementation, to handle intensity and labeled/binary images at least - although we **might** want to introduce more interpolation options. See also https://github.com/qupath/2022-qupath-hackathon/discussions/2#discussioncomment-2634192. ## Significance. Having OpenCV as a dependency of `qupath-core` showed up when testing on a M1 Mac: it meant *nothing* would work until OpenCV had compatible binaries. It does now, but that flagged the issue of OpenCV being dragged into pretty much everything. Removing it would mean that the core module - and therefore most serializable datastructures - depend upon *only* Java code. This could help in making it accessible elsewhere, e.g. from P",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/961:1403,perform,performed,1403,https://qupath.github.io,https://github.com/qupath/qupath/issues/961,1,['perform'],['performed']
Performance,ptEngineImpl.java:317); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:155); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:767); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:697); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.gui.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1288); at qupath.lib.gui.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1237); at javafx.concurrent.Task$TaskCallable.call(Task.java:1425); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); Caused by Java heap space at ij.process.FloatProcessor.snapshot(FloatProcessor.java:240); at ij.process.FloatProcessor.convolve(FloatProcessor.java:1069); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.doDetection(WatershedCellDetection.java:600); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:997); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:362); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurren,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:2676,concurren,concurrent,2676,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['concurren'],['concurrent']
Performance,"quPath 0.2.0-m7 fail to open some pyramid tif files that could be open with 0.1.2.; Unfortunately, I am not allowed to share the files. I dont think the problem is out of memory, since I have tif images that are twice as big that can be opened without problem. . I have tested both on Windows 10 and Ubuntu 18. Here is the log from a Windows machine:; INFO: Bio-Formats version 6.3.0; INFO: Loaded extension Bio-Formats server options (Bio-Formats 6.3.0) (22 ms); INFO: Loaded extension Experimental commands (18 ms); INFO: Loaded extension ImageJ extension (58 ms); INFO: Loaded extension JPen extension (22 ms); INFO: Loaded extension OpenCV extensions (3 ms); INFO: Loaded extension Rich script editor extension (373 ms); INFO: OpenSlide version 3.4.1; INFO: Selected style: null; INFO: Performing update check...; WARN: No changelog found - will not check for updates; INFO: Starting QuPath with parameters: []; WARN: Unable to obtain full image format info for file:/D:/pDST/eHE-PDS18-015016-leica.tif (class java.util.NoSuchElementException); WARN: Temp memoization directory created at C:\Users\DanielH\AppData\Local\Temp\qupath-memo-13737650391880953912; WARN: If you want to avoid this warning, either disable Bio-Formats memoization in the preferences or specify a directory to use; ERROR: *** One or more readers is misbehaving. See the debug output for more information. e.g.:; loci.formats.in.APLReader@578b4451 -> java.lang.NullPointerException('null') ***; WARN: Removing alpha channel; WARN: Removing alpha channel; ERROR: QuPath exception: Java heap space; at java.desktop/sun.awt.image.IntegerInterleavedRaster.getDataElements(Unknown Source); at qupath.lib.display.ChannelDisplayInfo$RGBDirectChannelInfo.getRGBIntBuffer(ChannelDisplayInfo.java:539); at qupath.lib.display.ChannelDisplayInfo$RBGColorTransformInfo.getValues(ChannelDisplayInfo.java:707); at qupath.lib.display.ImageDisplay$HistogramManager.ensureChannels(ImageDisplay.java:902); at qupath.lib.display.ImageDisplay.up",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/382:391,Load,Loaded,391,https://qupath.github.io,https://github.com/qupath/qupath/issues/382,7,"['Load', 'Perform']","['Loaded', 'Performing']"
Performance,"qupath.opencv.ops.ImageOps$ML$StatModelOp.apply(ImageOps.java:2812); at qupath.opencv.ops.ImageOps$Core$SequentialMultiOp.apply(ImageOps.java:2294); at qupath.opencv.ops.ImageOps$ChannelImageDataOp.apply(ImageOps.java:424); at qupath.opencv.ml.pixel.OpenCVPixelClassifier.applyClassification(OpenCVPixelClassifier.java:104); at qupath.lib.classifiers.pixel.PixelClassificationImageServer.readTile(PixelClassificationImageServer.java:299); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:184); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:238); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:56); at qupath.lib.gui.viewer.overlays.PixelClassificationOverlay.lambda$requestTile$5(PixelClassificationOverlay.java:547); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); ```. **To Reproduce**; Steps to reproduce the behavior:; 1. Open OS-1.ndpi on an M1 Mac, set to have a maximum of 4GB RAM for QuPath; 2. Start training a pixel classifier (default resolution and settings); 3. Zoom out to force preview classification across the full image; 4. Open the log & await the error; * If no error appears, adjust training annotations if needed to create a new classifier (it usually doesn't take long); 5. Check Activity Monitor to confirm that QuPath does not seem to be using a particularly large amount of memory. **Expected behavior**; Pixel classification continues without error for as long as its real memory use remains reasonable. **Desktop (please complete the following information):**; - OS: macOS, ARM; - QuPath V",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856:3153,concurren,concurrent,3153,https://qupath.github.io,https://github.com/qupath/qupath/issues/856,1,['concurren'],['concurrent']
Performance,"r and smaller training annotations. The actual `RTrees` classifiers are implemented in C++ (by OpenCV). After QuPath has generated the training data, the training itself is performed inside OpenCV and in accessible to QuPath. As far as I am aware, this is single-threaded in OpenCV and cannot be changed in QuPath. Similarly, JSON generation and parsing is performed with the help of the Gson library, so performance depends somewhat on Gson. GeoJSON is a standard for representing geometries; I think it solves a different problem from Parquet. In QuPath, it is primarily intended to facilitate exchanging annotations, where choosing an existing open format is strongly desirable for interoperability (rather than trying to define a new standard others have to follow). Performance should not be an issue with several hundred/thousand objects (the common scenario), but it will inevitably be slow to export to export millions of cells as GeoJSON. If you don't need geometry information, you could export much more efficiently features/classifications/centroids only (e.g. through [a measurement table](https://qupath.readthedocs.io/en/stable/docs/tutorials/exporting_measurements.html)). Alternatively, if you need a highly optimized solution or a custom format then you can implement one using a QuPath script or extension. I'd like to close this issue because I think there is no bug in QuPath. The best place for discussing the use of the software or suggested improvements is http://forum.image.sc/tag/qupath. >If you'd like to add a separate GitHub issue for the minimized windows, please fill in the bug report template. I have seen some issues on Ubuntu with Windows not being in the correct place, but not on Windows or macOS. I cannot tell if it is a problem that QuPath can solve, or if it is an issue in JavaFX. But the issue I have seen does not make the dialogs unusable. We don't have the bandwidth to test other linux distributions, so rely on fixes from others if there are problems.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/831#issuecomment-950106875:1364,optimiz,optimized,1364,https://qupath.github.io,https://github.com/qupath/qupath/issues/831#issuecomment-950106875,1,['optimiz'],['optimized']
Performance,"r) = 1.4; 13:20:06.362 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale FORMAT set to fr_FR; 13:20:06.366 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale DISPLAY set to en_US; 13:20:06.396 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 3568,00 MB; 13:20:07.893 [JavaFX Application Thread] [ERROR] qupath.opencv.OpenCVExtension - Unable to load OpenCV libraries!; java.lang.UnsatisfiedLinkError: /soft/c7/qupath/0.1.3/app/libopencv_java310.so: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by /soft/c7/qupath/0.1.3/app/libopencv_java310.so); 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$173(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/150#issuecomment-368857650:1241,load,loadNativeLibrary,1241,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650,1,['load'],['loadNativeLibrary']
Performance,r.java:334); at loci.formats.gui.BufferedImageReader.openImage(BufferedImageReader.java:86); at qupath.lib.images.servers.BioFormatsImageServer.readBufferedImage(BioFormatsImageServer.java:683); at qupath.lib.images.servers.BioFormatsImageServer.readBufferedImage(BioFormatsImageServer.java:95); at qupath.lib.images.stores.AbstractImageRegionStore$DefaultTileWorker$1.call(AbstractImageRegionStore.java:656); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by Array size too large: 23422 x 30978 x 3 x 1 at loci.common.DataTools.safeMultiply32(DataTools.java:1274); at loci.common.DataTools.allocate(DataTools.java:1247); at loci.formats.FormatReader.openBytes(FormatReader.java:877); at loci.formats.ImageReader.openBytes(ImageReader.java:444); at loci.formats.ReaderWrapper.openBytes(ReaderWrapper.java:334); at loci.formats.ReaderWrapper.openBytes(ReaderWrapper.java:334); at loci.formats.gui.BufferedImageReader.openImage(BufferedImageReader.java:86); at qupath.lib.images.servers.BioFormatsImageServer.readBufferedImage(BioFormatsImageServer.java:683); at qupath.lib.images.servers.BioFormatsImageServer.readBufferedImage(BioFormatsImageServer.java:95); at qupath.lib.images.stores.AbstractImageRegionStore$DefaultTileWorker$1.call(AbstractImageRegionStore.java:656); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ```. After that I tried another tif sized 91.5MB and it can be opened without problem. Then I tried an svs sized 643MB and it can be opened too. So do you know why my first tif file can't be opened successfully?. Many thanks!,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/221:21376,concurren,concurrent,21376,https://qupath.github.io,https://github.com/qupath/qupath/issues/221,3,['concurren'],['concurrent']
Performance,r.lambda$handleDragDrop$2(GlassSceneDnDEventHandler.java:108); at java.base/java.security.AccessController.doPrivileged(Unknown Source); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragDrop(GlassSceneDnDEventHandler.java:104); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragDrop$11(GlassViewEventHandler.java:766); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:412); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragDrop(GlassViewEventHandler.java:765); at com.sun.glass.ui.View.handleDragDrop(View.java:713); at com.sun.glass.ui.View.notifyDragDrop(View.java:1042); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:174); at java.base/java.lang.Thread.run(Unknown Source); Caused by null at qupath.lib.projects.DefaultProject.loadPathClasses(DefaultProject.java:1130); at qupath.lib.projects.DefaultProject.loadProject(DefaultProject.java:1086); at qupath.lib.projects.DefaultProject.loadFromFile(DefaultProject.java:171); at qupath.lib.projects.ProjectIO.loadProject(ProjectIO.java:97); at qupath.lib.gui.viewer.DragDropFileImportListener.handleFileDropImpl(DragDropFileImportListener.java:248); at qupath.lib.gui.viewer.DragDropFileImportListener.handleFileDrop(DragDropFileImportListener.java:158); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:126); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:64); at com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:234); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:191); at com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDispatcher.java:59); at com.sun.javafx.event.Ba,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/613#issuecomment-708516373:2919,load,loadProject,2919,https://qupath.github.io,https://github.com/qupath/qupath/issues/613#issuecomment-708516373,1,['load'],['loadProject']
Performance,ractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:863); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:902); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:216); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by null at java.base/java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(Unknown Source); at java.base/java.util.concurrent.locks.ReentrantLock.lockInterruptibly(Unknown Source); at java.base/java.util.concurrent.ArrayBlockingQueue.put(Unknown Source); at qupath.lib.images.servers.bioformats.BioFormatsImageServer$ReaderPool.openImage(BioFormatsImageServer.java:1411); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:909); at qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583:2482,concurren,concurrent,2482,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583,1,['concurren'],['concurrent']
Performance,rce); at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(Unknown Source); at java.base/java.util.stream.AbstractPipeline.evaluate(Unknown Source); at java.base/java.util.stream.ReferencePipeline.collect(Unknown Source); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:941); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:886); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$6(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:859); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$5(StarDist2D.java:812); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:812); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript.run(QuPathScript:48); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:331); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:161); at qupath.lib.gui.scripting.languages.DefaultScriptLanguage.execute(DefaultScriptLanguage.java:234); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:1179); at qupath.lib.gui.scripting.DefaultScriptEditor$3.run(DefaultScriptEditor.java:1545); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source). ```. Best; Ofra,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1635:2441,concurren,concurrent,2441,https://qupath.github.io,https://github.com/qupath/qupath/issues/1635,4,['concurren'],['concurrent']
Performance,rce); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:55); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:196); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:216); at Script3.run(Script3.groovy:6); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:317); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:155); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:767); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:697); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.gui.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1288); at qupath.lib.gui.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1237); at javafx.concurrent.Task$TaskCallable.call(Task.java:1425); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); Caused by Java heap space at ij.process.FloatProcessor.snapshot(FloatProcessor.java:240); at ij.process.FloatProcessor.convolve(FloatProcessor.java:1069); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.doDetection(WatershedCellDetection.java:600); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:997); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedC,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:2280,concurren,concurrent,2280,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['concurren'],['concurrent']
Performance,read(ObjectField.java:125); at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:543); at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:731); at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:543); at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:731); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:391); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:302); at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:731); at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:543); at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:709); at loci.formats.Memoizer$KryoDeser.loadReader(Memoizer.java:163); at loci.formats.Memoizer.loadMemo(Memoizer.java:888); at loci.formats.Memoizer.setId(Memoizer.java:666); at qupath.lib.images.servers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1360); at qupath.lib.images.servers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1265); at qupath.lib.images.servers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.getReaderForThread(BioFormatsImageServer.java:1191); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.getReader(BioFormatsImageServer.java:815); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:848); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:184); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:275); at qupath.lib.images.servers.AbstractTilea,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/717:4147,load,loadReader,4147,https://qupath.github.io,https://github.com/qupath/qupath/issues/717,1,['load'],['loadReader']
Performance,"rent.FutureTask.run(Unknown Source); qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:217); qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:287); qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:60); qupath.lib.analysis.images.ContourTracing.traceGeometriesImpl(ContourTracing.java:1157); qupath.lib.analysis.images.ContourTracing.traceGeometries(ContourTracing.java:1143); qupath.lib.analysis.images.ContourTracing.lambda$traceGeometriesImpl$9(ContourTracing.java:1022); qupath.lib.analysis.images.ContourTracing$$Lambda$2595/0x00000008009b7a18.apply(Unknown Source); qupath.lib.analysis.images.ContourTracing.lambda$invokeAll$8(ContourTracing.java:1000); qupath.lib.analysis.images.ContourTracing$$Lambda$2596/0x00000008009b7c58.call(Unknown Source); java.base/java.util.concurrent.FutureTask.run(Unknown Source); java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); java.base/java.lang.Thread.run(Unknown Source); ``` . ```json; {; ""pixel_classifier_type"": ""OpenCVPixelClassifier"",; ""metadata"": {; ""inputPadding"": 0,; ""inputResolution"": {; ""pixelWidth"": {; ""value"": 1.006,; ""unit"": ""µm""; },; ""pixelHeight"": {; ""value"": 1.006,; ""unit"": ""µm""; },; ""zSpacing"": {; ""value"": 1.0,; ""unit"": ""z-slice""; },; ""timeUnit"": ""SECONDS"",; ""timepoints"": []; },; ""inputWidth"": 512,; ""inputHeight"": 512,; ""inputNumChannels"": 3,; ""outputType"": ""CLASSIFICATION"",; ""outputChannels"": [],; ""classificationLabels"": {; ""0"": {; ""name"": ""Area"",; ""colorRGB"": -6895466; },; ""1"": {; ""colorRGB"": -12566464; }; }; },; ""op"": {; ""type"": ""data.op.channels"",; ""colorTransforms"": [; {; ""channelName"": ""Red""; }; ],; ""op"": {; ""type"": ""op.core.sequential"",; ""ops"": [; {; ""type"": ""op.gaussian"",; ""sigmaX"": 4.0,; ""sigmaY"": 4.0; },; {; ""type"": ""op.constant"",; ""thresholds"": [; 239.0",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1322#issuecomment-1719699500:2384,concurren,concurrent,2384,https://qupath.github.io,https://github.com/qupath/qupath/issues/1322#issuecomment-1719699500,1,['concurren'],['concurrent']
Performance,"riptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by null at qupath.lib.images.servers.BioFormatsImageServer.getTimePoint(BioFormatsImageServer.java:930); at qupath.imagej.images.servers.BufferedImagePlusServer.getTimePoint(BufferedImagePlusServer.java:173); at qupath.imagej.helpers.IJTools.calibrateImagePlus(IJTools.java:220); at qupath.imagej.images.servers.BufferedImagePlusServer.readImagePlusRegion(BufferedImagePlusServer.java:241); at qupath.imagej.detect.tissue.SimpleTissueDetection2$GlobalThresholder.runDetection(SimpleTissueDetection2.java:158); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:120); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); INFO: Processing complete in 4,20 seconds; INFO: Completed with error java.lang.NullPointerException; INFO: ; qupath.imagej.detect.tissue.SimpleTissueDetection2 {""threshold"": 224, ""requestedPixelSizeMicrons"": 20.0, ""minAreaMicrons"": 100000.0, ""maxHoleAreaMicrons"": 1000000.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": true, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:11524,concurren,concurrent,11524,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,6,['concurren'],['concurrent']
Performance,roovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ERROR: Error running plugin: java.lang.NullPointerException; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.scripting.QPEx.runPlugin(QPEx.java:266); at qupath.lib.scripting.QPEx.runPlugin(QPEx.java:286); at qupath.lib.scripting.QPEx$runPlugin.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:214); at Script30.run(Script30.groovy:12); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEng,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:9062,concurren,concurrent,9062,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['concurren'],['concurrent']
Performance,"rown everytime I toggle ""Group by ID"" as well.; ```; ERROR: QuPath exception: Cannot invoke ""javafx.scene.control.TreeTableColumn.setPrefWidth(double)"" because ""columnImage"" is null; java.lang.NullPointerException: Cannot invoke ""javafx.scene.control.TreeTableColumn.setPrefWidth(double)"" because ""columnImage"" is null; at qupath.lib.gui.tma.TMASummaryViewer.lambda$refreshTableData$66(TMASummaryViewer.java:1463); ```; 2. In the log I also noticed ```WARN: Unable to find censored column - survival data will be uncensored``` - not sure why ? ; ```; INFO: Update check for https://github.com/qupath/qupath; WARN: You need to enable the startup script in the Preferences if you want to run it; INFO: Starting QuPath with parameters: []; INFO: Update check for https://github.com/qupath/qupath-extension-stardist; INFO: Predicate set to: null; INFO: Parsed 84 from HS-1_Scan1.ome.tif.qptma (84 total); INFO: Parsed 84 from HS-2_Scan1.ome.tif.qptma (168 total); INFO: Parsed 84 from HS-3_Scan1.ome.tif.qptma (252 total); INFO: Parsed 84 from HS-4_Scan1.ome.tif.qptma (336 total); INFO: Parsed 84 from HS-5_Scan1.ome.tif.qptma (420 total); INFO: Parsed 84 from HS-6_Scan1.ome.tif.qptma (504 total); WARN: Unable to find censored column - survival data will be uncensored; INFO: Survival column: Overall survival, Censored column: OS censored; INFO: Survival column: Overall survival, Censored column: OS censored; INFO: No p-values < 0.05; INFO: Smoothing log-rank test p-values by 1; INFO: Longest stretch of p-values < 0.05: 12294.9 - 13980.4 (18 entries, 5 observed); INFO: Smoothing log-rank test p-values by 11; INFO: Longest stretch of p-values < 0.05: 12294.9 - 13980.4 (18 entries, 5 observed); INFO: Smoothing log-rank test p-values by 11; ```; I can see in the next couple of line the survival data is being loaded , and they are displayed in the table as well. 3. I also noticed the ""Missing"" column is missing in the TMA Data viewer when I load the qptma file in the Offline TMA Data Viewer.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1083#issuecomment-1289564901:2740,load,loaded,2740,https://qupath.github.io,https://github.com/qupath/qupath/issues/1083#issuecomment-1289564901,2,['load'],"['load', 'loaded']"
Performance,"rp; import loci.formats.tiff.TiffParser; import qupath.lib.gui.QuPathGUI; import qupath.lib.images.servers.BioFormatsImageServer; import qupath.lib.scripting.QPEx. // Access the current image; def server = QPEx.getCurrentImageData().getServer() as BioFormatsImageServer. if (server.willParallelize()); print 'For this to work, you will need to turn off parallelization in the QuPath preferences!'. // Create a new reader that intercepts the photometric interpretation, and 'trick' QuPath into using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(reader2)). // Clear the tile cache; def viewer = QPEx.getCurrentViewer(); def imageData = viewer.getImageData(); Platform.runLater {; viewer.setImageData(null); viewer.getImageRegionStore().clearCacheForServer(server); viewer.setImageData(imageData); }. // See https://github.com/openmicroscopy/bioformats/blob/master/components/formats-bsd/src/loci/formats/in/MinimalTiffReader.java; class LeicaSCNReaderRGB extends LeicaSCNReader {. /** Reinitialize the underlying TiffParser. */; protected void initTiffParser() {; QuPathGUI.getInstance().logger.info('INITIALIZING TIFF PARSER'); if (this.in == null) {; try {; this.in = new RandomAccessInputStream(getCurrentFile(), 16);; }; catch (IOException e) {; LOGGER.error(""Could not initialize stream"", e);; }; }; tiffParser = new TiffParserRGB(this.in);; tiffParser.setDoCaching(false);; tiffParser.setUse64BitOffsets(use64Bit);; }. }. class TiffParserRGB extends TiffParser {. public TiffParserRGB(RandomAccessInputStream stream) {; super(stream); }. public byte[] getTile(IFD ifd, byt",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/141#issuecomment-358985847:2026,cache,cache,2026,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358985847,2,['cache'],['cache']
Performance,rs.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:909); at qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.lib.images.servers.CroppedImageServer.readRegion(CroppedImageServer.java:90); at qupath.lib.images.servers.CroppedImageServer.readRegion(CroppedImageServer.java:39); at qupath.lib.images.servers.SparseImageServer.readTile(SparseImageServer.java:265); at qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:863); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:902); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:216); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Sou,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583:4001,concurren,concurrent,4001,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583,1,['concurren'],['concurrent']
Performance,rs.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:911); at qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.lib.images.servers.CroppedImageServer.readRegion(CroppedImageServer.java:90); at qupath.lib.images.servers.CroppedImageServer.readRegion(CroppedImageServer.java:39); at qupath.lib.images.servers.SparseImageServer.readTile(SparseImageServer.java:265); at qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:863); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:902); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:216); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Sou,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583:1367,concurren,concurrent,1367,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583,1,['concurren'],['concurrent']
Performance,runPlugin.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:214); at Script30.run(Script30.groovy:12); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by null at qupath.lib.images.servers.BioFormatsImageServer.getTimePoint(BioFormatsImageServer.java:930); at qupath.imagej.images.servers.BufferedImagePlusServer.getTimePoint(BufferedImagePlusServer.java:173); at qupath.imagej.helpers.IJTools.calibrateImagePlus(IJTools.java:220); at qupath.imagej.images.servers.BufferedImagePlusServer.readImagePlusRegion(BufferedImagePlusServer.java:241); at qupath.imagej.detect.tissue.SimpleTissueDetection2$GlobalThresholder.runDetection(SimpleTissueDetection2.java:158); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:120); at java.util.concurrent.Executors$RunnableAdapter.call(Exe,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:10563,concurren,concurrent,10563,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['concurren'],['concurrent']
Performance,"s *mostly ok*, except that it does rely on *hierarchy relationships* rather than *spatial relationships*.; Which is to say, it hasn't really changed since v0.1.2. **To Reproduce**; Create an arrangement of objects similar to that shown below:. ![0-orig](https://github.com/user-attachments/assets/cf1a87fc-c73a-4ac6-be24-d830f0014604). 1. If I run *Delaunay cluster features 2D* with **_all_ annotations selected**, I see triangulation lines which *do not cross the boundary between the annotations containing cells*. ![1-all selected](https://github.com/user-attachments/assets/3309e1e3-76ca-4ec7-bf5c-e0c76b8f2d96). But I **also** get a `ConcurrentModificationException`:; ```; 15:47:01.829	[Plugin thread]	ERROR	qupath.lib.plugins.AbstractTaskRunner	Error running plugin: java.util.ConcurrentModificationException	java.util.concurrent.ExecutionException: java.util.ConcurrentModificationException; 	at java.base/java.util.concurrent.FutureTask.report(Unknown Source); 	at java.base/java.util.concurrent.FutureTask.get(Unknown Source); 	at qupath.lib.plugins.AbstractTaskRunner.awaitCompletion(AbstractTaskRunner.java:147); 	at qupath.lib.plugins.AbstractTaskRunner.runTasks(AbstractTaskRunner.java:117); 	at qupath.lib.gui.TaskRunnerFX.runTasks(TaskRunnerFX.java:106); 	at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:147); 	at qupath.lib.gui.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:177); 	at java.base/java.lang.Thread.run(Unknown Source); Caused by: java.util.ConcurrentModificationException; 	at java.base/java.util.ArrayList$Itr.checkForComodification(Unknown Source); 	at java.base/java.util.ArrayList$Itr.next(Unknown Source); 	at java.base/java.util.Collections$UnmodifiableCollection$1.next(Unknown Source); 	at java.base/java.util.AbstractCollection.addAll(Unknown Source); 	at qupath.lib.objects.PathObjectTools.getAvailableFeatures(PathObjectTools.java:2026); 	at qupath.opencv.features.DelaunayTriangulation.<init>(DelaunayTriangulation.java:86); 	at",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1590:1269,concurren,concurrent,1269,https://qupath.github.io,https://github.com/qupath/qupath/issues/1590,1,['concurren'],['concurrent']
Performance,"s. However, as you say, this isn't a hardware memory limit problem, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/112#issuecomment-343336690:1407,concurren,concurrent,1407,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690,1,['concurren'],['concurrent']
Performance,"s.java). <h1>qupath.lib.analysis.stats.survival</h1>. - KaplanMeierData; 	1. Created tests (TestKaplanMeierData.java). <h1>qupath.lib.awt.common</h1>. - AwtTools; 	1. Created tests (TestAwtTools.java); 	2. Suppressed default constructor for non-instantiability; - BufferedImageTools; 	1. Created tests (TestBufferedImageTools.java); 	2. Suppressed default constructor for non-instantiability; 	3. Added 'breaks' to switch statement in setValues(...). <h1>qupath.lib.classifiers</h1>. - CompositeClassifier. 	1. Created tests (TestCompositeClassifier.java); 	2. Added comment in classifyPathObjects() to clarify the value of the returned int; - PathClassifierTools; 	1. Suppressed default constructor for non-instantiability; 	2. Fixed bug that did not handle missing measurement values (NaN) in setIntensityClassification(...). Now reset the PathClass to the non intensity ancestor class of the current object's one.; 	3. Throws an Exception if supplying an empty or null measurement name in setIntensityClassification(), as it can't perform classification without a measurement.; - PathIntensityClassifier; 	1. getRequiredMeasurements() with null measurement now returns an empty list to avoid NPE when calling getRequiredMeasurements() in CompositeClassifier; 	2. Fixed bug that did not handle missing measurement values (NaN) in setIntensityClassification(...). Now it does not change the class of the object if measurement is missing. Why? Because if we run a CompositeClassifier, one classifier's classification shouldn't be reset by the next one. <h1>qupath.lib.common</h1>. - ColorTools; 	1. Suppressed default constructor for non-instantiability.; 	2. Made class final.; - GeneralTools; 	1. Suppressed default constructor for non-instantiability.; 	2. Made class final.; 	3. Added some tests to existing tests.; 	4. Fixed blankString(...), which did not use the 'trim' param and was always trimming the input String.; 	5. Fixed isMultipartExtension(...) to account for String of length == 1.;",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/687:1429,perform,perform,1429,https://qupath.github.io,https://github.com/qupath/qupath/pull/687,1,['perform'],['perform']
Performance,sController.doPrivileged(Unknown Source); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$2(GlassViewEventHandler.java:450); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:424); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:449); at com.sun.glass.ui.View.handleMouseEvent(View.java:557); at com.sun.glass.ui.View.notifyMouse(View.java:943); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:184); at java.base/java.lang.Thread.run(Unknown Source); Caused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: OpenCV(4.5.3) D:\a\javacpp-presets\javacpp-presets\opencv\cppbuild\windows-x86_64\opencv-4.5.3\modules\core\src\channels.cpp:141: error: (-215:Assertion failed) i1 >= 0 && j < ndsts && dst[j].depth() == depth in function 'cv::mixChannels'. at java.base/java.util.concurrent.FutureTask.report(Unknown Source); at java.base/java.util.concurrent.FutureTask.get(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:222); ... 58 common frames omitted; Caused by: java.lang.RuntimeException: OpenCV(4.5.3) D:\a\javacpp-presets\javacpp-presets\opencv\cppbuild\windows-x86_64\opencv-4.5.3\modules\core\src\channels.cpp:141: error: (-215:Assertion failed) i1 >= 0 && j < ndsts && dst[j].depth() == depth in function 'cv::mixChannels'. at org.bytedeco.opencv.global.opencv_core.mixChannels(Native Method); at qupath.opencv.tools.OpenCVTools.mergeChannels(OpenCVTools.java:413); at qupath.opencv.ops.ImageOps$Core$SplitMergeOp.transformPadded(ImageOps.java:2511); at qupath.opencv.ops.ImageOps$Core$SplitMergeOp.apply(ImageOps.java:2470); at qupath.opencv.ops.ImageOps$ChannelImageDataOp.apply(ImageOps.java:425); at qupath.opencv.ops.ImageOpServer.readTile(ImageOpServer.java:98); at qupath.lib.images.servers.Abstrac,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/947:10079,concurren,concurrent,10079,https://qupath.github.io,https://github.com/qupath/qupath/issues/947,1,['concurren'],['concurrent']
Performance,"second ""mergeSelectedAnnotations();"" after ; resetSelection();; selectObjects { p -> p.getPathClass() == getPathClass(""NAMEofCLASS"") };. ERROR: Error at line 27: null. ERROR: Script error; at java.util.LinkedHashMap$LinkedHashIterator.nextNode(LinkedHashMap.java:719); at java.util.LinkedHashMap$LinkedKeyIterator.next(LinkedHashMap.java:742); at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042); at qupath.lib.scripting.QPEx.mergeAnnotations(QPEx.java:320); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:353); at qupath.lib.scripting.QPEx.mergeSelectedAnnotations(QPEx.java:309); at qupath.lib.scripting.QPEx$mergeSelectedAnnotations$0.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:198); at Script132.run(Script132.groovy:28); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/129#issuecomment-354857398:2258,concurren,concurrent,2258,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354857398,4,['concurren'],['concurrent']
Performance,"sis → Delaunay cluster features 2D* is not well-defined when applying the command to annotations that are nested (in the hierarchy) or overlapping. For 'flat' annotation arrangements the behavior is *mostly ok*, except that it does rely on *hierarchy relationships* rather than *spatial relationships*.; Which is to say, it hasn't really changed since v0.1.2. **To Reproduce**; Create an arrangement of objects similar to that shown below:. ![0-orig](https://github.com/user-attachments/assets/cf1a87fc-c73a-4ac6-be24-d830f0014604). 1. If I run *Delaunay cluster features 2D* with **_all_ annotations selected**, I see triangulation lines which *do not cross the boundary between the annotations containing cells*. ![1-all selected](https://github.com/user-attachments/assets/3309e1e3-76ca-4ec7-bf5c-e0c76b8f2d96). But I **also** get a `ConcurrentModificationException`:; ```; 15:47:01.829	[Plugin thread]	ERROR	qupath.lib.plugins.AbstractTaskRunner	Error running plugin: java.util.ConcurrentModificationException	java.util.concurrent.ExecutionException: java.util.ConcurrentModificationException; 	at java.base/java.util.concurrent.FutureTask.report(Unknown Source); 	at java.base/java.util.concurrent.FutureTask.get(Unknown Source); 	at qupath.lib.plugins.AbstractTaskRunner.awaitCompletion(AbstractTaskRunner.java:147); 	at qupath.lib.plugins.AbstractTaskRunner.runTasks(AbstractTaskRunner.java:117); 	at qupath.lib.gui.TaskRunnerFX.runTasks(TaskRunnerFX.java:106); 	at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:147); 	at qupath.lib.gui.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:177); 	at java.base/java.lang.Thread.run(Unknown Source); Caused by: java.util.ConcurrentModificationException; 	at java.base/java.util.ArrayList$Itr.checkForComodification(Unknown Source); 	at java.base/java.util.ArrayList$Itr.next(Unknown Source); 	at java.base/java.util.Collections$UnmodifiableCollection$1.next(Unknown Source); 	at java.base/java.util.AbstractCollection.addAll",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1590:1059,Concurren,ConcurrentModificationException,1059,https://qupath.github.io,https://github.com/qupath/qupath/issues/1590,1,['Concurren'],['ConcurrentModificationException']
Performance,"ssage, ""Failed to load one image."" is shown when trying to add one file at a time. **To Reproduce**; Steps to reproduce the behavior:; 1. Click on 'Create project' (make a new folder and name it); 2. Click on 'Add images'; 3. Click on 'choose files'; 4. Navigate to file and select it. ; 5. Click on 'Open'; 6. Click on 'Import'; 7. The result is either a pink thumbnail and pink image or an error message and no image added. **Expected behavior**; A clear and concise description of what you expected to happen:; All tif files should be added to the project and names and thumbnails should be visible on the left hand side of QuPath. Slide backgrounds should be white and not pink. (I know the background isn't actually pink because the files open correctly in ImageScope.). **Screenshots**; Pink background for TMA tiff files; ![2019-11-07_1304](https://user-images.githubusercontent.com/6699385/68389277-db8b8c80-0162-11ea-9a67-38f297589135.png). Failure to upload error message with the attempted upload file highlighted in the Windows window; ![2019-11-07_1334](https://user-images.githubusercontent.com/6699385/68389530-74baa300-0163-11ea-993d-a55b99b93934.png). **Desktop (please complete the following information):**; - OS: Windows 10 Enterprise version 1809; Intel i7; 64GB RAM (45 GB alotted for QuPath); - QuPath Version: 0.2.0-m5. **Additional context**; The accompanying .ndpi files for this data set load without issue. This problem was noticed because I tried to load png files for another data set that loaded in the previous version (Version: 0.1.2) but not the new version of QuPath. We realized the png files needed to be higher quality so they need to be rescanned at 40x and saved as tif files. Here I was testing to see if 40x tifs could successfully be analyzed using QuPath. The pink smaller tif files that do load appear to load and zoom correctly. The problem is the pink background and the inability to load the high resolution files that are needed for cell segmentation.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/374:2352,load,load,2352,https://qupath.github.io,https://github.com/qupath/qupath/issues/374,6,['load'],"['load', 'loaded']"
Performance,"st on GPUs. Tested with RTX 3090 and GTX 1660 Ti GPUs. I have a version of QuPath built on 2022-11-21 which has no problem running StarDist on the GPU, so it's likely tied to any commits between this period. Issue taken from forum post: https://forum.image.sc/t/stardist-gpu-support-unknown-error/74779. **To Reproduce**; Steps to reproduce the behavior:; 1. Build QuPath from source using the following command:; ```; git clone https://github.com/qupath/qupath; cd qupath; ./gradlew clean jpackage -Pcuda-redist; ```; 2. Install either the 0.3.2 or 0.4.0 releases of the StarDist extension: https://github.com/qupath/qupath-extension-stardist/releases; 3. Download pretrained models in .pb format; 4. Draw an annotation on a brightfield image; 5. Download the following script: https://github.com/MarkZaidi/Universal-StarDist-for-QuPath/blob/main/GPU_Multimodal%20StarDist%20Segmentation.groovy; 6. Run the script; 7. Observe the following error message:; ```; INFO: Performing detection on Brightfield image using single-channel trained model; INFO: [Annotation]; ERROR: OpenCV(4.6.0) D:\a\javacpp-presets\javacpp-presets\opencv\cppbuild\windows-x86_64-gpu\opencv-4.6.0\modules\dnn\src\cuda4dnn\csl\memory.hpp:54: error: (-217:Gpu API call) the provided PTX was compiled with an unsupported toolchain. in function 'cv::dnn::cuda4dnn::csl::ManagedPtr<float>::ManagedPtr'; in GPU_Multimodal StarDist Segmentation.groovy at line number -2. ERROR: org.bytedeco.opencv.opencv_dnn.Net.forward(Native Method); qupath.opencv.dnn.OpenCVDnn$OpenCVNetFunction.predict(OpenCVDnn.java:718); qupath.opencv.dnn.OpenCVDnn$OpenCVNetFunction.predict(OpenCVDnn.java:732); qupath.opencv.dnn.DnnModel.convertAndPredict(DnnModel.java:100); qupath.ext.stardist.StarDist2D.detectObjectsForTile(StarDist2D.java:1249); qupath.ext.stardist.StarDist2D.lambda$detectObjects$7(StarDist2D.java:934); java.base/java.util.stream.ReferencePipeline$7$1.accept(Unknown Source); java.base/java.util.ArrayList$ArrayListSpliterator.forEa",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1180:1687,Perform,Performing,1687,https://qupath.github.io,https://github.com/qupath/qupath/issues/1180,1,['Perform'],['Performing']
Performance,"still exists in 0.2.0m3, and with the additional problem that some multichannel images generate the following error. ERROR: Error running plugin: java.lang.IllegalArgumentException: No boolean parameter with key 'doMedian'; at java.base/java.util.concurrent.FutureTask.report(Unknown Source); at java.base/java.util.concurrent.FutureTask.get(Unknown Source); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:193); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:157); at qupath.lib.gui.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:156); at qupath.lib.algorithms.IntensityFeaturesPlugin.runPlugin(IntensityFeaturesPlugin.java:336); at qupath.lib.gui.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:185); at java.base/java.lang.Thread.run(Unknown Source); Caused by No boolean parameter with key 'doMedian' at qupath.lib.plugins.parameters.ParameterList.getBooleanParameterValue(ParameterList.java:379); at qupath.lib.plugins.parameters.ParameterList.getBooleanParameterValue(ParameterList.java:417); at qupath.lib.algorithms.IntensityFeaturesPlugin$MedianFeatureComputer.addMeasurements(IntensityFeaturesPlugin.java:945); at qupath.lib.algorithms.IntensityFeaturesPlugin.processObject(IntensityFeaturesPlugin.java:594); at qupath.lib.algorithms.IntensityFeaturesPlugin$IntensityFeatureRunnable.run(IntensityFeaturesPlugin.java:429); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/301#issuecomment-514482720:1530,concurren,concurrent,1530,https://qupath.github.io,https://github.com/qupath/qupath/issues/301#issuecomment-514482720,6,['concurren'],['concurrent']
Performance,t javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2623); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:411); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:301); at java.base/java.security.AccessController.doPrivileged(Unknown Source); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$2(GlassViewEventHandler.java:450); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:424); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:449); at com.sun.glass.ui.View.handleMouseEvent(View.java:557); at com.sun.glass.ui.View.notifyMouse(View.java:943); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:184); at java.base/java.lang.Thread.run(Unknown Source); Caused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: OpenCV(4.5.3) D:\a\javacpp-presets\javacpp-presets\opencv\cppbuild\windows-x86_64\opencv-4.5.3\modules\core\src\channels.cpp:141: error: (-215:Assertion failed) i1 >= 0 && j < ndsts && dst[j].depth() == depth in function 'cv::mixChannels'. at java.base/java.util.concurrent.FutureTask.report(Unknown Source); at java.base/java.util.concurrent.FutureTask.get(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:222); ... 58 common frames omitted; Caused by: java.lang.RuntimeException: OpenCV(4.5.3) D:\a\javacpp-presets\javacpp-presets\opencv\cppbuild\windows-x86_64\opencv-4.5.3\modules\core\src\channels.cpp:141: error: (-215:Assertion failed) i1 >= 0 && j < ndsts && dst[j].depth() == depth in function 'cv::mixChannels'. at org.bytedeco.opencv.global.opencv_core.mixChannels(Native Method); at qupath.opencv.tools.OpenCVTools.mergeChannels(OpenCVTools.java:413); at qupath.opencv.,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/947:9757,concurren,concurrent,9757,https://qupath.github.io,https://github.com/qupath/qupath/issues/947,1,['concurren'],['concurrent']
Performance,"t shouldn't, but if it does I wouldn't say it's necessarily a bug... since QuPath is already needing to do a *lot* of stuff to get acceptable performance across a wide range of scenarios. Specifically here:; * For a downsample >= 1, repainting detections caches tiles and multiple resolution levels for performance - this is why QuPath can handle millions of objects.; * For downsample < 1, repainting happens for all detections in the field of view (like for annotations) for improved appearance without nasty bitmap-upsampling artefacts. This is inevitably laggier than using cached tiles, but caching itself has considerable overhead in terms of memory and worse appearance. I think this tradeoff makes sense, since details really matter when viewing the image at high magnification but the number of objects visible should be limited (possibly thousands, but not millions). However it does mean that if you have a large enough monitor, many detections, and a downsample value slightly less than 1, performance there certainly can be a noticeable lag... and object connections make this worse by meaning that thousands more lines need to be rendered. However, investigating this revealed that QuPath was painting all the connections twice, which certainly wasn't helping things :). So the PR fixes the double-painting bug. Along the way, it adds a spatial cache that enables QuPath to be a bit smarter about which connections it paints. The main reason for this change is to overcome an issue with long connections sometimes being broken at some resolutions:. ### Old behavior:; ![connection_bug-1](https://user-images.githubusercontent.com/4690904/194024037-795fceaa-e542-4c67-8fa2-84e6a8aca691.png). ### New behavior:; ![connection_fix-1](https://user-images.githubusercontent.com/4690904/194024122-00080b78-b59b-4b8f-bf0d-aa990683268c.png). Together, I'm not certain whether or not you'll see a substantial improvement in performance - but these changes address any related bugs that I know of.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1069#issuecomment-1268167189:1595,cache,cache,1595,https://qupath.github.io,https://github.com/qupath/qupath/issues/1069#issuecomment-1268167189,2,"['cache', 'perform']","['cache', 'performance']"
Performance,"t sure if a crucial bug. Carried over from last release to v5. **To Reproduce**; Steps to reproduce the behavior:; 1. Ctl+Shift+A; 2. Run cell detection as a script:; ```; setImageType('FLUORESCENCE');; selectAnnotations();; runPlugin('qupath.imagej.detect.cells.WatershedCellDetection', '{""detectionImage"":""DAPI"",""requestedPixelSizeMicrons"":0.1,""backgroundRadiusMicrons"":4.0,""backgroundByReconstruction"":true,""medianRadiusMicrons"":1.0,""sigmaMicrons"":2.5,""minAreaMicrons"":11.0,""maxAreaMicrons"":400.0,""threshold"":1000.0,""watershedPostProcess"":true,""cellExpansionMicrons"":5.0,""includeNuclei"":true,""smoothBoundaries"":true,""makeMeasurements"":true}'); ```; 4. Error:; ```; ERROR: Error running plugin: java.lang.NullPointerException: Cannot invoke ""java.awt.image.BufferedImage.getSampleModel()"" because ""img"" is null; java.util.concurrent.ExecutionException: java.lang.NullPointerException: Cannot invoke ""java.awt.image.BufferedImage.getSampleModel()"" because ""img"" is null; at java.base/java.util.concurrent.FutureTask.report(Unknown Source); at java.base/java.util.concurrent.FutureTask.get(Unknown Source); at qupath.lib.plugins.AbstractTaskRunner.awaitCompletion(AbstractTaskRunner.java:147); at qupath.lib.plugins.AbstractTaskRunner.runTasks(AbstractTaskRunner.java:117); at qupath.lib.gui.TaskRunnerFX.runTasks(TaskRunnerFX.java:106); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:147); at qupath.lib.gui.QuPathGUI.runPlugin(QuPathGUI.java:2245); at qupath.lib.gui.scripting.QPEx.runPlugin(QPEx.java:248); at qupath.lib.gui.scripting.QPEx.runPlugin(QPEx.java:270); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript.run(QuPathScript:4); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:331); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:161); at qupath.lib.gui.scripting.languages.DefaultScriptLanguage.execute(DefaultScriptLanguage.java:234); at qup",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443:1466,concurren,concurrent,1466,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443,1,['concurren'],['concurrent']
Performance,"t(ROIs.createEmptyROI()); pathObjects << pathObject; for (int k = 0; k <= i; k++); pathObject.measurementList.put(""M_$k"", i); }); t.join(); ; println ""Done!""; ```. I see an exception; ```; ERROR: null; java.util.ConcurrentModificationException: null; at java.base/java.util.ArrayList$Itr.checkForComodification(Unknown Source); at java.base/java.util.ArrayList$Itr.next(Unknown Source); at java.base/java.util.Collections$UnmodifiableCollection$1.next(Unknown Source); at java.base/java.util.AbstractCollection.addAll(Unknown Source); at qupath.lib.objects.PathObjectTools.getAvailableFeatures(PathObjectTools.java:2026); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript$_run_closure1.doCall(QuPathScript:11); at QuPathScript$_run_closure1.doCall(QuPathScript); at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(Unknown Source); at java.base/java.lang.reflect.Method.invoke(Unknown Source); at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:343); at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:328); at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:279); at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1008); at groovy.lang.Closure.call(Closure.java:433); at groovy.lang.Closure.call(Closure.java:412); at groovy.lang.Closure.run(Closure.java:505); at java.base/java.lang.Thread.run(Unknown Source); ```. **Expected behavior**; The code runs without any exception. **Desktop (please complete the following information):**; - OS: macOS (but probably all); - QuPath Version: v0.5.1. **Additional context**; This seems to only occur with detections. The underlying issue in this specific case seems to be that these can return an unmodifiable list of measurement names, but when this is used by `PathObjectTools.getAvailableFeatures(Collection)` the underlying list is being modified. A fix may require revising `MeasurementList` more thoroughly",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1591:1895,Cache,CachedMethod,1895,https://qupath.github.io,https://github.com/qupath/qupath/issues/1591,1,['Cache'],['CachedMethod']
Performance,"t.FutureTask.run(Unknown Source); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); 	... 1 more; ```. 2. If I repeat with **the outer rectangle selected**, then I *do* see connections.; This is because the triangulation uses *all descendant detections below the rectangle, based on the object hierarchy*. ![2-rectangle](https://github.com/user-attachments/assets/21b82d18-ce97-45c3-9644-7abdf85ab007). 3. If I repeat with **the outer ellipse selected**, I get *no connections at all*.; This is because the ellipse isn't set to be a parent of any of the other objects - this would change if I called *Resolve hierarchy* first. ![3-ellipse](https://github.com/user-attachments/assets/3c39bea5-9a9c-4ae3-bcc9-7ece1e8bae9c). 4. If I repeat with **the inner rectangles selected**, I get connections that don't cross *and I don't get any exception*.; This is because each cell is only handled once, so I don't get the concurrency trouble. ![4-inner rectangles](https://github.com/user-attachments/assets/74edf4a3-05c0-49ea-bd38-f82d327d9564). 5. If I repeat with **only 1 inner rectangle selected**, I get connections within that rectangle only. ![5-single rectangle](https://github.com/user-attachments/assets/492cf523-c58d-4b48-b417-ac44662a7a5a). **Expected behavior**; This isn't obvious... Nevertheless:; 1. The `ConcurrentModificationException` is clearly bad. But it's also kind of helpful here, because 2. and 4. give different results... and when that's the case, if we select all the annotations in 2. and 4. in one go, it's not obvious what *should* happen.; 2. The reliance on hierarchical relationships may not be very intuitive to a user, since measurements like 'Positive %' are dynamically computed using spatial location relative to any selected annotation - not hierarchical relationships. **Desktop (please complete the following information):**; - OS: All; - QuPath Version:",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1590:3672,concurren,concurrency,3672,https://qupath.github.io,https://github.com/qupath/qupath/issues/1590,1,['concurren'],['concurrency']
Performance,t3.run(Script3.groovy:6); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:317); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:155); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:767); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:697); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.gui.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1288); at qupath.lib.gui.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1237); at javafx.concurrent.Task$TaskCallable.call(Task.java:1425); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); Caused by Java heap space at ij.process.FloatProcessor.snapshot(FloatProcessor.java:240); at ij.process.FloatProcessor.convolve(FloatProcessor.java:1069); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.doDetection(WatershedCellDetection.java:600); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:997); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:362); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.c,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:2582,concurren,concurrent,2582,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['concurren'],['concurrent']
Performance,"t> Collection<T> filterByROIIntersectsNucleus(ROI roi, Collection<T> pathObjects); public static <T extends PathObject> Collection<T> filterByROIContainsNucleusCentroid(ROI roi, Collection<T> pathObjects); ```. In case you just want to check if objects are present quickly - but don't necessarily need the objects themselves - you can use:. ```java; // Old method, deprecated; public boolean hasObjectsForRegion(Class<? extends PathObject> cls, ImageRegion region). // New methods; public boolean hasObjectsForRegion(ImageRegion region); public boolean hasAnnotationsForRegion(ImageRegion region); public boolean hasDetectionsForRegion(ImageRegion region); ```. These should effectively report whether `getXXXForRegion` would return an empty collection or not, without needing to generate that collection. ### Accessing objects with point ROIs; This simply accesses objects then filters by ROI type. ```java; // Old method, deprecated; public synchronized Collection<PathObject> getPointObjects(Class<? extends PathObject> cls). // New methods; public Collection<PathObject> getAllPointObjects(); public Collection<PathObject> getAllPointAnnotations() ; ```; This should be sufficiently obscure that there is no need to have separate methods to request point objects of more classes. If you *really* need point detections, for example. filtering the resulting collection should be straightforward, e.g.; ```java; var pointAnnotations = hierarchy.getAllPointObjects().stream().filter(PathObject::isDetection).toList();; ```. ---. To support these changes, `GeometryROI.contains(x, y)` was also updated to make use of an [`IndexedPointInAreaLocator`](https://locationtech.github.io/jts/javadoc/org/locationtech/jts/algorithm/locate/IndexedPointInAreaLocator.html) for complex geometries - enabling centroid tests to benefit from performance improvements with no special logic required outside the `ROI` class itself. Also, some deprecated methods - and deprecated classes that used them - were removed.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1563:6669,perform,performance,6669,https://qupath.github.io,https://github.com/qupath/qupath/pull/1563,1,['perform'],['performance']
Performance,"tProcessor.snapshot(FloatProcessor.java:240); at ij.process.FloatProcessor.convolve(FloatProcessor.java:1069); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.doDetection(WatershedCellDetection.java:600); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:997); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:362); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.cells.WatershedCellDetection {""detectionImageFluorescence"": 1, ""requestedPixelSizeMicrons"": 0.1, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 0.9, ""minAreaMicrons"": 6.0, ""maxAreaMicrons"": 150.0, ""threshold"": 2000.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 3.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Training size: org.bytedeco.javacpp.opencv_core$Size[address=0x608000811620,position=0,limit=1,capacity=1,deallocator=org.bytedeco.javacpp.Pointer$NativeDeallocator[ownerAddress=0x608000811620,deallocatorAddress=0x13aaec9c0]]; INFO: Responses size: org.bytedeco.javacpp.opencv_core$Size[address=0x60800080d2a0,position=0,limit=1,capacity=1,deallocator=org.bytedeco.javacpp.Pointer$NativeDealloc",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:3838,concurren,concurrent,3838,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['concurren'],['concurrent']
Performance,tTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:863); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:902); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:216); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by null at java.base/java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(Unknown Source); at java.base/java.util.concurrent.locks.ReentrantLock.lockInterruptibly(Unknown Source); at java.base/java.util.concurrent.ArrayBlockingQueue.put(Unknown Source); at qupath.lib.images.servers.bioformats.BioFormatsImageServer$ReaderPool.openImage(BioFormatsImageServer.java:1411); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:909); at qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); at java.base/java.util.concurrent.FutureTask.run(Unknow,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583:2254,concurren,concurrent,2254,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583,1,['concurren'],['concurrent']
Performance,tag: '71884c6'; 20:47:08.674 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Setting tile cache size to 8024.00 MB (25.0% max memory). (QuPath:8487): Gdk-WARNING **: 20:47:09.200: XSetErrorHandler() called with a GDK error trap pushed. Don't do that.; 20:47:09.626 [JavaFX Application Thread] [INFO ] qupath.lib.scripting.QP - Initializing type adapters; *** Error in `./QuPath': free(): invalid pointer: 0x00007f79411f0c80 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x81329)[0x7f82287f5329]; /lib64/libstdc++.so.6(_ZNSt6locale5_Impl16_M_install_facetEPKNS_2idEPKNS_5facetE+0x142)[0x7f7940f5a192]; /lib64/libstdc++.so.6(_ZNSt6locale5_ImplC1Em+0x1e3)[0x7f7940f5a5e3]; /lib64/libstdc++.so.6(+0x71555)[0x7f7940f5b555]; /lib64/libpthread.so.0(+0x620b)[0x7f822813720b]; /lib64/libstdc++.so.6(+0x715a1)[0x7f7940f5b5a1]; /lib64/libstdc++.so.6(_ZNSt6localeC2Ev+0x13)[0x7f7940f5b5e3]; /lib64/libstdc++.so.6(_ZNSt8ios_base4InitC2Ev+0xbc)[0x7f7940f5843c]; /home/grad3/jalal/.javacpp/cache/opencv-4.5.3-1.5.6-linux-x86_64.jar/org/bytedeco/opencv/linux-x86_64/libopencv_core.so.4.5(+0x64ddd)[0x7f7866536ddd]; /lib64/ld-linux-x86-64.so.2(+0xf9c3)[0x7f82290579c3]; /lib64/ld-linux-x86-64.so.2(+0x1459e)[0x7f822905c59e]; /lib64/ld-linux-x86-64.so.2(+0xf7d4)[0x7f82290577d4]; /lib64/ld-linux-x86-64.so.2(+0x13b8b)[0x7f822905bb8b]; /lib64/libdl.so.2(+0xfab)[0x7f8228e44fab]; /lib64/ld-linux-x86-64.so.2(+0xf7d4)[0x7f82290577d4]; /lib64/libdl.so.2(+0x15ad)[0x7f8228e455ad]; /lib64/libdl.so.2(dlopen+0x31)[0x7f8228e45041]; /scratch3/downloads/QuPath/lib/runtime/lib/server/libjvm.so(+0xc57924)[0x7f8227786924]; /scratch3/downloads/QuPath/lib/runtime/lib/server/libjvm.so(+0xc57a5a)[0x7f8227786a5a]; /scratch3/downloads/QuPath/lib/runtime/lib/server/libjvm.so(JVM_LoadLibrary+0xbb)[0x7f822745bd6b]; /scratch3/downloads/QuPath/lib/runtime/lib/libjava.so(Java_jdk_internal_loader_NativeLibraries_load+0x17f)[0x7f822544627f]; [0x7f820e860bbb]; ======= Memory map: ========; 414cb000-414cd000 r-xs 000,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018:2457,cache,cache,2457,https://qupath.github.io,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018,1,['cache'],['cache']
Performance,"th.lib.gui.QuPathGUI - No directory set for log files! None will be written.; 10:11:47.048 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - QuPath build: Version: 0.2.0-m4; Build time: 2019-08-20, 20:38; Latest commit tag: 'e9b60579'; 10:11:47.051 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Setting tile cache size to 1996.50 MB (25.0% max memory). (QuPath-0.2.0-m4:17581): Gdk-WARNING **: 10:11:47.691: XSetErrorHandler() called with a GDK error trap pushed. Don't do that.; 10:11:48.207 [JavaFX Application Thread] [INFO ] q.l.i.s.b.BioFormatsOptionsExtension - Bio-Formats version 6.2.0; 10:11:48.216 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Bio-Formats server options (Bio-Formats 6.2.0) (20 ms); 10:11:48.235 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Experimental commands (19 ms); 10:11:48.278 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension ImageJ extension (42 ms); 10:11:48.290 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension JPen extension (12 ms); 10:11:48.294 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension OpenCV extensions (3 ms); Oct 13, 2019 10:11:48 AM jpen.provider.NativeLibraryLoader$4 run; INFO: loading JPen 2-150301 JNI library: jpen-2-4-x86_64 ...; Oct 13, 2019 10:11:48 AM jpen.provider.NativeLibraryLoader$4 run; INFO: jpen-2-4-x86_64 loaded; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.codehaus.groovy.vmplugin.v7.Java7$1 (file:/usr/local/src/QuPath-0.2.0-m4/app/groovy-2.5.7.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class,int); WARNING: Please consider reporting this to the maintainers of org.codehaus.groovy.vmplugin.v7.Java7$1; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operation",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/369:2245,Load,Loaded,2245,https://qupath.github.io,https://github.com/qupath/qupath/issues/369,1,['Load'],['Loaded']
Performance,th/lib/runtime/lib/libawt.so; 7f7942bd0000-7f7942bdb000 rw-p 0009e000 fd:02 10819064500 /scratch3/downloads/QuPath/lib/runtime/lib/libawt.so; 7f7942bdb000-7f7942d00000 rw-p 00000000 00:00 0 ; 7f7942d00000-7f7942e00000 rw-p 00000000 00:00 0 ; 7f7942e00000-7f7943100000 rw-p 00000000 00:00 0 ; 7f7943100000-7f79431f0000 rw-p 00000000 00:00 0 ; 7f79431f0000-7f7943200000 ---p 00000000 00:00 0 ; 7f7943200000-7f7943400000 rw-p 00000000 00:00 0 ; 7f794343c000-7f79434ec000 r--p 00000000 fd:03 721040943 /scratch/usr-shr/share/fonts/dejavu/DejaVuSans.ttf; 7f79434ec000-7f79434f0000 r-xp 00000000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79434f0000-7f79436ef000 ---p 00004000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79436ef000-7f79436f0000 r--p 00003000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79436f0000-7f79436f1000 rw-p 00004000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79436f1000-7f79436f6000 r-xp 00000000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79436f6000-7f79438f5000 ---p 00005000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f5000-7f79438f6000 r--p 00004000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f6000-7f79438f7000 rw-p 00005000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f7000-7f79438fa000 r-xp 00000000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f79438fa000-7f7943af9000 ---p 00003000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f7943af9000-7f7943afa000 r--p 00002000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f7943afa000-7f7943afb000 rw-p 00003000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so;,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018:18371,cache,cache,18371,https://qupath.github.io,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018,1,['cache'],['cache']
Performance,tic(CallSiteArray.java:55); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:196); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:216); at Script3.run(Script3.groovy:6); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:317); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:155); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:767); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:697); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.gui.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1288); at qupath.lib.gui.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1237); at javafx.concurrent.Task$TaskCallable.call(Task.java:1425); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); Caused by Java heap space at ij.process.FloatProcessor.snapshot(FloatProcessor.java:240); at ij.process.FloatProcessor.convolve(FloatProcessor.java:1069); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.doDetection(WatershedCellDetection.java:600); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:997); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:362); at qupath.lib.plugins.DetectionPluginTools$Detecti,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:2354,concurren,concurrent,2354,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['concurren'],['concurrent']
Performance,"time to load. Opening the images themselves is comparatively faster, yet are still read into memory. No noticeable change in memory usage is occurring when the QuPath project is being loaded, indicating that these images may not be pre-loaded (i.e. cached) during loading of the project itself. My guess is that the thumbnails are being reconstructed each time the QuPath project is loaded (computer must be restarted to reproduce, closing and relaunching QuPath is not sufficient). Given that thumbnail generation was updated in the changelog of the newest unofficial release, I'll build from source now and close the ticket if I can't reproduce the bug. It's a minor inconvenience at best, especially since it's only a delay of two minutes. But keep in mind, the CPU here is a Ryzen 5950X with among the highest single thread speeds of desktop CPUs, and only 1 of the 32 threads is being used during this period. Depending on the root cause and a user's hardware configuration, load times may scale linearly or exponentially as project sizes move into the range of thousands of images. If this is caused by thumbnail generation, then this may only be affecting multiplexed IHC images such as those acquired through IMC or CODEX. **To Reproduce**; Video demonstration: https://www.youtube.com/watch?v=q4Jn9UTKUMw; 1. Create a QuPath project; 2. Load ~300 IMC images. Example IMC images can be found here: https://drive.google.com/file/d/1UcQmiIcjIfYdBVK1v6Phb32FBjHXciuH/view; 3. Close QuPath and restart system; 4. Launch QuPath and open the aforementioned project. Observe relatively long project load times. **Expected behavior**; Loading of a QuPath project should take a few seconds, especially if no measurements are present. **Screenshots**; See video demonstration above. Note, memory usage doesn't change substantially when project is being loaded, however one thread is maxed at 100%, indicating that some kind of non-parallelized process is acting as the rate limiting step. **Desktop (ple",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1154:1724,load,load,1724,https://qupath.github.io,https://github.com/qupath/qupath/issues/1154,1,['load'],['load']
Performance,time/lib/libawt.so; 7f7942bdb000-7f7942d00000 rw-p 00000000 00:00 0 ; 7f7942d00000-7f7942e00000 rw-p 00000000 00:00 0 ; 7f7942e00000-7f7943100000 rw-p 00000000 00:00 0 ; 7f7943100000-7f79431f0000 rw-p 00000000 00:00 0 ; 7f79431f0000-7f7943200000 ---p 00000000 00:00 0 ; 7f7943200000-7f7943400000 rw-p 00000000 00:00 0 ; 7f794343c000-7f79434ec000 r--p 00000000 fd:03 721040943 /scratch/usr-shr/share/fonts/dejavu/DejaVuSans.ttf; 7f79434ec000-7f79434f0000 r-xp 00000000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79434f0000-7f79436ef000 ---p 00004000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79436ef000-7f79436f0000 r--p 00003000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79436f0000-7f79436f1000 rw-p 00004000 00:2f 2306019409 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_pango.so; 7f79436f1000-7f79436f6000 r-xp 00000000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79436f6000-7f79438f5000 ---p 00005000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f5000-7f79438f6000 r--p 00004000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f6000-7f79438f7000 rw-p 00005000 00:2f 2306019407 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font_freetype.so; 7f79438f7000-7f79438fa000 r-xp 00000000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f79438fa000-7f7943af9000 ---p 00003000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f7943af9000-7f7943afa000 r--p 00002000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f7943afa000-7f7943afb000 rw-p 00003000 00:2f 2306019406 /home/grad3/jalal/.openjfx/cache/17.0.1/libjavafx_font.so; 7f7943afb000-7f7943aff000 ---p 00000000 00:00 0 ; 7f7943aff000-7f7943bfc000 rw-p 00000000 00:00 0 ; 7f7943bfc000-7f7943c0,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018:18493,cache,cache,18493,https://qupath.github.io,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018,1,['cache'],['cache']
Performance,"tive Method). at com.sun.glass.ui.win.WinApplication.lambda$null$147(WinApplication.java:177). at java.lang.Thread.run(Thread.java:748). INFO: Selected style: Modena Light. INFO: Performing update check... INFO: Starting QuPath with parameters: []. . I deinstalled the other version but there it did work without any problems. Is there any way to deinstall qupath so that I can try to install it again?. . Best,. Marcel. . . Von: Pete [mailto:notifications@github.com] ; Gesendet: Dienstag, 7. August 2018 03:02; An: qupath/qupath; Cc: 2010mars2010; Author; Betreff: Re: [qupath/qupath] touch gestures: zooms when moving up/down (#188). . I only got one problem: QuPath cannot open any *.svs (scanscope virtual slide) images any more. Do you have a solution for that?. I this running on Windows 10, and are there any errors under View → Show log when you try to open an .svs file? Does it work with the other version of QuPath on the same machine (v0.1.2)?. My guess is that OpenSlide isn't loading for you, but it's the same version as in v0.1.2... so it one works, then I'd expect the other to work as well. If you were running QuPath from an IDE (e.g. IntelliJ, eclipse) then paths would also need to be set for OpenSlide to work, and that would be an explanation. But if instead you follow the step by step instructions <https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html#step-by-step-guide> right to the end, it should result in a QuPath.exe file that work if you double-click it without any further effort. The other option is to install the latest QuPath Bio-Formats extension <https://github.com/qupath/qupath-bioformats-extension> ... but it shouldn't be necessary for standard .svs files. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub <https://github.com/qupath/qupath/issues/188#issuecomment-410954902> , or mute the thread <https://github.com/notifications/unsubscribe-auth/Ans9t66btf2pNKUFzGRoCitGUIq4Cyj0ks",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/188#issuecomment-411621646:2404,load,loading,2404,https://qupath.github.io,https://github.com/qupath/qupath/issues/188#issuecomment-411621646,1,['load'],['loading']
Performance,"tive cells in different images and combining the results could potentially cause practical problems in terms of partially overlapping cells, which might have differing positive/negative classifications depending upon staining localization and intensity... resulting in a confusing or unexpected result. Therefore, to avoid this situation, it is not supported. I would suggest applying your detection using optical density sum, but adjusting the other parameters to try to obtain a better result. In particular, . * Increasing/decreasing 'Threshold' under *Intensity parameters*; * Either increasing 'Background radius', or setting the value to zero (to eliminate background subtraction altogether) - this is mostly relevant if the cells in the image is particularly large or densely-packed. Use of the brightness/contrast tool (as described [here](https://github.com/qupath/qupath/wiki/Changing-colors#the-brightnesscontrast-tool)) to separate stains, along with the pixel intensity values shown in the bottom right of the viewer, can help figure out appropriate values for the intensity threshold. This can also help you see how cleanly the hematoxylin and DAB have been separated. If the stain separation is not particularly good, the documentation on [Estimating stain vectors](https://github.com/qupath/qupath/wiki/Preprocessing#estimate-stain-vectors) and [CD3 analysis](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis#estimate-stain-vectors-watch) show how this may be improved. Your other option for Ki67 would be to use *Fast cell counts* - as documented for [CD3](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis). This gives another method of detection that may sometimes perform better (and sometimes less well). But since it only creates a single point for each cell (rather than detecting the full cell), it is best used for defined regions of interest... when you don't need to use the full cell information to train QuPath to distinguish between tumor and non-tumor cells.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/46#issuecomment-275932246:1845,perform,perform,1845,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-275932246,1,['perform'],['perform']
Performance,tractCallSite.callStatic(AbstractCallSite.java:196); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:216); at Script3.run(Script3.groovy:6); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:317); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:155); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:767); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:697); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.gui.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1288); at qupath.lib.gui.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1237); at javafx.concurrent.Task$TaskCallable.call(Task.java:1425); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); Caused by Java heap space at ij.process.FloatProcessor.snapshot(FloatProcessor.java:240); at ij.process.FloatProcessor.convolve(FloatProcessor.java:1069); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.doDetection(WatershedCellDetection.java:600); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:997); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:362); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.c,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:2425,concurren,concurrent,2425,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['concurren'],['concurrent']
Performance,"ugh I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:. // Print the current memory situation. def runtime = Runtime.getRuntime(). double scale = 1.0/1024.0/1024.0. print 'Max memory (MB): ' + (runtime.maxMemory() * scale). print 'Total memory (MB): ' + (runtime.totalMemory() * scale). print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache. javafx.application.Platform.runLater {. getCurrentViewer().getImageRegionStore().cache.clear(). System.gc(). }. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/130#issuecomment-355845333>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AhgDyN_FkkG6m9PVrCtutL6J2PYQHVfHks5tIRihgaJpZM4RUCsS>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/130#issuecomment-355877016:1858,cache,cache,1858,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355877016,2,['cache'],['cache']
Performance,ui.commands.ProjectImportImagesCommand$1.lambda$call$1(ProjectImportImagesCommand.java:278); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(Unknown Source); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); at java.base/java.util.stream.ForEachOps$ForEachTask.compute(Unknown Source); at java.base/java.util.concurrent.CountedCompleter.exec(Unknown Source); at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); at java.base/java.util.concurrent.ForkJoinTask.doInvoke(Unknown Source); at java.base/java.util.concurrent.ForkJoinTask.invoke(Unknown Source); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateParallel(Unknown Source); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(Unknown Source); at java.base/java.util.stream.AbstractPipeline.evaluate(Unknown Source); at java.base/java.util.stream.ReferencePipeline.forEach(Unknown Source); at java.base/java.util.stream.ReferencePipeline$Head.forEach(Unknown Source); at qupath.lib.gui.commands.ProjectImportImagesCommand$1.call(ProjectImportImagesCommand.java:276); at qupath.lib.gui.commands.ProjectImportImagesCommand$1.call(ProjectImportImagesCommand.java:236); at javafx.concurrent.Task$TaskCallable.call(Task.java:1425); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); 14:59:04.778 [JavaFX Application Thread] [ERROR] qupath.lib.gui.dialogs.Dialogs - Import images: Failed to load one image.; 14:59:04.806 [JavaFX Application Thread] [INFO ] q.l.g.c.ProjectImportImagesCommand -; ```,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/396:2780,concurren,concurrent,2780,https://qupath.github.io,https://github.com/qupath/qupath/issues/396,7,"['concurren', 'load']","['concurrent', 'load']"
Performance,uild ImageServer for file:/D:/Random%20for%20core/qupath%20to%20csv/2016-08-11%20%2006_Flattened-Create%20Image%20Subset-01.czi (args=[]); at qupath.lib.images.servers.ImageServerBuilder$DefaultImageServerBuilder.buildOriginal(ImageServerBuilder.java:323); at qupath.lib.images.servers.ImageServerBuilder$AbstractServerBuilder.build(ImageServerBuilder.java:147); at qupath.lib.gui.commands.ProjectImportImagesCommand.initializeEntry(ProjectImportImagesCommand.java:505); at qupath.lib.gui.commands.ProjectImportImagesCommand$1.lambda$call$1(ProjectImportImagesCommand.java:278); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(Unknown Source); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); at java.base/java.util.stream.ForEachOps$ForEachTask.compute(Unknown Source); at java.base/java.util.concurrent.CountedCompleter.exec(Unknown Source); at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); at java.base/java.util.concurrent.ForkJoinTask.doInvoke(Unknown Source); at java.base/java.util.concurrent.ForkJoinTask.invoke(Unknown Source); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateParallel(Unknown Source); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(Unknown Source); at java.base/java.util.stream.AbstractPipeline.evaluate(Unknown Source); at java.base/java.util.stream.ReferencePipeline.forEach(Unknown Source); at java.base/java.util.stream.ReferencePipeline$Head.forEach(Unknown Source); at qupath.lib.gui.commands.ProjectImportImagesCommand$1.call(ProjectImportImagesCommand.java:276); at qupath.lib.gui.commands.ProjectImportImagesCommand$1.call(ProjectImportImagesCommand.java:236); at javafx.concurrent.Task$TaskCallable.call(Task.java:1425); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/396:1980,concurren,concurrent,1980,https://qupath.github.io,https://github.com/qupath/qupath/issues/396,1,['concurren'],['concurrent']
Performance,"ullObject.invokeMethod(NullObject.java:91); at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:48); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.NullCallSite.call(NullCallSite.java:35); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:117); at Script1.run(Script1.groovy:18); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:757); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:687); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:669); at qupath.lib.scripting.DefaultScriptEditor.access$3(DefaultScriptEditor.java:659); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:979); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). I should say that I wasn't able to copy libjep.jnilib as it doesn't exist on my system, instead it's called libjep.so. I don't know if that might be causing some problem. . I am quite keen to run some python image processing code that I have via QuPath so I will keep on helping with this if I am able. Just getting the jep connection running would let me see if I can begin to work on wrapping/exchanging data issues. Thanks!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/27#issuecomment-262778143:1511,concurren,concurrent,1511,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262778143,4,['concurren'],['concurrent']
Performance,"umor: Negative` - where both come from a base `Tumor` classification (represented by a `PathClass` object). QuPath aims to ensure that every classification and derived classification is a singleton, i.e. it exists only once. This means that requesting the parent class for `Tumor: Positive` and `Tumor: Negative` should always return the exact same classification object, and that should be identical to what is returned by `QP.getPathClass('Tumor')`. The issue is that whenever a derived classification is *reloaded* in QuPath v0.4.x, a necessary check is missed and this makes it possible for the parent classification of `Tumor: Positive` and `Tumor: Negative` to *not* be identical to the result of `QP.getPathClass('Tumor')`. This could potentially cause confusion when attempting to count objects that share the same classification. **To Reproduce**; The bug is hard to reproduce, and I don't know of any way to reproduce it within a single QuPath session. It requires data to be saved, and then loaded into a new QuPath session (i.e. after closing QuPath and reopening it, or running QuPath on a different computer). Steps to reproduce the behavior:; 1. Perform a workflow that creates derived classifications, e.g. [positive tumor cell classification](https://qupath.readthedocs.io/en/0.4/docs/tutorials/cell_classification.html); 2. Save the data, restart QuPath, reload the data; 3. Run a script such as the following to count the objects with a specified base classification; ```groovy; println getCellObjects().count {; it.getPathClass().getBaseClass() === getPathClass('Tumor')}; ```; 4. Check that the printed count is 0, even if objects can be found with the specified base classification in the image. **Expected behavior**; Classifications should always be singletons. Given a derived classification, requesting the parent classification should always give the same result as if the parent was created separately. **Screenshots**; The screenshot below shows the issue. According to t",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1306:2061,load,loaded,2061,https://qupath.github.io,https://github.com/qupath/qupath/issues/1306,1,['load'],['loaded']
Performance,"un(DefaultScriptEditor.java:1033); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by No double parameter with key 'haralickMin' at qupath.lib.plugins.parameters.ParameterList.getDoubleParameterValue(ParameterList.java:386); at qupath.lib.plugins.parameters.ParameterList.getDoubleParameterValue(ParameterList.java:427); at qupath.lib.algorithms.IntensityFeaturesPlugin$HaralickFeaturesComp.updateFeatures(IntensityFeaturesPlugin.java:1056); at qupath.lib.algorithms.IntensityFeaturesPlugin.processObject(IntensityFeaturesPlugin.java:628); at qupath.lib.algorithms.IntensityFeaturesPlugin$IntensityFeatureRunnable.run(IntensityFeaturesPlugin.java:454); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); INFO: Processing complete in 0.01 seconds; INFO: ; qupath.lib.algorithms.IntensityFeaturesPlugin {""pixelSizeMicrons"": 2.0, ""region"": ""ROI"", ""tileSizeMicrons"": 25.0, ""colorOD"": true, ""colorStain1"": true, ""colorStain2"": true, ""colorStain3"": false, ""colorRed"": false, ""colorGreen"": false, ""colorBlue"": false, ""colorHue"": false, ""colorSaturation"": false, ""colorBrightness"": false, ""doMean"": false, ""doStdDev"": false, ""doMinMax"": false, ""doMedian"": false, ""doHaralick"": true, ""haralickDistance"": 1, ""haralickBins"": 32}; INFO: ",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/358:2974,concurren,concurrent,2974,https://qupath.github.io,https://github.com/qupath/qupath/issues/358,1,['concurren'],['concurrent']
Performance,"useInstanceLabels() replaces useUniqueLabels(), and new getInstanceLabels() method can be used to query labels later.; Improved performance when working with large numbers of objects and better parallelization.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/787:128,perform,performance,128,https://qupath.github.io,https://github.com/qupath/qupath/pull/787,1,['perform'],['performance']
Performance,"ushed. Don't do that.; 12:07:42.748 [JavaFX Application Thread] [INFO ] q.l.i.s.b.BioFormatsOptionsExtension - Bio-Formats version 6.0.0; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.codehaus.groovy.vmplugin.v7.Java7$1 (file:/home/joelrv/software/opt/QuPath/qupath_0.2.0-m1/app/groovy-2.5.6.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class,int); WARNING: Please consider reporting this to the maintainers of org.codehaus.groovy.vmplugin.v7.Java7$1; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 12:07:43.276 [JavaFX Application Thread] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1; 12:07:43.360 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: null; 12:07:43.360 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 12:07:43.365 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 12:08:18.669 [JavaFX Application Thread] [WARN ] q.l.i.s.o.OpenslideImageServer - Openslide: Property 'openslide.mpp-x' not available, will return default value NaN; 12:08:18.670 [JavaFX Application Thread] [WARN ] q.l.i.s.o.OpenslideImageServer - Openslide: Property 'openslide.mpp-y' not available, will return default value NaN; 12:08:18.670 [JavaFX Application Thread] [WARN ] q.l.i.s.o.OpenslideImageServer - Openslide: Property 'openslide.objective-power' not available, will return default value NaN; 12:08:18.677 [JavaFX Application Thread] [WARN ] q.l.i.s.o.OpenslideServerBuilder - Unable to open file:/media/joelrv/SDB/Dropbox/PhD/ST_Thyroid/r_plotting/input_data/new_sample/ndpi_and_tifs/st1_d1_HE_final.tif with OpenSlide: Pixel width must be a finite number > 0, not NaN; 12:08:19.076 [JavaFX Application Thread] [INFO ] loci.formats.ImageReader - Tif",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/279:2230,Perform,Performing,2230,https://qupath.github.io,https://github.com/qupath/qupath/issues/279,1,['Perform'],['Performing']
Performance,va.security.AccessController.doPrivileged(Unknown Source); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragDrop(GlassSceneDnDEventHandler.java:104); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragDrop$11(GlassViewEventHandler.java:766); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:412); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragDrop(GlassViewEventHandler.java:765); at com.sun.glass.ui.View.handleDragDrop(View.java:713); at com.sun.glass.ui.View.notifyDragDrop(View.java:1042); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:174); at java.base/java.lang.Thread.run(Unknown Source); Caused by null at qupath.lib.projects.DefaultProject.loadPathClasses(DefaultProject.java:1130); at qupath.lib.projects.DefaultProject.loadProject(DefaultProject.java:1086); at qupath.lib.projects.DefaultProject.loadFromFile(DefaultProject.java:171); at qupath.lib.projects.ProjectIO.loadProject(ProjectIO.java:97); at qupath.lib.gui.viewer.DragDropFileImportListener.handleFileDropImpl(DragDropFileImportListener.java:248); at qupath.lib.gui.viewer.DragDropFileImportListener.handleFileDrop(DragDropFileImportListener.java:158); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:126); at qupath.lib.gui.viewer.DragDropFileImportListener.handle(DragDropFileImportListener.java:64); at com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:234); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:191); at com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDispatcher.java:59); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:58); at com.sun.ja,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/613#issuecomment-708516373:2996,load,loadFromFile,2996,https://qupath.github.io,https://github.com/qupath/qupath/issues/613#issuecomment-708516373,1,['load'],['loadFromFile']
Performance,va:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:206); at Script30.run(Script30.groovy:10); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ERROR: Error running plugin: java.lang.NullPointerException; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.scripting.QPEx.runPlugin(QPEx.java:266); at qupath.lib.scripting.QPEx.runPlugin(QPEx.java:286); at qupath.lib.scripting.QPEx$runPlugin.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.gro,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:8811,concurren,concurrent,8811,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['concurren'],['concurrent']
Performance,va:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:206); at Script30.run(Script30.groovy:10); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ERROR: QuPath exception; at com.sun.glass.ui.Application.checkEventThread(Application.java:443); at com.sun.glass.ui.View.getNativeView(View.java:449); at com.sun.glass.ui.win.WinAccessible.get_HostRawElementProvider(WinAccessible.java:672); at com.sun.glass.ui.win.WinAccessible.UiaRaiseAutomationEvent(Native Method); at com.sun.glass.ui.win.WinAccessible.sendNotification(WinAccessible.java:287); at javafx.scene.Node.notifyAccessibleAttributeChanged(Node.java:9604); at javafx.scene.control.TableView$TableViewSelectionModel.focus(TableView.java:2003); at javafx.scene.control.TableView$TableViewArrayListSelectionModel.updateDefaultSelection(TableView.java:2930); at javafx.scene.control.TableView$TableViewArrayListSelectionModel.updateItemsObserver(TableView.java:2907); at javafx.scene.control.TableView$TableViewArrayListSelectionModel.access$2000(TableView.java:2028); at javafx.scen,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:5349,concurren,concurrent,5349,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['concurren'],['concurrent']
Performance,va:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:214); at Script30.run(Script30.groovy:12); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by null at qupath.lib.images.servers.BioFormatsImageServer.getTimePoint(BioFormatsImageServer.java:930); at qupath.imagej.images.servers.BufferedImagePlusServer.getTimePoint(BufferedImagePlusServer.java:173); at qupath.imagej.helpers.IJTools.calibrateImagePlus(IJTools.java:220); at qupath.imagej.images.servers.BufferedImagePlusServer.readImagePlusRegion(BufferedImagePlusServer.java:241); at qupath.imagej.detect.tissue.SimpleTissueDetection2$GlobalThresholder.runDetection(SimpleTissueDetection2.java:158); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:120); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at ja,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:10784,concurren,concurrent,10784,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['concurren'],['concurrent']
Performance,"ve my problem, but reporting a potential bug. I'm fine with using 0.2.0-m5. I've already read the sentence you quoted, also the sentence right after it:. > If you find bugs, please report them on GitHub or image.sc - don’t just stick with an older milestone that seemed to work!. And this one under object hierarchy section:. > Things that worked before should still work (if they don’t, please report the bug!). To reproduce:. 1. Create a project in m5, import an image; 2. Copy this qpdata to the project entry: [data.zip](https://github.com/qupath/qupath/files/3857086/data.zip); 3. Open project with m6. I don't recall the version that created this qpdata file, but it works with m5. It contains some non-hierarchical annotations. Stack trace:. > INFO: Bio-Formats version 6.3.0; INFO: Loaded extension Bio-Formats server options (Bio-Formats 6.3.0) (27 ms); INFO: Loaded extension Experimental commands (26 ms); INFO: Loaded extension ImageJ extension (90 ms); INFO: Loaded extension JPen extension (34 ms); INFO: Loaded extension OpenCV extensions (4 ms); INFO: Loaded extension Rich script editor extension (562 ms); INFO: OpenSlide version 3.4.1; INFO: Selected style: null; INFO: Performing update check...; WARN: No changelog found - will not check for updates; INFO: Starting QuPath with parameters: []; INFO: Project set to Project: deneme-project; WARN: Openslide: Property 'openslide.mpp-x' not available, will return default value NaN; WARN: Openslide: Property 'openslide.mpp-y' not available, will return default value NaN; WARN: Openslide: Property 'openslide.objective-power' not available, will return default value NaN; INFO: Image data set to ImageData: Not set, B-11285-15_2.tif; ERROR: QuPath exception: missing initial moveto in path definition; at java.desktop/java.awt.geom.Path2D$Float.needRoom(Unknown Source); at java.desktop/java.awt.geom.Path2D.closePath(Unknown Source); at qupath.lib.roi.ShapeSimplifier.simplifyPath(ShapeSimplifier.java:310); at qupath.lib.gui.viewe",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/376#issuecomment-554873027:898,Load,Loaded,898,https://qupath.github.io,https://github.com/qupath/qupath/issues/376#issuecomment-554873027,5,['Load'],['Loaded']
Performance,version. Problem is that it detects cuda 12.1 so maybe it does not even want to try to load the CPU version?. `Failed to load PyTorch native library; ai.djl.engine.EngineException: Failed to load PyTorch native library; 	at ai.djl.pytorch.engine.PtEngine.newInstance(PtEngine.java:90); 	at ai.djl.pytorch.engine.PtEngineProvider.getEngine(PtEngineProvider.java:41); 	at ai.djl.engine.Engine.getEngine(Engine.java:190); 	at qupath.ext.instanseg.core.PytorchManager.lambda$getEngineOnline$0(PytorchManager.java:28); 	at qupath.ext.instanseg.core.PytorchManager.callWithTempProperty(PytorchManager.java:114); 	at qupath.ext.instanseg.core.PytorchManager.callOnline(PytorchManager.java:106); 	at qupath.ext.instanseg.core.PytorchManager.getEngineOnline(PytorchManager.java:28); 	at qupath.ext.instanseg.ui.InstanSegController.downloadPyTorch(InstanSegController.java:826); 	at qupath.ext.instanseg.ui.InstanSegController.ensurePyTorchAvailable(InstanSegController.java:815); 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(Unknown Source); 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.exec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source); Caused by: java.lang.UnsatisfiedLinkError: C:\Users\username\.djl.ai\pytorch\2.3.1-cu121-win-x86_64\cudnn_cnn_infer64_8.dll: The specified procedure could not be found; 	at java.base/jdk.internal.loader.NativeLibraries.load(Native Method); 	at java.base/jdk.internal.loader.NativeLibraries$NativeLibraryImpl.open(Unknown Source); 	at java.base/jdk.internal.loader.NativeLibraries.loadLibrary(Unknown Source); 	at java.base/jdk.internal.loader.NativeLibraries.loadLibrary(Unkn,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1636:1139,concurren,concurrent,1139,https://qupath.github.io,https://github.com/qupath/qupath/issues/1636,1,['concurren'],['concurrent']
Performance,"windows-x86_64\opencv-4.5.3\modules\core\src\channels.cpp:141: error: (-215:Assertion failed) i1 >= 0 && j < ndsts && dst[j].depth() == depth in function 'cv::mixChannels'`. OpenCV's mixChannels: https://docs.opencv.org/3.4/d2/de8/group__core__array.html#ga51d768c270a1cdd3497255017c4504be. For now, I've been reducing the number of channels passed, which gives me a training accuracy of ~88%. But it would be great to train on all available data, and see what the variable importance is of each feature and channel. **To Reproduce**; Steps to reproduce the behavior:; 1. Create a project with ~143 IMC images; 2. Annotate structures within ~38 images with 5 different classifications of annotations; 3. Open a non-annotated image; 4. Attempt to train a pixel classifier using all channels, scales, and features, loading training from other annotated images in the project.; 5. Click ""Live Preview"", note the error at the end of the post. **Expected behavior**; A pixel classifier should be trained, and a preview should be applied to the currently loaded image. **Desktop (please complete the following information):**; - OS: Windows 10, 32-thread processor, 127/128 Gb RAM allocated for QuPath, ~500 Gb SSD storage for tile cache; - QuPath Version 0.3.2. **Additional context**; Error log:; ```; 12:10:44.040 [JavaFX Application Thread] [INFO ] q.p.g.c.ml.PixelClassifierPane - Creating training data from 38 images; 12:10:44.953 [JavaFX Application Thread] [ERROR] q.p.g.c.ml.PixelClassifierTraining - Error requesting features for ImageOp server: ImageData: Other, xxxx___ROI8_ROI_008.ome.tiff - ROI8_ROI_008.ome {""colorTransforms"":[{""channelName"":""Pr(141)_141-SMA""},{""channelName"":""Nd(142)_142Nd-CD19""},{""channelName"":""Nd(143)_143Nd-Vimentin""},{""channelName"":""Nd(144)_144Nd-cd14""},{""channelName"":""Nd(146)_146NdCD16""},{""channelName"":""Nd(148)_148-Pan-Ker""},{""channelName"":""Sm(149)_149Sm-CD11b""},{""channelName"":""Sm(152)_152Sm-CD45""},{""channelName"":""Sm(154)_154Sm-CD11c""},{""channelName"":""Gd(155)_155",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/947:1762,load,loaded,1762,https://qupath.github.io,https://github.com/qupath/qupath/issues/947,1,['load'],['loaded']
Performance,"with a GDK error trap pushed. Don't do that. 12:35:12.161 [JavaFX Application Thread] [INFO ] q.l.i.s.b.BioFormatsOptionsExtension - Bio-Formats version 6.5.0; 12:35:12.165 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Bio-Formats server options (Bio-Formats 6.5.0) (12 ms); 12:35:12.166 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Experimental commands (1 ms); 12:35:12.199 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Experimental commands (33 ms); 12:35:12.234 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension ImageJ extension (34 ms); Warning: Could not load Loader: java.lang.UnsatisfiedLinkError: no jnijavacpp in java.library.path: [/home/gordon/src/qupath/build/dist/QuPath-0.2.0-m12/lib/app, /home/gordon/src/qupath/build/dist/QuPath-0.2.0-m12/bin]; 12:35:12.248 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension JPen extension (13 ms); May 26, 2020 12:35:12 PM jpen.provider.NativeLibraryLoader$4 run; INFO: loading JPen 2-150301 JNI library: jpen-2-4-x86_64 ...; May 26, 2020 12:35:12 PM jpen.provider.NativeLibraryLoader$4 run; INFO: jpen-2-4-x86_64 loaded; Warning: Could not load Pointer: java.lang.UnsatisfiedLinkError: no jnijavacpp in java.library.path: [/home/gordon/src/qupath/build/dist/QuPath-0.2.0-m12/lib/app, /home/gordon/src/qupath/build/dist/QuPath-0.2.0-m12/bin]; #; # A fatal error has been detected by the Java Runtime Environment:; [thread 50032 also had an error]; #; # SIGSEGV (0xb) at pc=0x00007f6271c2df1e, pid=49988, tid=50030; #; # JRE version: OpenJDK Runtime Environment AdoptOpenJDK (14.0.1+7) (build 14.0.1+7); # Java VM: OpenJDK 64-Bit Server VM AdoptOpenJDK (14.0.1+7, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # C [libc.so.6+0x8af1e] __libc_malloc+0x11e; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/lib/system",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/484#issuecomment-634101819:1943,Load,Loaded,1943,https://qupath.github.io,https://github.com/qupath/qupath/issues/484#issuecomment-634101819,1,['Load'],['Loaded']
Performance,"with try-with-resources... but it looks weird; * If a measurement is unavailable, `Double.NaN` is returned... but is indistinguishable from that being the *correct* value; * It's a whole non-standard API to learn when scripting. It's all pretty cumbersome, as can be seen in a Groovy script:. ```groovy; def allCells = getCellObjects(). // Get an individual measurement for the first cell; def cell = allCells[0]; println cell.getMeasurementList().getMeasurementValue('Nucleus: Area'). // Get all the measurement names and values; println cell.getMeasurementList().getMeasurementNames(); def values = []; for (int i = 0; i < cell.getMeasurementList().size(); i++) {; values << cell.getMeasurementList().getMeasurementValue(i); }; println values; ```. ### Describe the solution you'd like. *Ideally* we'd have a `Map<String, double>` that preserves the efficiency of `MeasurementList`... if only this was permitted by Java. In practice, `Map<String, Double>` is likely to give adequate performance in Groovy - as long as the values are stored as primitives for efficiency in Java. In fact, to maintain compatibility we could initially implement an `AbstractMap` that wraps around an existing `MeasurementList` - with the latter still used internally. We'd need a method added to `PathObject`. ```java; public Map<String, Double> getMeasurements();; ```. This would help by:. * Providing a standard API, which explicitly doesn't permit duplicate keys; * Fitting well with GeoJSON export; * Permitting `MeasurementList` to be deprecated; * Making scripting a lot more intuitive... and almost pythonic. The last one is the biggest motivating factor, since we can then immediate benefit from some extra Groovy goodness. For example, the following script works:. ```groovy; def allCells = getCellObjects(). // Get an individual measurement for the first cell; def cell = allCells[0]; println cell.measurements['Nucleus: Area']. // Get all the measurement names, values or both; println cell.measurements.key",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1085:2197,perform,performance,2197,https://qupath.github.io,https://github.com/qupath/qupath/issues/1085,1,['perform'],['performance']
Performance,y.control.ErrorCollector.failIfErrors(ErrorCollector.java:311); at org.codehaus.groovy.control.CompilationUnit.applyToSourceUnits(CompilationUnit.java:980); at org.codehaus.groovy.control.CompilationUnit.doPhaseOperation(CompilationUnit.java:647); at org.codehaus.groovy.control.CompilationUnit.processPhaseOperations(CompilationUnit.java:623); at org.codehaus.groovy.control.CompilationUnit.compile(CompilationUnit.java:600); at groovy.lang.GroovyClassLoader.doParseClass(GroovyClassLoader.java:390); at groovy.lang.GroovyClassLoader.access$300(GroovyClassLoader.java:89); at groovy.lang.GroovyClassLoader$5.provide(GroovyClassLoader.java:330); at groovy.lang.GroovyClassLoader$5.provide(GroovyClassLoader.java:327); at org.codehaus.groovy.runtime.memoize.ConcurrentCommonCache.getAndPut(ConcurrentCommonCache.java:147); at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:325); at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:309); at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:251); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.getScriptClass(GroovyScriptEngineImpl.java:331); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:153); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:766); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:696); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:676); at qupath.lib.gui.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1033); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834). ```,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/282#issuecomment-473504477:2155,concurren,concurrent,2155,https://qupath.github.io,https://github.com/qupath/qupath/issues/282#issuecomment-473504477,4,['concurren'],['concurrent']
Performance,"yROI()); pathObjects << pathObject; for (int k = 0; k <= i; k++); pathObject.measurementList.put(""M_$k"", i); }); t.join(); ; println ""Done!""; ```. I see an exception; ```; ERROR: null; java.util.ConcurrentModificationException: null; at java.base/java.util.ArrayList$Itr.checkForComodification(Unknown Source); at java.base/java.util.ArrayList$Itr.next(Unknown Source); at java.base/java.util.Collections$UnmodifiableCollection$1.next(Unknown Source); at java.base/java.util.AbstractCollection.addAll(Unknown Source); at qupath.lib.objects.PathObjectTools.getAvailableFeatures(PathObjectTools.java:2026); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript$_run_closure1.doCall(QuPathScript:11); at QuPathScript$_run_closure1.doCall(QuPathScript); at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(Unknown Source); at java.base/java.lang.reflect.Method.invoke(Unknown Source); at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:343); at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:328); at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:279); at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1008); at groovy.lang.Closure.call(Closure.java:433); at groovy.lang.Closure.call(Closure.java:412); at groovy.lang.Closure.run(Closure.java:505); at java.base/java.lang.Thread.run(Unknown Source); ```. **Expected behavior**; The code runs without any exception. **Desktop (please complete the following information):**; - OS: macOS (but probably all); - QuPath Version: v0.5.1. **Additional context**; This seems to only occur with detections. The underlying issue in this specific case seems to be that these can return an unmodifiable list of measurement names, but when this is used by `PathObjectTools.getAvailableFeatures(Collection)` the underlying list is being modified. A fix may require revising `MeasurementList` more thoroughly to improve its ",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1591:1915,Cache,CachedMethod,1915,https://qupath.github.io,https://github.com/qupath/qupath/issues/1591,1,['Cache'],['CachedMethod']
Performance,"ylib; jniopencv_ml : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_ml.dylib; opencv_imgproc@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_imgproc.405.dylib; jniopencv_dnn : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_dnn.dylib; jnijavacpp : 	/Users/pbankhea/.javacpp/cache/javacpp-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/javacpp/macosx-x86_64/libjnijavacpp.dylib; jniopenblas : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libjniopenblas.dylib; quadmath@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libquadmath.0.dylib; openblas_nolapack@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libopenblas_nolapack.0.dylib; opencv_core@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_core.405.dylib; jniopenblas_nolapack : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libjniopenblas_nolapack.dylib; jniopencv_imgproc : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_imgproc.dylib; openblas@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libopenblas.0.dylib; opencv_dnn@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_dnn.405.dylib; ```. The `-Dorg.bytedeco.javacpp.maxPhysicalBytes=0` workaround does avoid the problem, but I haven't implemented it.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980:2381,cache,cache,2381,https://qupath.github.io,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980,5,['cache'],['cache']
Safety," ""spacingMicrons"": 10.0, ""maxIterations"": 10, ""regularization"": 0.25, ""adaptRegularization"": false, ""useDeconvolved"": false}');; selectDetections();; runPlugin('qupath.lib.algorithms.IntensityFeaturesPlugin', '{""pixelSizeMicrons"": 0.25, ""region"": ""ROI"", ""tileSizeMicrons"": 25.0, ""colorOD"": true, ""colorStain1"": true, ""colorStain2"": true, ""colorStain3"": false, ""colorRed"": false, ""colorGreen"": false, ""colorBlue"": false, ""colorHue"": false, ""colorSaturation"": false, ""colorBrightness"": false, ""doMean"": true, ""doStdDev"": true, ""doMinMax"": false, ""doMedian"": false, ""doHaralick"": false, ""haralickDistance"": 1, ""haralickBins"": 32}');; ```. You can also choose a larger size for your SLICs if you want to do more of a tissue structure analysis. Smaller is usually better if you are looking for color differences though. Another options is just using the cell detection mentioned above:; ```; selectAnnotations();; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.25, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 15.0, ""maxAreaMicrons"": 60.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2690789473684211, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; ```. Which yielded the following for my square. You may want to tweak the DAB threshold value, and you can always create your own classifier as well based on more data than just the Nucleus DAB OD mean (https://github.com/qupath/qupath/wiki/Classifying-objects):; ![image](https://user-images.githubusercontent.com/23145209/37378645-52636d20-26ed-11e8-88ac-5401852cb5bc.png). It really depends on what exactly you are interested in measuring.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/157#issuecomment-372875465:2081,detect,detectionImageBrightfield,2081,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372875465,1,['detect'],['detectionImageBrightfield']
Safety," ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 2443 nuclei detected (processing time: 2.11 seconds); INFO: Processing complete in 2.15 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 2443 nuclei detected (processing time: 3.01 seconds); INFO: Processing complete in 3.03 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Smoothing using TMA cores; INFO: Processing complete in 0.18 seconds; INFO: Completed!; INFO: ; qupath.lib.plugins.objects.SmoothFeaturesPlugin {""fwhmMicrons"": 25.0, ""smoothWithinClasses"": false, ""useLegacyNames"": false}; INFO: Measurement mapper limits for Smoothed: 25 µm: Nucleus/Cell area ratio: 0.12291267514228821, 0.4222889840602875; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO:",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418647572:4139,detect,detectionImageBrightfield,4139,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418647572,1,['detect'],['detectionImageBrightfield']
Safety, (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: ,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:3019,detect,detected,3019,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety," (H-DAB), R-PICCOLO-16_CDX2-88_20x; INFO: Will (re)compute TMA grid...; INFO: Processing complete in 1.26 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.dearray.TMADearrayerPluginIJ {""coreDiameterMM"": 0.7, ""labelsHorizontal"": ""1-16"", ""labelsVertical"": ""A-J"", ""labelOrder"": ""Row first"", ""densityThreshold"": 5, ""boundsScale"": 105}; INFO: Adding Rectangle to hierarchy; INFO: Requesting region for stain vector editing: ; INFO: 1932 nuclei detected (processing time: 3.82 seconds); INFO: Processing complete in 3.92 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 1165 nuclei detected (processing time: 3.94 seconds); INFO: Processing complete in 3.98 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Requesting region for stain vector editing: ; INFO: Adding Rectangle to hierarchy; INFO: Requesting region for stain vector editing: ; INFO: 989 nuclei detected (processing time: 1.90 seconds); INFO: Processing complete in 1.92 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"":",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418647572:2066,detect,detected,2066,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418647572,1,['detect'],['detected']
Safety," (annotations.isEmpty()) {; Dialogs.showWarningNotification(""Classify annotations"", ""No annotations found!""); return; }; for (def annotation in annotations); classifySingleAnnotation(annotation); imageData.getHierarchy().fireObjectClassificationsChangedEvent(this, annotations); }. def classifySingleAnnotation(PathObject pathObject) {; def roiName = pathObject.getROI()?.getRoiName(); pathObject.setPathClass(PathClass.getInstance(roiName)); }; ```. I think it makes sense for such classifiers to be added to a single *Object classification* submenu, rather than split between *Detection* and *Annotation* (also, there might one day be a need to classify *TMA cores*, which don't fit into either category). Also, the top of the *Train object classifier* dialog makes it possible to select different types of objects to classify. <img width=""418"" alt=""Train object classifier"" src=""https://github.com/qupath/qupath/assets/4690904/d6977ca8-a018-4d33-bd7c-f31eed611749"">. Admittedly, these are all detections or subtypes of detection... but that's because I couldn't think of a good workflow to use them for annotations (since you're using annotations to train the classifier, how should QuPath distinguish between which annotations are for training and which should be classified...?). The internal representation of the object classifier is capable of specifying the type of object it should be applied to, even though we have no easy way to interactively create annotation classifiers through the user interface, or examples where that is actually used. Perhaps more usefully, we plan to enable the use of deep learning models for classification - and these don't have the complication of needing annotations for training. Much of the code to enable this has already been written, but we need to figure out how best to link it up to the user interface and provide meaningful models for the feature to be useful. When it *is* useful, I expect it to become *very* useful. QuPath's best features probabl",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1501#issuecomment-2075386110:2297,detect,detections,2297,https://qupath.github.io,https://github.com/qupath/qupath/issues/1501#issuecomment-2075386110,2,['detect'],"['detection', 'detections']"
Safety," * 'Requesting attention', e.g. forcing the app to the front; * A small, unobtrusive progress bar that can be 'always on top' (even if QuPath isn't). I'm not sure adding one option to the batch script dialog will be enough to solve the problem, and adding many becomes a lot more clutter and effort to maintain. To overcome that, my initial idea was to provide the option of adding a 'batch script listener' to the script editor. . So you could add a listener using something like this (in Groovy):; ```groovy; def scriptEditor = getQuPath().getScriptEditor(); scriptEditor.addBatchScriptListener(e -> {; if (e.isLastScript()) {; // Do something... beep, email, whatever; java.awt.Toolkit.defaultToolkit.beep(); }; }); ```. The thing is that the listeners would be cumulative, so you'd likely want to just add one on startup and leave it (rather than add multiple listeners and then have them all firing when scripts are run). But then it becomes harder to turn it on/off the listener's behavior. Nevertheless, this approach would make it possible to add small extensions that offer different kinds of behavior, controlled via preferences or something else. So you could have a preference allowing the user to choose the audio file they want played on completion, for example.... but still, remembering to turn the option on and off could be a pain, since it wouldn't be easy to incorporate it as a checkbox in the batch processing dialog itself. While writing this, another option I've thought of is to make more info about the current script accessible within the script itself. So it might look like this:. ```groovy; if (getScriptInfo().isBatchProcessing() && getScriptInfo().isLastScript()) {; // Do something... beep, email, whatever; java.awt.Toolkit.defaultToolkit.beep(); }; ```. So any notification would be something pasted at the end of the script itself. It's like @MichaelSNelson's approach except avoids worrying so much about the last file being uniquely named. What do you all think?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1029#issuecomment-1200084804:2271,avoid,avoids,2271,https://qupath.github.io,https://github.com/qupath/qupath/issues/1029#issuecomment-1200084804,1,['avoid'],['avoids']
Safety," Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelS",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:3197,detect,detected,3197,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety," Again **with the annotation selected**:; ```; runPlugin('qupath.imagej.superpixels.SLICSuperpixelsPlugin', '{""sigmaMicrons"": 1.0, ""spacingMicrons"": 10.0, ""maxIterations"": 10, ""regularization"": 0.25, ""adaptRegularization"": false, ""useDeconvolved"": false}');; selectDetections();; runPlugin('qupath.lib.algorithms.IntensityFeaturesPlugin', '{""pixelSizeMicrons"": 0.25, ""region"": ""ROI"", ""tileSizeMicrons"": 25.0, ""colorOD"": true, ""colorStain1"": true, ""colorStain2"": true, ""colorStain3"": false, ""colorRed"": false, ""colorGreen"": false, ""colorBlue"": false, ""colorHue"": false, ""colorSaturation"": false, ""colorBrightness"": false, ""doMean"": true, ""doStdDev"": true, ""doMinMax"": false, ""doMedian"": false, ""doHaralick"": false, ""haralickDistance"": 1, ""haralickBins"": 32}');; ```. You can also choose a larger size for your SLICs if you want to do more of a tissue structure analysis. Smaller is usually better if you are looking for color differences though. Another options is just using the cell detection mentioned above:; ```; selectAnnotations();; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.25, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 15.0, ""maxAreaMicrons"": 60.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2690789473684211, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; ```. Which yielded the following for my square. You may want to tweak the DAB threshold value, and you can always create your own classifier as well based on more data than just the Nucleus DAB OD mean (https://github.com/qupath/qupath/wiki/Classifying-objects):; ![image](https://user-images.githubusercontent.co",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/157#issuecomment-372875465:1960,detect,detection,1960,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372875465,1,['detect'],['detection']
Safety, Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: ,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:2900,detect,detected,2900,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety," GUI:; We can see that the path was a combination of two paths, this is the problem. >> RMD_slide2ims_Entry; 23:18:18.288 [main] [INFO ] qupath.QuPath - Launching QuPath with args: -image, D:\\QMDownload\\5\\Leica_scn\\Leica-Fluorescence-1.scn, -script, D:\\QMDownload\\5\\tpc9321172_2c3b_4e82_b55c_7ae4380fda4b.groovy ; 23:18:18.368 [main] [ERROR] q.lib.images.servers.FileFormatInfo - Checking Big TIFF images currently not supported!!! ; 23:18:18.428 [main] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1 ; WARNING: An illegal reflective access operation has occurred ; WARNING: Illegal reflective access by com.esotericsoftware.kryo.util.UnsafeUtil (file:/C:/Program%20Files/QuPath-0.2.0-m1/app/kryo-2.24.0.jar) to constructor java.nio.DirectByteBuffer(long,int,java.lang.Object) ; WARNING: Please consider reporting this to the maintainers of com.esotericsoftware.kryo.util.UnsafeUtil ; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations ; WARNING: All illegal access operations will be denied in a future release ; 23:18:19.436 [main] [WARN ] loci.formats.Memoizer - deleting invalid memo file: D:\QMDownload\5\Leica_scn\.Leica-Fluorescence-1.scn.bfmemo ; com.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 458; Serialization trace:; service (loci.formats.in.OperettaReader); readers (loci.formats.ImageReader); reader (loci.formats.DimensionSwapper); reader (loci.formats.FileStitcher); helper (loci.formats.in.FilePatternReader); readers (loci.formats.ImageReader) ; 	at com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:119) ; 	at com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:641) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:375) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:289) ; 	at com.es",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/280#issuecomment-472915452:969,Unsafe,UnsafeUtil,969,https://qupath.github.io,https://github.com/qupath/qupath/issues/280#issuecomment-472915452,1,['Unsafe'],['UnsafeUtil']
Safety," H&E and Fluorescence scripts. (I set the model path). ```; ERROR: 'org.locationtech.jts.geom.Geometry qupath.lib.roi.GeometryTools.createRectangle(double, double, double, double)'; java.lang.NoSuchMethodError: 'org.locationtech.jts.geom.Geometry qupath.lib.roi.GeometryTools.createRectangle(double, double, double, double)'; at qupath.ext.stardist.StarDist2D.lambda$detectObjects$10(StarDist2D.java:940); at java.base/java.util.stream.ReferencePipeline$2$1.accept(Unknown Source); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(Unknown Source); at java.base/java.util.stream.AbstractPipeline.evaluate(Unknown Source); at java.base/java.util.stream.ReferencePipeline.collect(Unknown Source); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:941); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:886); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$6(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:859); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$5(StarDist2D.java:812); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:812); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript.run(QuPathScript:48); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:331); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:161); at qupath.lib.gui.scripting.languages.DefaultScriptLanguage.execute(DefaultScriptLanguage.jav",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1635:1217,detect,detectObjects,1217,https://qupath.github.io,https://github.com/qupath/qupath/issues/1635,1,['detect'],['detectObjects']
Safety," I can't find it now. Anyway, rough workflow for me:; `def string = ""G:\\MyProjectData\\Data""; saveDetectionMeasurements(string, ); saveTMAMeasurements(string, ); saveAnnotationMeasurements(string, )`; I first use that script and edit it for whatever project I want to export from, then ""Run for project"" and select all of the slides. I specifically need the double slashes because I am running Windows. Once all of the annotation files are in one place, I use the following R code to merge it all into one .csv file, which I finally open in Excel, edit for clarity, and save. You may find it easier to edit the file names before running the R script, I usually use a bulk file rename utility.; ```; library(dplyr); library(readr); #Takes multiple annotation files in a ""Path"" directory and mergest them into a single CSV document. Each line of the ; #CSV file represents an annotation, and if a file has multiple annotations, only the first is listed with the file name; # and all subsequent blank names are part of the first listed file.; path = ""G:/MyProjectData/Data""; setwd(path); outFile <-""Tumor Assay Annotation measurements.csv"". #Replace .txt with whatever identifier will pick up all of the files you want to analyze. Detections or Annotations are common choices; Annotationfiles <- dir(path,pattern = "".txt""). #an empty frame to place data into; Measurements <- data.frame(); #simple for loop to read each file and keep a sum of the cell areas.; for(i in 1:length(Annotationfiles)){; data.raw <- read_delim(Annotationfiles[i],""\t"", escape_double = FALSE, trim_ws = TRUE); ; #place the file names in the first column; Sample = tools::file_path_sans_ext(Annotationfiles[i]); data.raw[1,2]<-Sample; Measurements<-bind_rows(Measurements, data.raw); ; ; }. #set row names to F if you don't want a numbered list as the first column; write.csv(Measurements, outFile, row.names=T); ```. I am not an expert R coder, so I am sure there are more elegant ways to accomplish this, but it works for me!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/79#issuecomment-305082313:1285,Detect,Detections,1285,https://qupath.github.io,https://github.com/qupath/qupath/issues/79#issuecomment-305082313,1,['Detect'],['Detections']
Safety," Nikon software? Is there any possibility they were saved with a different version of the software, or someone else might have changed some obscure setting?. Your description and the screenshots are very helpful to rule out some of my other guesses; because the images are both described as 14-bit and read using Bio-Formats, I don't see any clear reason why there would be a problem - although I see there is a small difference in the width & height, which makes me wonder if there was at least some small change at the time of acquisition... but I don't know what. I'd suggest trying to open the images in [Fiji](http://fiji.sc) and checking under *Image &rarr; Properties...* to see if the pixel size information is there. If it is, the first thing I'd do is make sure you have the latest [QuPath Bio-Formats extension & bioformats_package.jar](https://github.com/qupath/qupath-bioformats-extension), and try again. Alternatively, you can manually enter the pixel width & height values in Fiji (if you know them - is it safe to assume they are the same as in your other images?). Then you can save the image with pixel sizes as a TIFF in Fiji, and read the TIFF rather than ND2 file into QuPath. However, I should warn you: if you use the save-as-TIFF-in-Fiji trick, then ImageJ will be used to read the image and there is an unfortunate bug in QuPath v0.1.2 that means for this application you should probably also change the preferences to only use 1 parallel thread (described [here](https://github.com/qupath/qupath/issues/74)). Alternatively, you could try the latest-not-quite-released QuPath changes described [here](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html), which should include a fix for the bug. (In case that sounds alarming: the bug shouldn't cause any trouble if you see *Server type: Bio-Formats* or *Server type: OpenSlide*, only *Server type: ImageJ* is affected - and even then not always. It should be fairly clear if it causes trouble, in that spots",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/163#issuecomment-379493712:1130,safe,safe,1130,https://qupath.github.io,https://github.com/qupath/qupath/issues/163#issuecomment-379493712,1,['safe'],['safe']
Safety," a image analysis problem. 20X might also be challenging with truly thin, elongated nuclei. Even more challenging if the Hamamatsu defaults to saving with JPEG compression (bad for analysis, great for file size). You can both classify regions and cellular populations, so you can subdivide your sample into ""tumor"" and ""stroma"" annotations first, and then perform positive cell detection within each of those (or however many classifications you want). Another option is using derived classes, so that you would first classify by tumor and stroma, then classify the cells as positive or negative within those classifications: https://github.com/qupath/qupath/wiki/Object-classifications<https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fwiki%2FObject-classifications&data=01%7C01%7Clucia.montorsi%40kcl.ac.uk%7Cc0fb04b4d26e44a6d0fa08d63529246a%7C8370cf1416f34c16b83c724071654356%7C0&sdata=UQryuEzaf5zSNRtDGv8hrkp%2FfCUaV5EV%2FABLyh8vxoY%3D&reserved=0>. Either way, you can then ignore the stromal positive cells in the data processing (merge populations) however you want, or create a step that re-classifies any Stroma-positive to Stroma-negative, etc. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fissues%2F231%23issuecomment-431117318&data=01%7C01%7Clucia.montorsi%40kcl.ac.uk%7Cc0fb04b4d26e44a6d0fa08d63529246a%7C8370cf1416f34c16b83c724071654356%7C0&sdata=f0CtUFa8ECpcchyI4Q7%2BY8PwuygiWZKq9wwPdVmoZKo%3D&reserved=0>, or mute the thread<https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAlLGAJDTdTi-Ix7yRlQnu_6NIcX4uIMjks5umMsLgaJpZM4XuQ5V&data=01%7C01%7Clucia.montorsi%40kcl.ac.uk%7Cc0fb04b4d26e44a6d0fa08d63529246a%7C8370cf1416f34c16b83c724071654356%7C0&sdata=DouOAad6wA%2FpgEMUgYt2wSQKeQqOGqeqfsaR4L6Naps%3D&reserved=0>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/231#issuecomment-431292156:2125,safe,safelinks,2125,https://qupath.github.io,https://github.com/qupath/qupath/issues/231#issuecomment-431292156,2,['safe'],['safelinks']
Safety," amask=0 IntegerInterleavedRaster: width = 193 height = 200 #Bands = 3 xOff = 0 yOff = 0 dataOffset[0] 0); INFO: Returning server: OpenSlide for N:\Faculty-of-Medicine-and-Health\LICAP\DATA\PTHY\Pathology\Breast Group\BCCTB Samples\Audits\BCN QA 2017\Frozen samples QuPath tumourstromaratio\Batch_2\Tumour\402428.svs; INFO: Estimating H & E staining; INFO: Image data set to ImageData: Brightfield (H&E), 402428; INFO: 1 region detected (processing time: 215.44 seconds); INFO: Processing complete in 215.63 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.tissue.SimpleTissueDetection2 {""threshold"": 219, ""requestedPixelSizeMicrons"": 2.0, ""minAreaMicrons"": 20.0, ""maxHoleAreaMicrons"": 200.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (pro",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:2246,detect,detected,2246,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety," and probability output - then ran the script at the bottom. Using a Mac Studio (2022) with M1 Max and 32 GB RAM the processing time was:. | v0.3.0 | v0.4.0-SNAPSHOT |; | ------------- | ------------- |; | 593.9 s | 60.1 s |. Results identical as far as I can tell. So... quite a substantial difference :). Cell detection took close to 30s, with 326 498 cells detected,. ```groovy; def checkpoints = [:]. setImageType('BRIGHTFIELD_H_E'); setColorDeconvolutionStains('{""Name"" : ""H&E default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049"", ""Stain 2"" : ""Eosin"", ""Values 2"" : ""0.2159 0.8012 0.5581"", ""Background"" : "" 255 255 255""}'). clearAllObjects(). checkpoints << ['Tissue detection': System.currentTimeMillis()]. createAnnotationsFromPixelClassifier(""Tissue detection"", 10000.0, 0.0, ""INCLUDE_IGNORED""). checkpoints << ['Cell detection': System.currentTimeMillis()]. selectAnnotations(); runPlugin('qupath.imagej.detect.cells.WatershedCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 1.0, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}'). for (classifier in ['Some probability', 'Some classification']) {. // Create annotation measurements; checkpoints << [""Annotation measurements for $classifier"": System.currentTimeMillis()]; selectAnnotations(); addPixelClassifierMeasurements(classifier, classifier); ; // Create cell measurements; checkpoints << [""Cell measurements for $classifier"": System.currentTimeMillis()]; selectCells(); addPixelClassifierMeasurements(classifier, classifier); }; checkpoints << [""Done"": System.currentTimeMillis()]; resetSelection(); println 'Done!'. def entries = checkpoints.entrySet() as List; println ""Total time: \t${entries[-1].value - entri",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1076#issuecomment-1279692584:1121,detect,detectionImageBrightfield,1121,https://qupath.github.io,https://github.com/qupath/qupath/pull/1076#issuecomment-1279692584,1,['detect'],['detectionImageBrightfield']
Safety," annotations restored. I've continued closing and reopening the project, and a different number of images have annotations each time. I have tried downloading the newest version of QuPath, after which there were 5 images with annotations and detections restored and one with only annotations restored. Since updating, the same data is the same every time I reopen it. I have also tried updating and restarting my computer. I have no idea how or why this happened or how to get my data back. This is many hours of work, and I'm scared to start my new project, if this is a possible outcome.;  ; **To Reproduce**; I'm sorry, but I have no idea.;  ; **Expected behavior**; Normally, when I go from one image to another, I save one and then the next one opens the old annotations and detections.;  ; **Screenshots**; <img width=""1264"" alt=""Screenshot 2023-09-04 at 6 43 43 PM"" src=""https://github.com/qupath/qupath/assets/79068467/16ab2d72-a5ad-4910-b1eb-c1fc0a9c8842"">; This is a list of images, you can see that it shows five on this view as opened and the rest as new. ;  ; **Desktop (please complete the following information):**;  - OS:  macOS Ventura Version 13.5.1 (22G90);  - QuPath Version: currently Version: 0.4.4, unfortunately, I didn't check the old version before updating;  ; **Additional context**; The only thing I think *could* be a contributing factor is that the image files are large, and my Mac automatically offloads them to the cloud if I haven't opened them for a few days. When I want to work on the project, I redownload the images from the cloud, and have never had an issue viewing my old annotations on those images before. All of the images are currently downloaded, and there is no consistency between the ones that got offloaded to the cloud and the ones that lost annotations. There are six that were never offloaded to the cloud, and three of them lost annotations/detections. There are also three that were offloaded to the cloud that retained annotations/detections.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1313:2762,detect,detections,2762,https://qupath.github.io,https://github.com/qupath/qupath/issues/1313,2,['detect'],['detections']
Safety," are not all connected, including parallelisation. The algorithm is:; 1. Extract all polygons from the input.; 2. Identify intersecting and non-intersecting polygons; 3. Group all polygons that should potentially be merged, because they intersect (directly or indirectly) with other polygons in the group; each polygon should be represented in only one group; 4. Union all the polygon groups; 5. Combine all resulting polygons into a single polygon or multipolygon. This addressing the pixel classification performance bottleneck described at https://forum.image.sc/t/can-creating-detections-from-pixel-classifier-be-made-to-run-faster/96745. When implementing this, it became clear that extremely complex polygons couldn't be displayed in the viewer because generating an `Area` object failed (ultimately with out-of-memory error). Also, `PolygonROI.getGeometry()` was slow when called repeatedly because the geometry is recomputed each time. So the PR uses a `SoftReference` to avoid this, while still allowing references to be dropped when memory is low. When the geometry isn't needed, the overhead should be avoided. This PR also addresses this problem by using JTS' shape representation instead. ## To test. ### Union of many objects. A simple test:; * Detect cells in an image; * Run the following script. ```groovy; import qupath.lib.common.Timeit; import qupath.lib.roi.GeometryTools. import static qupath.lib.scripting.QP.*. def detections = getDetectionObjects(). List<GeometryTools> geoms = detections.collect {it.getROI().getGeometry()}. def timeit = new Timeit(); .start(); def geomUnion = GeometryTools.union(geoms); println timeit.stop(). double sumArea = geoms.sum {g -> g.getArea()}; println ""Sum area: \t${sumArea}""; println ""Num geometries: \t${geoms.size()}""; def roi = GeometryTools.geometryToROI(geomUnion, ImagePlane.getDefaultPlane()); def pathClass = getPathClass(""Merged geometries""); removeObjects(getAnnotationObjects().findAll(p -> p.getPathClass() == pathClass), true);",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1543:1074,avoid,avoid,1074,https://qupath.github.io,https://github.com/qupath/qupath/pull/1543,1,['avoid'],['avoid']
Safety," background:. * When a line is drawn, it is represented inside QuPath by the coordinates of its end points, ```(x1,y1)``` and ```(x2,y2)```; * When the line is saved, these coordinates are written (correctly) into the ```.qpdata``` file; * When the ```.qpdata``` file is loaded again later, the first thing QuPath does is read the coordinates and convert them into ```(x1, y1)``` and ```(x2-x1, y2-y1)```. This last step is a bug; there is no need to subtract the first coordinates from the second. It happens because, long ago (and before being released), QuPath stored its lines differently (with the first coordinate and then displacement).... and this bit of the code was not updated when it should have been, and lines were used rarely enough for it to go unnoticed. With that in mind, the error can be cumulative; if you open a ```.qpdata``` file and the lines display wrongly, and then you save it again, QuPath will now save the wrong coordinates... and, when reading them, make them even more wrong, i.e. ```(x2-x1-x1, y2-y1-y1)```. You'd have to run the script twice to fix such lines. Therefore it is important to have all your lines corrected before you save, and then run the script to fix them immediately after opening the image. This avoids having a combination of correct and incorrect lines on the image at the same time. The purpose of the script is to go through and fix the second coordinate for all your lines by adding the first coordinate. It does this for all lines, regardless of whether or not they are correct. If you want to change only some of the lines then @Svidro's idea is great - select the lines you want to change (e.g. in the list at the top of the *Annotations* tab on the left of the screen) and run this script instead:. ```groovy; getSelectedObjects().each {; roi = it.getROI(); if (roi instanceof qupath.lib.roi.LineROI) {; roi.x2 += roi.x; roi.y2 += roi.y; }; }; fireHierarchyUpdate(); ```. This will fix the selected lines, and leave the others unchanged.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/71#issuecomment-299623260:1449,avoid,avoids,1449,https://qupath.github.io,https://github.com/qupath/qupath/issues/71#issuecomment-299623260,1,['avoid'],['avoids']
Safety," be able to come up whit a classifier right?; ![image](https://user-images.githubusercontent.com/36917491/45081418-75871d80-b0f7-11e8-9ed9-373228da976e.png). Log-file:; INFO: Selected style: Modena Light; INFO: Performing update check...; INFO: Starting QuPath with parameters: []; ERROR: Openslide: Property not available: openslide.objective-power; INFO: Test reading thumbnail with openslide: passed (BufferedImage@77accd0e: type = 1 DirectColorModel: rmask=ff0000 gmask=ff00 bmask=ff amask=0 IntegerInterleavedRaster: width = 200 height = 193 #Bands = 3 xOff = 0 yOff = 0 dataOffset[0] 0); INFO: Returning server: OpenSlide for L:\basic\divg\CEMM-Lexor\SannetH\1. SANNE\Project 2. IHC Validation PICCOLO and COIN\Qupath PICCOLO\R-PICCOLO-16_CDX2-88_20x.tiff; INFO: Estimating H-DAB staining; INFO: Image data set to ImageData: Brightfield (H-DAB), R-PICCOLO-16_CDX2-88_20x; INFO: Will (re)compute TMA grid...; INFO: Processing complete in 1.26 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.dearray.TMADearrayerPluginIJ {""coreDiameterMM"": 0.7, ""labelsHorizontal"": ""1-16"", ""labelsVertical"": ""A-J"", ""labelOrder"": ""Row first"", ""densityThreshold"": 5, ""boundsScale"": 105}; INFO: Adding Rectangle to hierarchy; INFO: Requesting region for stain vector editing: ; INFO: 1932 nuclei detected (processing time: 3.82 seconds); INFO: Processing complete in 3.92 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 1165 nuclei detected (processing time: 3.94 seconds); INFO: Processing complete in 3.98 seconds; INFO: Completed!; INFO: ; qupath.imagej.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418647572:1187,detect,detect,1187,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418647572,1,['detect'],['detect']
Safety," be breaking... and when a path needs to be found through the pain (e.g. the ability to import images from v0.1.2 projects to v0.2.0). When it's in the public API, we have no idea how it is used or the implications of our changes. Because the scripting approach I proposed only uses `ImageDisplay` internally, so long as any improved approach is capable of supporting a method that does the same thing then we're free to change the method in `QPEx` without worrying about breaking things for anyone else. We can even move it up into `QP` so that it works without knowing anything about the viewer at all. I think that as a compromise this is more than fair. It means you get the outcome you want, and we did not have to compromise to do something that I strongly believe will end up wasting a lot of time in the future (be that mine or someone else's). QuPath remains a 0.x.x release and so the API shouldn't be interpreted as stable. I don't encourage writing extensions for that reason. But I do recognise that extensions are important, and so if someone wants to do it (aware of the risks) then it is supported. I hope that more clearly explains my logic. Since it feels like we've discussed this subject many times, I thought I should be thorough in this answer. Now I've no time to shorten it.... I hope it is useful. v0.2.0 has been a rather... intense experience. Pretty much the entire software has been rewritten, while still trying to keep it basically functional and respond to the ever-increasing questions and requests from users. Sometimes it gets exhausting. QuPath is by no means finished, but I do think it is substantially better and more coherent than it previously was. The goal of v0.2.0 was to get decent foundations as quickly as possible - but the task turned out to be huge. The importance of many of the new features will only become clear in future releases. v0.3.0 won't have so many milestones, and I hope will mark the start of a more sustainable development approach...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/26#issuecomment-632668731:5821,risk,risks,5821,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731,1,['risk'],['risks']
Safety," bmask=ff amask=0 IntegerInterleavedRaster: width = 200 height = 193 #Bands = 3 xOff = 0 yOff = 0 dataOffset[0] 0); INFO: Returning server: OpenSlide for L:\basic\divg\CEMM-Lexor\SannetH\1. SANNE\Project 2. IHC Validation PICCOLO and COIN\Qupath PICCOLO\R-PICCOLO-16_CDX2-88_20x.tiff; INFO: Estimating H-DAB staining; INFO: Image data set to ImageData: Brightfield (H-DAB), R-PICCOLO-16_CDX2-88_20x; INFO: Will (re)compute TMA grid...; INFO: Processing complete in 1.26 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.dearray.TMADearrayerPluginIJ {""coreDiameterMM"": 0.7, ""labelsHorizontal"": ""1-16"", ""labelsVertical"": ""A-J"", ""labelOrder"": ""Row first"", ""densityThreshold"": 5, ""boundsScale"": 105}; INFO: Adding Rectangle to hierarchy; INFO: Requesting region for stain vector editing: ; INFO: 1932 nuclei detected (processing time: 3.82 seconds); INFO: Processing complete in 3.92 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 1165 nuclei detected (processing time: 3.94 seconds); INFO: Processing complete in 3.98 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Requesting region for stai",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418647572:1642,detect,detectionImageBrightfield,1642,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418647572,1,['detect'],['detectionImageBrightfield']
Safety," daemon [_thread_in_native, id=7376, stack(0x0000002279b00000,0x0000002279c00000)]. Stack: [0x0000002279b00000,0x0000002279c00000], sp=0x0000002279bf9e20, free space=999k; Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code); C 0x0000000000cb5b26. Java frames: (J=compiled Java code, j=interpreted, Vv=VM code); j org.bytedeco.opencv.opencv_ml.LogisticRegression.predict(Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;I)F+0; j qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predictWithLock(Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;)V+11; j qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predict(Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;)V+14; j qupath.opencv.ml.OpenCVClassifiers$LogisticRegressionClassifier.predict(Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;)V+4; j qupath.opencv.ml.pixel.OpenCVPixelClassifier.applyClassification(Lqupath/lib/images/ImageData;Lqupath/lib/regions/RegionRequest;)Ljava/awt/image/BufferedImage;+235; j qupath.lib.classifiers.pixel.PixelClassificationImageServer.readTile(Lqupath/lib/images/servers/TileRequest;)Ljava/awt/image/BufferedImage;+84; J 14172 c1 qupath.lib.images.servers.AbstractTileableImageServer.getTile(Lqupath/lib/images/servers/TileRequest;)Ljava/awt/image/BufferedImage; (133 bytes) @ 0x000001d52232b9dc [0x000001d52232b3e0+0x00000000000005fc]; J 14898 c1 qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(Lqupath/lib/regions/RegionRequest;)Ljava/awt/image/BufferedImage; (1110 bytes) @ 0x000001d522ceb264 [0x000001d522ce2920+0x0000000000008944]; j qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(Lqupath/lib/regions/RegionRequest;)Ljava/lang/Object;+2; j qupath.lib.gui.ml.PixelClassificationOverlay.lambda$re",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/394:3166,predict,predict,3166,https://qupath.github.io,https://github.com/qupath/qupath/issues/394,1,['predict'],['predict']
Safety," entire area. However, in that case it is just a display thing - and the rectangle quickly disappears. But based on your post I've just checked and I can reproduce it using *Subtract selected annotations*... in which case the rectangle can hang around for longer. It still *does* disappear (sometimes...) if I select it, then start drawing a new annotation - but not entirely consistently. What I think is happening is this:; * Whenever a ROI is effectively removed (either with the brush tool or subtraction), it results in a rectangle at location (0, 0) with zero width and zero height - this is nevertheless still drawn on screen; * When removing with the brush tool, a sanity check is applied to see if the resulting ROI has no area - and if so, the object is removed (e.g. [see here](https://github.com/qupath/qupath/blob/61a382e1e345e671b3fde32da08e03f08f4f7bcf/qupath-gui-fx/src/main/java/qupath/lib/gui/viewer/tools/AbstractPathDraggingROITool.java#L100)); * This sanity check isn't applied with the *Subtract selected annotations* command... so the 'empty' ROI does not result in the object being automatically removed; * Sometimes the sanity check can be triggered later... but it entirely clear when and why. I've flagged this as a bug, since something here is definitely not right and should be fixed. I do think that there is a broader issue with the usefulness of the commands for combining annotations; these can and should behave more predictably. It may not be helped by the fact that for a long time (before release) QuPath didn't support multiple objects being selected simultaneously, and much of the original code was written back in those days; as you can imagine, this was quite limiting. You're completely right about support for subtracting multiple annotations being tricky from a how-to-present-this-to-the-user point of view. I will give this some more thought. My preference would be to replace the existing commands to combine annotations with entirely new ones that hav",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/78#issuecomment-302926092:1104,sanity check,sanity check,1104,https://qupath.github.io,https://github.com/qupath/qupath/issues/78#issuecomment-302926092,1,['sanity check'],['sanity check']
Safety," file. Is there something we're doing wrong or is this a software problem? Can you let me know how I can fix it/when the issue will be resolved?. Thanks,. Cam. The error message is as follows:; INFO: Selected style: Modena Light; INFO: Performing update check...; INFO: Starting QuPath with parameters: [N:\Faculty-of-Medicine-and-Health\LICAP\DATA\PTHY\Pathology\Breast Group\BCCTB Samples\Audits\BCN QA 2017\Frozen samples QuPath tumourstromaratio\Batch_2\Tumour\402428.svs]; INFO: Test reading thumbnail with openslide: passed (BufferedImage@5d207157: type = 1 DirectColorModel: rmask=ff0000 gmask=ff00 bmask=ff amask=0 IntegerInterleavedRaster: width = 193 height = 200 #Bands = 3 xOff = 0 yOff = 0 dataOffset[0] 0); INFO: Returning server: OpenSlide for N:\Faculty-of-Medicine-and-Health\LICAP\DATA\PTHY\Pathology\Breast Group\BCCTB Samples\Audits\BCN QA 2017\Frozen samples QuPath tumourstromaratio\Batch_2\Tumour\402428.svs; INFO: Estimating H & E staining; INFO: Image data set to ImageData: Brightfield (H&E), 402428; INFO: 1 region detected (processing time: 215.44 seconds); INFO: Processing complete in 215.63 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.tissue.SimpleTissueDetection2 {""threshold"": 219, ""requestedPixelSizeMicrons"": 2.0, ""minAreaMicrons"": 20.0, ""maxHoleAreaMicrons"": 200.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nu",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:1399,detect,detected,1399,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety," helpful outside the class. It could also be handled with composition rather than inheritance by passing a Supplier<ReaderWrapper> as an argument to its constructor if really necessary, like when creating a ThreadLocal. If this change is made, ReaderPool could still be subclassed, but wouldn't have to be subclassed. I made `ReaderPool` a concrete class by using a `Supplier` like you suggested (well, not exactly a `Supplier` but a `Callable` because I needed to throw exceptions). I removed the child classes of `ReaderPool`. > Elsewhere ReaderPool contains a lot of logic for image reading, which feels like it belongs in the reader itself - not the pool for managing readers. And it's also quite Bio-Formats-focussed, since the idea of a series within an image is quite Bio-Formats-specific.; > ; > So overall I don't have a clear idea of the logical separation between ReaderWrapper and ReaderPool. It feels like the logic of image reading is now more split across more classes + Bio-Formats itself, and it's quite hard to trace what is happening.; > . I moved the image reading logic from `ReaderPool` to `ReaderWrapper`. > It only supports returning all pixels for all channels simultaneously. In preparation for the future, it would be beneficial to have an API that optionally supports returning individual channels.; > ; > * This isn't needed if the refactoring is minor. But any major refactoring has a chance of regression (in terms of some obscure images failing), so we should try to avoid doing it multiple times. Should I add a `openImage(TileRequest tileRequest, int series, int channel, boolean isRGB, ColorModel colorModel)` function to `ReaderPool`?. > Associated images can sometimes be very big - even pyramidal or with multiple channels. So the logic for reading them doesn't have to be fundamentally different to the logic for reading other images. From a Bio-Formats perspective, you might just request the image for a different series. I'm not sure I understood this point.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1287#issuecomment-1709836979:3706,avoid,avoid,3706,https://qupath.github.io,https://github.com/qupath/qupath/pull/1287#issuecomment-1709836979,1,['avoid'],['avoid']
Safety," imp.getStatistics().mean; // Add mean as a measurement; def parent = params.getParent(); parent.measurements['My mean'] = mean; if (mean > 100); parent.classifications = ['High']; else; parent.classifications = ['Low']; // Smooth the image & threshold at the mean; def fp = imp.getProcessor().convertToFloatProcessor(); fp.blurGaussian(4); fp.setThreshold(-1, mean, ImageProcessor.NO_LUT_UPDATE); // Return the image with the threshold set; return fp; }; ```. Note that the `process` function has access to things that it may need, i.e. an `ImagePlus` representing the tile it should work on, which is already properly calibrated and with the corresponding ROI set. Also, it only returns a `FloatProcessor` with a threshold set. An `OutputHandler` automatically determines that the thresholded image should be used to create objects, which are then clipped to the parent object and added. ### Tiled processing with ImageJ. The following script applies tiled processing across an entire whole slide image to detect tissue, with regions automatically merged to form annotations. ```groovy; import qupath.lib.experimental.pixels.*; import ij.*; import ij.process.*; import ij.plugin.filter.*. def runner = new qupath.lib.gui.PluginRunnerFX(getQuPath()); def imageData = getCurrentImageData(). def pathObjects = [imageData.getHierarchy().getRootObject()]. def processor = ImageJProcessor.builder(this::process); .outputHandler(; OutputHandler.createMaskAndSplitObjectOutputHandler(; ImageJProcessor.createAnnotationConverter(); ); ); .tile(512, 512); .mergeSharedBoundaries(0.5); .pixelSize(1.0); .padding(8); .build(); ; processor.processObjects(runner, imageData, pathObjects). def process(params) {; // Calculate mean for the region; // With ImageJ, the ROI should already be set; def imp = params.getImage(); // Smooth the image & threshold at the mean; def fp = imp.getProcessor().convertToFloatProcessor(); fp.blurGaussian(4); fp.setThreshold(-1, 200, ImageProcessor.NO_LUT_UPDATE); // Return the ",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1355:3842,detect,detect,3842,https://qupath.github.io,https://github.com/qupath/qupath/pull/1355,1,['detect'],['detect']
Safety," new classifier, and export the results again.; This way you can use multiple classifiers. It’s not very elegant at all, and I’m not sure that I would recommend it… but it is an option.; > If you try this, you could toggle the ‘Missing’ status in a script or manually. If you do it manually, I’d suggest opening the ‘Hierarchy’ tab on the left of the screen, and selecting the first core. Make sure you have clicked somewhere inside the main viewer to activate it, then use the arrow keys to move around the TMA grid, and press ‘backspace’ to toggle the ‘Missing’ status. Because the default settings mean that selected cores are shown as yellow, rather than dark/light blue, having the ‘Hierarchy’ tab open is useful to show you whether the selected core is missing or not. 3. You could do something similar to the above, but set the ‘missing’ status before cell detection… so you end up without any cells in the cores that shouldn’t be included. This helps avoid generating a lot of badly-classified data that you then need to remember to ignore later. However, it does then require being able to estimate in advance which cores should be classified together. 4. If you want to use a separate classifier for every core, you could try a more drastic approach of exporting every core as a separate image. To do this, first dearray your slide. Then, you can use [Extension &rarr; ImageJ &rarr; ImageJ macro runner](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#running-macros) to export each image. You need a very simple macro, like the one below:; ```; saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle()); ```; where you’ll need to change the path to be something more suitable for your computer. It takes advantage of the fact that the ‘title’ of the image sent to ImageJ is the same as the TMA core, so using this as the filename can help you identify the core afterwards. > This may give you individual core images that are a bit big... you can change ""tif” to “jpg” to decrease",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/57#issuecomment-288818401:2498,avoid,avoid,2498,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401,1,['avoid'],['avoid']
Safety," other polygons in the group; each polygon should be represented in only one group; 4. Union all the polygon groups; 5. Combine all resulting polygons into a single polygon or multipolygon. This addressing the pixel classification performance bottleneck described at https://forum.image.sc/t/can-creating-detections-from-pixel-classifier-be-made-to-run-faster/96745. When implementing this, it became clear that extremely complex polygons couldn't be displayed in the viewer because generating an `Area` object failed (ultimately with out-of-memory error). Also, `PolygonROI.getGeometry()` was slow when called repeatedly because the geometry is recomputed each time. So the PR uses a `SoftReference` to avoid this, while still allowing references to be dropped when memory is low. When the geometry isn't needed, the overhead should be avoided. This PR also addresses this problem by using JTS' shape representation instead. ## To test. ### Union of many objects. A simple test:; * Detect cells in an image; * Run the following script. ```groovy; import qupath.lib.common.Timeit; import qupath.lib.roi.GeometryTools. import static qupath.lib.scripting.QP.*. def detections = getDetectionObjects(). List<GeometryTools> geoms = detections.collect {it.getROI().getGeometry()}. def timeit = new Timeit(); .start(); def geomUnion = GeometryTools.union(geoms); println timeit.stop(). double sumArea = geoms.sum {g -> g.getArea()}; println ""Sum area: \t${sumArea}""; println ""Num geometries: \t${geoms.size()}""; def roi = GeometryTools.geometryToROI(geomUnion, ImagePlane.getDefaultPlane()); def pathClass = getPathClass(""Merged geometries""); removeObjects(getAnnotationObjects().findAll(p -> p.getPathClass() == pathClass), true); addObject(PathObjects.createAnnotationObject(roi, pathClass)); ```. ### Pixel classification. One approach to test with CMU-1.svs is to save the following pixel classifier:; * [Nuclei.json](https://github.com/user-attachments/files/15809355/Nuclei.json). and run a simple scr",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1543:1353,Detect,Detect,1353,https://qupath.github.io,https://github.com/qupath/qupath/pull/1543,1,['Detect'],['Detect']
Safety," qupath.lib.GenowisAPI.cellSegmentation(GenowisAPI.java:69); celery_qupath_1 | 	at qupath.lib.GenowisAPI.getPNPolygon(GenowisAPI.java:172); celery_qupath_1 | 05:43:43.787 [main] [INFO ] q.l.i.s.o.OpenslideServerBuilder - If you want to use OpenSlide, you'll need to get the native libraries (either building from source or with a packager manager); celery_qupath_1 | and add them to your system PATH, including openslide-jni.; celery_qupath_1 | 05:43:44.319 [main] [INFO ] loci.formats.ImageReader - TiffDelegateReader initializing /mnt/sdb/docker_disk/DATA/maijie01/test1.tif; celery_qupath_1 | 05:43:44.323 [main] [INFO ] loci.formats.in.MinimalTiffReader - Reading IFDs; celery_qupath_1 | 05:43:44.336 [main] [INFO ] loci.formats.in.MinimalTiffReader - Populating metadata; celery_qupath_1 | 05:43:44.349 [main] [INFO ] loci.formats.in.TiffReader - Checking comment style; celery_qupath_1 | 05:43:44.350 [main] [INFO ] loci.formats.in.BaseTiffReader - Populating OME metadata; celery_qupath_1 | 05:43:44.364 [main] [INFO ] q.l.i.s.b.BioFormatsImageServer - No memoization file generated for /mnt/sdb/docker_disk/DATA/maijie01/test1.tif; celery_qupath_1 | 05:43:44.396 [main] [INFO ] q.l.i.servers.ImageServerProvider - Returning server: Bio-Formats for /mnt/sdb/docker_disk/DATA/maijie01/test1.tif; celery_qupath_1 | 05:43:53.593 [plugin-runner-0-1] [INFO ] q.lib.plugins.DetectionPluginTools - 0 nuclei detected (processing time: 9.12 seconds); celery_qupath_1 | 05:43:53.610 [main] [INFO ] q.l.p.CommandLinePluginRunner$CommandLineProgressMonitor - 0 nuclei detected (100%); celery_qupath_1 | 05:43:53.611 [main] [INFO ] q.l.p.CommandLinePluginRunner$CommandLineProgressMonitor - Processing complete in 9.14 seconds; celery_qupath_1 | 05:43:53.611 [main] [INFO ] q.l.p.CommandLinePluginRunner$CommandLineProgressMonitor - Tasks completed!; celery_qupath_1 | 05:43:53.612 [main] [INFO ] qupath.lib.plugins.AbstractPlugin - ; celery_qupath_1 | qupath.imagej.detect.cells.PositiveCellDetection null",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/389:3467,Detect,DetectionPluginTools,3467,https://qupath.github.io,https://github.com/qupath/qupath/issues/389,4,"['Detect', 'detect']","['DetectionPluginTools', 'detect', 'detected']"
Safety," select all of the slides. I specifically; > need the double slashes because I am running Windows.; >; > Once all of the annotation files are in one place, I use the following R; > code to merge it all into one .csv file, which I finally open in Excel,; > edit for clarity, and save. You may find it easier to edit the file names; > before running the R script, I usually use a bulk file rename utility.; >; > library(dplyr); > library(readr); > #Takes multiple annotation files in a ""Path"" directory and mergest them into a single CSV document. Each line of the; > #CSV file represents an annotation, and if a file has multiple annotations, only the first is listed with the file name; > # and all subsequent blank names are part of the first listed file.; > path = ""G:/MyProjectData/Data""; > setwd(path); > outFile <-""Tumor Assay Annotation measurements.csv""; >; > #Replace .txt with whatever identifier will pick up all of the files you want to analyze. Detections or Annotations are common choices; > Annotationfiles <- dir(path,pattern = "".txt""); >; > #an empty frame to place data into; > Measurements <- data.frame(); > #simple for loop to read each file and keep a sum of the cell areas.; > for(i in 1:length(Annotationfiles)){; > data.raw <- read_delim(Annotationfiles[i],""\t"", escape_double = FALSE, trim_ws = TRUE); >; > #place the file names in the first column; > Sample = tools::file_path_sans_ext(Annotationfiles[i]); > data.raw[1,2]<-Sample; > Measurements<-bind_rows(Measurements, data.raw); >; >; > }; >; >; > #set row names to F if you don't want a numbered list as the first column; > write.csv(Measurements, outFile, row.names=T); >; > I am not an expert R coder, so I am sure there are more elegant ways to; > accomplish this, but it works for me!; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/79#issuecomment-305082313>, or mute; > the thread; > <https://github.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/79#issuecomment-305188668:1456,Detect,Detections,1456,https://qupath.github.io,https://github.com/qupath/qupath/issues/79#issuecomment-305188668,1,['Detect'],['Detections']
Safety," size (be cautious!!!); def metadata = getCurrentImageData().getServer().getOriginalMetadata(); metadata.magnification = 40; metadata.pixelWidthMicrons = 0.25; metadata.pixelHeightMicrons = 0.25. setImageType('BRIGHTFIELD_H_DAB');; Thread.sleep(100); setColorDeconvolutionStains('{""Name"" : ""H-DAB TMA40x"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.82788 0.53885 0.15571 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.15891 0.36799 0.91615 "", ""Background"" : "" 210 208 209 ""}');; Thread.sleep(100); runPlugin('qupath.imagej.detect.tissue.SimpleTissueDetection2', '{""threshold"": 224, ""requestedPixelSizeMicrons"": 20.0, ""minAreaMicrons"": 100000.0, ""maxHoleAreaMicrons"": 1000000.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": true, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}');; Thread.sleep(100); selectAnnotations();; Thread.sleep(100); runPlugin('qupath.imagej.detect.nuclei.WatershedCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 14.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.09, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}');; Thread.sleep(100). Error log:. INFO: Starting script at Thu Sep 27 09:20:09 CEST 2018; ERROR: QuPath exception; at com.sun.glass.ui.Application.checkEventThread(Application.java:443); at com.sun.glass.ui.View.getNativeView(View.java:449); at com.sun.glass.ui.win.WinAccessible.get_HostRawElementProvider(WinAccessible.java:672); at com.sun.glass.ui.win.WinAccessible.UiaRaiseAutomationEvent(Native Method); at com.sun.glass.ui.win.WinAccessible.sendNotification(WinAccessible.java:287); at javafx.scene.Node.notifyAccessibleAttributeChanged(Node.java:9604); at javafx.scene.control.TableView$TableViewSelectionModel.focus(TableView.java",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:1334,detect,detectionImageBrightfield,1334,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['detect'],['detectionImageBrightfield']
Safety," text on it.; - [x] It's confusing that there's a list, but nothing can be selected. If I click on the list, the top item can take the focus, but nothing else.; - [x] I'm not sure if the version needs some indication of what it is, either by using a table (and column heading) or adding a v at the start; I think centred vertical alignment for the version and buttons would look bette; - [x] The description text would ideally be lighter in color (e.g. using opacity); - [x] The purpose of the 'remove' and 'update' buttons is unclear - especially for built-in extension that can't be changed. ; - [x] Does update 'Check for updates' or actually update?; - [x] I'm not sure that 'Cancel' and 'Accept' are the right terms; I assume 'Accept' basically means 'Download & install'?. > I'm not sure if the version needs some indication of what it is, either by using a table (and column heading) or adding a v at the start;. I'd be more inclined to even do ""version: 0.1.0"" rather than having column headers that would be largely redundant. > Does update 'Check for updates' or actually update?. It checks for updates; if one is available, it asks if you'd like to download it. If not, it pops up a notification saying it's up-to-date. > I'm not sure that 'Cancel' and 'Accept' are the right terms; I assume 'Accept' basically means 'Download & install'?. Yes, similarly it asks if you want to download before going ahead. ![Screenshot from 2023-10-02 22-37-08](https://github.com/qupath/qupath/assets/10779688/b0404e3f-320d-4fbf-b990-3cad161dee24). Note that here the top list is focusable, the bottom isn't. The titles are obviously WIP (see below). Same with the extensions dir button not being full-width (although I don't truly love that personally, it's up to you). > Finally, I think splitting the lists at the top into different sections would make sense, if they have different purposes. Rather than 'servers' and 'extensions', they could be split between 'Built-in extensions' and 'Optional exten",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1342#issuecomment-1743806490:1436,redund,redundant,1436,https://qupath.github.io,https://github.com/qupath/qupath/pull/1342#issuecomment-1743806490,1,['redund'],['redundant']
Safety," time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Writing object hierarchy with 29994 object(s)...; INFO: Image data written to N:\Faculty-of-Medicine-and-Health\LICAP\DATA\PTHY\Pathology\Breast Group\BCCTB Samples\Audits\BCN QA 2017\Frozen samples QuPath tumourstromaratio\Batch_2\Tumour\402428.qpdata in 2.08 seconds; INFO: Training size: 33x5031; INFO: Responses size: 1x5031; INFO: RTrees classifier termination criteria: { type: 1, maxCount: 50, epsilon: 0.0}; ERROR: QuPath exception; at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseE",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:4096,detect,detect,4096,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detect']
Safety, true}; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 3,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:2841,detect,detected,2841,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety," your post I've just checked and I can reproduce it using *Subtract selected annotations*... in which case the rectangle can hang around for longer. It still *does* disappear (sometimes...) if I select it, then start drawing a new annotation - but not entirely consistently. What I think is happening is this:; * Whenever a ROI is effectively removed (either with the brush tool or subtraction), it results in a rectangle at location (0, 0) with zero width and zero height - this is nevertheless still drawn on screen; * When removing with the brush tool, a sanity check is applied to see if the resulting ROI has no area - and if so, the object is removed (e.g. [see here](https://github.com/qupath/qupath/blob/61a382e1e345e671b3fde32da08e03f08f4f7bcf/qupath-gui-fx/src/main/java/qupath/lib/gui/viewer/tools/AbstractPathDraggingROITool.java#L100)); * This sanity check isn't applied with the *Subtract selected annotations* command... so the 'empty' ROI does not result in the object being automatically removed; * Sometimes the sanity check can be triggered later... but it entirely clear when and why. I've flagged this as a bug, since something here is definitely not right and should be fixed. I do think that there is a broader issue with the usefulness of the commands for combining annotations; these can and should behave more predictably. It may not be helped by the fact that for a long time (before release) QuPath didn't support multiple objects being selected simultaneously, and much of the original code was written back in those days; as you can imagine, this was quite limiting. You're completely right about support for subtracting multiple annotations being tricky from a how-to-present-this-to-the-user point of view. I will give this some more thought. My preference would be to replace the existing commands to combine annotations with entirely new ones that have more clearly defined purposes and limitations. In the meantime, since you're already coding, it might be helpful t",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/78#issuecomment-302926092:1277,sanity check,sanity check,1277,https://qupath.github.io,https://github.com/qupath/qupath/issues/78#issuecomment-302926092,1,['sanity check'],['sanity check']
Safety,"![111](https://user-images.githubusercontent.com/31824571/30250353-233ffab2-964d-11e7-8df9-09bcddfdb1a9.png). Hello all, ; Sorry if my question is basic but I could'nt find an answer and am looking for your help.; So I have 500 Scans of renal biopsies which are stained for Macrophages (CD68). The question is how can I tile the already marked tissue Area through (Simple Tissue detection) into 3 regions of interest (Cortex, Medulla and extrarenal tissue)?. Does it work somehow to draw lines to seperate the areas?.; Next question is, can I get a table with the percentages of positive Area for each ROI in all 500 slides? . Many Thanks",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/99:379,detect,detection,379,https://qupath.github.io,https://github.com/qupath/qupath/issues/99,1,['detect'],['detection']
Safety,"![17032701](https://cloud.githubusercontent.com/assets/15114623/26643056/f94028f8-45fd-11e7-9c55-953359b2a21b.png). I apologize if this issue has already been posted. Sometimes, when running the cell detection algorithm, certain tiles demonstrate variability in detection (as pictured). . How can I reduce or remove this variability between tiles?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/80:200,detect,detection,200,https://qupath.github.io,https://github.com/qupath/qupath/issues/80,2,['detect'],['detection']
Safety,"![roi_image](https://user-images.githubusercontent.com/40424957/42136435-27fb3254-7d53-11e8-849a-be9f82ae2613.png). Dear Pete,. yes, I chose the wrong words, I didnt want to say bad things about QuPath, I like it. I just described what I miss most (acutely, get the .rois to ImageJ and in general, some API to look up classes and methods and so on), with caring too less about my wording. I am sorry. ; Yes, I am not using whole slide images this time, but IHC-fluorescence. And I want to quantify DNA-damage foci and that I know best in ImageJ. I tried to attach an image, so the script for the .rois works very well, thank you. But I would like to do more with QuPath, now that I know the .rois get out, I can write the script to do the cell detection and the classification for the whole folder of images automatically. And I also like to contribute to the project, so if there is a place to donate...; Best regards; Philipp",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/182#issuecomment-401617889:744,detect,detection,744,https://qupath.github.io,https://github.com/qupath/qupath/issues/182#issuecomment-401617889,1,['detect'],['detection']
Safety,""" : ""DAB"", ""Values 2"" : ""0.72191 0.55664 0.41109 "", ""Background"" : "" 255 255 255 ""}');; selectAnnotations();; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.27, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 2.0, ""minAreaMicrons"": 30.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.6, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.4, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; ```; ![image](https://user-images.githubusercontent.com/23145209/50290376-79864380-0439-11e9-86dc-7b4375cee119.png); ![image](https://user-images.githubusercontent.com/23145209/50290399-873bc900-0439-11e9-937b-7dc5c5ce1139.png). A couple of things to note about this, some cells in certain sections of your sample are so dark that they basically show up as all colors. That makes them very difficult to distinguish, although it might be possible to exclude them or classify them as a third type if it is important enough. The script above should work for the central areas with the blue stained cells. Your scanner/sample plane is also slightly off, and you can see that in the above screenshots where the lower right corner of the (by image) frame changes focus. Small variations like that can have significant impacts on detecting faintly stained objects, so your negative nuclear accuracy may vary based on where in the frame you are counting. ![image](https://user-images.githubusercontent.com/23145209/50290628-43958f00-043a-11e9-9125-032f51c04a5d.png). That said, hopefully the above script works well for you. I ended up selecting a small area that included a blue nucleus and manually adjusting the color vectors, which are included in the script.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/250#issuecomment-449019237:2289,detect,detecting,2289,https://qupath.github.io,https://github.com/qupath/qupath/issues/250#issuecomment-449019237,1,['detect'],['detecting']
Safety,""": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Requesting region for stain vector editing: ; INFO: Adding Rectangle to hierarchy; INFO: Requesting region for stain vector editing: ; INFO: 989 nuclei detected (processing time: 1.90 seconds); INFO: Processing complete in 1.92 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 2443 nuclei detected (processing time: 2.11 seconds); INFO: Processing complete in 2.15 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 2443 nuclei detected (processing time: 3.01 seconds); INFO: Processing complete in 3.03 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Smoothing using TMA",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418647572:3546,detect,detectionImageBrightfield,3546,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418647572,1,['detect'],['detectionImageBrightfield']
Safety,"""Cell detection"" variability between tiles",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/80:6,detect,detection,6,https://qupath.github.io,https://github.com/qupath/qupath/issues/80,1,['detect'],['detection']
Safety,"""No features selected!"" when attempting to create detection classifier",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/63:50,detect,detection,50,https://qupath.github.io,https://github.com/qupath/qupath/issues/63,1,['detect'],['detection']
Safety,"""create detection classifier"" function not found in QP version0.4",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1269:8,detect,detection,8,https://qupath.github.io,https://github.com/qupath/qupath/issues/1269,1,['detect'],['detection']
Safety,"""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 1165 nuclei detected (processing time: 3.94 seconds); INFO: Processing complete in 3.98 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Requesting region for stain vector editing: ; INFO: Adding Rectangle to hierarchy; INFO: Requesting region for stain vector editing: ; INFO: 989 nuclei detected (processing time: 1.90 seconds); INFO: Processing complete in 1.92 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 2443 nuclei detected (processing time: 2.11 seconds); INFO: Processing complete in 2.15 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"":",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418647572:2919,detect,detect,2919,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418647572,1,['detect'],['detect']
Safety,"""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Requesting region for stain vector editing: ; INFO: Adding Rectangle to hierarchy; INFO: Requesting region for stain vector editing: ; INFO: 989 nuclei detected (processing time: 1.90 seconds); INFO: Processing complete in 1.92 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 2443 nuclei detected (processing time: 2.11 seconds); INFO: Processing complete in 2.15 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 2443 nuclei detected (processing time: 3.01 seconds); INFO: Processing complete in 3.03 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundar",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418647572:3507,detect,detect,3507,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418647572,1,['detect'],['detect']
Safety,"## Before we begin... Before submitting your bug report, please check the following:. * [x] I've definitely found a bug (it you're not sure, please use [image.sc](https://forum.image.sc/tags/qupath) instead); * [x] I've checked https://qupath.github.io for a new release that might already have fixed the issue; * [x] I've checked the [Changelog](https://github.com/qupath/qupath/blob/master/CHANGELOG.md) to see if the bug has already been fixed in the next release; * [x] I've checked for existing GitHub issues describing the same problem. ## Bug report. **Describe the bug**; When using Jet (legacy), the ColorMap returns the first RGB map value for all values if max < min. Reported here first: https://forum.image.sc/t/qupath-lut-change-in-measurmernts-maps/92030/4. **To Reproduce**; Steps to reproduce the behavior:; 1. Create detections; 2. Open measurement maps; 3. Select jet color scheme; 4. Move max above min. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**. Regular:; ![Screenshot from 2024-02-19 12-12-14](https://github.com/qupath/qupath/assets/10779688/eadbae26-a73b-4f47-997c-51ff574fbdcc). Inverted:; ![Screenshot from 2024-02-19 12-12-22](https://github.com/qupath/qupath/assets/10779688/8571c9fa-e4ce-4971-b5fc-0bcefe2933c0). **Desktop:**. - OS: Linux (any though); - QuPath Version: [e.g. 0.5.0]. **Additional context**; PR incoming, this is just to document the behaviour",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1470:835,detect,detections,835,https://qupath.github.io,https://github.com/qupath/qupath/issues/1470,1,['detect'],['detections']
Safety,"## Bug report - 'Add intensity features' not working. I am trying to calculate the intensity feature for my image. I selected a ROI and divided it into tiles, trimming the tiles to ROI. then I select the detections (tiles) and I try to run Analyze->Calculate features->Add intensity features. I select the channel of interest and all the features (Mean, Std dev, min max and median), then I run the analysis for the selected objects (tiles). Now, quite often, it is not possible to get the measurement for all my tiles, but only for few initial tiles and then the calculation stops (which I can assess in the 'show detection measurements' table. . I am running QuPath on a macOS. . Do you know what I can do to fix this error? . ![Screenshot 2023-08-15 at 09 44 06](https://github.com/qupath/qupath/assets/142295421/d334a749-9599-4d52-bc49-6728835240a6)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1290:204,detect,detections,204,https://qupath.github.io,https://github.com/qupath/qupath/issues/1290,2,['detect'],"['detection', 'detections']"
Safety,"## Bug report. **Describe the bug**. When running cell detection on a brightfield image and specifying that hematoxylin should be used for detection, the first deconvolved channel is *always* used - regardless of whether it is actually the one corresponding to hematoxylin or not. This is hard-coded at https://github.com/qupath/qupath/blob/88c7cc45648c1d5b09a840bd1e497ea9a46453aa/qupath-core-processing/src/main/java/qupath/imagej/detect/cells/WatershedCellDetection.java#L231. **To Reproduce**; Steps to reproduce the behavior:; 1. Open a brightfield image e.g. *CMU-1-Small-Region.svs*; 2. Set type to *Brightfield (Other)*; 3. Set 2 or 3 stains, ensuring Hematoxylin is *not* the first; 4. Run *Cell detection* using hematoxylin image; 5. Inspect image to check which channel was really used for detection. **Expected behavior**; The minimal required changes are:; * Use the stain name to identify the hematoxylin image, don't just assume it's the first; * Log a clear warning or throw an exception if anything else is done / there is no hematoxylin available. Ideally, options to detect using any/all stains should be provided to the user. **Screenshots**; Using the following stains; ```groovy; setColorDeconvolutionStains('{""Name"" : ""Some other stains"", ""Stain 1"" : ""Something"", ""Values 1"" : ""0.11793 0.84247 0.52567"", ""Stain 2"" : ""Another"", ""Values 2"" : ""0.32293 0.56288 0.76084"", ""Stain 3"" : ""Hematoxylin "", ""Values 3"" : ""0.61203 0.70103 0.36602"", ""Background"" : "" 255 255 255""}');; ```; the detection looks as below; ![Screenshot 2021-12-26 at 07 51 32](https://user-images.githubusercontent.com/4690904/147402284-3dd60b6b-e301-4efc-850d-fb35f56ced0d.jpg); ![Screenshot 2021-12-26 at 07 51 39](https://user-images.githubusercontent.com/4690904/147402286-d946f166-c927-4d24-9b56-3fec4a54a192.jpg); ![Screenshot 2021-12-26 at 07 51 43](https://user-images.githubusercontent.com/4690904/147402287-b250b3f1-9891-45d7-a1bd-2aea942a185a.jpg); ![Screenshot 2021-12-26 at 07 51 55](https://user-ima",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/878:55,detect,detection,55,https://qupath.github.io,https://github.com/qupath/qupath/issues/878,5,['detect'],"['detect', 'detection']"
Safety,"## Bug report. **Describe the bug**; ""Copy to Clipboard"" for detection results fails due to NUL-Byte in text. **To Reproduce**; Steps to reproduce the behavior:; 1. Create some annotation; 2. Run cell detection; 3. Open ""Show detection measurements""; 4. Select one or multiple measurements; 5. Click on ""Copy to Clipboard""; 6. Paste into text editor; 7. Result: Headers are copied, data terminates after the content of the ""Image"" field for the first entry. In contrast: Export to file via ""Save"" works and shows that a NUL-byte is present in the ""Image"" fields - which probably interferes with the clipboard functionality. **Expected behavior**; Content in the clipboard should be identical to the one that can be obtained by saving to text via ""Save"". **Screenshots**; Copy-paste result:; ![copy-paste](https://user-images.githubusercontent.com/4951046/88553507-a6430980-d025-11ea-810f-da10d831f57e.png). Save to file result, showing NUL bytes in the Image field:; ![save-to-file](https://user-images.githubusercontent.com/4951046/88553625-c4a90500-d025-11ea-9a4d-30cb18899a44.PNG). **Desktop (please complete the following information):**; - OS: Windows 10; - QuPath Version 0.2.1. Thank you & best regards,; Simon",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/573:61,detect,detection,61,https://qupath.github.io,https://github.com/qupath/qupath/issues/573,3,['detect'],['detection']
Safety,"## Bug report. **Describe the bug**; *Detect centroid distances 2D* doesn't calculate distances for different planes of a z-stack; only the default plane is supported. Relatedly, *Convert detections to points* under the counting tool adds points to the default plane - not the plane on which the detections were originally. **To Reproduce**; See https://forum.image.sc/t/cannot-detect-centroid-distances-in-2d-when-i-have-multiple-planes-in-my-images/50958. **Expected behavior**; 2D distance operations work on planes of an image. They are not expected to work across planes, but should return distances within each plane. *Convert detections to points* works as expected for z-stacks/time series. **Desktop (please complete the following information):**; - OS: All platforms; - QuPath Version v0.2.x. **Additional context**; The underlying problem is that [`PathObjectTools.convertToPoints(Collection<PathObject> pathObjects, boolean preferNucleus)`](https://github.com/qupath/qupath/blob/43aad4ecda893a7eb03c30774e64da5b9547bc86/qupath-core/src/main/java/qupath/lib/objects/PathObjectTools.java#L469) always uses the default plane.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/696:38,Detect,Detect,38,https://qupath.github.io,https://github.com/qupath/qupath/issues/696,5,"['Detect', 'detect']","['Detect', 'detect-centroid-distances-in-', 'detections']"
Safety,"## Bug report. **Describe the bug**; *Resolve hierarchy* does not work correctly when applied to images containing both TMA cores and detections. **To Reproduce**; Steps to reproduce the behavior:; 1. Open and dearray a TMA image; 2. Create an annotation inside a core; 3. Detect cells within the annotation; 4. Call *Resolve hierarchy*. The detections are now 'orphaned'; no longer under the parent annotation (but rather under the root object). **Expected behavior**; Detection objects remain under their parent annotation, which should now be correctly assigned below the corresponding TMA core. **Additional context**; First noticed when exploring https://forum.image.sc/t/spatial-analysis-distance-to-annotation-2d-performance-in-tmas/39288",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/540:134,detect,detections,134,https://qupath.github.io,https://github.com/qupath/qupath/issues/540,4,"['Detect', 'detect']","['Detect', 'Detection', 'detections']"
Safety,"## Bug report. **Describe the bug**; .qpdata files corresponding to OMERO images cannot be opened directly, but rather *only* via a project. **To Reproduce**; Steps to reproduce the behavior:; 1. Open an image hosted via OMERO (e.g. through IDR) *without* using a QuPath project; 2. Draw an annotation and save a .qpdata file; 3. Restart QuPath (or open another image) and then try opening the .qpdata file... this gives a NPE. **Expected behavior**; Images can be reloaded from .qpdata files, without necessarily occurring inside projects. **Desktop (please complete the following information):**; - QuPath v0.2.2 and earlier. **Additional context**; This happens because; 1. .qpdata files store only the basic file path / URI (since that's what they did in v0.1.2), and *not* the full information needed to build the server; 2. the path alone isn't parsed [here](https://github.com/qupath/qupath/blob/master/qupath-extension-omero/src/main/java/qupath/lib/images/servers/omero/OmeroWebImageServerBuilder.java#L264). I think the 'best' solution is to store the JSON representation of the `ServerBuilder` inside the `.qpdata` file. Although this is redundant when inside a project, it is needed elsewhere. However, backwards compatibility should be maintained so that older .qpdata files can be read. For the same reasons, other more complex servers cannot be reconstructed from `.qpdata` files alone, e.g. rotated servers. This makes it *essential* to use a project in many cases. An alternative (short-term) approach *to resolve the OMERO problem only* would be to update the `getURIs(URI, String...)` method to parse the path. That would work around issues in v0.2 for OMERO, but doesn't resolve the bigger problem.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/598:1149,redund,redundant,1149,https://qupath.github.io,https://github.com/qupath/qupath/issues/598,1,['redund'],['redundant']
Safety,"## Bug report. **Describe the bug**; 1. TMA Data viewer table colors does not match with the ""Moderna Dark"" theme; 2. TMA Data viewer table has missing values for column Object ID, Name, Missing, Centroid X, and Centroid Y; 3. Vertical scrolling for the TMA Data Viewer is sluggish (only when loading from the entire project which has a lot of detections) . **To Reproduce**; Steps to reproduce the behavior:; 1. Open a project with TMA images, open an image with TMA Data; 4. Click on File -> ""TMA Data"" -> ""Launch TMA Data Viewer""; 5. In the TMA Result Viewer window unchecking the ""Group by ID"" results in a table with light background and gray text. See the screenshot; 6. Values from the following columns are missing: Object ID, Name, Missing, Centroid X, and Centroid Y; 7. Test vertical scrolling in the TMA Data Viewer. **Expected behavior**; 1. TMA Data viewer colors should match ""Moderna Dark"" theme; 2. Populate values for the following columns: Object ID, Name, Missing, Centroid X, and Centroid Y; 3. Improve table for smooth vertical scrolling - if possible!. **Screenshots**; <p align=""center"">; <img src=""https://user-images.githubusercontent.com/10900214/197264041-a4c298d4-b3b3-43e8-a142-9d8d9b8ff47a.png"" width=""800"">; </p>. **Desktop (please complete the following information):**; - OS: Windows 10; - QuPath Version: 0.3.2 & 0.4.0-SNAPSHOT",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1083:344,detect,detections,344,https://qupath.github.io,https://github.com/qupath/qupath/issues/1083,1,['detect'],['detections']
Safety,"## Bug report. **Describe the bug**; Add intensity measurements fails with error below when run on a JPG image (set to image type fluorescence). It seems likely that this is due to the normalized OD colors channel showing up second in the list, which inserts it into the channel list prior to the Red Green and Blue channels.; ![image](https://user-images.githubusercontent.com/23145209/65450506-1b382800-ddf2-11e9-82ba-681885b1897b.png); ERROR: Error running plugin: java.lang.IllegalArgumentException: No boolean parameter with key 'colorOD'; at java.base/java.util.concurrent.FutureTask.report(Unknown Source); at java.base/java.util.concurrent.FutureTask.get(Unknown Source); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:193); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:157); at qupath.lib.gui.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:156); at qupath.lib.algorithms.IntensityFeaturesPlugin.runPlugin(IntensityFeaturesPlugin.java:355); at qupath.lib.gui.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:185); at java.base/java.lang.Thread.run(Unknown Source); **To Reproduce**; Steps to reproduce the behavior:; Load a 3 color fluorescent image that has been converted into a JPG (Wince. Yes.) Generate cells, try to run Add Intensity Features. Adding fails with a message that is only reported in the log. In multichannel images there is no Normalized OD colors channel that expects or generates OD measurements. In previous versions 1.2/1.3 this also did not occur. I haven't exhaustively checked which M# versions are affected. **Desktop (please complete the following information):**; - OS: Win10; - QuPath Version 0.2.0m4. **Additional context**; Referencing: https://forum.image.sc/t/saving-cell-detection-locations-and-loading-them-in-another-image/29746/12",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/365:1879,detect,detection-locations-and-loading-them-in-another-image,1879,https://qupath.github.io,https://github.com/qupath/qupath/issues/365,1,['detect'],['detection-locations-and-loading-them-in-another-image']
Safety,## Bug report. **Describe the bug**; Adding/removing points is slow whenever many objects are present on an image. There can be a brief-but-disturbing delay of a second or so when making adjustments. This relates to the work involved in processing hierarchy update events when interactively annotating with the counting tool. **To Reproduce**; Steps to reproduce the behavior:; 1. Open an image & create thousands of detections; 2. Create a Point annotation and add/remove points. **Expected behavior**; Adding points is almost instantaneous. **Desktop (please complete the following information):**; - OS: All; - QuPath Version v0.2.0-m9 (and probably some earlier ones),MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/412:417,detect,detections,417,https://qupath.github.io,https://github.com/qupath/qupath/issues/412,1,['detect'],['detections']
Safety,"## Bug report. **Describe the bug**; After running QuPath's cell detection on a multichannel fluorescent image with Channel names ""Nuclei"" and ""Protein X"", the measurements; 'Nucleus: Nuclei sum` and `Nucleus: Protein X sum` are computed. However the following measurements are missing; 'Cell: Nuclei sum` and `Cell: Protein X sum`; 'Cytoplasm: Nuclei sum` and `Cytoplasm: Protein X sum`. **To Reproduce**; Steps to reproduce the behavior:; 1. Open a fluorescence image; 2. Use Cell detection with a non zero expansion; 3. Look a the resulting measurements for each cell. **Expected behavior**; All compartments should have `sum` measurement for all channels or not have it at all. **Screenshots**; ![image](https://github.com/qupath/qupath/assets/319932/9bbf5da2-b5bb-4cae-a0b1-4efa96e2ec5a); Image with cells detected and the detectiom measurements showing the columns containing `sum`; The non-`Nucleus` compartments do not have a `sum` measurement. **Desktop (please complete the following information):**; - OS: Windows 11; - QuPath Version: 0.5.0. All the best",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1454:65,detect,detection,65,https://qupath.github.io,https://github.com/qupath/qupath/issues/1454,4,['detect'],"['detected', 'detectiom', 'detection']"
Safety,"## Bug report. **Describe the bug**; Calling `resolveHierarchy()` for some images with both TMA cores and detections can be extremely, unusably slow.; See https://forum.image.sc/t/resolve-hierarchy-improve-tma-performance/40705 where a time > 4 hours is reported. **To Reproduce**; Steps to reproduce the behavior:; 1. Apply dearraying to a TMA image; 2. Detect cells in the image; 3. Add annotations within cores, but not for the *full* core (i.e. allow detections inside cores but outside annotations); 4. Call *Resolve hierarchy*. It may be necessary to call *Resolve hierarchy* twice to see the issue. **Expected behavior**; The hierarchy is resolved in seconds / no more than a few minutes. **Affected version**; v0.2.1. **Additional context**; The time is spent in `ensureCacheCreated()`.; Ultimately, the performance problem occurs if 'parentless' detections need to be added [here](https://github.com/qupath/qupath/blob/c417905851de2c778573ebebff60c33b284ba82d/qupath-core/src/main/java/qupath/lib/objects/hierarchy/PathObjectHierarchy.java#L279). The cache is reset for every detection that must be added.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/564:106,detect,detections,106,https://qupath.github.io,https://github.com/qupath/qupath/issues/564,5,"['Detect', 'detect']","['Detect', 'detection', 'detections']"
Safety,"## Bug report. **Describe the bug**; Cell expansion (including nucleus size constraint) can fail due to a TopologyException. See:; * https://forum.image.sc/t/stardist-in-qupath-error-message/41242; * https://forum.image.sc/t/topologyexception-found-non-noded-intersection-between-linestring/38549. **To Reproduce**; Hard to reproduce... but depends upon running StarDist cell detection in QuPath v0.2.2 with cell expansion set. Fails intermittently. **Expected behavior**; A single cell failure doesn't cause everything to break down. **Additional context**; Adding in validity checks along the way risks having a substantial performance impact in the majority of cases that *do* work fine, so a more graceful recovery from errors may be sufficient.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/587:376,detect,detection,376,https://qupath.github.io,https://github.com/qupath/qupath/issues/587,3,"['detect', 'recover', 'risk']","['detection', 'recovery', 'risks']"
Safety,"## Bug report. **Describe the bug**; Error message with 'Locked status cannot be set!' when trying to add pixel classifier measurements to a full image (rather than annotations or detections). **To Reproduce**; Steps to reproduce the behavior:; 1. Create and save pixel classifier or thresholder; 2. Request adding measurements everywhere. **Expected behavior**; No attempt is made to lock the 'Image' (root) object, and no error is shown. **Desktop (please complete the following information):**; - QuPath v.0.2",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/595:180,detect,detections,180,https://qupath.github.io,https://github.com/qupath/qupath/issues/595,1,['detect'],['detections']
Safety,"## Bug report. **Describe the bug**; I compiled QuPath with Stardist as described in the docs. The detection of nuclei on the blue channel works fine (although the cell expansion value is ignored). The Measurements are however not correct! I get only values for the red channel of a RGB image (see attachment) and they are incorrect (negative values, see screenshot). There are no values for the green channel. **To Reproduce**; The script (I have it in a subfolder of the QuPath executable 'ScriptStardist', it finds the model then automatically.; [ScriptStardist.zip](https://github.com/qupath/qupath/files/6183384/ScriptStardist.zip). The image (ImageJ Tiff file); [CTRL-01.zip](https://github.com/qupath/qupath/files/6183389/CTRL-01.zip). **Expected behavior**; Measurements like the 'Cell Detection' command. **Screenshots**; Screenshot of the negative values.; ![ss-negative-values](https://user-images.githubusercontent.com/46439648/112015678-5244e200-8b2c-11eb-9654-41fcd2c50c4f.png). **Desktop (please complete the following information):**; - OS: Windows; - QuPath Version 0.2.3 and 0.3.0 Snapshot 22/3/2021",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/686:99,detect,detection,99,https://qupath.github.io,https://github.com/qupath/qupath/issues/686,2,"['Detect', 'detect']","['Detection', 'detection']"
Safety,"## Bug report. **Describe the bug**; If I create objects using a pixel classifier, but set the minimum size to larger than any object that would be created, it creates a phantom polyline object. This does not appear on the image, and has a centroid position of NaN, but is listed in the hierarchy. It happens for either type of pixel classifier and for annotation or detection objects. If I create objects inside a collection of parent annotations, the regions that have valid new detection work fine, but the ones that don't each get a polyline. . **To Reproduce**; Steps to reproduce the behavior:; 1. Train a pixel classifier.; 2. Create objects (detection or annotation). Set the minimum size to be larger than whatever region this classifier is selecting. ; 3. A surprise polyline object appears in the hierarchy. . **Expected behavior**; No object should be created at all. **Screenshots**; Set up:; ![image](https://user-images.githubusercontent.com/29264310/85805453-34fbf800-b701-11ea-95ae-3b2463227743.png). Invisible Polyline:; ![image](https://user-images.githubusercontent.com/29264310/85805506-5f4db580-b701-11ea-9265-bc5dae3f29db.png). **Desktop (please complete the following information):**; Windows 10. ; QuPath 0.2.1 (tensorflow-cpu build).",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/544:367,detect,detection,367,https://qupath.github.io,https://github.com/qupath/qupath/issues/544,3,['detect'],['detection']
Safety,"## Bug report. **Describe the bug**; If attempting to remove over 255 measurements at once through the measurement manager, the corresponding workflow entry for that action will throw an error. This is due to the maximum number of supported arguments for a groovy function being 255. **To Reproduce**; Steps to reproduce the behavior:; 1. Create >255 different measurements for a project entry containing detection objects.; 2. Remove >255 measurements through the measurement manager GUI in one action.; 3. Create a script from the workflow tab consisting of all of the above actions. Note the error message:; `ERROR: MultipleCompilationErrorsException: startup failed:; General error during instruction selection: The max number of supported arguments is 255, but found 1191`. **Expected behavior**; The script generated from the workflow tab should be able to reproduce most of the plugin-based actions, including the act of removing measurements. A quick fix is to modify the generated script and distribute the list of measurements to remove over multiple `removeMeasurement()` operations. **Screenshots**; ![image](https://user-images.githubusercontent.com/52012166/154319405-e0b09a53-0f29-4feb-a77f-43640053b828.png). **Desktop (please complete the following information):**; - OS: Windows 10; - QuPath Version 0.4.0-SNAPSHOT. **Additional context**; Minor issue, easy enough to manually distribute the list of measurements to remove over multiple `removeMeasurement()` statements",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/915:405,detect,detection,405,https://qupath.github.io,https://github.com/qupath/qupath/issues/915,1,['detect'],['detection']
Safety,"## Bug report. **Describe the bug**; If we have detections and cell objects and try to run Detection Centroid Distances 2D, it will only output a result for the cells and not the detections. . **To Reproduce**; Steps to reproduce the behavior:; 1. Annotate a small region and use cell detection to create cells (with expansion) and classify them as ""Stroma""; 2. Annotate another region (It can overlap with the other, but it does not matter) and detect cells **without** expansion, label them as ""Other""; 3. Use **Detection Centroid Distances 2D** with the defaults; 4. If you look at the Cell objects, they have a **Distance to detection with Stroma um**; 5. If you look at the Detections (not expanded cells) there is no measurement. If you repeat the steps above but make only **Cell objects** or **Detections without expansion** (Where both are of the same type) then it works as expected, meaning both PathObjects have the distance measurements. **Expected behavior**; I would expect the Detection Centroid Distances 2D would work for heterogeneous groups (cells and detections) as cells are detections too. **Desktop (please complete the following information):**; - OS: Win 11; - QuPath Version: 0.5.1",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1550:48,detect,detections,48,https://qupath.github.io,https://github.com/qupath/qupath/issues/1550,12,"['Detect', 'detect']","['Detection', 'Detections', 'detect', 'detection', 'detections']"
Safety,"## Bug report. **Describe the bug**; In a project I'm currently working on, QuPath seems to be distorting images so that I am unable to reliably do a cell detection, analyze and even view the images. When I open the images in other image processing programs like gimp the images do not appear distorted. It looks like the distortion that is taking place is that part of the image is being copied and translated into a different part of the image. . **To Reproduce**; Steps to reproduce the behavior:; 1. Go to QuPath 0.1.2; 2. Click on File -> Open Image; 3. Select specific image; 4. See error. **Expected behavior**; The image should not be cut into pieces and distorted. . **Screenshots**; Here is what the image should look like:( Here I opened the .tif image in gimp). ![image](https://user-images.githubusercontent.com/10617598/70916106-1f3aa700-1fe9-11ea-91d2-72f5340bdcb4.png). Here is what the image looks like in QuPath:( note I have drawn an annotation in the image here- the red rectangle which can be ignored). ![image](https://user-images.githubusercontent.com/10617598/70915929-c79c3b80-1fe8-11ea-87b3-7c16e5dc3fef.png). Here is what the image looks like in QuPath when I do a cell segmentation on the image. ![image](https://user-images.githubusercontent.com/10617598/70916181-3da0a280-1fe9-11ea-9d5d-fff3625a9fe5.png). You can see here that there are areas of the screen which have no cells but are being marked as having cells due to this distortion. . **Desktop (please complete the following information):**; - OS: Ubuntu 16.04; - QuPath Version 0.1.2. **Additional context**; The images being analyzed were originally .ndpi files which were converted to .tif files. When I open them in other image processing programs like gimp the images are not distorted. Also, the thumbnails which are displayed in the image list of the left of the QuPath window do not appear distorted like in the gimp images. . ![image](https://user-images.githubusercontent.com/10617598/70916404-a1c36680-1",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/386:155,detect,detection,155,https://qupath.github.io,https://github.com/qupath/qupath/issues/386,1,['detect'],['detection']
Safety,"## Bug report. **Describe the bug**; In some circumstances, a `ConcurrentModificationException` can be thrown when working with measurement lists in parallel threads. A related issue is reported at https://github.com/qupath/qupath/pull/1466 but the proposed fix does not solve the problem here. **To Reproduce**; Try running the script below:; ```groovy; // A growing list of objects; def pathObjects = Collections.synchronizedList([]). // Number of iterations; int n = 1000. // Create a thread to continually request all measurement names; def t = new Thread( {; while (pathObjects.size() < n) {; def list = PathObjectTools.getAvailableFeatures(new ArrayList<>(pathObjects)); }; }); t.start(). // Create a parallel stream to add new objects; java.util.stream.IntStream.range(0, n); .parallel(); .forEach(i -> {; // This happens only with detections!; def pathObject = PathObjects.createDetectionObject(ROIs.createEmptyROI()); pathObjects << pathObject; for (int k = 0; k <= i; k++); pathObject.measurementList.put(""M_$k"", i); }); t.join(); ; println ""Done!""; ```. I see an exception; ```; ERROR: null; java.util.ConcurrentModificationException: null; at java.base/java.util.ArrayList$Itr.checkForComodification(Unknown Source); at java.base/java.util.ArrayList$Itr.next(Unknown Source); at java.base/java.util.Collections$UnmodifiableCollection$1.next(Unknown Source); at java.base/java.util.AbstractCollection.addAll(Unknown Source); at qupath.lib.objects.PathObjectTools.getAvailableFeatures(PathObjectTools.java:2026); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript$_run_closure1.doCall(QuPathScript:11); at QuPathScript$_run_closure1.doCall(QuPathScript); at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(Unknown Source); at java.base/java.lang.reflect.Method.invoke(Unknown Source); at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:343); at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:328);",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1591:839,detect,detections,839,https://qupath.github.io,https://github.com/qupath/qupath/issues/1591,1,['detect'],['detections']
Safety,"## Bug report. **Describe the bug**; Initial bug report and steps to reproduce at https://forum.image.sc/t/qupath-script-cannot-access-java-library-and-project-data-simultanely/63388. The problem is that a class cannot be loaded from an extension far for multiple images in a project. When I tried, the first image 'worked' but all subsequent images failed with the error; ```; It looks like you have tried to import a class ‘qupath.ext.biop.cellpose.CellposeSetup’ that doesn’t exist!; MultipleCompilationErrorsException at line 7: startup failed:; Script2.groovy: 8: unable to resolve class qupath.ext.biop.cellpose.CellposeSetup; ```. **Expected behavior**; Extension jars are available for all images in the project when running from the command line, similar to how they are available when running through the GUI. **Desktop (please complete the following information):**; - OS: All; - QuPath v0.3.2 (earlier versions had other extension classpath problems). **Additional context**; The problem originates at https://github.com/qupath/qupath/blob/main/qupath-app/src/main/java/qupath/QuPath.java#L299 when a new `ExtensionClassLoader` instance is created. We need to instead use `QuPathGUI.getExtensionClassLoader()` consistently, since this is also requested within `DefaultScriptEditor`, e.g. [here](https://github.com/qupath/qupath/blob/7090e8137825f8f7dbc623c20bc62030c5c7db65/qupath-gui-fx/src/main/java/qupath/lib/gui/scripting/DefaultScriptEditor.java#L479). But if doing that, it may make more sense to add an `ExtensionClassLoader.getInstance()` method to avoid relying on `QuPathGUI.class` altogether.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/914:1570,avoid,avoid,1570,https://qupath.github.io,https://github.com/qupath/qupath/issues/914,1,['avoid'],['avoid']
Safety,"## Bug report. **Describe the bug**; Issue detected when naming a stain vector the same as a built-in channel name (eg. ""Red""). Interferes with brightness/contrast viewing. . **To Reproduce**; Steps to reproduce the behavior:; 1. Set stain vector to ""Red""; 2. Open brightness and contrast and view the ""Red"" channel on its own (select ""Keep settings""); 3. Save and open another image; 4. Return to original image and view the ""Red"" channel on its own, is it consistent to what was seen before?. **Expected behavior**; Brightness and contrast min and max to remain consistent when returning to the image. . **Screenshots**. **Desktop (please complete the following information):**; - OS: Windows; - QuPath Version: 0.4.3. **Additional context**",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1245:43,detect,detected,43,https://qupath.github.io,https://github.com/qupath/qupath/issues/1245,1,['detect'],['detected']
Safety,"## Bug report. **Describe the bug**; It isn't possible to run cell detection on channels with `""` in the name. This has come up twice on the forum so far:; * https://forum.image.sc/t/error-when-trying-to-run-cell-detection-plugin/62739; * https://forum.image.sc/t/error-in-loading-ome-tiff-images-in-qupath/29758/16. **To Reproduce**; Steps to reproduce the behavior:; 1. Open a fluorescence (non-RGB) image; 2. Change a channel name to `""DAPI""` or similar; 3. Try to run cell detection; 4. Observe an error - something pretty & informative like5. ; ```; Plugin error: com.google.gson.stream.MalformedJsonException: Unterminated object at line 1 column 23 path $.; ```. **Expected behavior**; A `""` in a channel name isn't a good idea, but it shouldn't be a deal breaker. **Desktop (please complete the following information):**; - OS: All; - QuPath v0.3.2 and earlier. **Additional context**; The root cause is my dodgy JSON-converting code at https://github.com/qupath/qupath/blob/main/qupath-core/src/main/java/qupath/lib/plugins/parameters/ParameterList.java#L585. Switching to use `GsonTools` should resolve it, but this will need a bit of care to ensure nothing breaks along the way.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1022:67,detect,detection,67,https://qupath.github.io,https://github.com/qupath/qupath/issues/1022,3,['detect'],"['detection', 'detection-plugin']"
Safety,"## Bug report. **Describe the bug**; Many `ImageServer` implementations are derived from `AbstractTileableImageServer`, which breaks requests into fixed tiles and fulfils them using a cache where possible. Duplicate tile requests occur e.g. when writing an OME-TIFF using multithreading or running a pixel classifier and with a tile size larger than the tile size of the reader. It can result in the same image tiles being read multiple times, potentially adding considerable unnecessary overhead (since tile decompression can be a bottleneck). Reducing or eliminating this can potentially improve performance substantially, particularly for cases where tile reading is slow. **To Reproduce**; The bug can easily be reproduced when writing a pyramidal OME-TIFF or training a pixel classifier - although unfortunately it isn't easy to *tell* that it has been reproduced, since the duplicate requests aren't reported. The problem was identified through VisualVM profiling and running in debug mode, checking for repeated tile requests while trying to improve image write performance. **Expected behavior**; If a thread wants to obtain a tile that is currently being read by another thread, the first thread should wait until the tile is returned - it should *not* submit a new read request. **Desktop (please complete the following information):**; - OS: All; - QuPath Version 0.3.0 (and earlier). **Additional context**; This isn't really an issue when only viewing images, since requests are made that perfectly match tiles available through the `ImageServer` and pending requests are checked. However it can be an issue when regions are requested in any other way. Any solution should avoid generating more threads within an `ImageServer`.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/861:1686,avoid,avoid,1686,https://qupath.github.io,https://github.com/qupath/qupath/issues/861,1,['avoid'],['avoid']
Safety,"## Bug report. **Describe the bug**; QuPath crashes very frequently when I try to use the pixel classifier tool. The program just closes without any further warning or error message. Sometimes an error report is generated an saved. . **To Reproduce**. Steps to reproduce the behavior:; 1. Go to 'Classify'; 2. Click on 'Train pixel classifier (experimental)'; 3. Settings: . - Classifier: Random trees, Parameters: Maximum tree depth: 20, Minimum sample count: 10, ; - Resolution: Full (0.3 µm/px), ; - Features: Scales: 0.5, 1.0, 2.0, 4.0, 8.0, Features: Gaussian, Gradient magnitude, ; - Advanced options: Feature normalization: Mean & variance, Boundary strategy: Classify as Stroma, Boundary thickness: 2 pixels. The crash happens when I try to change the settings above, while 'Live prediction' runs. 4. See error; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # EXCEPTION_ACCESS_VIOLATION (0xc0000005) at pc=0x0000000000cb5b26, pid=9416, tid=7376; #; # JRE version: OpenJDK Runtime Environment (13.0.1+9) (build 13.0.1+9); # Java VM: OpenJDK 64-Bit Server VM (13.0.1+9, mixed mode, tiered, compressed oops, g1 gc, windows-amd64); # Problematic frame:; # C 0x0000000000cb5b26; #; # No core dump will be written. Minidumps are not enabled by default on client versions of Windows; #; # If you would like to submit a bug report, please visit:; # https://github.com/AdoptOpenJDK/openjdk-build/issues; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. --------------- S U M M A R Y ------------. Command Line: -Djava.library.path=C:\Users\ag5-35\Downloads\QuPath-0.2.0-m8-Windows\QuPath-0.2.0-m8\app;C:\Users\ag5-35\Downloads\QuPath-0.2.0-m8-Windows\QuPath-0.2.0-m8 -Djava.launcher.path=C:\Users\ag5-35\Downloads\QuPath-0.2.0-m8-Windows\QuPath-0.2.0-m8 -Xmx8192M -XX:MaxRAMPercentage=50 qupath.QuPath. Host: Intel(R) Core(TM) i5-9400 CPU @ 2.90GHz, 6 cores, 15G, Windows 10 , 64 bit Build 183",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/394:788,predict,prediction,788,https://qupath.github.io,https://github.com/qupath/qupath/issues/394,2,"['detect', 'predict']","['detected', 'prediction']"
Safety,"## Bug report. **Describe the bug**; QuPath has some very rough code to estimate the type of an image, which is used for commands like cell detection. For many applications, the type doesn't really matter; for example, if QuPath is used with 'normal' photographs then the type should really be 'Other'. Currently, QuPath tends to estimate 'Fluorescence' for RGB images that just happen to be a bit dark. **Expected behavior**; 'Fluorescence' is estimated less often, and 'Other' is the default. **Desktop (please complete the following information):**; - OS: All; - QuPath Version: 0.4.0 (and all previous versions). **Additional context**; The current 'image type' system isn't flexible enough, and needs to be extended / amended in the future anyway.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1178:140,detect,detection,140,https://qupath.github.io,https://github.com/qupath/qupath/issues/1178,1,['detect'],['detection']
Safety,"## Bug report. **Describe the bug**; QuPath throws an exception when attempting to show the extensions in the UI when the manifest is `null`. **To Reproduce**; See https://forum.image.sc/t/qupath-script-debugging-in-eclipse/47699/4?u=petebankhead; Issue is reproducible with the provided jar (even though it *does* contain a manifest...). **Expected behavior**; QuPath recovers from the `null` and continues with its best-guess at a version. **Additional context**; Problem method is at https://github.com/qupath/qupath/blob/43aad4ecda893a7eb03c30774e64da5b9547bc86/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/ShowInstalledExtensionsCommand.java#L228-L240. This works around the issue:; ```java; if (stream != null) {; Manifest manifest = stream.getManifest();; if (manifest != null) {; Attributes mainAttributes = manifest.getMainAttributes();; return mainAttributes.getValue(""Implementation-Version"");						; }; }; ```",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/664:369,recover,recovers,369,https://qupath.github.io,https://github.com/qupath/qupath/issues/664,1,['recover'],['recovers']
Safety,"## Bug report. **Describe the bug**; QuPath v0.3.2 hangs when attempting to open certain images with Bio-Formats, outside of a project. The problem occurs when:; * Bio-Formats is the reader; * There are multiple series (non-thumbnail) in the file; * A project is *not* used to open the image. See https://forum.image.sc/t/problem-about-opening-ndpis-files-in-qupath-v0-3-1/62184/4. > **Update: Sometimes QuPath doesn't hang, but the image only opens at a low resolution**; > * #1023. **To Reproduce**; Steps to reproduce the behavior:; 1. Launch QuPath but do *not* open a project; 2. Try to open an image containing multiple (non-thumbnail) series using Bio-Formats; * e.g. see https://downloads.openmicroscopy.org/images/Hamamatsu-NDPI/manuel/; 3. Select any series from the *Open image* dialog; 4. Wait... and wait.... and wait... then force quit. **Expected behavior**; Image opens properly, both inside and outside a project. **Desktop (please complete the following information):**; - OS: All; - QuPath v0.3.1 and v0.3.2. **Additional context**; Problem was introduced in https://github.com/qupath/qupath/pull/867 so should not affect any older versions. **Solution / Workaround**; [Create a a project](https://qupath.readthedocs.io/en/0.3/docs/tutorials/projects.html) first, then open the image. This avoids showing the 'Open image' dialog, and so should work.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/894:1309,avoid,avoids,1309,https://qupath.github.io,https://github.com/qupath/qupath/issues/894,1,['avoid'],['avoids']
Safety,"## Bug report. **Describe the bug**; Reloading a legacy RTrees classifier can give different results each time:; https://forum.image.sc/t/random-trees-detection-classifier-v-0-2-1-and-v-0-20/40795. **To Reproduce**; Steps to reproduce the behavior:; 1. Interactively train a legacy object classifier with *Create detection classifier*; 2. Save the classifier; 3. Run the classifier several times, either from a script or via *Load detection classifier* (if the latter, the file needs to be reloaded to see differences). Results of the classification will generally differ. **Expected behavior**; The classifier gives the same results each time. **Desktop (please complete the following information):**; - QuPath Version v0.2.0 and v0.2.1. **Additional context**; This is caused by a change in OpenCV: https://github.com/opencv/opencv/commit/8aebef2459af9544dc1e51bf84231bca1724738f; It is problematic because of the need to retrain classifiers in v0.1.2 because of another OpenCV bug with Java bindings at the time: https://github.com/qupath/qupath/issues/343. It can be remedied in QuPath by setting the RNG in OpenCV explicitly during training, but this doesn't guarantee the same results as were obtained when interactively classifiers in older v0.2.x versions - since the global RNG state at the time is unknown.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/567:151,detect,detection-classifier-v-,151,https://qupath.github.io,https://github.com/qupath/qupath/issues/567,3,['detect'],"['detection', 'detection-classifier-v-']"
Safety,"## Bug report. **Describe the bug**; Repeated calls to ""Create thresholder"" results in a larger dialog box each time, and progressively slower startup. **Expected behavior**; Dialog opens at the same size each time. **Additional context**; The slower startup likely comes from repeatedly adding listeners to the same UI components, and because the measurement updates are fired without the `isChanging` property. It may be possible to avoid reinitializing the Stage and not firing the measurement change event at all.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/517:435,avoid,avoid,435,https://qupath.github.io,https://github.com/qupath/qupath/issues/517,1,['avoid'],['avoid']
Safety,"## Bug report. **Describe the bug**; See https://forum.image.sc/t/apply-script-to-non-imported-images/90559. **To Reproduce**; Steps to reproduce the behavior:; 1. Create a project; 2. Add a *lot* of images (perhaps > 1,000); 3. Scroll around the project tab. It may be laggy and annoying as thumbnails are being generated, and also afterwards as they are read from disk. (I should admit I haven't tried this myself... I'm just assuming this will be problematic based on the description). **Expected behavior**; The project tab should be responsive, especially after thumbnails are created. **Desktop (please complete the following information):**; - OS: All; - QuPath Version: v0.5.0 (and earlier). **Additional context**; The relevant code is [here](https://github.com/qupath/qupath/blob/864ac71893a8749ff226c99e51642a5e10ea89ea/qupath-gui-fx/src/main/java/qupath/lib/gui/panes/ProjectBrowser.java#L1223). Generating a thumbnail can be expensive, so is currently done lazily on-demand in a single thread. For example, a large non-pyramidal image might require a lot of memory - and so attempting to parallelize thumbnail generation could be risky. We also might not be able to cache *all* thumbnails in a map, as this could be too memory demanding. We might nevertheless consider; 1. A ‘None’ option to not show thumbnails; 2. A ‘Generate missing thumbnails’ option to instruct QuPath to create all of them at once, instead of on-demand.; 3. Using the main tile cache for project thumbnail caching (since this should eject old entries when too much memory is needed)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1446:1143,risk,risky,1143,https://qupath.github.io,https://github.com/qupath/qupath/issues/1446,1,['risk'],['risky']
Safety,"## Bug report. **Describe the bug**; See https://forum.image.sc/t/distances-between-objects-and-annotations/77933. **To Reproduce**; Steps to reproduce the behavior:; 1. Open an image; 2. Detect and classify cells (e.g. with *Positive cell detection*); 3. Run *Analyse &rarr; Spatial analysis &rarr; Detect centroid distances 2D*; 4. Check the distance for several objects between themselves and objects with the same class. This is *usually* 0, but can be greater than 0. **Expected behavior**; The distance between an object and itself should always be 0. The underlying issue seems to be a rounding error due to the way the calculation is performed:; https://github.com/qupath/qupath/blob/1368912885c1a191beaea32c28d85a3707f657f8/qupath-core/src/main/java/qupath/lib/analysis/DistanceTools.java#L358. This involved converting objects to points, and the geometries will likely have precision models applied. **Desktop (please complete the following information):**; - OS: Likely all; - QuPath Version: 0.4.3 (but no known relevant changes made recently, so probably earlier versions too). **Additional context**; When fixing this, it may also be possible to make the calculation more efficient by checking for object matches in the source and target list.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1249:188,Detect,Detect,188,https://qupath.github.io,https://github.com/qupath/qupath/issues/1249,3,"['Detect', 'detect']","['Detect', 'detection']"
Safety,"## Bug report. **Describe the bug**; See https://forum.image.sc/t/subcellular-spot-detection-problem/69403/12. **To Reproduce**; Steps to reproduce the behavior:; 1. Open any RGB image; 2. Set the image type to *Fluorescence*; 3. Try toggling channels with `1`, `2` or `3`; 4. Observe that channels don't toggle as expected; 6. Check the *Brightness/Contrast* dialog to see what's going on. **Expected behavior**; Pressing `1` should toggle red, `2` should toggle green and `3` should toggle blue. **Desktop (please complete the following information):**; - OS: All; - QuPath v0.3 (and probably before)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1006:83,detect,detection-problem,83,https://qupath.github.io,https://github.com/qupath/qupath/issues/1006,1,['detect'],['detection-problem']
Safety,"## Bug report. **Describe the bug**; See https://github.com/qupath/qupath/pull/835 from @jameshball. In summary, measurement lists are only included by `PathObjectTypeAdapters` when deserialising detection objects, as can be seen in the code from https://github.com/qupath/qupath/blob/v0.3.0/qupath-core/src/main/java/qupath/lib/io/PathObjectTypeAdapters.java#L412. A second, more subtle bug is that when measurement lists *are* retained, their type can be changed. This is not expected to have any major effect beyond efficiency, but could potentially be important in some situations. **To Reproduce**; Run the following script:; ```groovy; def roi = ROIs.createRectangleROI(0, 10, 20, 30, ImagePlane.getDefaultPlane()); def annotation = PathObjects.createAnnotationObject(roi); annotation.setName(""Original""); annotation.setPathClass(getPathClass(""My custom class"")); annotation.getMeasurementList().addMeasurement(""First measurement"", 1.0); annotation.getMeasurementList().addMeasurement(""Second measurement"", -2.0). def json = GsonTools.getInstance(true).toJson(annotation). // Print original annotation, class and measurement list; println ""ORIGINAL""; println annotation; println annotation.getPathClass(); println annotation.getMeasurementList().class; println annotation.getMeasurementList(); println ""----------------"". // Print deserialized annotation, class and measurement list; def newAnnotation = GsonTools.getInstance().fromJson(json, PathObject); println ""FROM JSON""; println newAnnotation; println newAnnotation.getPathClass(); println newAnnotation.getMeasurementList().class; println newAnnotation.getMeasurementList(); ```. The new annotation does not have any measurements in QuPath v0.3.0. Moreover, switching to use `PathObjects.createDetectionObject(roi)` reveals that the measurements *are* retained, but the class of the measurement list is changed from `FloatList` to `DoubleList` - requiring more memory. **Expected behavior**; As much information as possible is retained wh",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/845:196,detect,detection,196,https://qupath.github.io,https://github.com/qupath/qupath/issues/845,1,['detect'],['detection']
Safety,"## Bug report. **Describe the bug**; Subcellular detections don't work with z-stacks on anything other than the default slice. See https://forum.image.sc/t/problem-detecting-subcellular-object-from-nd2-files/51111. **To Reproduce**; Steps to reproduce the behavior:; 1. Open a z-stack; 2. Detect cells on multiple slices; 3. Run the subcellular detection command. If no pixel sizes are available in µm, nothing will be detected. Otherwise, all detections will be shown on the first slice. **Expected behavior**; Subcellular detections are shown in the correct cells; a meaningful warning is displayed if pixel sizes are unavailable. **Desktop (please complete the following information):**; - OS: All; - QuPath Version v.2",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/701:49,detect,detections,49,https://qupath.github.io,https://github.com/qupath/qupath/issues/701,7,"['Detect', 'detect']","['Detect', 'detected', 'detecting-subcellular-object-from-', 'detection', 'detections']"
Safety,"## Bug report. **Describe the bug**; The ScriptEditor throws an `IndexOutOfBoundsException` when deleting text that was just inserted, having `CTRL` down (and probably `CMD` too?). **To Reproduce**; Steps to reproduce the behavior:; 1. Go to the script editor; 2. Get the first auto-completed word by hitting `CTRL` + `SPACE` (i.e. `BRIGHTFIELD_H_DAB` at the time of writing); 3. Delete the word, by hitting the `CTRL` + `BACKSPACE` keys; 4. Re-hit `CTRL` + `SPACE` to trigger the auto-complete again.; 5. See Exception thrown. **Expected behavior**; The word should be auto-completed again (i.e. `BRIGHTFIELD_H_DAB` should be written). **Desktop (please complete the following information):**; - OS: All; - QuPath Version: v0.3.2. **Additional context**; I believe the problem originates [here](https://github.com/qupath/qupath/blob/10b44a58b8c08ca925aa44bc08eaf1fa3eb70584/qupath-extension-script-editor/src/main/java/qupath/lib/gui/scripting/richtextfx/RichScriptEditor.java#L357), where reinitialising the `AutoCompletor` object is skipped and it shouldn't. However, the reason for this `if` block is to avoid the `AutoCompletor` object to be reinitialised when the user is iterating through all the possible completion suggestions (e.g. most users will naturally hit the `CTRL`/`CMD` key before the `SPACE` key, creating a `KeyEvent` in the middle that needs to be filtered out).",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/916:1108,avoid,avoid,1108,https://qupath.github.io,https://github.com/qupath/qupath/issues/916,1,['avoid'],['avoid']
Safety,"## Bug report. **Describe the bug**; The performance of `MeasurementExporter` is unacceptably slow when large numbers of objects and measurements. (Although, as we shall see, it's not entirely its fault...). **To Reproduce**; Steps to reproduce the behavior:; 1. Run cell detection on a large regions (generating >100k cells); 2. Run an export script that *should* be limited to export just one measurement per cell, e.g. following https://forum.image.sc/t/qupath-extremely-slow-exporting-detection-measurements/71154/6; 3. Predict how long it should take (a second or two?); 4. Be disappointed and confused (possibly). **Expected behavior**; Exporting hundreds of thousands of measurements takes a matter of seconds. **Desktop (please complete the following information):**; - OS: All; - QuPath Version: 0.3.2 (and earlier). **Additional context**; The discussion behind this is at https://forum.image.sc/t/qupath-extremely-slow-exporting-detection-measurements/71154. Investigating revealed a few issues:; * `MeasurementExporter` might not be using a buffered output stream (although how much this matters if unclear); * When using 'includeColumns', it's converting *all* numeric measurements to strings... even if they aren't needed; * Lots of measurements can cause horrible performance even when they aren't being written to the file; * The frequent calls to `GeneralTools.formatNumber` show up on VisualVM as a bottleneck. The first is easy to address, although may not help much. The second can also be addressed by excluding columns earlier. The third may be tricker, but is needed to help in cases where a full table should be export.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1045:272,detect,detection,272,https://qupath.github.io,https://github.com/qupath/qupath/issues/1045,4,"['Predict', 'detect']","['Predict', 'detection', 'detection-measurements']"
Safety,"## Bug report. **Describe the bug**; There's a problem with the tile caching v0.3.2 and v0.4.2 (probably other versions) when using the the same image opened in multiple viewers. Basically, detections made in one image can show up in the other. The reason is that tiles that show the detections are being cached using the same key in both viewers, because the underlying image files are the same. **To Reproduce**; 1. Create a project & add an image; 2. Duplicate the image in the project; 3. Open the original image & its duplicate in different QuPath viewers; 4. Detect cells in a small region in one viewer; 5. Detect cells in a different region in the second viewer; 6. See the cells magically appear in both viewers. **Expected behavior**; It's possible to work with the same image in multiple viewers. **Screenshots**; ![mixed-viewers](https://user-images.githubusercontent.com/4690904/214566216-208471e0-d729-4338-993d-0fa12420f504.png). **Desktop (please complete the following information):**; - OS: All; - QuPath Version: v0.4.2 (also v0.3.2 and likely other versions); ; **Additional context**; Because it's a tile caching issue, the problem isn't evident when zoomed in (since the tile cache isn't used to paint detections). The issue was first reported at https://forum.image.sc/t/qupath-problem-with-showing-detections-in-multi-view/76334/3. The cell counts etc. should be unaffected. One workaround is to duplicate the underlying image file, so that it has a different key for caching (based upon the file name/path).",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1217:190,detect,detections,190,https://qupath.github.io,https://github.com/qupath/qupath/issues/1217,6,"['Detect', 'detect']","['Detect', 'detections', 'detections-in-multi-view']"
Safety,"## Bug report. **Describe the bug**; When creating a measurement table and entering text in the 'column filter' textfield, an exception can appear. ```; ERROR: QuPath exception: TableColumn.visible : A bound value cannot be set.; java.lang.RuntimeException: TableColumn.visible : A bound value cannot be set.; at javafx.beans.property.BooleanPropertyBase.set(BooleanPropertyBase.java:141); at javafx.scene.control.TableColumnBase.setVisible(TableColumnBase.java:230); at qupath.lib.gui.commands.SummaryMeasurementTableCommand.lambda$18(SummaryMeasurementTableCommand.java:379); at com.sun.javafx.binding.ExpressionHelper$Generic.fireValueChangedEvent(ExpressionHelper.java:360); at com.sun.javafx.binding.ExpressionHelper.fireValueChangedEvent(ExpressionHelper.java:80); ```. **To Reproduce**; Steps to reproduce the behavior:; 1. Open an image; 2. Detect some cells; 3. Run *Measure &rarr; Show detection measurements*; 4. Type something in the 'Column filter' field; 5. See the exception pop up (although the filter is applied). **Expected behavior**; No exceptions. **Desktop (please complete the following information):**; - OS: All (presumably); - QuPath Version: v0.4.1",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1209:849,Detect,Detect,849,https://qupath.github.io,https://github.com/qupath/qupath/issues/1209,2,"['Detect', 'detect']","['Detect', 'detection']"
Safety,"## Bug report. **Describe the bug**; When optimising perameters for a project by creating a sparse composite image from different image entries. When running cell detection using script editor, errors are generated for the final tiles **IF** the entire shape is not a perfect rectangle. If using stardist script for cell detection, errors are generated before any detections. **Can avoid both by manual annotation** with a polygon tool to follow image boundaries -> so not sure if a crucial bug. Carried over from last release to v5. **To Reproduce**; Steps to reproduce the behavior:; 1. Ctl+Shift+A; 2. Run cell detection as a script:; ```; setImageType('FLUORESCENCE');; selectAnnotations();; runPlugin('qupath.imagej.detect.cells.WatershedCellDetection', '{""detectionImage"":""DAPI"",""requestedPixelSizeMicrons"":0.1,""backgroundRadiusMicrons"":4.0,""backgroundByReconstruction"":true,""medianRadiusMicrons"":1.0,""sigmaMicrons"":2.5,""minAreaMicrons"":11.0,""maxAreaMicrons"":400.0,""threshold"":1000.0,""watershedPostProcess"":true,""cellExpansionMicrons"":5.0,""includeNuclei"":true,""smoothBoundaries"":true,""makeMeasurements"":true}'); ```; 4. Error:; ```; ERROR: Error running plugin: java.lang.NullPointerException: Cannot invoke ""java.awt.image.BufferedImage.getSampleModel()"" because ""img"" is null; java.util.concurrent.ExecutionException: java.lang.NullPointerException: Cannot invoke ""java.awt.image.BufferedImage.getSampleModel()"" because ""img"" is null; at java.base/java.util.concurrent.FutureTask.report(Unknown Source); at java.base/java.util.concurrent.FutureTask.get(Unknown Source); at qupath.lib.plugins.AbstractTaskRunner.awaitCompletion(AbstractTaskRunner.java:147); at qupath.lib.plugins.AbstractTaskRunner.runTasks(AbstractTaskRunner.java:117); at qupath.lib.gui.TaskRunnerFX.runTasks(TaskRunnerFX.java:106); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:147); at qupath.lib.gui.QuPathGUI.runPlugin(QuPathGUI.java:2245); at qupath.lib.gui.scripting.QPEx.runPlugin(QPEx.java:248); ",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443:163,detect,detection,163,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443,7,"['avoid', 'detect']","['avoid', 'detect', 'detection', 'detectionImage', 'detections']"
Safety,"## Bug report. **Describe the bug**; When running QuPath in command line/script mode, runClassifier appears to retrain the RTrees classifier. In the screenshot of logs below, note the 3.5 minute lag in timestamps before ""Classifier trained with 281528 samples"". **To Reproduce**; We have a .qpclassifier model saved that is 91M. In the script we run runClassifier(); after cell detection. **Expected behavior**; Relatively fast scoring. **Screenshots**; ![image](https://user-images.githubusercontent.com/7959016/61900030-bdb75600-aeea-11e9-993e-bddfef876da1.png). **Desktop (please complete the following information):**; - OS: Ubuntu; - QuPath Version 0.1.3",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/343:378,detect,detection,378,https://qupath.github.io,https://github.com/qupath/qupath/issues/343,1,['detect'],['detection']
Safety,"## Bug report. **Describe the bug**; When running subcellular detection, the `Num spots` and `Num clusters` measurements are incorrect; the spots contain both spots and clusters, while the count of clusters is 0. **To Reproduce**; See https://forum.image.sc/t/about-num-cluster-column-of-subcellular-detection/55585. **Expected behavior**; Num spots and Num clusters measurements match what is visible in the viewer, at least at the time of creation (they don't automatically update). **Desktop (please complete the following information):**; - QuPath Version: v0.2.3, v0.3.0-rc1. **Additional context**; See; https://github.com/qupath/qupath/blob/75ec9cebe5e3bc5843fc60b07b455ce1215e1fb9/qupath-core-processing/src/main/java/qupath/imagej/detect/cells/SubcellularDetection.java#L360-L373. It might be fixed with a change to:; ```java; if (isCluster); clusterObjects.add(cluster);; else; spotObjects.add(cluster);; ```",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/788:62,detect,detection,62,https://qupath.github.io,https://github.com/qupath/qupath/issues/788,3,['detect'],"['detect', 'detection']"
Safety,"## Bug report. **Describe the bug**; When training an object classifier multiple times, different results can be seen. This only happens (I *think*) whenever the image has been reopened: training is consistent if the image is not closed in the meantime. **To Reproduce**; Steps to reproduce the behavior:; 1. Open an image and detect some cells; 2. Train an object classifier with 2 small annotations & default settings; 3. Save the data and close the image; 4. Reopen the image, and train a new classifier with the same annotations and settings; 5. Observe that the classifications (probably) change... indicating that the classifier must be somehow different. **Expected behavior**; Training the same classifier with the same data *and the same RNG seed* should give the same results. **Desktop (please complete the following information):**; - OS: macOS (all presumably); - QuPath v0.3.2 (presumably some before as well). **Additional context**; See https://forum.image.sc/t/how-to-measure-the-staining-intensity-without-positive-cell-detection/66847/14 for the first report of related behaviour*. I'm labelling this as a bug despite my efforts to claim it isn't one :). All relevant RNGs should be properly seeded. I believe the problem occurs because the order of the objects used for training isn't deterministic, because `HashSets` and the like are used along the way.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1016:327,detect,detect,327,https://qupath.github.io,https://github.com/qupath/qupath/issues/1016,2,['detect'],"['detect', 'detection']"
Safety,"## Bug report. **Describe the bug**; When using Ctrl+Shift to avoid overlapping annotations, QuPath is taking annotations on other z-slices into account. **To Reproduce**; - Have a multi-z image open in QuPath; - Draw an annotation; - Move up to a different z-slice; - Hold down Ctrl and Shift and try and draw an annotation that would overlap with your first one if they were on the same slice. **Expected behavior**; I expected this to work on a per-slice method and that Ctrl + Shift would only take into account the annotations on the current slice. **Screenshots**; ![QuPath_Bug](https://user-images.githubusercontent.com/36237950/151961462-76c5c84f-6174-4692-8fa8-e566f5f021c2.png). **Desktop:**; - OS: Windows 10; - QuPath Version: 0.3.2, 0.3.0 and 0.2.3",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/905:62,avoid,avoid,62,https://qupath.github.io,https://github.com/qupath/qupath/issues/905,1,['avoid'],['avoid']
Safety,"## Bug report. **Describe the bug**; When using ```Charts.pieChart()``` the colors of the chart match the colors for that class of objects. However, the colors of the legend do not match!. **To Reproduce**; Steps to reproduce the behavior:; 1. Run Positive cell detection on an image; 2. Use the following code to create a pie chart:; ```; chartData = getDetectionObjects().countBy(p -> p.getPathClass()); Charts.pieChart(); .title('Test Chart'); .data(chartData); .show(); ```. **Expected behavior**; The colors of the legend shall match the colors of the pie. **Screenshots**; <p align=""center"">; <img src=""https://user-images.githubusercontent.com/10900214/192350181-ebb62218-af1a-4031-b107-fe255d5efd69.png"" width=""450"">; </p>. **Desktop (please complete the following information):**; - OS: Windows 10; - QuPath Version: Tested on v2.3 and the latest snapshot. **Additional context**; More details on the forum:; https://forum.image.sc/t/pie-chart-legend-colors/72051",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1062:262,detect,detection,262,https://qupath.github.io,https://github.com/qupath/qupath/issues/1062,1,['detect'],['detection']
Safety,"## Bug report. **Describe the bug**; When using the `TileExporter`, pixel size and channel color information can be lost. **To Reproduce**; Use the `TileExporter` class to export fixed-size tiles as ImageJ TIFF, e.g. with this script applied to the LuCa sample image:. ```groovy; def path = buildPathInProject(""tiles""); mkdirs(path); def imageData = getCurrentImageData(); new TileExporter(imageData); .writeTiles(path); ```. Open the resulting TIFFs in ImageJ and see that no calibration is set. **Expected behavior**; Channel colors are preserved, and the image properties are set (pixel size and origin). **Desktop (please complete the following information):**; - OS: All; - QuPath Version: v0.5.1 (and earlier). **Additional context**; Relates to https://github.com/qupath/qupath/issues/1503 but is not identical. The relevant code is at; https://github.com/qupath/qupath/blob/0ab5d054a2aac2e21d1bcc234306e164e44965bb/qupath-core/src/main/java/qupath/lib/images/writers/TileExporter.java#L786. The difficulty is guaranteeing that tiles have a fixed size, rather than risking an off-by-one error, when we can only define the region with an `ImageServer` and `RegionRequest` that can have an arbitrary downsample.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1516:1072,risk,risking,1072,https://qupath.github.io,https://github.com/qupath/qupath/issues/1516,1,['risk'],['risking']
Safety,"## Bug report. **Describe the bug**; When using the brush tool, I can not add an area to or remove from existing annotations that were created using the „simple tissue detection“ command. This was possible with the same files yesterday when using the m9 version. Creating entirely new annotations with the brush tool does work, as well as using the brush tool to add to/remove from these new annotations. The existing annotations are of course all „unlocked“ and everything is as it was set to in m9. **To Reproduce**; 1. open a project that has an an image with existing annotations that were created using the „simple tissue detection“ command.; 2. select one of the existing annotations (if not done already, right click the annotation and set it to „unlocked“ or do so for all annotations by using the annotations tab); 3. click on the brush tool or press „B“; 4. try to edit the exisitng annotation while holding down Shift or CMD. **Expected behavior**; The annotations should be editable like this. **Desktop:**; - OS: macOS 10.14.6 on MacBook Air 2014, 1.4 GHz i5, 4GB RAM, Intel HD Graphics 5000; - QuPath Version: 0.2.0-m10",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/456:168,detect,detection,168,https://qupath.github.io,https://github.com/qupath/qupath/issues/456,2,['detect'],['detection']
Safety,"## Bug report. **Describe the bug**; You can enter arbitrary values in the text fields of a ParameterPanelFX, even though it knows what type(s?) the parameter accepts. **To Reproduce**; Steps to reproduce the behavior:; 1. Ctrl/Cmd + L; 3. Cell detection; 5. Tab twice/select pixel size text field; 7. Type ""dakjdpokowakdapodw"" into pixel size text field. **Expected behavior**; Parameter input fields should only accept (potentially) valid input",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1541:245,detect,detection,245,https://qupath.github.io,https://github.com/qupath/qupath/issues/1541,1,['detect'],['detection']
Safety,"## Bug report. **Describe the bug**; _Load Classifier_ attempts, or scripts which attempt to run pixel classifiers automatically, fail without error for the _Create simple thresholder_ (experimental) function.; ![image](https://user-images.githubusercontent.com/23145209/74885105-a11cb880-5329-11ea-8165-f6e20af6cc91.png). **To Reproduce**; Steps to reproduce the behavior:; Create a Create simple thresholder.; Save it.; ![image](https://user-images.githubusercontent.com/23145209/74885541-acbcaf00-532a-11ea-8554-2a6bf622b709.png). (Optional) Create annotation or detection objects (Success!); Close the pixel classifier; Load Pixel Classifier; Select your pixel classifier and see that the overlay looks correct for the previously created thresholder.; **Attempt to _Create objects_ creates no objects.**. **Expected behavior**; After loading the classifier successfully, objects are create-able. **Screenshots**; If applicable, add screenshots to help explain your problem. **Desktop (please complete the following information):**; Windows7,10. QuPath 0.2.0m8,m9. Side note: _Classify Detections_, when working off of a loaded classifier, seems to try to do something, then fails with a whole lot of:; `WARN: Classification Unclassified is invalid! Will be set to null instead`",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/403:566,detect,detection,566,https://qupath.github.io,https://github.com/qupath/qupath/issues/403,1,['detect'],['detection']
Safety,"## Bug report. Sometimes when running cell detection (`qupath.imagej.detect.cells.WatershedCellDetection`) in the parallel tiled mode it will fail saying `ERROR: Exception during post-processing`. It appears the final QuPath method call before calling into a library is `qupath.lib.plugins.ParallelTileObject.resolveOverlaps`, and the error is from [line 280](https://github.com/qupath/qupath/blob/cf618cb91a7e43716c3a4bc7b431de6a88ee98be/qupath-core/src/main/java/qupath/lib/plugins/ParallelTileObject.java#L280), the offending call being `firstGeometry.intersection(secondGeometry)`. The error message from this is `Caused by found non-noded intersection between LINESTRING ( 6336.81 3918.04, 6335.4 3918.39 ) and LINESTRING ( 6335.39013671875 3918.389892578125, 6335.41 3918.39 ) [ (6335.400213222254, 3918.38994707249, NaN) ] at org.locationtech.jts.noding.FastNodingValidator.checkValid(FastNodingValidator.java:140)`. **To Reproduce**; [This script](https://gist.github.com/reynoldscem/4d5f5bf0428057769da6bfd54037e02e) should reproduce the issue. One such image for which this happens is `breast_2/scale-20pc/HE.jpg` from the [ANHIR](https://anhir.grand-challenge.org/Data/) dataset. To reproduce manually we can:. Load an image, and make a rectangular selection around it all. Go to Analyze, Cell Detection, choose the appropriate settings and run. **Expected behavior**; I expect the cell detection to work. As it is, the cells are only detected for some subset of the tiles. **Screenshots**; As we can see only some of the tiles here finish. ![image](https://user-images.githubusercontent.com/5931862/80495409-c9471a00-895f-11ea-942d-cd3b98446c0d.png). **Desktop (please complete the following information):**; - OS: Ubuntu 19.10; - QuPath Version 0.2.0-m10, but I have seen the same issue in m9. Please let me know anything I can try to work around this, or any info on potentially fixing this problem.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/459:43,detect,detection,43,https://qupath.github.io,https://github.com/qupath/qupath/issues/459,5,"['Detect', 'detect']","['Detection', 'detect', 'detected', 'detection']"
Safety,"## Bug report; The pan tool has a high initial latency when working with large images with many detections. It takes a few seconds until the image starts to follow the mouse pointer after the initial click.; After overcoming this lag, the panning itself is sufficiently smooth, though.; The phenomenon is not influenced by zoom level or the display status of annotations or detections.; I don't think this is related to hardware ressources, CPU/GPU utilization bareley changes during this - and the computer should be sufficiently powerful. **To Reproduce**; Steps to reproduce the behavior:; Load NDPI (approx. 30x30 MP in size); Draw ROIs (in this case generated from pixel classifications and smoothed); Use positive cell detection, resulting in about 152,000 detected nuclei; Try using the pan tool. **Expected behavior**; More or less immediate pan action. **Desktop (please complete the following information):**; - OS: Windows 10 64-bit. HP Z840 dual Xeon E5-2667v3, 128 GB RAM, Nvidia Quadro K6000; - QuPath Version 0.2.0-m9 (set to use 64 GB of RAM). Thank you for this great piece of software! :-)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/440:96,detect,detections,96,https://qupath.github.io,https://github.com/qupath/qupath/issues/440,4,['detect'],"['detected', 'detection', 'detections']"
Safety,"## Bug report;  ; **Describe the bug**; I have a project containing about 20 images, each one a TMA. I analyzed all of them about 6 months ago, exported the data I needed to excel, and analyzed it there. However, I wanted to add another variable to analyze the data by, and opened the QuPath project to add a variable to the TMA data grid.;  ; After doing this with the first five images, I saved one and clicked to open the next one, and went to the bathroom while it loaded. When I returned, it was telling me to select an image type, and I realized it had deleted all the annotations and detections. Upon further inspection, it had deleted all the detections and annotations on all of the images except the one I had just been editing, and showed the rest as new and unopened images. ;  ; I closed without saving and reopened, and then two had the detections and annotations restored. I've continued closing and reopening the project, and a different number of images have annotations each time. I have tried downloading the newest version of QuPath, after which there were 5 images with annotations and detections restored and one with only annotations restored. Since updating, the same data is the same every time I reopen it. I have also tried updating and restarting my computer. I have no idea how or why this happened or how to get my data back. This is many hours of work, and I'm scared to start my new project, if this is a possible outcome.;  ; **To Reproduce**; I'm sorry, but I have no idea.;  ; **Expected behavior**; Normally, when I go from one image to another, I save one and then the next one opens the old annotations and detections.;  ; **Screenshots**; <img width=""1264"" alt=""Screenshot 2023-09-04 at 6 43 43 PM"" src=""https://github.com/qupath/qupath/assets/79068467/16ab2d72-a5ad-4910-b1eb-c1fc0a9c8842"">; This is a list of images, you can see that it shows five on this view as opened and the rest as new. ;  ; **Desktop (please complete the following information):**;  - OS",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1313:591,detect,detections,591,https://qupath.github.io,https://github.com/qupath/qupath/issues/1313,3,['detect'],['detections']
Safety,"## Feature request. ### Is your feature request related to a problem? Please describe. It's possible to set colors for instances of a `PathObject` and `PathClass`, but inconvenient and inconsistent. The main reason is that both represent the color using an `Integer`, in packed ARGB form. The thinking was that this would be a) efficient, b) portable, and c) avoid creating *yet another* `Color` class (since this exists for Java AWT, JavaFX, OME...). The main problem is that both classes use different method signatures, and both require the color to be packed into an integer before being set. So we end up with code like this:; ```java; pathObject.setColorRGB(ColorTools.packRGB(255, 0, 0));; pathClass.setColor(ColorTools.packRGB(255, 0, 0));; ```. There are similar getter methods, which return the packed integer (or sometimes null, if the color isn't set). This then may need to be unpacked, e.g.; ```java; var rgb = pathObject.getColorRGB();; int red = ColorTools.red(rgb);; int green = ColorTools.green(rgb);; int blue = ColorTools.blue(rgb);; ```. A secondary problem is that it isn't clear whether alpha will be used or not. This is possible:; ```java; pathObject.setColorRGB(ColorTools.packARGB(127, 255, 0, 0));; pathClass.setColor(ColorTools.packARGB(127, 255, 0, 0));; ```; but it's not obvious whether the alpha will do anything. ### Describe the solution you'd like. It would be preferable to have something standardized, including the option to provide separate RGB values, e.g.; ```java; pathObject.setColor(red, green, blue); pathClass.setColor(red, green, blue); ```. This could be implemented quickly, deprecating the `PathObject.setColorRGB(Integer)` method. The main decision is whether to take 8-bit RGB values or floats/doubles as input. For now, I propose keeping `public Integer getColor()` - although `getRed()`, `getGreen()` and `getBlue()` methods could potentially be added. ### Describe alternatives you've considered. One way to enforce standardization would be thro",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1086:359,avoid,avoid,359,https://qupath.github.io,https://github.com/qupath/qupath/issues/1086,1,['avoid'],['avoid']
Safety,"## Feature request. **Describe the bug**; Some dialogs use a combination of an text entry box and up/down arrows for entering numerical values - the Simple thresholder would be an example. It would be great, if these UI elements would react to mouse wheel events for increments/decrements. On another note there are a few places where numerical UI entry elements are inconsistent now: The Simple thresholder is using the entry-field-with-up-down-arrows-variant whereas e.g. the positive cell detection does not. I guess it would make sense to use the same type in all these places. ;-). **Desktop (please complete the following information):**; - OS: Windows 10 64bit; - QuPath Version 0.2.0-m12",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/495:492,detect,detection,492,https://qupath.github.io,https://github.com/qupath/qupath/issues/495,1,['detect'],['detection']
Safety,"## Feature request. **Is your feature request related to a problem? Please describe.**; At the moment, SVG exports [1] behave differently from their bitmap counterparts [2], in the sense that the bitmap exports include whichever overlays are currently displayed, but the SVG exports only include the original image. [1] File -> Export images -> Rendered SVG and File -> Export snapshot -> Current viewer content (SVG); [2] File -> Export images -> Rendered RGB (with overlays), File -> Export snapshot -> Main window content and File -> Export snapshot -> Current viewer content. **Describe the solution you'd like**; I would *both* types of exports to include overlays if the user so wishes. See the discussion on https://forum.image.sc/t/export-snapshot-current-view-content-svg-does-not-include-the-density-map/82740. **Describe alternatives you've considered**; I have a two-step workaround in the meantime:; 1. Export images -> Rendered SVG (Linked raster); 2. Hide the annotations and detections, then Export images -> Rendered RGB to overwrite the linked raster image, using PNG and the same downsample as used in step 1. **Additional context**; SVG is a great format. The files can be edited in [Inkscape](https://inkscape.org/) and also be used as-is in (recent versions of) Microsoft Office Word and Powerpoint. And they look great when printed, which is why I think it's important for QuPath to have the best possible SVG export functions.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1272:991,detect,detections,991,https://qupath.github.io,https://github.com/qupath/qupath/issues/1272,1,['detect'],['detections']
Safety,"## Feature request. **Is your feature request related to a problem? Please describe.**; QuPath's built-in cell detection makes measurements at the same time and at the same resolution as detection. This isn't sustainable as we support a wider range of cell detection methods. That's why the [`ObjectMeasurements`](https://github.com/qupath/qupath/blob/a5c02a0d8e8e2a010824a2a0dc0fb0c45602fd76/qupath-core-processing/src/main/java/qupath/lib/analysis/features/ObjectMeasurements.java#L74) class exists. This is used internally [by the QuPath StarDist extension](https://github.com/qupath/qupath-extension-stardist/blob/c9424b488a356a3af26ef7bc58eb9bce2592a108/src/main/java/qupath/ext/stardist/StarDist2D.java#L1014) - but it still has the basic form of 'make measurements at the same time as detection'. I think we need to decouple these two things, or at least ensure that it's possible to add cell measurements *after* detection. **Describe the solution you'd like**; A new, scriptable command to add cell measurements. **Describe alternatives you've considered**; Build upon the existing *'Add intensity features'* command. I can think of a few relevant considerations:. * We want shape measurements as well, not just intensity measurements (although perhaps the command could be generalized to include shapes too); * *'Add intensity features'* can simultaneously give too many and too few measurements. We probably don't need the Haralick features generally, but do need the possibility of membrane measurements (possibly with control over thickness?).; * *'Add intensity features'* tries to handle the tricky problem of arbitrarily large ROIs, by tiling. It is easier to code more imaginative feature measurements if we can assume that all pixels and binary mask can fit easily into RAM.; * *'Add intensity features'* does *not* handle the different cell compartments currently (i.e. nucleus, cytoplasm, cell, membrane). **Additional context**; In writing this, it's not clear to me if we should ",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1551:111,detect,detection,111,https://qupath.github.io,https://github.com/qupath/qupath/issues/1551,5,['detect'],['detection']
Safety,"## Feature request. **Is your feature request related to a problem? Please describe.**; When training a pixel classifier, various settings can be customized (including features). These automatically return to their defaults when the dialog is closed. See original discussion at https://forum.image.sc/t/change-default-settings-on-pixel-classifier/70371. **Describe the solution you'd like**; A more efficient way to set these values than through clicking in the UI. **Additional context**; This could be through a saved parameter file, or recovering the settings from an existing saved classifier (reloading a saved classifier is also a frequent request). Neither is entirely straightforward, given that the available settings change based upon image properties and not all settings are currently serialised in the JSON for a classifier. Potentially, this request could be relevant for object classifiers and density maps.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1055:539,recover,recovering,539,https://qupath.github.io,https://github.com/qupath/qupath/issues/1055,1,['recover'],['recovering']
Safety,"## IMPORTANT!. * [X] I've definitely found a bug (it you're not sure, please use [image.sc](https://forum.image.sc/tags/qupath) instead); * [X] I've checked https://qupath.github.io for a new release that might already have fixed the issue; * [X] I've checked the [Changelog](https://github.com/qupath/qupath/blob/master/CHANGELOG.md) to see if the bug has already been fixed in the next release; * [X] I've checked for existing GitHub issues describing the same problem. ## Bug report. **Describe the bug**; Object connections cause moderate viewer lag when downsample factor is less than 1, evident when panning. Very minor and niche issue, but I figured I'd open a ticket anyways. **To Reproduce**; Steps to reproduce the behavior:; 1. Run cell detection across a whole-slide annotation; 2. Generate object connections via ""Delaunay cluster features 2D""; 3. Set viewer downsample factor to 0.99 or less; 4. Observe lag when panning. Unchecking ""show object connections"" or setting a downsample factor greater than or equal to 1 will resolve this issue. **Expected behavior**; Visualizing objects overlaid onto images shouldn't result in substantial lag. **Screenshots**; Video recording: https://www.youtube.com/watch?v=qOBp2X6HVUc. **Desktop (please complete the following information):**; - OS: Windows 10; - QuPath Version: Version: 0.4.0-SNAPSHOT; Build time: 2022-01-24, 13:48. **Additional context**; A 24-class composite classifier, annotation-generating pixel classifier, and several other spatial analyses were also performed.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1069:748,detect,detection,748,https://qupath.github.io,https://github.com/qupath/qupath/issues/1069,1,['detect'],['detection']
Safety,"## Version 0.2.0-m6; This is a *milestone* (i.e. still in development) version made available to try out new features early.; ### Important bug fix!; * Positive per mm^2 measurement fixed; this could be wrong in v0.2.0-m5 (other versions not affected); ### Important behavior change!; * Parent-child relationships are no longer automatically calculated between objects!; For an explanation of the reasons behind this change & what it means, see the blog.; ### Other changes:; * Pixel classifier shows live area measurements with 'Classification' output (in m5 this worked only with 'Probability' output); * New 'Detection centroid distances 2D' command (e.g. to find distances to cells with different classifications); * Smoother drawing, faster viewer repainting; * Point annotation improvements; * Faster repainting; * Converting detections to points now uses nucleus ROIs when applied to cells, no longer requires deleting the detections; * More shortcuts, e.g. Ctrl+Alt+A to select annotations, Ctrl+Alt+D to select detections; * GeometryROI now replaces AreaROI and AWTAreaROI for improved performance and consistency; * Fixed bug when converting ROIs with nested holes to JTS Geometries; * Undo/Redo and tile cache size information added to Memory Monitor; * Added support for ImageWriters to write to output streams; * Updated build script to Gradle 6.0; * Use bioformats_package.jar rather than separate dependences (easier to upgrade/downgrade if needed)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/375:612,Detect,Detection,612,https://qupath.github.io,https://github.com/qupath/qupath/pull/375,4,"['Detect', 'detect']","['Detection', 'detections']"
Safety,"## WHAT; This PR improves performance when running a script that does not need to access the image files on multiple images.; Additionally, allowed to modify `ObjectClassifierCommand` too so that it can read all detections' measurements in the training set without uselessly reading the image files.; This last change alone allowed, on my projects, to improve the time when creating an object classifier from ~10/15minutes to ~5seconds.; I feel like this change is useful when a laboratory works with large projects with image locations being on a remote server. This is also possible thanks to QuPath's amazing design choice to never directly modify images.; If the scripts being run wants to access the images' pixels, it gracefully halts the execution of the all the following project entries too. _example_:; ```groovy; import qupath.imagej.tools.IJTools; import qupath.lib.images.PathImage; import ij.ImagePlus. var server = getCurrentServer(); var downsample = server.getDownsampleForResolution(Math.min(server.nResolutions()-1, 4)); PathImage<ImagePlus> pathImage = IJTools.convertToImagePlus(server, RegionRequest.createInstance(server, downsample)); ```; ""_Run for project (without saving and opening)_"":; ```; INFO: Starting script at Tue Mar 26 15:20:37 CET 2024; ERROR: The script tried to read pixels off an image while also requiring to run the script without accessing the image files.; WARN: Script cancelled with 53 image(s) remaining; INFO: Processed 54 images; INFO: Total processing time: 280 milliseconds; ```. ## HOW; Essentially this works by creating a `ImageServerStub` that extends `AbstractImageServer`. It retrieves metadata from the ProjectImageEntry itself (which in turn, i think, it gets them from the `.qpproj` file) and fails when `readRegion()` is being called. Additionally, it does not provide a server builder. This way, if the resulting image data are to be saved, the original ImageServer won't be overwritten/lost.; You can now pass a `openImage` boolean to `P",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1488:212,detect,detections,212,https://qupath.github.io,https://github.com/qupath/qupath/pull/1488,1,['detect'],['detections']
Safety,"### Reason for change. - Previously, only 'detections' supported importing measurements from GeoJSON, as the `measurementList` is ignored for annotations; - This fixes this, allowing measurements to be imported from a GeoJSON file. ### Changes. - Measurements are now not ignored when creating annotations; - Before this, measurements were fetched but not actually used in `PathObjects.createAnnotationObject`; - This does not change behaviour when the `measurements` array is not provided for a feature; - `measurementList` is `null` initially, and only populated if `measurements` is in the GeoJSON; - The previous code didn't pass in any list, which calls the overloaded `PathObjects.createAnnotationObject`, which just returns `createAnnotationObject(roi, pathClass, null);` anyway; - This means code-flow is unchanged if `measurements` are not provided. ### Images. #### Custom measurements extracted from GeoJSON:; ![image](https://user-images.githubusercontent.com/38670946/139694740-375af432-4cd4-4e56-90f6-57dd7be8970d.png); ![image](https://user-images.githubusercontent.com/38670946/139695945-1d0af088-ff6a-4287-8951-e3fe81f3c59f.png). ### Testing. - Works perfectly fine with GeoJSON files that create annotations both with and without a `measurements` field; - Example GeoJSON file I used for testing: https://pastebin.com/trYDYLXM; - Tested this file with and without the `measurements`",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/835:43,detect,detections,43,https://qupath.github.io,https://github.com/qupath/qupath/pull/835,1,['detect'],['detections']
Safety,"### issue; I cannot do cell detection when I use ; `ImageServerProvider.buildServer(imagePath, BufferedImage.class);`; ### detail：; 05:43:43.770 [main] [ERROR] q.lib.images.servers.FileFormatInfo - Checking Big TIFF images currently not supported!!!; celery_qupath_1 | 05:43:43.787 [main] [ERROR] q.l.i.s.o.OpenslideServerBuilder - Could not load OpenSlide native libraries; celery_qupath_1 | java.lang.UnsatisfiedLinkError: no openslide-jni in java.library.path: [/usr/local/lib, /usr/java/packages/lib, /usr/lib64, /lib64, /lib, /usr/lib]; celery_qupath_1 | 	at java.base/java.lang.ClassLoader.loadLibrary(ClassLoader.java:2660); celery_qupath_1 | 	at java.base/java.lang.Runtime.loadLibrary0(Runtime.java:827); celery_qupath_1 | 	at java.base/java.lang.System.loadLibrary(System.java:1902); celery_qupath_1 | 	at org.openslide.OpenSlideJNI.<clinit>(OpenSlideJNI.java:55); celery_qupath_1 | 	at org.openslide.OpenSlide.<clinit>(OpenSlide.java:53); celery_qupath_1 | 	at qupath.lib.images.servers.openslide.OpenslideServerBuilder.<clinit>(OpenslideServerBuilder.java:87); celery_qupath_1 | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); celery_qupath_1 | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); celery_qupath_1 | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); celery_qupath_1 | 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500); celery_qupath_1 | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481); celery_qupath_1 | 	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:781); celery_qupath_1 | 	at java.base/java.util.ServiceLoader$ProviderImpl.get(ServiceLoader.java:723); celery_qupath_1 | 	at java.base/java.util.ServiceLoader$3.next(ServiceLoader.java:1395); celery_qupath_1 | 	at qupath.lib.images.s",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/389:28,detect,detection,28,https://qupath.github.io,https://github.com/qupath/qupath/issues/389,1,['detect'],['detection']
Safety,"#1465 should fix the first issue. About:. > Quick addition. Defining an area using a polygon no longer works for the in-built detection, just when running a stardist script:. I wasn't able to reproduce the error. Does it happens on every run? Is it possible to share the project throwing the error?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443#issuecomment-1938648182:126,detect,detection,126,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443#issuecomment-1938648182,1,['detect'],['detection']
Safety,"$1.next(Unknown Source); 	at java.base/java.util.AbstractCollection.addAll(Unknown Source); 	at qupath.lib.objects.PathObjectTools.getAvailableFeatures(PathObjectTools.java:2026); 	at qupath.opencv.features.DelaunayTriangulation.<init>(DelaunayTriangulation.java:86); 	at qupath.opencv.features.DelaunayClusteringPlugin$DelaunayRunnable.run(DelaunayClusteringPlugin.java:208); 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); 	at java.base/java.util.concurrent.FutureTask.run(Unknown Source); 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); 	at java.base/java.util.concurrent.FutureTask.run(Unknown Source); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); 	... 1 more; ```. 2. If I repeat with **the outer rectangle selected**, then I *do* see connections.; This is because the triangulation uses *all descendant detections below the rectangle, based on the object hierarchy*. ![2-rectangle](https://github.com/user-attachments/assets/21b82d18-ce97-45c3-9644-7abdf85ab007). 3. If I repeat with **the outer ellipse selected**, I get *no connections at all*.; This is because the ellipse isn't set to be a parent of any of the other objects - this would change if I called *Resolve hierarchy* first. ![3-ellipse](https://github.com/user-attachments/assets/3c39bea5-9a9c-4ae3-bcc9-7ece1e8bae9c). 4. If I repeat with **the inner rectangles selected**, I get connections that don't cross *and I don't get any exception*.; This is because each cell is only handled once, so I don't get the concurrency trouble. ![4-inner rectangles](https://github.com/user-attachments/assets/74edf4a3-05c0-49ea-bd38-f82d327d9564). 5. If I repeat with **only 1 inner rectangle selected**, I get connections within that rectangle only. ![5-single rectangle](https://github.com/user-attachments/assets/492cf523-c58d-4b48-b417-ac44662a7a5a). ",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1590:3001,detect,detections,3001,https://qupath.github.io,https://github.com/qupath/qupath/issues/1590,1,['detect'],['detections']
Safety,"'Old' detection classifiers can be trained using multiple images. 'New' object and pixel classifiers currently only support training using multiple images if these are concatenated into a single image using *Create combined training image*. They should also support being built using training samples from multiple images, to facilitate refining classifiers later if more training becomes available.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/462:6,detect,detection,6,https://qupath.github.io,https://github.com/qupath/qupath/issues/462,1,['detect'],['detection']
Safety,'Resolve hierarchy' does not work correctly for TMA images with detections,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/540:64,detect,detections,64,https://qupath.github.io,https://github.com/qupath/qupath/issues/540,1,['detect'],['detections']
Safety,'Sum' measurement only available for Nucleus in Cell detection,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1454:53,detect,detection,53,https://qupath.github.io,https://github.com/qupath/qupath/issues/1454,1,['detect'],['detection']
Safety,"'s a comparison of the different object types [here](https://github.com/qupath/qupath/wiki/Types-of-object#annotations--detections)). With this many objects involved, you also probably don't want to add your objects to the hierarchy one-by-one within the loop, since this will trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side after already generating the polygon, using [`ShapeSimplifier.simplifyPolygon(PolygonROI polygon, final double altitudeThreshold)`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core/src/main/java/qupath/lib/roi/experimental/ShapeS",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/81#issuecomment-357045269:1293,detect,detection,1293,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269,1,['detect'],['detection']
Safety,"(processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Writing object hierarchy with 29994 object(s)...; INFO: Image data written to N:\Faculty-of-Medicine-and-Health\LICAP\DATA\PTHY\Pathology\Breast Group\BCCTB Samples\Audits\BCN QA 2017\Frozen samples QuPath tumourstromaratio\Batch_2\Tumour\402428.qpdata in 2.08 second",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:3793,detect,detected,3793,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,") to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""det",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:3137,detect,detected,3137,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"). 3. If I repeat with **the outer ellipse selected**, I get *no connections at all*.; This is because the ellipse isn't set to be a parent of any of the other objects - this would change if I called *Resolve hierarchy* first. ![3-ellipse](https://github.com/user-attachments/assets/3c39bea5-9a9c-4ae3-bcc9-7ece1e8bae9c). 4. If I repeat with **the inner rectangles selected**, I get connections that don't cross *and I don't get any exception*.; This is because each cell is only handled once, so I don't get the concurrency trouble. ![4-inner rectangles](https://github.com/user-attachments/assets/74edf4a3-05c0-49ea-bd38-f82d327d9564). 5. If I repeat with **only 1 inner rectangle selected**, I get connections within that rectangle only. ![5-single rectangle](https://github.com/user-attachments/assets/492cf523-c58d-4b48-b417-ac44662a7a5a). **Expected behavior**; This isn't obvious... Nevertheless:; 1. The `ConcurrentModificationException` is clearly bad. But it's also kind of helpful here, because 2. and 4. give different results... and when that's the case, if we select all the annotations in 2. and 4. in one go, it's not obvious what *should* happen.; 2. The reliance on hierarchical relationships may not be very intuitive to a user, since measurements like 'Positive %' are dynamically computed using spatial location relative to any selected annotation - not hierarchical relationships. **Desktop (please complete the following information):**; - OS: All; - QuPath Version: v0.5.1 (and earlier). **Additional context**; This relates to:; * #1444; * #1466. The behavior of *Delaunay cluster features 2D* is *in general* not very good for more reasons than these. For example, the display of the connection lines is already a bit of a hack (smuggled into `ImageData` properties) - and showing/hiding these can be unreliable. But fixing #1466 risks swallowing the `ConcurrentModificationException`, meaning we get unexpected results rather than an exception - which is potentially worse.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1590:5015,risk,risks,5015,https://qupath.github.io,https://github.com/qupath/qupath/issues/1590,1,['risk'],['risks']
Safety,* 'Show TMA measurements' showed detection measurements instead; * Added more filters for *Create thresholder*,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/498:33,detect,detection,33,https://qupath.github.io,https://github.com/qupath/qupath/pull/498,1,['detect'],['detection']
Safety,"* Add `--illegal-access=permit` Java option, intended to work around bugs such as https://github.com/qupath/qupath/issues/717 (and the inability to set project entry metadata, spotted by @Svidro); * Avoid using paragraph folding, new in RichTextFX 0.10.6, which could result in script editor exceptions (thanks to @melvingelbard for spotting that)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/721:199,Avoid,Avoid,199,https://qupath.github.io,https://github.com/qupath/qupath/pull/721,1,['Avoid'],['Avoid']
Safety,"* Add fill/unfill annotations toolbar button; * Reduce update check fail to a warning (rather than an error); * Show a more informative message is (probably) unable to connect to the internet; * Add 'Training data' title to object/pixel classifier training pie charts; * Remove confusion about whether the pie charts refer to the training or predictions; * Support log histograms with 'single measurement classifier' and 'set cell intensity classification' commands; * Fix the extensions directory path (use 'extensions' subdirectory, not the user path)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1391:342,predict,predictions,342,https://qupath.github.io,https://github.com/qupath/qupath/pull/1391,1,['predict'],['predictions']
Safety,"* Add gzip support for geojson import/export; * Prompt to update duplicate ids when importing objects; * This includes import via the menu & via drag & drop; * Add copy & paste to objects, via system clipboard and geojson; * Extract `FeatureCollection` into its own class; * Introduce max objects to copy preference; * Avoid shortcut+c because it intercepts other copying efforts (e.g. measurements from the 'Analysis pane'; * Make `PreferencePane` code easier to follow",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1103:319,Avoid,Avoid,319,https://qupath.github.io,https://github.com/qupath/qupath/pull/1103,1,['Avoid'],['Avoid']
Safety,"* Avoid calling `PointerScope.deallocate()`, because this may thwart `Pointer.retainReference()`; * Attempt to improve closing with object classification & the wand tool",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/789:2,Avoid,Avoid,2,https://qupath.github.io,https://github.com/qupath/qupath/pull/789,1,['Avoid'],['Avoid']
Safety,"* Enable new `DnnModel` implementations to be added via extensions (using a `ServiceLoader`); * Make all DeepJavaLibrary engines available when building via gradle properties; * Handle single-channel probability predictions as if they are multichannel when creating objects; * Without this, the 'softmax' assumption would mean that everything was treated as 'detected' since there was no higher channel available; * Store all actions added with `installActions`, so they can be found again via `QuPathGUI.lookupActionByText(String)`; * Add title to startup message (because otherwise drop shadow missing on Windows)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1160:212,predict,predictions,212,https://qupath.github.io,https://github.com/qupath/qupath/pull/1160,2,"['detect', 'predict']","['detected', 'predictions']"
Safety,"* Further reduce memory use with ImageOps / ImageDataOp; * Fix multithreading ImageOps color deconvolution bug; * Allow the number of live prediction threads to be adjusted with pixel classifiers; * Reduce the length of the server path used with pixel classifiers (could cause performance issues for some classifiers, e.g. Trees, with long JSON representations); * Add extra checks in DelaunayTools to reduce risk of trying to access a coordinate that isn't there",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/808:139,predict,prediction,139,https://qupath.github.io,https://github.com/qupath/qupath/pull/808,2,"['predict', 'risk']","['prediction', 'risk']"
Safety,"* Import/export objects as GeoJSON without scripting, via 'File -> Object data... -> ...'; * Import objects from .json, .geojson & .qpdata files via via 'File -> Object data... -> Import objects' or with drag & drop; * GeoJSON features now use ""properties>object_type"" rather than ""id"" property to map to a QuPath object type (e.g. ""annotation"", ""detection"", ""cell""); * 'id' is likely to be used as a unique identifier in a later QuPath version",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/698:347,detect,detection,347,https://qupath.github.io,https://github.com/qupath/qupath/pull/698,1,['detect'],['detection']
Safety,"* Include z/t index in measurement tables (if non-zero); * Don't show ROI type in `PathObjecttoString()`, but do show non-zero z-index and t-index.; * Make annotation list order more predictable; * Fix bug that meant brush/wand could edit an annotation on a different plane, if it was selected; * Ensure annotations are removed if they have an empty ROI after brush/wand editing; * Don't paint objects with an empty ROI",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1121:183,predict,predictable,183,https://qupath.github.io,https://github.com/qupath/qupath/pull/1121,1,['predict'],['predictable']
Safety,"* Introduce `OpenCVFunction` as a more generic way to call prediction, permitting multiple inputs and outputs.; * Support some of OpenCV's `Model` classes to simplify the use of different model types; * Support JSON serialization for `Scalar` and `Size`; * Support building with CUDA.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/794:59,predict,prediction,59,https://qupath.github.io,https://github.com/qupath/qupath/pull/794,1,['predict'],['prediction']
Safety,"* Many pixel classifier improvements; * Training annotations are used from all compatible images that are currently open; * New 'Load training' button to support training using annotations from multiple images; * New 'Measure' button to store measurements after the classifier is closed; * More control over the regions where the classifier is applied in 'live' preview mode; * Default classifier is now ANN (often better & much faster than Random Trees); * Measurement lists are reset if an object's ROI is changed; * This guards against inadvertently producing invalid measurements by modifying an annotate after measuring; * Viewer no longer centered on selected object when the selection changes or when typing 'Enter'; * Fixes some annoyances, especially when annotating across multiple viewers; * Center viewer by double-clicking objects in the 'Annotations' or 'Hierarchy' tab, or in a measurement table; * Improved spatial measurements; * Optionally split multi-part classifications (e.g. ""Class 1: Class 2"") for distance calculations (https://github.com/qupath/qupath/issues/405); * 'Classify -> Object classification -> Set cell intensity classification' now works for all detections, if no cells are present; * LabeledImageServer improvements; * Supports more than 255 distinct labels; * New useUniqueLabels() option to support labelling by object, not only classification; * Fixed bug/ambiguity in 'Fill holes' & 'Remove fragments and holes'; * Handle nested polygons/holes more reliably; * Changed behavior! Area thresholds now refer to total polygon/hole area ignoring any nested polygons or holes; * Other bug fixes, including:; * Local normalization now applied before calculating other features (was applied after in m11); * Fixed bug in 'Simplify shape' to handle polygons and rectangles properly; * Projects are automatically saved after changing the image name (https://github.com/qupath/qupath/issues/465)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/475:1183,detect,detections,1183,https://qupath.github.io,https://github.com/qupath/qupath/pull/475,1,['detect'],['detections']
Safety,* Properties can now be read from `userdirectory/localization`; * PreferencePane avoids recreating editors each time the pane is reopened or the mode is changed,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1243:81,avoid,avoids,81,https://qupath.github.io,https://github.com/qupath/qupath/pull/1243,1,['avoid'],['avoids']
Safety,* Removing 'action' class from ToggleButton seems to help toolbar behave properly; * Ensure weak listeners for PathObjectImageManagers; * Fixes problem when changing the image after creating a measurement table; * Fix default colors for derived PathClasses (don't retain the parent class color); * Reset preferences earlier in initialization if requested; * Avoid sorting exceptions in PathHierarchyImageServer,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1144:358,Avoid,Avoid,358,https://qupath.github.io,https://github.com/qupath/qupath/pull/1144,1,['Avoid'],['Avoid']
Safety,* Replace makeRGB(A) with pack(A)RGB methods to improve consistency/predictability; * Enable 'Rotate annotation' to work with point annotations; * Fix behavior of RotatedImageServer with empty tiles https://github.com/qupath/qupath/issues/641,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/705:68,predict,predictability,68,https://qupath.github.io,https://github.com/qupath/qupath/pull/705,1,['predict'],['predictability']
Safety,* Reposition script & log toolbar buttons; * Add preference to control display of toolbar badges; * Avoid calling `Desktop` during startup (this was causing trouble on macOS),MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1348:100,Avoid,Avoid,100,https://qupath.github.io,https://github.com/qupath/qupath/pull/1348,1,['Avoid'],['Avoid']
Safety,* Support deleting some/all measurements from objects of any class; * New clearMeasurements methods to handle specific cases; * Avoid showing 'Num detections' measurement for images that contain no detections at all,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/478:128,Avoid,Avoid,128,https://qupath.github.io,https://github.com/qupath/qupath/pull/478,3,"['Avoid', 'detect']","['Avoid', 'detections']"
Safety,* Switch `OpenCVTools` percentile method to match NumPy (can give different results!); * Improve percentile performance by using streams & avoiding array sort; * Add tests for percentiles,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1146:139,avoid,avoiding,139,https://qupath.github.io,https://github.com/qupath/qupath/pull/1146,1,['avoid'],['avoiding']
Safety,"* Use 'classification' rather then 'class' (to improve consistency, and reduce confusion with Java classes); * Add a new 'Object type' measurement to tables, giving a readable string ('Annotation', 'Detection', 'Cell' etc.); * No longer show a default 'Name' if no name has been set; * i.e. don't show 'PathAnnotationObject' or the classification as a placeholder, since this causes confusion for people writing scripts and requesting the name; * Renaming 'counting dialog' to 'points dialog'. Two bug fixes:; * Restore the classification colors in icons for points ROIs (regression in v0.5.0-rc1); * Fix bug that causes the pixel classifier training dialog to increase its width when some combo boxes were clicked on",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1392:199,Detect,Detection,199,https://qupath.github.io,https://github.com/qupath/qupath/pull/1392,1,['Detect'],['Detection']
Safety,"* [x] I've definitely found a bug (it you're not sure, please use [image.sc](https://forum.image.sc/tags/qupath) instead); * [ ] I've checked https://qupath.github.io for a new release that might already have fixed the issue; * [ ] I've checked the [Changelog](https://github.com/qupath/qupath/blob/master/CHANGELOG.md) to see if the bug has already been fixed in the next release; * [ ] I've checked for existing GitHub issues describing the same problem. ## Bug report. **Describe the bug**. Redundancy in if-else condition to throw IOException in [ImageWriteTools.java](https://github.com/qupath/qupath/blob/6b8bafc566356fe9b97770fb88227e9e768f14da/qupath-core/src/main/java/qupath/lib/images/writers/ImageWriterTools.java#L176). `		; ```; if (firstException == null && firstException == null); 			throw new IOException(""Unable to write "" + path + ""! No compatible writer found."");; 		else; 			throw new IOException(""Unable to write "" + path + ""!"", firstException);; 	}; ```; `. **Expected behavior**; A",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/816:494,Redund,Redundancy,494,https://qupath.github.io,https://github.com/qupath/qupath/issues/816,1,['Redund'],['Redundancy']
Safety,"* downsample; double tileHeight = tileHeightPixels * downsample. // Loop through the image - including z-slices (even though there's normally only one...); int counter = 0;; for (int z = 0; z < server.nZSlices(); z++) {; for (double y = 0; y < server.getHeight(); y += tileHeight) {. // Compute integer y coordinates; int yi = (int)(y + 0.5); int y2i = (int)Math.min((int)(y + tileHeight + 0.5), server.getHeight());; int hi = y2i - yi. // Check if we requesting a region that is too small; if (hi / downsample < minImageDimension) {; println(""Image dimension < "" + minImageDimension + "" - skipping row""); continue; }. for (double x = 0; x < server.getWidth(); x += tileWidth) {. // Compute integer x coordinates; int xi = (int)(x + 0.5); int x2i = (int)Math.min((int)(x + tileWidth + 0.5), server.getWidth());; int wi = x2i - xi. // Create request; RegionRequest request = RegionRequest.createInstance(path, downsample, xi, yi, wi, hi, z, 0). // Check if we requesting a region that is too small; if (wi / downsample < minImageDimension) {; // Only print warning if we've not skipped this before; if (y > 0); println(""Image dimension < "" + minImageDimension + "" - skipping column""); continue; }. // Surround with try/catch in case the server gives us trouble; try {; // Read the image region; ImagePlus imp = server.readImagePlusRegion(request).getImage(false); // Get a suitable file name; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; File file = new File(dirOutput, name); // Save the image; IJ.save(imp, file.getAbsolutePath()); // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); } catch (Exception e) {; // Check if we have had a sufficient number of errors to just give up; nErrors++;; if (nErrors > maxErrors) {; println(""Maximum number of errors exceeded - aborting...""); return; }; e.printStackTrace(); }; }; }; }; println(""Done"");; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/85#issuecomment-315148862:4334,abort,aborting,4334,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862,1,['abort'],['aborting']
Safety,* showConfirmDialog method never uses its title parameter https://github.com/qupath/qupath/issues/662; * Error in Measurement with StarDist script with RGB fluorescence images https://github.com/qupath/qupath/issues/686; * Detect centroid distances 2D doesn't work on different planes of a z-stack https://github.com/qupath/qupath/issues/696,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/697:223,Detect,Detect,223,https://qupath.github.io,https://github.com/qupath/qupath/pull/697,1,['Detect'],['Detect']
Safety,"**Describe the bug**; Create a box annotation of the entire slide and run positive cell detection. Some slides work fine, others seem to just stop with no error. . **To Reproduce**; Steps to reproduce the behavior:; 1. Go to 'Analyze' -> Cell Detection ->Positive Cell Detection; 2. Accept defaults.; 3. Runs with no errors. . **Expected behavior**; A full slide with every cell detected and classified. . **Screenshots**; ![image](https://user-images.githubusercontent.com/14006401/135633690-717d4fc9-6010-4de6-b235-54bd3dc98ea6.png). **Desktop (please complete the following information):**; - OS: Windows, 64GB RAM, 32 core processor, Nvidia GTX1060 with CUDA 11.1 installed.; - QuPath Version 3.0. **Additional context**; RAM usage at around 60%, ; No plugins loaded after initial install.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/828:88,detect,detection,88,https://qupath.github.io,https://github.com/qupath/qupath/issues/828,4,"['Detect', 'detect']","['Detection', 'detected', 'detection']"
Safety,"**Describe the bug**; On QuPath 0.4.1, when I try to create points, at the moment I right click to set a Class, the bug appears, and a log window indicates:. `INFO: QuPath build: Version: 0.4.1; Build time: 2023-01-07, 12:00; INFO: Setting tile cache size to 3972.00 MB (25.0% max memory); INFO: Refreshing extensions in Path/to/QuPath/extensions/extensions; INFO: Added extension: Path/to/QuPath/extensions/extensions/qupath-extension-stardist-0.4.0.jar; INFO: Added extension: Path/to/QuPath/extensions/extensions/qupath-extension-cellpose-0.6.0.jar; INFO: Added extension: Path/to/QuPath/extensions/extensions/qupath-extension-imagecombiner-0.2.3.jar; INFO: Initializing type adapters; INFO: CUDA detected and will be used if possible. Use DnnTools.setUseCuda(false) to turn this off.; INFO: Loaded extension BIOP Cellpose extension (3 ms); INFO: Bio-Formats version 6.11.1; INFO: Bio-Formats memoization is turned OFF (based on Java 17.0.5+8, Bio-Formats 6.11.1); INFO: Loaded extension Bio-Formats options (Bio-Formats 6.11.1) (9 ms); INFO: Loaded extension ImageCombiner extension (1 ms); INFO: Loaded extension ImageJ extension (34 ms); INFO: Loaded extension Processing extension (16 ms); INFO: Loaded extension Rich script editor extension (144 ms); INFO: Loaded extension SVG export extension (0 ms); INFO: Loaded extension StarDist extension (2 ms); INFO: OpenSlide version 3.4.1; INFO: Starting QuPath with parameters: []; INFO: Update check for https://github.com/qupath/qupath; INFO: No newer release for QuPath (0.4.1 is newer than 0.4.1); INFO: Update check for https://github.com/qupath/qupath-extension-stardist; INFO: No newer release for StarDist extension (0.4.0 is newer than 0.4.0); INFO: Update check for https://github.com/biop/qupath-extension-cellpose; INFO: No newer release for Cellpose 2D QuPath Extension (0.6.0 is newer than 0.6.0); WARN: Selecting project file /media/image_in/T7 Shield/Recherche/LABO/12.22-Efferocytose_InCuCyte/qupath/QupathProject_donneur1/project.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1202:700,detect,detected,700,https://qupath.github.io,https://github.com/qupath/qupath/issues/1202,1,['detect'],['detected']
Safety,"**Describe the bug**; Panning around an image with a high number of cell detection objects will result in minor lag due to 100% CPU usage of a single processor, even if the object opacity slider is set to 0. . **To Reproduce**; Steps to reproduce the behavior:; 1. Run a cell detection (StarDist was used in the video demo below); 2. Click on 'Show Detections'; 3. Set the detection opacity slider to 0; 4. Pan around, observe minor lag; 5. uncheck 'Show Detections', note lag is no longer present. **Expected behavior**; Panning around with the opacity slider set to 0 should behave as if 'Show Detections' was disabled, however it seems like the objects are still being rendered. **Screenshots**; Video demonstration: https://www.youtube.com/watch?v=QKxKfBYyoB8. **Desktop (please complete the following information):**; - OS: Windows 10; - QuPath Version: 0.3.0 with CUDA. **Additional context**; Issue impacts QoL very slightly, but I'm curious if the lag is more disruptive/noticeable on lower-end machines. If it's not, then might not be something worth spending the time to fix.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/826:73,detect,detection,73,https://qupath.github.io,https://github.com/qupath/qupath/issues/826,6,"['Detect', 'detect']","['Detections', 'detection']"
Safety,**Describe the bug**; Running (some) scripts from the command line can be substantially slower than running the same scripts from the QuPath script editor. **To Reproduce**; See https://forum.image.sc/t/cell-detection-from-command-line-script-slower-than-when-using-gui/40636. **Expected behavior**; Running a command line script is as fast/faster when compared to running the same script through the UI. **Additional context**; The tile cache is usually initialized with the GUI; tiles are not cached when running from the command line. Therefore I suspect that the lack of a tile cache may be the cause of/a contributor to the performance difference - but initial tests of this were inconclusive. It appears that avoiding the jpackage-generated launcher and instead using `java -jar qupath-0.2.1.jar ...` substantially improves performance (for reasons as yet unknown).,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/561:208,detect,detection-from-command-line-script-slower-than-when-using-gui,208,https://qupath.github.io,https://github.com/qupath/qupath/issues/561,2,"['avoid', 'detect']","['avoiding', 'detection-from-command-line-script-slower-than-when-using-gui']"
Safety,"**Describe the bug**; Unfortunately I am not able to share a lot of details (screenshots/reports) as it happenned a few days ago... but after all I thought it would be a good idea to share it here.; I was working on the analysis of some IF images. I created a project, set the images to fluorescence, applied the viewing settings I wanted, and started annotating the tissue. I have several annotations to draw on each tissue to mark specific areas, and it is relatively time consuming to do for 20 images. I also worked out the best cellular detections, trained a classifier, and got pretty much where I wanted.; I checked all images again, double checked all annotations and everything seemed fine.; I then started a batch analysis... which started normally. Once finished (and I didn't get any error message), I checked my detection and annotations results and >15 slides had no data. When I tried openning the images in the QuPath project, everything was gone: I get ask to set the image type and all annotations had disappear. I tried openning the .backup file but everything was gone there too. ; I'm thinking I must have done something wrong but I have no idea what... and unfortunately the .backup file was not enough to save me from doing everything again. I guess my questions are: do you know what could have caused this to happen? would there be a way of exporting the annotations separately (to save them for easy re-load if needed) ?. **Desktop:**; - OS: macOS Sierra; - QuPath Version 0.2",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316:542,detect,detections,542,https://qupath.github.io,https://github.com/qupath/qupath/issues/316,2,['detect'],"['detection', 'detections']"
Safety,"**Description of the bug**; Left-click on the Automate-Button to open the drop down menue that incorporates the ""script editor"" causes opening of log window with the qupath-exception text (see below). . Even not after reinstallation of QuPath and Java. ; Even to run QuPath inside a ZIP downloaded version does not solve the probem. . **To Reproduce**; Steps to reproduce the behavior:; 1. run the lock script: ; selectAnnotations(); getSelectedObjects().each {; it.setLocked(true); }; fireHierarchyUpdate(). There were large annotations with hierarchy. But only 170kb vertex points. One of them was a simple tissue detection. . ; **Desktop (please complete the following information):**; - 64 bit Windows10 ; - QuPath Version 0.1.2. **Exception text in log file**; at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:49); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.control.Menu.setShowing(Menu.java:199); at javafx.scene.control.Menu.show(Menu.java:408); at com.sun.javafx.scene.control.skin.MenuBarSkin.lambda$rebuildUI$401(MenuBarSkin.java:677); at com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:238); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:191); at com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDispatcher.java:59); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:58); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(Ev",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/422:616,detect,detection,616,https://qupath.github.io,https://github.com/qupath/qupath/issues/422,1,['detect'],['detection']
Safety,"**Please avoid creating issues for anything other than bug reports; use [the forum](http://forum.image.sc/tags/qupath/) instead.**. <img width=""696"" alt=""Issues"" src=""https://user-images.githubusercontent.com/4690904/71262757-5afea500-2338-11ea-8c14-91f68652c70b.png"">",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/395#issuecomment-581003028:9,avoid,avoid,9,https://qupath.github.io,https://github.com/qupath/qupath/issues/395#issuecomment-581003028,1,['avoid'],['avoid']
Safety,"**You've checked https://qupath.github.io for a new release that might already have fixed the issue, right?**. **And you've searched for related issues here to see if the issues has already been reported?**. Good, then please fill in the template about the bug... > For general questions about the software (not bugs) use [image.sc](https://forum.image.sc/tags/qupath). ----. **Describe the bug**; Not sure if this is a bug or intended:; In 0.1.x versions of qupath the qupath project would save the relative path to the images if placed inside a folder inside the project folder.; In version 0.2.0-m2 the path to an image is always absolute.; This makes moving a project folder very risky :). **To Reproduce**; Steps to reproduce the behavior:; - How I setup a project under QuPath 0.2.0-m2 and 0.1.2:; 1. In QuPath choose empty folder for the project; 2. mkdir images inside the project folder; 3. copy images into new folder images; 4. In QuPath add images from this images folder to the project; 5. Save/Close; 5. Check QuPath project file with texteditor:; -> v 0.1.2 - path to images are relative to project folder; -> v 0.2.0-m2 - path to images are absolute. **Expected behavior**; Same behavior in v0.2.0-m2 as i v0.1.2 - usage of relative path in project file. **Screenshots**; -. **Desktop (please complete the following information):**; - OS: Windows 10 x64; - QuPath Version 0.2.0-m2 vs 0.1.2. **Additional context**; - Work-around:; - setup project folder directly in the base directory (https://github.com/qupath/qupath/issues/325#issuecomment-497796974); - Edit project file with text editor to replace/update absolute path",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/325:684,risk,risky,684,https://qupath.github.io,https://github.com/qupath/qupath/issues/325,1,['risk'],['risky']
Safety,"*; Steps to reproduce the behavior:; 1. Open a brightfield image e.g. *CMU-1-Small-Region.svs*; 2. Set type to *Brightfield (Other)*; 3. Set 2 or 3 stains, ensuring Hematoxylin is *not* the first; 4. Run *Cell detection* using hematoxylin image; 5. Inspect image to check which channel was really used for detection. **Expected behavior**; The minimal required changes are:; * Use the stain name to identify the hematoxylin image, don't just assume it's the first; * Log a clear warning or throw an exception if anything else is done / there is no hematoxylin available. Ideally, options to detect using any/all stains should be provided to the user. **Screenshots**; Using the following stains; ```groovy; setColorDeconvolutionStains('{""Name"" : ""Some other stains"", ""Stain 1"" : ""Something"", ""Values 1"" : ""0.11793 0.84247 0.52567"", ""Stain 2"" : ""Another"", ""Values 2"" : ""0.32293 0.56288 0.76084"", ""Stain 3"" : ""Hematoxylin "", ""Values 3"" : ""0.61203 0.70103 0.36602"", ""Background"" : "" 255 255 255""}');; ```; the detection looks as below; ![Screenshot 2021-12-26 at 07 51 32](https://user-images.githubusercontent.com/4690904/147402284-3dd60b6b-e301-4efc-850d-fb35f56ced0d.jpg); ![Screenshot 2021-12-26 at 07 51 39](https://user-images.githubusercontent.com/4690904/147402286-d946f166-c927-4d24-9b56-3fec4a54a192.jpg); ![Screenshot 2021-12-26 at 07 51 43](https://user-images.githubusercontent.com/4690904/147402287-b250b3f1-9891-45d7-a1bd-2aea942a185a.jpg); ![Screenshot 2021-12-26 at 07 51 55](https://user-images.githubusercontent.com/4690904/147402288-55dd97c1-6b3b-4c15-898f-84bc314cea2a.jpg). The detected nuclei correspond to the first deconvolved stain, not the third (as it ought to). **Desktop (please complete the following information):**; - OS: All; - QuPath v0.3.1 (and all previous). **Additional context**; Issue discovered while investigating https://forum.image.sc/t/positive-cell-detection-function-unable-to-detect-stain-3-hematoxylin-in-the-intensity-threshold-parameters-section/61414",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/878:1502,detect,detection,1502,https://qupath.github.io,https://github.com/qupath/qupath/issues/878,3,['detect'],"['detected', 'detection', 'detection-function-unable-to-detect-stain-']"
Safety,", ""minAreaPixels"": 100000.0, ""maxHoleAreaPixels"": 500.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}');. // Get the file name from the current server; def name = server.getShortServerName(). // We need to get the display settings (colors, line thicknesses, opacity etc.) from the current viewer, if available; def overlayOptions = QuPathGUI.getInstance() == null ? new OverlayOptions() : QuPathGUI.getInstance().getViewer().getOverlayOptions(). // Calculate downsample factor depending on the requested pixel size; double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()). // Write output image, with and without overlay; def dir = new File(path); def fileImage = new File(dir, name + "".jpg""); def img = ImageWriterTools.writeImageRegion(server, request, fileImage.getAbsolutePath()); def fileImageWithOverlay = new File(dir, name + ""-overlay.jpg""); ImageWriterTools.writeImageRegionWithOverlay(img, imageData, overlayOptions, request, fileImageWithOverlay.getAbsolutePath()); ----------------------------------------------------------------------; WARN: Invalid requested downsample 1.0 - will use 1.057 instead; INFO: 1 region detected (processing time: 2.97 seconds); INFO: Processing complete in 3.06 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.tissue.SimpleTissueDetection2 {""threshold"": 162, ""requestedDownsample"": 1.0, ""minAreaPixels"": 100000.0, ""maxHoleAreaPixels"": 500.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}; ERROR: Error writing D:\image-project\export\358.jpg with JPEG; ERROR: Unable to write D:\image-project\export\358.jpg! No compatible writer found.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/216#issuecomment-420287639:2439,detect,detected,2439,https://qupath.github.io,https://github.com/qupath/qupath/issues/216#issuecomment-420287639,2,['detect'],"['detect', 'detected']"
Safety,", ImageRegion region). public synchronized Collection<PathObject> getPointObjects(Class<? extends PathObject> cls); ```. This PR deprecates these methods, and provides alternatives that do not require Java classes to be specified. ### Accessing objects for a `ROI`; This provides a way to access objects within (in some sense!) a specified ROI:; ```java; // Old method, discouraged (but not yet deprecated); public Collection<PathObject> getObjectsForROI(Class<? extends PathObject> cls, ROI roi). // New methods; public Collection<PathObject> getAllObjectsForROI(ROI roi); public Collection<PathObject> getAnnotationsForROI(ROI roi); public Collection<PathObject> getTilesForROI(ROI roi); public Collection<PathObject> getCellsForROI(ROI roi); public Collection<PathObject> getAllDetectionsForROI(ROI roi); ```. **There is an important (and possibly-unexpected) subtlety here!**. The new methods follow the original in *returning objects using QuPath's 'hierarchy' rules*:; * An annotation is 'within' a ROI if it is *completely contained* by the ROI; * A detection is 'within' a ROI if *its centroid* is within the ROI. Note that these methods take a `ROI` as input and not a `PathObject`: they aren't using the parent/child relationships between objects when deciding what to return. However they do correspond with how QuPath determines dynamic measurements (e.g. Positive % of cells), or what happens when `resolveHierarchy()` is called. If all this seems too confusing and you just want to get objects for a defined area, you may instead want to try... ### Accessing objects for an `ImageRegion`; This provides a way to get all objects that intersect (or even just *may* intersect) with a specified 2D image region. ```java; // Old method, deprecated; public Collection<PathObject> getObjectsForRegion(Class<? extends PathObject> cls, ImageRegion region, Collection<PathObject> pathObjects). // New methods (the collection parameter is optional & can be null); public Collection<PathObject> getA",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1563:2154,detect,detection,2154,https://qupath.github.io,https://github.com/qupath/qupath/pull/1563,1,['detect'],['detection']
Safety,",. I convert my image in mrxs (tiles in jpeg) channel by channel with panoramic viewer. So now I can open the image with Qupath. Is there a way to calculate the intensity for fluorescence above a threshold with Qupath or do we have to use Image J with the; Function (Extension/Image J/Send region to ImageJ) ?. I also try to export also the image in TIF with panoramic viewer (jpeg). Using Image J to open it is very long ( around 5 minutes), the TIF have several resolution, I load the best resolution (extended), my computer is quite powerful but the image is around 4Gb.; I obtain 3 channels whereas I should have only one. So it seems not easy to work with TIF tiles images (no compression or jpeg compression) with Image J. In QuPath, I cannot load this TIF, is-it normal ?. Thanks very much for your help,. Mathieu. De : Pete <notifications@github.com>; Envoyé : Friday, July 20, 2018 4:50 PM; À : qupath/qupath <qupath@noreply.github.com>; Cc : Mathieu FALLET <fallet@ciml.univ-mrs.fr>; Author <author@noreply.github.com>; Objet : Re: [qupath/qupath] resolution very bad with mrxs format (#187). It may work if it is 8-bit RGB (i.e. three channels), and does not use JPEG-XR compression. However if the original data is 16-bit, or has more channels, then there is the risk of a considerable loss of information on conversion. It would be fantastic if the company behind the format could offer a solution - ideally through Bio-Formats (since QuPath and many other software applications already support Bio-Formats). Otherwise, it is sadly the case that people depending on certain scanners using proprietary file formats may not be able to analyze their data with QuPath, or open source tools. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/187#issuecomment-406624163>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AnjxC34M2KOVzGqUYk4mTbNwwg4P8gbDks5uIe4ngaJpZM4VYHCt>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/187#issuecomment-407029411:1283,risk,risk,1283,https://qupath.github.io,https://github.com/qupath/qupath/issues/187#issuecomment-407029411,1,['risk'],['risk']
Safety,"- Added the handling of new lines following a '{' character, which works as follows:; 1. A block is generally '{' + new line + indentation + new line + '}'; 2. The final caret position is set to inside the block; 3. If there originally was some text after '{', the text will be included inside the block. E.g. ; ```; forEach{doSomething(); }; ```; becomes: ; ```; forEach {; doSomething(); }; ```; 4. If the amount of '{' and '}' in the text is equal, it will add the new line but won't create a block. This is to avoid cases where there already is a closing bracket. E.g. hitting 'Enter' after the opening bracket in the following example will not add a closing bracket, since one is already present: ; ```; forEach { ; doSomething(); }; ```; becomes; ```; forEach {; ; doSomething(); }; ```; And not:; ```; forEach {; ; }; doSomething(); }; ```; 5. A space is added before '{' if there wasn't one already (purely aesthetic):; ```; forEach{...; }; ```; and; ```; forEach {...; }; ```; both become: ; ```; forEach {; ...; }; ```. - At this stage, this is quite experimental. However, it could develop into something more advanced in the future.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/901:514,avoid,avoid,514,https://qupath.github.io,https://github.com/qupath/qupath/pull/901,1,['avoid'],['avoid']
Safety,"- Added the possibility to sort project entries by additional keys (more than just entry metadata values, see below).; - Added URI key to sort project entries by URIs (e.g. different images coming from the same file will be grouped together).; - A warning now appears when applying detection classifier with missing features (https://github.com/qupath/qupath/issues/411)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/417:282,detect,detection,282,https://qupath.github.io,https://github.com/qupath/qupath/pull/417,1,['detect'],['detection']
Safety,"- Added tooltip in Pixel classifier UI to notify users that classifiers can't be saved if not working inside a project (tooltip only appears when no project is detected).; - Added ability to Drag & Drop classifier(s) onto the Load object classifier pane to add a classifier from a different source (e.g. a different project).; - Added ability to add classifier(s) to the `comboBox` in Load pixel classifier pane to add a classifier from a different source. (e.g. a different project). Note (and possibly `TODO`): when adding a `PixelClassifier`, no check is made to ensure that the classifier is valid.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/642:160,detect,detected,160,https://qupath.github.io,https://github.com/qupath/qupath/pull/642,1,['detect'],['detected']
Safety,"- Added tooltip in Pixel classifier UI to notify users that classifiers can't be saved if not working inside a project (tooltip only appears when no project is detected).; - Added ability to Drag & Drop classifier(s) onto the _Load object classifier_ pane to add a classifier from a different source (e.g. a different project).; - Added ability to add classifier(s) to the `comboBox` in _Load pixel classifier_ pane to add a classifier from a different source. (e.g. a different project). Note (and possibly `TODO`): when adding a `PixelClassifier`, no check is made to ensure that the classifier is valid.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/637:160,detect,detected,160,https://qupath.github.io,https://github.com/qupath/qupath/pull/637,1,['detect'],['detected']
Safety,"- Created MeasurementExporter, to make the export of (annotation/detection) measurements easy.; - Created MeasurementExportCommand, a simple GUI for MeasurementExporter.; - Created ProjectDialogs, which contains a single method for displaying ListSelectionViews with project image entries.; - Refactored DefaultScriptEditor so it now uses the method in ProjectDialogs.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/425:65,detect,detection,65,https://qupath.github.io,https://github.com/qupath/qupath/pull/425,1,['detect'],['detection']
Safety,"- Fixed several formatting issues for Windows, including:; - Import of tab-delimited data (e.g. TMA grids); - Escaping of paths when exporting TMA data; - Separation of paths in 'Help -> System info'; - Cached image paths (still experimental); - TMA data export now records directory (rather than name) in script, so that it can be reused across a project without editing; - Added use of OpenSlide's background color - this fixes previously-buggy appearance when scans where part of the image is omitted (e.g. some mrxs images); - Updated TMA dearraying command to support fluorescence TMAs; - Modified TMA dearraying script command to abort if dearraying for the first time by default - this encourages good practice of checking dearrayed result prior to running full analysis (although means that any generated script would need to be run twice - once to dearray, and then again to do everything else); - 'Relabel TMA Grid' now a scriptable command; - Fixed reassigning child objects with 'Make inverse annotation' command; - Fixed bug that prevented plugins cancelling more than once; - Minor improvements to Brightness/Contrast panel; - Set default logging level to INFO; - Added sample script to change logging level; - Improved display of licenses & third-party dependencies; - Updated location of user preferences; - Added menu entry to reset preferences",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/4:636,abort,abort,636,https://qupath.github.io,https://github.com/qupath/qupath/pull/4,1,['abort'],['abort']
Safety,"- Now allows 3 different kinds of OMERO URLs (i.e. ""Webgateway"", ""Webclient"", ""iViewer""); - Handles import of multiple images in a single URL; - Handles whole projects/datasets import; - Safer password handling; - Clearer warning/error messages when Exceptions occur",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/479:187,Safe,Safer,187,https://qupath.github.io,https://github.com/qupath/qupath/pull/479,1,['Safe'],['Safer']
Safety,"- QuPath now checks for the validity of OMERO image entries when opening projects/datasets through the OMERO browser (so the user is not stuck getting a lot of error messages when opening a dataset with loads of invalid images).; - Restrict the objects sent back to OMERO through the GUI to annotations only. Sending detections is still possible but only throught scripting.; - Running 'Send selected annotations to OMERO' with no selection will prompt the user with a dialog that asks if the command should be ran with all the annotations present in the current image.; - Removed '(s)'; - Added TMACoreObject serialization. This means that it is technically possible to run 'Send selected annotations to OMERO' for a selected TMA core. It will then behave as expected (N.B. on OMERO, it will still appear as a normal 'OMERO ROI')",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/708:317,detect,detections,317,https://qupath.github.io,https://github.com/qupath/qupath/pull/708,1,['detect'],['detections']
Safety,- Reduce instances of TopologyException (currently in StarDist) by fixing geometries produced by estimateCellBoundary if needed.; - Improve detectionsToCells to avoid losing all cells if one throws an exception.,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/992:140,detect,detectionsToCells,140,https://qupath.github.io,https://github.com/qupath/qupath/pull/992,2,"['avoid', 'detect']","['avoid', 'detectionsToCells']"
Safety,"-2.17.so; 7fa4aa4d3000-7fa4aa4d7000 r--p 001c3000 00:27 2499 /usr/lib64/libc-2.17.so; 7fa4aa4d7000-7fa4aa4d9000 rw-p 001c7000 00:27 2499 /usr/lib64/libc-2.17.so; 7fa4aa4d9000-7fa4aa4de000 rw-p 00000000 00:00 0 ; 7fa4aa4de000-7fa4aa5df000 r-xp 00000000 00:27 2613 /usr/lib64/libm-2.17.so; 7fa4aa5df000-7fa4aa7de000 ---p 00101000 00:27 2613 /usr/lib64/libm-2.17.so; 7fa4aa7de000-7fa4aa7df000 r--p 00100000 00:27 2613 /usr/lib64/libm-2.17.so; 7fa4aa7df000-7fa4aa7e0000 rw-p 00101000 00:27 2613 /usr/lib64/libm-2.17.so; 7fa4aa7e0000-7fa4aa7e2000 r-xp 00000000 00:27 2528 /usr/lib64/libdl-2.17.so; 7fa4aa7e2000-7fa4aa9e2000 ---p 00002000 00:27 2528 /usr/lib64/libdl-2.17.so; 7fa4aa9e2000-7fa4aa9e3000 r--p 00002000 00:27 2528 /usr/lib64/libdl-2.17.so; 7fa4aa9e3000-7fa4aa9e4000 rw-p 00003000 00:27 2528 /usr/lib64/libdl-2.17.so; 7fa4aa9e4000-7fa4aaa06000 r-xp 00000000 00:27 2475 /usr/lib64/ld-2.17.so; 7fa4aaa0d000-7fa4aaae1000 rw-p 00000000 00:00 0 ; 7fa4aaae1000-7fa4aaae9000 ---p 00000000 00:00 0 ; 7fa4aaae9000-7fa4aaaed000 ---p 00000000 00:00 0 ; 7fa4aaaed000-7fa4aabee000 rw-p 00000000 00:00 0 ; 7fa4aabf8000-7fa4aabf9000 rw-p 00000000 00:00 0 ; 7fa4aabf9000-7fa4aac01000 rw-s 00000000 00:d6 7895008 /tmp/hsperfdata_xxx/19036; 7fa4aac01000-7fa4aac02000 ---p 00000000 00:00 0 ; 7fa4aac02000-7fa4aac03000 r--p 00000000 00:00 0 ; 7fa4aac03000-7fa4aac04000 ---p 00000000 00:00 0 ; 7fa4aac04000-7fa4aac05000 rw-p 00000000 00:00 0 ; 7fa4aac05000-7fa4aac06000 r--p 00021000 00:27 2475 /usr/lib64/ld-2.17.so; 7fa4aac06000-7fa4aac07000 rw-p 00022000 00:27 2475 /usr/lib64/ld-2.17.so; 7fa4aac07000-7fa4aac08000 rw-p 00000000 00:00 0 ; 7ffd463f8000-7ffd46422000 rw-p 00000000 00:00 0 [stack]; 7ffd465a9000-7ffd465ac000 r--p 00000000 00:00 0 [vvar]; 7ffd465ac000-7ffd465ae000 r-xp 00000000 00:00 0 [vdso]; ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0 [vsyscall]; /home/xxx/QuPath-0.3/bin/QuPath.sh: line 5: 19036 Aborted ""$DIR/QuPath"" ""$@"". **Desktop :**; - OS: CentOS 7; - QuPath Version [e.g. 0.3]",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/825:29586,Abort,Aborted,29586,https://qupath.github.io,https://github.com/qupath/qupath/issues/825,1,['Abort'],['Aborted']
Safety,"-extension-processing:jar; > Task :qupath-extension-script-editor:processResources; > Task :qupath-extension-script-editor:classes; > Task :qupath-extension-script-editor:jar; > Task :qupath-extension-svg:processResources; > Task :qupath-extension-svg:classes; > Task :qupath-extension-svg:jar; > Task :qupath-gui-fx:processResources; > Task :qupath-gui-fx:classes; > Task :qupath-gui-fx:jar; > Task :generateLicenseReport; > Task :copyLicenses; > Task :extractNativeLibraries; > Task :jar; > Task :assemble; > Task :compileTestJava NO-SOURCE; > Task :processTestResources; > Task :testClasses; > Task :test NO-SOURCE; > Task :check UP-TO-DATE; > Task :copyLicenseReport; > Task :copyRuntimeLibs; > Task :build; > Task :qupath-core:assemble. > Task :qupath-core:compileTestJava; Note: Some input files use or override a deprecated API.; Note: Recompile with -Xlint:deprecation for details.; Note: /home/gordon/src/qupath/qupath-core/src/test/java/qupath/lib/io/TypeAdaptersCVTest.java uses unchecked or unsafe operations.; Note: Recompile with -Xlint:unchecked for details. > Task :qupath-core:processTestResources; > Task :qupath-core:testClasses. > Task :qupath-core:test FAILED. TypeAdaptersCVTest > testGetOpenCVTypeAdaptorFactory() FAILED; java.lang.ExceptionInInitializerError at TypeAdaptersCVTest.java:32; Caused by: java.lang.NullPointerException at TypeAdaptersCVTest.java:32. TypeAdaptersCVTest > testGetTypeAdaptor() FAILED; java.lang.NoClassDefFoundError at TypeAdaptersCVTest.java:99. 42 tests completed, 2 failed. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':qupath-core:test'.; > There were failing tests. See the report at: file:///home/gordon/src/qupath/qupath-core/build/reports/tests/test/index.html. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Get more help at https://help.gradle.org. Deprecated Gradle features were use",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/484#issuecomment-630769356:5580,unsafe,unsafe,5580,https://qupath.github.io,https://github.com/qupath/qupath/issues/484#issuecomment-630769356,1,['unsafe'],['unsafe']
Safety,". This script at least runs, although I'm not sure if it's what you want or not:; ```groovy; //Exporting Image as .tif files; import qupath.lib.gui.ImageWriterTools. import qupath.lib.images.servers.ImageServer; import qupath.lib.regions.RegionRequest; import qupath.lib.scripting.QP. import java.awt.image.BufferedImage. /*; * Adjustable parameters; */; int tileWidthPixels =1500 // Width of (final) output tile in pixels; int tileHeightPixels = tileWidthPixels // Width of (final) output tile in pixels; double downsample = 70 // Downsampling used when extracting tiles; String format = ""tif"" // Format of the output image - TIFF or ZIP is best for ImageJ to preserve pixel sizes; String dirOutput = buildFilePath(PROJECT_BASE_DIR, 'something else') // BE SURE TO ADD AN OUTPUT DIRECTORY HERE!!!; mkdirs(dirOutput). int maxErrors = 20 // Maximum number of errors... to avoid trying something doomed forever; int minImageDimension = 16 // If a tile will have a width or height < minImageDimension, it will be skipped; // This is needed to avoid trying to read/write images that are too tiny to be useful (and may even cause errors). //-------------------------------------------------------. /*; * Processing; */. // Check we have an output directory; if (dirOutput == null) {; println(""Be sure to set the 'dirOutput' variable!""); return; }. // Initialize error counter; int nErrors = 0. // Get the image server; ImageServer<BufferedImage> server = QP.getCurrentImageData().getServer(). // Ensure convert the format to a file extension; String ext; if (format.startsWith(""."")); ext = format.substring(1).toLowerCase(); else; ext = format.toLowerCase(). // Extract useful variables; String path = server.getPath(); String serverName = server.getShortServerName(); double tileWidth = tileWidthPixels * downsample; double tileHeight = tileHeightPixels * downsample. // Loop through the image - including z-slices (even though there's normally only one...); int counter = 0;; for (int z = 0; z < server.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/309#issuecomment-486778605:936,avoid,avoid,936,https://qupath.github.io,https://github.com/qupath/qupath/issues/309#issuecomment-486778605,2,['avoid'],['avoid']
Safety,". What I think is happening is this:; * Whenever a ROI is effectively removed (either with the brush tool or subtraction), it results in a rectangle at location (0, 0) with zero width and zero height - this is nevertheless still drawn on screen; * When removing with the brush tool, a sanity check is applied to see if the resulting ROI has no area - and if so, the object is removed (e.g. [see here](https://github.com/qupath/qupath/blob/61a382e1e345e671b3fde32da08e03f08f4f7bcf/qupath-gui-fx/src/main/java/qupath/lib/gui/viewer/tools/AbstractPathDraggingROITool.java#L100)); * This sanity check isn't applied with the *Subtract selected annotations* command... so the 'empty' ROI does not result in the object being automatically removed; * Sometimes the sanity check can be triggered later... but it entirely clear when and why. I've flagged this as a bug, since something here is definitely not right and should be fixed. I do think that there is a broader issue with the usefulness of the commands for combining annotations; these can and should behave more predictably. It may not be helped by the fact that for a long time (before release) QuPath didn't support multiple objects being selected simultaneously, and much of the original code was written back in those days; as you can imagine, this was quite limiting. You're completely right about support for subtracting multiple annotations being tricky from a how-to-present-this-to-the-user point of view. I will give this some more thought. My preference would be to replace the existing commands to combine annotations with entirely new ones that have more clearly defined purposes and limitations. In the meantime, since you're already coding, it might be helpful to create your own script/extension to handle your specific needs. To do this, I'd suggest looking into [PathROIToolsAwt.java](https://github.com/qupath/qupath/blob/a3e9246640f9819701d57c513bb21a0546cff130/qupath-core-awt/src/main/java/qupath/lib/roi/PathROIToolsAwt.java) ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/78#issuecomment-302926092:1583,predict,predictably,1583,https://qupath.github.io,https://github.com/qupath/qupath/issues/78#issuecomment-302926092,1,['predict'],['predictably']
Safety,".com>; Cc: ""Montorsi, Lucia"" <lucia.montorsi@kcl.ac.uk>, Author <author@noreply.github.com>; Subject: Re: [qupath/qupath] Elongated nuclei not correctly detected (#231). For the nuclei, I would recommend starting a thread on the forum where you can post some pictures, that sounds like more of a image analysis problem. 20X might also be challenging with truly thin, elongated nuclei. Even more challenging if the Hamamatsu defaults to saving with JPEG compression (bad for analysis, great for file size). You can both classify regions and cellular populations, so you can subdivide your sample into ""tumor"" and ""stroma"" annotations first, and then perform positive cell detection within each of those (or however many classifications you want). Another option is using derived classes, so that you would first classify by tumor and stroma, then classify the cells as positive or negative within those classifications: https://github.com/qupath/qupath/wiki/Object-classifications<https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fwiki%2FObject-classifications&data=01%7C01%7Clucia.montorsi%40kcl.ac.uk%7Cc0fb04b4d26e44a6d0fa08d63529246a%7C8370cf1416f34c16b83c724071654356%7C0&sdata=UQryuEzaf5zSNRtDGv8hrkp%2FfCUaV5EV%2FABLyh8vxoY%3D&reserved=0>. Either way, you can then ignore the stromal positive cells in the data processing (merge populations) however you want, or create a step that re-classifies any Stroma-positive to Stroma-negative, etc. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fissues%2F231%23issuecomment-431117318&data=01%7C01%7Clucia.montorsi%40kcl.ac.uk%7Cc0fb04b4d26e44a6d0fa08d63529246a%7C8370cf1416f34c16b83c724071654356%7C0&sdata=f0CtUFa8ECpcchyI4Q7%2BY8PwuygiWZKq9wwPdVmoZKo%3D&reserved=0>, or mute the thread<https://emea01.safelinks.protection.outlook.com/?url=https",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/231#issuecomment-431292156:1502,safe,safelinks,1502,https://qupath.github.io,https://github.com/qupath/qupath/issues/231#issuecomment-431292156,1,['safe'],['safelinks']
Safety,".g. the *plugins* directory of a Fiji installation).; Then use *Send region to ImageJ* to send all or part of the image to ImageJ for processing, and call the *Trainable Weka segmentation* from there. > Note that QuPath won't actually use Fiji itself, but rather ImageJ1, so whenever you set the *plugins* directory to be that of a Fiji installation you may find that some commands don't work (if they have Fiji-specific dependencies). But I think *Trainable Weka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choose a tile diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's ofte",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/56#issuecomment-288506877:1491,detect,detection,1491,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877,1,['detect'],['detection']
Safety,".groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); 	... 2 common frames omitted. ---------------------------------------------------------; t6.groovy:; import qupath.lib.gui.ImageWriterTools; import qupath.lib.gui.QuPathGUI; import qupath.lib.gui.viewer.OverlayOptions; import qupath.lib.regions.RegionRequest; import qupath.lib.scripting.QPEx. // Aim for an output resolution of approx 20 µm/pixel; double requestedPixelSize = 20. // Create the output directory, if required; def path = ""./out/t6result"" //QPEx.buildFilePath(QPEx.PROJECT_BASE_DIR, ""export""); QPEx.mkdirs(path). // Get the imageData & server; def imageData = QPEx.getCurrentImageData(); def server = imageData.getServer(); setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; runPlugin('qupath.imagej.detect.tissue.SimpleTissueDetection2', '{""threshold"": 127, ""requestedDownsample"": 1.0, ""minAreaPixels"": 100000.0, ""maxHoleAreaPixels"": 500.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}');. // Get the file name from the current server; def name = server.getShortServerName(). // We need to get the display settings (colors, line thicknesses, opacity etc.) from the current viewer, if available; def overlayOptions = QuPathGUI.getInstance() == null ? new OverlayOptions() : QuPathGUI.getInstance().getViewer().getOverlayOptions(). // Calculate downsample factor depending on the requested pixel size; double downsample = 5 //requestedPixelSize / server.getAveragedPixelSizeMicrons(); def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()). // Write output image, with and without overlay; def dir = n",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/216#issuecomment-420486003:6402,detect,detect,6402,https://qupath.github.io,https://github.com/qupath/qupath/issues/216#issuecomment-420486003,1,['detect'],['detect']
Safety,.java:547); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by Physical memory usage is too high: physicalBytes (16451M) > maxPhysicalBytes (16384M) at org.bytedeco.javacpp.Pointer.deallocator(Pointer.java:712); at org.bytedeco.javacpp.Pointer.init(Pointer.java:126); at org.bytedeco.opencv.opencv_core.Mat.allocate(Native Method); at org.bytedeco.opencv.opencv_core.Mat.<init>(Mat.java:241); at qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predictWithLock(OpenCVClassifiers.java:468); at qupath.opencv.ml.OpenCVClassifiers$ANNClassifierCV.predictWithLock(OpenCVClassifiers.java:1425); at qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predict(OpenCVClassifiers.java:442); at qupath.opencv.ops.ImageOps$ML$StatModelOp.apply(ImageOps.java:2812); at qupath.opencv.ops.ImageOps$Core$SequentialMultiOp.apply(ImageOps.java:2294); at qupath.opencv.ops.ImageOps$ChannelImageDataOp.apply(ImageOps.java:424); at qupath.opencv.ml.pixel.OpenCVPixelClassifier.applyClassification(OpenCVPixelClassifier.java:104); at qupath.lib.classifiers.pixel.PixelClassificationImageServer.readTile(PixelClassificationImageServer.java:299); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:184); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:238); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:56); at qupath.lib.gui.viewer.overlays.PixelClassificationOverlay.lambda$requestTile$5(PixelClassificationOverlay.java:547); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); a,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856:2118,predict,predict,2118,https://qupath.github.io,https://github.com/qupath/qupath/issues/856,1,['predict'],['predict']
Safety,.lib.images.servers.CroppedImageServer.readRegion(CroppedImageServer.java:39); at qupath.lib.images.servers.SparseImageServer.readTile(SparseImageServer.java:265); at qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:863); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:902); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:216); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by null at java.base/java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(Unknown Source); at java.base/java.util.concurrent.locks.ReentrantLock.lockInterruptibly(Unknown Source); at java.base/java.util.concurrent.ArrayBlockingQueue.put(Unknown Source); at qupath.lib.images.servers.bioformats.BioFormatsImageServer$ReaderPool.openImage(BioFormatsImageServer.java:1411); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(BioFormat,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583:2051,Detect,DetectionPluginTools,2051,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583,1,['Detect'],['DetectionPluginTools']
Safety,".plugin.JpegWriter;; import javafx.scene.SnapshotResult;; import qupath.lib.gui.ImageWriterTools;; import qupath.lib.gui.QuPathGUI;; import qupath.lib.gui.commands.SaveViewCommand;; import qupath.lib.gui.prefs.PathPrefs;; import qupath.lib.images.ImageData;; import qupath.lib.images.servers.ImageServer;; import qupath.lib.images.servers.ImageServerProvider;; import qupath.lib.io.ImageWriter;; import qupath.lib.regions.RegionRequest;; import qupath.lib.roi.interfaces.ROI;; import qupath.lib.scripting.QP;; import qupath.lib.scripting.QPEx;. public class test01 {; 	private static QuPathGUI qupath;; 	private static boolean wholeWindow;; 	; 	public void mydetection() throws InterruptedException {; 		// TODO Auto-generated method stub; 		String imagePath=""D:\\Overview\\9624CE91-1DA8-40AE-89AC-41412BE756DB.jpg"";; 		ImageServer<BufferedImage> server = ImageServerProvider.buildServer(imagePath, BufferedImage.class);; 		ImageData imageData = new ImageData<>(server);; 		String bind = ""{\""threshold\"": 162, \""requestedDownsample\"": 1.0, \""minAreaPixels\"": 100000.0, \""maxHoleAreaPixels\"": 500.0, \""darkBackground\"": false, \""smoothImage\"": true, \""medianCleanup\"": true, \""dilateBoundaries\"": false, \r\n"" + ; 				"" \""smoothCoordinates\"": true, \""excludeOnBoundary\"": false, \""singleAnnotation\"": true}');"";; 		boolean detection = false;; 		try {; 			detection = QP.runPlugin(""qupath.imagej.detect.tissue.SimpleTissueDetection2"",bind);; 		} catch (Exception e) {; 			// TODO Auto-generated catch block; 			e.printStackTrace();; 		}; 		int x = 0,y = 0;; 		int width=server.getWidth(),height = server.getHeight();; 		RegionRequest request = RegionRequest.createInstance(imageData.getServerPath(),1, x, y, width, height);; 		System.out.println(imageData.getServerPath());; 		ImageWriterTools.writeImageRegion(server, request,""d:/out-detection01.png"");; 	}; 	; 	; 	public static void main(String[] args) throws InterruptedException, IOException {; 		test01 t = new test01();; 		t.mydetection();; 	}. }",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/216#issuecomment-420269884:1853,detect,detection,1853,https://qupath.github.io,https://github.com/qupath/qupath/issues/216#issuecomment-420269884,3,['detect'],"['detect', 'detection']"
Safety,"// Check if we requesting a region that is too small; if (hi / downsample < minImageDimension) {; println(""Image dimension < "" + minImageDimension + "" - skipping row""); continue; }. for (double x = 0; x < server.getWidth(); x += tileWidth) {. // Compute integer x coordinates; int xi = (int)(x + 0.5); int x2i = (int)Math.min((int)(x + tileWidth + 0.5), server.getWidth());; int wi = x2i - xi. // Create request; RegionRequest request = RegionRequest.createInstance(path, downsample, xi, yi, wi, hi, z, 0). // Check if we requesting a region that is too small; if (wi / downsample < minImageDimension) {; // Only print warning if we've not skipped this before; if (y > 0); println(""Image dimension < "" + minImageDimension + "" - skipping column""); continue; }. // Surround with try/catch in case the server gives us trouble; try {; // Put at top of file for neater code...; ext = "".jpg""; imageData = getCurrentImageData(); overlayOptions = getCurrentViewer().getOverlayOptions(); ; // Write out the region with overlay; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); File file = new File(dirOutput, name); ImageWriterTools.writeImageRegionWithOverlay(imageData, overlayOptions, request, file.getAbsolutePath()). // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); }; catch (Exception e) {; // Check if we have had a sufficient number of errors to just give up; nErrors++;; if (nErrors > maxErrors) {; println(""Maximum number of errors exceeded - aborting...""); return; }; e.printStackTrace(); }; }; }; }; ```; The original version contained quite a bit of ImageJ-related stuff but on closer inspection I'm not sure why since it actually writes JPEGs instead of ImageJ TIFFs. If the above script doesn't work, I think it would be best to start a new discussion at https://forum.image.sc/tags/qupath describing what it should do and perhaps there is an easier way to get there.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/309#issuecomment-486778605:3872,abort,aborting,3872,https://qupath.github.io,https://github.com/qupath/qupath/issues/309#issuecomment-486778605,1,['abort'],['aborting']
Safety,"0.2.0-m8-Windows\QuPath-0.2.0-m8\app;C:\Users\ag5-35\Downloads\QuPath-0.2.0-m8-Windows\QuPath-0.2.0-m8 -Djava.launcher.path=C:\Users\ag5-35\Downloads\QuPath-0.2.0-m8-Windows\QuPath-0.2.0-m8 -Xmx8192M -XX:MaxRAMPercentage=50 qupath.QuPath. Host: Intel(R) Core(TM) i5-9400 CPU @ 2.90GHz, 6 cores, 15G, Windows 10 , 64 bit Build 18362 (10.0.18362.329); Time: Tue Jan 28 18:35:40 2020 W. Europe Standard Time elapsed time: 148 seconds (0d 0h 2m 28s). --------------- T H R E A D ---------------. Current thread (0x000001d550e5e800): JavaThread ""classifier-overlay6"" daemon [_thread_in_native, id=7376, stack(0x0000002279b00000,0x0000002279c00000)]. Stack: [0x0000002279b00000,0x0000002279c00000], sp=0x0000002279bf9e20, free space=999k; Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code); C 0x0000000000cb5b26. Java frames: (J=compiled Java code, j=interpreted, Vv=VM code); j org.bytedeco.opencv.opencv_ml.LogisticRegression.predict(Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;I)F+0; j qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predictWithLock(Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;)V+11; j qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predict(Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;)V+14; j qupath.opencv.ml.OpenCVClassifiers$LogisticRegressionClassifier.predict(Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;)V+4; j qupath.opencv.ml.pixel.OpenCVPixelClassifier.applyClassification(Lqupath/lib/images/ImageData;Lqupath/lib/regions/RegionRequest;)Ljava/awt/image/BufferedImage;+235; j qupath.lib.classifiers.pixel.PixelClassificationImageServer.readTile(Lqupath/lib/images/servers/TileRequest;)Ljava/awt/image/BufferedImage;+84; J 14172 c1 qupath.lib.images.servers.AbstractTileableImageServer.get",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/394:2623,predict,predict,2623,https://qupath.github.io,https://github.com/qupath/qupath/issues/394,1,['predict'],['predict']
Safety,"1. There seems to no longer be an 'extensions directory' in the `Preferences` menu; 2. When drag and dropping an extension, you are prompted whether to use the default location or to choose one. If you choose one, it does not work. Is this a conscious choice? For us in the facility, it is useful for the extensions to be shared among users, this avoids us from having to install them for everyone when as they use their own logins on our processing PCs.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/298:347,avoid,avoids,347,https://qupath.github.io,https://github.com/qupath/qupath/issues/298,1,['avoid'],['avoids']
Safety,"1. https://groups.google.com/forum/#!searchin/qupath-users/small$20annotations%7Csort:date/qupath-users/TL6KCc6aB_E/UG3ESt5HBgAJ; 2. If your annotation is being generated by simple tissue detection, it might be easier to increase the minimum hole size value (Max fill area). Otherwise, I think the only way to do that would be to split the annotation into it's component parts, and then somehow reform it using only the components over a certain area measurement.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/219#issuecomment-420473760:188,detect,detection,188,https://qupath.github.io,https://github.com/qupath/qupath/issues/219#issuecomment-420473760,1,['detect'],['detection']
Safety,5 bytes) @ 0x00000295ed1d409c [0x00000295ed1d3fa0+0x00000000000000fc]; J 15713 c1 qupath.opencv.ops.ImageOps$Core$SequentialMultiOp.apply(Lorg/bytedeco/opencv/opencv_core/Mat;)Lorg/bytedeco/opencv/opencv_core/Mat; (42 bytes) @ 0x00000295ed5c8654 [0x00000295ed5c8300+0x0000000000000354]; J 15744 c1 qupath.opencv.ops.ImageOps$DefaultImageDataOp.apply(Lqupath/lib/images/ImageData;Lqupath/lib/regions/RegionRequest;)Lorg/bytedeco/opencv/opencv_core/Mat; (74 bytes) @ 0x00000295ed0532ac [0x00000295ed052e20+0x000000000000048c]; J 14791 c2 qupath.tensorflow.stardist.StarDist2D.detectObjectsForTile(Lqupath/opencv/ops/ImageDataOp;Lqupath/lib/images/ImageData;Lqupath/lib/regions/RegionRequest;ZLorg/locationtech/jts/geom/Geometry;)Ljava/util/List; (146 bytes) @ 0x00000295f4f057b8 [0x00000295f4f05760+0x0000000000000058]; J 15706 c1 qupath.tensorflow.stardist.StarDist2D.lambda$detectObjects$1(Lqupath/lib/images/ImageData;Ljava/util/Collection;Lorg/locationtech/jts/geom/Geometry;Lqupath/lib/images/servers/TileRequest;)Ljava/util/stream/Stream; (36 bytes) @ 0x00000295ed75f334 [0x00000295ed75f160+0x00000000000001d4]; J 15743 c1 qupath.tensorflow.stardist.StarDist2D$$Lambda$2526.apply(Ljava/lang/Object;)Ljava/lang/Object; (24 bytes) @ 0x00000295ee0909ac [0x00000295ee090840+0x000000000000016c]; J 15156 c1 java.util.stream.ReferencePipeline$7$1.accept(Ljava/lang/Object;)V java.base@14.0.1 (127 bytes) @ 0x00000295edec35a4 [0x00000295edec34a0+0x0000000000000104]; J 15667 c2 java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Ljava/util/function/Consumer;)V java.base@14.0.1 (127 bytes) @ 0x00000295f51c2d44 [0x00000295f51c2c00+0x0000000000000144]; J 11772 c2 java.util.stream.AbstractPipeline.wrapAndCopyInto(Ljava/util/stream/Sink;Ljava/util/Spliterator;)Ljava/util/stream/Sink; java.base@14.0.1 (18 bytes) @ 0x00000295f4ba1aa8 [0x00000295f4ba19a0+0x0000000000000108]; j java.util.stream.ReduceOps$ReduceTask.doLeaf()Ljava/util/stream/ReduceOps$AccumulatingSink;+15 java.base@14.0.1; j java.u,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/481:4498,detect,detectObjects,4498,https://qupath.github.io,https://github.com/qupath/qupath/issues/481,1,['detect'],['detectObjects']
Safety,": 200.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:2663,detect,detected,2663,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"://github.com/qupath/qupath/blob/master/CHANGELOG.md) to see if the bug has already been fixed in the next release; * [x ] I've checked for existing GitHub issues describing the same problem. ## Bug report. **Describe the bug**; A clear and concise description of what the bug is.; After running clearDetections() TMA grid object isEditable property remains false (i.e. TMA grid circles cannot be rearranged etc). **To Reproduce**; Steps to reproduce the behavior:. setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049"", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759"", ""Background"" : "" 255 255 255""}');. //De-array TMA; runPlugin('qupath.imagej.detect.dearray.TMADearrayerPluginIJ', '{""coreDiameterMM"": 1.2, ""labelsHorizontal"": ""1-16"", ""labelsVertical"": ""A-J"", ""labelOrder"": ""Row first"", ""densityThreshold"": 5, ""boundsScale"": 105}');; selectTMACores();. //Detect cells using some method such as DAB; runPlugin('qupath.imagej.detect.cells.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.0, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": false, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Cell: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');. clearDetections();; fireHierarchyUpdate();; getTMACoreList().each{; println(it.isEditable());; };. INFO: false; INFO: false; INFO: false. **Expected behavior**; As the definition of isEditable() is ""TMA core cannot be edited if it contains any detections,"" I would expect TMA to be editable if you clear detections. Or there could be a setEditable() method to ",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1021:1627,Detect,Detect,1627,https://qupath.github.io,https://github.com/qupath/qupath/issues/1021,1,['Detect'],['Detect']
Safety,":35:40 2020 W. Europe Standard Time elapsed time: 148 seconds (0d 0h 2m 28s). --------------- T H R E A D ---------------. Current thread (0x000001d550e5e800): JavaThread ""classifier-overlay6"" daemon [_thread_in_native, id=7376, stack(0x0000002279b00000,0x0000002279c00000)]. Stack: [0x0000002279b00000,0x0000002279c00000], sp=0x0000002279bf9e20, free space=999k; Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code); C 0x0000000000cb5b26. Java frames: (J=compiled Java code, j=interpreted, Vv=VM code); j org.bytedeco.opencv.opencv_ml.LogisticRegression.predict(Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;I)F+0; j qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predictWithLock(Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;)V+11; j qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predict(Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;)V+14; j qupath.opencv.ml.OpenCVClassifiers$LogisticRegressionClassifier.predict(Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;)V+4; j qupath.opencv.ml.pixel.OpenCVPixelClassifier.applyClassification(Lqupath/lib/images/ImageData;Lqupath/lib/regions/RegionRequest;)Ljava/awt/image/BufferedImage;+235; j qupath.lib.classifiers.pixel.PixelClassificationImageServer.readTile(Lqupath/lib/images/servers/TileRequest;)Ljava/awt/image/BufferedImage;+84; J 14172 c1 qupath.lib.images.servers.AbstractTileableImageServer.getTile(Lqupath/lib/images/servers/TileRequest;)Ljava/awt/image/BufferedImage; (133 bytes) @ 0x000001d52232b9dc [0x000001d52232b3e0+0x00000000000005fc]; J 14898 c1 qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(Lqupath/lib/regions/RegionRequest;)Ljava/awt/image/BufferedImage; (1110 bytes) @ 0x000001d522ceb264 [0x000001d522ce2920+0x000000000000894",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/394:2974,predict,predict,2974,https://qupath.github.io,https://github.com/qupath/qupath/issues/394,1,['predict'],['predict']
Safety,"> (as only one is selected after duplication). That's strange, when I try with two annotations selected, I see that both the duplicated annotations are selected (and I can run cell detection immediately on both of them). Although either way i'm glad it works :). Will think some more about a flatten hierarchy command for the future.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1411#issuecomment-1790289826:181,detect,detection,181,https://qupath.github.io,https://github.com/qupath/qupath/issues/1411#issuecomment-1790289826,1,['detect'],['detection']
Safety,"> (since you're using annotations to train the classifier, how should QuPath distinguish between which annotations are for training and which should be classified...?). I'm not actually, sadly I don't get the chance to work in QuPath much as I mostly work with 3D images. This came about because of this post: https://forum.image.sc/t/using-annotations-imported-into-qupath/95333. It seems the user imported ROIs as annotations instead of detections. Ultimately probably more of a user error based on the current design of the system, but I just do feel it is confusing that everything is given the generic label of ""object"" (both the submenu and the filter) when it only works on detections. Perhaps another submenu within the Object classification menu specifically for Detection classification commands? I know that currently that would mean a single submenu item in the Object classification menu, but it would add clarity to the current state of things, and I would imagine that at least some of these commands will be restricted to detections only well into the future.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1501#issuecomment-2079438553:439,detect,detections,439,https://qupath.github.io,https://github.com/qupath/qupath/issues/1501#issuecomment-2079438553,4,"['Detect', 'detect']","['Detection', 'detections']"
Safety,"> @oharismendy it sounds like in v0.2 the image is being opened with Bio-Formats. In v0.1.2 OpenSlide would have been used by default (unless you installed the Bio-Formats extension), and this flags specific images as label for a few formats (including .svs).; > ; > You can choose the image reader when importing an image to a project: https://qupath.readthedocs.io/en/latest/docs/tutorials/projects.html#add-images; > ; > Because QuPath relies upon open source image readers that support a wide range of formats, it's difficult/impossible to _know_ in all cases whether an image stored within a file as intended a 'full' image for analysis, label or macro image... particularly since different vendors write images in different ways, and we don't have specifications for the formats. It may be necessary for us to remove the label pop-up in the future, since it will inevitably fail to find a label sometimes sometimes.; > ; > Misassigning a full image as a label is a big problem, since QuPath doesn't support any analysis on labels - therefore we need to err on the side of caution.; > ; > If you can share an example image along with details of how it was written (e.g. software/scanner) then we might be able to add some logic to handle this specific case but otherwise we can only guess what a fix might be. Thanks. It makes perfect sense. I think dropping the pop-up and clarifying this label image is available under master is likely a safer way to go. Unless my issue is very rare.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/643#issuecomment-732318132:1445,safe,safer,1445,https://qupath.github.io,https://github.com/qupath/qupath/issues/643#issuecomment-732318132,1,['safe'],['safer']
Safety,"> Actually, tags are one key-word annotation. Ah... makes sense. > My suggestion is to add a one-keyword metadata field. Sounds sensible, but I wonder is it possible that people will then want tags with different interpretations?. The alternative I'm thinking is to simply have a dictionary entry ; ```json; {; ""omeroTags"": ""tag1, tag2, tag3""; }; ```; but I don't know whether it's safe to use a comma (or anything else) as a delimiter. Otherwise, I guess there could be a general `tags` list in a QuPath project entry. Do you think either option is strongly preferable to the other?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1289#issuecomment-1687567852:382,safe,safe,382,https://qupath.github.io,https://github.com/qupath/qupath/issues/1289#issuecomment-1687567852,1,['safe'],['safe']
Safety,"> And as in @biovoxxel's video (thanks for the resource!), our users sometimes struggle with the ""DPI/PPI"" calculations. If this was a set parameter in preferences (e.g. 300PPI by default), then you could write next to downsample what would be the maximum figure size for that PPI (e.g. downsample 2, 300PPI -> up to 1200cm x 800cm figure).; > ; > The user would then be able to choose an appropriate downsample for their figure that's say, up to 20cm wide at the requested PPI. Side note:; I would fully avoid scaling and adapting to DPI, since this is not very helpful regarding the figure quality. Once you have the SVG you can adapt it to the document size without the need of changing any resolution etc. Boils down to: Less need for thinking and calculating with a better result image!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1272#issuecomment-1604299185:505,avoid,avoid,505,https://qupath.github.io,https://github.com/qupath/qupath/issues/1272#issuecomment-1604299185,1,['avoid'],['avoid']
Safety,"> Converting to composite works. Is it an option to let QuPath do this automatically when the image type is set to Fluorescence? . I'm afraid not, QuPath doesn't really allow you to modify the image in any way, so changes like this are difficult. Batch conversion in ImageJ is the easiest 'fix' I can think of. The code used to make measurements with StarDist is a lot more generic than the code for the built-in cell detection... but I overlooked the RGB problem since I didn't have any images quite like that. Good to know about it now so we can fix it before the next release. > Thanks for the great program. We like QuPath a lot!. I'm glad! If you haven't already, it would be great if you could fill in the [user survey](https://edinburgh.onlinesurveys.ac.uk/qupath-user-survey-2021) - and please share it with anyone else you know uses the software!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/686#issuecomment-804259530:418,detect,detection,418,https://qupath.github.io,https://github.com/qupath/qupath/issues/686#issuecomment-804259530,1,['detect'],['detection']
Safety,"> Great! How?. * I opened `CMU-1.tiff` in a project.; * I defined an annotation covering almost the entire image.; * I defined another annotation also almost covering the entire image.; * I made the 2nd annotation a child of the first.; * I ran `Cell Detection` inside the 2nd annotation with default parameters. I got 99465 detections.; * I saved the image. The exception occurs each time I run `Delaunay cluster features 2D` with `Add cluster measurements` checked. It's a bit weird because I did the same thing yesterday but I didn't have the exception. > Looks good, is there a way to check if it has any significant performance impact?. It has, because running `Delaunay cluster features 2D` takes around 2.67s without the PR and around 3.71s with the PR (for 99465 detections).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1444#issuecomment-1943644892:251,Detect,Detection,251,https://qupath.github.io,https://github.com/qupath/qupath/issues/1444#issuecomment-1943644892,3,"['Detect', 'detect']","['Detection', 'detections']"
Safety,"> I agree, this feels a bit aggressive to me. If the existing copy may not be atomic, I'd rather try to implement an atomic version than to switch to a ""definitely not atomic"" version. I am afraid that copy operations were never guaranteed to be atomic in mainstream OSes. But I agree that this should be something where chance has no room to play. > This sounds good to me, it's important for obvious reasons that user data operations are done as safely as possible. Alright then, I'll work on it.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1449#issuecomment-1908286981:448,safe,safely,448,https://qupath.github.io,https://github.com/qupath/qupath/pull/1449#issuecomment-1908286981,1,['safe'],['safely']
Safety,"> I can't replicate the bug on my Mac - if I drag a URL from chrome, the dragboard contains both a URL and a String - but good if it solves the problem somewhere. Yeah I suspect it's a Linux issue, either way I think trying to handle Strings as URLs is about the best we can do, as long as it shows the right kind of error. > *-I've consistently avoided [starred imports] & convinced my IntelliJ to stop doing it automatically - can discuss later if we want to change that policy. I don't pay any heed to imports; they're automatically hidden for me. The only strong argument I've been exposed to on the topic was that having a) a license and b) every imported class/static method right at the top of the file means that every file you open, you need to page down a couple of times before reading any code. If there was a risk of ambiguity I might be more concerned, but I think when there's a collision Java forces you to use a fully qualified name?. Anyways I think the license and imports are auto-hidden for me, so this doesn't really matter",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1338#issuecomment-1731105750:346,avoid,avoided,346,https://qupath.github.io,https://github.com/qupath/qupath/pull/1338#issuecomment-1731105750,2,"['avoid', 'risk']","['avoided', 'risk']"
Safety,> I changed it in pom.xml and opencv-stitching-jlink did work with 4.3.0-1.5.3. The stitching worked too. (I deleted the previous result first.). > Building this succeeded as well: https://github.com/bytedeco/gradle-javacpp/tree/master/samples/javacv-demo. `java -jar build/libs/javacv-demo-1.5.3.jar` does seem to do face detection correctly (only had to change 0 to 1 in `FrameGrabber.createDefault(0)` because the IR cam is the default one). > Building should work with QuPath... if it stops before running/testing. I just have no idea how to configure it correctly in `build.gradle`. (edit: typo),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/484#issuecomment-633518010:323,detect,detection,323,https://qupath.github.io,https://github.com/qupath/qupath/issues/484#issuecomment-633518010,1,['detect'],['detection']
Safety,"> I still feel uneasy about explicitly deleting before attempting any copy or move.... since 'may not be atomic' still gives me some hope that we won't end up in some unfortunate state. Corrupt data files was previously a somewhat common complaint, which has reduced a lot over recent releases. I agree, this feels a bit aggressive to me. If the existing copy may not be atomic, I'd rather try to implement an atomic version than to switch to a ""definitely not atomic"" version. > If atomicity of the operation is what worries you, i could implement a method that does it safely, very similarly to what you do with .qpproj files. This sounds good to me, it's important for obvious reasons that user data operations are done as safely as possible.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1449#issuecomment-1908172126:571,safe,safely,571,https://qupath.github.io,https://github.com/qupath/qupath/pull/1449#issuecomment-1908172126,2,['safe'],['safely']
Safety,"> I suppose there could be an even worse option where you also encode getASelectedObject() which returns the first, or largest, or some other logic. Hmmm, might need to think about it some more but I think that risks increasing rather than reducing complexity. I'd rather have fewer options with more predictable behavior - in rare cases where something more complex is needed, it's always possible to query all the selected objects and then filter them however you like. But I don't think that should be part of the core API. > I was also just thinking about this - what situations lead to there being no primary object, and could those be addressed instead?. `selectAnnotations()` is a good example. Basically, anything that can select multiple objects without a clear 'main' object. So if you would run another command like `selectObjects(p -> p.getPathClass() == getPathClass('Tumor'))` you'd see the same: possibly multiple objects selected, but no 'main' selection. Or, with my pull request, a 'main' selection plucked more or less randomly - *unless* only one object is available, in which case it's just what you'd expect. > Alternatively, specially code getSelectedObject() to allow for an array, check for an array size of 1, and handle that situation specifically if it arises. Still return null in other situations, along with an informative error message (or warning). Internally there is already a set of selected objects - distinct from the main selected object. However, if there is a main selected object then it should always be included in the set. I think errors/warnings need to be used very sparingly to avoid causing undue alarm. But I'm coming around to the compromise I mentioned above, which I think falls somewhere between my pull request and your original suggestion.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/758#issuecomment-869227006:211,risk,risks,211,https://qupath.github.io,https://github.com/qupath/qupath/issues/758#issuecomment-869227006,3,"['avoid', 'predict', 'risk']","['avoid', 'predictable', 'risks']"
Safety,"> I would safely estimate 200+ .qpdata files, and all .qpdata files are saved right below their respective .tifs in their respective folders. Hmmm, but that is not all the same folder...?. I ask because this could probably be resolved in a script, or with a change to QuPath to search for missing files in the same directory as the .qpdata file. Because you say it's urgent, the second option may not work for you. The first option requires knowing exactly how the files are arranged... and also the file format (if you are using Bio-Formats to read them rather than OpenSlide, the process may need to be slightly different). The operating system would also help (Windows/Linux/macOS). But @Svidro 's approach would be the most straightforward and fastest if it works for you.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/266#issuecomment-461126113:10,safe,safely,10,https://qupath.github.io,https://github.com/qupath/qupath/issues/266#issuecomment-461126113,1,['safe'],['safely']
Safety,"> It is a slightly scary change to make since it is so core. Yes, i get it. It's better being cautious here!. > When ImageServer metadata is written in a project and when it isn't (I see it missing sometimes, which has previously been irrelevant since it's generated when the ImageServer is built... but becomes much more important if the server isn't necessarily built). what I would say that in that case it would load the server, read the metadata and write them in the `.qpproj` file for future accesses. I wouldn't assure that `ImageData.getServerMetadata()` never loads the image server. It avoids it as long as it is possible, otherwise it will. > What happens when a script changes the metadata, but the server itself hasn't been read (e.g. setting channel names or pixel size). Again, if `ImageData.updateServerMetadata()` i would actually load the server()+update `qpproj` file. Avoid doing it lazily, as that would easily lead to unexpected states for the users. > How exceptions are handled when lazy loading fails. What's wrong in behaving the same as when an exception occurs while creating an `ImageServer`?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1489#issuecomment-2271091629:597,avoid,avoids,597,https://qupath.github.io,https://github.com/qupath/qupath/pull/1489#issuecomment-2271091629,2,"['Avoid', 'avoid']","['Avoid', 'avoids']"
Safety,> It looks like the exception is coming from the attempt to load the classifications (the ones that appear under the 'Annotations' tab). These are stored in the project under _classifiers/classes.json_.; > ; > Something has gone wrong with that file; you can try simply deleting it (if it exists) or replacing the corresponding file from another project. Deleting the classes.jon file worked! Is there something that I did wrong to create the issue that I can avoid in the future?,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/613#issuecomment-708523858:460,avoid,avoid,460,https://qupath.github.io,https://github.com/qupath/qupath/issues/613#issuecomment-708523858,1,['avoid'],['avoid']
Safety,"> It would be interesting to compare it with applyColorTransforms() where you pass all the ColorTransform objects and avoid concatChannels(). Using `concatChannels`, the JSON entry makes 430 lines, while with only `applyColorTransforms` the JSON entry makes 195 lines. I'll update the Image.sc script with only `applyColorTransforms`. > I suggest providing both TransformedServerBuilder.applyColorTransforms(ColorTransform... transforms) and TransformedServerBuilder.applyColorTransforms(Collection<? extends ColorTransform> transforms) for convenience. Added in last commit. > What is the name given to any new channel generated in this way?. * If the channel names are provided with the coefficients, it's the linear combination with the channel names, for example `""-0.25*PDL1 + -0.15*FoxP3 + 1.0*CD8""`; * If only the coefficients are provided, it's the linear combination with `""channel"" + channelIndex` as channel names, for example `""-0.25*channel1 + -0.15*channel3 + 1.0*channel4""`",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1566#issuecomment-2260446815:118,avoid,avoid,118,https://qupath.github.io,https://github.com/qupath/qupath/pull/1566#issuecomment-2260446815,1,['avoid'],['avoid']
Safety,"> Okay, I think I describe what I want to do. And I would like to do that as automatically as possible, so in qupath in a .groovy script, I guess:; > ; > I have a folder with IHC-fluorescence images (DAPI + antibody staining) of tumors with stroma; > In Qupath:; > For every image of the folder:; > 2) In QuPath - perform cell detection; > 3) In Qupath - object classification with a pretrained classifier (tumor vs. stroma); > 4) Export detections with annotation into .roi file. Ok, you don't describe your images being whole slide images - so I assume they can be read into ImageJ fully and without problems. In that case, you might try this QuPath script:; https://gist.github.com/petebankhead/8d541effc8898d6a07edd4ed95b6929c. Keep in mind that a `.roi` file contains a single region; as far as I'm aware, a `.zip` file is needed for all the QuPath objects to be represented in a way ImageJ can access all in one go. > So, I want to use quPath for what it does very, very good and fast, cell identification, segmentation and classification, and not for anything else. Scripting in FIJI is more or less easy for me, so once I have the .roi files, I can do almost anything with them there. Just, for the ""QuPath part"", I dont even know how to script those simple steps, because there is not much documentation, no Qupath API, so its hard for me to even get started. I am not a professional programmer, but a biologist with some (Python, Java, ImageJ) programming background,. Ok, but please keep in mind that ImageJ has existed in some form for more than 30 years, and has had input from many fantastically knowledgeable people both in terms of development and documentation. There has been a huge amount of volunteer effort, alongside many components and plugins developed as part of larger, funded projects. On the other hand, QuPath was created and documented essentially by one person and has only been available for a couple of years. The same person also wrote all the wiki, the [blog](https:",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/182#issuecomment-401546472:327,detect,detection,327,https://qupath.github.io,https://github.com/qupath/qupath/issues/182#issuecomment-401546472,2,['detect'],"['detection', 'detections']"
Safety,"> One idea would be to write an ome.tiff of the sparse image inside the QuPath project on the first instance that the sparse image is loaded, and each subsequent time it's opened, it'll read that image. It's tempting, but OME-TIFF can take a long time to write, and that requires some decisions to be made regarding compression (which could impact pixel classifiers). Therefore I think writing any image needs to be explicitly triggered by the user to avoid unwelcome surprises. > Tangentially related, but many scripts will break when running it on a sparse image with an empty region:. I tried but couldn't replicate this. Given the intention to revisit sparse images generally, I wouldn't plan to spend time fixing it unless it is shown to be problematic in a normal workflow, with a reproducible failing example (which would really belong in a separate issue).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1407#issuecomment-1826754801:452,avoid,avoid,452,https://qupath.github.io,https://github.com/qupath/qupath/issues/1407#issuecomment-1826754801,1,['avoid'],['avoid']
Safety,"> One option for Show/Hide would be to have the right click menu be context sensitive:; > ; > * If one or multiple classifications are selected and visible, the context menu becomes ""Hide selected classes"" (Instead of show/Hide > Hide classes in viewer); > * If one or multiple classifications are selected and hidden, the context menu becomes ""Show selected classes"" (Instead of show/Hide > Show classes in viewer). What about if multiple classifications are selected, some shown and some hidden?. I'm apprehensive about trying to make the code too clever, and confusing people more by the menu changing when they click it. If the core issue is that the common things are too hard to access, would simply moving `Show/hide` higher up the menu be a solution?. My hesitation with that is that currently the top part of the menu (above the divider) is all concerned with adding/removing classifications. So `Show/Hide` would have to go to the *very* top, to avoid interrupting this logical grouping... and, as you say, spacebar does that job, so `Add/Remove` might be needed more often.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1644#issuecomment-2358972679:956,avoid,avoid,956,https://qupath.github.io,https://github.com/qupath/qupath/issues/1644#issuecomment-2358972679,1,['avoid'],['avoid']
Safety,"> Since the recycling is really important, should you do it in a finally block?. I need to check this! An the cleaner thing as well, but for now, Fiji = Java 8, so yeah, let's see if I can avoid it. ; I'm limiting the number of reader as well, it's a property of my dataset, and it's true that limiting the number of parallel reader to around 10 usually gives the best result (usually lower than the number of cores). > One minor difference is that my version restricts creating new readers to a single background thread, since I found that sometimes (although rarely) constructing many reader simultaneously had really bad performance, as all the constructors got stuck parsing XML. Right! In bdv, a first reader is created to parse metadata and build the memo file, I guess it's similar in QuPath. Then extra readers are creating for tile reading, once the memo file is already created. . There may be some optimisation possible for these 'extra readers', since metadata is not required anymore: https://forum.image.sc/t/open-czi-in-bio-formats-large-ram-requirements/45592/5, but I did not test it.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/867#issuecomment-1002527257:189,avoid,avoid,189,https://qupath.github.io,https://github.com/qupath/qupath/pull/867#issuecomment-1002527257,1,['avoid'],['avoid']
Safety,"> This is extremely strange. @balgillo said this isn't happening for him with Rosetta... Hi, not sure what you're referring to here. In our case, we saw JavaCPP v1.5.6 detecting excessively-high physicalBytes under Rosetta, we put in place the workaround:; ```; -Dorg.bytedeco.javacpp.maxPhysicalBytes=0; ```; ... and it's still in place, we haven't tried anything else since.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856#issuecomment-1022952240:168,detect,detecting,168,https://qupath.github.io,https://github.com/qupath/qupath/issues/856#issuecomment-1022952240,1,['detect'],['detecting']
Safety,"> To avoid the 'update URIs' dialog in am multi-user setting, each user can duplicate the project.qpproj file and use the duplicate as their own view on it, i.e. they open and update the project file to contain the absolute paths relevant to them. To facilitate this, when dragging a project directory on top of QuPath one can choose the precise file to open from a drop-down list. There is also a Recent Projects option to reopen the last project. Thanks for the suggestion, we will be doing that then. I apologize for the use of GitHub issues. I really thought that for some reason it was not taking the relative paths in windows and not that the feature had been removed.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/468#issuecomment-623989433:5,avoid,avoid,5,https://qupath.github.io,https://github.com/qupath/qupath/issues/468#issuecomment-623989433,1,['avoid'],['avoid']
Safety,"> When I build QuPath with ./gradlew jpackage I'm only getting the non-core QuPath jars (qupath-bioimageio-spec and qupath-fxtras). Does it also happen with `./gradlew clean jpackage`? Since it's a `Copy` task it's safer to `clean` before. > I also don't see any javadocs if I call ./gradlew run; it would be nice if they could be available, but it isn't crucial since the normal use will be via jpackage builds. Added with last commit. > Lastly, when I open the Javadoc viewer, I see this:. There is an automatic redirection that is not triggered on the old Javadoc viewer. It seems to work on the new Javadoc viewer, can you check if it also works on your side?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1513#issuecomment-2095709470:215,safe,safer,215,https://qupath.github.io,https://github.com/qupath/qupath/pull/1513#issuecomment-2095709470,1,['safe'],['safer']
Safety,"> When importing images to a QuPath project, there is a space to input arguments. Inserting --no-crop there will avoid using the OpenSlide bounds. Thanks, very helpful. > Potentially all objects would need to store that info, or else they would need to be export as a FeatureCollection with an additional custom property. The second sounds preferably but would remain very QuPath-specific. Already `properties` values are very QuPath specific (`isEllipse`...), so I don't see much of a problem here. > As it currently stands, I think QuPath is more internally consistent by cropping - and this reduces rather than increases the dependency on OpenSlide, by making its use interchangeable with Bio-Formats. If there are cases where QuPath crops* and Bio-Formats or other popular libraries don't, then we might need to look at it again, but I don't know of any. I did not know about the Bio-Formats approach. Since DICOM is slowly opening up to the open-source WSI world, I think the problem will arise sooner or later. For now, for performance reasons, we go with TIFF files that do not have this metadata stored, and all software (including quPath) fails to read cropped data, thus having inconsistencies everywhere. Thanks for the insight.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1278#issuecomment-1630799401:113,avoid,avoid,113,https://qupath.github.io,https://github.com/qupath/qupath/issues/1278#issuecomment-1630799401,1,['avoid'],['avoid']
Safety,"> Which is nice, since it prevents subcellular detections from being counted! That could get crazy. Yes, I have some distant memory that that was the reason... and also detections inside other detections need (progressively) thinner lines, giving a visual clue.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/259#issuecomment-457856110:47,detect,detections,47,https://qupath.github.io,https://github.com/qupath/qupath/issues/259#issuecomment-457856110,3,['detect'],['detections']
Safety,"> Would it be possible to avoid duplicating the shortcuts in the properties files, and instead extract them directly from the Action accelerator property?. Yes, it's now the case. > A complication I see is that making the tooltip text auto-update if the accelerator or action 'long description' is changed - but this is not an essential feature (since it should be rare). Right now I have the impression that the tooltip text will auto-update if the language changes. Is that enough?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1463#issuecomment-1941752636:26,avoid,avoid,26,https://qupath.github.io,https://github.com/qupath/qupath/pull/1463#issuecomment-1941752636,1,['avoid'],['avoid']
Safety,"> but I wonder is it possible that people will then want tags with different interpretations?. Yes, this is also true. > The alternative I'm thinking is to simply have a dictionary entry; > {; > ""omeroTags"": ""tag1, tag2, tag3""; > }; > ; > but I don't know whether it's safe to use a comma (or anything else) as a delimiter. Actually, I already thought of the solution but our final goal would be to sort the images within the current project according to one or more tags. > Otherwise, I guess there could be a general tags list in a QuPath project entry. I would rather go for this solution as I think it is the best way to make them independant and searchable.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1289#issuecomment-1687762439:269,safe,safe,269,https://qupath.github.io,https://github.com/qupath/qupath/issues/1289#issuecomment-1687762439,1,['safe'],['safe']
Safety,"> it only zooms if I 'swipe' at the end of the gesture. This actually EXACTLY my issue! Avoiding the swipe motion requires very careful handling of the pen which makes it very unhandy for navigating large images and that in turn makes a tablet almost useless for this purpose since I do a lot of navigating while drawing (my tablet is rather small, so I cant draw on a precisely on large area). Is there some way to disable the swipe for zoom or make it switchable?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/188#issuecomment-479827096:88,Avoid,Avoiding,88,https://qupath.github.io,https://github.com/qupath/qupath/issues/188#issuecomment-479827096,1,['Avoid'],['Avoiding']
Safety,> might be the D or H key?. It's 'H' for 'Hide' :); But I've been tempted to make it 'D' for 'Detections'... [List of shortcut keys](https://github.com/qupath/qupath/wiki/Shortcut-keys),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/157#issuecomment-373143331:94,Detect,Detections,94,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-373143331,1,['Detect'],['Detections']
Safety,"> tbh I'd never noticed this or seen it as problematic. Fair yeah, it's been bugging me, but I am happy to allow it to continue to bug me if it's not consequential or shared by others. > You could also change main.css to avoid any change on hover at all, but personally I think it looks quite nice and helps titles stand out. It certainly helps for collapsible panes",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1517#issuecomment-2123069781:221,avoid,avoid,221,https://qupath.github.io,https://github.com/qupath/qupath/pull/1517#issuecomment-2123069781,1,['avoid'],['avoid']
Safety,"> was running a script but it never finishes. I don't understand exactly what steps you are taking?; * Are you using *Run &rarr; Run* from the script editor, or *Run &rarr; Run for project*? *Run for project* enables you to [run the same script sequentially across multiple images](https://qupath.readthedocs.io/en/stable/docs/scripting/workflows_to_scripts.html#running-a-script-for-multiple-images), but I don't know if you're using this.; * Do you have multiple images open simultaneously in QuPath, or only a single image at a time?. Please see also my question above:. >> I still have 15GB free; > ; > Is this available to QuPath, or only to the operating system? You can track QuPath's memory use with View → Show memory monitor (although this won't include anything JavaCPP does... which mostly means things connected with pixel/object classifiers). The memory monitor also provides ways to reclaim memory at any time. Although problem **the most important thing** is that I can see in your script (and screenshot) that you are running the cell detection after; ```groovy; createSelectAllObject(true);; ```; This is likely to be **extremely** inefficient, because it will process all the empty white space as well. Processing should be much faster, and memory use much lower, if you restrict cell detection to only the tissue regions.; See [Detecting tissue](https://qupath.readthedocs.io/en/stable/docs/tutorials/thresholding.html) for details; [Pixel classification](https://qupath.readthedocs.io/en/stable/docs/tutorials/pixel_classification.html) is another option.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/828#issuecomment-939704186:1052,detect,detection,1052,https://qupath.github.io,https://github.com/qupath/qupath/issues/828#issuecomment-939704186,3,"['Detect', 'detect']","['Detecting', 'detection']"
Safety,"> yes - the problem is reproducible.; Until now I was aware of one lacking cell. This time it was two cells lacking. Things like this make me think of parallelization and the threads of the GUI. Not certain this is the issue, but rather than; ```groovy; selectObjects { p -> p.getPathClass() == null && p.isAnnotation() && p.getROI().getArea() < 4000 }; annotations = getSelectedObjects(); ```; I'd suggest trying something like:; ```groovy; getAnnotationObjects().findAll { p -> p.getPathClass() == null && p.isAnnotation() && p.getROI().getArea() < 4000 }; ```; As has occurred before, weird things can happen when modifying the hierarchy too quickly after selections within scripts that are run interactively in the GUI (since the GUI elements may not have completed processing before the later lines of the script have run). If this is correct, the trouble shouldn't arise if ; 1. you can avoid selecting/deselecting objects, or ; 2. run the script in batch mode via _Run &rarr; Run for project_. Out of curiosity, what happens if you select one of the weird-behaving cells and run the following:; ```groovy; def selected = getSelectedObject(); def parent = selected.getParent(); print selected; print parent; print selected == parent; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/259#issuecomment-457730791:893,avoid,avoid,893,https://qupath.github.io,https://github.com/qupath/qupath/issues/259#issuecomment-457730791,1,['avoid'],['avoid']
Safety,"@AnthonyOrvedahl Figuring out the rotation or adjustments necessary to make the cells overlap is a difficult problem to solve, and beyond the scope of QuPath currently. Potentially anything is possible, since QuPath is open source and supports scripts and extensions, and so someone might take on the task of adding this functionality in the future. I have looked a bit into aligning slides to transfer larger regions, but the kind of fine-grained alignment necessary for cell-by-cell measurements is much more awkward and it isn't something I am actively working on myself. As @Svidro says, if you take care of registering the slides elsewhere then it may well be possible to hack together something in QuPath to transfer the detected cells and that could be useful... but it would take some effort and would probably not be ideal in terms of workflow or accuracy. Two other ways in which QuPath might help with looking at multiple markers per cell:; * Support for brightfield and fluorescence multiplexing; * Ability to align restained sections of the same tissue. Both are things I'm looking to add or improve in QuPath. To some extent, the first is already present; a nice solution for the second one would also them mean better support for images registered-outside-of-QuPath... but it's not quite there yet. One other things: if you've any screenshots of example images that would be helpful. I've assumed you're working with brightfield whole slide images. Registering smaller image regions is more doable, as there are a range of relevant registration plugins within [Fiji](https://imagej.net/Registration).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/178#issuecomment-398666277:727,detect,detected,727,https://qupath.github.io,https://github.com/qupath/qupath/issues/178#issuecomment-398666277,1,['detect'],['detected']
Safety,"@Rylern Very good question... no, but maybe?. Its primary use is for showing overlays in the viewer, where it should really be called on the application thread (or a background thread dedicated to rendering). It *could* also be called when writing out a rendered image + overlays... and *maybe* that would involve writing tiles in parallel. If so, then I'd expect important variables never to be changed: we'd create an overlay per image we want to export. Therefore I can't think of a time when this will be problematic in practice, but it's definitely something to be cautious about. . If we don't find any specific case where the current behavior is problematic, then I'm not sure it's worth making it properly thread-safe - and instead devote the time that would require to an entirely new viewer with overlays that are designed much better than this from the start.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1532#issuecomment-2130922325:721,safe,safe,721,https://qupath.github.io,https://github.com/qupath/qupath/pull/1532#issuecomment-2130922325,1,['safe'],['safe']
Safety,"@Svidro That's a different error. I couldn't replicate it, but my idea of a 'decent number' may be lower. If you are displaying all detections under the 'Hierarchy' tab, you can right-click on it and choose to hide them. That might help.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/307#issuecomment-484627853:132,detect,detections,132,https://qupath.github.io,https://github.com/qupath/qupath/issues/307#issuecomment-484627853,1,['detect'],['detections']
Safety,"@ajerusalmi the error is caused by the old Weka extension being installed. This is compatible with v0.1.2, but not v0.2.0. Two things you can do:; * delete the Weka extension; to find its location, go to *Edit &rarr; Preferences* and check the 'QuPath user directory'; * use *Edit &rarr; Reset preferences* to reset the location of the user directory in QuPath, so the extension will not be found. I will close this issue since it is not a bug, however a change has been made for v0.2.0-m11 to enable QuPath to recover better in cases like this, see https://github.com/qupath/qupath/issues/454",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/458#issuecomment-620375806:511,recover,recover,511,https://qupath.github.io,https://github.com/qupath/qupath/issues/458#issuecomment-620375806,1,['recover'],['recover']
Safety,"@aliys97 I've hidden this comment as it is really a question about using QuPath and the forum is a better place to discuss that. Also, it looks like you have already posted about it [on the forum here](https://forum.image.sc/t/batch-processing-create-and-save-density-map/82135/7) and I'd like to avoid having two parallel discussions.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1272#issuecomment-1637444330:297,avoid,avoid,297,https://qupath.github.io,https://github.com/qupath/qupath/issues/1272#issuecomment-1637444330,1,['avoid'],['avoid']
Safety,"@melvingelbard ; Thank you for kindly providing a possible solution!; However, manually modifying `.qptma` file is rather complicated. I have to first export `.qptma`, insert uniqueID, and import it, for every image.; For now, my alternative solution is through menu File -> TMA data -> import TMA data, copy arranged Unique ID, finally `Paste Gird`. At least, this method avoids export `.qptma` file with lots of other images. Hope the ""Drag and Drop `.qpmap`"" feature can be repaired soon~",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/829#issuecomment-944358370:373,avoid,avoids,373,https://qupath.github.io,https://github.com/qupath/qupath/issues/829#issuecomment-944358370,1,['avoid'],['avoids']
Safety,"@mezwick Hashes aren't currently generated or made available. Making a release remains a fairly laborious and manual process. Although the builds themselves are now generated automatically using GitHub Actions, I have to download and check these run on each platform and then upload again. And write all the release notes, tag the version etc. There can also be some extra renaming required, since `jpackage` (used for the build) has some awkwardness connected to artefact naming and 0.x.x versions that affects some platforms but not others (e.g. I think macOS forbids 0.x.x versions, so this needs worked around; also, it needs to be possible for people to have multiple versions installed for reproducibility). It's already a real pain to do, and I don't want to add any more manual steps if I can avoid it. It would be strongly preferable to automate the whole process a bit more, using [Upload to Release](https://github.com/marketplace/actions/upload-to-release) to avoid the download/upload requirement, and somehow include hashes (e.g. using the links from @KrisJanssen's last post) at that point. This seems to me at least a bit awkward to set up though, since the upload action is only triggered when a release is made. The [build workflow](https://github.com/qupath/qupath/blob/v0.3.2/.github/workflows/jpackage.yml) would have to be quite a bit more complex (e.g. to handle cross-platform filenames/content types for the builds, as well as different artefact compression methods). I'd also still need to retain the ability to check the release manually on each platform *before* the release itself is created, because creating the release is what triggers any update notifications... and after the release has been tagged is a bad time to identify some platform-specific breakage. These tend to happen with every release, e.g. because some dialog ends up misbehaving on Ubuntu but looks fine everywhere else. I strongly suspect I'd mess it up quite a few times before (hopefully) getting i",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1027#issuecomment-1208071371:801,avoid,avoid,801,https://qupath.github.io,https://github.com/qupath/qupath/issues/1027#issuecomment-1208071371,2,['avoid'],['avoid']
Safety,"@petebankhead I will definitely share the new QuPath jobs. Thank you for these fixes to the TMA Data viewer. The table now has correct colors and all the columns that were missing values now have correct values. . I am just realizing that the data table is only sluggish when the TMAs have cell detections present. If I were to calculate my measurements of interest for each TMA and remove detections before testing the TMA Data viewer then it works very smooth. Is it possible that the vertical scroll issue sluggishness is a side effect of being able to view huge combined dataset ""live""!. I hope TMA Viewer is here to stay as a legacy feature for a while, it seems to have served well and continues to work. Thank you for keeping it alive.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1083#issuecomment-1289156832:295,detect,detections,295,https://qupath.github.io,https://github.com/qupath/qupath/issues/1083#issuecomment-1289156832,2,['detect'],['detections']
Safety,@petebankhead so then it is expected that whenever you load .qptrain objects it they will be overwritten? Doesn't that make them impossible to use? Also I seem to recall being able to do load these saved training points in the past through creating a new detection classifier which is why I am also confused. I do have a feeling this is a bug and not the way the code is written because of that.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/360#issuecomment-530538010:255,detect,detection,255,https://qupath.github.io,https://github.com/qupath/qupath/issues/360#issuecomment-530538010,1,['detect'],['detection']
Safety,"@petebankhead, many thanks for fast feedback! I've marked this PR as draft and going to work further.; As you mentioned, there is also an option to use OpenCV API but OpenVINO API will give better performance (at least once I could fix asynchronous efficiency issue). Briefly answering your questions,. > Should the OpenVINO backend in OpenCV 4.5.1 offer an equivalent level of support and performance, or are there advantages in using this instead / as well?. Yes, it can help to avoid IR conversion, in example. OpenVINO natively can load only IR or ONNX at this moment. However it'll require a separate package with OpenCV linked against OpenVINO. > Can/could this work across Windows, Linux & macOS - or is it Linux-only?. Yes, no problem at all. I just published a test package for Linux only but going to expand it in future. > Am I right in thinking the dependencies are all Apache (or at least GPL-compatible)?. OpenVINO is Apache 2.0: https://github.com/openvinotoolkit/openvino/blob/master/LICENSE",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/665#issuecomment-777016613:481,avoid,avoid,481,https://qupath.github.io,https://github.com/qupath/qupath/pull/665#issuecomment-777016613,1,['avoid'],['avoid']
Safety,"@pyushkevich . > Curious, do you offer or plan to offer a supervised learning-based object detection tool, sort of like Ilastik?. Yes! That is indeed what I was obscurely referencing I have a working prototype, but it is some way away from being useful (e.g. it shows a live overlay, but this can't readily be converted into any meaningful measurements or objects). I plan to write a bit more about it whenever I get time to work on it again, and have a clearer idea when it'll be ready. I'll send you a message, it would be great to discuss further and perhaps incorporate some of your experience from ITK-SNAP if you're interested. @Svidro ; Thank you, creative as always and nothing I'd ever have come up with :). @mnolan1989 . > In the end it actually worked great - a substantial amount of the paper we are about to submit made use of positive pixel detection (QuPath is referenced!). Great! Thanks for confirming... and for referencing :) Don't know if you saw I mentioned on Twitter recently that just over half the papers using QuPath this year didn't reference the *Sci Reports* publication - would be very good to turn that around!. And thanks also for the extra information on the lab side.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/67#issuecomment-391979772:91,detect,detection,91,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391979772,2,['detect'],['detection']
Safety,"@suzeteguarda you could try posting your question on the forum at https://forum.image.sc/tag/qupath. The error is that there isn't enough memory, but without having the classifier and knowing how much memory you have, I can't really guess what could be responsible. (This topic is really about loading training data to create classifiers, not classifiers themselves, so I will hide these posts to avoid distraction).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/493#issuecomment-1791280813:397,avoid,avoid,397,https://qupath.github.io,https://github.com/qupath/qupath/issues/493#issuecomment-1791280813,1,['avoid'],['avoid']
Safety,"@takakono this looks like confusion over the purpose of the classifier. You need to detect cells first before there can be anything to classify. Running the classifier won't do anything if you haven't already detected cells on the image. The supplementary material in the [Scientific Reports paper](https://www.nature.com/articles/s41598-017-17204-5) may be helpful, especially the PDF, as it describes step-by-step how I applied some similar analyses. I will close this because it doesn't appear to be a bug in QuPath after all. The forum is the right place for questions about using the software: https://forum.image.sc/tags/qupath",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/331#issuecomment-501902237:84,detect,detect,84,https://qupath.github.io,https://github.com/qupath/qupath/issues/331#issuecomment-501902237,2,['detect'],"['detect', 'detected']"
Safety,"A fairly complete description of TMA setup is here: https://github.com/qupath/qupath/wiki/TMA-CD3-analysis. The only difference for H-score is running ""Positive cell detection"" instead of ""Fast Cell Counts"". You can find information on Positive cell detection here: https://github.com/qupath/qupath/wiki/Detecting-objects",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/190#issuecomment-408301912:166,detect,detection,166,https://qupath.github.io,https://github.com/qupath/qupath/issues/190#issuecomment-408301912,3,"['Detect', 'detect']","['Detecting-objects', 'detection']"
Safety,"A few more things:; * If I try to load a pixel classifier, I'm still prevented from opening the dialog if there is no classifier in the current project. In this case, I'd expect the dialog to open and allow me to choose a classifier.; * There's a gap to the right of the options now in the dialog that looks like it shouldn't be there.; ![Screenshot 2021-03-05 at 13 45 30](https://user-images.githubusercontent.com/4690904/110123703-23eba680-7db9-11eb-84f8-1aad3899d4ac.png); * It would be a little nicer to determine whether `(s)` is needed or not and adjust the message displayed to the user accordingly when offering to copy the classifier. I also think the wording is a bit redundant; I'd prefer 'Copy classifier to the current project?' and *Yes*, *No*, *Cancel*. Depending upon how the dialog is constructed you may have space to add some further text to explain what it means (but I'm not sure that's really needed).; ![Screenshot 2021-03-05 at 13 45 38](https://user-images.githubusercontent.com/4690904/110123699-2221e300-7db9-11eb-8204-fd45b13976d2.png); * I couldn't see a way to work drag & drop with the pixel classifier. I *can* drag a classifier onto QuPath's main window, but it appears that QuPath then tries (and fails) to open the classifier as an image. It doesn't display any meaningful error - or at least not for long enough for me to read it.; * There isn't any text in the *Load object classifiers* dialog that indicates you can load a classifier by drag & drop. I think this text should be added; you might also support adding a classifier by double-clicking and providing a file chooser. It doesn't have to part of this pull request, but since this will offer support for loading classifiers from elsewhere, perhaps we should relax the strict requirement that classifiers can only be saved within a project. What do you think?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/642#issuecomment-791435458:679,redund,redundant,679,https://qupath.github.io,https://github.com/qupath/qupath/pull/642#issuecomment-791435458,1,['redund'],['redundant']
Safety,"Actually there are more errors, introduced (I think) in v0.2.0-m5 when attempting to avoid recursion. The running statistics are not being reset between clusters, potentially resulting in further problems throughout these measurements.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/552#issuecomment-656226269:85,avoid,avoid,85,https://qupath.github.io,https://github.com/qupath/qupath/issues/552#issuecomment-656226269,1,['avoid'],['avoid']
Safety,"Actually, it may be that the issues with `*.czi` or `*.mrxs` may be more similar than I realised... it seems that `*.mrxs` may also involve JPEG-XR compression, which [OpenSlide does not currently handle](https://github.com/openslide/openslide/issues/184). If this is the source of the problem, in the short term I'm afraid you may need to change your settings when saving your images in the first place to avoid JPEG-XR (regular JPEG compression should work). There is also an export ability within [Pannoramic Viewer](http://www.3dhistech.com/pannoramic_viewer), although I have not tried this myself.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/12#issuecomment-258226826:407,avoid,avoid,407,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258226826,1,['avoid'],['avoid']
Safety,"Actually, on reflection, there isn't really anything ImageJ-specific in your method, making it a good candidate to go into one of the 'core' modules. I could see it being useful in other places - potentially with different memory proportion limits - such as when extracting images to write to disk, or possibly even to throttle parallelization when running a detection command.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/134#issuecomment-357533416:359,detect,detection,359,https://qupath.github.io,https://github.com/qupath/qupath/pull/134#issuecomment-357533416,1,['detect'],['detection']
Safety,"Adding simple text fields to objects would certainly be nice for cluster/neighborhood/external to QuPath analyses where users may prefer to add non-class labels like ""immune dense cluster"" rather than ""1"" and look up what 1 was. Especially in cases involving many clusters. ; Possibly make it locked behind a default ""Off"" setting. I am guessing it might result in data file sizes getting somewhat out of hand in the cases of millions of cells?. I am less certain that detection objects should have descriptions, but maybe making a ""toAnnotation"" or ""toDetection"" function to make object type swapping simpler when scripting would reduce the need to place complex labels on detections.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1005#issuecomment-1180616120:469,detect,detection,469,https://qupath.github.io,https://github.com/qupath/qupath/issues/1005#issuecomment-1180616120,2,['detect'],"['detection', 'detections']"
Safety,"Adding to the above suggestions, I understand by the manual you mean the section on [TMA CD3 analysis](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis). You can see in the screenshots the kind of settings that were used in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/53#issuecomment-282469327:358,detect,detection,358,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327,2,['detect'],"['detecting', 'detection']"
Safety,"Addresses https://github.com/qupath/qupath/issues/1069 by avoiding drawing each connecting line twice. Also incorporates image plane information when painting (previously, connections would only be shown if z=0 and t=0). There is still a problem with connections being lost if both objects are outside the current field of view, but their connecting line crosses the view.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1070:58,avoid,avoiding,58,https://qupath.github.io,https://github.com/qupath/qupath/pull/1070,1,['avoid'],['avoiding']
Safety,Addresses problems raised on the forum:; * https://forum.image.sc/t/stardist-qupath-3-0-snaphot-detection-for-bigger-annotations/51978; * https://forum.image.sc/t/resaving-xlef-file-creates-non-functional-lif-tif-file/51802,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/716:96,detect,detection-for-bigger-annotations,96,https://qupath.github.io,https://github.com/qupath/qupath/pull/716,1,['detect'],['detection-for-bigger-annotations']
Safety,"After detecting cells within each TMA core I then ran tissue detection on the same TMA cores.; It found all tissue areas but replaced all objects. I had thousands of objects per core (for each cell) and now there is one object per core (tissue).; I was able to do cell detection within the tissue detection annotation earlier, but then didn't have the core name in my output.; I will save each separately.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/60:6,detect,detecting,6,https://qupath.github.io,https://github.com/qupath/qupath/issues/60,4,['detect'],"['detecting', 'detection']"
Safety,"After using the ""Show"" button for the pixel classifier features, it would be nice to have a similar feature for the image the Cell Detection function uses to generate nuclei. Even better if we could see a small area change in real time as we adjust the values!",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/327:131,Detect,Detection,131,https://qupath.github.io,https://github.com/qupath/qupath/issues/327,1,['Detect'],['Detection']
Safety,"Ah, I was just thinking that, but stuck in lab meeting!; Yes, I tend to calculate my tissue areas after the fact in R rather than using the simple tissue detection, so when I saw that line in your script, I figured that might be what was happening. Good luck!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/59#issuecomment-289537633:154,detect,detection,154,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-289537633,1,['detect'],['detection']
Safety,"Ah, does that mean it's a .czi file, or is there another scanner/source that produces this...?. Anyway, a couple of suggestions:; * You could export summary results three times, and then merge them together into a single table later... but then you won't have any info about whether individual cells are positive in multiple channels (just summary results for each channel independently); * You can use *Measure &rarr; Show detection measurements* to get all the details for every cell in each image, and explore how to summarize this elsewhere (e.g. in Excel, with R, with Python). If you take the second approach, whatever method of summarizing you choose could then potentially be worked back into becoming a QuPath script. But there isn't any built-in way to do that currently (and I'm not sure what would be the appropriate, general-purpose way to summarize this kind of data).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/16#issuecomment-391777258:424,detect,detection,424,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391777258,1,['detect'],['detection']
Safety,"Ah, fair enough. To me, it makes sense for there to be a single cell detection window, and I'd put sub-panes in that window if needed, but that sounds like a total pain and pretty useless in terms of overall UX gain",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1560#issuecomment-2256352714:69,detect,detection,69,https://qupath.github.io,https://github.com/qupath/qupath/pull/1560#issuecomment-2256352714,1,['detect'],['detection']
Safety,"Ah, no, the script does not create sub-categories for each cell type, it overwrites cell classes based on the subcellular detection count. I would have to look into something a bit different to do what is in your top image. I'm not sure what the bottom image is though. The result of the script if you swap in DAB should be something like:; ![image](https://user-images.githubusercontent.com/23145209/36644405-c7245426-1a0e-11e8-8c52-4a525fd5588f.png). At least based on the shoddy naming scheme I used in the basic script!. Note that it was not designed to subdivide tumor or stroma cells into categories, but to create new categories within annotation regions purely based on a spot count. I would have to look into some different scripting to subdivide that way, though Pete recently posted a script that has a function I did want to test out.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/146#issuecomment-368327932:122,detect,detection,122,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368327932,1,['detect'],['detection']
Safety,"Ah, no, you are absolutely correct. I normally would handle this by exporting the detections file and processing it in R. But if you want to visualize the ratio (with view measurements etc) you will need to update the cell measurements once you have determined the nuclear/cytoplasmic localization. Roughly speaking, you need to either cycle through all cells, and sum/average their stats for that cell, or cycle through all subcellular detections, and update the parent cell as each one is processed. I only know how to do the latter. You already have the loop for all cells from the previous example, and a loop for all clusters from the first. I will start with the loop for all clusters since I have some idea how that would work. Note that this does not summarize stain OD or actual spot area, just estimated spot count. It also only works if the second stain is labeled as DAB! After that, you should have the two values you need to get your ratio. ```; import qupath.lib.scripting.QP; def NuclearSum = ""Nuclear Spot Sum""; def CytoSum = ""Cytoplasmic Spot Sum"". //Probably not necessary when using putMeasurement, but I liked to have this loop for completeness, plus it will reset all values to zero when rerunning the script.; for (def cell : QP.getDetectionObjects()) {; def ml = cell.getMeasurementList(); ml.putMeasurement(NuclearSum, 0); ml.putMeasurement(CytoSum, 0); ml.closeList(); }; def clusters = getObjects({p -> p.class == qupath.imagej.detect.cells.SubcellularDetection.SubcellularObject.class}). // Loop through clusters; for (c in clusters) {; // Each subcellular detection can have one parent; def cell = c.getParent(). def ml = cell.getMeasurementList(); ; //Important note: This value (Num Spots) will be heavily influenced by the Estimated Spot Size when running the; //subcellular detection command. you may instead want to use the Area measurement which you can find; //by clicking on a subcellular detection; double thisCluster = c.getMeasurementList().getMeasurementValue(",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/119#issuecomment-347208202:82,detect,detections,82,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-347208202,2,['detect'],['detections']
Safety,"Ah, sorry, I actually deleted it once I realized it wasn't actually answering your question correctly. I thought you were having trouble detecting positivity within your cells, not missing cells entirely! The only other thing I could think of for that was along the same lines as Pete's suggestion. . Sometimes with more complicated stains I ""cheat"" by creating my own stain vector as a mix of Hematoxylin and DAB, and save it over Hematoxylin. In a straight HDAB this shouldn't give very different results from full OD (and could easily be worse), though, but it may be worth a try if you are still having trouble.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/46#issuecomment-276007341:137,detect,detecting,137,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-276007341,1,['detect'],['detecting']
Safety,"Ah, sorry, I probably should have mentioned, it might not be your laptop...; One of the dangers with using Positive Pixel detection is the strain it puts on the program when updating the screen with many very finely defined areas. I would recommend turning OFF all detection visualizations, then moving the screen to the location you want to see, then turning detection visualizations back on (might be the D or H key? I don't have access right now and forget). Turn them off again before you want to move the screen to a new position. It is somewhat cumbersome, but usually prevents my program from crashing. . In fact, the program is not usually crashing, but just very slowly rendering the entire image again. Though depending on your system it might sometimes take an hour or so! If you use Superpixels or Cell detection, this is not usually a problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/157#issuecomment-373141585:122,detect,detection,122,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-373141585,4,['detect'],['detection']
Safety,"Ah, thank you for investigating this!. The hierarchy event system is horrible, and traces back to the early versions of QuPath where the hierarchy was much more important, undo/redo didn't exist, and we didn't have a good spatial cache from JTS. Then, it was a continual fight to avoid very expensive processing every time an object changed - because `resolveHierarchy()` was effectively being called automatically, and lots of things needed to update. I thinks this shows event system is *very* overdue a major revision. > I'm sure there is reason behind it, but here a hierarchy changed event is emitted, instead of an object added event. From your post and my failing memory, I suspect that the idea was that the 'object added' event would just handle a single object, but if multiple objects were added then we fired a more general structure change event. I guess this was because, when adding a single object, we knew that it could only affect ancestor and descendent objects in QuPath v0.1.2 and earlier. But if we changed multiple objects, then all the *potential* auto-resolved parent/child relationships between objects would be too complex to decipher. Instead, it was easier and safer to fire an event that basically said: _'something big changed, don't try to figure out exactly what, but just update to handle the hierarchy as it now is'_. I'm reluctant to switch to `addObjects` firing an event that doesn't include all the objects that were added, in case there is any legacy code that might be sensitive to the change. Which leads to... > So, [this condition](https://github.com/qupath/qupath/blob/3544e613b40fd123236936d76e2cb5ee08d855f7/qupath-gui-fx/src/main/java/qupath/lib/gui/UndoRedoManager.java#L474) is true, the event is ignored, and the UndoRedoManager doesn't update its state. It looks like I failed to recognize that ; ```java; event.getChangedObjects().stream().allMatch(p -> p instanceof ParallelTileObject); ```; would return true when `getChangedObjects().isEmpty()`.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1578#issuecomment-2276091306:280,avoid,avoid,280,https://qupath.github.io,https://github.com/qupath/qupath/pull/1578#issuecomment-2276091306,1,['avoid'],['avoid']
Safety,"Ah, that will be a Pete question, but I don't know of any way currently. It took a bit of work for me to get find new _mean_ stain intensities for the nucleus/cytoplasm when applying a variety of color vectors for multiplexing... ; I suspect the nucleus would be doable since that is a stand alone ROI, especially if you dig into the java files (the pixel by pixel cytoplasmic values, as far as I know, are only used as the cells are generated), but the cytoplasm might be more difficult. ; The file I am thinking about is: https://gist.github.com/Svidro/eaf29399e36d34caacddf345ab668b0c#file-watershedcelldetection-java; That is a version of it that I edited to use % of different color vectors for the nuclear detection, rather than just OD sum or Htx. That is where I would recommend starting if you want to try to insert an IQR measurement. But I really don't know!. It would be nice to have that information available, if you/Pete can get it working, but I don't think I can help much more here.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/236#issuecomment-433484202:712,detect,detection,712,https://qupath.github.io,https://github.com/qupath/qupath/issues/236#issuecomment-433484202,1,['detect'],['detection']
Safety,"Ah, yes, I have seen that before once you get a large number of points defining the annotations. I think if I waited 30 minutes or so it came back, but it has been a while since I experienced that. I don't recall being able to do much about it either, though smoothing the annotations (if I was doing Tissue Detection) did help. It was especially noticeable when editing many annotations in very large TMAs. I also have a much better computer now, so that could be part of it! Hard to compare after all of the changes.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/267#issuecomment-461559724:308,Detect,Detection,308,https://qupath.github.io,https://github.com/qupath/qupath/issues/267#issuecomment-461559724,1,['Detect'],['Detection']
Safety,"Ah, yes, that sounds like it would be very difficult for standard cell detection methods. Good luck counting! Or you might be able to use an ImageJ script to manipulate each image into a state where it can be processed and the results sent back to QuPath... but it might be easier to just count if the fields are small.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/266#issuecomment-461196550:71,detect,detection,71,https://qupath.github.io,https://github.com/qupath/qupath/issues/266#issuecomment-461196550,1,['detect'],['detection']
Safety,"Ah.... so am I. It seems to be a bug if the directory isn't set. However, you can also set the plugins directory through *Edit &rarr; Preferences...* - type ImageJ into the search box, and the option should appear. Double-click on the text entry box to be able to choose the directory. Once you do that, *Edit &rarr; ImageJ &rarr; Set ImageJ plugins directory* should work again. That appears to work for me, and avoids the bug.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/91#issuecomment-321321549:413,avoid,avoids,413,https://qupath.github.io,https://github.com/qupath/qupath/issues/91#issuecomment-321321549,1,['avoid'],['avoids']
Safety,"Aims to avoid needing the more tortured logic of https://gist.github.com/petebankhead/63a6d2e93b7ce704e57eefb6885010fa. In a script, now simply call something like; ```groovy; getQuPath().setAccelerator(""File>Open..."", ""shift+o""); ```. Relates to https://forum.image.sc/t/feature-request-windows-with-favorite-menu-items/72721",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1128:8,avoid,avoid,8,https://qupath.github.io,https://github.com/qupath/qupath/pull/1128,1,['avoid'],['avoid']
Safety,"Aims to fix https://github.com/qupath/qupath/issues/865; This takes a different approach to parallelization, managing a pool of ImageReaders with each tile-requesting thread taking the next available reader.; If there are no readers available, and the total number is less than some maximum value (based upon the number if available processors), a new reader is generated on another thread and added to the queue when ready. This should; * avoid generating more readers than needed, with a limit separate from the number of tile requesting threads; * avoid attempting to initialize multiple readers simultaneously, which can be a bottleneck. In addition, more tests have been added.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/867:440,avoid,avoid,440,https://qupath.github.io,https://github.com/qupath/qupath/pull/867,2,['avoid'],['avoid']
Safety,Aims to fix https://github.com/qupath/qupath/issues/993; Also make it possible to avoid shuffling objects when exporting instance labels. I wanted this option when considering https://forum.image.sc/t/exports-annotations-with-individual-labels-line-between-touching-objects-and-user-defined-priority-between-touching-objects-of-different-classes/68971,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1000:82,avoid,avoid,82,https://qupath.github.io,https://github.com/qupath/qupath/pull/1000,1,['avoid'],['avoid']
Safety,"Allow me to thank you for the other day's issues.; I’ve been testing out the pixel classifier in QuPath to detect the collagen deposition using Masson's trichrome stain. ; I’d like to get the percentage of collagen fiber content in the tumor stroma for each TMA cores. Although it seems possible by classifying group stroma (as stroma), collagen (as other), and tumor (as ignore), I couldn’t find the way to apply the classifier for each TMA cores. ; How should I solve that? . I will be grateful for any help you can provide.; ![Masson trichrome collagen db stroma](https://user-images.githubusercontent.com/51498119/60206037-8ed49400-9807-11e9-954a-df2a647cd46b.PNG)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/335:107,detect,detect,107,https://qupath.github.io,https://github.com/qupath/qupath/issues/335,1,['detect'],['detect']
Safety,"Also after switching to channel 1 it still happens. I can repeat the same script. Sometimes I get the right cell distribution, sometimes cell detections from other parts of the image are randomly copied to places where they do absolutely not fit to the behind image content. I could not find a pattern yet, that the phenomen might follow.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/153#issuecomment-370411000:142,detect,detections,142,https://qupath.github.io,https://github.com/qupath/qupath/issues/153#issuecomment-370411000,1,['detect'],['detections']
Safety,Also fixes a possible bug when making measurements from point annotations.; Inspired by this discussion: https://forum.image.sc/t/qupath-measure-pixel-classifier-area-per-cell-detection-for-wsis/72701,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1076:176,detect,detection-for-wsis,176,https://qupath.github.io,https://github.com/qupath/qupath/pull/1076,1,['detect'],['detection-for-wsis']
Safety,"An example script (not tested on a real example!):. ```groovy; double dx = -getCurrentServer().boundsX; double dy = -getCurrentServer().boundsY. getTMACoreList().each {it.ROI = it.ROI.translate(dx, dy)}; getAnnotationObjects().each {it.ROI = it.ROI.translate(dx, dy)}; fireHierarchyUpdate(); ```. This moves only TMA cores and annotations (not detections... but transferring detections really isn't recommended, since many detection commands are substantially different in v0.2.0 compared to v0.1.2).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/547#issuecomment-650197416:344,detect,detections,344,https://qupath.github.io,https://github.com/qupath/qupath/issues/547#issuecomment-650197416,3,['detect'],"['detection', 'detections']"
Safety,"An interesting variant of this (brace yourself Pete for more of my crazy), depending on what and how you are measuring things, can be converting your measurement area into a ""pathCellObject"" (whether it is hand drawn, tiles, etc) and then running Subcellular detection on it for a bit more control. The segmentation allows you to do things like add further color measurements to the objects created, which then allows further thresholding (remove objects that are too much of a color you are not looking for to get rid of black junk). Can go more into specifics if it is something that would be of interest.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/67#issuecomment-391773235:259,detect,detection,259,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391773235,1,['detect'],['detection']
Safety,"An unanticipated issue that arose from QuPath going open source is how it can - and should - behave when being run in different regions, where numbers are expected to be formatted differently. So, for example, 1,234,567.89 in the UK or US might be written as 1.234.567,89 in Germany or 1 234 567,89 in Russia. This is described in more detail in the [Decimal mark](https://en.wikipedia.org/wiki/Decimal_mark) Wikipedia article. This scenario isn't great for software that is intended to be used worldwide for scientific applications, where the format in which numbers are entered and exported really matters. ### Locales & formatting numbers. The good news is that Java can support different [Locales](https://docs.oracle.com/javase/tutorial/i18n/locale/index.html). This makes it possible to write code that takes the region into consideration. The very bad news is that handling this predictably is far from straightforward. This arises partly because there are many ways to format numbers within Java, some more convenient than others, and some more problematic than others. For example, considering the following Groovy script to test out different methods:. ```groovy; import java.text.*;. def count = 1;; def sb = new StringBuffer(""\n"");. def s = NumberFormat.getInstance().format(1.234); // Depends on default Locale; sb.append(count++).append("": "").append(s).append(""\n"");. s = NumberFormat.getInstance(Locale.GERMANY).format(1.234); // 1,234; sb.append(count++).append("": "").append(s).append(""\n"");. s = new DecimalFormat(""#.##"").format(1.234); // Depends on default Locale, 2 decimal places; sb.append(count++).append("": "").append(s).append(""\n"");. s = String.format(""My number is %.3f"", 1.234); // Depends on default Locale; sb.append(count++).append("": "").append(s).append(""\n"");. s = ""My number is "" + 1.234; // 1.234 - always uses the dot; sb.append(count++).append("": "").append(s).append(""\n"");; ```. The output when I run it with my default English UK setting is:; ```; 1: 1.234; 2: 1,",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/29:886,predict,predictably,886,https://qupath.github.io,https://github.com/qupath/qupath/issues/29,1,['predict'],['predictably']
Safety,"And if you delete all of the annotations, select all of the detections, and run it, it plugs along for a while and ends up doing nothing. But successfully. In a lightly modified m4.; ![image](https://user-images.githubusercontent.com/23145209/64463124-bc677480-d0b7-11e9-91b6-bee324dc50df.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/359#issuecomment-529030048:60,detect,detections,60,https://qupath.github.io,https://github.com/qupath/qupath/issues/359#issuecomment-529030048,1,['detect'],['detections']
Safety,Annotations and detections deleted from saved project when switching between images,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1313:16,detect,detections,16,https://qupath.github.io,https://github.com/qupath/qupath/issues/1313,1,['detect'],['detections']
Safety,"Another (important!) one:; * With *Cell detection*, any third stain is not automatically measured in the nucleus/cytoplasm/full cell",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/73#issuecomment-299649956:40,detect,detection,40,https://qupath.github.io,https://github.com/qupath/qupath/issues/73#issuecomment-299649956,1,['detect'],['detection']
Safety,"Another possibility for TMAs might be something like ; ```; getDetectionObjects() each {detection -> detection.setName(detection.getParent().getName())}; fireHierarchyUpdate(); ```; in order to name all cells after their parent TMA core (assuming no other annotations have been drawn at this point). . At that point, there could be a list of TMA cores you wanted to apply that particular classifier to which the script checks before applying the current classification steps. ; Downside: you would have to create both the list and each classifier. ; Upside: you would have complete control over the classifier and once created it would be easy to apply across many TMAs. PS. It might be more streamlined to check the parent annotation name within the classifier script against the list, though.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/57#issuecomment-289249459:88,detect,detection,88,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-289249459,3,['detect'],['detection']
Safety,"Another workaround in your case could be a script like this:; ```groovy; def hierarchy = getCurrentHierarchy(); for (annotation in getAnnotationObjects()) {; hierarchy.getSelectionModel().setSelectedObject(annotation); runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; }; ```; Or you could set the number of threads in a script:; ```groovy; import qupath.lib.gui.prefs.PathPrefs; PathPrefs.setNumCommandThreads(1); // Do other things... e.g.; selectAnnotations(); runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; PathPrefs.setNumCommandThreads(Runtime.getRuntime().availableProcessors()) // The default; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/110#issuecomment-337002695:244,detect,detect,244,https://qupath.github.io,https://github.com/qupath/qupath/issues/110#issuecomment-337002695,4,['detect'],"['detect', 'detectionImageBrightfield']"
Safety,Any follow-up discussion should be at https://forum.image.sc/t/cell-detection-not-working-prob-because/24807,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/305#issuecomment-483056828:68,detect,detection-not-working-prob-because,68,https://qupath.github.io,https://github.com/qupath/qupath/issues/305#issuecomment-483056828,1,['detect'],['detection-not-working-prob-because']
Safety,"As I mentioned at both https://github.com/qupath/qupath/issues/363#issuecomment-606369334 and https://github.com/qupath/qupath/issues/426 the *next* release of QuPath will use JDK 14; v0.2.0-m9 does not (because it was not released at the time, and the version of Gradle used with it is not compatible with JDK 14). If you want v0.2.0-m9, you should follow the build instructions I posted under the above links using JDK 13 to build, but pointing to jpackage within JDK 14. It's cumbersome, but necessary because of the incompatibilities and the fact JDK 14 is extremely new. Otherwise you can build from the dev branch using JDK 14 or wait until v0.2.0-m10 is available. I will update the build documentation at that time. > **Please avoid creating issues for anything other than bug reports, and do not create multiple issues for the same thing. Use [the forum](http://forum.image.sc/tags/qupath/) for questions instead, as requested in the documentation and on the 'Issues' page itself.**; > ; > <img width=""696"" alt=""Issues"" src=""https://user-images.githubusercontent.com/4690904/71262757-5afea500-2338-11ea-8c14-91f68652c70b.png"">",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/427#issuecomment-606731627:735,avoid,avoid,735,https://qupath.github.io,https://github.com/qupath/qupath/issues/427#issuecomment-606731627,1,['avoid'],['avoid']
Safety,"Aside, have you tried the _Subcellular detection_ command or ImageJ macro runner for identifying the spot counts in QuPath? In case you were exporting the images for the FISH analysis. Otherwise, there are some decent options for scripts picking out objects and exporting them as individual files found at https://github.com/qupath/qupath/issues/97 although that is mostly if you want an image of the bounding box area. If you want the nuclei and no other image data, I am less certain, although there is probably a way to do so using the ImageJ macro runner and saving them via ImageJ using the commands there to remove the area outside of the nucleus ROI.; Edit:; More info about spot detection here: https://github.com/qupath/qupath/wiki/Spot-detection",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/118#issuecomment-345720827:687,detect,detection,687,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-345720827,2,['detect'],['detection']
Safety,"Attempt to resolve https://github.com/qupath/qupath/issues/744. The underlying problem is that concurrent modification exceptions occurred whenever nDescendants() was called by the UI thread while another thread was adding/removing objects. Adding *more* synchronization to try to overcome this resulted in deadlocks. This commit tries to resolve the issue in two ways:; - Making the childList a synchronized collection (actually a Set); - Reducing synchronization on the PathObject itself, and synchonizing more sparingly on the childList. This is hopefully sufficient to avoid simply counting objects in one thread interfering with adding/removing objects in another. Since most adding/removing access is via a PathObjectHierarchy, counting is (I think...) the main concurrency risk, and the resulting code should be more robust. Along the way, the childList was also given a better default capacity.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/750:573,avoid,avoid,573,https://qupath.github.io,https://github.com/qupath/qupath/pull/750,2,"['avoid', 'risk']","['avoid', 'risk']"
Safety,"Attempt to; 1. improve performance with higher thread counts, and; 2. block the UI for PathPlugin implementations that have a long startup time.; Specifically, this should prevent a user running cell detection interactively in complex, slow-to-tile annotations from modifying the object hierarchy in the time between pressing 'Run' and the modal progress dialog appearing. It also aims to reduce repaint frequency when the detection is running, so that less effort is 'wasted' updating the display.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/785:200,detect,detection,200,https://qupath.github.io,https://github.com/qupath/qupath/pull/785,2,['detect'],['detection']
Safety,Avoid UnsafeReflectionAccessor message,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/537:0,Avoid,Avoid,0,https://qupath.github.io,https://github.com/qupath/qupath/pull/537,2,"['Avoid', 'Unsafe']","['Avoid', 'UnsafeReflectionAccessor']"
Safety,Avoid assuming `PixelType.UINT8` and handle missing resolution (assuming full resolution should be used).,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/935:0,Avoid,Avoid,0,https://qupath.github.io,https://github.com/qupath/qupath/pull/935,1,['Avoid'],['Avoid']
Safety,Avoid confusing / by zero error when auto-setting image type fails,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/885:0,Avoid,Avoid,0,https://qupath.github.io,https://github.com/qupath/qupath/pull/885,1,['Avoid'],['Avoid']
Safety,Avoid exceptions when calling simple Dialogs without UI,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/854:0,Avoid,Avoid,0,https://qupath.github.io,https://github.com/qupath/qupath/pull/854,1,['Avoid'],['Avoid']
Safety,Avoid importing invisible TMA grids,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1345:0,Avoid,Avoid,0,https://qupath.github.io,https://github.com/qupath/qupath/pull/1345,1,['Avoid'],['Avoid']
Safety,Avoid pref-related warnings on startup,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1370:0,Avoid,Avoid,0,https://qupath.github.io,https://github.com/qupath/qupath/pull/1370,1,['Avoid'],['Avoid']
Safety,Avoid resetting cache too often when inserting detections,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/565:0,Avoid,Avoid,0,https://qupath.github.io,https://github.com/qupath/qupath/pull/565,2,"['Avoid', 'detect']","['Avoid', 'detections']"
Safety,Avoid server loading during DefaultProject.saveImageData() if it was never loaded before,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1579:0,Avoid,Avoid,0,https://qupath.github.io,https://github.com/qupath/qupath/pull/1579,1,['Avoid'],['Avoid']
Safety,"Avoid setting a 'zoom-to-fit' status that affects all viewers, but instead just adjust the zoom/positioning of the current viewer. This is to avoid the problem where a user might accidentally select the option, and then find themselves unable to zoom/pan in the image until the toggle has been deselected. Also turn off 'synchronize viewers' by default, but also make it a *persistent preference* so that its status is remembered when QuPath is restarted.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1398:0,Avoid,Avoid,0,https://qupath.github.io,https://github.com/qupath/qupath/pull/1398,2,"['Avoid', 'avoid']","['Avoid', 'avoid']"
Safety,"Avoid setting annotation color in a `PathObject` when setting other properties and keeping the default display color.; Previously, a color property was set even if the user only wanted to add a name or edit the object description through the UI. (Sidenote: the color is reset when a classification is assigned to an object.)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/923:0,Avoid,Avoid,0,https://qupath.github.io,https://github.com/qupath/qupath/pull/923,1,['Avoid'],['Avoid']
Safety,Avoid showing incompatible image types,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/925:0,Avoid,Avoid,0,https://qupath.github.io,https://github.com/qupath/qupath/pull/925,1,['Avoid'],['Avoid']
Safety,"Avoid showing the URI dialog if all missing image paths can be updated using relative links, and the links are all within the existing project directory. This can help make projects more self-contained.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1668:0,Avoid,Avoid,0,https://qupath.github.io,https://github.com/qupath/qupath/pull/1668,1,['Avoid'],['Avoid']
Safety,Avoid updating annotation color unnecessarily,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/923:0,Avoid,Avoid,0,https://qupath.github.io,https://github.com/qupath/qupath/pull/923,1,['Avoid'],['Avoid']
Safety,"Avoids use of default input name, in favor of whatever the prediction function can provide.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/811:0,Avoid,Avoids,0,https://qupath.github.io,https://github.com/qupath/qupath/pull/811,2,"['Avoid', 'predict']","['Avoids', 'prediction']"
Safety,"BTW I plan to revisit my StarDist-related code soon. [`CellMeasurements`](https://github.com/qupath/qupath/blob/cf618cb91a7e43716c3a4bc7b431de6a88ee98be/qupath-core-processing/src/main/java/qupath/imagej/tools/CellMeasurements.java) was created to aid with adding intensity measurements to cells from different sources. Still very early and everything subject to change (we remain far from v1.0.0 and any API stability promises...), but my intention is to make it 'easy' to add standardized measurements to cells and detections generated from any source. This is also why the 'intensity measurements' command is deprecated - but it will remain for now, since replacing it is rather more complicated (since it needs to support measurement intensities in regions that may be larger than what can be reasonably rasterized in one go).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/466#issuecomment-622349306:517,detect,detections,517,https://qupath.github.io,https://github.com/qupath/qupath/issues/466#issuecomment-622349306,1,['detect'],['detections']
Safety,"Basically, you can hide any jar that has `extension` in the name and QuPath should still work - it will just be missing whatever functionality the jar provided. In the OpenCV case, the main things are the detection classifiers and wand tool.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/150#issuecomment-368862255:205,detect,detection,205,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368862255,1,['detect'],['detection']
Safety,"Below is the command-line output if I run from command line instead of GUI:; We can see that the path was a combination of two paths, this is the problem. >> RMD_slide2ims_Entry; 23:18:18.288 [main] [INFO ] qupath.QuPath - Launching QuPath with args: -image, D:\\QMDownload\\5\\Leica_scn\\Leica-Fluorescence-1.scn, -script, D:\\QMDownload\\5\\tpc9321172_2c3b_4e82_b55c_7ae4380fda4b.groovy ; 23:18:18.368 [main] [ERROR] q.lib.images.servers.FileFormatInfo - Checking Big TIFF images currently not supported!!! ; 23:18:18.428 [main] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1 ; WARNING: An illegal reflective access operation has occurred ; WARNING: Illegal reflective access by com.esotericsoftware.kryo.util.UnsafeUtil (file:/C:/Program%20Files/QuPath-0.2.0-m1/app/kryo-2.24.0.jar) to constructor java.nio.DirectByteBuffer(long,int,java.lang.Object) ; WARNING: Please consider reporting this to the maintainers of com.esotericsoftware.kryo.util.UnsafeUtil ; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations ; WARNING: All illegal access operations will be denied in a future release ; 23:18:19.436 [main] [WARN ] loci.formats.Memoizer - deleting invalid memo file: D:\QMDownload\5\Leica_scn\.Leica-Fluorescence-1.scn.bfmemo ; com.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 458; Serialization trace:; service (loci.formats.in.OperettaReader); readers (loci.formats.ImageReader); reader (loci.formats.DimensionSwapper); reader (loci.formats.FileStitcher); helper (loci.formats.in.FilePatternReader); readers (loci.formats.ImageReader) ; 	at com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:119) ; 	at com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:641) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:375) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$Obje",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/280#issuecomment-472915452:732,Unsafe,UnsafeUtil,732,https://qupath.github.io,https://github.com/qupath/qupath/issues/280#issuecomment-472915452,1,['Unsafe'],['UnsafeUtil']
Safety,"Bigger than it sounds... involves reorganizing quite a lot of colormaps, colormodels and pixel classification. Density maps can be used to find hotspots or convert cell (or other) detections into annotations, as an alternative to pixel classification. They operate like pixel classifiers, but by default are limited in size to be 'small' (i.e. all tiles can be requested at once). Once it has been build, a density map is really just an `ImageServer` with a particular interpretation - indicated by its `ChannelType` being `DENSITY`. In theory, a density map could have several channels but in practice it currently has only one or two.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/762:180,detect,detections,180,https://qupath.github.io,https://github.com/qupath/qupath/pull/762,1,['detect'],['detections']
Safety,"Both of these issues are now addressed in `v0.0.5`. For now, running _Add intensity features_ will _always_ result in a prompt to confirm which objects will be used - to help force more deliberate choices. Additionally, large regions will be automatically split into tiles. Provisional checks suggest the results are almost identical to the untiled measurements - although further tests are needed. Some small loss in precision is to be expected compared to the 'true' measurement without tiling (e.g. with Haralick features, were adjacencies across tile boundaries will not be computed), but this should be low... and better than QuPath hanging, or an out-of-memory error. Currently, the _implicit_ tiling of large ROIs for the purposes of avoiding memory errors does not make use of parallelization. Therefore it is still _not_ advisable to compute measurements across very large areas at high resolution. However, it is expected that this shouldn't often be needed, because:; 1. the most useful measurement for a large region is the average intensity, which can be computed at a low resolution with good accuracy, and; 2. measurements of texture (e.g. standard deviation, or Haralick textures) are rarely meaningful when computed over very large numbers of pixels, but rather are more normally computed individually for (explicitly-created) tiles generated within such an the area (e.g. using the _Create tiles_ command). Intensity measurements made for _separate_ objects (including tile objects) will be parallelized, as normal.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/15#issuecomment-258995011:741,avoid,avoiding,741,https://qupath.github.io,https://github.com/qupath/qupath/issues/15#issuecomment-258995011,1,['avoid'],['avoiding']
Safety,"Bump dependencies and attempt to avoid ConcurrentModificationExceptions when clearing the waitingMap.; These could occur (rarely) when using Measurement maps. Since the errors were hard to reproduce, it's not entirely clear if they are solved.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/724:33,avoid,avoid,33,https://qupath.github.io,https://github.com/qupath/qupath/pull/724,1,['avoid'],['avoid']
Safety,"Calculate a negative distance to the inner surface of annotations rather than saving the distance from the detection to annotation as zero. As mentioned in several places on the forum, while it is possible to invert an annotation in order to measure the distance to annotations (2D) for detections within a particular annotation, it requires some coding and is a bit awkward. As inverting the annotation no longer inherits the class of the inverted annotation, that also adds an extra step that might be difficult for newer users. ; Finally, large complex annotations may stress some systems to invert, so it would be convenient to avoid this step if possible. ; Current workaround: https://forum.image.sc/t/distance-of-detections-to-border-of-parent-annotation/70199/9?u=research_associate; Some other instances of this coming up; https://forum.image.sc/t/need-help-with-troubleshooting-distance-to-annotation-calculation/48051/4?u=research_associate; https://forum.image.sc/t/qupath-distance-to-annotation-border-from-both-inside-and-outside-of-the-annotation/40643/3?u=research_associate; https://forum.image.sc/t/qupath-distance-between-annotations/47960/7?u=research_associate. Hopefully this could be as simple as replacing the logic that sets inside values to zero with multiplying by negative one, but I'm not sure. https://github.com/qupath/qupath/blob/053efeff6d941e7a73beab5445cf0d6238ed97b7/qupath-core/src/main/java/qupath/lib/analysis/DistanceTools.java#L187; I didn't see anything obvious, so guessing it has to do with how the geometries are being used. Additionally, it would probably be nice if it ""smartly"" took into account TMA core borders as well. Though _that_ would probably be a bit more complicated.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1032:107,detect,detection,107,https://qupath.github.io,https://github.com/qupath/qupath/issues/1032,4,"['avoid', 'detect']","['avoid', 'detection', 'detections', 'detections-to-border-of-parent-annotation']"
Safety,"Can you explain in more detail what would need to change to support this?. I don't have much experience of OMERO tags, but it sounds like what you're suggesting could either be handled entirely in the OMERO extension already (using QuPath's existing metadata support for project entries), or else could risk projects becoming more OMERO-specific (which I'd like to avoid).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1289#issuecomment-1675769245:303,risk,risk,303,https://qupath.github.io,https://github.com/qupath/qupath/issues/1289#issuecomment-1675769245,2,"['avoid', 'risk']","['avoid', 'risk']"
Safety,Can't load a detection classifier,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/402:13,detect,detection,13,https://qupath.github.io,https://github.com/qupath/qupath/issues/402,1,['detect'],['detection']
Safety,Cell Detection Error On Large TIF File,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/69:5,Detect,Detection,5,https://qupath.github.io,https://github.com/qupath/qupath/issues/69,1,['Detect'],['Detection']
Safety,Cell Detection Failing and Corrupting Data Files,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/174:5,Detect,Detection,5,https://qupath.github.io,https://github.com/qupath/qupath/issues/174,1,['Detect'],['Detection']
Safety,Cell detection and tissue detection not compatible at same level of hierarchy,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/60:5,detect,detection,5,https://qupath.github.io,https://github.com/qupath/qupath/issues/60,2,['detect'],['detection']
Safety,Cell detection background,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1098:5,detect,detection,5,https://qupath.github.io,https://github.com/qupath/qupath/pull/1098,1,['detect'],['detection']
Safety,Cell detection does not work probably because of high DAB background. Help me please?,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/305:5,detect,detection,5,https://qupath.github.io,https://github.com/qupath/qupath/issues/305,1,['detect'],['detection']
Safety,Cell detection only partially supports fluorescence images,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/14:5,detect,detection,5,https://qupath.github.io,https://github.com/qupath/qupath/issues/14,1,['detect'],['detection']
Safety,"Cell detection or Positive Cell detection at the top of the same _Analysis->Cell Analysis_ menu should work. . Set your first color vector to match the red stain (for nuclear detection) and the second stain to blue (for you X-Gal). More information on how to do that here:; https://github.com/qupath/qupath/wiki/Preprocessing; https://www.youtube.com/watch?v=IpCDnPnFvDc&t=7s. Either way you do it, you can use the first color vector to detect nuclei, and then the second color vector to judge whether the cells are positive or negative for X-Gal.; I would recommend leaving the names of the color vectors in the Image tab as they are and using Positive Cell Detection, with Hematoxylin OD (having been repurposed to ""red"") as the detection image, and Nucleus DAB OD (now ""blue"") mean as the Score Compartment. I expect it would come out looking something like this, though the file you included is the data file, not the image file, so I don't have a full image to work with. QPDATA files only include the annotation, detections, and other drawn on objects.; ![image](https://user-images.githubusercontent.com/23145209/49988566-158ce800-ff2c-11e8-8c57-cdab949e4ae0.png). Once you choose your threshold, you should be good to go. I think he might be considering removing Watershed nucleus detection (experimental) as it is. Cheers",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/250#issuecomment-447236061:5,detect,detection,5,https://qupath.github.io,https://github.com/qupath/qupath/issues/250#issuecomment-447236061,8,"['Detect', 'detect']","['Detection', 'detect', 'detection', 'detections']"
Safety,Cell detection over tiled regions fails on some images,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/459:5,detect,detection,5,https://qupath.github.io,https://github.com/qupath/qupath/issues/459,1,['detect'],['detection']
Safety,Cell detection using 'Hematoxylin' always assumes it is the first stain,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/878:5,detect,detection,5,https://qupath.github.io,https://github.com/qupath/qupath/issues/878,1,['detect'],['detection']
Safety,Change detection line thickness when upsampling,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1623:7,detect,detection,7,https://qupath.github.io,https://github.com/qupath/qupath/pull/1623,1,['detect'],['detection']
Safety,"Changelog:; ------------; * Completely revised projects; * New image importer, supports drag & drop for multiple images; * Specify image rotation on import; * Automatically check URIs when opening projects, attempt to resolve relative paths; * Fix broken paths through the user interface (rather than editing the .qpproj file manually); * Use the same image reader each time (e.g. OpenSlide, Bio-Formats); * Right-click in the project pane to add metadata for one or more selected images; * Store custom server metadata (double-click pixel sizes under the 'Image' tab to fix them); * Add support for more complex images via ServerBuilders (useful in the future...); * Adjust project pane thumbnail size in preferences; * Allow duplicate images in projects; * Viewer updates; * Improved touch gesture support; * New, perceptually uniform color tables for measurement maps; * Fixed bug with right-click being unresponsive on some Mac laptops; * Smoother Brush tool behavior; * Wand tool now pressure-sensitive (for supported graphics tablets only); * Revised pixel classifier features; * New Hessian features; * New 3D support; * Improved JSON serialization, via GsonTools class; * ROIs and PathObjects as GeoJSON; * Most ImageServers (via ServerBuilders); * Common OpenCV classes (Mat, StatModel); * Bio-Formats updates; * Update library to v6.2.0; * Improved multithreading and OME-TIFF export; * Avoid creating .bfmemo files in image directories (specify in preferences if/where you want them); * Miscellaneous changes; * Updated to JDK 12.0.2; * Default max memory to 50% available (previously 25%); * New .msi installer for Windows, optional 'debug' startup with console; * Improved 'Send to ImageJ' command, supports z-stacks & extra customization; * Major refactoring (warning, older scripts may not work!); * Added many javadocs for core modules; * Lots of bugs fixed! (No doubt some added...)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/342:1397,Avoid,Avoid,1397,https://qupath.github.io,https://github.com/qupath/qupath/pull/342,1,['Avoid'],['Avoid']
Safety,"Changelog:; ------------; * Positive cell detection supports different stainings (including multiplexed images); * Cell detection & the intensity measurement command use channel names rather than numbers; * (Note that channel order is still important when scripting the intensity measurement command); * Big changes to memory management; * Improved tile caching (using Guava) & more control; * Specify the proportion of available memory for tile caching in the preferences; * New options when importing images to a project; * 'Pyramidalize' large, single-resolution images; * Rotate images on import (90 degree increments); * Specify the image reading library (e.g. Bio-Formats, OpenSlide); * Improved resolution of paths to missing or moved images within projects; * New 'Search' button allows recursive search for missing images; * Improved 'Measurement map' behavior and colormap support; * Specify line cap when expanding line annotations; * For why this matters, see https://github.com/qupath/qupath/issues/228#issuecomment-518552859; * 'Send region to ImageJ' improvements; * Only send objects within the field of view as an overlay; * Set lookup tables where possible; * Support arbitrary small regions (can now send a 1x1 pixel image); * New preferences to specify viewer font size (scalebar, location text); * Code formatting is asynchronous (causes small delay, but reduces errors); * Project scripts are back... accessible from the 'Automate' menu; * More bugs fixed and others improvements, including; * Exceptions when generating some viewer/window snapshots; * Resolving relative URIs on Mac/Linux - https://github.com/qupath/qupath/issues/346; * SLIC bug - https://github.com/qupath/qupath/issues/344",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/353:42,detect,detection,42,https://qupath.github.io,https://github.com/qupath/qupath/pull/353,2,['detect'],['detection']
Safety,"Classifiers trained in v0.1.2 aren't compatible with v0.2.0. Some of the many changes (e.g. to cell detection) mean that the features calculated would not be identical, and so results are expected to differ. Classifiers should really only be used in the same version of the software for which they were trained.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/402#issuecomment-588430406:100,detect,detection,100,https://qupath.github.io,https://github.com/qupath/qupath/issues/402#issuecomment-588430406,1,['detect'],['detection']
Safety,"Closing this as it has gone quiet... and because I think the days of subcellular detection are/should be numbered. There will be no further changes for v0.2.0, and in future versions I think the command ought to be replaced rather than incrementally improved. From v0.2.0-m12 it should also now be possible to add object measurements based upon pixel classifications to cells. This has the aim of reducing the frequency with which subcellular detections are required.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/304#issuecomment-632234331:81,detect,detection,81,https://qupath.github.io,https://github.com/qupath/qupath/issues/304#issuecomment-632234331,2,['detect'],"['detection', 'detections']"
Safety,"Closing this because it has been quiet, and because the original issue should be fixed in the latest release. Positioning scenes in 2D remains a possible future improvement, but is a little tricky/risky because of uncertainty in how exactly to interpret position information consistently across formats. See https://forum.image.sc/t/improve-bio-formats-image-position-metadata/30770",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/337#issuecomment-632241436:197,risk,risky,197,https://qupath.github.io,https://github.com/qupath/qupath/issues/337#issuecomment-632241436,1,['risk'],['risky']
Safety,Closing this because there are no known issues in QuPath related to judicious use of validity checks (and adding many more checks 'to be on the safe side' could harm performance considerably).,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/527#issuecomment-1732338888:144,safe,safe,144,https://qupath.github.io,https://github.com/qupath/qupath/issues/527#issuecomment-1732338888,1,['safe'],['safe']
Safety,"Closing this issue after discussion with @melvingelbard... it's not something we plan to do, and would be very apprehensive about including the change even if someone else implemented it. As I mentioned above, the consistency thing has some (partly historic) reasons. We only started adding spinners recently; the underlying rationale has been that sliders are used when the range is known in advance, spinners are used when it's not... New commands will endeavour to apply this rule more consistently, and old commands will either be either removed or updated. Regarding spinners and mouse wheel input, I think this really would need to be implemented in JavaFX directly. There are ostensibly easy ways to add support by attaching a scroll listener, in my experience to date this can open a whole can of worms... basically, scroll events can differ a lot depending upon the input device/platform (not to mention 'natural' scrolling in some cases, which can flip the direction). Therefore I think the risk is too high of creating something that inadvertently makes the user experience *worse* for many, and we would have no way to test all the relevant platforms to check this. I presume the JavaFX developers have reasons for not implementing this directly yet - perhaps related to the reason I give. But in any case, they would have access to potentially more platform-specific information to enable a robust implementation. For these reasons, I'm afraid I don't think we can/should act on this feature request.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/495#issuecomment-641183465:1001,risk,risk,1001,https://qupath.github.io,https://github.com/qupath/qupath/issues/495#issuecomment-641183465,1,['risk'],['risk']
Safety,"Closing this issue because I'm afraid I don't see it as possible - at least not with the current cell detection. It might be more feasible in a future incarnation, but that may need to be radically different (e.g. like how the simple threshold in [v0.2.0-m5](https://github.com/qupath/qupath/releases/tag/v0.2.0-m5) can potentially replace simple tissue detection). Of course, feel free to prove me wrong with a pull request :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/327#issuecomment-549053462:102,detect,detection,102,https://qupath.github.io,https://github.com/qupath/qupath/issues/327#issuecomment-549053462,2,['detect'],['detection']
Safety,"Complete rewrite of `build.gradle` in the hope of something that less resembles an explosion in a a curly brackets factory. Now uses `buildSrc` directory to isolate shared conventions, with most of the packaging logic moved to a new `qupath-app` subproject. For basic use to create an image; ```bash; ./gradlew clean jpackage`; ```. The type of package can be specified as one of `[image, msi, exe, dmg, pkg, deb, rpm, installer, all]`. Not all are supported on all platforms, and `installer` simply selects a platform-dependent installer (although this may fail for Linux...). The syntax is; ```bash; gradlew jpackage -P qupath.package=installer -P git-commit=true; ```; where `git-commit` requests that the last git commit is included in jar files for reference. The improved structure means that more tasks work as they should, so that; ```bash; ./gradlew tasks; ```; finally becomes meaningful. **Native libraries** are extracted at an early stage, and put into `build/natives`, which means that this is a good choice as a working directory when running from an IDE. It is also used by `gradlew run`. Several other small changes were made to ensure Java 11 compatibility (change to a use of `FileSystems`) and to remove `&` from Javadocs. ## Important. The QuPath version is now set in `settings.gradle`, and this is added to the `resources` of `qupath-core` - thereby making it available through `GeneralTools`. This should be more reliable than depending upon a `VERSION` file in the main repo, particularly when launching QuPath with different working directories. Relatedly, the project logic has been updated; previously it would fail completely if no version was found within a project JSON file, in the assumption it originated from v0.1.2 or earlier. Now it will make an effort to recover.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/738:1793,recover,recover,1793,https://qupath.github.io,https://github.com/qupath/qupath/pull/738,1,['recover'],['recover']
Safety,"Complete rewrite of `build.gradle` in the hope of something that less resembles an explosion in a a curly brackets factory. Now uses `buildSrc` directory to isolate shared conventions, with most of the packaging logic moved to a new `qupath-app` subproject. For basic use to create an image; ```bash; ./gradlew clean jpackage`; ```. The type of package can be specified as one of `[image, msi, exe, dmg, pkg, deb, rpm, installer, all]`. Not all are supported on all platforms, and `installer` simply selects a platform-dependent installer (although this may fail for Linux...). The syntax is; ```bash; gradlew jpackage -P qupath.package=installer -P git-commit=true; ```; where `git-commit` requests that the last git commit is included in jar files for reference. The improved structure means that more tasks work as they should, so that; ```bash; ./gradlew tasks; ```; finally becomes meaningful. Native libraries are extracted at an early stage, and put into `build/natives`, which means that this is a good choice as a working directory when running from an IDE. It is also used by `gradlew run`. Several other small changes were made to ensure Java 11 compatibility (change to a use of `FileSystems`) and to remove `&` from Javadocs. ## Important. The QuPath version is now set in `settings.gradle`, and this is added to the `resources` of `qupath-core` - thereby making it available through `GeneralTools`. This should be more reliable than depending upon a `VERSION` file in the main repo, particularly when launching QuPath with different working directories. Relatedly, the project logic has been updated; previously it would fail completely if no version was found within a project JSON file, in the assumption it originated from v0.1.2 or earlier. Now it will make an effort to recover.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/736:1789,recover,recover,1789,https://qupath.github.io,https://github.com/qupath/qupath/pull/736,1,['recover'],['recover']
Safety,"Continued to work on this, and now the PR addresses both. * https://github.com/qupath/qupath/issues/1085; * https://github.com/qupath/qupath/issues/1087. **Please see the links for more detail. It's a fairly substantial change, so feedback would be very welcome!**. To see it in action, here is a script for multiplex classification - written for the famous [LuCa image](https://qupath.readthedocs.io/en/stable/docs/intro/acknowledgements.html) after running cell detection. The choice of threshold is dodgy, but the point is to show how this PR changes the way the scripter can interact with measurements and classifications, using a (I think) far simpler and more intuitive syntax, and fewer lines of code. ```groovy; // Get the server & cells; def server = getCurrentServer(); def cells = getCellObjects(). // Reset our classifications; cells.each { cell -> cell.resetPathClass() }. // Loop through channels; for (def channel in server.getMetadata().getChannels()) {; // Extract the channel name; def channelName = channel.name; ; // Skip some channels; if ('DAPI' in channelName || 'Autofluorescence' in channelName); continue; ; // Create a classification name from the channel; // Here, I take the first bit up until any whitespace; def classificationName = channelName.split()[0]. // Define the measurement we want; def measurementName = ""Cell: $channelName mean""; ; // Calculate some threshold from the measurement; // Here, just the mean; double threshold = cells.measurements[measurementName].average(); ; // Append a classification to all the cells above the threshold; cells.each { cell ->; if (cell.measurements[measurementName] > threshold); cell.classifications += [classificationName]; }; }. // Figure update (could do this automatically...); fireHierarchyUpdate(); ```. Closer inspection reveals a few Groovy tricks at work:. * `List.each { }` as a shorter alternative to for loops; * Avoid explicitly calling getters (e.g. `channel.name` rather than `channel.getName()`, `cell.measur",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1094#issuecomment-1289456235:464,detect,detection,464,https://qupath.github.io,https://github.com/qupath/qupath/pull/1094#issuecomment-1289456235,1,['detect'],['detection']
Safety,"Converting arbitrary shapes to Geometry objects has proven horribly difficult, although m9 should be better than any previous version. From your example I can see a way to improve the conversion a bit in the next release. New complex annotations should be Geometry objects immediately, avoiding the need for the conversion later. In the meantime, this script works for me to create a slightly simplified shape that can be converted to a valid Geometry for your example:; ```groovy; def file = new File('/path/to/broken_area_roi.ser'). def obj; file.withObjectInputStream {; obj = it.readObject(); }. obj = ROIs.createAreaROI(obj.getShape(), obj.getImagePlane()); roi = qupath.lib.roi.ShapeSimplifier.simplifyShape(obj, 0.5). println roi.getGeometry(); println roi.getGeometry().isValid(). println obj.getArea(); println roi.getGeometry().getArea(); ```; The area has been changed slightly, but not by much. Perhaps this, or the *Objects &rarr; Annotations... &rarr; Simplify shape* command might help resolve the conversion for you?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/429#issuecomment-607483340:286,avoid,avoiding,286,https://qupath.github.io,https://github.com/qupath/qupath/issues/429#issuecomment-607483340,1,['avoid'],['avoiding']
Safety,"Copy and paste from: https://forum.image.sc/t/semi-random-script-errors-when-adding-removing-objects/53617. I am using a script to demonstrate both removing and adding objects, ideally for new coders (dun dun dunnn). The setting is a small rectangular annotation with cells generated inside of it, which is also divided into tumor/stroma annotations.; image. The purpose of the script is to remove the cells in one area, run an analysis that adds measurements based only on the cells in the second area, and then restore the cells that were removed. ```; //Load the LuCa object data before running!; resolveHierarchy() //let's make sure all of the cells are child objects of their annotations!; tumorAnnos = getAnnotationObjects().findAll{it.getPathClass() == getPathClass(""Tumor"")}; tumorCells = getCellObjects().findAll{it.getParent().getPathClass() == getPathClass(""Tumor"")}. //Remove the tumor annotations and their cells; removeObjects(tumorAnnos,false); removeObjects(tumorCells,false); //Analyze->Spatial analysis->Detect centroid distances 2D. detectionCentroidDistances(true); //Add everything back, and make sure the hierarchy is resolved!; addObjects(tumorAnnos); addObjects(tumorCells); resolveHierarchy(); ```. The code works most of the time. Probably 70%? I lack my usual variety of computers to test out whether it is based on my computer - but I do have a project file hosted online I can make available to run the test. Errors include: Null pointer exception popup in the lower right,. INFO: Starting script at Sat Jun 05 20:54:28 CDT 2021; WARN: Resolving hierarchy that contains 3 annotations and 1236 detections - this may be slow!; ERROR: QuPath exception; WARN: Resolving hierarchy that contains 3 annotations and 1236 detections - this may be slow!; INFO: Script run time: 0.25 seconds; The log file is not hugely informative on that one. Alternatively, I sometimes see a TMA core error. ```; ERROR: QuPath exception: Cannot invoke ""qupath.lib.objects.PathObject.isTMACore()"" b",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/744:1022,Detect,Detect,1022,https://qupath.github.io,https://github.com/qupath/qupath/issues/744,1,['Detect'],['Detect']
Safety,"Could you post your workflow script? Farthest tab on the right (Workflow) should have a ""Create Script"" at the bottom which you can copy and paste here. I suppose a more specific question would be which Cell Detection you were using to get this result. (Cell detection+membrane comes to mind as having some odd behavior on certain types of background).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/80#issuecomment-305264373:208,Detect,Detection,208,https://qupath.github.io,https://github.com/qupath/qupath/issues/80#issuecomment-305264373,2,"['Detect', 'detect']","['Detection', 'detection']"
Safety,"Currently, *Classify &rarr; Create detection classifier* has the option to immediately sub-classify detections according to intensity - but *only* if these are classified as *'Tumor'*. This is a result of the original primary application of QuPath being in the scoring of biomarkers selectively within a tumor cell population (e.g. to calculate H-scores, or Ki67 labelling indices). Currently, classifying (or sub-classifying) detections in a general way according to staining intensity is only possibly by writing a script to do so. It would be helpful to be able to do so more easily, and in a scriptable manner (i.e. in a way that gets logged in the workflow).",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/16:35,detect,detection,35,https://qupath.github.io,https://github.com/qupath/qupath/issues/16,3,['detect'],"['detection', 'detections']"
Safety,"Currently, you can do that via the workflow tab - assuming you've run it once before on that image. Or you can leave the window open when switching images - assuming they are the same type... bad things may happen if not, e.g. fluorescence to brightfield. Although that led me to see that bad things happen with this PR when the image type changes: QuPath isn't able to adjust and update the available options. So if I run cell detection for brightfield, then I can't use it for fluorescence within that QuPath session - because it will be stuck with the same available channels the first time it was run.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1560#issuecomment-2255814318:428,detect,detection,428,https://qupath.github.io,https://github.com/qupath/qupath/pull/1560#issuecomment-2255814318,1,['detect'],['detection']
Safety,"Dear @Svidro ,. Many thanks for your suggestions. I am extremely sorry as I did not attach the original image to my previous post. I thought that you got everything with enclosed QPDATA files. I, here, give a ****download link** (below) of the original image.**; https://my.pcloud.com/publink/show?code=XZN1HC7ZCU8ImbiEUGShoj457lSYa7TCxtEy. **I have tried the following things as you suggested but could come up of the following issues:**. 1. I could not switch in-between diffient channels of colors as shown (comfortably) in the video. In other words, I could not check the _color deconvolution_ before estimating the vectors . 2. I wanted to get separate values for the number of cells with each color. But looks like, QuPath gives as a total number. Having them, is very important for me as . 3. In most cases, after _running_ the Positive Cell Detection, even some blue cells are not encircled, letting me assume that they were not counted probably. Image below:; ![capture](https://user-images.githubusercontent.com/44507241/50253977-ea821880-03b1-11e9-826e-bb092ba9b087.JPG). I admit that I am a newbie to QuPath. I apologize if you see these problems are because of very silly mistakes. . Many thanks for helping me out!; sincerely,; Partha",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/250#issuecomment-448783885:849,Detect,Detection,849,https://qupath.github.io,https://github.com/qupath/qupath/issues/250#issuecomment-448783885,1,['Detect'],['Detection']
Safety,"Dear @petebankhead . Hope this finds you well. I am back again for your input on an issue. First, let me tell briefly about **my task with the QuPath**. I stained slides of different mouse tissues. The main stain was X-gal stain (blue) to satin positive/expressed cells, and I co-stained the same section with Neutral red (red) to stain nuclei. Therefore, I have only two colours to play with. Overall, in a particular region (or, annotation) in those sections, I need to figure out what is the percentage of the blue signals wrt red signals. **Currently,** after annotating a region, I am mentioning QuPath to fetch me the two different signals based on the threshold chosen. Higher threshold values (say, 0.40) helped me to select blue signals, and low threshold (0.08) helped me to select both red and blue to denote the overall number of cells in that region (with all the other default settings as fixed). Till now everything was fine. **Problem is that** some nuclei are stained too dark, and they also show up in high threshold values along with blue signals, accounting for a high, unreal figure for positive signals. I assume the darker red nuclei have an overlapped intensities to the blue signals. **My question** to you: Is there any way to discriminate these cells based on the pixel colour, NOT the intensity of the colour so that I can avoid the artefacts? . Please let me know if you need any further clarification. . Many thanks in advance for your suggestion. Sincerely,; Partha. **Here is the dropbox link to my image file:**; https://www.dropbox.com/s/vz8e0jssrr7ur2w/Image%20file.qpdata?dl=0. **And, I show my procedure pictorially here:**; [procedure.pdf](https://github.com/qupath/qupath/files/2678866/procedure.pdf)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/250:1351,avoid,avoid,1351,https://qupath.github.io,https://github.com/qupath/qupath/issues/250,1,['avoid'],['avoid']
Safety,"Dear All,. Having 2 annotations, how could I perform the cell detection from a script on a particular annotation:; The create command for script gave me the following line:. `runPlugin('qupath.imagej.detect.nuclei.WatershedCellDetection', '{""detectionImageFluorescence"": 1, ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 100.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}');`. This command require to select annotation in advance.; I am aware I can add the line :. `selectAnnotations();`. But that's select **all** the annotation, when I would like to perform the cell detection on only **1** specific annotation. How could I perform that?. Best,",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/116:62,detect,detection,62,https://qupath.github.io,https://github.com/qupath/qupath/issues/116,4,['detect'],"['detect', 'detection', 'detectionImageFluorescence']"
Safety,"Dear All,. I am trying to perform analysis on multiple image (CZI files) containing multiple scene.; I created a project and loaded the 2 files, so from the interface, it looks like that:; ![qpath_multiple_image_multiple_scene_01](https://user-images.githubusercontent.com/1775952/30912322-60af88da-a38c-11e7-9c5f-7cf53aabd4fb.png). I ran the following script for 2 czi files containing multiple scene in order to detect the tissue:; ```setImageType('BRIGHTFIELD_H_DAB');; runPlugin('qupath.imagej.detect.tissue.SimpleTissueDetection2', '{""threshold"": 200, ""requestedPixelSizeMicrons"": 5.0, ""minAreaMicrons"": 10000.0, ""maxHoleAreaMicrons"": 1000.0, ""darkBackground"": false, ""smoothImage"": false, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; ```. It works, it looks the result is saved using the scene name, so in my case, for example, scene 0, only one ROI is saved for the 2 scenes 0:; ![qpath_multiple_image_multiple_scene](https://user-images.githubusercontent.com/1775952/30912398-9f537588-a38c-11e7-8b41-44454126f5eb.png). and:; ![image](https://user-images.githubusercontent.com/1775952/30912429-c32073e4-a38c-11e7-9158-d98fdd48d230.png). So it looks like the ROI is wrongly set . . Best,; Benjamin",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/103:414,detect,detect,414,https://qupath.github.io,https://github.com/qupath/qupath/issues/103,2,['detect'],['detect']
Safety,"Dear All,. I was analyzing a fluorescent tissue with 4 channels and after having performed Tissue detection followed by Watershed Cell detection, I realized that the detection measurement table doesn't contain the intensity features of my 4th channel.; It looks like by default it is done for 3 channels maximum.; Is there a way to by pass this limitation?. Using the Compute intensity features is not an option since it will not distinguished cell from nucleus from cytoplasm but measure on the whole ROI. I attached a small sample (an ome.tif file) : [Triple_Stained_Tumor_subset_07_small.ome.tif.zip](https://github.com/qupath/qupath/files/1902098/Triple_Stained_Tumor_subset_07_small.ome.tif.zip). The following has been performed:; `; setImageType('FLUORESCENCE');; runPlugin('qupath.imagej.detect.tissue.SimpleTissueDetection2', '{""threshold"": 4, ""requestedPixelSizeMicrons"": 5.0, ""minAreaMicrons"": 100000.0, ""maxHoleAreaMicrons"": 1000000.0, ""darkBackground"": true, ""smoothImage"": true, ""medianCleanup"": false, ""dilateBoundaries"": false, ""smoothCoordinates"": false, ""excludeOnBoundary"": false, ""singleAnnotation"": true}');; selectAnnotations();; runPlugin('qupath.imagej.detect.nuclei.WatershedCellDetection', '{""detectionImageFluorescence"": 1, ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 50.0, ""medianRadiusMicrons"": 5.0, ""sigmaMicrons"": 0.5, ""minAreaMicrons"": 100.0, ""maxAreaMicrons"": 2000.0, ""threshold"": 10.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 10.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}');; `. Thanks",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/164:98,detect,detection,98,https://qupath.github.io,https://github.com/qupath/qupath/issues/164,6,['detect'],"['detect', 'detection', 'detectionImageFluorescence']"
Safety,"Dear Arnulf,. Certainly I'm agreed with you on the benefits of fluorescence for image analysis. I intended that the cell detection should work with fluorescence, but since I have primarily been working with brightfield until now, this was not taken very far. Success with fluorescence cell detection previously relied upon several undocumented tricks in terms of choosing parameters, and the good fortune of having your nuclear counterstain in the first channel. This morning I tried to address this, and hopefully you find it functions better in [v0.0.5](https://github.com/qupath/qupath/releases/tag/v0.0.5), which I've just uploaded. An example image from a fluorescence microscope is shown below. ![qupath_fluorescence_cells](https://cloud.githubusercontent.com/assets/4690904/20115597/cf2682ae-a5f0-11e6-88c9-82298e3cd1ea.jpg). A few important points (which will eventually be documented on the Wiki):; - QuPath tries to identify brightfield and fluorescence images when they are opened (although you can ask it not to under _Auto-estimate image type on opening_ option in the _Preferences_); if it gets it wrong, you will need to double-click the `Image type` in the _Image_ tab to set this manually to fluorescence.; - The `Image type` needs to be set before running the _Cell detection_ command, to make sure that the right options are displayed; - The _Threshold_ option under _Intensity parameters_ will be important, and will likely need to be adjusted... the default is simply selected for all images of that type and bit-depth, and not based on the information present in the image; - If you are working with images at a relatively low resolution (such as in the screenshot I showed), it can be helpful to decrease the _Detection line thickness_ parameter in the _Preferences_ so that the cell or nucleus outlines do not obscure your view too much.; - The _Brightness/Contrast_ options currently misbehave somewhat with fluorescence. If you want to show/hide specific channels, it's actua",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/12#issuecomment-259250203:121,detect,detection,121,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-259250203,2,['detect'],['detection']
Safety,"Dear Pete and Svidro,. Thank you very much for your support, I really do appreciate it!; Pete, thank you for the link to the other issue, I followed the instructions there and renamed the detections according to the annotation (which I also renamed to have a unique index) they are in. Svidro, thanks a lot for the script! I tried doing exactly this and failed because of not knowing enough groovy and your script is very educational (apart from doing exactly what I need) in that sense. Thanks again!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/234#issuecomment-432962423:188,detect,detections,188,https://qupath.github.io,https://github.com/qupath/qupath/issues/234#issuecomment-432962423,1,['detect'],['detections']
Safety,"Dear Pete, ; Thank you so so much for your quick and detailed answer! I appreciate your help very much!! Too bad there is no direct way to continue training a classifier once it has been saved and closed. I am sure however that your suggested solutions will work fine in my case. Thank you! As for your answer concerning my second question I am unsure how to create a classifier that would work fine for all TMA cores in one slide as the immunecells in core A look very similar to the tumor cells in core B for example (so when I train the classifier it either works for well for core A or B). Also the tumor cells differ a lot in appearance from core to core. I understand that using the same classifier for the entire slide or better all slides in one project would be a more elegant solution but I don´t see how this should work in my case. I understand from your answer to my first question that even if I created a new classifier for each core it would automatically change the detections in another core on the same slide previously made using another classifier....Do you have any suggestions how to address this problem? I should also use this opportunity to point out how well quPath works in general! Great software!; Thank you so much for your help and support!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/57#issuecomment-288756351:983,detect,detections,983,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288756351,1,['detect'],['detections']
Safety,"Dear Pete,. I was wandering if we could use qupath to perform pixel classification, similar to what exist with weka plugin for ImageJ. And if yes, is there a tutorial for that. I have to detect adypocyte and did it with success with ImageJ/Weka but it require to export the slide to a lower resolution so ImageJ can open the image. I would be delighted to use Qupath for that if it was possible.; Benjamin",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/56:187,detect,detect,187,https://qupath.github.io,https://github.com/qupath/qupath/issues/56,1,['detect'],['detect']
Safety,"Dear Pete,. Is it possible to export the MEAN values of all 40 parameters of detection measurements by class or region? Currently, we can extract the values only on a single cell level. ; A workaround I see is to extract the mean in the ""show histogram"" section and stepwise clicking through all parameters. However, this is quite laborious for a TMA with many cores. . Best regards; Mark",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/299:77,detect,detection,77,https://qupath.github.io,https://github.com/qupath/qupath/issues/299,1,['detect'],['detection']
Safety,"Dear all, . I observed an artefact in simple tissue detection on ndpi and tiffs. About others, I do not know at the moment. ; It looks like that: ; ![grafik](https://user-images.githubusercontent.com/16352785/33805531-c48d2534-ddba-11e7-91b9-275012bf50e8.png). I used the white channel, because I do not want to show the image content. ; But the cornders are not white. They contain tissue! . Does somebody have an idea why it is like that?. Best; David",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/124:52,detect,detection,52,https://qupath.github.io,https://github.com/qupath/qupath/issues/124,1,['detect'],['detection']
Safety,"Dear all,; Many thanks for providing such a great tool for free!. Is it possible for each identified/detected object from an original input image to save all objects as sub-images via individual image files. My goal is to mark all nuclei in a FISH image and then export each nuclei as separate file. The saving needs to be done in one step.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/118:101,detect,detected,101,https://qupath.github.io,https://github.com/qupath/qupath/issues/118,1,['detect'],['detected']
Safety,"Dear qupath author,; i met a problem in qp v0.4 software as below:; In youtube web ur vedio shows the function ""create detection classifier"", ; <img width=""579"" alt=""9489b4d45da04b74f3c20854bf2d9d4"" src=""https://github.com/qupath/qupath/assets/70978097/eb076397-4e1c-4581-9fec-3bbaf99cb945"">; but i CANNOT find it in my qu-path V0.4.; ![35e753143f4f4812de29d22fa32c218](https://github.com/qupath/qupath/assets/70978097/4f749806-deb0-4f68-a75b-9b0ee0325905); How can i fix it?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1269:119,detect,detection,119,https://qupath.github.io,https://github.com/qupath/qupath/issues/1269,1,['detect'],['detection']
Safety,"Depending on the size, I would usually do something like that by sending a downsampled whole image to ImageJ to create and return a ""tissue annotation."" Then, tile that first annotation into further annotation tiles, and send each tile to ImageJ at full resolution. Use only your channel of interest to return detection objects for areas over your threshold. Removing all of the tile annotations would then leave you with your initial ""full"" annotation and a whole list of detection objects, which you could sum the area of and compare to the full annotation for a percent positive. The whole thing should be script-able. If you want to look at methods though or get help with scripting, I would recommend the [Google Group forum](https://groups.google.com/forum/#!forum/qupath-users).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/187#issuecomment-407093698:310,detect,detection,310,https://qupath.github.io,https://github.com/qupath/qupath/issues/187#issuecomment-407093698,2,['detect'],['detection']
Safety,Detect centroid distances 2D doesn't work on different planes of a z-stack,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/696:0,Detect,Detect,0,https://qupath.github.io,https://github.com/qupath/qupath/issues/696,1,['Detect'],['Detect']
Safety,Detection Centroid Distance interacts awkwardly with multiplexing,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/405:0,Detect,Detection,0,https://qupath.github.io,https://github.com/qupath/qupath/issues/405,1,['Detect'],['Detection']
Safety,Detection Centroid Distances does not work across detection types (Detections vs Cells),MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1550:0,Detect,Detection,0,https://qupath.github.io,https://github.com/qupath/qupath/issues/1550,3,"['Detect', 'detect']","['Detection', 'Detections', 'detection']"
Safety,"Detections could sometimes not appear in the viewer.; This was caused by an overly-enthusiastic attempted optimization, introduced in v0.6.0 pre-releases.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1680:0,Detect,Detections,0,https://qupath.github.io,https://github.com/qupath/qupath/pull/1680,1,['Detect'],['Detections']
Safety,Did that happen once or does it happen reproducibly? My first guess is that somehow the detections with thinner lines are inside (duplicated) detections. I don't know why.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/259#issuecomment-457707115:88,detect,detections,88,https://qupath.github.io,https://github.com/qupath/qupath/issues/259#issuecomment-457707115,2,['detect'],['detections']
Safety,Different cell detection result categories.,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/52:15,detect,detection,15,https://qupath.github.io,https://github.com/qupath/qupath/issues/52,1,['detect'],['detection']
Safety,Distance of detections to border of parent annotation,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1033:12,detect,detections,12,https://qupath.github.io,https://github.com/qupath/qupath/issues/1033,1,['detect'],['detections']
Safety,"DnnModel is now the main class, supported by BlobFunction and PredictionFunction.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/800:62,Predict,PredictionFunction,62,https://qupath.github.io,https://github.com/qupath/qupath/pull/800,1,['Predict'],['PredictionFunction']
Safety,"Does the View->Show log give you any information when this happens? . I am not sure in your case, but if you are running the full script I wonder if it isn't the cell detection rather than the classifier that is erroring out. I don't believe the classifier runs in tiles, it should apply to the entire image at once, and only after the cell detection part of the script is completed. Memory might be an issue there, though there used to be some possible edge cases with very small tiles (where the tile clips the edge of the tissue and a very tiny region is generated) causing problems. I usually was able to get around that by changing the Simple Tissue detection settings, as it was incredibly rare. The logs should help determine what is happening. You said randomly, so this means you can't reproduce it on any single slide running it twice? Are the images QuPath is accessing stored across a potentially busy or slow network?. As an aside, you are running both a classifier in the cell detection (Positive cell detection with three thresholds), and again with a trained classifier?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/130#issuecomment-355477217:167,detect,detection,167,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355477217,5,['detect'],['detection']
Safety,"Does the double-clicking work for you?; Since this is intended behavior, I'd like to close the issue - but could revisit it if there's a better way to help reviewing annotations while avoiding the old problems with multiple viewers (possibly in v0.3.0, if it is a substantial change).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/502#issuecomment-633196175:184,avoid,avoiding,184,https://qupath.github.io,https://github.com/qupath/qupath/issues/502#issuecomment-633196175,1,['avoid'],['avoiding']
Safety,"Does this help? The script exports annotation measurements and detection measurements into folders inside the project - as .txt file only. They can be imported into MS Excel. ; By Excel Macro you can even automate the .txt import, if you have many slides. . If you need to fuse measurements for many slides, there is also a combine script from Pete. ; The following script works only within projects!. //Script to save annotations results inside a results folder inside the project folder: . import qupath.lib.scripting.QPEx; // Create the output directory, if required; def path = QPEx.buildFilePath(QPEx.PROJECT_BASE_DIR, ""annotation measurements""); QPEx.mkdirs(path). // Get the imageData & server; def imageData = QPEx.getCurrentImageData(); def server = imageData.getServer(); // Get the file name from the current server; def name = server.getShortServerName(); def path2 = buildFilePath(PROJECT_BASE_DIR, ""annotation measurements"", name); saveAnnotationMeasurements(path2 + "".txt""); print('annotation results saved in results folder'). def path3 = QPEx.buildFilePath(QPEx.PROJECT_BASE_DIR, ""detection measurements""); QPEx.mkdirs(path3). def path4 = buildFilePath(PROJECT_BASE_DIR, ""detection measurements"", name); saveDetectionMeasurements(path4 + "".txt""); print('detection results saved in results folder')",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/229#issuecomment-430299780:63,detect,detection,63,https://qupath.github.io,https://github.com/qupath/qupath/issues/229#issuecomment-430299780,4,['detect'],['detection']
Safety,Elongated nuclei not correctly detected,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/231:31,detect,detected,31,https://qupath.github.io,https://github.com/qupath/qupath/issues/231,1,['detect'],['detected']
Safety,Enter coordinates for ROI rectangle and file name to run cell detection from command line,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/90:62,detect,detection,62,https://qupath.github.io,https://github.com/qupath/qupath/issues/90,1,['detect'],['detection']
Safety,Export Detection Measurements per Annotation,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/234:7,Detect,Detection,7,https://qupath.github.io,https://github.com/qupath/qupath/issues/234,1,['Detect'],['Detection']
Safety,Exporting Detection Centroids,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/214:10,Detect,Detection,10,https://qupath.github.io,https://github.com/qupath/qupath/issues/214,1,['Detect'],['Detection']
Safety,Exporting Detection as a labeled image,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/251:10,Detect,Detection,10,https://qupath.github.io,https://github.com/qupath/qupath/issues/251,1,['Detect'],['Detection']
Safety,Fast-red subcellular ISH detection,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/119:25,detect,detection,25,https://qupath.github.io,https://github.com/qupath/qupath/issues/119,1,['detect'],['detection']
Safety,Feature request: Cell Detection nuclear channel mini-viewer,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/327:22,Detect,Detection,22,https://qupath.github.io,https://github.com/qupath/qupath/issues/327,1,['Detect'],['Detection']
Safety,"First of all I would like to say thank you providing such great software for us all to use. With my DAB images it has saved so much time and is a joy to use. However, most of our work is now using fluorescent hamamtsu scans i.e. ndpis files. These are aligned ndpi files. I tried to use the bio-formats extension but this will also not open them. I have successfully got very good detection of DAPI nuclei on the individual dapi scan. What I would like to do is take these nuclei and overlay them on the over channels/images.; I did have some success opening up the qpdata file in notepad++ and changing the file name to a corresponding other channel e.g. FITC but the detection measurements are not recalculated.; So I guess my question is:. Is there a script I can use to import the dapi hierarchy from the dapi.qpdata file and overlay it on the other channels and then subsequently force re-measurement of the features e.g. intensity measures etc?. Thank you so much",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/113:381,detect,detection,381,https://qupath.github.io,https://github.com/qupath/qupath/issues/113,2,['detect'],['detection']
Safety,"First of all, this software is incredible and has made analyzing previously impossible amounts of data almost easy. So thank you!. I am working with large animal brains, DAB IHC stains. The cellular-level detection is pretty straightforward, however, I am trying to get information about staining intensity in the axons of some neurons, which necessitates subcellular level analysis that may be far away from relevant cell bodies. Do you have a way to generate a quantitative measure of pixel intensity across an entire slide? I'm not really concerned with the cell bodies or nuclei at all, more so the relative intensities of the DAB stains between brain slices. . I apologize if this is a foolishly simple question, but I have limited experience working with large slides such as these. Again, thank you for your excellent software!. Nick",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/220:205,detect,detection,205,https://qupath.github.io,https://github.com/qupath/qupath/issues/220,1,['detect'],['detection']
Safety,Fix #1444 by making NumericMeasurementList thread-safe. The synchronized keyword was added on every public or package-private function that was reading or writing to mutable states.,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1466:50,safe,safe,50,https://qupath.github.io,https://github.com/qupath/qupath/pull/1466,1,['safe'],['safe']
Safety,Fix 'Resolve hierarchy' for images with TMA cores and detections,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/541:54,detect,detections,54,https://qupath.github.io,https://github.com/qupath/qupath/pull/541,1,['detect'],['detections']
Safety,Fix bug in cluster counts with subcellular detection,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/792:43,detect,detection,43,https://qupath.github.io,https://github.com/qupath/qupath/pull/792,1,['detect'],['detection']
Safety,Fix exception when trying to open view tracking twice. More refactoring should be done in the future to avoid the use of the static dialog.,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1316:104,avoid,avoid,104,https://qupath.github.io,https://github.com/qupath/qupath/pull/1316,1,['avoid'],['avoid']
Safety,Fix out-of-bounds cell detection,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1607:23,detect,detection,23,https://qupath.github.io,https://github.com/qupath/qupath/pull/1607,1,['detect'],['detection']
Safety,"Fix the behavior in the viewer so that object names aren't shown if the object itself is not shown. Also support showing named detections, not just annotations.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1582:127,detect,detections,127,https://qupath.github.io,https://github.com/qupath/qupath/pull/1582,1,['detect'],['detections']
Safety,Fixed in `v0.0.5` by avoiding throwing a `RuntimeException` unnecessarily. A prompt now appears on Windows instead when the image can't be found.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/9#issuecomment-259219978:21,avoid,avoiding,21,https://qupath.github.io,https://github.com/qupath/qupath/issues/9#issuecomment-259219978,1,['avoid'],['avoiding']
Safety,"Fixes exception thrown when trying to run a script for a project, and avoids catastrophic failure (inability to start up) if a project is specified that isn't available.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/765:70,avoid,avoids,70,https://qupath.github.io,https://github.com/qupath/qupath/pull/765,1,['avoid'],['avoids']
Safety,"Fixes for; * https://github.com/qupath/qupath/issues/1265; * https://github.com/qupath/qupath/issues/1245; * https://github.com/qupath/qupath/issues/1249. Also improve image opening behavior... or non-opening when it fails ([here](https://github.com/qupath/qupath/commit/4b4955cea256d70272e96f7714cafe6e1a8b9762)). > Throw an `IOException` if `ImageDisplay.setImageData()` fails, and remove the constructor that takes an `ImageData` parameter in favor of adding a static `create()` method instead.; >; > The purpose is to 'fail faster and better' if pixels cannot be read from an image, to avoid putting the viewer into an invalid state.; > ; > Previously, failure to open an image (e.g. because JPEGXR decompression was unavailable on Apple Silicon) would lead to an extremely uninformative NPE, and then possibly a lot more exceptions when attempting to interact with the viewer in any way.; > ; > When making these changes, the constructors for `QuPathViewer` were changed to no longer take an `ImageData` as a parameter. This was always null anyway (viewers were always created without an image), so makes no real difference to the current code - but the change avoids the possibility of the constructor having to throw an exception if the image couldn't be set. Now the image must be set as a second step, after the viewer has been created.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1343:590,avoid,avoid,590,https://qupath.github.io,https://github.com/qupath/qupath/pull/1343,2,['avoid'],"['avoid', 'avoids']"
Safety,"Fixes https://github.com/qupath/qupath/issues/1606. Note that this makes the change at a higher level than cell detection, so potentially impacts (fixes?) other commands. Note also that it can potentially change how tiling operates, by adjusting the parent ROI temporarily. In other words, large regions may be tiled with a different origin - and so have boundaries in a different place. However it is planned for a v0.x release, and most ROIs shouldn't be outside the image, so any reproducibility impact is expected to be minimal.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1607:112,detect,detection,112,https://qupath.github.io,https://github.com/qupath/qupath/pull/1607,1,['detect'],['detection']
Safety,"Fixes to undo this fix:; * https://github.com/qupath/qupath/issues/1337. It turned out to be problematic in subtle ways. The main one was that there were strange permissions issues *that only emerged when the package was downloaded and installed* (not built locally). Basically, QuPath could no longer open images within its own project *unless* it had 'seen' them before in almost any interactive way (e.g. the images were opened via drag & drop, or even pasted into the script editor). When that was the case, the image opened fine consistently - and across restarts of QuPath, but not of the OS as a whole. For images QuPath hadn't seen, `new File(path).canRead()` would return false and there seemed to be no code-based way to convince it otherwise. The image-reading library didn't matter: OpenSlide, Bio-Formats, ImageJ all failed. Setting full disk access seemed promising, but ultimately didn't work consistently. The only workaround was to launch QuPath via a terminal, avoiding `launchd`. The hint that this was to blame came from; ```; tccutil reset SystemPolicyAllFiles QuPath-0.5; ```; producing an error and a report that the .plist had been modified... so macOS *knew*. Reverting this plist changes (and using Java 17) was sufficient to get things working again. The noticeable difference is that, when first trying to open an image, a system dialog pops up to ask whether QuPath can have access to Documents/Desktop/Downloads - which never happened with the change. Along the way, I learned that; * https://github.com/qupath/qupath/issues/1358. first emerged in JavaFX 20.0.1 so this PR also reverts to JavaFX 20 for now. I wanted to use Java 20 as well, but it complained when trying to build the `.pkg` from an existing `.app` because it didn't like the `app/.jpackage.xml` so that's why we're back on 17 for now.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1379:979,avoid,avoiding,979,https://qupath.github.io,https://github.com/qupath/qupath/pull/1379,1,['avoid'],['avoiding']
Safety,"Following up on https://github.com/qupath/qupath/issues/172. ; This is seeking help on how to detect the carbon vs DAB staining for digital analysis without having to manually delete the carbon regions that are positive. . I have quite a few images (TMA cores) to sort through and cannot afford to do this manually as dougzy did, so I need some more details on setting up a proper classifier for black vs. DAB. . I have attached a couple of files with examples of one of the stainings + carbon artifact. It is easily detected by eye, but harder (for me) to get the software to tell them apart. . ![carbon1](https://user-images.githubusercontent.com/40302478/58230113-3c73f500-7ce8-11e9-986f-093cdf4192f6.jpg); ![carbon2](https://user-images.githubusercontent.com/40302478/58230114-3c73f500-7ce8-11e9-8899-ab702e622081.jpg)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/319:94,detect,detect,94,https://qupath.github.io,https://github.com/qupath/qupath/issues/319,2,['detect'],"['detect', 'detected']"
Safety,"For small TMA cores and small biopsies (*.vsi and *.ndpi files, H-DAB, RGB, 100 - 500 mb, small images with one core or biopsy per image) the simple tissue detection and Stardist script often worked through the entire project in batch mode, about 100 images, without issues. For whole slides image projects (100 mb - 3,5 GB images) it can do 0 -1 images before crashing and more often crashes on the gigabyte whole slide images, so some sort of memory trouble can indeed be a possible issue (the m12 Tensorflow Qupath build only allows 32 GB memory I see, even though 64 GB is available - any way of forcing it to expand that?).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/481#issuecomment-630737119:156,detect,detection,156,https://qupath.github.io,https://github.com/qupath/qupath/issues/481#issuecomment-630737119,1,['detect'],['detection']
Safety,"For the existing 'true' cells, check if the annotations fall inside the full cell boundary (assuming that in this case you're only displaying the nuclei, but actually both the nucleus and cytoplasm regions exist). (If this is correct, it highlights that the `toString` method used for QuPath objects isn't very good... knowing that the parent object has a polygon ROI [which the script I posted above reveals] has limited use - it would help if printing out the object also told you if it was an annotation, detection, cell or whatever. I will make this change...)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/259#issuecomment-457817384:508,detect,detection,508,https://qupath.github.io,https://github.com/qupath/qupath/issues/259#issuecomment-457817384,1,['detect'],['detection']
Safety,"For the nuclei, I would recommend starting a thread on the forum where you can post some pictures, that sounds like more of a image analysis problem. 20X might also be challenging with truly thin, elongated nuclei. Even more challenging if the Hamamatsu defaults to saving with JPEG compression (bad for analysis, great for file size). You can both classify regions and cellular populations, so you can subdivide your sample into ""tumor"" and ""stroma"" annotations first, and then perform positive cell detection within each of those (or however many classifications you want). Another option is using derived classes, so that you would first classify by tumor and stroma, then classify the cells as positive or negative within those classifications: https://github.com/qupath/qupath/wiki/Object-classifications. Either way, you can then ignore the stromal positive cells in the data processing (merge populations) however you want, or create a step that re-classifies any Stroma-positive to Stroma-negative, etc.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/231#issuecomment-431117318:501,detect,detection,501,https://qupath.github.io,https://github.com/qupath/qupath/issues/231#issuecomment-431117318,1,['detect'],['detection']
Safety,"For the stain vectors, I used the manual method shown in the video from the menu option _Analyze->Preprocessing->Estimate Stain Vectors_. I had a fairly large area in the middle of your sample selected with an annotation. For this run I lowered the Minimum area to 20um^2, as the size limit had been excluding many of these darker types of cells. Part of the reason I did that is because many of the smallest nuclei are SO dark, they too are showing up as ""blue"" positive.; Here is the edited first script:; ```; setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""red blue"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.18752 0.65887 0.72851 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.72191 0.55664 0.41109 "", ""Background"" : "" 255 255 255 ""}');; selectAnnotations();; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.27, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 2.0, ""minAreaMicrons"": 20.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.6, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.30, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.45, ""thresholdPositive2"": 0.45, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; ```; And here is a variant of a classifier you can play with to optimize for your samples. Note that these sorts of classifiers are always sensitive to staining variations, so it may not be very accurate between samples (if the staining is not!). You can find more about[ scripting classifiers here](https://gist.github.com/Svidro/5b016e192a33c883c0bd20de18eb7764).; ```. blueThreshold = 0.45 //Set to class Tumor; brownThreshold = 1 //Set to class Stroma. // Get cells & reset all the classifications; def cells = getCellObjects(); resetDetectionClassifications(). cells.each ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/250#issuecomment-449989226:811,detect,detect,811,https://qupath.github.io,https://github.com/qupath/qupath/issues/250#issuecomment-449989226,2,['detect'],"['detect', 'detectionImageBrightfield']"
Safety,"For what it's worth, I checked the dll dependencies with `ldd` in git bash, and it was all satisfied. I've had to switch to using their windows build because I ended up with unsatisfied links for SSP and some weird minGW libraries that I wasn't going to be able to fix in time, so it really should be a safe bet.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1325#issuecomment-1748498287:303,safe,safe,303,https://qupath.github.io,https://github.com/qupath/qupath/pull/1325#issuecomment-1748498287,1,['safe'],['safe']
Safety,"Forgot to reference if in the commit message, but this deals with the problem by using the stored channel names instead: https://github.com/petebankhead/qupath/commit/0caf3c68a766035a9c77a64c6a6d8b65464fd2b2. And here the channel names are applied within the cell detection command, rather than 'Channel 1', 'Channel 2' etc.:; https://github.com/petebankhead/qupath/commit/79228883d06e4cf36ed6477cc0e226522c3de1d8",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/301#issuecomment-520137423:264,detect,detection,264,https://qupath.github.io,https://github.com/qupath/qupath/issues/301#issuecomment-520137423,1,['detect'],['detection']
Safety,"Found the solution:; `runPlugin('qupath.imagej.detect.cells.WatershedCellMembraneDetection', '{""detectionImageBrightfield"": ""Hematoxylin"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 1000.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": true, ""cellExpansionMicrons"": 8.0, ""includeNuclei"": true, ""limitExpansionByNucleusSize"": false, ""smoothBoundaries"": true, ""makeMeasurements"": true}');`",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/624#issuecomment-714494385:47,detect,detect,47,https://qupath.github.io,https://github.com/qupath/qupath/issues/624#issuecomment-714494385,2,['detect'],"['detect', 'detectionImageBrightfield']"
Safety,"From [v0.1.2](https://github.com/qupath/qupath/releases/tag/v0.1.2), *Measure &rarr; Show Annotation Measurements* should be recorded in the command history - and able to generate a script line, including filtering by specified columns if required. The syntax looks like this:; ```java; saveAnnotationMeasurements('/path/to/exported/file.txt', 'Area', 'Length'); ```. There is also now a small trick that can be used to run short scripts that affect the GUI (which must be run in the [JavaFX Platform thread](https://docs.oracle.com/javase/8/javafx/api/javafx/application/Platform.html#runLater-java.lang.Runnable-)), namely to include ```guiscript=true``` at the top of the script. This isn't a good idea routinely (since it will result in the entire script being run on that thread), but it avoids needing to use ```Platform.runLater(...)``` every time this is required. An example is given [here](https://gist.github.com/petebankhead/6f73a01a67935dae2f7fa75fabe0d6ee).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/25#issuecomment-269880610:793,avoid,avoids,793,https://qupath.github.io,https://github.com/qupath/qupath/issues/25#issuecomment-269880610,1,['avoid'],['avoids']
Safety,"From memory, *Simple tissue detection* doesn't do anything as sophisticated as color deconvolution - but it does take into consideration the 'Image type' (e.g. fluorescence/brightfield) to decide whether it is looking for something 'bright' and 'dark'. After that it converts the image to grayscale, or takes the first channel (see #93 for a request to add support for another channel). In many cases, *Simple tissue detection* is probably too simple. But if the results look especially strange, the first thing I'd do is to turn off the *Smooth coordinates* option. This basically takes the original shape, and then represents an approximation of it using fewer vertices. Sometimes this approximation is not particularly good - especially if the tissue overlaps with the image border. Turning off the option gets closer to the 'original' detection by thresholding.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/124#issuecomment-352167834:28,detect,detection,28,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-352167834,3,['detect'],['detection']
Safety,"From memory, I think the reason it prefers cells *when present* is so that it does something sensible in the (common?) scenario that someone is using subcellular detections. I agree that this behavior isn't obvious (and should at least be documented). I'm interested to better understand the use case where heterogenous groups should be treated the same.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1550#issuecomment-2188422166:162,detect,detections,162,https://qupath.github.io,https://github.com/qupath/qupath/issues/1550#issuecomment-2188422166,1,['detect'],['detections']
Safety,"From the script editor, you can choose *Run &rarr; Run for project* and then select all the images. You just need to be careful what your export file name is to avoid overwriting it for each image. Something like the following will include the name for the current image in the project in the export:; ```groovy; pathExport = buildFilePath(PROJECT_BASE_DIR, 'exported', getProjectEntry().getImageName() + '.txt'); print pathExport; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/132#issuecomment-356053505:161,avoid,avoid,161,https://qupath.github.io,https://github.com/qupath/qupath/issues/132#issuecomment-356053505,1,['avoid'],['avoid']
Safety,"From your description I don't think this is a bug. QuPath generates markup images on demand, and then caches these for performance. A lot of the functionality depends upon this ability (e.g. measurement maps, the ability to quickly fill/unfill detections), but it does mean that there can be a short delay when generating the markup tiles each time the delay changes significantly. This delay increases with the number of detections. Working with a static markup image would be a lot faster... but also a lot more restrictive. I don't know what you mean with 'high initial latency', but a second or two is to be expected. 10-20 seconds isn't. If this is the explanation you should find the latency returns if (for example) you press 'f' to fill/unfill the detections - but goes away again after a few seconds, once the new tiles have been cached. There is a performance issue with v0.2.0-m9 when it comes to drawing annotations (under some circumstances) on an image with a large number of annotations already present, but this will be fixed in the next release.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/440#issuecomment-614145319:244,detect,detections,244,https://qupath.github.io,https://github.com/qupath/qupath/issues/440#issuecomment-614145319,3,['detect'],['detections']
Safety,Full image annotation for Sparse training image throws errors for detections,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443:66,detect,detections,66,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443,1,['detect'],['detections']
Safety,Get detection measurements per annotation,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/225:4,detect,detection,4,https://qupath.github.io,https://github.com/qupath/qupath/issues/225,1,['detect'],['detection']
Safety,Getting area out of detection objects,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/159:20,detect,detection,20,https://qupath.github.io,https://github.com/qupath/qupath/issues/159,1,['detect'],['detection']
Safety,"Glad you made it that far! I have not played with exporting images much, but for cycling through the detections I think you want getDetectionObjects(). I do not think selecting them returns them, so your script is not actually running through anything. You can test it by putting a print statement inside the loop too.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/118#issuecomment-346643029:101,detect,detections,101,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346643029,1,['detect'],['detections']
Safety,"Going to have to make a few assumptions here, but I think that you probably changed locations or moved your project around from M2. M2 did not really tolerate changes to project locations very well, which led to the URI update detection and some other things. To work with the M2 projects in M2 again, the project file should either be in the same place, or I think you may need to edit the .qpproj file to update the new file path to the images. That is why the project will open (that path is set wherever you have run it from), but the images will not be found. If you open the log, I suspect that is the error message (and it will show the old file path). M8 will not run M2 projects, and I don't think it is very easy to even transfer annotations between them (you would probably need a script... and I'm not sure how well it would work even then).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/388#issuecomment-567689754:227,detect,detection,227,https://qupath.github.io,https://github.com/qupath/qupath/issues/388#issuecomment-567689754,1,['detect'],['detection']
Safety,"Good question... there's no command for that currently. I think a 'Flatten hierarchy' command would make sense, but I'm not 100% sure if we should add it. The risk I can think of is that objects wouldn't necessarily end up where they started in terms of the hierarchy after using 'flatten-then-resolve', and that might be confusing. Another option is to use *Objects &rarr; Annotations... &rarr; Duplicate selected annotations* (Shift + D). The duplicated annotations have no child objects, so you can detect within them - and then delete the new annotations afterwards if you want to, and resolve the hierarchy then if you need to. That should work both through the user interface and scripting. Would that work as an alternative in your case?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1411#issuecomment-1788879843:159,risk,risk,159,https://qupath.github.io,https://github.com/qupath/qupath/issues/1411#issuecomment-1788879843,2,"['detect', 'risk']","['detect', 'risk']"
Safety,"Good! I don't know - QuPath shouldn't really allow this to happen, so I'm not sure how it did... I'll close the issue now, but if you can find steps to reproduce it please let me know and we can try to fix it to avoid the trouble in the future.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/613#issuecomment-708524652:212,avoid,avoid,212,https://qupath.github.io,https://github.com/qupath/qupath/issues/613#issuecomment-708524652,1,['avoid'],['avoid']
Safety,"Great, thanks!. The API documentation would be good... although I'm not entirely sure where/how to arrange to get it hosted. I guess you may already have things set up with IntelliJ as described on the Wiki (if not, you probably should!), and through that there may be a way to generate javadocs... or at least browse the code directly. In moments of desperation when I'm relying only on QuPath's editor, I use Java reflection to get a list of methods. Here, for example, is a script to generate a list of all the methods in QPEx, with a little bit of cleanup to reduce redundancy:. ```groovy; import qupath.lib.scripting.QPEx. def objectMethods = Object.getMethods() as Set. def replacements = [; 'qupath.lib.scripting.QPEx.' : '',; 'qupath.lib.scripting.QP.' : '',; 'public static ' : '',; 'java.lang.': '',; 'java.io.File': 'File',; 'java.util.List': 'List',; ',': ', '; ]. def sb = new StringBuilder('Methods:\n'); for (m in QPEx.getMethods()) {; if (m in objectMethods); continue; def method = m.toString(); for (entry in replacements.entrySet()); method = method.replaceAll(entry.getKey(), entry.getValue()); sb << method; sb << '\n'; }; ; print sb; ```. One day I hope to get this documented better and available on the Wiki (like ImageJ's macro reference)...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/102#issuecomment-332629803:570,redund,redundancy,570,https://qupath.github.io,https://github.com/qupath/qupath/issues/102#issuecomment-332629803,1,['redund'],['redundancy']
Safety,Gson-related method was previously emitted:; WARNING: Illegal reflective access by com.google.gson.internal.reflect.UnsafeReflectionAccessor caused by AffineTransform,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/537:116,Unsafe,UnsafeReflectionAccessor,116,https://qupath.github.io,https://github.com/qupath/qupath/pull/537,1,['Unsafe'],['UnsafeReflectionAccessor']
Safety,"H-DAB Ki67 labeled tissue, ; celldetection of negative blue nuclei works best, with Hematoxylin OD Nucleus Detection. ; Drawback is lack of recognition of DAB positive cells. . Recognition of DAB positive cells works best, with optical density sum for nucleus detection, but a lot of blue negative cells are not detected. . Is it possible to combine both methods? Do both analysis, keep the result of Optical density sum for positive nuclei and keep the result for negative cells from Hematoxylin OD nucleus cell ##detection?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/46:107,Detect,Detection,107,https://qupath.github.io,https://github.com/qupath/qupath/issues/46,4,"['Detect', 'detect']","['Detection', 'detected', 'detection']"
Safety,"HI,. Thanks for you help!. File format: .tif . This is all the info of the image. I didn’t try with another version. Will do now. . Info under show log:. INFO: Initializing type adapters; INFO: Bio-Formats version 6.7.0; INFO: Loaded extension Bio-Formats options (Bio-Formats 6.7.0) (18 ms); INFO: Loaded extension ImageJ extension (69 ms); INFO: Loaded extension Processing extension (30 ms); INFO: Loaded extension Rich script editor extension (81 ms); INFO: Loaded extension SVG export extension (1 ms); INFO: OpenSlide version 3.4.1; INFO: Update check for https://github.com/qupath/qupath; INFO: Starting QuPath with parameters: []; INFO: Setting max Bio-Formats readers to 4; WARN: Temp memoization directory created at /var/folders/_v/1nq60v556l5cbwcdv47wq76w0000gn/T/qupath-memo-4532483650866269942; WARN: If you want to avoid this warning, either specify a memoization directory in the preferences or turn off memoization by setting the time to < 0; INFO: Image data set to ImageData: Not set, 16.tif - Series 0. Again, thank you very much for your incredible help!. Manuel. > El 30 may. 2022, a las 13:52, Pete ***@***.***> escribió:; > ; > ; > Hi, some questions:; > ; > What is the file format?; > Under the 'Image' tab, what is shown at the entry 'Server type'?; > Have you been able to view the whole slide image with any other version of QuPath (e.g. on Windows)?; > Is there any relevant information under View → Show log?; > If you have an mrxs image, this may be relevant: https://forum.image.sc/t/potential-fix-for-problem-low-resolution-mrxs-3dhistech-scans/32917 <https://forum.image.sc/t/potential-fix-for-problem-low-resolution-mrxs-3dhistech-scans/32917>; > If you have an mrxs or vsi image, you might be missing the folder the should exist alongside the main image file (the folder contains the high-resolution data).; > ; > —; > Reply to this email directly, view it on GitHub <https://github.com/qupath/qupath/issues/973#issuecomment-1141062643>, or unsubscribe <https://gi",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/973#issuecomment-1141124758:830,avoid,avoid,830,https://qupath.github.io,https://github.com/qupath/qupath/issues/973#issuecomment-1141124758,1,['avoid'],['avoid']
Safety,Have you clicked on the Select... button or Use All to the right side of the no features selected message? You will need cells or some kinds of detections to already exist in that image in order to populate the list.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/63#issuecomment-293362863:144,detect,detections,144,https://qupath.github.io,https://github.com/qupath/qupath/issues/63#issuecomment-293362863,1,['detect'],['detections']
Safety,"Have you run the (deprecated) _Analyze → Spatial analysis → Delaunay cluster features 2D_ command on any of these images, at any time?. If so, this can mess things up... When using the new command only, connections should be generated any time they are requested (including for visualisation). Resetting them only serves to request that they are recalculated on the next request. This behavior is entirely different from the old _Delaunay cluster features 2D_ command, where you had to explicitly request connections to be made. The goal here was to avoid the need for that extra step, so that querying connections is _always_ possible. (But this is also why the work is unfinished... because we don't have a good way to add in extra criteria for the visualisation, such as only generating connections less than a specified distance). If you've run _Delaunay cluster features 2D_ then this causes trouble because it sets a property within `ImageData`, and currently this is visualised instead when it's present. Sometimes the property gets out of sync with the original data, which is even worse, but that isn't a new bug.. and contributes to the reasons why _Delaunay cluster features 2D_ is deprecated.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1597#issuecomment-2404668520:550,avoid,avoid,550,https://qupath.github.io,https://github.com/qupath/qupath/pull/1597#issuecomment-2404668520,1,['avoid'],['avoid']
Safety,"Have you tried creating a new project with m3 and seeing how it behaves, without any extra modifications?. m3 avoids the use of `{$PROJECT_DIR}` as a QuPath-specific solution is rather hard to maintain, and switches to URIs to overcome backslash/forward slash issues and also support OMERO-hosted images as well as local files. Rather, what m3 should do is:; * Always store the absolute URI for the image; * Store the last known URI for any project file; * Check for the existence of the absolute URI; * If that succeeds, good!; * If that fails, relativize the URI based on the last known project file URI and try it; * Show a dialog box to confirm any required URI changes / missing URIs requiring manual correction",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/346#issuecomment-517615463:110,avoid,avoids,110,https://qupath.github.io,https://github.com/qupath/qupath/issues/346#issuecomment-517615463,1,['avoid'],['avoids']
Safety,"Hello Dear Pete, . First of all, thanks for this great program. You must be genius. Second of all, does ""Click on Advanced options in the Create detection classifier window and select the More... button on the right. If you choose Rebuild training from project QuPath will then loop through all the images in the project and use any annotations it finds to train the new classifier."" still work? I couldn´t really find these create detection classifier window, more or advance selections.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/57#issuecomment-1808333179:145,detect,detection,145,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-1808333179,2,['detect'],['detection']
Safety,"Hello Pete,; I tried to install QuPATH latest version on linux CentOS.; I installed openjdk and JavaFX.; While I was installing with command:; ./gradlew createPackage -Ppackager=~/tools/jdk-14/bin/jpackage; The following error occurred (which can also be seen from the 2 screenshots attached); ![error_message_part1](https://user-images.githubusercontent.com/9053403/65413033-1344ac00-de23-11e9-988e-3dc178c613c3.png); ![error_message_part2](https://user-images.githubusercontent.com/9053403/65413036-150e6f80-de23-11e9-9275-6fe70d290ece.png). "" Task :createRuntime; /public/home/yangzhzh/tools/jdk-12.0.2/bin/jlink --output /public/home/yangzhzh/tools/qupath-master/build/jre --add-modules java.desktop,java.xml,java.scripting,java.sql,java.naming,jdk.uns> Task :createPackage FAILED"". ""FAILURE: Build failed with an exception."" . Does this mean that only this task failed (I could use some of the tasks) or the compilation failed completely?. Also, if it indicates some of the tasks can be used, is there a place showing how to use the command line to perform analyses?. I only tried it on my macMini, but it frequently aborted. That's why I switched to linux. But I wonder how to use the commands. Looking forward to your response.; Zhenzhen",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/363:1122,abort,aborted,1122,https://qupath.github.io,https://github.com/qupath/qupath/issues/363,1,['abort'],['aborted']
Safety,"Hello everyone,. In my QuPath analysis I want to evaluate the distance of detections within an annotation to the parents annotation border. I only found scripts for analysing the distance of detections to borders of other annotations after assigning these annotations to classes.; This possible feature has been discussed on the image forum: https://forum.image.sc/t/distance-of-detections-to-border-of-parent-annotation/70199. Thank you and best regards,; Michael",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1033:74,detect,detections,74,https://qupath.github.io,https://github.com/qupath/qupath/issues/1033,3,['detect'],"['detections', 'detections-to-border-of-parent-annotation']"
Safety,"Hello!. First of all, this is a great piece of software! I am trying to write a script to export the nuclear area of nuclei detected within multiple annotations. However, I would like to have these measurements exported for each annotation rather than exporting the complete list of detection measurements altogether. If I just export the complete list I am no longer able to distinguish between the different annotations. I feel I am just simply overlooking something here, so I was wondering whether there is a piece of code to be able to do this?. Thank you very much!. Leon",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/225:124,detect,detected,124,https://qupath.github.io,https://github.com/qupath/qupath/issues/225,2,['detect'],"['detected', 'detection']"
Safety,"Hello!. We had been running qupath for cell detection on a number of small images crops and it worked well. However later we decided that it would be better to make a mosaic out of input images and open one instance of qupath with a mosaic image and then run cell detection on a number of ROI. This time it did not work well. At the begining it seemed to work, so we started integrating that. Later it turned out that it randomly messes up giving a result of one ROI in multiple ones. You can see that in the screenshot. . ![image](https://user-images.githubusercontent.com/9865688/31624260-610252b6-b2a2-11e7-86b0-b8c8c08c3e7f.png). It happens only one in a 2-3 runs. What's more today I've been thinking about how I want to avoid multithreading in some other project (as it is error prone) and realized that it may be the case here. So I changed the number of processors per parallel command (in preferences) and it seems that the problem no longer exists :). To sum up, multi ROI cell detection fails randomly when multithreading is on.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/110:44,detect,detection,44,https://qupath.github.io,https://github.com/qupath/qupath/issues/110,4,"['avoid', 'detect']","['avoid', 'detection']"
Safety,"Hello, . I was interested in using qupath.imagej.detect.cells.ObjectMeasurements in a package I am creating separately, but this class is currently package-private.; https://github.com/qupath/qupath/blob/c5cc1895f5ff6ff94b2431b4b2ede7fad78b071f/qupath-core-processing/src/main/java/qupath/imagej/detect/cells/ObjectMeasurements.java#L42. Would it be possible to have access to this class outside the package? I can use it in a script within QuPath without issues, but not in Java... . Thank you for any help/comments. . All the best. Oli",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/466:49,detect,detect,49,https://qupath.github.io,https://github.com/qupath/qupath/issues/466,2,['detect'],['detect']
Safety,"Hello, ; I am using QuPath to detect inclusions in the cytoplasm for DAB stainning, They are small and I want to do a quantification of the number of inclusions. Can somebody help with this issue? Thank you",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/994:30,detect,detect,30,https://qupath.github.io,https://github.com/qupath/qupath/issues/994,1,['detect'],['detect']
Safety,"Hello,. I am having trouble with automatic quantification for cellular staining (ISH with puncta) using QuPath. ; I have worked on counting ISH-puncta inside the neuron (mainly DRG or spinal cord). The program I use is below.; 1. Open ND2 file; 2. Draw the cells by hand; 3. Turn annotation into detection with script; 4. Analyse -> Cell Analysis -> Subcellular detection. Everything was going well until now. However, the program did not work suddenly even though I did not change anything. After turning into the detections, I cannot carry out subcellular detection analysis. The images I took previously still work well now even though I took and saved the images the same way, same setting, same file type. Do you have any solutions? . I found the window of ""Subcellular spot detection"" has changed. ""Spot & cluster parameters"" has gone. Before; ![2018-04-06 20 12 47](https://user-images.githubusercontent.com/38146083/38448988-801756b2-39d7-11e8-9c2f-72b9dfe16258.png); ; Now; ![2018-04-06 20 15 30](https://user-images.githubusercontent.com/38146083/38448999-99ee0f36-39d7-11e8-8ec7-a8087e40e9cd.png). And also now I cannot get the ""Centroid X/Y data"" on annotation measurements.; ![2018-04-06 20 19 23](https://user-images.githubusercontent.com/38146083/38449026-f5001298-39d7-11e8-8fce-4e077545e43c.png). Do you have any solutions?. Thanks,",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/163:296,detect,detection,296,https://qupath.github.io,https://github.com/qupath/qupath/issues/163,5,['detect'],"['detection', 'detections']"
Safety,"Hello,. I am trying to run the Tissue detection using structure information as a; groovy script ending with a binary downsampled mask. I am struggling; converting the mask information back to a QuPath annotation. Can you please; give me a hint?. Best regards,. Kai. Am So., 3. Jan. 2021 um 19:53 Uhr schrieb Pete <notifications@github.com>:. > https://forum.image.sc/search?q=%22qupath%22%20%22intellij%22; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/657#issuecomment-753660905>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AEG6ZGYKHKRM5ZB6XVXXQL3SYC4LVANCNFSM4VR5VYCA>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/657#issuecomment-757517752:38,detect,detection,38,https://qupath.github.io,https://github.com/qupath/qupath/issues/657#issuecomment-757517752,1,['detect'],['detection']
Safety,"Hello,. I have tried tissue detection using the ""Simple Tissue Detection (deprecated)"" and ""Create Thresholder"" commands. The main problem here are often missing parts of adipose tissue. Is it possible to integrate another algorithm using structure information? Described for example in ; Bug, Daniel, Friedrich Feuerhake, und Dorit Merhof. „Foreground Extraction for Histopathological Whole Slide Imaging“. In Bildverarbeitung für die Medizin 2015, 419–424. Springer, 2015. http://link.springer.com/chapter/10.1007/978-3-662-46224-9_72. I have added some lines of code for testing to ""SimpleTissueDetection2.java"". The Laplacian operator was replaced with the Canny edge detector and the floodFill steps by findContours/fillPoly using the OpenCV bindings. ; [patch-tissue-extraction.zip](https://github.com/qupath/qupath/files/5761754/patch-tissue-extraction.zip). Best regards,. Kai",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/657:28,detect,detection,28,https://qupath.github.io,https://github.com/qupath/qupath/issues/657,3,"['Detect', 'detect']","['Detection', 'detection', 'detector']"
Safety,"Hello,. I have tried to make batch analysis from workflow viewer.; Whereas it showed ""set image type"" and ""watershed cell detection"" as workflow records, the 3rd command does not come up.; What I set as 3rd (and 4th) command is that ""load classifier and run classifier"".; ![workflowviewer](https://user-images.githubusercontent.com/35938841/53768694-68709e80-3e8e-11e9-839e-48de35711579.JPG). Attached image is showing a workflow window and a classifier window.; This was done with v0.1.2 QuPath.; Please give any suggestion to solve this issue.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/272:122,detect,detection,122,https://qupath.github.io,https://github.com/qupath/qupath/issues/272,1,['detect'],['detection']
Safety,"Hello,. I'm using V. 0.2.0-m1 or m2 on a Mac computer. Anytime I attempt to detect cells across an entire TMA grid it starts and shows the progres bar, but after a few seconds the command fails - any suggestions how to solve this issue?. Thanks!",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/294:76,detect,detect,76,https://qupath.github.io,https://github.com/qupath/qupath/issues/294,1,['detect'],['detect']
Safety,"Hello,. In the process of grading bowel inflammation which includes leukocyte infiltrates. First step is to rotate the image to orientate the mucosa (epithelial layer) up as it's much easier to assess. Generally involves a +/- 90 degree rotation. Afterwards open counter tool and begin marking infiltrates. However the counter will register a click but no corresponding point will not appear on the image. Similarly converting detections to points does not display points either. Interestingly the points will display when the image is is rotated to <90 degrees either way. Furthermore the points will scale down with as the image is rotated towards to the original orientation. This is best seen when the smallest point size is selected. Otherwise a great program and is proving immensely helpful. Many thanks.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/193:427,detect,detections,427,https://qupath.github.io,https://github.com/qupath/qupath/issues/193,1,['detect'],['detections']
Safety,"Hello,. Instead of just displaying the ROIs of detections with their annotations (as color code), as it occurs by pressing the button ""Export to ImageJ --> send region"", it would be great to save those detections (with annotations) in a .roi file so it can be read by ""normal"", external ImageJ. ; Could this be done in a grooyv script?; Best regards and merci; Philipp",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/182:47,detect,detections,47,https://qupath.github.io,https://github.com/qupath/qupath/issues/182,2,['detect'],['detections']
Safety,"Here's a script that will loop through all objects (of any kind), and write out the polygon points to a text file inside the current project directory:; ```groovy; // Create an empty text file; def path = buildFilePath(PROJECT_BASE_DIR, 'polygons.txt'); def file = new File(path); file.text = ''. // Loop through all objects & write the points to the file; for (pathObject in getAllObjects()) {; // Check for interrupt (Run -> Kill running script); if (Thread.interrupted()); break; // Get the ROI; def roi = pathObject.getROI(); if (roi == null); continue; // Write the points; but beware areas, and also ellipses!; file << roi.getPolygonPoints() << System.lineSeparator(); }; print 'Done!'; ```; Be wary of any `Area` ROIs though (including `Area (AWT)`) - these can contain complex polygons with discontinuous regions, and you might well not get the expected output using this method. Any further help on this would require knowing exactly what the 'expected output' should be for these tricky cases. There are a few blog posts that describe other kinds of export, e.g. with raster images rather than vertices, which would help avoid the troublesome shapes. [This post](https://petebankhead.github.io/qupath/scripting/2018/03/14/script-export-labelled-images.html), for example.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/95#issuecomment-388114844:1131,avoid,avoid,1131,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388114844,1,['avoid'],['avoid']
Safety,"Hey @biovoxxel . > I would fully avoid scaling and adapting to DPI, since this is not very helpful regarding the figure quality. Problem is, the original images in QuPath are whole slide images, and rather large. [OS-2.ndpi for example](https://cytomine.com/collection/os-2/os-2-ndpi) is 126976 pixels wide. So first thing QuPath asks when doing an SVG export (with the image + overlay as background) is what downsampling factor should be applied to the original image. It's a necessary step, but what is not clear, is which factor would actually match some publication guidelines (for example, 300PPI + width of 170 mm for full page width figure [as defined here](https://cancerandmetabolism.biomedcentral.com/submission-guidelines/preparing-your-manuscript)). > Once you have the SVG you can adapt it to the document size without the need of changing any resolution etc. I agree with you, but the background bitmap embedded in the SVG document only needs to be as big as the physical size it will be printed at. Some reviews also impose a maximum file size for the SVG documents (e.g. < 20MB), so we can't just use a downsample of 1 or 2 and hope for the best. Then yes, anything vectoriel on top of the background image (lines, polygons, text...) just needs to be readable at the printed size and could easily be modified in Inkscape if not (fond size, linewidths...). Maybe I'm missing something (wouldn't be the first time), so let me know how you see this work. Cheers,; Egor",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1272#issuecomment-1604775665:33,avoid,avoid,33,https://qupath.github.io,https://github.com/qupath/qupath/issues/1272#issuecomment-1604775665,1,['avoid'],['avoid']
Safety,"Hey Guys!; I try to define cells into tumor and non-tumor cells with the detection classifier and determine afterwards the positive and negative cells in the respective class (with help of positive cell detection), but this second step doesn't work. Does anyone know how to search for positive and negative cells in already defined classes over a whole TMA-slide? Thanks a lot for your help!!",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/64:73,detect,detection,73,https://qupath.github.io,https://github.com/qupath/qupath/issues/64,2,['detect'],['detection']
Safety,"Hey Guys,; you helped me a lot with my last issues, so I´ll try it again. . I used ""Tiles and superpixels"", classified the pictures in stroma and tumor and used ""Tile classifications to annotations"" to get the measurements of the classified area. But I also should get the number of cells of every classified area/annotation.; So I was wondering, is there a possibility to change the superpixels (already classified and in annotations) in cells by a script?; I know that I can select every annotation individually and use cell detection. But where can I figure out the number of cells in the selected annotation without a new classifier?; And is there a script wich I could use for an automatically cell detection in every picture of a project?. Thanks for your help, hope you have an idea :); Simone",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/261:527,detect,detection,527,https://qupath.github.io,https://github.com/qupath/qupath/issues/261,2,['detect'],['detection']
Safety,"Hey Pete,. I think this might be a bit too much to ask even from QuPath but is it possible to give training sample annotations of clusters of cells (instead of cell types) and get these regions detected (instead of individual cells though _Analyze -> Cell analysis_ but analogous in the type of outcome I want)?; So, for example here I have 2 types of tissue I have annotated:; ![image](https://user-images.githubusercontent.com/20464068/46069903-e5c81280-c17c-11e8-95cd-c3a5e53cf124.png); Would it be possible to extend this to all of the whole slide image to identify each region as the red type or the orange type? . Alternatively, is it possible to classify cells within these training sample annotations then do cell detection then cell classification and somehow merge adjacent cells if they are from the same type?. Thank you for your time!; Shushan",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/222:194,detect,detected,194,https://qupath.github.io,https://github.com/qupath/qupath/issues/222,2,['detect'],"['detected', 'detection']"
Safety,"Hey Pete,; The script for exporting annotations as binary masks here [https://petebankhead.github.io/qupath/scripting/2018/03/13/script-export-import-binary-masks.html](url) works perfectly and is super helpful, thanks a lot! ; I was wondering though if it would be possible to modify it to run nucleus detection (with 'qupath.opencv.WatershedNucleiCV' and save detection measurements but for each annotation in a separate file. So far I have been using saveDetectionMeasurements() command but it exports everything in one file. Would be ideal to get separate .txt for each annotation feature export (for my further analysis I need to know which cells come from the same annotation). ; I tried adding the script lines to the _export binary masks_ script but with no result, so any help would be much appreciated!",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/234:303,detect,detection,303,https://qupath.github.io,https://github.com/qupath/qupath/issues/234,2,['detect'],['detection']
Safety,"Hey all,. I'm having similar issues to those described here above. TMA dearrayer refuse to detect cores on two images from the project.. seems like the H&E stain is a bit weaker in these slides:; ![image](https://user-images.githubusercontent.com/9028967/54885257-ce938480-4e82-11e9-9566-6b54a5ce77b2.png). I've attempted to change the background colors & stain vectors, but that did not work. Adding rows or columns manually do not work since they are added outside the frame and so I could not relocate them. Thanks!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/53#issuecomment-475997405:91,detect,detect,91,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-475997405,1,['detect'],['detect']
Safety,"Hey everyone, I was wondering whether it's possible to export the single cores detected after running ""TMA dearrayer"" as TIFF files instead of as JPEG files?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/85:79,detect,detected,79,https://qupath.github.io,https://github.com/qupath/qupath/issues/85,1,['detect'],['detected']
Safety,"Hey, . I noticed with the reopening of my Qupath that for (positive) cell detection - setup parameters - 'choose detection channel' shows as option (as seen below). How can I put it back to the original 'Choose detection image - (Hematoxylin OD)' option?. <img width=""1428"" alt=""screen shot 2018-10-04 at 12 38 31"" src=""https://user-images.githubusercontent.com/43847524/46469005-6ec0f880-c7d2-11e8-9a27-0983207cf3ac.png"">",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/226:74,detect,detection,74,https://qupath.github.io,https://github.com/qupath/qupath/issues/226,3,['detect'],['detection']
Safety,"Hi @KidElectric I agree that's a bit odd and it took me a while to figure out what was going on. I think it's a consequence of QuPath evolving a bit and the old docs not being kept updated. And me hardly ever working with TMAs for years now. Basically, the TMA core is locked. The locking happens whenever the core is used for object detection. It's essentially inheriting the same behavior as for annotations. Unfortunately it's not very clear when an object is locked; QuPath v0.4.0 will make this more obvious through the UI thanks to; * #924. In the meantime, calling `getTMACoreList().each { it.setLocked(false) }` should resolve it. I suspect - but don't entirely remember - that `TMACoreObject.isEditible()` existed before object locking became a thing in QuPath, and when [the object hierarchy was more strict](https://petebankhead.github.io/qupath/2019/11/17/changing-the-hierarchy.html), as a way to make it harder to completely mess up TMA data by shifting a core ROI by a few pixels. It should possibly be removed, since locking gives a better way to control ROI editability than checking for detections. (I hope that helps - I'll keep this issue open at least until the javadocs are updated.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1021#issuecomment-1190617712:334,detect,detection,334,https://qupath.github.io,https://github.com/qupath/qupath/issues/1021#issuecomment-1190617712,2,['detect'],"['detection', 'detections']"
Safety,"Hi @Svidro and @petebankhead . Thanks for getting back to me. I'm using positive pixel count to estimate the extent of pathology in defined annotations (TDP-43 in ALS motor cortex, H-DAB slides). I can't use positive cell detection because the pathology is varied in shape and structure and a sizeable proportion of it is extracellular. However, I'm finding that it is ok as long as each annotation is drawn, then counted, then another annotation drawn and so on. If you draw multiple annotations and try to run them simultaneously it doesn't like it. I'm recording my output as a ratio of positive pixels per µm2, so for me the number of negative pixels is irrelevant. . The software is already better and more user friendly than the ImageScope package we were using before, so thank you!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/67#issuecomment-297932408:222,detect,detection,222,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-297932408,1,['detect'],['detection']
Safety,"Hi @charleshugo I would need more information to understand if this is a bug, including; * Version of QuPath you are using; * Type of classifier (e.g. RTrees, ANN); * Information about how many training annotations you have (e.g. a few hundred cells, or a few million); * Number of features for the classifier; * What happens on freezing (any error message, it eventually works again or it never works). I would also need a way to replicate the issue. Memory use was improved in v0.3.0, but elements of the live training and prediction cannot easily be parallelised because QuPath is a JavaFX application, which requires 1 thread for the user interface. Based on your description, my guess is that you may have too many training annotations - or your training annotations are too large. I suggest only drawing small training annotations to begin with, and gradually increase annotations to correct misclassifications. This can also easily happen by accident: if you have a single large annotation that has a classification (e.g. defining the entire tissue) then this will be used during classifier training and may cause a freeze. One workaround to this is to leave any large regions unclassified (or [use an 'ignored' class with an asterisk in the name](https://qupath.readthedocs.io/en/stable/docs/concepts/classifications.html#ignored-classifications); I often use `Region*`).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/831#issuecomment-949332484:525,predict,prediction,525,https://qupath.github.io,https://github.com/qupath/qupath/issues/831#issuecomment-949332484,1,['predict'],['prediction']
Safety,"Hi @codybum,; Your problem should be fixed by simply changing the order or your args like this:; `./QuPath-0.2.0 script --image myimage.svs --script myscript.groovy`. So this shouldn't be a bug - though it might be worth adding that the CLI is somewhat strict with the argument order to the docs. As a rule of thumb and to avoid future problems, I would always call the command first, followed by all the desired options/parameters (called with their identification). ; E.g. `QuPath-0.2.0 [command-name] [-option1=<option1>] [-option2=<option2>]`. I'll close this for now as it's not a bug if you don't mind. Feel free to open a new thread on the [forum](https://forum.image.sc/tag/qupath) if you have a question regarding the CLI and its use (or open a new issue here if you find a bug!).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/511#issuecomment-637634883:323,avoid,avoid,323,https://qupath.github.io,https://github.com/qupath/qupath/issues/511#issuecomment-637634883,1,['avoid'],['avoid']
Safety,"Hi @dkurt sorry for the long delay, I'm finally getting back to StarDist/ImageOps/normalization before the next release. In the end, percentile normalization turned out to have a lot of extra complexities that I hadn't originally considered. I've tried to address them in; * https://github.com/qupath/qupath/pull/1130; * https://github.com/qupath/qupath/pull/1146. These are intended to help QuPath fully support the [bioimage.io preprocessing spec](https://github.com/bioimage-io/spec-bioimage-io/blob/gh-pages/preprocessing_spec_0_4.md), which assumes 32-bit input and output. They also add support to normalize channels independently or jointly (since it [turns out some of the StarDist models uses joint channel normalization](https://forum.image.sc/t/stardist-in-qupath-normalization-issue/38912/13)). I hadn't realised Apache Commons Math provides [10 different methods that can give different results](https://commons.apache.org/proper/commons-math/javadocs/api-3.6.1/org/apache/commons/math3/stat/descriptive/rank/Percentile.EstimationType.html)), so I've now switched to using the one that matches with NumPy (and I think also R, Julia and others). Along the way, performance should be substantially improved by avoiding full array sorting and using parallelization; I'm seeing reductions from ~1 second to 0.2-0.3s in some tests. Because of these changes, I'd like to close this PR in favor of keeping the code simpler and not introducing an optimized alternative specifically for 8-bit RGB. Thanks again though - this helped to show me how slow & in need of improvement the original code was :). (If you ever want to test how the performance of your optimized approach compares with the new version, I'd be curious about the result - but I realise that probably isn't a priority. In any case, my [timing code is here](https://github.com/qupath/qupath/blob/main/qupath-core-processing/src/test/java/qupath/opencv/tools/TestOpenCVTools.java#L487)).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/827#issuecomment-1319775547:1221,avoid,avoiding,1221,https://qupath.github.io,https://github.com/qupath/qupath/pull/827#issuecomment-1319775547,1,['avoid'],['avoiding']
Safety,"Hi @hubutui could you try building with `gradlew` (Gradle wrapper) instead? That's the 'proper' way to build QuPath - see https://qupath.readthedocs.io/en/stable/docs/reference/building.html. The part you link to in `build.gradle` isn't actually trying to specify the toolchain, but rather to recover the Java version for the toolchain that is already being used. When it comes to *specifying* the toolchain, it looks like the example you give is just copied from the code I wrote here :); https://github.com/qupath/qupath/blob/main/buildSrc/src/main/groovy/qupath.java-conventions.gradle#L11. That's what QuPath already uses, so you can already pass it a `-Ptoolchain=20` if you like. **However** I think the problem is that QuPath's build is locked to Gradle 7.5.1 because of ; * https://github.com/bytedeco/gradle-javacpp/issues/28. There hasn't been another `gradle-javacpp` release yet, and I don't want to switch to a snapshot - so I'm waiting for that before updating our build scripts. Since Gradle releases break stuff pretty often, I suspect other changes will be needed. Also, older Gradles can't build using toolchains for newer Javas and Java 20 wasn't around when Gradle 7.5.1 was released - so you're probably stuck building QuPath v0.4.x on Java 17-19. But using Gradle wrapper avoids most of those problems, as long as you use a compatible toolchain version.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1262#issuecomment-1524666346:293,recover,recover,293,https://qupath.github.io,https://github.com/qupath/qupath/issues/1262#issuecomment-1524666346,2,"['avoid', 'recover']","['avoids', 'recover']"
Safety,"Hi @petebankhead , Hi @belliveau13 . The growing need coming from our users and [lacan](https://github.com/lacan)'s curiosity for the QuPath ""extension"" made him write a tool which allow the user to :; - Save/Load the current display settings; - Apply the settings to the similar images in the project . From @lacan : “_It requires QuPath 0.1.4, which is a minor update released by our group, that has a few functions made public. We’ve also created a small extension (which is currently only compatible with v0.1.4) that can handle saving and reapplying brightness and contrast settings (NEED DOC). ; Howeever, we would like to point out that you can use this version at your own risk. We will, of course merge all we can with @petebankhead’s new and coming release and modify what we need, but some functionality may be broken in between._”. In case you are interested, you can find some links on our [documentation page](https://c4science.ch/w/bioimaging_and_optics_platform_biop/image-processing/qupath/). Best,. Romain. ![image](https://user-images.githubusercontent.com/8309560/51099846-5a2dcc80-17d3-11e9-95e4-e967c8afedcc.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/26#issuecomment-453955094:681,risk,risk,681,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-453955094,1,['risk'],['risk']
Safety,Hi @petebankhead - thank you for your helpful reply! That does the trick. It totally makes sense to lock annotations once a detection is performed. I got distracted by isEditable and didn't realize to check what other relevant methods might be inherited. I agree with removing isEditable() and I look forward to the locked/unlocked annotation update! Thank you for the great tool!,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1021#issuecomment-1190645393:124,detect,detection,124,https://qupath.github.io,https://github.com/qupath/qupath/issues/1021#issuecomment-1190645393,1,['detect'],['detection']
Safety,"Hi @pssaha - great to hear about the exciting research!; Try double-clicking where it says 'Min display'. Also, if this is for a positive cutoff (rather than detection), see https://petebankhead.github.io/qupath/tips/2018/03/22/setting-positive.html",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/237#issuecomment-433489049:158,detect,detection,158,https://qupath.github.io,https://github.com/qupath/qupath/issues/237#issuecomment-433489049,1,['detect'],['detection']
Safety,"Hi @saudet thanks very much for checking this. Yes, it is still a problem with JavaCPP 1.5.6 (although less often, with the larger limit). I have just confirmed it following the steps to reproduce above and the [OS-1.ndpi](https://openslide.cs.cmu.edu/download/openslide-testdata/Hamamatsu/OS-1.ndpi) image from openslide.org. ![Screenshot 2022-01-21 at 05 53 09](https://user-images.githubusercontent.com/4690904/150473986-f94358f8-f834-46d6-b502-d80d040829a6.png). ![Screenshot 2022-01-21 at 05 50 03](https://user-images.githubusercontent.com/4690904/150474005-3aae13a4-6bed-44f9-af05-fb0b677abf0b.png). QuPath's *Memory Monitor* above is based upon whatever `Runtime` provides. I followed the exact same steps on a 2013 iMac without any problems, so there does seem to be something different on the M1. Our use may be a little obscure. QuPath's pixel classifier ([docs](https://qupath.readthedocs.io/en/stable/docs/tutorials/pixel_classification.html)) is designed to support interactively training a machine learning classifier. It should support many image types, but is typically used with very large, tiled, multiresolution biomedical images (usually 10-50 GB per 2D image). The pixel classification uses OpenCV's ML module via JavaCPP, but in principle also supports semantic segmentation using a pretrained deep learning model with OpenCV's DNN module or TensorFlow - JavaCPP is central to it all (thanks!). In all cases, each required image tile is read on demand and cached as a Java `BufferedImage`. It is converted to an OpenCV `Mat` temporarily for whatever calculations are required, then the end result converted back to a `BufferedImage`. Therefore quite a lot of fairly large `Mat` objects can be generated for the pixels, features and predictions, but closed after use and using `PointerScope` extensively since QuPath v0.3. This seems to be working very well everywhere except on M1.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856#issuecomment-1018215470:1755,predict,predictions,1755,https://qupath.github.io,https://github.com/qupath/qupath/issues/856#issuecomment-1018215470,1,['predict'],['predictions']
Safety,"Hi @tp81 I've had a look at this and would like to make a counter-offer :). Would https://github.com/qupath/qupath/pull/848 be a suitable replacement?. Triggering the 'Delete' button feels safer to me than copying the viewer behavior. I think the main difference is that my proposed alternative will always prompt for confirmation, while backspace within the viewer could delete a single selected annotation immediately. It also means both buttons (*Select all* and *Delete*) have exact keyboard replacements. What do you think?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/830#issuecomment-974651012:189,safe,safer,189,https://qupath.github.io,https://github.com/qupath/qupath/pull/830#issuecomment-974651012,1,['safe'],['safer']
Safety,"Hi @vladpopovici . There's more info about this behavior on the user forum [here](https://forum.image.sc/t/qupath-is-cropping-white-background-in-whole-slide-image-how-to-avoid-this-behavior/40853/2). Basically, you'll need to get the bounding box coordinates from OpenSlide. You can do this either from within a Groovy script in QuPath, or later by accessing OpenSlide through Python. Pete. PS. I'll close this as an issue because the [forum](http://forum.image.sc/tag/qupath) is really the best place for non-bug-related QuPath questions. PPS. Nice to see QuPath could be useful for you, I recognize your name from [this](https://doi.org/10.1093/bioinformatics/btx027) :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/820#issuecomment-919160755:171,avoid,avoid-this-behavior,171,https://qupath.github.io,https://github.com/qupath/qupath/issues/820#issuecomment-919160755,1,['avoid'],['avoid-this-behavior']
Safety,"Hi Erexhepa. thanks for your hint. I didnt know the simple tissue detection uses the color deconvolution vectors. I do not have a H-DAB image. I adapted the vectors via the stain estimator but it did not have an effect. . The I tried all kind of combinations of requestend pixel sizes and Threshold. ; Indeed, it reduced the artefact in the corners - they did not dissapear, but became this small that i would not care. ; Transfer to other pictures failed because of different required thresholds. . The exclue on boundary option would make my whole ROI disappear. It covers nearly the whole slide. . Thus i gonna use a superpixel approach for the tissue detection on the glass slide. It will be slower, but more accurate. . Thanks for your ideas!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/124#issuecomment-350561039:66,detect,detection,66,https://qupath.github.io,https://github.com/qupath/qupath/issues/124#issuecomment-350561039,2,['detect'],['detection']
Safety,"Hi Ieva, ; That shall defenitely be possible. You can generate regions of interest for each spheroid. That works via superpixel approach: Analyse > Region identification > Tiles & Superpixels > SLIC or DoG. You generate superpixels: ; ![grafik](https://user-images.githubusercontent.com/16352785/33573958-c45aa460-d937-11e7-8d4f-1d13d89a5e61.png). Change the image type in the image tab into ""Brightfield H&E"". ; Then feed it with statistics. ; Analyse > Calculate features > add intensity features. Use these checkboxes: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574028-0b866eb4-d938-11e7-820d-3629d339a516.png). and run it for detections. . Next step is to train a classifier to detect the spheroids: First create a class ""Spheroid"" in the annotation tab by rightclick onto the list of classes: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574089-3396762e-d938-11e7-8665-d2eef84ae60b.png). Then use the polygon and draw a circle around spheroids can set class of the polygon to ""Spheproid""; and paint polygon in the whitespace and set class to other or whitespace: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574170-7e522f3c-d938-11e7-9a84-d75add61bf04.png). Now go to menue ""Classify"" > ""create detection classifier"". ; Press advanced options and then ""use all"". Then build and apply. ; ![grafik](https://user-images.githubusercontent.com/16352785/33574202-9c0ac8a4-d938-11e7-822b-a9706b8cf600.png). The first result looks like that: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574227-a943d70e-d938-11e7-84a0-f4aef4baa9b1.png). after enough training you can convert the spheroid reagions into real regions of interest and afterwards for example count cells: . That is done by: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574256-c49afc1c-d938-11e7-8dfc-f03f1967c133.png). choose only spheroids to be converted to roi: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574300-e2e",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/121#issuecomment-349092952:652,detect,detections,652,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349092952,2,['detect'],"['detect', 'detections']"
Safety,"Hi Liese,. You might be able to directly continue retaining a classifier if you use the *Save training objects* option under the ```More``` button, and then *Load training objects* next time. At least that is what that option is intended for... although I can’t say I have used it very much, so it hasn’t had a lot of testing. Regarding the second question, I feared that this would be the problem when I wrote my reply... I suppose that in the absence of an elegant solution, it is worth considering inelegant ones. I can think of a few possibilities, although how feasible they are would depend upon how many cores you need to analyze, what outputs you require, and just how different the cores are. ---. Here are some ideas (not necessarily all good ones):. 1. You could annotate regions of interest and detect cells only inside your annotations - no need for a classifier at all. This would mean you need to draw an awful lot of annotations (one or more for every core), but at least you are in full control of what is annotated. 2. You could train up a classifier for all the ‘similar-enough-looking’ cores on one slide, and save that classifier. For all the cores that aren’t handled well enough, you could go through and set them as ‘Missing’. When you export your results, you need to be careful to ignore all the ‘Missing’ cores.; Then, you can duplicate your project, and delete all your annotations. You can go through and set all the ‘Missing’ cores to be available, and all the available cores to be ‘Missing’. Then train up a new classifier, and export the results again.; This way you can use multiple classifiers. It’s not very elegant at all, and I’m not sure that I would recommend it… but it is an option.; > If you try this, you could toggle the ‘Missing’ status in a script or manually. If you do it manually, I’d suggest opening the ‘Hierarchy’ tab on the left of the screen, and selecting the first core. Make sure you have clicked somewhere inside the main viewer to activate i",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/57#issuecomment-288818401:807,detect,detect,807,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401,1,['detect'],['detect']
Safety,"Hi Pete!; Reopening this as it's very similar and still happening in QuPath 0.5.0; A user had an annotation inside which there was another annotation filled with detections (over 5000); When runing ""Delaunay cluster features 2D"" we ran into; ```; Error running plugin: java.util.ConcurrentModificationException; java.util.concurrent.ExecutionException: java.util.ConcurrentModificationException; at java.base/java.util.concurrent.FutureTask.report(Unknown Source); at java.base/java.util.concurrent.FutureTask.get(Unknown Source); at qupath.lib.plugins.AbstractTaskRunner.awaitCompletion(AbstractTaskRunner.java:147); at qupath.lib.plugins.AbstractTaskRunner.runTasks(AbstractTaskRunner.java:117); at qupath.lib.gui.TaskRunnerFX.runTasks(TaskRunnerFX.java:106); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:147); at qupath.lib.gui.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:177); at java.base/java.lang.Thread.run(Unknown Source); Caused by: java.util.ConcurrentModificationException; at java.base/java.util.ArrayList.checkForComodification(Unknown Source); at java.base/java.util.ArrayList.equals(Unknown Source); at java.base/java.util.WeakHashMap.matchesKey(Unknown Source); at java.base/java.util.WeakHashMap.get(Unknown Source); at java.base/java.util.Collections$SynchronizedMap.get(Unknown Source); at qupath.lib.measurements.NumericMeasurementList$AbstractNumericMeasurementList.getNameMap(NumericMeasurementList.java:142); at qupath.lib.measurements.NumericMeasurementList$AbstractNumericMeasurementList.close(NumericMeasurementList.java:133); at qupath.lib.measurements.NumericMeasurementList$FloatList.close(NumericMeasurementList.java:352); at qupath.opencv.features.DelaunayTriangulation.addClusterMeasurements(DelaunayTriangulation.java:466); at qupath.opencv.features.DelaunayClusteringPlugin$DelaunayRunnable.run(DelaunayClusteringPlugin.java:215); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1182#issuecomment-1876997601:162,detect,detections,162,https://qupath.github.io,https://github.com/qupath/qupath/issues/1182#issuecomment-1876997601,1,['detect'],['detections']
Safety,"Hi Pete, . Thanks for the suggestion. using duplicate works well, and it is better solution for me than deleting all the annotations and restoring them back. . as a comment for others: ; I didn't find an easy way to select the all the duplicated annotations (as only one is selected after duplication) ; so I had to loop through the selected annotations and for each of them : Select, Duplicate, run StarDist, Delete. `def Anns = getAnnotationObjects().findAll{it.getPathClass().toString()==Class1 || it.getPathClass().toString()==Class2 }; for (ann in Anns) ; {; selectObjects(ann); duplicateSelectedAnnotations() ; dup_ann = getSelectedObjects(); stardist.detectObjects(imageData, dup_ann); } ; removeObjects(Anns, true) // keep children of the removed annotation. `; best; Ofra",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1411#issuecomment-1790260581:658,detect,detectObjects,658,https://qupath.github.io,https://github.com/qupath/qupath/issues/1411#issuecomment-1790260581,1,['detect'],['detectObjects']
Safety,"Hi Pete, ; it happend two more times and I found in the log file, that the chosen channel 4 does not offer information for celldetection. After that QuPath switches automatically into channel 1. But Cell detection errors happen. Maybe because the switch is to slow?. You can see the nature of the cell detection errors in the screenshots. It happens, that QuPath copies celldetections form one part of the image into another one. I marked that in the screenshot above with the red polygons. . I changed the script using directly channel 1 instead of channel 4. ; Now it seems like not to happen anymore. I keep you updated. Since I changed the channel, I analysed only two more images. . The script uses fluorescence type on a DAB only stained jpg image for watershed cell detection. ; That seems to make no sence in the first place. But I found out by accident, that it allows cell detection in white areas if nuclei are not stained at all. ; This is very useful for many applications. . Is there any argument against this way for image processing of a brightfield image?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/153#issuecomment-370400288:204,detect,detection,204,https://qupath.github.io,https://github.com/qupath/qupath/issues/153#issuecomment-370400288,4,['detect'],['detection']
Safety,"Hi Pete, ; thank you for your answer. Indeed reset preferences enables the automate menu. ; We can reopen the scirpt editor. But loading the script causes the bug again and again. ; It happens directly with opening the script, before the first run. ; Is there anything else we can try to avoid it?. best; David",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/422#issuecomment-606430083:288,avoid,avoid,288,https://qupath.github.io,https://github.com/qupath/qupath/issues/422#issuecomment-606430083,1,['avoid'],['avoid']
Safety,"Hi Pete, dear all, . I merged annotations of the same class into an Area annotation with class. ; Afterwards I let QuPath run cell detection. ; But it does not count the cells inside the ROI anymore!; Normally the cell count will be shown in the annotions tab: ; ![grafik](https://user-images.githubusercontent.com/16352785/36159106-368468ea-10de-11e8-886e-467bf90ae69d.png). And, even a bigger problem: the cell count does not appear anymore in the annotations results!. Is it maybe a formation error after merging annotations?. I use the following script to merge annotations: . selectAnnotations();; annotations = getAnnotationObjects().findAll {it.isAnnotation() && it.getPathClass() == getPathClass(""NameOfClass"")}; mergeAnnotations(annotations); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""NameOfClass"")}; mergeSelectedAnnotations();",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/147:131,detect,detection,131,https://qupath.github.io,https://github.com/qupath/qupath/issues/147,1,['detect'],['detection']
Safety,"Hi Pete,. - We want the number of positive and negative cells and also the percentage of positive cells in the different regions: in the tumor center (500 µm from the tumor border) (black), in the invasive front (area between the green and black annotation) and in the tumor (blue). - In this case it was not problematic that the green region extended outside of the tissue since there were no cells of interest in this “white space”. But ideally it would also fallow the “cut”. - I always start with lining the tumor border (blue) and then I extend it 500µm to get the green one. After this I perform the cell detection in the green one (but the blue one always disappears) after this I run the classifier and when this is completed I ‘expand’ my green annotation with -500µm to get the blue one again and after this I ‘expand the blue one with -500µm to get the black one. I think it may be better that the green and blue would be hollow rings around the outside of the black one. Since we want to measure cells in three different regions: in the tumor center (500 µm from the tumor border) (black), in the invasive front (area between the green and black annotation) and in the tumor (blue).But as of now I don’t know if it is possible to establish this?. - We want to count every immune cell in the tumor (+ and -) but not the tumor cells. In the beginning I tried “Positive cell detection” but when using this command, the software also counted a lot of cells that weren’t immune cells. That is why I switched to the classifier, I am very pleased with the results the classifier is giving me. We are scoring 7 different staining’s (70 samples per staining) and I would like to train the classifier for each staining but within a staining I would like to apply the same classifier for each sample. - In total it will be around 500 images. - I am just starting and trying some things out. I will try to create the annotations before cell detection, but as I have mentioned above: I start with the b",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/198#issuecomment-411026150:611,detect,detection,611,https://qupath.github.io,https://github.com/qupath/qupath/issues/198#issuecomment-411026150,1,['detect'],['detection']
Safety,"Hi Pete,. I have used the code from ""Simple Tissue Detection"" for demonstration; purposes because I have no experience in Java (and Groovy too) development; at all. The few lines of demo code are simply placed between your ui/image; extraction code and the transformation of the tissue area mask to an; annotation.; Is it possible to reuse this module code and transfer to an extension or a; script?. Best regards,. Kai. Am So., 3. Jan. 2021 um 16:34 Uhr schrieb Pete <notifications@github.com>:. > Hi Kai,; >; > Thanks for the link, I only skimmed the first part of the paper. The; > method looks very interesting, I'll give some more thought about if/how it; > could be added to QuPath.; >; > In the meantime, you can already integrate whatever algorithms you like; > via scripting (in Groovy) or creating a Java extension. Changing/adding; > core algorithms raises a lot more complications in terms of user; > expectations and reproducibility (QuPath has thousands of users...), not to; > mention maintenance, and increasingly we need to think carefully about; > algorithms that handle images with different numbers of channels.; >; > Note that you can also use pixel classification; > <https://qupath.readthedocs.io/en/latest/docs/tutorials/pixel_classification.html>,; > which provides more sophisticated options than simply thresholding.; >; > I'd suggest reimplementing your changes as either a script or extension.; > Also, since this isn't a bug in QuPath, I will close the issue - the best; > place to discuss such things is the forum at; > http://forum.image.sc/tag/qupath; >; > Best wishes,; >; > Pete; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/657#issuecomment-753634843>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AEG6ZG4BEALLTARPZEDYZVLSYCFBTANCNFSM4VR5VYCA>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/657#issuecomment-753650048:51,Detect,Detection,51,https://qupath.github.io,https://github.com/qupath/qupath/issues/657#issuecomment-753650048,1,['Detect'],['Detection']
Safety,"Hi Pete,. Sorry I just saw your email in the junkbox. Thanks for informing that.; I have tried to look up the new writings for calling imageJ somewhere and modified a bit in my script and now it is working. P.S. I am a very beginner for writing the script. From: Pete <notifications@github.com>; Sent: 22 May 2020 07:46; To: qupath/qupath <qupath@noreply.github.com>; Cc: Wong, Dickson <dwong@ukaachen.de>; Comment <comment@noreply.github.com>; Subject: Re: [qupath/qupath] Failed to launch JVM (SOLVED) (#497). Glad it's resolved - I've just made a small change that will hopefully make QuPath's inability to load the old Weka extension a bit more graceful in v0.2.0, and also added a note on the downloads page for the extension to warn that it is incompatible. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fissues%2F497%23issuecomment-632495950&data=02%7C01%7C%7Cc314e1e59f974884e4a808d7fe135d77%7C5a6d5ee56edf4a26ba93f5872dbb9614%7C0%7C0%7C637257231445064114&sdata=eepYC0iEwfTzvOrYiM0sSczIVqw2XCVBl1XLca4S0QE%3D&reserved=0>, or unsubscribe<https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAL5RYCOZ67FFTMCPJL624QDRSYGQJANCNFSM4NHKGXFA&data=02%7C01%7C%7Cc314e1e59f974884e4a808d7fe135d77%7C5a6d5ee56edf4a26ba93f5872dbb9614%7C0%7C0%7C637257231445074103&sdata=VALeHGevcV768bCs06vCj7qhSGOSp827e%2Bw8ngY7%2BOU%3D&reserved=0>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/497#issuecomment-637489171:876,safe,safelinks,876,https://qupath.github.io,https://github.com/qupath/qupath/issues/497#issuecomment-637489171,2,['safe'],['safelinks']
Safety,"Hi Pete,. Thank you for the swift reply! The actual project file itself is stored in a local-only folder, since it is a much smaller size than the image files themselves. I apologize for not including the log, I was in full panic mode when I first realized what had happened and didn't think about looking through the log or at the version until much later. Do you think there is any way to get this data back? And do you think it will be safer if I have everything on an external hard drive for my next project, including all image and project files? I can also make individual project files for each image to avoid losing too much data at once, but that seems like a pretty time-consuming/ computationally intense option.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1313#issuecomment-1706882325:439,safe,safer,439,https://qupath.github.io,https://github.com/qupath/qupath/issues/1313#issuecomment-1706882325,2,"['avoid', 'safe']","['avoid', 'safer']"
Safety,"Hi Pete,. Thank you for your reply!; Version of QuPath you are using: 0.3.0; Type of classifier: RTrees; How many training annotations: 1+ Million to 3+ Million detected cells and 200+ annotations which cover 90% of the detected cells; Number of features for the classifier: 20 to 30; What happens on freezing: when freezing, only one core of CPU is running, less than 10G of 64G RAM is occupied. the rotating icon is keep rotating. Other issue:; Classify -> Train Object Classifier -> Select Class, the pop up window is minimized and can not be resized so I can't choose classes. This window issue happen in multiple place, when I choose Simple tissue detection from ""Ctrl-L"". When the number of detect cells is 3 million, Exporting objects will last 20 to 30 minutes, saving any change will take 3 to 5 minutes, importing a 7G geojson will take nearly 45mins to 1hour, not because of the shortage of resources. I noticed that the usage of CPU is 1 to 2 CPU and RAM is 6 to 10G when exporting and importing, much lower than I assigned to Qpath.. May you consider to re-write Qpath with other language to parallelize exporting, importing, saving etc. I/O related tasks and the Parquet format may be a better format than geojson. Without parallelize above task, Qpath is good at detection but freezing in the scenario of Millions level I/O, training and classifying. We have to turn to other tools to analyze the data exported from Qpath. Thank you Pete for your effort!; Charles",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/831#issuecomment-949927812:161,detect,detected,161,https://qupath.github.io,https://github.com/qupath/qupath/issues/831#issuecomment-949927812,5,['detect'],"['detect', 'detected', 'detection']"
Safety,"Hi Pete,. Thanks for your reply and sorry for posting in the wrong place! I was indeed wondering if it was a bug. Next time I'll post in the QuPath forum and only move to here if advised to do so!. You were right adding a . `selectAnnotations();`. did make this work. Unsure why though, as I thought superpixels were detections not annotations? I had tried with . `selectDetections();`. but was obviously unsuccessful. Thanks for your help and sorry again for posting in the wrong place!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/704#issuecomment-816696147:317,detect,detections,317,https://qupath.github.io,https://github.com/qupath/qupath/issues/704#issuecomment-816696147,1,['detect'],['detections']
Safety,"Hi Pete,. Very sorry if this issue has been addressed previously. I want to use QuPath as part of a project I am working on! I need a labelled image where each class represents a tissue type. The problem is I haven't been able to export the resulting detection as a labelled segmentation image. I went through the following script: https://petebankhead.github.io/qupath/scripting/2018/03/14/script-export-labelled-images.html, if I understand correctly this script exports an labeled image for each annotations and not the detection, found within a particular annotation. So far I was able to create a classifier that will allow me to classify the 3 labels of interest (Grey Matter ==1, White Matter ==2, Background ==3). Also, I use this classifier to classify the tissue types within one annotation, ideally this annotation is the size of the original image. BTW the classification tools in QuPath is amazing!. An example Image is shown below. . ![image](https://user-images.githubusercontent.com/34345427/50388480-98652e00-06f6-11e9-9cf0-6f51b6526e66.png). **What I want to do at this point is to be able to export the detection as a labelled segmentation image.** Thank you in advance!",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/251:251,detect,detection,251,https://qupath.github.io,https://github.com/qupath/qupath/issues/251,3,['detect'],['detection']
Safety,"Hi Pete,. having basically the same problem, could you give me a hint on how to extract all the polygons that are made in the image at once? So far your suggested code works for one polygon. I believe it works when you have selected one prior running the script. I was trying to select all (=make them all yellow) and then running the script but it still gives me only the coordinates of one polygon. Is there a way to avoid this heavy time-consuming task of selecting all the polygons individually and exporting them?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/95#issuecomment-388106470:419,avoid,avoid,419,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-388106470,1,['avoid'],['avoid']
Safety,"Hi Pete,. in retrospect, I shouldn't have added the middle button code to one of your existing events. Instead, I gave the code its own `viewer.getView().addEventHandler(MouseEvent.MOUSE_PRESSED, e -> {})` event, which hopefully makes it easier to follow. This has also solved my debouncing issues, it seems. I actually had code that logged whether a bounce was detected within 10ms (as detailed above) but never saw such an event. Interestingly, and this is code I left commented out in my commit, checking for `isStillSincePressed()` as you suggested led to missed clicks. That, or maybe my logic is flawed:; ```java; 			if (e.isMiddleButtonDown()) {; 				/* ; 				if (!e.isStillSincePress() ) {; 					logger.warn(""The mouse moved! {}"", System.currentTimeMillis());; 					return;; 				}; 				*/; 				...; 			}; ```; However, moving the mouse while pressing the middle button doesn't have any adverse effect. Cheers,; Egor",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1037#issuecomment-1237132670:362,detect,detected,362,https://qupath.github.io,https://github.com/qupath/qupath/pull/1037#issuecomment-1237132670,1,['detect'],['detected']
Safety,"Hi Pete,; I was wondering if QuPath is capable of predicting tumor percentage.; If the answer is, could you write up a brief summary?; Thanks,; Zhenzhen",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/364:50,predict,predicting,50,https://qupath.github.io,https://github.com/qupath/qupath/issues/364,1,['predict'],['predicting']
Safety,"Hi Pete,; thanks for your reply!. The latency is about 3 seconds, maybe this is to be expected. :-). If I understand you correctly then the cached tiles don't have to be regenerated on each pan action but will be if I toggle annotations, detections, etc., right?. I've attached a gif animation of the behavior. ![latency-demo](https://user-images.githubusercontent.com/4951046/79364460-ad984880-7f49-11ea-8d93-1c529efe4d56.gif)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/440#issuecomment-614153366:238,detect,detections,238,https://qupath.github.io,https://github.com/qupath/qupath/issues/440#issuecomment-614153366,1,['detect'],['detections']
Safety,"Hi Svidro, ; thanks for your ideas. ; I discovered that I merged twice and now work with the first part. . selectAnnotations();; annotations = getAnnotationObjects().findAll {it.isAnnotation() && it.getPathClass() == getPathClass(""NameOfClass"")}; mergeAnnotations(annotations). It does not change anything about the problem. ; Also the sleep time of 100 milliseconds does not help. . And I do not start celldetection immeadetly after merging. It comes much later. . The cell detection runs very well - as allways. They appear in the viewer and in the ""show detection results"". ; But not in the annotation results anymore AND not in the anntoations tab, where you can normally see the object count within an ROI/annotation. . I try to upload such an annotation qudata file.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/147#issuecomment-365446425:475,detect,detection,475,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365446425,2,['detect'],['detection']
Safety,"Hi Svidro,. Many thanks for the help. I think derived classes should work fine with me. I have trained a classifier and the problem is that it makes the sub-class “Tumour: Positive” but not “Stroma: Positive” and I can’t understand how to create this. Many tanks again, I’ll work on the nuclei shape more extensively later on. Lucia. From: Svidro <notifications@github.com>; Reply-To: qupath/qupath <reply@reply.github.com>; Date: Thursday, 18 October 2018 at 19:40; To: qupath/qupath <qupath@noreply.github.com>; Cc: ""Montorsi, Lucia"" <lucia.montorsi@kcl.ac.uk>, Author <author@noreply.github.com>; Subject: Re: [qupath/qupath] Elongated nuclei not correctly detected (#231). For the nuclei, I would recommend starting a thread on the forum where you can post some pictures, that sounds like more of a image analysis problem. 20X might also be challenging with truly thin, elongated nuclei. Even more challenging if the Hamamatsu defaults to saving with JPEG compression (bad for analysis, great for file size). You can both classify regions and cellular populations, so you can subdivide your sample into ""tumor"" and ""stroma"" annotations first, and then perform positive cell detection within each of those (or however many classifications you want). Another option is using derived classes, so that you would first classify by tumor and stroma, then classify the cells as positive or negative within those classifications: https://github.com/qupath/qupath/wiki/Object-classifications<https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fwiki%2FObject-classifications&data=01%7C01%7Clucia.montorsi%40kcl.ac.uk%7Cc0fb04b4d26e44a6d0fa08d63529246a%7C8370cf1416f34c16b83c724071654356%7C0&sdata=UQryuEzaf5zSNRtDGv8hrkp%2FfCUaV5EV%2FABLyh8vxoY%3D&reserved=0>. Either way, you can then ignore the stromal positive cells in the data processing (merge populations) however you want, or create a step that re-classifies any Stroma-positive to Stroma-negative, etc.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/231#issuecomment-431292156:660,detect,detected,660,https://qupath.github.io,https://github.com/qupath/qupath/issues/231#issuecomment-431292156,1,['detect'],['detected']
Safety,"Hi Svidro:. Thanks for your help!. I attempted to run your script but was unsuccessful. . I used the Estimate stain vectors function > Auto to make sure that the vectors were set correctly. I then ran Cell Detection followed by the Subcellular Classifier (Experimental) to identify the spots. QuPath nicely identifies the spots and separates the clusters! I then annotated ""Stroma"" (where the ISH signal is located) and ""Tumor"" and ran the Detection Classifier. QuPath perfectly separates stroma and tumor cells. Then I ran your script. QuPath seems to have classified all cells as if they have > 15+ spots. . Here is a screenshot. I would appreciate your thoughts. , ![image](https://user-images.githubusercontent.com/36250970/36341754-3ad312da-13c1-11e8-9287-eaed3de4b7d2.png). Thanks for your help!!!. Jim",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/146#issuecomment-366444082:206,Detect,Detection,206,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-366444082,2,['Detect'],['Detection']
Safety,"Hi Svidro:. When I run the Subcellular detection (experimental) command, the program perfectly identifies the red ISH spots in the image. Here are my subcellular detection parameters:; ![image](https://user-images.githubusercontent.com/36250970/36643217-911c24d2-1a16-11e8-9693-b8e3aeb1aee2.png). When I run the script: setCellIntensityClassifications(""Subcellular: DAB: Num spots estimated"",1,4,10), The program perfectly divides the classes into 4 categories, Negative 1+, 2+ and 3+:; ![image](https://user-images.githubusercontent.com/36250970/36643281-3288c096-1a17-11e8-8920-e47c8109b580.png). However, when I substitute your script for the one above (using exactly the same settings), the program fails to divide the classes into 5 categories (Negative through 4+) and here is the output: ; ![image](https://user-images.githubusercontent.com/36250970/36643319-b580f8ba-1a17-11e8-909d-6e6c5e619ee0.png). My goal is to have an 5-category output that will match the Advanced Cell Diagnostics scoring scheme. I would appreciate your thoughts. . Thanks!. Jim",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/146#issuecomment-368318946:39,detect,detection,39,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368318946,2,['detect'],['detection']
Safety,"Hi everybody,. I have IHC images to analyze and it has high DAB background. Probably because of the background, 'Cell detection' function does not work at all to detect any cells in the image even after changing the parameters. Could anybody help how to train Qupath to detect cells in this case?. I attach my script below and an original image as well. Thanks!. [Blank-C2M3.zip](https://github.com/qupath/qupath/files/3077842/Blank-C2M3.zip). ------------------------------------------------------------------------; setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB modified"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.71124 0.61052 0.34843 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.10193 0.39945 0.91107 "", ""Background"" : "" 225 175 148 ""}');; runPlugin('qupath.imagej.detect.cells.WatershedCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}');; ------------------------------------------------------------------------------------------------------",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/305:118,detect,detection,118,https://qupath.github.io,https://github.com/qupath/qupath/issues/305,5,['detect'],"['detect', 'detection', 'detectionImageBrightfield']"
Safety,"Hi everyone,. I tried using QuPath v0.2.0-m2 on my Mac with old qpdata files I had generated. They opened fine and it appeared that I could save the files when I was using the new version with qpdata files made with the old one. However, although it seemed to save, the original qpdata file is deleted or renamed/moved in such a way that I cannot find it anymore. It is not in the trash, and there is not a new/alternate file name generated in the same folder the original file was in. I know that in the window that appears when you open the new version that it says opening old files can make them incompatible, but I wasn't expecting to have no record of the file anymore. I have some alterations I made that would be great to recover, but otherwise, this is more reporting for a general notice. Thank you.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/292:730,recover,recover,730,https://qupath.github.io,https://github.com/qupath/qupath/issues/292,1,['recover'],['recover']
Safety,"Hi everyone. I'm running into problems with QuPath I first noticed when running positive cell detection on a bunch of TMAs. When I reviewed the results, the annotations were missing from a number of them. I was able to restore most from a backup, but following this positive cell detection has been erratic. . At the moment, positive cell detection will run, but will cut out before completing. There will be cores which work, but the majority do not. Once completed, the others can be manually selected and run through cell detection, which appears to work. The next problem arises once that file is saved, and another TMA is selected. If I then return to the original TMA I was working on, all the annotations will be missing, and the data file no longer opens (and appears to shrink to about half its previous size) suggesting it has been corrupted in some way. . This wasn't happening at the start of my project, so I'm not quite sure what's going on. . Any help would be greatly appreciated.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/174:94,detect,detection,94,https://qupath.github.io,https://github.com/qupath/qupath/issues/174,4,['detect'],['detection']
Safety,"Hi there!. I'm trying to get my head around the functionalities of QuPath in terms of automatic object detection (or segmentation). I'm currently working on a project that comprises the detection of mitosis on H&E stained slides. Since I'm not a med student, I'm having a hard time to understand whether I can transfer the analysis process in the tutorials (e.g. https://github.com/qupath/qupath/wiki/Detecting-objects). For me it seems that QuPath can detect cells/nuclei (?) and determine if they are positive or negative for the Ki-67 marker (?). Does this analysis include some sort of mitosis detection? From the german wikipedia page, I understand that the Ki-67 marker can be used to mark dividing cells which would be mitosis detection as I see it. Can this detection process also be transferred to H&E stained slides by QuPath then in any way? If not could QuPath be of any help in mitosis detection on H&E stained slides other than manually annotating them? . Thanks a lot for your help!",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/205:103,detect,detection,103,https://qupath.github.io,https://github.com/qupath/qupath/issues/205,8,"['Detect', 'detect']","['Detecting-objects', 'detect', 'detection']"
Safety,"Hi!. I managed to do cell detection and intensity analysis with 3 tresholds to all of my project images (about 70 images) with scripting. Now the question is that can I get the annotation measurements somehow written to one summary file so that there would be separate row for each images' measurements? Ideally excel-file. For the purpose now at hand I am only interested for one specific measure (H-Score), so can I filter somehow file building that only one/few wanted measures would be included?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/152:26,detect,detection,26,https://qupath.github.io,https://github.com/qupath/qupath/issues/152,1,['detect'],['detection']
Safety,"Hi, . I am using the classifier to detect positive and negative cells in a tumor, I am measuring them in three different areas: 500µm outside of the tumor (green), the whole tumor (blue) and tumor centre (black). When I substract the black one from the green one I get an idea of how many cells there are located in the invasive front of the tumor.; ; I do this by running the classifier on the biggest area (green) and expanding this annotation with -500µm to get the blue one and expanding this one with -500µm to get the black one. It gives me nice results; But because some of my slides only have a part of the tumor (cut), I want the black annotation to be merged with the yellow annotation (to get a correct estimation of the cells located in the invasive front).; When I do this, I get very low cell counts, while I see a lot more cells in that yellow area that should be counted as well. Is there a way to get the correct number of cells when merging two annotations after using the classifier?. Thanks!; Lieze. ![qupath classifier](https://user-images.githubusercontent.com/42168520/43763207-771611c6-9a2a-11e8-812a-5765bc54cdac.jpg)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/198:35,detect,detect,35,https://qupath.github.io,https://github.com/qupath/qupath/issues/198,1,['detect'],['detect']
Safety,"Hi, . I discovered by accident, that cell detections are copied from the top right into the bottom left area of JPG images, using watershed in fluorescence image type setting. ; It happened while analysing by script workflow and I can not reproduce it!. Here is a screenshot. The problematic areas are shown by red polygon: ; ![grafik](https://user-images.githubusercontent.com/16352785/36973101-df059924-2071-11e8-9ca8-558335596f0f.png); ![grafik](https://user-images.githubusercontent.com/16352785/36973240-712c0586-2072-11e8-8f7a-2e4732aaa2a6.png). Pete, if you need the qpddata file, it has 15 MB and can not be uploaded here. I can directly send it. ; . Best; David",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/153:42,detect,detections,42,https://qupath.github.io,https://github.com/qupath/qupath/issues/153,1,['detect'],['detections']
Safety,"Hi, . I have been using QuPath's cell detection algorithm on my H&E images for over a year now and I noticed a new parameter when running it today that I had not seen in the past- Requested pixel size. I'm not sure if I accidentally chose the wrong segmentation algorithm but usually when I do the watershed cell detection it looks exactly like the image posted below except without that parameter. Let me know if there is any other information I can give to help you understand this question. Thanks!. ![image](https://user-images.githubusercontent.com/10617598/64191503-a010d100-ce46-11e9-8b9b-78c79931fbe9.png)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/357:38,detect,detection,38,https://qupath.github.io,https://github.com/qupath/qupath/issues/357,2,['detect'],['detection']
Safety,"Hi, . if manually drawn annotations are converted into detections with the following script, they will be correctly counted in the annotation measurements. ; But the Annotation TAB at the left side will count only ""now detections minus one!""; Why is that?. import qupath.lib.objects.PathTileObject; import qupath.lib.roi.RectangleROI; import qupath.lib.scripting.QP. selectObjects { p -> p.getPathClass() == null && p.isAnnotation() && p.getROI().getArea() < 4000 }; annotations = getSelectedObjects(); // Create corresponding detections (name this however you like); def classification = getPathClass('NAME'); def detections = annotations.collect {; new qupath.lib.objects.PathDetectionObject(it.getROI(), classification); }. // Remove ellipse annotations & replace with detections; removeObjects(annotations , true); addObjects(detections); fireHierarchyUpdate()",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/259:55,detect,detections,55,https://qupath.github.io,https://github.com/qupath/qupath/issues/259,6,['detect'],['detections']
Safety,"Hi, ; I'm having some frustrating problems.; My first problem is: I counted cells manual (negative and positive), and then ran the 'positive cell detection' on my ROI. Thereafter, Qupath did not save my negative count but only my positive cells. Why is that? Now I lost a whole morning counting more then 2000 cells for nothing. Really frustrating and time consuming. Second problem: The program sometimes fails to run the command on both single and multi ROI. My solution was save the file, close Qupath and open it again. However, my third problem came a cross.... It didn't want to open my Qupath data file... Other files can be opened. I tried to open in by clicking on the file self and by drag and dropping it into qupath. I also tried opening the original file (CZI) and then drag and drop the Qupath file, but without succes. Does anyone have answers and release me of my frsutrations? or can the bugs be fixed please?. Cheers, ; Eline",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/112:146,detect,detection,146,https://qupath.github.io,https://github.com/qupath/qupath/issues/112,1,['detect'],['detection']
Safety,"Hi, ; QuPath looks like it could be an extremely useful tool for a standard analysis I do. Basically, I want to:; - Identify cells in spinal cord tissue sections, either automatically or by manually.; - I'm willing to draw ROIs by hand or some combination of auto-detect plus clean-up by hand. That's not horrible. But counting and finding overlaps, that is the part that I need to automate. ; - Identify the cellular staining: Usually, cells have (DAPI) and then one or more IHC signals (antibody) or ISH signal (RNAscope, which usually show as puncta); - Count the overlapping events: I want to see which cells have combinations of fluorescent signals: red alone, red+green, green alone, etc. Sometimes this will be binary (yes/no) but it'd be nice to make more bins like absent, low, medium and high. ; - Optional for ISH: Count puncta inside of cells. This is such a core analysis for a lot of neuroscience. I've tried to use Fiji and I still don't know how to do this in a straight forward way. I've resorted to just using Photoshop and manually counting, but that's a huge pain. CellProfiler looks like it might have some cool features, and I presented the problem there too:; http://forum.cellprofiler.org/t/rnascope-in-spinal-cord-neurons-quantitation-of-overlap-between-different-in-situ-probes/5355/3. But could some combination of QuPath + Cell Profiler (or QuPath alone) get the job done? I feel like it can. . Here is an example image:; ![composite](https://user-images.githubusercontent.com/7445362/33910649-7b71bcc6-df5d-11e7-92e8-468649392c9d.jpg). PS @petebankhead thank you so much for all your efforts. I've been enjoying the book you made on fluorescent image analysis as well.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/126:264,detect,detect,264,https://qupath.github.io,https://github.com/qupath/qupath/issues/126,1,['detect'],['detect']
Safety,"Hi, I have an image to analyse but do not have hematoxylin and wonder if I can do cell segmentation by using other colour detection? If yes then how can I change the script",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/155#issuecomment-617095912:122,detect,detection,122,https://qupath.github.io,https://github.com/qupath/qupath/issues/155#issuecomment-617095912,1,['detect'],['detection']
Safety,"Hi, I'm not completely sure I understand - is this what you are looking for? https://github.com/qupath/qupath/blob/v0.1.2/qupath-processing-ij/src/main/java/qupath/imagej/detect/dearray/TMADearrayerPluginIJ.java; You can also search for 'TMA' within the QuPath GitHub repository. This is shorter and might also help: https://github.com/qupath/qupath/issues/77#issuecomment-301234930",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/258#issuecomment-457601907:171,detect,detect,171,https://qupath.github.io,https://github.com/qupath/qupath/issues/258#issuecomment-457601907,1,['detect'],['detect']
Safety,"Hi, I'm trying to do something very simple (I think). I have slidescanner images from which I select 10 annotations which each have around 4,000 cells in. I want to run positive cell detection on all annotations however Qupath will not process more than 2 at a time. I'm using a 3.2GHz i5 with 8GB of ram. I've tried merging the annotations then running the positive cell detection. This sometimes works but is unreliable. I also thought I could write a script which processes each annotation individually however I don't know the code to select the first annotation, run detection, select 2nd annotation, run detection, etc.... Any help much appreciated!; Al",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/148:183,detect,detection,183,https://qupath.github.io,https://github.com/qupath/qupath/issues/148,4,['detect'],['detection']
Safety,"Hi, Svidro; Thank you so much for your help on the understanding of the features’ meaning! Do you know how to draw the cluster of the cells, or calculate the cluster features, as the photo I attached. I know it’s easy but I can’t find the way to make it.; Thank you so much for your help!; Xiaxia. From: Svidro [mailto:notifications@github.com]; Sent: Thursday, July 12, 2018 11:45 AM; To: qupath/qupath <qupath@noreply.github.com>; Cc: Meng, Xiaxia <XMENG2@mgh.harvard.edu>; Author <author@noreply.github.com>; Subject: Re: [qupath/qupath] What's the meaning of specific features in Qupath? (#185). External Email - Use Caution. More specifically for the coherence features, OD sum (you can have an OD sum sum, if you add up the total of each pixel's OD sum value, as opposed to the OD sum mean which is the average of each pixel's OD sum) will be the total optical density, and the tile diameter appears to be a circle/square around the centroid of the detection. Here I ran the coherence twice on OD sum where i had a very dark center of the cell. Notice that the sum/mean go up as I shrink the ""tile"" size to only fit inside the nucleus.; [Image removed by sender. coherence]<https://user-images.githubusercontent.com/23145209/42643926-29b98578-85af-11e8-9c33-385e5588d7e3.JPG>; The most dramatic change is in the minimum, once the entire tile would fit inside of the dark ""nucleus."". In general you might want to use that instead of smoothing, if you want ALL of the pixels around a detection out to a certain distance included in the measurement (tissue based measurements). —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/185#issuecomment-404557901>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AnH_7_REgO9uqIhkZxQGWmMVJq17ptFYks5uF278gaJpZM4VKA8r>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/185#issuecomment-404956257:955,detect,detection,955,https://qupath.github.io,https://github.com/qupath/qupath/issues/185#issuecomment-404956257,2,['detect'],['detection']
Safety,"Hi, sorry I'm coming to this a bit late... From looking at the image, I agree that it would be good to try to find a way to detect the regions you want with a threshold (maybe *Simple tissue detection* or an ImageJ macro). However, I can't really say very confidently how well this will work since I have not tried an application like this before. With regard to *Trainable Weka segmentation*, you might be able to run it through QuPath by pointing the ImageJ plugins directory (under *Edit &rarr; Preferences...*, double-click on the text field beside *ImageJ plugins directory*) somewhere where the *Trainable Weka segmentation* plugin and all its dependencies can be found (e.g. the *plugins* directory of a Fiji installation).; Then use *Send region to ImageJ* to send all or part of the image to ImageJ for processing, and call the *Trainable Weka segmentation* from there. > Note that QuPath won't actually use Fiji itself, but rather ImageJ1, so whenever you set the *plugins* directory to be that of a Fiji installation you may find that some commands don't work (if they have Fiji-specific dependencies). But I think *Trainable Weka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/56#issuecomment-288506877:124,detect,detect,124,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877,2,['detect'],"['detect', 'detection']"
Safety,"Hi, this sounds potentially very challenging in H&E. It may be possible using a combination of existing QuPath features, such as superpixels and random trees classifiers and cell detection, although the steps are likely to be quite involved and elaborate. But it is not really possible to judge the difficulty without seeing some example images. I'm currently embroiled a multitude of tasks necessary to make a new release of QuPath ahead of some talks and workshops in March; this release will have some new features that may very well be useful for this application, but I need to finish them first. In the meantime, since this is more a question about applying the software, and not an 'issue' as such, you might get more answers on the QuPath user forum at [Google Groups](https://groups.google.com/forum/#!forum/qupath-users)*. I'm afraid I can't help more myself at the moment, since I need to dive back into the code to try to meet the deadline... > *-Before getting too attached to the Google Group, I should mention that the main forum will likely move to https://forum.image.sc to coincide with the next release.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/262#issuecomment-458652442:179,detect,detection,179,https://qupath.github.io,https://github.com/qupath/qupath/issues/262#issuecomment-458652442,1,['detect'],['detection']
Safety,"Hi,. Cell detection seems to fail when being performed on large areas of tiff images. I seem to be able to run the cell detection on smaller areas, but when running on larger areas, it generates some message (that disappears too quickly to be read) and then leaves yellow box elements seen in the attached picture, which was taken after trying to do one of these cell detection. ; The image I'm using is a single large tiff image (~500Mb) generated by stitching tiles of a scan made by a Zeiss microscope together. Perhaps there is a better way to stitch these files to mimic one of the more standard file types?. ![capture](https://cloud.githubusercontent.com/assets/4945684/25635069/c14857f0-2f31-11e7-9d81-8209ca5bab58.JPG)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/69:10,detect,detection,10,https://qupath.github.io,https://github.com/qupath/qupath/issues/69,3,['detect'],['detection']
Safety,"Hi,. Congratulations for QuPath v2-mx series, amazing work!. Working with .ndpi files, ""No label available"". It would be useful to see the label in QuPath, e.g. when working with large collections of images from different experimental conditions, errors can easily occur when renaming the files after scanning, and being able to view the label would be valuable to detect possible errors, while at the same time adding an alternative to only relying on the file name for slide identification. Kind regards,; Carlos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/40#issuecomment-622099365:365,detect,detect,365,https://qupath.github.io,https://github.com/qupath/qupath/issues/40#issuecomment-622099365,1,['detect'],['detect']
Safety,"Hi,. I would like to know if it is possible to detect not only the percentage of positive cells but also the area that they occupy. ; What I tried to do was: 1. Use positive cells selection. 2. Create a classifier to differentiate between tumour and stroma and 3. send detections to ImageJ (in an intend to merge all the detections into a ROI and calculate the area occupied by positive tumour cells). My problem is that when I send the region to ImageJ i get all (tumour and stroma) detections and I cannot differentiate them anymore (in ImageJ all objects are treated as the same overlay).; Is there any way in QuPath to calcuate the area that occupy all positive tumour cells? and if not, is it possible to send only the detection of tumour cells to ImageJ already as a single selection? (because if I have thousands of detections and I want to merge them as a single ROI it has an extremely high cost in terms of processing power for the computer). Thanks.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/159:47,detect,detect,47,https://qupath.github.io,https://github.com/qupath/qupath/issues/159,6,['detect'],"['detect', 'detection', 'detections']"
Safety,"Hi,. I'm attempting to quantify a chromogenic ISH method that uses a fast-red signal. I have tried using the subcellular detection tool but it appears geared towards DAB signal detection. Is there a workaround/does anybody have any suggestions?. Thanks!. Matthew",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/119:121,detect,detection,121,https://qupath.github.io,https://github.com/qupath/qupath/issues/119,2,['detect'],['detection']
Safety,"Hi,. I'm trying to find a way to analyse the spheroids I have cultured and I feel like there must be a way to make QuPath tell these larger shapes with multiple cells inside apart from the scaffold they're in. Ideally, I would like it to detect amount of spheroids within a region and their size. Is this possible in any way? I've attached an example image of the spheroids for reference. Thanks,. Ieva. ![he_ch_17d_2](https://user-images.githubusercontent.com/34248337/33568732-c0439fc2-d927-11e7-8fc0-361db860aa8e.jpg)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/121:238,detect,detect,238,https://qupath.github.io,https://github.com/qupath/qupath/issues/121,1,['detect'],['detect']
Safety,"Hi,. Is it possible to run QuPath from command line? I would like to run your cell detection/classification part at scale with Azure Batch. . Thanks!",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/94:83,detect,detection,83,https://qupath.github.io,https://github.com/qupath/qupath/issues/94,1,['detect'],['detection']
Safety,"Hi,. Thanks for this new exciting version.; I was trying to compare InstaSeg results to StarDist results. InstaSeg is working nicely but the StarDist scripts (from Extensions>StarDist) fail with the following error.; I tried both H&E and Fluorescence scripts. (I set the model path). ```; ERROR: 'org.locationtech.jts.geom.Geometry qupath.lib.roi.GeometryTools.createRectangle(double, double, double, double)'; java.lang.NoSuchMethodError: 'org.locationtech.jts.geom.Geometry qupath.lib.roi.GeometryTools.createRectangle(double, double, double, double)'; at qupath.ext.stardist.StarDist2D.lambda$detectObjects$10(StarDist2D.java:940); at java.base/java.util.stream.ReferencePipeline$2$1.accept(Unknown Source); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(Unknown Source); at java.base/java.util.stream.AbstractPipeline.evaluate(Unknown Source); at java.base/java.util.stream.ReferencePipeline.collect(Unknown Source); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:941); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:886); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$6(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:859); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$5(StarDist2D.java:812); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:812); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript.run(QuPathScript:48); at org.codehaus.groovy.jsr223.GroovyScriptEngine",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1635:596,detect,detectObjects,596,https://qupath.github.io,https://github.com/qupath/qupath/issues/1635,1,['detect'],['detectObjects']
Safety,"Hi,; I want to test basic cell detection in QuPath, from the command line. ; Is it possible to enter coordinates (from a user) and a specified image, and then have QuPath run any script on that image?. eg. groovy detect.groovy -x 2,2 -y 3,3 ~/image.svc. This should open up image.svc, draw a rectangle from 2,3 to 2,3 and run the following code. It's default cell detection code from QuPath. `//setImageType('BRIGHTFIELD_H_DAB');; //; //setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; //createSelectAllObject(true);; //runPlugin('qupath.imagej.detect.nuclei.WatershedCellMembraneDetection', '{""detectionImageBrightfield"": ""Hematoxylin"", ""requestedPixelSizeMicrons"": 1.0, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 40.0, ""maxAreaMicrons"": 300.0, ""threshold"": 0.2, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": true, ""cellExpansionMicrons"": 15.0, ""limitExpansionByNucleusSize"": false, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}');; //selectObjectsByMeasurement(""Nucleus/Cell area ratio < .13""); //clearSelectedObjects(true);; //clearSelectedObjects();; //saveDetectionMeasurements('~', )`. I've seen some posts on creating a ROI from coordinates, but how do I run this from the command lane and not the QuPath script GUI? Should I include the QuPath code in the same code that handles parsing of command line arguments?. In essence, how do I link up the command line and QuPath?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/90:31,detect,detection,31,https://qupath.github.io,https://github.com/qupath/qupath/issues/90,5,['detect'],"['detect', 'detection', 'detectionImageBrightfield']"
Safety,"Hi,; On a whole-slide-image I use simple tissue detection to select the whole tumour area, then positive cell selection to identify positive cells and finally I train a classifier to distinguish between tumour and stromal cells.; I would like to know if it is possible to send to ImageJ ONLY the annotation of tumour cells because when I click send region to ImageJ i get all annotations as overlays even if I remove stromal annotations using Toggle dispaly class.; Thanks",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/108:48,detect,detection,48,https://qupath.github.io,https://github.com/qupath/qupath/issues/108,1,['detect'],['detection']
Safety,"Hi,; Thanks for the reply and sorry for late feedback. So, I tested it all with a fresh install of m3 and a clean dedicated folder for testing. the structure is as follows:. -TestFolder; -- ImageFolder; -- qupath_project_folder1; -- qupath_project_folder2. For both projects, I generate a fresh initialization, load all the images in the ImageFolder and do some operations (shapes, cell detection ...). My aim is to be able to open either of both projects and it finding the relevant image files relatively (going one folder up), especially after moving the TestFolder around. Now I tested it on different PCs and VMs and keep getting the same behavior, i.e. getting the prompt window to manually re-specify the URI paths. So either I am missing something or I am going wrong about it. While the prompt is not a problem for me per se, when sending the files to collaborators, people tend to get scared or confused by the prompt, so I wanted to manually specify relative paths to make it more user friendly.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/346#issuecomment-518195636:387,detect,detection,387,https://qupath.github.io,https://github.com/qupath/qupath/issues/346#issuecomment-518195636,1,['detect'],['detection']
Safety,"Hi. When running cell detection on Annotation with child annotation, the child annotation is being deletd.; An optional way to overcome this is by using ; `def annotations = getAnnotationObjects(); removeObjects(annotations, false); addObjects(annotations)`. as suggested for example in [this image.sc post](https://forum.image.sc/t/qupath-scripting-annotations-deleted-when-running-cell-detection/41292/6). I was thinking that resetting the object Hierarchy before cell detection and resolving it again afterward may be an alternative solution ; Is there a command that let you reset the object Hierarchy ? . Thanks; Ofra",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1411:22,detect,detection,22,https://qupath.github.io,https://github.com/qupath/qupath/issues/1411,3,['detect'],['detection']
Safety,"Hi:. The latest release of the QuPath v0.5.1:. [QuPath-v0.5.1-Mac-arm64.pkg](https://github.com/qupath/qupath/releases/download/v0.5.1/QuPath-v0.5.1-Mac-arm64.pkg); [QuPath-v0.5.1-Mac-x64.pkg](https://github.com/qupath/qupath/releases/download/v0.5.1/QuPath-v0.5.1-Mac-x64.pkg). The issue with Mac applications that use ad-hoc signatures is that, while they provide a code signing digest (or cdhash) allowing macOS to verify whether the app or component has been altered, they don't verify the identity of the developer. This means that macOS can detect if the code has changed but has no way to confirm who signed the code or if it comes from a trusted source. Key concerns with ad-hoc signatures include:. No Developer Identity Verification: Ad-hoc signatures don’t provide information about the developer’s identity, unlike certificates from Apple, which are linked to verified developer accounts. This can pose security risks as it’s harder to establish trust in the source of the code. Limited Use Cases: Ad-hoc signing is typically used for specific scenarios, such as:; Unsigned code running on Apple Silicon, where macOS requires all code to be signed, even if it’s just ad-hoc.; Web Apps on macOS 14 Sonoma, where the code isn't distributed via traditional app distribution methods. Security Risks: Since there is no certification authority involved in ad-hoc signing, it is easier for malicious or unauthorized code to be signed ad-hoc and executed, which could expose the system to potential vulnerabilities. I would recommend moving away from ad-hoc certificates and following the Apple Developer guidelines on application creation & distribution. For example, here is a free GUI application called ""Apparency"" that will help explain issues and test your applications.; https://mothersruin.com/software/Apparency/. ![image](https://github.com/user-attachments/assets/d69830e4-e271-430a-987c-c58b1b708481); ![image](https://github.com/user-attachments/assets/4a03b7ba-c911-486b-91de-2d86d0e",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1672:547,detect,detect,547,https://qupath.github.io,https://github.com/qupath/qupath/issues/1672,2,"['detect', 'risk']","['detect', 'risks']"
Safety,Hi; From your picture it seems to me that you:; - have detected cells in an elipse; - started making a classifier (the small red and green circles); - are satisfied with the classifier (the cells are classfied correctly). It seems that you already got some measurements registered in the oval like total number of stromal and tumor cells and probably also number of cells per mm^2. What additional measurements are you after? . - Cell measurements?; - Measurements specific to certain classified cells?; - Measurements specific to certain areas?. Much is possible. You probably have to do some scripting if you want something tailored to your specific needs. I think you might find more answers in the [qupath google group](https://groups.google.com/forum/#!forum/qupath-users),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/229#issuecomment-430237196:55,detect,detected,55,https://qupath.github.io,https://github.com/qupath/qupath/issues/229#issuecomment-430237196,1,['detect'],['detected']
Safety,"Hm, perhaps.. In my case I worked on 0.2.0-m2 only, and within a project, so there must be more to it... I've tried again with different images this morning after my post, and I found that processing 1 image worked, but running the analysis on a batch of 3 images did not... with a similar outcome (analysis stopped and lost all annotations).; Except this time I did get an error message (maybe I missed it last time). Here is part of it:. ```; INFO: 2159 nuclei detected (processing time: 21.18 seconds); INFO: 2159 nuclei detected (10%); INFO: 1803 nuclei detected (processing time: 19.79 seconds); INFO: 1803 nuclei detected (11%); ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:237); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:201); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.gui.scripting.QPEx.runPlugin(QPEx.java:258); at qupath.lib.gui.scripting.QPEx.runPlugin(QPEx.java:278); at qupath.lib.gui.scripting.QPEx$runPlugin.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:55); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:196); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:216); at Script3.run(Script3.groovy:6); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:317); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:155); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:767); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:697); at qupath.lib.gui.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:463,detect,detected,463,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,4,['detect'],['detected']
Safety,"Hmm, I am not sure about creating a multi-cell object on purpose, but you could use smoothing (_Add smoothed measurements_) or clustering to generate groups of classified objects, or re-classify/add additional classification based off of smoothed values. As far as boundary regions, if the necrotic space was sufficiently different in stain/color intensity, you could use ""_Add intensity features_"" and rather than using the cell ROI (which is the default), choose to use information from a 10/20um square or circle around the cell. If the mean value of your color of interest is increased or depressed by being next to sufficient necrotic area, you could detect that.; As far as I know, it extends in all directions equally, so keep that in mind!; ![image](https://user-images.githubusercontent.com/23145209/50932446-7cfa6280-141a-11e9-9368-8aab4f4a5f68.png). Come to think of it, if the necrotic regions are nuclei free, you might increase the cell expansion, and perform a subcellular detection that picks up the necrotic tissue specifically. And classify based on that.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/254#issuecomment-452892735:656,detect,detect,656,https://qupath.github.io,https://github.com/qupath/qupath/issues/254#issuecomment-452892735,2,['detect'],"['detect', 'detection']"
Safety,"Hmm, I still think your best option will be running something like the Simple Tissue Detection to get your annotation area to exclude all background that is external to your tissue (you may have to go over the edges yourself, and definitely play with the Max fill area, as setting it to just larger than the largest fat globule you want to measure is key!) so that you only have two populations, background/fat globule (low OD) and tissue (high OD).; You might also play with tiling your tissue annotation (pretty much everything I suggest will involve generating an annotation, I'm afraid) and then sending each tile to ImageJ for thresholding (Extensions->ImageJ->ImageJ Macro runner). The returned detections end up looking something like these... and depending on how much you play with your thesholds (both size and OD) you will see more or less of the errors around the edges. The tiling allows you to analyze the image in small enough sections such that ImageJ can handle the full resolution.; Edit: deleted on account of privacy. Maybe Peter will have something better I have not thought of, though :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/56#issuecomment-286453790:85,Detect,Detection,85,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286453790,2,"['Detect', 'detect']","['Detection', 'detections']"
Safety,"Hmm, interesting. We are getting different behavior or choosing a different step order. I am not sure I could get it to do that. Are you using version 0.1.2? And what OS (I don't think it should matter, but maybe Peter will know better)?. After running the dearrayer then selecting a core/cores to run cell detection, I see the following for cell by cell data.; ![tma names](https://cloud.githubusercontent.com/assets/23145209/24367053/12f1cd4e-12d0-11e7-8fc0-dabcda42d2cd.JPG)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/59#issuecomment-289508349:307,detect,detection,307,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-289508349,1,['detect'],['detection']
Safety,"Hmmm, I'm not sure what we gain from this?. We lose the ability to have multiple dialogs open to test the use of different parameters, e.g. for cell detection. And also, we lose the ability to double-click on a past entry under the 'Workflow' tab to open cell detection with the correct parameters. I think this is a really handy and important feature. So I'd tend towards rejecting and closing this, or have I missed a benefit?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1560#issuecomment-2255802929:149,detect,detection,149,https://qupath.github.io,https://github.com/qupath/qupath/pull/1560#issuecomment-2255802929,2,['detect'],['detection']
Safety,"Hmmm, for the min/max error do you see similar behavior to the previous problem *after* the exception has been thrown once? It sounds like a bug that can be fixed on the QuPath side with better thread handling. If QuPath recovers and can handle later radius adjustments then I think it's unconnected. The OpenCV thing is very weird indeed.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/776#issuecomment-874056600:221,recover,recovers,221,https://qupath.github.io,https://github.com/qupath/qupath/issues/776#issuecomment-874056600,1,['recover'],['recovers']
Safety,"Hmmm, this isn't a scenario I ever had to deal with myself... it looks like an unfortunate limitation of how the project arranges ```.qpdata``` files simply according to the image name stored for the entry in the image. There's no 'good' way to fix it currently, unless you're willing to put all your images in separate projects... which would kind of defeat the purpose of using a project. So you could try this as a workaround:. ```groovy; guiscript=true. // Get QuPath & project; def qupath = getQuPath(); def project = qupath.getProject(). // Loop through images, setting the name; // (actually accessing a private field... therefore 'bad'); project.getImageList().each {; def path = it.getServerPath(); int ind = path.lastIndexOf(':'); def scene = path[ind+1..-1]; def name = new File(path[0..ind-2]).getName(); it.putMetadataValue('Slide_ID', name); it.imageName = name + ' (' + scene + ')'; print it.imageName; }. // Need to set to null first to force update; qupath.setProject(null); qupath.setProject(project). // Be very careful is you use this to write the project!; // The logic is a bit weird and it will probably overwrite ; // the existing project - so duplicate your .qpproj file to be safer; //qupath.lib.projects.ProjectIO.writeProject(project); ```. Basically, this should rename the images in the project to include both the original file name and the scene. This should then be used by QuPath when arranging the ```.qpdata``` files afterwards. It won't automatically update the names of any existing data files - this would have to be done manually. It has the added bonus of setting the 'Slide_ID' keyword; if you right-click on the project, you can then choose to *Sort by &rarr; Slide ID*.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/103#issuecomment-332598953:1202,safe,safer,1202,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332598953,1,['safe'],['safer']
Safety,"How bad is this really...?. I remember from conversations with @melvingelbard that validating numbers in a text field is far from straightforward... at least if trying to handle `+-.,e`. These might be used for valid numbers, but at the point they are typed the text may not be a valid number. He wrote [this method](https://github.com/qupath/qupath-fxtras/blob/007d91581049d7fd9439fd233211dcecf44d8fef/src/main/java/qupath/fx/utils/FXUtils.java#L260) to help sort that. ControlsFX doesn't handle this so well: you can see it in the preference pane, built using ControlsFX. Find a numeric field, e.g. `Brush diameter`. You can type `50` but you *cannot* type `-50` in the usual way. But you *can* type `50` and then go back to add the `-` (or even `+`). It seems to use a validation that is much too eager. I find this to be more annoying and problematic, so the `ParameterPanelFX` errs on the side of 'type anything, it's up to you for it to make sense'. The main thing is that we shouldn't through exceptions too quickly. But you could try switching the parameter pane to use Melvin's method linked above and see if it behaves better. In any case, I think a solution belongs in `qupath-fxtras` since it is so fiddly. For the number of bins, you can set an upper limit on the parameter - but this will have the effect of using a slider instead. That might be fine in this case; if you need more customisation, then it'd be better to avoid `Parameter` altogether and just got straight to JavaFX (which could be preferable for the measurement table histograms since then it'd be easier to make the selections persistent).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1541#issuecomment-2162178336:1434,avoid,avoid,1434,https://qupath.github.io,https://github.com/qupath/qupath/issues/1541#issuecomment-2162178336,1,['avoid'],['avoid']
Safety,How to detect nuclei with different staining,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/83:7,detect,detect,7,https://qupath.github.io,https://github.com/qupath/qupath/issues/83,1,['detect'],['detect']
Safety,"I agree with @petebankhead here, since subcellular detections would too often get in the way. I think it would make more sense to _force the type of objects you want to have interact in this way to all have the same type_, though I acknowledge users might need dig around on the forum a bit to look up the right lines of script to accomplish this. . I can definitely see situations where different types of cells require different types of detection methods, for example larger macrophages that can be multinucleated requiring something like CellPose to create the boundary, which may, at the time, be simply a detection as there isn't a convenient way to create a multinucleated object. I still feel like it makes more sense to have a more convenient way to force detections to be cells, rather than trying to figure out a way to exclude subcellular detections when you do not want those interactions calculated - aside from removing the measurements after the fact.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1550#issuecomment-2189876097:51,detect,detections,51,https://qupath.github.io,https://github.com/qupath/qupath/issues/1550#issuecomment-2189876097,5,['detect'],"['detection', 'detections']"
Safety,"I am actually just getting into this from the other side, learning how to set up a deep learning model to take in images generated by QuPath. Part of the question is what kinds of images do you want to send out, and do you want to classify them ahead of time? For example, I am probably going to be looking at cells, so I intend to export the cell object (in this case each cell is ""polygon"" as an image:; ```; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, polygon.getROI())). ImageIO.write(img, 'PNG', new File(dirOutput, name + '.png')); ```; although I will need to edit the write name to both increment so that it does not overwrite, edit the name so it includes the class (for anything in the training set), and edit the ""polygon.getROI()"" so that it is the correct size. . Also, once you have your 256 by 256 tile size in micrometers (multiply out by the pixel width in the Image tab), you can also use the _Analyze-> Region identification-> Tiles and superpixels -> Create tiles_ to see what a grid export could look like for your Simple tissue detection annotation. And Pete beat me to it anyway! So I won't include my much more terrible box drawing script!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/137#issuecomment-357349047:1084,detect,detection,1084,https://qupath.github.io,https://github.com/qupath/qupath/issues/137#issuecomment-357349047,1,['detect'],['detection']
Safety,"I am afraid I do not know what the problem is with more than 3 channels, and I certainly do not have the programming experience to dive into it, unfortunately! I agree that it would be nice to be able to handle more fluorescence channels. I also understand the need to study co-expression of markers, however, which is very possible even after you split the channels into two images, provided each image still has DAPI in order for QuPath to generate the same exact cell population. Merging the data sets later gives you your co-expressors. For example, since the Detections output file is in the same cell by cell order, the first cell from image 1 might be positive for markers A and B, with the first cell in the second image positive or negative for marker C. Fluorescent channels are independent, anyway, though you would need an extra program such as R (or just Excel if your sample is small enough) to combine the data sets to see the co-expressing population cell by cell, and you would lack the visualization tools of QuPath, but you could get the data (percentage positive for each type, or per mm^2) with a fairly straightforward script!. As a side note, I think increasing the tile size to maximum dramatically decreases the export time in Pannoramic viewer. I have spent quite a while with it running on multiple computers though, so I understand it can be frustrating.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/49#issuecomment-278268312:564,Detect,Detections,564,https://qupath.github.io,https://github.com/qupath/qupath/issues/49#issuecomment-278268312,1,['Detect'],['Detections']
Safety,"I am encountering a bug; 1. Detect cells using something (StarDist, I did it with no cell expansion); 2. Run the script ; ```; def hierarchy = getCurrentHierarchy(); def cells = getDetectionObjects(); for (cell in cells) {; cell.measurements['Num neighbors'] = hierarchy.findAllNeighbors(cell).size() ; }; ```; 3. Try to remove the neighbors in another script; ```; def hierarchy = getCurrentHierarchy(); hierarchy.resetNeighbors(); ```; This does nothing; 4. Delete the cells and recompute them (by running StarDist again on the same region); 5. The cells still have the connections shown; 6. Run cell detection in a *new* region: The new cells also have connections; 7. Open another image that already had cells detected. Some cell regions also have connections where there were none before; 8. On this other image, trying to add neighbors to detections inside a new parent using the first script results works (Num Neighbors exists) but neighbor conenctions are not drawn in the viewer (although they are still showing for the previous detections)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1597#issuecomment-2404588353:28,Detect,Detect,28,https://qupath.github.io,https://github.com/qupath/qupath/pull/1597#issuecomment-2404588353,5,"['Detect', 'detect']","['Detect', 'detected', 'detection', 'detections']"
Safety,"I am getting the same problem using SLICs and classifiers to yield area; annotations for whole tissue slides. Detections are handled without a; problem, but the program freezes when I try to create margins for the; annotations. I do not run out of memory, but using the memory monitor I; notice a sawtooth pattern whe is the freezes happen. Perhaps it will run better if run from the command line since it no longer; will have to compete with the application thread?. I will set up a more powerful computer tomorrow. Perhaps that will handle; the problem. 7. feb. 2019 20:46 skrev ""Pete"" <notifications@github.com>:. It's hard to tell much here without a clearer idea of what 'a lot of rather; large and complex annotations' means, but it may very well be that there; are too many vertices that that slows down the rendering too much (on the; JavaFX application thread, same as the menus and rest of the GUI). If so it; isn't really a bug, but more pushing QuPath with a different application; than that for which it was previously designed/optimized... See https://github.com/qupath/qupath/wiki/Types-of-object for differences; in object types, and why it's not really intended to have very large; numbers of annotations. You might try having fewer vertices somehow, perhaps with *Objects →; Simplify annotation shape* or splitting larger annotations into smaller; ones (since annotations outside the field of view do not need to be; rendered). Or write a script that periodically converts annotations you; won't need to change any more into detections. Or try to leave parts of the; image that are particularly complex *unannotated*, and then interpret the; unannotated region appropriately later. (I was actually looking into this today for completely different reasons,; and may be able to improve the annotation handling somewhat... but it; doesn't help you now). —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub; <https://gith",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/267#issuecomment-461575920:110,Detect,Detections,110,https://qupath.github.io,https://github.com/qupath/qupath/issues/267#issuecomment-461575920,1,['Detect'],['Detections']
Safety,"I am not able to create classifiers because I am not able to select features. ""No features selected!"" when attempting to create detection classifier in the ""Advanced options"" drop down under ""Classifier"" in ""Create detection classifier"". . Seems like I am missing something simple -- any ideas?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/63:128,detect,detection,128,https://qupath.github.io,https://github.com/qupath/qupath/issues/63,2,['detect'],['detection']
Safety,"I am running a simple script to detect positive cells for DAB using a classifier.; Usually it works, but randomly (often for larger files) it suddenly stops classifying halfway through, and all of the workflow tiles change from red/yellow (in progress/completed) to blue. I wonder if this is due to memory issues, or is there another bug that I can work around?; Thanks!; Chris. script: ; setImageType('BRIGHTFIELD_H_DAB');; clearDetections();; resetSelection();; selectAnnotations();; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""backgroundRadius"": 40.0, ""medianRadius"": 0.0, ""sigma"": 3.0, ""minArea"": 10.0, ""maxArea"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansion"": 10.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Cytoplasm: DAB OD max"", ""thresholdPositive1"": 0.3, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.5, ""singleThreshold"": false}');; runClassifier('E:\\qupath projects\\prongf_cancer_project\\classifiers\\ptc_3.qpclassifier');",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/130:32,detect,detect,32,https://qupath.github.io,https://github.com/qupath/qupath/issues/130,3,['detect'],"['detect', 'detectionImageBrightfield']"
Safety,"I am running the groovy script in qupath as follows, but the saved image is the original image instead of the analyzed image. import qupath.lib.gui.ImageWriterTools; import qupath.lib.regions.RegionRequest; import qupath.lib.scripting.QPEx. def imageData = QPEx.getCurrentImageData(); def server = imageData.getServer(); def filename = server.getShortServerName(). setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; runPlugin('qupath.imagej.detect.tissue.SimpleTissueDetection2', '{""threshold"": 162, ""requestedDownsample"": 1.0, ""minAreaPixels"": 100000.0, ""maxHoleAreaPixels"": 500.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}');; int x = 0,y = 0;; int width=server.getWidth(),height = server.getHeight();; def request = RegionRequest.createInstance(imageData.getServerPath(),1, x, y, width, height);; ImageWriterTools.writeImageRegion(server, request,""d:/snapshot.png"");",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/216#issuecomment-420281214:646,detect,detect,646,https://qupath.github.io,https://github.com/qupath/qupath/issues/216#issuecomment-420281214,1,['detect'],['detect']
Safety,"I am sorry, I must have missed this message!. In my case, I was thinking to help extensions I use to take full advantage of this new feature. Specifically, I was looking into [`qupath-extension-abba`](), but the only thing stopping me from being able to port it is that [it checks](https://github.com/BIOP/qupath-extension-abba/blob/main/src/main/java/qupath/ext/biop/abba/AtlasImporter.java#L203) whether the current image is rotated or not. If it is, it applies a transformation to the imported ROIs. I guess interrogating specific image server is unfeasible (i.e. using `rotated_server.getRotation()`), however we could perhaps avoid requesting for the server if it can't be interrogated. Hence why I was thinking to expose the builders: extensions/scripts can decide whether to make the server concrete based on their implementation.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1489#issuecomment-2396452661:631,avoid,avoid,631,https://qupath.github.io,https://github.com/qupath/qupath/pull/1489#issuecomment-2396452661,1,['avoid'],['avoid']
Safety,"I am sure the answer to this question is simple but I just don´t find it in the ""user guide"". I created a detection classifier (to distinguish between tumor, stroma and immune cells) which was doing ok, so I saved it for later use. When I created it, it got better and better as I drew more annotations and set their class. However it is not working as well as it needs to. So I loaded it again today in an attempt to continue training it. I opened the classifier (Classify -> load classifier (the one I had saved the other day) -> run classifier. At this point it worked like it had when I saved it. How do I continue teaching it from here on? Drawing annotations and setting their class doesn´t work like it did when I created the classifier. Selecting Classify -> create detection classifier does not work because this way I am creating a whole new classifier. How can I get my existing classifier in the mode where I can press auto update or where it automatically continues to update? I must be missing a very simple step! . I have one more question: I am using the classifier on a TMA slide. The TMA cores differ quite a bit. So I have to adjust/train the classifier slightly for each single core until it works the way I want. Do these changes in classification only apply to the selected annotation (TMA core) or does this automatically change the classifications already made using the classifier in other TMA cores on the same slide? ; Thank you very much for your help! . Kind regards,. Liese",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/57:106,detect,detection,106,https://qupath.github.io,https://github.com/qupath/qupath/issues/57,2,['detect'],['detection']
Safety,"I am working on the IHC staining of cancer slides. I want to do several annotations on a image and run the simple tissue detection to outline tissue areas within each annotations. However, every time I run simple tissue detection, it will annotate the whole slides and remove my annotations. Is that a way to limit the simple tissue detection within each annotation?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/248:121,detect,detection,121,https://qupath.github.io,https://github.com/qupath/qupath/issues/248,3,['detect'],['detection']
Safety,"I can start a new thread for this if you want, but the error I was referring to earlier I could replicate quickly by generating a decent number of subcellular detections... and then trying to double click on a cell in the viewer to see values. After this happens, any interaction with the viewer results in the same Exception spam popup in the corner of the program. The popup itself says Stack Overflow. > ; > qupath.imagej.detect.cells.SubcellularDetection {""detection[Channel 1]"": 2000.0, ""detection[Channel 2]"": 2000.0, ""detection[Channel 3]"": -1.0, ""doSmoothing"": false, ""splitByIntensity"": false, ""splitByShape"": true, ""spotSizeMicrons"": 1.0, ""minSpotSizeMicrons"": 0.5, ""maxSpotSizeMicrons"": 2.0, ""includeClusters"": true}; > INFO: Processing complete in 34.46 seconds; > INFO: Completed!; > INFO: ; > qupath.imagej.detect.cells.SubcellularDetection {""detection[Channel 1]"": 2000.0, ""detection[Channel 2]"": 2000.0, ""detection[Channel 3]"": -1.0, ""doSmoothing"": false, ""splitByIntensity"": false, ""splitByShape"": true, ""spotSizeMicrons"": 1.0, ""minSpotSizeMicrons"": 0.5, ""maxSpotSizeMicrons"": 2.0, ""includeClusters"": true}; > ERROR: QuPath exception; > at javafx.scene.Node.access$100(Node.java:398); > at javafx.scene.Node$1.doMarkDirty(Node.java:424); > at com.sun.javafx.scene.NodeHelper.markDirtyImpl(NodeHelper.java:158); > at com.sun.javafx.scene.shape.ShapeHelper.markDirtyImpl(ShapeHelper.java:80); > at com.sun.javafx.scene.NodeHelper.markDirty(NodeHelper.java:98); > at javafx.scene.shape.Shape$2.invalidated(Shape.java:463); > at javafx.beans.property.ObjectPropertyBase.markInvalid(ObjectPropertyBase.java:112); > at javafx.beans.property.ObjectPropertyBase.set(ObjectPropertyBase.java:147); > at javafx.css.StyleableObjectProperty.set(StyleableObjectProperty.java:82); > at javafx.css.StyleableObjectProperty.applyStyle(StyleableObjectProperty.java:68); > at javafx.scene.shape.Path.<init>(Path.java:139); > at impl.org.controlsfx.skin.BreadCrumbBarSkin$BreadCrumbButton.createButtonShap",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/307#issuecomment-484622516:159,detect,detections,159,https://qupath.github.io,https://github.com/qupath/qupath/issues/307#issuecomment-484622516,9,['detect'],"['detect', 'detection', 'detections']"
Safety,"I can think of easy enough ways to get the single horseshoe idea to work, but it sounds like you would want this to find multiple holes and interconnect them all, and the outside of the exterior polygon? At that point you need something like nearest neighbors to find the closest vertices of all of the inner polygons, and after that connect the inner polygons to the outer polygon using another nearest neighbors based on the entire interior structure... And this could get really bad depending on how many vertices were on the outer polygon (open up a massive highway if two vertices are far enough apart due to smoothing or the edge of an image/slide). Maybe a safer way would be to create very thin (1 pixel wide) rectangles between single vertices and subtract annotations? Just kind of spitballing here. I do not have enough experience digging into AWT polygons to know the structure of the vertices.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/177#issuecomment-398244678:664,safe,safer,664,https://qupath.github.io,https://github.com/qupath/qupath/issues/177#issuecomment-398244678,1,['safe'],['safer']
Safety,"I can't claim to be fluent in Java but I had a look at the code in Bioformats and went at my TIFF files with a hex editor and I don't understand where that NUL comes from. Bioformats uses a routine to read the image name that starts at some specific offset and stops on NUL (so extracts a classic C-style zero delimited string but without the NUL). The image file has additional NULs after the terminating NUL but they should not matter if I understand the function correctly. Strange.; I also get no NUL when using bfconvert to convert from (SIS-)TIFF to OME-TIFF and open that file in QuPath. Strange.; And I agree, it's not really QuPath's responsibility. But since NUL is illegal in Windows' clipboard anyway, one could see it as a ""safeguard"" for proper clipboard function, independently from the originating data source. ;-). https://github.com/ome/bioformats/blob/d572fc0240c168cf9ca5260ddebdde55a16ff6fd/components/common/src/loci/common/RandomAccessInputStream.java#L255; https://github.com/ome/bioformats/blob/d572fc0240c168cf9ca5260ddebdde55a16ff6fd/components/common/src/loci/common/RandomAccessInputStream.java#L191; https://github.com/ome/bioformats/blob/c68f457223d9bd6be73490632774d23df7c58390/components/formats-gpl/src/loci/formats/in/SISReader.java#L174. ![hex_tiff](https://user-images.githubusercontent.com/4951046/88569158-51f65480-d03a-11ea-8688-405e246a89dc.PNG)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/573#issuecomment-664512769:737,safe,safeguard,737,https://qupath.github.io,https://github.com/qupath/qupath/issues/573#issuecomment-664512769,1,['safe'],['safeguard']
Safety,"I can't replicate this - on my Mac, if the simple tissue detections have been unlocked then I can edit them using the brush tool as expected. I am not sure what is the significance of shift/cmd here. Can the annotations be edited if these are not pressed?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/456#issuecomment-619373343:57,detect,detections,57,https://qupath.github.io,https://github.com/qupath/qupath/issues/456#issuecomment-619373343,1,['detect'],['detections']
Safety,"I can't speak for @ElEd2 (thanks from me too for the scripts!), but performance should be ok. One important thing is that you should *definitely* use `PathDetectionObject` and not `PathAnnotationObject`, just like in the code above (there's a comparison of the different object types [here](https://github.com/qupath/qupath/wiki/Types-of-object#annotations--detections)). With this many objects involved, you also probably don't want to add your objects to the hierarchy one-by-one within the loop, since this will trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/81#issuecomment-357045269:358,detect,detections,358,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269,1,['detect'],['detections']
Safety,"I cannot make pytorch work. I tried also with a conda env but nothing works. Even if I just select CPU in Instantseg, it tries to load the cuda version. Problem is that it detects cuda 12.1 so maybe it does not even want to try to load the CPU version?. `Failed to load PyTorch native library; ai.djl.engine.EngineException: Failed to load PyTorch native library; 	at ai.djl.pytorch.engine.PtEngine.newInstance(PtEngine.java:90); 	at ai.djl.pytorch.engine.PtEngineProvider.getEngine(PtEngineProvider.java:41); 	at ai.djl.engine.Engine.getEngine(Engine.java:190); 	at qupath.ext.instanseg.core.PytorchManager.lambda$getEngineOnline$0(PytorchManager.java:28); 	at qupath.ext.instanseg.core.PytorchManager.callWithTempProperty(PytorchManager.java:114); 	at qupath.ext.instanseg.core.PytorchManager.callOnline(PytorchManager.java:106); 	at qupath.ext.instanseg.core.PytorchManager.getEngineOnline(PytorchManager.java:28); 	at qupath.ext.instanseg.ui.InstanSegController.downloadPyTorch(InstanSegController.java:826); 	at qupath.ext.instanseg.ui.InstanSegController.ensurePyTorchAvailable(InstanSegController.java:815); 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(Unknown Source); 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.exec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source); 	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source); Caused by: java.lang.UnsatisfiedLinkError: C:\Users\username\.djl.ai\pytorch\2.3.1-cu121-win-x86_64\cudnn_cnn_infer64_8.dll: The specified procedure could not be found; 	at java.base/jdk.internal.loader.NativeLibraries.load(Native Method); 	at java.base/jdk.internal.loader.NativeLibraries$NativeLibraryImpl.open(Unknown Source); 	",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1636:172,detect,detects,172,https://qupath.github.io,https://github.com/qupath/qupath/issues/1636,1,['detect'],['detects']
Safety,"I created a script to detect CD3 positive cells and export annotations as txt. It runs on a single image, although the txt file only contains the column headers, no results. When I run it for project it does not run (no cell detection) and also creates txt file only contains the column headers. Could you help me out?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/268:22,detect,detect,22,https://qupath.github.io,https://github.com/qupath/qupath/issues/268,2,['detect'],"['detect', 'detection']"
Safety,"I don't think changing the extension of .qpdata files works here, and this may be the source of not being able to access it - would need to zip up the original file. But note that the cell count is never shown when an annotation is *classified* in that location in QuPath v0.1.2. It's also not an ideal place to get this number, because it is not actually a cell count but rather a count of the number of *direct child objects*. This should be the same as the cell count if there are no other objects (e.g. nested annotations), but otherwise it may not be. In my own QuPath fork I've added a detection count to the main built-in measurements for all annotations, which looks deeper through the hierarchy to get all cells - even if they are inside nested annotations. This works also for unclassified cells, but in v0.1.2 counts are only provided if the cells are classified. As a workaround in v0.1.2 you could set your cells to have any arbitrary class, e.g.; ```groovy; getCellObjects().each { it.setPathClass(getPathClass('My cell')) }; fireHierarchyUpdate(); ```; Then they should at least appear in any annotation measurement tables.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/147#issuecomment-365536462:592,detect,detection,592,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365536462,1,['detect'],['detection']
Safety,"I extended the export-import Script from Pete to be able to to export import of annotations in batch mode for many images - dependent on their names. The scripts create annotation folders and create annotation databanks. . **Script for anotation export (without detections or cells):** . import qupath.lib.scripting.QPEx; // Get the imageData & server; def imageData = QPEx.getCurrentImageData(); def server = imageData.getServer(); // Get the file name from the current server; def name = server.getShortServerName(). def path = QPEx.buildFilePath(QPEx.PROJECT_BASE_DIR, ""annotations""); QPEx.mkdirs(path). def path2 = buildFilePath(PROJECT_BASE_DIR,""annotations"", name +'_annotations'); def annotations = getAnnotationObjects().collect {new qupath.lib.objects.PathAnnotationObject(it.getROI(), it.getPathClass())}; new File(path2).withObjectOutputStream {; it.writeObject(annotations); }; print 'Done!'. **This script is for import the annotation - works only with corresponding image names:** . import qupath.lib.scripting.QPEx; // Get the imageData & server; def imageData = QPEx.getCurrentImageData(); def server = imageData.getServer(); // Get the file name from the current server; def name = server.getShortServerName(). def path = buildFilePath(PROJECT_BASE_DIR, ""annotations"", name + '_annotations'); def annotations = null; new File(path).withObjectInputStream {; annotations = it.readObject(); }; addObjects(annotations); print 'Added ' + annotations",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/235#issuecomment-433603073:262,detect,detections,262,https://qupath.github.io,https://github.com/qupath/qupath/issues/235#issuecomment-433603073,1,['detect'],['detections']
Safety,"I feel that is likely to cause more confusing and maintenance headaches as the software develops, mostly for the reasons I outlined above. Commands will change and improve. The same command (e.g. *Load object classifier*) might meaningfully only work for detections now, but handle other object types in the future (I think that, in principle, it already *does* support other object types, if you can somehow create and save a classifier that applies to annotations). There had been a *Train detection classifier* in earlier versions, so the renaming in that case was to reduce confusion because there was a transition period during which both commands were maintained in parallel. If we move things, we need to update the documentation - and some of the docs are in the form of videos, so that's not straightforward. And if we push the term 'detection classifier' it will likely confuse *someone* who thinks it isn't relevant to them because they have cells, not detections. I don't think the current arrangement is ideal, but we are always trying to balance the current software with the past, the future, the docs, and a large number of users with very different needs and expectations... and a very small number of developers. Added to that are the people who write extensions, for whom changing menu structures can cause trouble. It is not an easy project to manage.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1501#issuecomment-2079524506:255,detect,detections,255,https://qupath.github.io,https://github.com/qupath/qupath/issues/1501#issuecomment-2079524506,4,['detect'],"['detection', 'detections']"
Safety,I find that defining the inner region from expanding the outer region and intersecting with the original area helps to avoid getting an inner margin in regions where the area of interest expands all the way to the tissue border where it makes no sense to add an inner margin. The central margin is then just the original area - the inner margin,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/198#issuecomment-468241801:119,avoid,avoid,119,https://qupath.github.io,https://github.com/qupath/qupath/issues/198#issuecomment-468241801,1,['avoid'],['avoid']
Safety,"I had forgotten about this, but someone [recently brought up](https://github.com/qupath/qupath/issues/185) something that could be used for hot spot analysis. . QuPath does actually have a built in way of detecting what I think you are looking for, assuming you have cells that are classified. If you are still working on this, you might be able to use the Delaunay clustering (with both boxes checked), to identify areas where you have clusters of cells that are the same class. You could then use the ""Cluster size"" measurement to perform further classification and identify the hotspot, possibly by creating a list of all of the cell XY coordinates, and then taking the four outermost coordinates to form a ""box"" around your cluster. That box would have a centroid of it's own which could be used for comparison with other hot spots, either further clustering of hot spots or distance analysis... etc. ![cluster analysis](https://user-images.githubusercontent.com/23145209/42777909-4a01c2ac-88f0-11e8-97ed-3b7176dcfef0.JPG). Just a thought.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/181#issuecomment-405348162:205,detect,detecting,205,https://qupath.github.io,https://github.com/qupath/qupath/issues/181#issuecomment-405348162,1,['detect'],['detecting']
Safety,"I hadn't seen the problem where some lines require multiple corrections, but from your explanation I think I understand what has happened. The issue should be predictable and reproducible; here's the background:. * When a line is drawn, it is represented inside QuPath by the coordinates of its end points, ```(x1,y1)``` and ```(x2,y2)```; * When the line is saved, these coordinates are written (correctly) into the ```.qpdata``` file; * When the ```.qpdata``` file is loaded again later, the first thing QuPath does is read the coordinates and convert them into ```(x1, y1)``` and ```(x2-x1, y2-y1)```. This last step is a bug; there is no need to subtract the first coordinates from the second. It happens because, long ago (and before being released), QuPath stored its lines differently (with the first coordinate and then displacement).... and this bit of the code was not updated when it should have been, and lines were used rarely enough for it to go unnoticed. With that in mind, the error can be cumulative; if you open a ```.qpdata``` file and the lines display wrongly, and then you save it again, QuPath will now save the wrong coordinates... and, when reading them, make them even more wrong, i.e. ```(x2-x1-x1, y2-y1-y1)```. You'd have to run the script twice to fix such lines. Therefore it is important to have all your lines corrected before you save, and then run the script to fix them immediately after opening the image. This avoids having a combination of correct and incorrect lines on the image at the same time. The purpose of the script is to go through and fix the second coordinate for all your lines by adding the first coordinate. It does this for all lines, regardless of whether or not they are correct. If you want to change only some of the lines then @Svidro's idea is great - select the lines you want to change (e.g. in the list at the top of the *Annotations* tab on the left of the screen) and run this script instead:. ```groovy; getSelectedObjects().each {; ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/71#issuecomment-299623260:159,predict,predictable,159,https://qupath.github.io,https://github.com/qupath/qupath/issues/71#issuecomment-299623260,1,['predict'],['predictable']
Safety,I have an issue with the example script called Exporting detection centroids [https://github.com/qupath/qupath/wiki/Scripting-examples#exporting-detection-centroids](url). The script is outputting the X and Y coordinates of detections but these are not the same as the X and Y coordinates I see when I click on _Show measurement table_ then _Show detection measurement_. And in terms of the general pattern of the numbers (as compared by scatterplots) they seem to be the same but after min-max normalisation they were still different. I am a bit confused by what exactly is this command (_roi.getCentroidX()_ for Centroid X) in the script doing and why is it different from the one I see on the left hand side of QuPath _(Hierarchy--Value--Centroid X)_?. Any help is much appreciated!,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/214:57,detect,detection,57,https://qupath.github.io,https://github.com/qupath/qupath/issues/214,4,['detect'],"['detection', 'detection-centroids', 'detections']"
Safety,"I have kept meaning to try the Weka plugin, but never seemed to get around to it! This sounds like an excellent chance to test it out.; Somewhat related, I am not sure I understand exactly what you are measuring, but if you are measuring ""the amount of white space"" in your tissue, I have a couple of suggestions.; 1. Create a macro that sends your annotation areas to ImageJ, which can then create detection objects from a mask created to detect below/above a certain ""white"" threshold.; 2a. Built in, create a smallish annotation that includes significant whitespace and your tissue of interest. Next use the Analyze->Preprocessing->Estimate stain vectors to both set your background to the mode (first popup), and secondly set one stain vector as best you can to line up with your detections, and the other you can pretty much ignore.; ![step1](https://cloud.githubusercontent.com/assets/23145209/23876638/b0997bee-07fb-11e7-9c2a-434dacaddead.JPG); 2b. Use the Analyze->Region Identification->Positive Pixel Count (experimental) with very a very low threshold for the stain vector you used in the previous step, and an absurdly high threshold for your second vector which we will ignore. I would iterate a few times on a VERY small area, as this is very computationally intensive, and the program tends to respond very slowly for me after running it on a large area.; 2c. Once you have your settings and run the pixel count on your annotation, you can use your pixel area and the total area to get a percentage of total pixels that are below threshold. In the case of my image, I used the hematoxylin vector, so I multiplied the negative pixel count times the area of my pixels (seen under the image tab, Pixel Width and Pixel Height) and used that to obtain a percentage of non-tissue area within my annotation. You can see that in the Excel window, and that it roughly matches up with what you can see in the annotation.; ![step2](https://cloud.githubusercontent.com/assets/23145209/23877031/93cf",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/56#issuecomment-286257042:399,detect,detection,399,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286257042,3,['detect'],"['detect', 'detection', 'detections']"
Safety,"I have seen the same error before, but not since updating to JDK 14 (which will be a minimum requirement for v0.2.0, since it greatly simplifies building by including jpackage). To avoid the error with JDK 11-13, I think you'd need to change the build script to include more modules with jlink.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/436#issuecomment-612953950:181,avoid,avoid,181,https://qupath.github.io,https://github.com/qupath/qupath/issues/436#issuecomment-612953950,1,['avoid'],['avoid']
Safety,"I have seen the tiny rectangle appear whenever I use the brush tool in 'subtract' mode (with the ```Alt``` key down), and remove the entire area. However, in that case it is just a display thing - and the rectangle quickly disappears. But based on your post I've just checked and I can reproduce it using *Subtract selected annotations*... in which case the rectangle can hang around for longer. It still *does* disappear (sometimes...) if I select it, then start drawing a new annotation - but not entirely consistently. What I think is happening is this:; * Whenever a ROI is effectively removed (either with the brush tool or subtraction), it results in a rectangle at location (0, 0) with zero width and zero height - this is nevertheless still drawn on screen; * When removing with the brush tool, a sanity check is applied to see if the resulting ROI has no area - and if so, the object is removed (e.g. [see here](https://github.com/qupath/qupath/blob/61a382e1e345e671b3fde32da08e03f08f4f7bcf/qupath-gui-fx/src/main/java/qupath/lib/gui/viewer/tools/AbstractPathDraggingROITool.java#L100)); * This sanity check isn't applied with the *Subtract selected annotations* command... so the 'empty' ROI does not result in the object being automatically removed; * Sometimes the sanity check can be triggered later... but it entirely clear when and why. I've flagged this as a bug, since something here is definitely not right and should be fixed. I do think that there is a broader issue with the usefulness of the commands for combining annotations; these can and should behave more predictably. It may not be helped by the fact that for a long time (before release) QuPath didn't support multiple objects being selected simultaneously, and much of the original code was written back in those days; as you can imagine, this was quite limiting. You're completely right about support for subtracting multiple annotations being tricky from a how-to-present-this-to-the-user point of view. I will give thi",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/78#issuecomment-302926092:805,sanity check,sanity check,805,https://qupath.github.io,https://github.com/qupath/qupath/issues/78#issuecomment-302926092,1,['sanity check'],['sanity check']
Safety,"I have the same problem with CZI files. . Pete answered with this - i didnt try to find if my settings were FL instead of brightfield yet, but most of the suggestions i tested already. It did not help. Here the suggestions: . This happens whenever QuPath is unable to detect any cores. There are a few reasons why this may occur:. The Image type is wrong (e.g. set to fluorescence rather than brightfield) - this can be seen after clicking on the Image tab on the left. There is a screenshot here.; The specified TMA core diameter is either too large or too small. QuPath determines the expected TMA grid from 'complete' cores, which have a diameter within a small tolerance of the value set in the dialog box. If no cores fall within this tolerance, the grid cannot be found.; The intensity threshold is either too high or too low (but it is automatically determined from the data, and I don't see any reason in your image why it would be determined wrongly). If the image type is set correctly, then I would try increasing and decreasing the TMA core diameter to see if this gives any improvements. If not, then there may be some issue happening internally when trying to read from the CZI file - although I have not seen such a problem before. The contents of View → Show log may be helpful to track down the problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/53#issuecomment-282308795:268,detect,detect,268,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282308795,1,['detect'],['detect']
Safety,"I have tried to write several lines of code to get the subimage:. def imagelist = server.getSubImageList(); print(""Note: .vsi image list detected"" +imagelist); def project = getProject() //usually is null if no project opened; print(project); if (project != null){; def entries = project.getImageList(); }; def aSubImg = imagelist.getAt(4) ; print(aSubImg) //Series 4 (20x_04); def aSubImgPath = server.getSubImagePath(aSubImg); print(aSubImgPath) //file:/D:/QMDownload/6/BatchII%2024%20h%206%23_20190314.vsi#4. But now I can not find a way to set the subimage as active, so as to use the server to do further stuff on current active subimage",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/296#issuecomment-475876274:137,detect,detected,137,https://qupath.github.io,https://github.com/qupath/qupath/issues/296#issuecomment-475876274,1,['detect'],['detected']
Safety,"I haven't been able to replicate this issue. If I set the stains with the following script; ```groovy; setImageType('BRIGHTFIELD_OTHER');; setColorDeconvolutionStains('{""Name"" : ""My strange stains"", ""Stain 1"" : ""Orange"", ""Values 1"" : ""0.012 0.276 0.961"", ""Stain 2"" : ""Black"", ""Values 2"" : ""0.631 0.631 0.451 "", ""Stain 3"" : ""Purple"", ""Values 3"" : ""0.304 0.922 0.239"", ""Background"" : "" 255 255 255 ""}');; ```; Then all three turn up under _Subcellular spot detection_ as options. There is some logic for identifying which stains to show/hide:; https://github.com/qupath/qupath/blob/b4a442535b2bd8169aacf16ecf6aac61004971b0/qupath-core-processing/src/main/java/qupath/imagej/detect/cells/SubcellularDetection.java#L673-L681; But I don't see why black is failing in your case, unless it has wrongly been identified as a 'residual' stain (i.e. there are only two stains, and it represents what is left over).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/304#issuecomment-518016965:672,detect,detect,672,https://qupath.github.io,https://github.com/qupath/qupath/issues/304#issuecomment-518016965,1,['detect'],['detect']
Safety,"I just want to use qupath by script. ```; private String lastOpenPath = """";; private ImageServer<BufferedImage> server;; private ImageData<BufferedImage> imageData;; private ObjectDetector<BufferedImage> detector;; private Collection<PathObject> cells;; public double threshold, thresholdPositive, expansions = 5;; public int threadNum = 4;; public String positiveMode = ""Cell: DAB OD mean"";; public Collection<PathObject> cellSegmentation(; String imagePath,; double x, double y,; double width, double height; ) throws IOException {. if (!imagePath.equals(lastOpenPath)) {; server = ImageServerProvider.buildServer(imagePath, BufferedImage.class);; imageData = new ImageData<>(server, ImageData.ImageType.BRIGHTFIELD_H_DAB);; lastOpenPath = imagePath;; }. RectangleROI roi = new RectangleROI(x, y, width, height);; ROI dup_roi =roi.duplicate();; PathAnnotationObject object = new PathAnnotationObject();; object.setROI(dup_roi);; imageData.getHierarchy().getSelectionModel().setSelectedObject(object);. PositiveCellDetection watershedDetector = new PositiveCellDetection();; watershedDetector.params.addDoubleParameter(""threshold"", ""Threshold"", threshold, null, ""Intensity threshold - detected nuclei must have a mean intensity >= threshold"");; watershedDetector.params.addDoubleParameter(""thresholdPositive1"", ""Threshold 1+"", thresholdPositive, null, 0, 1.5);. //ParameterList params = watershedDetector.getDefaultParameterList(imageData);; AbstractPluginRunner.setNumThreadsRequested(threadNum);; PluginRunner<BufferedImage> runner = new CommandLinePluginRunner<BufferedImage>(imageData,false);; watershedDetector.runPlugin(runner,null);; cells = imageData.getHierarchy().getSelectionModel().getSelectedObject().getChildObjects();. return cells;; }; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/389#issuecomment-568362506:204,detect,detector,204,https://qupath.github.io,https://github.com/qupath/qupath/issues/389#issuecomment-568362506,2,['detect'],"['detected', 'detector']"
Safety,"I know it's possible to use a script load a classifier and apply it to detections, but is it possible to script the creation of a detection classifier, based on some existing annotations? I realize that this is a little off-piste, but it would be nice to automate this when you want to do slide-level classifications. ; My look through the code base suggests the answer is no, since the ClassifierCommand requires user input. ; Any workarounds?; Apologies if someone has already asked something similar, didn't find anything with a few searches. . Best Regards,; Colin",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/208:71,detect,detections,71,https://qupath.github.io,https://github.com/qupath/qupath/issues/208,2,['detect'],"['detection', 'detections']"
Safety,"I like it! Seems to work well. Tiny thing: it looks like `Pattern pattern = Pattern.compile(""[a-zA-Z&&[^Ee]]+"");` is called on every validation of the text field. Since `Pattern` instances are immutable (according to the javadocs), I think this should be initialized outside as a `private final static` variable to avoid the unnecessary overhead.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/668#issuecomment-791375357:315,avoid,avoid,315,https://qupath.github.io,https://github.com/qupath/qupath/pull/668#issuecomment-791375357,1,['avoid'],['avoid']
Safety,I like that solution - and clever use of `concatChannels` to make the script more concise. . It would be interesting to compare it with `applyColorTransforms()` where you pass all the `ColorTransform` objects and avoid `concatChannels()`. I have a feeling that would result in a more concise JSON representation but I'm not certain. There is an unpleasantness in how transformed `ImageServer` tend to include the metadata from all the servers they wrap in the JSON representation. My guess is that the use of `concatChannels()` may result in the same metadata being duplicated multiple times - and also the same image being opened twice when it is used - although even if that happens it should be harmless. I suggest providing both `TransformedServerBuilder.applyColorTransforms(ColorTransform... transforms)` and `TransformedServerBuilder.applyColorTransforms(Collection<? extends ColorTransform> transforms)` for convenience. What is the name given to any new channel generated in this way?,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1566#issuecomment-2260286184:213,avoid,avoid,213,https://qupath.github.io,https://github.com/qupath/qupath/pull/1566#issuecomment-2260286184,1,['avoid'],['avoid']
Safety,"I looked at the image and there are two main problems:; * The pixel size is completely off (169.3 μm). It looks like it was converted from a 'dots per inch' value used for printing resolution, but doesn't relate to the actual size of anything in the image.; * The background is values in your script are much too low. Draw a rectangle in one of the small 'white' areas and double-click on the 'Background' values under the 'Image' tab to set them. The first of these is the bigger problem. I don't know the source of your image, but ideally you'd be able to go back to it and save the file in a format that preserves the pixel size information properly. > Note: **Please** do not post [the same question](https://forum.image.sc/t/cell-detection-not-working-prob-because/24807) in multiple places. As described [here](https://github.com/qupath/qupath/wiki/Getting-help) and [here](https://github.com/qupath/qupath/issues/new/choose), GitHub issues is intended for bug reports and not for questions.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/305#issuecomment-483056604:735,detect,detection-not-working-prob-because,735,https://qupath.github.io,https://github.com/qupath/qupath/issues/305#issuecomment-483056604,1,['detect'],['detection-not-working-prob-because']
Safety,"I love the new multiplex object classification in m9! However, when you calculate detection centroid distances on objects with multiple classifications, the results are difficult to interpret. It gives a separate measurement for the distance to the nearest cell of each permutation of classes individually. So, it gives the shortest distance to a cell of classA: classB, then separately to classA: classC, etc. But often what I want to know is the distance from a cell to another of classA of any subtype. Can you add a summary measurement for the shortest distance to any cell of classA, maybe like a classA*?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/405:82,detect,detection,82,https://qupath.github.io,https://github.com/qupath/qupath/issues/405,1,['detect'],['detection']
Safety,"I missed that, I don't understand the workflow enough and there may be a bug here. But there may also be a workaround through the link I posted. The medium-term plan is to replace the detection classifier (building on the milestones, not v0.1.2) so if there's a workaround at all for training across images then I would not plan to fix this issue but rather invest the time in developing the improved command (both for reasons outlined in https://github.com/qupath/qupath/issues/343 and to better unify the code with the pixel classifier).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/360#issuecomment-530510840:184,detect,detection,184,https://qupath.github.io,https://github.com/qupath/qupath/issues/360#issuecomment-530510840,1,['detect'],['detection']
Safety,"I really like your draft. It seems the most beautiful, design-wise. The `ImageServerStub` solution in the end may just work as a helper for writing ""good"" fast scripts, exposing exactly where the image files are absolutely needed. I made a small comment on your draft PR about the metadata, as i feel that is an important info to access *offline*. But in the end, if that was sorted out, that solution would be a drop-in replacement to mine. As you said, at last it will come down to which one is the most maintainable. I see pros and cons in both: `ImageServerStub` offers a solution that is segregated in one file, but then requires to punch multiple small holes in QP interface in order to use it; `lazy-server` distributes the code responsibility to multiple classes and requires to be careful in future development of QuPath so that it does not end up requesting for the server when it is not really useful. In the latter case it is due to the solution having a silent behaviour. However, since everything is managed internally in the lazy approach, in the future it may create less problems surging from punching holes in QuPath's interface. Ultimately, I think your solution is better maintainable-wise, granted that a few things are managed:; * have the retrieval of the image server be loud in logs. Perhaps even with some traceback to what portion of code triggered it?; * expose a `getCurrentMetadata()` function to avoid having to do `getServer().getMetadata()`; * check qupath code that requested for the server but may not need it.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1488#issuecomment-2032062846:1427,avoid,avoid,1427,https://qupath.github.io,https://github.com/qupath/qupath/pull/1488#issuecomment-2032062846,1,['avoid'],['avoid']
Safety,I removed the depth parameter when searching for extension jars (it was set at 1). This corrects the bug but I don't know if it's very safe to not have a depth at all. Maybe I should just set a higher depth (like 5)?. I also implemented a try-with-resources block because `Files.walk()` needs to be closed.,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1461:135,safe,safe,135,https://qupath.github.io,https://github.com/qupath/qupath/pull/1461,1,['safe'],['safe']
Safety,"I see the same - I don't think it was the case before v0.1.2 was released (I developed it on a Mac and think I'd have noticed...). So my guess is that some macOS update in between could be responsible, but I'm not certain. As a workaround, under the _Preferences_ try turning on the option _Use tile brush_. This will change the behavior of the brush if you happen to be using superpixels... but otherwise it shouldn't. However, it _will_ avoid the attempted use of a custom cursor, which appears to be what is causing the trouble.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/194#issuecomment-409582139:439,avoid,avoid,439,https://qupath.github.io,https://github.com/qupath/qupath/issues/194#issuecomment-409582139,1,['avoid'],['avoid']
Safety,"I tested performance using CMU-1.svs.; I used a very basic thresholder and simple classifier trained for 3 classes, saved for both classification and probability output - then ran the script at the bottom. Using a Mac Studio (2022) with M1 Max and 32 GB RAM the processing time was:. | v0.3.0 | v0.4.0-SNAPSHOT |; | ------------- | ------------- |; | 593.9 s | 60.1 s |. Results identical as far as I can tell. So... quite a substantial difference :). Cell detection took close to 30s, with 326 498 cells detected,. ```groovy; def checkpoints = [:]. setImageType('BRIGHTFIELD_H_E'); setColorDeconvolutionStains('{""Name"" : ""H&E default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049"", ""Stain 2"" : ""Eosin"", ""Values 2"" : ""0.2159 0.8012 0.5581"", ""Background"" : "" 255 255 255""}'). clearAllObjects(). checkpoints << ['Tissue detection': System.currentTimeMillis()]. createAnnotationsFromPixelClassifier(""Tissue detection"", 10000.0, 0.0, ""INCLUDE_IGNORED""). checkpoints << ['Cell detection': System.currentTimeMillis()]. selectAnnotations(); runPlugin('qupath.imagej.detect.cells.WatershedCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 1.0, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}'). for (classifier in ['Some probability', 'Some classification']) {. // Create annotation measurements; checkpoints << [""Annotation measurements for $classifier"": System.currentTimeMillis()]; selectAnnotations(); addPixelClassifierMeasurements(classifier, classifier); ; // Create cell measurements; checkpoints << [""Cell measurements for $classifier"": System.currentTimeMillis()]; selectCells(); addPixelClassifierMeasurements(classifier, classifier); }; checkpoints << [""Done"": System.currentT",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1076#issuecomment-1279692584:457,detect,detection,457,https://qupath.github.io,https://github.com/qupath/qupath/pull/1076#issuecomment-1279692584,5,['detect'],"['detected', 'detection']"
Safety,"I think I do get the point, but want to ensure it's clear what exactly should be solved here, as I suspect there are alternative approached to consider. For example, I quickly drafted a rough alternative at https://github.com/qupath/qupath/pull/1489. This simply delays loading images until the `ImageServer` is requested. It has the advantages of being simpler (no need for different 'Run' actions), doesn't introduce any new `ImageServerStub` class, and avoids failure if pixels are requested. It probably has disadvantages too, as calling code needs to be more careful not to request the server at all (even for metadata), to avoid triggering the image to be loaded. I'm not sure which is best, but we should go with the most maintainable solution that solves the main problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1488#issuecomment-2025049875:456,avoid,avoids,456,https://qupath.github.io,https://github.com/qupath/qupath/pull/1488#issuecomment-2025049875,2,['avoid'],"['avoid', 'avoids']"
Safety,"I think all of those things may be correct.; If you collapse the rectangle in the Hierarchy tab, do you see two cells ""outside"" of the rectangle (although they are are mostly inside of it?; Edit, or the two cells that are parents to your hand drawn cells are somehow invisible? :). What shows up when you highlight the parent polygon? I am guessing that the polygons are your detected cells, and the AWTs are your hand-drawn, within that hierarchy.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/259#issuecomment-457722556:376,detect,detected,376,https://qupath.github.io,https://github.com/qupath/qupath/issues/259#issuecomment-457722556,1,['detect'],['detected']
Safety,I think it requires the fix in JavaFX - which appears to be coming soon. Adding shortcuts to the dialogs throughout QuPath would be a rather large task and add further messiness to the code that I'd rather avoid... Does v0.1.2 have the same problem?,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/336#issuecomment-507206796:206,avoid,avoid,206,https://qupath.github.io,https://github.com/qupath/qupath/issues/336#issuecomment-507206796,1,['avoid'],['avoid']
Safety,"I think the closest you can get is the median whole cell measurements, at the moment. Of course, if you can script it, you can generate that information easily! All of the base values should exist, you would just have to do the calculations. Depending on your experience, though, it might be easier to export the detection measurements to Excel or R. Actually, re-reading, if you mean a cell by cell measurement of IRQ (based on the pixel values for each individual cell), you might need to use ImageJ scripts? I am not sure about that one. Overall IQR of all detections shouldn't be too hard though.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/236#issuecomment-433478046:313,detect,detection,313,https://qupath.github.io,https://github.com/qupath/qupath/issues/236#issuecomment-433478046,2,['detect'],"['detection', 'detections']"
Safety,"I think the main problem is that your TIFF file was saved with incorrect pixel size information. Without that information it is very difficult to find settings that will work, though it is possible. Note that each one of your pixels is expected to be 163 um in size. Your entire image is about 0.2 meters in size. If you are using the ImageJ server, everything needs to be in pixels instead, though since you have a requestedPixelSize entry, I am guessing that is not the case here. If you are using a BioFormats server (see Image tab), you can get started with these settings, though I have not optimized them at all. ```; setImageType('BRIGHTFIELD_H_DAB');; createSelectAllObject(true);; setColorDeconvolutionStains('{""Name"" : ""H-DAB"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.81041 0.56974 0.13652 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26524 0.50132 0.8236 "", ""Background"" : "" 254 190 154 ""}');; selectAnnotations();; runPlugin('qupath.imagej.detect.cells.WatershedCellDetection', '{""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 300.0, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 600.0, ""minAreaMicrons"": 10000.0, ""maxAreaMicrons"": 8.0E7, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 1000.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}');; ```. Note the extremely large values in most measurements. It would be better to fix the pixel sizes in ImageJ, though.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/305#issuecomment-483056585:948,detect,detect,948,https://qupath.github.io,https://github.com/qupath/qupath/issues/305#issuecomment-483056585,2,['detect'],"['detect', 'detectionImageBrightfield']"
Safety,"I think the parallelisation makes sense. When moving to a stream, shouldn't we use `filter` *at least* once, rather than rely on `forEach`?. (If looks like `filter` could be used twice and the results added to the `pending` collection - avoiding the need to make it concurrent - but not sure if that's cleaner or not).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1504#issuecomment-2082341842:237,avoid,avoiding,237,https://qupath.github.io,https://github.com/qupath/qupath/pull/1504#issuecomment-2082341842,1,['avoid'],['avoiding']
Safety,"I think the video is showing exactly this issue: https://github.com/qupath/qupath/issues/894; It relates to opening a subset of images *outside of a project* using Bio-Formats in v0.3.1 and v0.3.2, when QuPath hangs. Not all svs files are affected, it depends upon how labels/macro images are stored inside. Some other formats (e.g. .vsi, .lif) suffer the issue too. I've already fixed that and the fix will be in the next release. Because that particular bug is related to the UI, I don't think it should have any impact when called from the command line - so I think it's different from the original tiling issue here. I'm really interested to find out of the tiling issue is avoided when using QuPath v0.3.0. There was a change in how tiles are requested in parallel in QuPath v0.3.1 and v0.3.2. This didn't directly *cause* the UI problem, but it revealed its existence (because the UI code was requesting tiles from an image after it was closed, and that caused the hang). Intermittent issues like the tiling one here do sound like parallelisation is somehow involved, but the initial error on this thread is strange.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/932#issuecomment-1057173906:678,avoid,avoided,678,https://qupath.github.io,https://github.com/qupath/qupath/issues/932#issuecomment-1057173906,1,['avoid'],['avoided']
Safety,"I think this is an issue of naming/documentation, not behavior. If the caller knows that their string can be converted to a `File`, then it's very easy for them to just call `new File(String)` first and use `getNameWithoutExtension(File)`. But the current behavior is consistent and useful for cases where this isn't the desired result. Although the naming isn't great, `getNameWithoutExtension(String)` does not specify the name to be a *file*name. Although it's natural for the user to think it would be, I don't think the method should silently assume that. Also, QuPath can work with images where the URL doesn't relate to a file system file, or this method could be called with a String that contains characters that are invalid for a filename. I don't *think* `new File(String)` throws an exception in that case, but I'm not certain and behavior might be platform-dependent. For these reasons I would prefer to either; * Rename the method to `stripExtension(String)` (but deprecate the original for removal in the future); * Keep the original but improve the javadoc. (There is also a major refactoring currently under way, so I'm reluctant to merge other PRs in the short term to avoid conflicts.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1275#issuecomment-1621077476:1187,avoid,avoid,1187,https://qupath.github.io,https://github.com/qupath/qupath/pull/1275#issuecomment-1621077476,1,['avoid'],['avoid']
Safety,"I tried reproducing the error a few times with that classifier with 4 GB of RAM and I wasn't able to reproduce it. I bumped up the resolution to `1,01 µm/px` and two `OutOfMemoryError` came up with only one stacktrace (this happened without any GC or cache clearing; didn't try with it enabled either). **This was running on 0.3.2**, I can give it a try on newer versions if any relevant parts have changed in the code. I've attached the whole classifier below (it's just a simple thersholder to filter out the background). I think the original analysis was done with 6 GB or 8 GB of RAM but I also had other scripts with `qupath.imagej.detect.cells.WatershedCellDetection` running and I can't say for 100% certainty whether it was the Pixel Classifier, Cell Counting or both which caused OutOfMemoryErrors. ```; ERROR: OutOfMemoryError: Java heap space. ERROR: qupath.opencv.tools.OpenCVTools.matToBufferedImage(OpenCVTools.java:765); qupath.opencv.ml.pixel.OpenCVPixelClassifier.applyClassification(OpenCVPixelClassifier.java:115); qupath.lib.classifiers.pixel.PixelClassificationImageServer.readTile(PixelClassificationImageServer.java:299); qupath.lib.images.servers.AbstractTileableImageServer.lambda$getTile$0(AbstractTileableImageServer.java:213); qupath.lib.images.servers.AbstractTileableImageServer$$Lambda$1691/0x0000000800796740.call(Unknown Source); java.base/java.util.concurrent.FutureTask.run(Unknown Source); qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:217); qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:287); qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:60); qupath.lib.analysis.images.ContourTracing.traceGeometriesImpl(ContourTracing.java:1157); qupath.lib.analysis.images.ContourTracing.traceGeometries(ContourTracing.java:1143); qupath.lib.analysis.images.ContourTracing.lambda$traceGeometriesImpl$9(ContourT",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1322#issuecomment-1719699500:637,detect,detect,637,https://qupath.github.io,https://github.com/qupath/qupath/issues/1322#issuecomment-1719699500,1,['detect'],['detect']
Safety,"I tried the script and below is the part of the result where I recognize the channels. The wavelength matches the naming, but no colors are mentioned. I also searched the whole script result for blue and green, but nothing were found. EmissionWavelength=""455.0"" EmissionWavelengthUnit=""nm"" ID=""Channel:7:0"" Name=""DAPI"" SamplesPerPixel=""1""><DetectorSettings Binning=""1x1"" ID=""Detector:0:7""/><LightPath/></Channel><Channel EmissionWavelength=""518.0"" EmissionWavelengthUnit=""nm"" ID=""Channel:7:1"" Name=""FITC"" SamplesPerPixel=""1""><DetectorSettings Binning=""1x1"" ID=""Detector:0:7""/><LightPath/></Channel><Channel EmissionWavelength=""565.0"" EmissionWavelengthUnit=""nm"" ID=""Channel:7:2"" Name=""TRITC"" SamplesPerPixel=""1""><DetectorSettings Binning=""1x1"" ID=""Detector:0:7""/><LightPath/></Channel><Channel ID=""Channel:7:3"" Name=""CY5"" SamplesPerPixel=""1""><DetectorSettings Binning=""1x1""",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/361#issuecomment-531192852:340,Detect,DetectorSettings,340,https://qupath.github.io,https://github.com/qupath/qupath/issues/361#issuecomment-531192852,7,['Detect'],"['Detector', 'DetectorSettings']"
Safety,"I tried to modify the script proposed in #97 for the case demonstrated in the following figure:. ![02](https://user-images.githubusercontent.com/20478730/33174622-18c2a36e-d059-11e7-9972-ee1a58d4fe01.PNG). Script:; ```; import javax.imageio.ImageIO; import qupath.lib.regions.RegionRequest. // Define resolution - 1.0 means full size; double downsample = 1.0. // Create output directory inside the project; def dirOutput = buildFilePath(""XXX/TESTFOLDER""); mkdirs(dirOutput). // Write the nuclei; def server = getCurrentImageData().getServer(); def path = server.getPath(); for (Polygon in selectDetections()){; // Stop if Run -> Kill running script is pressed ; if (Thread.currentThread().isInterrupted()); break; // Write the image; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'PNG', new File(dirOutput, Polygon.getName() + '.png')); }; print('Done!'); ```; I substituted _core_ from the original script with _Polygon_ and `getTMACoreList()` with `selectDetections()` to make it working for detections. . There is no error message in the script but it doesn´t work. Does anyone have an advice? Thank you!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/118#issuecomment-346617281:1065,detect,detections,1065,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346617281,1,['detect'],['detections']
Safety,I want to get the percentage or quantify the DAB membrane staining cells. Could you please tell me how can I use cell+membrane detection tool?,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/227#issuecomment-428253931:127,detect,detection,127,https://qupath.github.io,https://github.com/qupath/qupath/issues/227#issuecomment-428253931,1,['detect'],['detection']
Safety,"I wanted to switch the measurement table histogram to use JavaFX yesterday, using observable values and making them persistent, but didn't have the time / concentration / will to actually do it. That would give more customisation control - there is no real reason they need to use the `Parameter` stuff (which is primarily to make it easier to write scriptable commands, like cell detection, without needing to code the whole UI). Feel free to make that change. Or, the easy one, just clip a maximum number of histogram bins in the code and log a warning if the user requests something unreasonable that we don't use.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1541#issuecomment-2162260361:381,detect,detection,381,https://qupath.github.io,https://github.com/qupath/qupath/issues/1541#issuecomment-2162260361,1,['detect'],['detection']
Safety,"I was looking into this, and ways to classify multiple sets of cells within an image, and found one way that may or may not be useful here.; Massive disclaimer, this does not work for using the ""Create Detection Classifier,"" but does work for the script Peter wrote to perform classifications based on features. I'll add a copy in at the end. 1. Create an annotation around the cells you want to generate in a certain way (sometimes I want to create larger cells for muscles vs smaller for other tissues), then generate your cells for each annotation.; 2. This step could use a short script from Peter (select all cells within a certain annotation class), but if you select a given subset of cells by picking one annotation (usually easy enough by clicking on that annotation in the hierarchy and shift+clicking) you can then add a dummy measurement to those cells using settings in the Compute Intensity Features (or a script, probably) that you do not need for classification. In my case I chose Hue-Mean.; 3. Include Hue-Mean in your classification script as a measurement it checks for the presence of, and if not found, the classifier does not even try to classify those cells. I tested this by adding Hue-Mean, Saturation-Min, and Saturation-Max to three different sets of cells, and was able to run 3 different classifiers on all of my cells, and only have the correct cells (the ones with the dummy measurement) receive the results of the correct classification.; I'm sure this is somewhat complicated by the TMAs and dealing with multiple cores, and I haven't had a chance to figure out how to make that work since you can't draw an annotation to include multiple TMA cores, but maybe this could prove useful as a stepping stone for running multiple classifiers within a TMA. Here is the code for the dummy Hue-Mean classifier (specifically run at 0.50 µm). I have muddled around in the code here, and I think this is working because I never create a ""def"" for my ""baseClass"" of ""Tumor."" Ther",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/57#issuecomment-289248209:202,Detect,Detection,202,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-289248209,1,['Detect'],['Detection']
Safety,"I wasn't sure whether select annotations/detections had to be called before the actual processing but if it can be avoived it is great as depending on how many objects you have it might be slow. yes it is generating one file per slide with the idea of deleting everything once the analysis is over for the slide (although this bit of code is commented now). . outAnnoationsStatFname = ""H://""+strfnameTrim+""_steatosis_annotations.txt"". This is the line creating the variable holding the filename. . It is not an issue of size (I thought about that too) because if you limit the analysis to the first 10 tiles for every slide you are dealing with files of <100K. Although the complete file it should be < 20MB.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/136#issuecomment-357016567:41,detect,detections,41,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357016567,1,['detect'],['detections']
Safety,"I work with a 250 mb .svs with roundabout 30 pieces of tissue and want to run a simpe positive pixel count. . It works if simple tissue detection is run with single annotation. ; As soon as the checkbox is deactivated, there are 30 separate annotations on the slide. . With ""selectAnnotations();"" and then run ""positive pixel count"" it works for only roundabout 1/3 of the ROIs on the slide. ; The others dont. Even if they are manually selected.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/111:136,detect,detection,136,https://qupath.github.io,https://github.com/qupath/qupath/issues/111,1,['detect'],['detection']
Safety,"I would definitely recommend doing the export with ImageJ if you can, using the [ImageJ macro runner](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#running-macros) and a very simple ImageJ macro like this one. ```; saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle()); ```. You'll need to make sure that the export directory exists before running it. Still, if you do it this way then if you open the resulting TIFF within ImageJ you should find that the pixel sizes are preserved - and even the information regarding where in the image the region was taken (look under *Image &rarr; Properties* in ImageJ). This isn't stored if you export in any other format (e.g. PNG, JPEG). Even if you don't need it currently, this at least gives the possibility that you could relate any detected regions etc. that come from processing the TIFF back to where they came from in the original, whole slide image. You can also modify the export resolution by changing the 'Downsample factor' in the macro runner.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/85#issuecomment-317354440:795,detect,detected,795,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-317354440,1,['detect'],['detected']
Safety,"I would first check the log file (View-> show log), but it does look like you might have run out of memory. . It is also possible that *sometimes* the detection creation functions run into problems with ""small"" tiles, and the entire process stops. To get around this (or test for it) I would recommend choosing slightly different settings in your Simple Tissue Detection (more smoothing, requested pixel size change, etc.).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/115#issuecomment-343274362:151,detect,detection,151,https://qupath.github.io,https://github.com/qupath/qupath/issues/115#issuecomment-343274362,2,"['Detect', 'detect']","['Detection', 'detection']"
Safety,"I would like to use IQR of DAB intensity in the nucleus, cytoplasm, and cell detections. Is there any way to get this information from QuPath?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/236:77,detect,detections,77,https://qupath.github.io,https://github.com/qupath/qupath/issues/236,1,['detect'],['detections']
Safety,"I would safely estimate 200+ .qpdata files, and all .qpdata files are saved right below their respective .tifs in their respective folders.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/266#issuecomment-461120253:8,safe,safely,8,https://qupath.github.io,https://github.com/qupath/qupath/issues/266#issuecomment-461120253,1,['safe'],['safely']
Safety,"I'll close this issue, since I think most things that can and will be fixed now have been:. * CZI images can now be read with QuPath, as described [here](https://github.com/qupath/qupath/wiki/Supported-image-formats#zeiss-czi) - thanks to the work of OME with [Bio-Formats 5.3.0](https://www.openmicroscopy.org/site/support/bio-formats5.3/about/whats-new.html).; * Cell detection in fluorescence images now gives the option to select the detection channel, and more sensible defaults; * The Brightness/Contrast tricks mentioned above are now documented more fully on the [wiki](https://github.com/qupath/qupath/wiki/Changing-colors); * Most RGB ```.mrxs``` files should be readable, although unfortunately 16-bit or JPEG-XR-compressed files are not and there are no immediate plans to add this support within QuPath. However, if OpenSlide or Bio-Formats are able to support these images, then QuPath will benefit through its use of these libraries.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/12#issuecomment-266718638:370,detect,detection,370,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-266718638,2,['detect'],['detection']
Safety,"I'll merge this now to avoid having too many conflicts to resolve, and to have more time to try it in combination with all the other v0.6.0 changes. I'd still be grateful for anyone interested to test this!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1489#issuecomment-2275920618:23,avoid,avoid,23,https://qupath.github.io,https://github.com/qupath/qupath/pull/1489#issuecomment-2275920618,1,['avoid'],['avoid']
Safety,"I'm afraid I don't have much experience of handling dependencies on Linux. There is a little more information the binaries were created at https://github.com/qupath/qupath/issues/2. Basically I compiled it on Ubuntu 16.04 and have not tested it on 14.04. The possibilities that I can think of that might help would be:; * Try a newer version of Ubuntu if possible.; * Make sure Java is installed in Ubuntu. I don't think this should be necessary (since it is included in the QuPath download)... but perhaps.; * Try removing any ```.jar``` files connected to OpenSlide / OpenCV / JInput / JPen from within QuPath (the libraries should be mentioned in the ```qupath-***.jar``` file name). Apart from the Java Runtime Environment (JRE) itself, these are the parts that depend on native libraries. QuPath should still work without them, but will miss some features - such as whole slide image handling and classification. If the JRE is not the problem then hopefully this would enable QuPath to start, and you can recover some of the missing functionality by downloading [extensions](https://github.com/qupath/qupath/wiki/Extensions) that don't require native libraries.; * Try compiling QuPath from source from within Eclipse. You may find this easier to set up using Oracle's Java Development Kit than OpenJDK... but both should work.; * Try launching QuPath from the command line, setting the ```java.library.path``` variable and possibly using a different JRE if required... figuring out how to do this could be tricky, although [this](https://github.com/qupath/qupath/issues/27) may help a little bit. I hope something in there might be useful. If you are able to find a solution, it would be great if you could post it here.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/51#issuecomment-280861844:1010,recover,recover,1010,https://qupath.github.io,https://github.com/qupath/qupath/issues/51#issuecomment-280861844,1,['recover'],['recover']
Safety,"I'm afraid not, since `The crash happened outside the Java Virtual Machine in native code.` it will probably be very hard to debug. The actual problem has happened outside of QuPath, and the best QuPath can do is to try to avoid calling the problematic code. Such errors have been quite common when using OpenCV, and it is a constant battle to eliminate them as far as possible... I will look out for it, but since the TensorFlow code is still at a very early and experimental stage (and not part of the public release) I'm afraid it really isn't something I'm able to support at this stage. If you are able to replicate it with a minimal sequence of steps and/or find any solution, please do let me know.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/481#issuecomment-630152060:223,avoid,avoid,223,https://qupath.github.io,https://github.com/qupath/qupath/issues/481#issuecomment-630152060,1,['avoid'],['avoid']
Safety,"I'm afraid that would be tricky... you'll definitely need access to the raw pixels. To achieve this after detection, it's best _not_ to choose _Smooth boundaries_ in the cell detection parameters, to keep the contours as close as possible to their original shapes... then you could potentially loop through every cell, extract the pixels for the cell, create a binary mask for the nucleus and another for the cell, and work from there. Or alternatively you could write an entirely new cell detection (e.g. with ImageJ or OpenCV). Another option would be to look at exporting the pixels, and the cell ROIs as labelled images (with unique integer labels for each cell). Then you can potentially tackle the task in Python or R. Whichever way you choose it's not entirely straightforward, and calculating the values efficiently for large numbers of cells would be a further challenge. So... it's technically possible, but would require quite a lot of effort.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/236#issuecomment-433483920:106,detect,detection,106,https://qupath.github.io,https://github.com/qupath/qupath/issues/236#issuecomment-433483920,3,['detect'],['detection']
Safety,"I'm not sure about this. It has been a long time, but I think the reason I excluded sum from non-nucleus measurements is because it is common for people to train classifiers using all features. Because cell expansion is only distance-based, I felt that sum measurements outside the nucleus could be extremely unreliable. Also, the sum depends upon the resolution at which the measurement is calculated; for the default cell detection, this is the detection resolution, but that might not be what the user expects. The need for a nucleus sum, however, seemed sufficiently common that it should be included - and the nucleus ROI is likely to be more reliable, which reduces the problems slightly. I realise it's a judgement call and people may disagree. I'm reluctant to change the built-in cell detection, since the current behavior hasn't changed across releases and any modifications can impact classifiers. I'd rather we focus on moving away to alternative cell detection methods, and decouple measurement from detection to improve flexibility.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1454#issuecomment-1909779883:424,detect,detection,424,https://qupath.github.io,https://github.com/qupath/qupath/issues/1454#issuecomment-1909779883,5,['detect'],['detection']
Safety,"I'm not sure what you mean by 'hierarchy export'?; I think it would probably be good to have a column in the detection table giving the name of the TMA core containing the detection. A column to add the immediate 'parent' object could also be helpful. I suspect that trying to put more information concerning the hierarchy into the table could be confusing (since some detections might be at lower levels in the hierarchy than others), but I'll give it some thought. I suspect @Svidro is much more familiar with R than I am, but if you are happy with R then I would suggest trying out some scripting in QuPath with Groovy. There is a bit of documentation in the Wiki (starting [here](https://github.com/qupath/qupath/wiki/Writing-custom-scripts)). It may take a little while to become familiar with QuPath's data structures, but I think Groovy has quite a nice syntax and [IntelliJ](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ) can help considerably. With even a little bit of scripting, you are no longer limited by the tables QuPath gives, but you can export your data any way you like... for use in R or elsewhere.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/59#issuecomment-290309875:109,detect,detection,109,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-290309875,3,['detect'],"['detection', 'detections']"
Safety,"I'm not sure which approach is preferable to solve this. I have the feeling there will always be a need for an alternative to whichever default approach we take. As usual, the workaround would be a script. Here's one that shows how to get much more control over which distances are calculated, here using all detections without a parent that is a detection:. ```groovy; def detections = getDetectionObjects().findAll {!it.getParent()?.isDetection()}. def stroma = detections.findAll {it.getPathClass() == getPathClass('Stroma')}; def other = detections.findAll {it.getPathClass() == getPathClass('Other')}. def pixelWidth = getCurrentServer().getPixelCalibration().getPixelWidthMicrons(); def pixelHeight = getCurrentServer().getPixelCalibration().getPixelHeightMicrons(). DistanceTools.centroidToCentroidDistance2D(; detections, other, pixelWidth, pixelHeight, ""Distance to Other µm""; ); DistanceTools.centroidToCentroidDistance2D(; detections, stroma, pixelWidth, pixelHeight, ""Distance to Stroma µm""; ); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1550#issuecomment-2283437122:309,detect,detections,309,https://qupath.github.io,https://github.com/qupath/qupath/issues/1550#issuecomment-2283437122,7,['detect'],"['detection', 'detections']"
Safety,"I'm still busy with optimising the parameters for the positive cell detection such as nucleaus DAB mean/max or cytoplasm or cell. After a serie of runs on single ROI, Qupath fails again with the same 'problem' out of memory. Which is likely to be false 'cause I still have 3.5 gb RAM free and its the only program open. When I close the program and open it, it works a gain, but after a ten-fold runs it 'crashes' again.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/112#issuecomment-344193230:68,detect,detection,68,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-344193230,1,['detect'],['detection']
Safety,"I'm trying to do subcellular spot detection in ubuntu 18.; The menu doesn't look like the one on the wiki. Looks like it's missing options. ![image](https://user-images.githubusercontent.com/7494967/58989186-6bdb3500-87b1-11e9-82a1-39c25b9c122a.png). I have a 3 channel image, I got a script from somebody using Windows, when trying to run from a script, spots don't get detected. ```; // Detect in DAPI (channel 3); runPlugin('qupath.imagej.detect.nuclei.WatershedCellDetection', '{""detectionImageFluorescence"": 3, ""backgroundRadius"": 15.0, ""medianRadius"": 0.0, ""sigma"": 3.0, ""minArea"": 10.0, ""maxArea"": 1000.0, ""threshold"": 25.0, ""watershedPostProcess"": true, ""cellExpansion"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}');; // Run subcellular for channel 1; runPlugin('qupath.imagej.detect.cells.SubcellularDetection', '{""detection[Channel 1]"": 0.1, ""detection[Channel 2]"": -1, ""detection[Channel 3]"": -1, ""doSmoothing"": false, ""splitByIntensity"": false, ""splitByShape"": false'); . ```",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/328:34,detect,detection,34,https://qupath.github.io,https://github.com/qupath/qupath/issues/328,9,"['Detect', 'detect']","['Detect', 'detect', 'detected', 'detection', 'detectionImageFluorescence']"
Safety,"I'm trying to run QuPath on my linux server and use X forwarding to view on my local system. Basically, the server is much more powerful, which is why I want to do it this way, but it doesn't work. Would really appreciate your advice. Here's the error message I get:. ```; 18:26:55.603 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; Prism ES2 Error - nInitialize: glXChooseFBConfig failed; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000000000ad66, pid=159313, tid=0x00007ff2286f0700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-2ubuntu0.16.04.2-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C 0x000000000000ad66; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/rrawat/QuPath/app/hs_err_pid159313.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #; Aborted; ```",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/109:432,detect,detected,432,https://qupath.github.io,https://github.com/qupath/qupath/issues/109,2,"['Abort', 'detect']","['Aborted', 'detected']"
Safety,"I'm working with some multiplex (brightfield) immunohistochemistry whole slide images that are stained with five colors (brown, purple, teal, red, black). Here's an example:. ![penta qupath 1](https://user-images.githubusercontent.com/3537118/37111528-c6c69b68-21f4-11e8-8543-f9e54bcaa5f0.png). Analyze -> Cell analysis -> Cell detection does an acceptable job of identifying cells:. ![penta qupath 2](https://user-images.githubusercontent.com/3537118/37111535-c9b80622-21f4-11e8-9cb9-a5eca67f3a4e.png). I would like to classify them by color, ideally with a script. I'm aware that QuPath doesn't have built-in support for multiple colors at this time. Also aware that Estimate stain vectors can be used to change what colors QuPath considers to be, for example, DAB. However, I don't think this would work for 5 colors. I can loop through the detected cells no problem. Is it possible to extract mean pixel intensity separately for the red, green, and blue channels? Something like:. ```; for (def cell: getCellObjects()) {. 	double r = cell.getMeasurementList().getMeasurementValue(""Cell: Mean Red Intensity""); 	double g = cell.getMeasurementList().getMeasurementValue(""Cell: Mean Green Intensity""); 	double b = cell.getMeasurementList().getMeasurementValue(""Cell: Mean Blue Intensity""); 	; 	if (isBrown(r,g,b)) {; 		cell.setPathClass(Brown); 	}; 	...; }; ```. From `getAvailableFeatures(getCellObjects())` it doesn't seem like it. Any other suggestions are much appreciated!",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/155:328,detect,detection,328,https://qupath.github.io,https://github.com/qupath/qupath/issues/155,2,['detect'],"['detected', 'detection']"
Safety,"I've added a PR that is intended to address this... although its main focus is on another related bug: https://github.com/qupath/qupath/pull/1070. > Visualizing objects overlaid onto images shouldn't result in substantial lag. Ideally it shouldn't, but if it does I wouldn't say it's necessarily a bug... since QuPath is already needing to do a *lot* of stuff to get acceptable performance across a wide range of scenarios. Specifically here:; * For a downsample >= 1, repainting detections caches tiles and multiple resolution levels for performance - this is why QuPath can handle millions of objects.; * For downsample < 1, repainting happens for all detections in the field of view (like for annotations) for improved appearance without nasty bitmap-upsampling artefacts. This is inevitably laggier than using cached tiles, but caching itself has considerable overhead in terms of memory and worse appearance. I think this tradeoff makes sense, since details really matter when viewing the image at high magnification but the number of objects visible should be limited (possibly thousands, but not millions). However it does mean that if you have a large enough monitor, many detections, and a downsample value slightly less than 1, performance there certainly can be a noticeable lag... and object connections make this worse by meaning that thousands more lines need to be rendered. However, investigating this revealed that QuPath was painting all the connections twice, which certainly wasn't helping things :). So the PR fixes the double-painting bug. Along the way, it adds a spatial cache that enables QuPath to be a bit smarter about which connections it paints. The main reason for this change is to overcome an issue with long connections sometimes being broken at some resolutions:. ### Old behavior:; ![connection_bug-1](https://user-images.githubusercontent.com/4690904/194024037-795fceaa-e542-4c67-8fa2-84e6a8aca691.png). ### New behavior:; ![connection_fix-1](https://user-images.g",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1069#issuecomment-1268167189:480,detect,detections,480,https://qupath.github.io,https://github.com/qupath/qupath/issues/1069#issuecomment-1268167189,2,['detect'],['detections']
Safety,"I've added a new preference so that this can be turned on/off, to help us explore if we like it or not. (If it stays, we might need to tweak the behavior a bit to make detections easier to see in other ways - especially cells, where the boundaries may be too faint currently). <img width=""549"" alt=""Dynamic thickness"" src=""https://github.com/user-attachments/assets/72f3efa3-d3f6-4d47-a79e-13defcc96248"">",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1623#issuecomment-2333206629:168,detect,detections,168,https://qupath.github.io,https://github.com/qupath/qupath/pull/1623#issuecomment-2333206629,1,['detect'],['detections']
Safety,"I've been thinking about this, and made an attempt to get the best of both worlds: https://github.com/qupath/qupath/pull/676. I remain reluctant to do too much parsing, since as long as the string is passed to Groovy it's quite possible to parse it within the script itself. But I see the risk in allowing misspelled arguments. I hope this approach is a suitable compromise, but I don't do a huge amount of command line stuff so not sure if I've broken some convention along the way. Curious as to what you think...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/647#issuecomment-794360793:289,risk,risk,289,https://qupath.github.io,https://github.com/qupath/qupath/pull/647#issuecomment-794360793,1,['risk'],['risk']
Safety,"I've discussed this with @melvingelbard and we propose to change the export to a single csv/tsv table that includes class and name as optional columns, and avoids the 'header' information in the current export format. I suspect that the main usefulness of this is to support spatial analysis outside QuPath, or import points from other sources. Following the instructions in the tutorial to create duplicate images, or using the annotation export methods in the docs, there shouldn't be any need to rely on this method of saving/loading points for training.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/410#issuecomment-597155651:156,avoid,avoids,156,https://qupath.github.io,https://github.com/qupath/qupath/issues/410#issuecomment-597155651,1,['avoid'],['avoids']
Safety,"I've flagged this as a duplicate, since it sounds the same as the issue linked to by @Svidro. I've given the details there, and potential direction for how it might be addressed in the long term. In this case, it might be possible to improve matters by ensuring that all entries in the 'hierarchy' tab are first closed - or that there are no child objects. Then the results in the annotation table can be sorted by area, and all the top entries (with low areas) selected in one go. In the longer term, the better way to handle this would be to write a script that finds all the annotations with an area below a specified threshold, and removes them directly from the object hierarchy. Using a script it is possible to avoid the need for selecting the annotations in the GUI entirely, and get *much* better performance. Clearly this is a bit more work to begin with, but I highly recommend working through the scripting parts on the Wiki if you haven't done so already - this is the kind of application where scripting can be invaluable.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/86#issuecomment-317358116:718,avoid,avoid,718,https://qupath.github.io,https://github.com/qupath/qupath/issues/86#issuecomment-317358116,1,['avoid'],['avoid']
Safety,"I've had a quick look at the code and it should be possible to make some minor improvements to help with this, although it isn't a completely trivial fix. The main reason is that opacity = 0 is not equivalent to not painting anything; there is an *Always show selected objects* preference (on by default) that means selected objects should always be painted. So the object-painting code cannot be switched off entirely, and the various other painting optimizations need to be navigated carefully. The behavior you are seeing is also somewhat zoom-dependent, because detections are painted directly when upsampling - but otherwise they are painted once and cached. So if you zoom out a little, I'd hope that any lag you notice would be temporary at most. There are lots of possible permutations of options (showing/hiding detections/annotations, filled, unfilled, selected/unselected, global opacity option & per-overlay opacity option, zoom) - the most common of these have already been optimized to some degree, but the specific scenario you point out hasn't yet. > Issue impacts QoL very slightly, but I'm curious if the lag is more disruptive/noticeable on lower-end machines. If it's not, then might not be something worth spending the time to fix. The lag should be no more than what occurs whenever opacity is not zero - and I'd expect that someone using QuPath will generally want to see their objects at some point. Therefore if it's a major issue for anyone, I'd expect QuPath to already be unusable for them. If this is the only problem they encounter, there is already an easy fix with a shortcut (turn off the detections with `D`).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/826#issuecomment-926350763:566,detect,detections,566,https://qupath.github.io,https://github.com/qupath/qupath/issues/826#issuecomment-926350763,3,['detect'],['detections']
Safety,"I've made a PR at https://github.com/qupath/qupath/pull/1195. It involved entirely changing how the Groovy syntax highlighting works, and adding support for a few other Groovy features (like using colors to indicate `""string $interpolation""`, or numeric values). It doesn't handle everything, because that would require fully parsing the code too avoid getting mixed up (e.g. mistaking a division operator for the start of a slashy string). The code was very fiddly to write, so I wouldn't be surprised to learn its broken in some places - but as far as I can tell, it's better than the previous version. @Rdornier if you've time to check it out, please let me know if there are problems.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1176#issuecomment-1357429790:347,avoid,avoid,347,https://qupath.github.io,https://github.com/qupath/qupath/issues/1176#issuecomment-1357429790,1,['avoid'],['avoid']
Safety,"I've made an update that will be included in v0.1.2 so that QuPath can recover more gracefully if it finds that OpenSlide cannot be loaded. Previously, it recovered only the first time... but subsequent attempts to open images were thwarted by a particularly nasty error - which caused the trouble you found. Therefore while it still remains a mystery why OpenSlide cannot be used on one of your computers, at least there should be no need to manually disable OpenSlide through renaming from now on. (Note: I'd recommend uninstalling QuPath before installing the update, since otherwise it is likely that the current files, renamed and not, will hang around within Windows... they shouldn't cause trouble, but uninstalling manually can help make sure.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/35#issuecomment-268797552:71,recover,recover,71,https://qupath.github.io,https://github.com/qupath/qupath/issues/35#issuecomment-268797552,2,['recover'],"['recover', 'recovered']"
Safety,"I've made some progress. After cell detection, I did _Analyze → Calculate features → Add intensity features (experimental)._, with a pixel size of 1 um. I chose Red, Green, and Blue, and Mean. Then the following code:. ```; import qupath.lib.objects.classes.PathClass; import qupath.lib.objects.classes.PathClassFactory. def Brown = PathClassFactory.getPathClass(""Brown""); def Red = PathClassFactory.getPathClass(""Red""); def Purple = PathClassFactory.getPathClass(""Purple""); def Teal = PathClassFactory.getPathClass(""Teal""). def rmean = ""ROI: 1.00 µm per pixel: Red: Mean""; def gmean = ""ROI: 1.00 µm per pixel: Green: Mean""; def bmean = ""ROI: 1.00 µm per pixel: Blue: Mean"". for (def cell :getCellObjects()) {; ; double r = cell.getMeasurementList().getMeasurementValue(rmean); double g = cell.getMeasurementList().getMeasurementValue(gmean); double b = cell.getMeasurementList().getMeasurementValue(bmean); ; if (isBrown(r,g,b)); cell.setPathClass(Brown). else if (isPurple(r,g,b)) ; cell.setPathClass(Purple). else if (isTeal(r,g,b)); cell.setPathClass(Teal). else if (isRed(r,g,b)) ; cell.setPathClass(Red). }; ```. the `isBrown()`, etc. functions just do some simple thresholding of the r,g,b values to decide what color a cell is stained. I'm still tweaking those functions, but it's working pretty well (white outlines are unclassified cells, the rest are outlined in the appropriate color):. ![5-plex snapshot](https://user-images.githubusercontent.com/3537118/37124548-9755fc06-221d-11e8-93c5-dc4f02dd68ac.png). I think this will work well enough for my application (we'll be presenting this data as a platform presentation at USCAP in Vancouver in a couple weeks, if anyone is interested in multiplex IHC).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/155#issuecomment-371327542:36,detect,detection,36,https://qupath.github.io,https://github.com/qupath/qupath/issues/155#issuecomment-371327542,1,['detect'],['detection']
Safety,I've updated these limits in v0.2.1. Hopefully that is enough to avoid this issue resurfacing.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/96#issuecomment-644847539:65,avoid,avoid,65,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-644847539,1,['avoid'],['avoid']
Safety,IQR for detection measurements?,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/236:8,detect,detection,8,https://qupath.github.io,https://github.com/qupath/qupath/issues/236,1,['detect'],['detection']
Safety,"If I understand correctly, then everything is actually behaving as it is supposed to... adding a new object that is inside an existing one (even a cell) gets positioned 'below' it. So... it might not be what you wanted, but it is correct - right?. If you don't need the cell boundaries (or associated measurements) then by reducing the 'cell expansion' parameter to zero during detection you can create a 'nucleus detector' only, which may help avoid confusion.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/259#issuecomment-457854313:378,detect,detection,378,https://qupath.github.io,https://github.com/qupath/qupath/issues/259#issuecomment-457854313,3,"['avoid', 'detect']","['avoid', 'detection', 'detector']"
Safety,"If I understand correctly, this PR is to make the top title change on hover but *not* the bottom one - because the top one can be expanded/collapsed, but the bottom one can't. https://github.com/qupath/qupath/assets/4690904/d115720b-3ace-41b2-b7e7-017cb21cc4c7. tbh I'd never noticed this or seen it as problematic. If you think it needs a fix, then should it not go into `qupath-fxtras`? This is the new home to [`simplifyTitledPane`](https://github.com/qupath/qupath-fxtras/blob/4a88b9b427ae6c9a17c33702c06f0c536cad6915/src/main/java/qupath/fx/utils/FXUtils.java#L550)... but then you'd need to load an external .css (like with the simplify method), e.g.; ```java; public void makeNonCollapsible(TitledPane pane) {; pane.setCollapsible(false);; // Whatever other styling is needed here; }; ```. Hard-coding a reference to the CSS class feels a bit brittle to me, and is tied very much to QuPath in a way that is unusable elsewhere. And I imagine we'll end up with inconsistencies as we'll forget / extension writers won't know to add this style class... which to me seems potentially worse. You could also change `main.css` to avoid any change on hover at all, but personally I think it looks quite nice and helps titles stand out. Was there any particular user complaint or confusion caused by the default JavaFX approach of slightly changing the behavior on hover, regardless of the 'collapsible' status?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1517#issuecomment-2123062919:1129,avoid,avoid,1129,https://qupath.github.io,https://github.com/qupath/qupath/pull/1517#issuecomment-2123062919,1,['avoid'],['avoid']
Safety,"If I understand correctly, this is expected behavior. If you run cell or tissue detection inside an object, then the existing contents of that object will be removed and the results of running the command will be added instead. This is the best way that I could think of to make the behavior predictable and (generally) unobtrusive. Otherwise, if you ran either command multiple times you would end up having multiple tissue annotations or cell objects relating to the same structures in the image. To get around this, you'd need to explicitly delete the older objects... which would be laborious if you want to run the same command multiple times to test out different settings. Also, in this specific example, by detecting cells first and then tissue you could very easily end up with cells within a TMA core being located outside the tissue region... which could be rather confusing. For these reasons, if you want both tissue annotations *and* cell detections, then you should create the tissue first and then detect the cells inside the tissue. If you want, you can delete the tissue annotations afterwards but keep the cells (e.g. *Objects &rarr; Delete... &rarr; Delete all annotations*). As described in #59, if the goal is to have the core name exported along with the individual cell measurements then that can be done by scripting. There are lots of ways to approach this in a script, although I can't think of a way currently to get that specific output without writing a script.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/60#issuecomment-290307913:80,detect,detection,80,https://qupath.github.io,https://github.com/qupath/qupath/issues/60#issuecomment-290307913,5,"['detect', 'predict']","['detect', 'detecting', 'detection', 'detections', 'predictable']"
Safety,"If atomicity of the operation is what worries you, i could implement a method that does it safely, very similarly to what you do with `.qpproj` files.; 1. `write <file>.tmp` (if it already exists, it will just overwrite it). If this fails, you have the previous `<file>`; 2. `rm <file>.backup --if-exists`. If this fails, you have the `<file.tmp>` and `<file>` as the newest versions; 3. `mv <file> <file>.backup` (works as we are sure the target doesn't exists already). If this fails, you have the `<file.tmp>` as the newest version; 4. `mv <file>.tmp <file>` (same, as the previous operation worked). If this fails, you have the `<file.backup>` as the backup version; 5. `rm <file>.backup`, if desired. > could you give the full stack trace for what exception you get without these changes?. The ""problem"" is that there is no exception thrown. It just fails on step 3 and/or 4 because `source` is identified as the same file as `target`, so it just [does not do anything](https://github.com/openjdk/jdk/blob/cbfddf4e1d3ff8dddb95bcb9242b31c175b768fc/src/java.base/windows/classes/sun/nio/fs/WindowsFileCopy.java#L363). As if the `target` was the `source`.; This means that a project saved on an SFTP server will always end up with three files, `project.qpproj`, `project.qpproj.backup` and `project.qpproj.tmp`, where the latter is the ""real"" project.; But it also means that when a project is saving the image data it does the following if there was a previous backup:; * `mv <pathData> <pathBackup>` -> **FAILS** : `<pathBackup>`now has the older backup saved, while `<pathData>` still exists.; * `write <pathData>` -> dangerous operation: if it fails for whatever reason, the only saved state is the one from an older backup. > Is there any easy way for us to replicate the issue?. Not that I know of. You have to connect to an SFTP server with windows to do this. Finally, i think `DefaultProject.java` could be the only source file that would need to be modified to improve SSH support from win",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1449#issuecomment-1898959824:91,safe,safely,91,https://qupath.github.io,https://github.com/qupath/qupath/pull/1449#issuecomment-1898959824,1,['safe'],['safely']
Safety,"If the images are being rescanned, can they be saved as .ndpi? Or what is the scanner being used?. As a format .tif can be very variable inside, and I'm afraid I can't really predict what may have gone wrong without a sample image. Different software can write .tif images in very different ways. However, there have been discussions here about Leica images (usually .scn) that appear pink, and this seems to be an issue with Bio-Formats, e.g. https://github.com/qupath/qupath/issues/141 and https://github.com/ome/bioformats/issues/2811. I think it is likely that the issue is related to this, and not actually a bug in QuPath itself. If it worked in v0.1.2 then perhaps QuPath was at that time using OpenSlide rather than Bio-Formats to open the image (or else an earlier version of Bio-Formats with different behavior). I suggest three possible options:; * Try to use a different file format, or write the .tif image in a different way; * Add the image to a project in v0.2.0-m5, and when doing so specify the 'server'. Try both Bio-Formats and OpenSlide to see if either works.; * If under the 'Image' tab in QuPath, you see the words 'Bio-Formats server' then you can report it to the Bio-Formats team",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/374#issuecomment-551070262:175,predict,predict,175,https://qupath.github.io,https://github.com/qupath/qupath/issues/374#issuecomment-551070262,1,['predict'],['predict']
Safety,"If you are looking at H&E, I usually found it best to divide up the tissue; using superpixels, add texture and color measurements, then classify based; on the measurements. Once your areas are classified, there is a command to merge them all into; new annotations, which you can then perform Positive pixel or Cell; detection on. A combination of two of the steps described above. On Mar 18, 2018 10:36 AM, ""geodza"" <notifications@github.com> wrote:. > Well, as promised; > I had an opportunity to test Your script on a bigger amount of glasses.; > It seems that everything is fine; > I will now start a new project with a new staining, probably ~100 glasses,; > with analytics fully based on QuPath; > Still need to understand, how to analyse stroma in H&E staining :); > But anyway, I am really grateful for Your advice. If ill be able to; > publish my results, I will let You know!; > I`ll close this topic as the solution was found.; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/157#issuecomment-374020816>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AWEq-UInIm1YbnApmIKVlfq9PPDSVpZfks5tfpsjgaJpZM4Sl4d_>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/157#issuecomment-374022361:316,detect,detection,316,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-374022361,1,['detect'],['detection']
Safety,"If you are referring to the core, that should be part of the ""Name"" column, or first column, in the detections measurements list (my first entry shows up as A-12 - Negative). If you want to apply the name of the TMA, you would have to do that when you import the other TMA patient data, I think.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/59#issuecomment-289487421:100,detect,detections,100,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-289487421,1,['detect'],['detections']
Safety,"If you are still running into problems, I would be interested in whether they also show up with a freshly opened QuPath instance (create ROIs, save and close, open, run cell detection). The tests in my last post showed that I could run a fairly large cell detection (570k cells) with only 2GB of RAM allowed, as long as it was the first thing I did after opening QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/112#issuecomment-343607120:174,detect,detection,174,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343607120,2,['detect'],['detection']
Safety,"If you can provide more information about when it does/doesn't happen that would be helpful. Also if you have seen it across different versions of the software and different methods of generating detections (e.g. using the built-in cell detection instead). And also if it persists after restarting QuPath. Since you mention pixel classification, I wonder if it is still active in the background. (When v0.2.0-m10 becomes available you will be able to use VisualVM to profile it and see what might be causing slowdowns... but it doesn't work easily with v0.2.0-m9)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/440#issuecomment-614159617:196,detect,detections,196,https://qupath.github.io,https://github.com/qupath/qupath/issues/440#issuecomment-614159617,2,['detect'],"['detection', 'detections']"
Safety,"If you could provide a screenshot of what you are looking at (cell detections/annotations+the classifier dialog) and a copy of the log (View->Show Log), that would help the troubleshooting a bit. Occasionally the classifier does run into errors and those show up in the log (unless that is what you meant by details).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418390877:67,detect,detections,67,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418390877,1,['detect'],['detections']
Safety,"If you don't have a huge number of cores, and could tolerate just manually annotating and deleting certain regions, that might be the easiest way... draw around the region you don't want (*after* detecting cells/superpixels or whatever your previous step was) and press *Backspace* to delete the annotation - and then choose *No* when asked about keeping descendent objects. Based on the description, my guess is you're using *Positive cell detection*. You might also try to create a classifier (as described [here](https://github.com/qupath/qupath/wiki/Classifying-objects)) and leave it up to the classifier to find the areas of carbon based on whatever features have been calculated; for example, you could assign classifications for *Carbon* and *Valid* (or whatever other category names you want to use). Then delete the carbon areas and reapply the positive/negative classifications using something like the following script:. ```groovy; carbon = getDetectionObjects().findAll {it.getPathClass() == getPathClass('Carbon')}; removeObjects(carbon, true); setCellIntensityClassifications('Nucleus: DAB OD mean', 0.2); ```. If this doesn't work well enough, then you can tell QuPath to calculate new features for each cell using *Analyze &rarr; Calculate features &rarr; Add intensity features (experimental)*; I'd suggest adding the mean values for red, green and blue as a starting point and see if that's enough. Otherwise, if you're able to provide an example image and say a bit more about what steps are involved in your analysis then maybe we can think of other ways.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/172#issuecomment-388539146:196,detect,detecting,196,https://qupath.github.io,https://github.com/qupath/qupath/issues/172#issuecomment-388539146,2,['detect'],"['detecting', 'detection']"
Safety,"If you upload a sample slide I could probably generate a sample script... but from the image it seems like either _Analyze->Region Identification->Positive Pixel Count_ within an annotation (you might try searching https://groups.google.com/forum/#!forum/qupath-users), or _Analyze-> Cell Analysis-> Cell Detection_ (https://github.com/qupath/qupath/wiki/Detecting-objects) with Optical Density chosen instead of Hematoxylin should give decent results. SLICs might also give you a simple way to detect area, and then if you add more measurements to them (Add Intensity Measurements) relating to texture (Haralick, etc) you might be able to automatically distinguish between tumor and stroma. If you want to play around with that, it's also under _Region Identification->Tiles and Superpixels_. https://github.com/qupath/qupath/issues/121 has an example.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/157#issuecomment-372155003:355,Detect,Detecting-objects,355,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372155003,2,"['Detect', 'detect']","['Detecting-objects', 'detect']"
Safety,"If you use VisualVM then you should be able to find exactly what takes time. Thumbnail generation can't safely be done in parallel because there's no guarantee the images will be pyramidal, so there is a high risk of out of memory errors. That being said, I'm not certain thumbnail generation is the problem. If it's once per day, there could be some issue associated with update checking... but I can't see why that would be a problem and it wouldn't happen with the project is requested. VisualVM should resolve it one way or another in any case. One other thing: is there anything conventional about where the project/images are stored? The need for a reboot makes me think there could be an operating system component. I've never seen it myself and don't recall anyone having reported it before.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1154#issuecomment-1325599611:104,safe,safely,104,https://qupath.github.io,https://github.com/qupath/qupath/issues/1154#issuecomment-1325599611,2,"['risk', 'safe']","['risk', 'safely']"
Safety,"If you zoom in more, by default the brush will be effectively smaller and so it's easier to select a region without changing the shape. Of you change just switch to the *Move* tool to select another region by double-clicking on it, without any risk of changing its shape. You can toggle between tools by just pressing `M` and `B`. In general, you might find 'locking' annotations helpful - that helps avoid changing them accidentally, and also allows you to draw _new_ regions inside an existing annotation with the brush. To do so, select the annotation and then right-click on it, and choose *Annotations &rarr; Lock*. Finally, if you are doing a lot of painstaking annotations be sure to save regularly (*Ctrl + S*)... or consider trying the beta/pre-release version [here](https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html). Installation is a bit more awkward, but it does provide (limited) undo support along with many other improvements - so may be worth it.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/179#issuecomment-399201573:244,risk,risk,244,https://qupath.github.io,https://github.com/qupath/qupath/issues/179#issuecomment-399201573,2,"['avoid', 'risk']","['avoid', 'risk']"
Safety,ImageJ cleanup & fix a detection display bug,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1680:23,detect,detection,23,https://qupath.github.io,https://github.com/qupath/qupath/pull/1680,1,['detect'],['detection']
Safety,"ImageReader.openImage(BufferedImageReader.java:86); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:648); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:61); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:166); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:19); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:536); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:573); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:156); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:120); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:47); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:269); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); ERROR: IOException exception reading file:/Volumes/Storage/Work/SLIDESCANS/190512_OLYMPUS_YKA_Batch/CRUK_YKA_16.1D_tam_2_20190513.vsi#1: x=9728, y=34816, w=512, h=512, z=0, t=0, downsample=1; at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:199); at java.base/sun.nio.ch.FileChannelImpl.endBlocking(FileChannelImpl.java:162); at java.base",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:7818,Detect,DetectionPluginTools,7818,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,2,['Detect'],"['DetectionPluginTools', 'DetectionRunnable']"
Safety,"Implement a much faster approach to computing the union of large numbers of polygons when they are not all connected, including parallelisation. The algorithm is:; 1. Extract all polygons from the input.; 2. Identify intersecting and non-intersecting polygons; 3. Group all polygons that should potentially be merged, because they intersect (directly or indirectly) with other polygons in the group; each polygon should be represented in only one group; 4. Union all the polygon groups; 5. Combine all resulting polygons into a single polygon or multipolygon. This addressing the pixel classification performance bottleneck described at https://forum.image.sc/t/can-creating-detections-from-pixel-classifier-be-made-to-run-faster/96745. When implementing this, it became clear that extremely complex polygons couldn't be displayed in the viewer because generating an `Area` object failed (ultimately with out-of-memory error). Also, `PolygonROI.getGeometry()` was slow when called repeatedly because the geometry is recomputed each time. So the PR uses a `SoftReference` to avoid this, while still allowing references to be dropped when memory is low. When the geometry isn't needed, the overhead should be avoided. This PR also addresses this problem by using JTS' shape representation instead. ## To test. ### Union of many objects. A simple test:; * Detect cells in an image; * Run the following script. ```groovy; import qupath.lib.common.Timeit; import qupath.lib.roi.GeometryTools. import static qupath.lib.scripting.QP.*. def detections = getDetectionObjects(). List<GeometryTools> geoms = detections.collect {it.getROI().getGeometry()}. def timeit = new Timeit(); .start(); def geomUnion = GeometryTools.union(geoms); println timeit.stop(). double sumArea = geoms.sum {g -> g.getArea()}; println ""Sum area: \t${sumArea}""; println ""Num geometries: \t${geoms.size()}""; def roi = GeometryTools.geometryToROI(geomUnion, ImagePlane.getDefaultPlane()); def pathClass = getPathClass(""Merged geometrie",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1543:675,detect,detections-from-pixel-classifier-be-made-to-run-faster,675,https://qupath.github.io,https://github.com/qupath/qupath/pull/1543,1,['detect'],['detections-from-pixel-classifier-be-made-to-run-faster']
Safety,"Improve build scripts for building using Apple silicon; * Avoid including TensorFlow & OpenSlide (which won't work); * Support a -Popenslide=/path/to/openslide.jar preference to create a build that uses a local openslide jar; * Give more informative error if (when) OpenSlide can't be found. Without a custom build, installing with homebrew and including `libopenslide-jni.jnilib` in the app directory can also work (assuming it contains links to its dependencies).",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1170:58,Avoid,Avoid,58,https://qupath.github.io,https://github.com/qupath/qupath/pull/1170,1,['Avoid'],['Avoid']
Safety,"Improve responsiveness, somewhat counterintuitively, by introducing a delay. The point is to avoid always processing drop events (e.g. to open images) directly in the `handle(DragEvent event)` method because these could take too long - especially when launching other dialogs (e.g. to set the image type, or import to a project). This previously had the outcome that other applications (e.g. Finder on macOS) could hang for several seconds, or other temporary weirdness might occur. By storing the files/URL that were dropped and then processing them after a short delay (here, 50 ms) this problem can be avoided.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1054:93,avoid,avoid,93,https://qupath.github.io,https://github.com/qupath/qupath/pull/1054,2,['avoid'],"['avoid', 'avoided']"
Safety,"In ImageJ it's quick, but as Pete mentioned, you can't actually save the file as a .nd2 file (unless there is a plugin that I do not know of!). If you use FIJI, you can save as an OME-TIFF, which will open with the Bio-Formats server, thus avoiding the threading problem (I think) that Pete mentioned above, so I would recommend that. Open FIJI/ImageJ, then File->Open your .nd2 file.; Then go to Image-> Properties, and change your XY pixel sizes to whatever you want.; ![change pixel size 1](https://user-images.githubusercontent.com/23145209/38470206-591f7e0c-3b14-11e8-8588-0952d4715b42.JPG); ![change pixel size 2](https://user-images.githubusercontent.com/23145209/38470212-5d7bdad6-3b14-11e8-97d9-586637de7659.JPG). Save as the OME-TIFF type, which for me was all the way at the bottom of the Save as... menu. I looked into a couple of other programs to try to edit the metadata while still keeping the file as .nd2, but did not have any success with nip or XnView. If you do convert, definitely keep both versions of the file! While the TIFF will have pixel sizes, it will not have most of the other metadata contained in the .nd2 files, such as microscope settings.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/163#issuecomment-379565929:240,avoid,avoiding,240,https://qupath.github.io,https://github.com/qupath/qupath/issues/163#issuecomment-379565929,1,['avoid'],['avoiding']
Safety,"In OpenSlide we're working on some build system changes which may help here. OpenSlide Java has already been converted to Meson and OpenSlide will follow soon. Afterward I'm hoping to convert winbuild to a Meson project that can build a unified DLL with most of the dependencies statically linked, since Meson has good support for that. That could be a good starting point for doing similar builds for Linux and macOS. We've generally avoided putting OpenSlide Java into package managers so far. It's not really maintained and the API probably shouldn't be considered ""stable"" in its current form. I wasn't aware of JEP 424; thanks for the pointer. I've filed https://github.com/openslide/openslide-java/issues/50 to track possibly switching to it.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/629#issuecomment-1358055896:435,avoid,avoided,435,https://qupath.github.io,https://github.com/qupath/qupath/issues/629#issuecomment-1358055896,1,['avoid'],['avoided']
Safety,"In case this is still an issue for one of your projects, I think the best workaround would be to run each of the individual classifiers and the distance to detections right after it by script using. https://forum.image.sc/t/scripting-json-classifiers-in-qupath-0-2-0-m9/34614/2. followed by detectionCentroidDistances(). Both functions tend to run pretty fast, so it shouldn't be too problematic to write or run. *Note that if you run detectionCentroidDistances again after running the full classifier, that will overwrite things you don't want to overwrite, but as long as each of the base classes are named differently, the measurements should stack up nicely and independently.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/405#issuecomment-596597264:156,detect,detections,156,https://qupath.github.io,https://github.com/qupath/qupath/issues/405#issuecomment-596597264,3,['detect'],"['detectionCentroidDistances', 'detections']"
Safety,"In m4, Haralick features will not calculate. I've tried it on SLICs, tiles, cells, and annotations. When going through the menu Analyze > Calculate Features > Add Intensity Features, it will select cells/detections as normal, but no measurement appears. In a script, this error appears:. ```; ERROR: Error running plugin: java.lang.IllegalArgumentException: No double parameter with key 'haralickMin'; at java.base/java.util.concurrent.FutureTask.report(Unknown Source); at java.base/java.util.concurrent.FutureTask.get(Unknown Source); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:193); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:157); at qupath.lib.gui.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:156); at qupath.lib.algorithms.IntensityFeaturesPlugin.runPlugin(IntensityFeaturesPlugin.java:355); at qupath.lib.gui.scripting.QPEx.runPlugin(QPEx.java:260); at qupath.lib.gui.scripting.QPEx.runPlugin(QPEx.java:280); at qupath.lib.gui.scripting.QPEx$runPlugin.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:55); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:196); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:216); at Script1.run(Script1.groovy:3); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:317); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:155); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:766); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:696); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:676); at qupath.lib.gui.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/358:204,detect,detections,204,https://qupath.github.io,https://github.com/qupath/qupath/issues/358,1,['detect'],['detections']
Safety,"In particular, remove legacy detection classifiers and related code. They are much less maintainable than the current ObjectClassifier implementation, and relied upon serialization + retraining. Serialized classifiers from older QuPath releases couldn't even be read in the latest version due to serialization incompatibilities, or could sometimes be read but would not give the expected results (e.g. because of differences in feature calculations). One significant change is that `PathClassifierTools` has been removed, with the relevant methods moved primarily to `PathObjectTools` or (for channels) `ServerTools`.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1015:29,detect,detection,29,https://qupath.github.io,https://github.com/qupath/qupath/pull/1015,1,['detect'],['detection']
Safety,"In the Brightness/Contrast dialog, update the settings combo box whenever settings are modified (e.g. sliders moved) to include an asterisk and name in italics. This is intended to address https://forum.image.sc/t/please-help-us-test-the-qupath-v0-5-0-release-candidate/87976/23. The change is relatively conservative, aiming to avoid any substantial overhead whenever changes are made quickly. Specifically, we don't check whether and changes have been *reversed* so that the settings are now 'unmodified again'. We also don't try to handle settings being flagged as changed when switching across multiple viewers. Therefore the asterisk and italics doesn't mean the settings are different, only that they might be different. This could be addressed, but the tests would be more expensive to perform and therefore a little risky immediately before release, in case the performance impact is noticeable. @lacan @MichaelSNelson",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1433:329,avoid,avoid,329,https://qupath.github.io,https://github.com/qupath/qupath/pull/1433,2,"['avoid', 'risk']","['avoid', 'risky']"
Safety,"In the end it actually worked great - a substantial amount of the paper we are about to submit made use of positive pixel detection (QuPath is referenced!). Tau is normally more heterogenously shaped than pTDP-43, I don't use it routinely as I work on ALS. When using the positive pixel count tool I only quantified user-defined annotations, so I could choose where to place them and avoid any bits of crud on the slide. Tweaking the colour deconvolution for your DAB channel might help. If there's a lot of background I would try raising the primary Ab dilution. Regardless of the antibody, I find that incubating the primary overnight at 4'C pretty much always gives the best signal with minimal background. . Regarding the settings, I basically just played around with the parameters until I found settings that struck a balance between being specific enough and not taking too much time to complete after clicking run. I then copied the generated script and applied it to every section. Hope this helps!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/67#issuecomment-391834425:122,detect,detection,122,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391834425,2,"['avoid', 'detect']","['avoid', 'detection']"
Safety,"In the second video tutorial I talk about different cell detection parameters, and the impact they have on detection - this may help with optimizing the detection a bit further: https://petebankhead.github.io/qupath/2018/08/22/qupath-video-tutorials.html. It's hard to judge without seeing an example image, but it's quite possible that QuPath's generic cell detection isn't accurate enough for your application. In this case, it might require a custom detection method (e.g. with an ImageJ macro or script) to get the results you want, although that may involve a considerable amount of work and image processing. I'd definitely recommend exploring what can be achieved by adjusting the parameters first. For more information about setting cells as positive/negative (regardless of cell type), see https://petebankhead.github.io/qupath/tips/2018/03/22/setting-positive.html",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/231#issuecomment-431261059:57,detect,detection,57,https://qupath.github.io,https://github.com/qupath/qupath/issues/231#issuecomment-431261059,5,['detect'],['detection']
Safety,"Interesting, I can get the file, and when I look inside it, I see the same .qpdata structure as ones I have with only annotations, but when I load it there are no annotations. I am unsure if the reason I do not get any annotations is related to your problem, or something else related to regional settings/commas/periods. One last try before I leave this for Pete... sometimes cells can get trapped ""outside"" of the annotations, and you need to force an update. I honestly forget when this happens, but I have an example of it right now where the Annotations tab shows the annotation with no cells, and the Hierarchy tab shows the annotation at the top (but empty) and a list of polygons below it, all on the first level. In order to resolve the above case, you can either select and ""jiggle"" the annotation slightly, or to be more precise, use the following script to try and force it to update. Be aware it may seem to freeze if you have a large number of detections. For ~600,000 detections it took about 10-15 minutes on my fairly fast computer since it only runs on one CPU core. https://gist.github.com/Svidro/5829ba53f927e79bb6e370a6a6747cfd#file-force-update-selected-annotation-groovy",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/147#issuecomment-365453095:958,detect,detections,958,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365453095,2,['detect'],['detections']
Safety,"Interesting, I hadn't seen that challenge. . I notice the image you reference is a jpeg. If that is the case, the min size is 5pixels? That seems rather small for defining a cell. I saw on the website a mention of the images being 40x. . The other settings in the watershed cell detection part of your script do suggest that you are running your detection in pixels.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/459#issuecomment-620678819:279,detect,detection,279,https://qupath.github.io,https://github.com/qupath/qupath/issues/459#issuecomment-620678819,2,['detect'],['detection']
Safety,"Introduce `qupath.lib.objects.utils.ObjectMerger` as an attempt to provide a general, reusable and performant way to handle tile boundary issues with segmentation algorithms. It is designed to support different merging criteria, with three baseline implementations for now. This might be extended in the future. The following Groovy script shows it in action:. ```groovy; import qupath.lib.objects.utils.ObjectMerger. def pathObjects = getSelectedObjects(). println ""Before merging: ${pathObjects.size()}"". // Create a merger that requires one horizontal/vertical boundary to match; // (with a minimum shared length threshold, and a small overlap tolerance); double threshold = 0.75; def merger = ObjectMerger.createSharedTileBoundaryMerger(threshold). // Alternatives; // merger = ObjectMerger.createSharedClassificationMerger() // ROIs can be discontinuous; // merger = ObjectMerger.createTouchingMerger() // ROIs must touch, but not intersect. // Do the merging; def mergedObjects = merger.merge(pathObjects); println ""After merging: ${mergedObjects.size()}"". // Replace the objects; removeObjects(pathObjects, true); addObjects(mergedObjects); ```. On my M1 Max Mac Studio it is capable of reducing 88350 detections to 76394 in 2-4 seconds.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1346:1209,detect,detections,1209,https://qupath.github.io,https://github.com/qupath/qupath/pull/1346,1,['detect'],['detections']
Safety,"Introduce a `MinimalMetadataStore` interface (may be renamed) and use it with `PathObject`, `Project` and `ProjectImageEntry`. This adds support for `String` key/value metadata, and enables us to deprecate some old metadata-related code. ## Use. Because a standard modifiable `Map<String, String>` is returned, we can use a convenient Groovy syntax, e.g.; ```groovy; getProject().metadata['key'] = 'value'; getProjectEntry().metadata['key'] = 'value'; getSelectedObject().metadata['key'] = 'value'; ```. ## Don't use metadata too much!; For `PathObject`, the metadata is generated lazily on demand - so imposes no overhead if it isn't needed. This means that *it's generally a bad idea to start adding metadata to detections* - especially if we may have a huge number.; It introduces considerable overhead to store a `Map` for each object.; This is typically find for other kinds of `PathObject`, but we don't want to store millions of additional maps if they are not needed. ## Use `""_key""` format for internal use; A documented convention for `MinimalMetadataStore` is to use `""_""` as the first character for metadata values that are used internally. The practical implication is that values starting with `""_""` aren't typically shown to the user, e.g. within measurement tables. ## Thread safety; The maps returned by `DefaultProject` and its image entries are synchronized. The map returned by `PathObject.getMetadata()` is currently *not* thread-safe. This can be confirmed with the following script:; ```groovy; def pathObject = PathObjects.createAnnotationObject(ROIs.createEmptyROI()). // Control synchronization; boolean doSynchronize = true. // Make sure we have no metadata at the start; pathObject.metadata.clear(); int before = pathObject.metadata.size(). java.util.stream.IntStream.range(0, 1000); .parallel(); .forEach(i -> {; def map = pathObject.metadata; if (doSynchronize) {; synchronized (map) {; map[UUID.randomUUID().toString()] = ""Yes""; }; } else {; map[UUID.randomUUID().toStri",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1587:714,detect,detections,714,https://qupath.github.io,https://github.com/qupath/qupath/pull/1587,1,['detect'],['detections']
Safety,"It certainly is, although there are different methods for doing so. It mostly involves how much overlap you want your users to have in terms of annotations.; 1. Have all images on a server, and all QuPath projects on the client computers. This means each person will have access to the same images, but will not share any cell generation or annotations. Safest and easiest to set up, but probably least useful.; 2. Map the same network drive to the image location on all client computers (say, S: drive for your server), and use the same shared QuPath directory (say, Q: drive) created for each project on every computer. This would mean that every user would have access to all images and modifications done through QuPath, but there are some fairly heavy caveats here.; 2A. There is NO file copy protection AT ALL. All users would have equal access to overwriting the current .qpdata file, and for all I know, they might attempt to save two different versions at the same time, creating a mess. ; 2B. If your .qpdata files are large (can get up to 3GB or so fairly easily with SLICs) you may have network bandwidth problems accessing both images and data files. Actually, access to the images alone could be problematic depending on your hardware. Multiple users accessing data on a single hard drive through a 1gigabit network connection can cause slowdowns in refresh rate.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/100#issuecomment-328936155:354,Safe,Safest,354,https://qupath.github.io,https://github.com/qupath/qupath/issues/100#issuecomment-328936155,1,['Safe'],['Safest']
Safety,"It could be I was thinking of the pre-tiling days for cell detection, or maybe SLICs and subcellular detections on large images? And yes, I'm probably not typical :) Never used CZI images, so I have no idea about the effect of those. Anyway, giving a few things a shot. One thing I already noticed is that when I zip around an image and cap out the available memory that way, I tend to run into detection problems. However, as you say, this isn't a hardware memory limit problem, as I can lower the memory cap down to 2GB on a fairly large image (Annotation area 1.3x10^8 um^2) and have it run successfully, but slowly. If I fill up those 2 GB by looking around the image, though, it failed it's cell detection. Even on a comparatively small image (2.5x10^6 um^2) I ran into problems once the memory was filled. On the other hand, once I bumped the available memory up to 5GB, I stopped running into errors on the smaller image, though it was very difficult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.ut",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/112#issuecomment-343336690:59,detect,detection,59,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690,4,['detect'],"['detection', 'detections']"
Safety,It depends what kind of object you added the features to - but you can create measurement tables with _Measure &rarr; Show annotation measurements_ or _Measure &rarr; Show detection measurements_ and save the results from either table. See also [Exporting results](https://github.com/qupath/qupath/wiki/Exporting-results) on the wiki.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/183#issuecomment-403232897:172,detect,detection,172,https://qupath.github.io,https://github.com/qupath/qupath/issues/183#issuecomment-403232897,1,['detect'],['detection']
Safety,"It is possible, but depends on how regular the sequential sections are. I have seen it done before, but the registration was not done in QuPath. You can definitely take whole sets of objects and alter their position by translation and rotation, but determining how much of a translation and rotation are needed are somewhat up to you. In short, I would recommend finding an external solutions to match up your images as perfectly as possible, and then you can copy and paste your detections between images, and use ""Add Intensity Features"" for whole cell measurements [or a script ](https://gist.github.com/Svidro/68dd668af64ad91b2f76022015dd8a45#file-nuclear-and-cytoplasmic-color-vector-means-groovy) for cytoplams/nuclear measurements to generate values using the new image data. Further information, though much of it references each other.; https://github.com/qupath/qupath/issues/171; https://github.com/qupath/qupath/issues/162. A couple of posts on image registration in general.; https://groups.google.com/forum/#!searchin/qupath-users/registration%7Csort:date/qupath-users/5-JMvmCKRBo/6NeAyDwsBQAJ; https://groups.google.com/forum/#!searchin/qupath-users/registration%7Csort:date/qupath-users/VLJL6UCXqEk/lvu6LO0bBAAJ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/178#issuecomment-398618472:480,detect,detections,480,https://qupath.github.io,https://github.com/qupath/qupath/issues/178#issuecomment-398618472,1,['detect'],['detections']
Safety,"It isn't possible to run cell detection on channels with "" in the name",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1022:30,detect,detection,30,https://qupath.github.io,https://github.com/qupath/qupath/issues/1022,1,['detect'],['detection']
Safety,"It looks like OpenSlide may need to be recompiled (maybe with a different libtiff) to handle these files. In the meantime, it should be possible to get QuPath to use an alternative version of OpenSlide by removing the OpenSlide-related files from QuPath, and amending the ```java.library.path``` used when launching QuPath if needed. I do not have much experience of handling native libraries with Java on Linux, but Issue #27 may be of some use for reference. Basically you can launch QuPath from the command line and set ```-Djava.library.path``` or modify the ```QuPath.cfg``` file. If you would prefer to avoid this, as a shortcut do either of these two methods work?. * Install the Bio-Formats extension, as described [here](https://github.com/qupath/qupath-bioformats-extension), to use Bio-Formats as an alternative; * Copy ```libopenslide.so.0``` from your working OpenSlide distribution to replace the corresponding file in your QuPath installation.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/65#issuecomment-296463668:609,avoid,avoid,609,https://qupath.github.io,https://github.com/qupath/qupath/issues/65#issuecomment-296463668,1,['avoid'],['avoid']
Safety,"It may work if it is 8-bit RGB (i.e. three channels), and does not use JPEG-XR compression. However if the original data is 16-bit, or has more channels, then there is the risk of a considerable loss of information on conversion. It would be fantastic if the company behind the format could offer a solution - ideally through Bio-Formats (since QuPath and many other software applications already support Bio-Formats). Otherwise, it is sadly the case that people depending on certain scanners using proprietary file formats may not be able to analyze their data with QuPath, or open source tools.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/187#issuecomment-406624163:172,risk,risk,172,https://qupath.github.io,https://github.com/qupath/qupath/issues/187#issuecomment-406624163,1,['risk'],['risk']
Safety,"It seems like the easiest way to resolve the minor issue would be swapping the for loop/tiles to detections, if that works with the imagewritertools.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/62#issuecomment-293124108:97,detect,detections,97,https://qupath.github.io,https://github.com/qupath/qupath/issues/62#issuecomment-293124108,1,['detect'],['detections']
Safety,"It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:; ```groovy; // Print the current memory situation; def runtime = Runtime.getRuntime(); double scale = 1.0/1024.0/1024.0; print 'Max memory (MB): ' + (runtime.maxMemory() * scale); print 'Total memory (MB): ' + (runtime.totalMemory() * scale); print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache; javafx.application.Platform.runLater {; getCurrentViewer().getImageRegionStore().cache.clear(); System.gc(); }; ```. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/130#issuecomment-355845333:1462,detect,detection,1462,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355845333,1,['detect'],['detection']
Safety,"It sounds like maybe you used *Create tiles* or one of the superpixel commands?. If so, these don't produce any features/measurements by default, as required by the classifier. You can add some by running *Analyze &rarr; Calculate features &rarr; Add intensity features*.; But be warned... you generally need to choose the *Process all: Detections* option after you press *Run*. Otherwise the features might be calculated for something else (e.g. the annotation containing your tiles/superpixels... but not the tiles/superpixels themselves).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/63#issuecomment-293362848:337,Detect,Detections,337,https://qupath.github.io,https://github.com/qupath/qupath/issues/63#issuecomment-293362848,1,['Detect'],['Detections']
Safety,"It sounds like the QuPath window only is being shared, but not the entire screen - and you need to share the entire screen for it to work. I use a Mac myself, and I find I always need to share the entire screen if I want to demo something in QuPath and have all the windows appear. I also avoid using full screen mode with QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/693#issuecomment-812052355:289,avoid,avoid,289,https://qupath.github.io,https://github.com/qupath/qupath/issues/693#issuecomment-812052355,1,['avoid'],['avoid']
Safety,"It sounds like you need a simple, one-line script that contains your settings. QuPath should already record these settings for you under the 'Workflow' tab. Double-clicking an entry there should open/run the corresponding command with the appropriate settings... but this is only available for commands you've already run for the current image. To transfer settings across an image, press *Create script*. The automatically-generated script will probably contain too many lines, but you can simply delete the ones you don't want; for example, just keep the last line if the last thing you did was run the cell counting algorithm. The script you end up with probably looks something like this:; ```groovy; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; ```. You can then save this as a file with the extension ```.groovy``` and drag it onto QuPath again to open it. Press *Run &rarr; Run* from the top menubar to apply it. There is some more information under https://github.com/qupath/qupath/wiki/From-workflows-to-scripts",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/105#issuecomment-333905568:730,detect,detect,730,https://qupath.github.io,https://github.com/qupath/qupath/issues/105#issuecomment-333905568,2,['detect'],"['detect', 'detectionImageBrightfield']"
Safety,"It will only show up when your pixels have a size. Your previous post showed that your images were missing metadata indicating what size each pixel was, so that option would not have been useful. Also, it is essentially a downsampling option, to make the cell detection run more smoothly.; https://www.youtube.com/watch?v=Hh-53Uqik-Y; Another description:; https://forum.image.sc/t/qupath-intro-choose-your-own-analysis-adventure/27906/12. Finally, questions like this should be directed to the forum, not the issues page.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/357#issuecomment-527537199:260,detect,detection,260,https://qupath.github.io,https://github.com/qupath/qupath/issues/357#issuecomment-527537199,1,['detect'],['detection']
Safety,"It would help to have the script to go off of, but there's a good chance you aren't selecting the annotation as part of the script (before running cell detection). I am not sure why your annotation export would contain no results if you have annotations. More info!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/268#issuecomment-467658427:152,detect,detection,152,https://qupath.github.io,https://github.com/qupath/qupath/issues/268#issuecomment-467658427,1,['detect'],['detection']
Safety,"It would help to see your Workflow script, as I am not really sure what you mean in your first paragraph. Perhaps you were using the Points Tool?. It also sounds like you might be running into a lack of memory error, but I don't have enough information about your computer to help there either. QuPath requires significant resources (RAM) to run large scale cell detections and the program is failing to run Positive cell detection might indicate a problem there. Another possibility is that by default it only runs the cell detection on the ROIs that you have selected. If you want to run Positive cell detection on everything, you would need to make sure you have either nothing or everything selected.; I'm not sure I can be much more help without your [Workflow](https://github.com/qupath/qupath/wiki/Workflows) or more exact information about the steps you took.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/112#issuecomment-342841570:363,detect,detections,363,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342841570,4,['detect'],"['detection', 'detections']"
Safety,"It's definitely not too basic a question... I haven't personally needed anything quite like this, and unfortunately can't think of any really elegant way to do it currently. However, I think it should be possible in an inelegant way. This is how I would suggest:. * First unlock you annotation (it’s locked by default during simple tissue detection). Either select it, right click and choose *Annotations &rarr; Unlock*, or else run the following script to unlock all annotations in the image. ```groovy; getAnnotationObjects().each {it.setLocked(false)}; ```. * Create separation lines using the brush tool with the 'Alt' key pressed (to put it into eraser mode). This won't entirely solve the problem, because the resulting split region will still be treated as one 'object' - giving one set of measurements, and taking one classification… but it’s a start. * Split the multi-part (area) annotation into separate polygons. The following script should do this (be sure to save your data before trying it, in case it doesn’t give the result that you want). ```groovy; import static qupath.lib.roi.PathROIToolsAwt.splitAreaToPolygons; import qupath.lib.roi.AreaROI; import qupath.lib.objects.PathAnnotationObject. // Get all the annotations; def annotations = getAnnotationObjects(). // Prepare to add/remove annotations in batch; def toAdd = []; def toRemove = []. // Loop through the annotations, preparing to make changes; for (annotation in annotations) {; def roi = annotation.getROI(); // If we have an area, prepare to remove it - ; // and add the separated polygons; if (roi instanceof AreaROI) {; toRemove << annotation; for (p in splitAreaToPolygons(roi)[1]) {; toAdd << new PathAnnotationObject(p, annotation.getPathClass()); }; }; }. // Perform the changes; removeObjects(toRemove, true); addObjects(toAdd); ```. * Set a classification for each new polygon, to help identify it later. * If you do not need/want to do a cell analysis, try *Analyze &rarr; Region identification &rarr; Positiv",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/99#issuecomment-328360122:339,detect,detection,339,https://qupath.github.io,https://github.com/qupath/qupath/issues/99#issuecomment-328360122,1,['detect'],['detection']
Safety,"It's definitely possible, as long as each annotation is of some manageable size (which it is here). A couple of blog posts are relevant:; * https://petebankhead.github.io/qupath/scripting/2018/03/13/script-export-import-binary-masks.html; * https://petebankhead.github.io/qupath/scripting/2018/03/07/script-extracting-image-regions-to-imagej.html. For the first one, you can remove the `ImageIO.write(imgMask, 'PNG', fileMask)` bit if you don't need a binary image (which wouldn't be very meaningful here...). For the second you'd need to uncomment the `//IJ.save(imp, '/path/to/save.tif')` part, choose a sensible output name, and avoid showing the image through ImageJ. It should be possible to _Run &rarr; Run for project_ in both cases, so long as your image files all have distinct names. A recent script from Sara might help too: https://groups.google.com/d/msg/qupath-users/aHcikTZF9HE/dkcn0BoFBwAJ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/233#issuecomment-431887783:632,avoid,avoid,632,https://qupath.github.io,https://github.com/qupath/qupath/issues/233#issuecomment-431887783,1,['avoid'],['avoid']
Safety,"It's hard to tell much here without a clearer idea of what 'a lot of rather large and complex annotations' means, but it may very well be that there are too many vertices that that slows down the rendering too much (on the JavaFX application thread, same as the menus and rest of the GUI). If so it isn't really a bug, but more pushing QuPath with a different application than that for which it was previously designed/optimized... See https://github.com/qupath/qupath/wiki/Types-of-object for differences in object types, and why it's not really intended to have very large numbers of annotations. You might try having fewer vertices somehow, perhaps with _Objects &rarr; Simplify annotation shape_ or splitting larger annotations into smaller ones (since annotations outside the field of view do not need to be rendered). Or write a script that periodically converts annotations you won't need to change any more into detections. Or try to leave parts of the image that are particularly complex _unannotated_, and then interpret the unannotated region appropriately later. (I was actually looking into this today for completely different reasons, and may be able to improve the annotation handling somewhat... but it doesn't help you now)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/267#issuecomment-461569891:920,detect,detections,920,https://qupath.github.io,https://github.com/qupath/qupath/issues/267#issuecomment-461569891,1,['detect'],['detections']
Safety,"It's not totally clear to me whether this is something best approached using QuPath or Fiji. Factors to consider would be:. * Is there a DAPI channel? If so, QuPath's cell detection could give a head start.; * Is 'detecting peaks in each color channel' a suitable way to determine whether a cell is positive? This would depend on whether the staining is localized in each cell (e.g. in the nucleus, or dispersed elsewhere).; * Are you using (part of) a whole slide image?. Apart from that, [this ImageJ forum post](http://forum.imagej.net/t/counting-double-labeled-cells-in-fiji/3832/2?u=petebankhead) might help to get started.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/98#issuecomment-327718940:172,detect,detection,172,https://qupath.github.io,https://github.com/qupath/qupath/issues/98#issuecomment-327718940,2,['detect'],"['detecting', 'detection']"
Safety,"It's tempting, but it feels risky. The choice of `round` and `floor` when converting pixel coordinates has been problematic in the past, e.g. see https://github.com/qupath/qupath/pull/1072#issuecomment-1278540089. I'm not 100% sure, but I think switching this behavior could break or confuse other things whenever we want to try to ensure we obtain a consistent image size.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1528#issuecomment-2124476822:28,risk,risky,28,https://qupath.github.io,https://github.com/qupath/qupath/pull/1528#issuecomment-2124476822,1,['risk'],['risky']
Safety,Ive just downloaded and re-installed on my mac and its working now! What a pallava! I think I was tried to add extensions on the mac where they weren't needed and it seems to be working now. Ive just had a look at some tissue detections and it seems to be functional! I will continue using the software and would you mind if I checked in again if I continue having problems?. Thank you again,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/135#issuecomment-357061650:226,detect,detections,226,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-357061650,1,['detect'],['detections']
Safety,"I’ve tried to replicate this, but couldn’t (albeit on my Mac). Which platform are you running on?. There can indeed be trouble when trying to save very large detection measurement tables; a String is generated first then written to a file. The rationale was that this meant the same code could be used to generate data for copying to clipboard... but if the String ends up exceeding the maximum length permitted by Java, then it fails. Anyhow, I understand that's not the trouble here. Does it make any difference is you save the detections first, then the annotations?. The option of last resort is probably to just write the export code operating on the detections directly. That would at least give maximum flexibility, and should be reasonably concise with Groovy. If you decide to go that way the following might help:; ```groovy; def fileOutput = new File(buildFilePath(PROJECT_BASE_DIR, 'detections.txt')). // Get the detections; def detections = getDetectionObjects(). // Get the names, in an ordered set; def names = new LinkedHashSet<>(); detections.each {names.addAll(it.getMeasurementList().getMeasurementNames())}. // Loop through objects & names; fileOutput.text = String.join('\t', names); df = new java.text.DecimalFormat('#.###'); detections.each { detection ->; // Map measurements for the object to a suitably-formatted string; def values = names.collect({name -> df.format(detection.getMeasurementList().getMeasurementValue(name))}); fileOutput << String.join('\t', values) << System.lineSeparator(); }. print 'Done!'; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/136#issuecomment-357019559:158,detect,detection,158,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357019559,10,['detect'],"['detection', 'detections']"
Safety,"JC02UjlE2keamNPfGPyTA13hxoJ6aI6fRjs8P6PPD3ag1gjsZJuHqXh28XIp9ClIy6uiD9WiE2a29pnEogefoBAUSjm8iBfMR0HcxqAtG_TdnAk0f4Y8BA4E5sVwzFhbDhm_alns-l7jx4c65825lN1brlaamgEFYOcr-bx0yB5-ONuFLKVRdD6nCGWcI1iPAsoohE7nnVhyPIYtURWpKQ/https%3A%2F%2Fgithub.com%2Fsuzeteguarda> you could try posting your question on the forum at https://forum.image.sc/tag/qupath<https://secure-web.cisco.com/13_E9lRMQxY8xtZmKYPnw2mmwaiElPiHzTIMUOwQH_-6FzgRz4LkCsf_cFjrfUWLwo9750a0MmRr_eXTVN0eusQkomn-qYLuoCcVIKhtD0lyGLisH8Fxc-WFZwGzOR3GcJ4WLvQ2nVTFF7JEFSGly69C9pq9zGxJ69U6IM5ck9ofp9vkUV14NNMWH0h1u9pMUi3qXwaLEHdnCfRaAU7pipTjdj7etnYxMl6fke2A03VF49uEY6P4XmHIM3ote076fSVZpQqVTzYq0orKjFBwoKIbptcmC4XxHSSCRt900YIULIVQAtzU62qtHv_TEqaLa9vgoz2qhsY9NbYDfMfFPtA/https%3A%2F%2Fforum.image.sc%2Ftag%2Fqupath>. The error is that there isn't enough memory, but without having the classifier and knowing how much memory you have, I can't really guess what could be responsible. (This topic is really about loading training data to create classifiers, not classifiers themselves, so I will hide these posts to avoid distraction). —; Reply to this email directly, view it on GitHub<https://secure-web.cisco.com/1S_KCvGqBkfLiU4jUNxk9Bycpt04YwO2EwOrgjo7gUjY2EmjAMNPYCK9KZ3g1BcPOjN1yFkyZLgJnmGWBrpfDiblAR5l3lwK7LfMcHNHJqtYoWGQYJ9WYQ6dCoewz0Xk9P5-ZDRFW4OknOTxChetxm4Bs7LEng-ebDLB6a6AAXrEy8mWNCALTRoJs81HHMcvnMhDSjonYiBRlurLnCnBJZ4a9YvcrT8TplefFlZKST3NVLHrWPL3RgIyoJsDosp8GVf6MH94rRAHuopZp9J5pOcqjQmwnlC51e34AFYd1-8yRTnj7X0qzcw7aHtnILPwFXQIqYdBTGMqf-iZSDUUexg/https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fissues%2F493%23issuecomment-1791280813>, or unsubscribe<https://secure-web.cisco.com/16fbsI3bTg2IXBtZ19rtjLXO9mTw2FP1PcVHSk2XFBBZjPYBQWKvTLiqsGr7UCwdHhDGRsg9tR1qzmQGBIyUICyyRtVvGvh-eu_HtL8Iyt807-ztz3U-i887buKPXzn2O2YTuhy7Xwb13QKvs-TXcflZ21x0cz69j7BIZd4l-aFk4r0Kw89JYQAASuY7o5O0vLb801LbUikLbLtblZgMPHiBe_SrbHoAccvQxrwkY0sMyvxdP_sq89PM0YloMPcUZfoeyvQt8mkLvXp5q2fymfiSTMaZDZDyzknBIzrUh60kAx4knbh5x28AHq2RAZ6YnA3Au7RGuJTZ8YYt7B4VE6g/https%3A%2F%2Fgithub.com%2",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/493#issuecomment-1791396738:2567,avoid,avoid,2567,https://qupath.github.io,https://github.com/qupath/qupath/issues/493#issuecomment-1791396738,1,['avoid'],['avoid']
Safety,JPEG export; I can confirm the 'small issue'.; It is fixed with a sanity check in build().; @petebankhead Do you think this is suitable?,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/688#issuecomment-811887705:66,sanity check,sanity check,66,https://qupath.github.io,https://github.com/qupath/qupath/pull/688#issuecomment-811887705,1,['sanity check'],['sanity check']
Safety,Just in case that's useful (I may be late...) I use a readerpool in bigdataviewer-bioformats. I used the class from here:. https://www.dbtsai.com/blog/2013/java-concurrent-dynamic-object-pool-for-non-thread-safe-objects-using-blocking-queue/. It's working great so far. One thing to take care of is to put tile reading in between a `pool.acquire()` and `pool.recycle(reader)` statements:. https://github.com/BIOP/bigdataviewer-bioformats/blob/bfb48be52694ffebaa03fbbe6339ac509aab66ea/src/main/java/ch/epfl/biop/bdv/bioformats/bioformatssource/BioFormatsBdvSourceUnsignedShort.java#L119-L157,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/867#issuecomment-1001474808:207,safe,safe-objects-using-blocking-queue,207,https://qupath.github.io,https://github.com/qupath/qupath/pull/867#issuecomment-1001474808,1,['safe'],['safe-objects-using-blocking-queue']
Safety,"Just to get things started, you do not need to select anything before saving! I always have those two commands at the end of my scripts, and they are not related to what has been selected, it is just a full list of everything that shows up when you look in ""Show detection measurements"" or ""Show annotation measurements"" in the Measure menu. I wonder if you remove the selectDetections if maybe that will help things, since selecting all of the detections might cause a slowdown that messes up the save measurements command. You also might try the guiscript=true command at the top of your script, which seems to help some of the cases where the script doesn't allow a command to finish before trying the next one. Is it generating one file for every slide image?; Could you show us the part of your script where outDetectionsStatFname is created?. The only issues I have ever had with the saveDetectionMeasurements were when the output was over 2GB, and it doesn't sound like the issue here, so I am not sure what is happening.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/136#issuecomment-357000908:263,detect,detection,263,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357000908,2,['detect'],"['detection', 'detections']"
Safety,"Last commit avoids showing all the extra color transforms if the `ImageType` is `FLUORESCENCE`. This makes the behaviour of RGB and non-RGB fluorescence images consistent *except* with the limitation that channel colors cannot be adjusted for RGB images: they remain fixed to red, green & blue. However, the same transforms are displayed in the Brightness/Contrast dialog and channel names can be changed. Hopefully this is an improvement on the situation in v0.5.x and before, where channel names were fixed and many (usually irrelevant) 'channels' were displayed in the dialog. Screenshots below show the color is unavailable, while the name can be set. If the transforms are desirable, but the images aren't brightfield, then the `ImageType` can be set to `OTHER`. ### With `ImageType.FLUORESCENCE`; <img width=""330"" alt=""Renaming 'FLUORESCENCE' image"" src=""https://github.com/user-attachments/assets/eda6e7c6-c508-4364-9211-3c41f034d47d"">. ### With `ImageType.OTHER`; <img width=""330"" alt=""Renaming 'OTHER' image"" src=""https://github.com/user-attachments/assets/8014d5e8-9e11-481b-b69d-c74baa4fe309"">",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1659#issuecomment-2382998283:12,avoid,avoids,12,https://qupath.github.io,https://github.com/qupath/qupath/pull/1659#issuecomment-2382998283,1,['avoid'],['avoids']
Safety,"Latest commit adds more options to restrict where live pixel classifier prediction is calculated. Previously, it could be restricted to annotations - but using their full bounding box. This could sometimes still result in very large regions being processed. ![annotations_bounds](https://user-images.githubusercontent.com/4690904/195979231-ee656727-83dd-4569-80d7-318beb8c4c6f.png). Now it's also possible to restrict using the annotation ROI directly (i.e. the ROI shape intersects the tiled region that may be processed). This can reduce the amount of processing required substantially in some cases. ![annotations_only](https://user-images.githubusercontent.com/4690904/195979232-ef0c6862-d715-47b9-a022-0f4267f1c47c.png). Both options still exist, since the more complex calculations to restrict the predicted regions could *potentially* slow things down in some cases.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1076#issuecomment-1279704970:72,predict,prediction,72,https://qupath.github.io,https://github.com/qupath/qupath/pull/1076#issuecomment-1279704970,2,['predict'],"['predicted', 'prediction']"
Safety,"Make opening by reconstruction optional as a background subtraction method. This is intended help address issues like; * https://github.com/petebankhead/qupath/issues/22; * https://github.com/qupath/qupath/issues/80. Keeping the option on (the default) should give the same results as previous QuPath versions. Turning it off should improve consistency when detection is applied to the same pixels within different ROIs (i.e. when they are tiled differently for detection) because all the background calculations are then local. Also, optionally show an ImageJ stack demonstrating the images generated during cell detection. In a script use; ```groovy; qupath.imagej.detect.cells.WatershedCellDetection.setDebugMode(true); // run cell detection; qupath.imagej.detect.cells.WatershedCellDetection.setDebugMode(false); ```",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1098:358,detect,detection,358,https://qupath.github.io,https://github.com/qupath/qupath/pull/1098,6,['detect'],"['detect', 'detection']"
Safety,MeasurementList is not fully thread-safe,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1591:36,safe,safe,36,https://qupath.github.io,https://github.com/qupath/qupath/issues/1591,1,['safe'],['safe']
Safety,Merge annotations - afterwards QuPath does not count Cell detections anymore,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/147:58,detect,detections,58,https://qupath.github.io,https://github.com/qupath/qupath/issues/147,1,['detect'],['detections']
Safety,"Merged now - alongside https://github.com/qupath/qupath/pull/975 this should resolve the issue with labeled image export in two ways: avoiding 'smooth' (area averaging) interpolation when it shouldn't be used, and fixing its behavior for integer images when it is used. https://github.com/qupath/qupath/issues/961 should be handled later in a separate PR. Thanks again for the bug report and PR!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/964#issuecomment-1142018795:134,avoid,avoiding,134,https://qupath.github.io,https://github.com/qupath/qupath/pull/964#issuecomment-1142018795,1,['avoid'],['avoiding']
Safety,Mitosis Detection/Counting,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/205:8,Detect,Detection,8,https://qupath.github.io,https://github.com/qupath/qupath/issues/205,1,['Detect'],['Detection']
Safety,"Mmh yes and no.; Git must have added the renaming of my local `ViewTrackerAnalysisCommand.java` to the commit somehow, which will probably be part of a future commit.. I'll close this PR and re-open it without the file renaming (to avoid weird behaviour).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/558#issuecomment-659502340:232,avoid,avoid,232,https://qupath.github.io,https://github.com/qupath/qupath/pull/558#issuecomment-659502340,1,['avoid'],['avoid']
Safety,"More specifically for the coherence features, OD sum (you can have an OD sum sum, if you add up the total of each pixel's OD sum value, as opposed to the OD sum mean which is the average of each pixel's OD sum) will be the total optical density, and the tile diameter appears to be a circle/square around the centroid of the detection. Here I ran the coherence twice on OD sum where i had a very dark center of the cell. Notice that the sum/mean go up as I shrink the ""tile"" size to only fit inside the nucleus.; ![coherence](https://user-images.githubusercontent.com/23145209/42643926-29b98578-85af-11e8-9c33-385e5588d7e3.JPG); The most dramatic change is in the minimum, once the entire tile would fit inside of the dark ""nucleus."". In general you might want to use that instead of smoothing, if you want ALL of the pixels around a detection out to a certain distance included in the measurement (tissue based measurements).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/185#issuecomment-404557901:325,detect,detection,325,https://qupath.github.io,https://github.com/qupath/qupath/issues/185#issuecomment-404557901,2,['detect'],['detection']
Safety,"Most things are possible with a (possibly-complicated) script, but there is no easy way to do what you describe in QuPath. Detecting positive and negative cells in different images and combining the results could potentially cause practical problems in terms of partially overlapping cells, which might have differing positive/negative classifications depending upon staining localization and intensity... resulting in a confusing or unexpected result. Therefore, to avoid this situation, it is not supported. I would suggest applying your detection using optical density sum, but adjusting the other parameters to try to obtain a better result. In particular, . * Increasing/decreasing 'Threshold' under *Intensity parameters*; * Either increasing 'Background radius', or setting the value to zero (to eliminate background subtraction altogether) - this is mostly relevant if the cells in the image is particularly large or densely-packed. Use of the brightness/contrast tool (as described [here](https://github.com/qupath/qupath/wiki/Changing-colors#the-brightnesscontrast-tool)) to separate stains, along with the pixel intensity values shown in the bottom right of the viewer, can help figure out appropriate values for the intensity threshold. This can also help you see how cleanly the hematoxylin and DAB have been separated. If the stain separation is not particularly good, the documentation on [Estimating stain vectors](https://github.com/qupath/qupath/wiki/Preprocessing#estimate-stain-vectors) and [CD3 analysis](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis#estimate-stain-vectors-watch) show how this may be improved. Your other option for Ki67 would be to use *Fast cell counts* - as documented for [CD3](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis). This gives another method of detection that may sometimes perform better (and sometimes less well). But since it only creates a single point for each cell (rather than detecting the full cell), it is best used for ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/46#issuecomment-275932246:123,Detect,Detecting,123,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-275932246,3,"['Detect', 'avoid', 'detect']","['Detecting', 'avoid', 'detection']"
Safety,Multi ROI cell detection fails randomly,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/110:15,detect,detection,15,https://qupath.github.io,https://github.com/qupath/qupath/issues/110,1,['detect'],['detection']
Safety,Multi positive cell detections fails + Quapath data file doesn't open + does not save cell counting,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/112:20,detect,detections,20,https://qupath.github.io,https://github.com/qupath/qupath/issues/112,1,['detect'],['detections']
Safety,"My experience with ISH makes me prefer straight measurement of estimated spot count versus using or creating H-scores. Sets of numbers representing+1 to +4 can be useful to distinguish populations with both high and low members versus a medium number of spots, but once you want to compare samples by a single number you might be better off with the spot count Mean/Median/Standard deviation, since those are all probably one or two lines of code. Plus I am not sure how well the new version of the H-score would compare to older publications, even if the math was adjusted to a 0-300 scale. I second using the Brightfield (other) when eliminating yellow areas like that for brightfield ISH. Sometimes once you have enough colors, though, you have to apply multiple sets of measurements to the ISH spots (select the subcellular detections, pick your color vectors, Add Intensity Measurements), and then filter them in a script, and update a ""Filtered Red Estimated Num spots"" or something like that. Two color brightfield ISH with red blood cells in the background gets to be a real pain. For a first pass you could try moving the color vectors in Estimate color vectors to something like :; ![image](https://user-images.githubusercontent.com/23145209/36652180-ed8010a8-1a61-11e8-8d09-d639962fd706.png); One vector picks up as much red as possible, and one to get ""the rest"" of what is in your sample. They do not need to be the same as when you did the cell detection. Picking up Groovy isn't bad if you understand programming basics like variables, if/for loops, etc. The main trick (for me) is learning the QuPath specific functions to use, and making use of either Gists, the forums, or IntelliJ to figure out how doable my plans actually are! I mostly just modify other people's scripts. I'm trying to fill out some of what I have learned in my Gists as I go along. On the image, it looks like you are missing quite a few of the smaller spots. If that isn't intentional, I would try turning off a",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/146#issuecomment-368380554:828,detect,detections,828,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368380554,1,['detect'],['detections']
Safety,"My nodes run CentOS, so I can't use Qupath due to the version of libc :. > QuPath; > /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by QuPath). So I try to run Qupath in a Ubuntu container, and java core dump : ; > singularity exec ubuntu_1604.simg .../QuPath/QuPath ; > A fatal error has been detected by the Java Runtime Environment:; > ; > SIGBUS (0x7) at pc=0x00007fc8990a9ca1, pid=95904, tid=0x00007fc8ab79e740; > ; > JRE version: (8.0_111-b14) (build ); > Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); > Problematic frame:; > j java.lang.Object.<clinit>()V+0; > ; > Core dump written. Default location: .../QuPath/app/core or core.95904; > ; > An error report file with more information is saved as:; > .../QuPath/app/hs_err_pid95904.log; > Memory fault (core dumped) . Any idea ?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/150:319,detect,detected,319,https://qupath.github.io,https://github.com/qupath/qupath/issues/150,1,['detect'],['detected']
Safety,NFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO:,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:3079,detect,detected,3079,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"NGELOG.md) to see if the bug has already been fixed in the next release; * [x ] I've checked for existing GitHub issues describing the same problem. ## Bug report. **Describe the bug**; A clear and concise description of what the bug is.; After running clearDetections() TMA grid object isEditable property remains false (i.e. TMA grid circles cannot be rearranged etc). **To Reproduce**; Steps to reproduce the behavior:. setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049"", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759"", ""Background"" : "" 255 255 255""}');. //De-array TMA; runPlugin('qupath.imagej.detect.dearray.TMADearrayerPluginIJ', '{""coreDiameterMM"": 1.2, ""labelsHorizontal"": ""1-16"", ""labelsVertical"": ""A-J"", ""labelOrder"": ""Row first"", ""densityThreshold"": 5, ""boundsScale"": 105}');; selectTMACores();. //Detect cells using some method such as DAB; runPlugin('qupath.imagej.detect.cells.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.0, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": false, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Cell: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');. clearDetections();; fireHierarchyUpdate();; getTMACoreList().each{; println(it.isEditable());; };. INFO: false; INFO: false; INFO: false. **Expected behavior**; As the definition of isEditable() is ""TMA core cannot be edited if it contains any detections,"" I would expect TMA to be editable if you clear detections. Or there could be a setEditable() method to override. **Screenshots**; If applicable, a",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1021:1696,detect,detect,1696,https://qupath.github.io,https://github.com/qupath/qupath/issues/1021,1,['detect'],['detect']
Safety,Nested record patterns seem a feature I would rather avoid,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1603#issuecomment-2311817615:53,avoid,avoid,53,https://qupath.github.io,https://github.com/qupath/qupath/pull/1603#issuecomment-2311817615,1,['avoid'],['avoid']
Safety,"New option in `ScriptParameters` and under the 'Run' menu of the script editor. Because the `ScriptEngine` is reused, it seems *possible* that information could leak from one invocation of the script to the next. I couldn't find any way to do this, since a new `ScriptContext` is provided each time - but it remains an experimental off-by-default option until we're confident it behaves well. I've noticed some small performance improvements (fractions of a second) by avoiding the need to create a new script engine and compile the script again each time - but it remains to be seen if these become more worthwhile for more complex scripts.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1149:469,avoid,avoiding,469,https://qupath.github.io,https://github.com/qupath/qupath/pull/1149,1,['avoid'],['avoiding']
Safety,"No problem, glad it's fixed! I'll close the issue. Yes, sometimes it's not entirely clear even to me whether some commands require selecting annotations or detections. I don't recall exactly what I was thinking when I wrote it, but the idea may have been that it operates on the detections *within* specific annotations... i.e. not indiscriminately merging detections regardless of the annotations they are inside. This makes some sense if you have multiple pieces of tissue as different annotations and don't want a single disconnected region to be generated that spans across them. The best way to find out what should be selected is to run the command without anything selected at all. The popup dialog should then only give you valid options (here, *Annotations* or *Entire image*).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/704#issuecomment-816710295:156,detect,detections,156,https://qupath.github.io,https://github.com/qupath/qupath/issues/704#issuecomment-816710295,3,['detect'],['detections']
Safety,"No problem, it is also challenging to advise correctly without having the full image, so thank you for that!; Changing channels should be possible with the 1/2/3/4 keys, but you can only do this once you have picked color vectors. They do not update ""live."". I am not sure what you mean by question 2, but hopefully the script below improves things for you, and I am sure if you play around with the values you can improve it even further!. Here is what I came up with for settings that seem to work for cell detection in the main bulk of your tissue:; ```; setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""red blue"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.18752 0.65887 0.72851 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.72191 0.55664 0.41109 "", ""Background"" : "" 255 255 255 ""}');; selectAnnotations();; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.27, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 2.0, ""minAreaMicrons"": 30.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.6, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.4, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; ```; ![image](https://user-images.githubusercontent.com/23145209/50290376-79864380-0439-11e9-86dc-7b4375cee119.png); ![image](https://user-images.githubusercontent.com/23145209/50290399-873bc900-0439-11e9-937b-7dc5c5ce1139.png). A couple of things to note about this, some cells in certain sections of your sample are so dark that they basically show up as all colors. That makes them very difficult to distinguish, although it might be possible to exclude them or classify them as a third type if it is important enough. The script ab",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/250#issuecomment-449019237:509,detect,detection,509,https://qupath.github.io,https://github.com/qupath/qupath/issues/250#issuecomment-449019237,3,['detect'],"['detect', 'detection', 'detectionImageBrightfield']"
Safety,"No, see for example https://github.com/qupath/qupath/issues/122 and also [this blog post](https://petebankhead.github.io/qupath/2019/08/21/scripting-in-v020.html#serialization--json). > **Please avoid creating issues for anything other than bug reports; use [the forum](http://forum.image.sc/tags/qupath/) instead.**; > ; > <img width=""696"" alt=""Issues"" src=""https://user-images.githubusercontent.com/4690904/71262757-5afea500-2338-11ea-8c14-91f68652c70b.png"">",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/390#issuecomment-567951991:195,avoid,avoid,195,https://qupath.github.io,https://github.com/qupath/qupath/issues/390#issuecomment-567951991,1,['avoid'],['avoid']
Safety,"Not all commands currently show up in the workflow viewer. You would almost certainly want something like selectAnnotations() before your watershed cell detection (unless you want to manually select something before you run the script), and runClassifier(""classifierlocation"") for the classification. More on that here:; https://groups.google.com/d/msg/qupath-users/dgAabXK0eBU/W4Ex4KiQDAAJ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/272#issuecomment-469470464:153,detect,detection,153,https://qupath.github.io,https://github.com/qupath/qupath/issues/272#issuecomment-469470464,1,['detect'],['detection']
Safety,"Not currently... do you think off is a better default? My thinking is that:. * names often aren't used (might be different for you); * most people won't know names can be displayed at all if they are not revealed by default; * pressing `n` doesn't cost much. It might well become persistent in the next release, but for now it's not worth the risk of getting it wrong and introducing late bugs.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/499#issuecomment-632639493:343,risk,risk,343,https://qupath.github.io,https://github.com/qupath/qupath/issues/499#issuecomment-632639493,1,['risk'],['risk']
Safety,"Not entirely sure what you are looking at or want to accomplish, but maybe these will help:; https://github.com/qupath/qupath/issues/126; Using subcellular detections, and expanding on the current classification setup:; https://github.com/qupath/qupath/issues/146. In general, it sounds like you will want to use some sort of subcellular detection, and then classify based on the number or total intensity of subcellular objects?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/181#issuecomment-400041117:156,detect,detections,156,https://qupath.github.io,https://github.com/qupath/qupath/issues/181#issuecomment-400041117,2,['detect'],"['detection', 'detections']"
Safety,"Not sure if this is what you are interested in, and I only did a quick run at different types of measurements, but I:; 1. Converted the image to a tiff so that I could have pixel measurements (necessary for Subcellular detections); 2. Created a whole image annotation; 3. Converted that into a cell; 4. Fixed up my color vectors and ran a subcellular detection on DAB (did not really do a great job there); 5. Add Intensity Features-most of them; Found that the residual did a decent job of picking out what I think are the extraneous black dots. I imagine there are better color vector sets that you could use to identify those areas, and eliminate them from analysis. Not sure if this is what you are looking for though before I go too crazy with it.; ![image](https://user-images.githubusercontent.com/23145209/40504972-bc8c1fd4-5f47-11e8-8377-630411164e51.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/67#issuecomment-391819273:219,detect,detections,219,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391819273,2,['detect'],"['detection', 'detections']"
Safety,"Not sure, it looks like you could mean two different things. I don't think you can really turn the superpixels into pathCellObjects since there is no nucleus/cytoplasm, though you could possibly use the XY centroids of each superpixel, create a small circle there, and then convert it plus it's parent superpixel into a cell. Alternatively, if you want to run cell detection, you should be able to selectAnnotations(); and then run your cell detection command. Sum the results in the annotation tab, or use a script to select only the annotations of a particular class and then use mergeSelectedAnnotations();; See here: https://gist.github.com/Svidro/8f9c06e2c8bcae214cdd7aa9afe57c50#file-a-selection-guide-groovy; That could at least get you one annotation per class, and make it easier to read out the results. Another option might be to generate all of the cells and then classify them by their parent annotation's class. Might need an image or something to be more help.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/261#issuecomment-458183899:365,detect,detection,365,https://qupath.github.io,https://github.com/qupath/qupath/issues/261#issuecomment-458183899,2,['detect'],['detection']
Safety,"Notable changes:; * Translucent overlay for live prediction (useful to identify if a tile has been processed when at least one class is transparent); * New 2D/3D thinning & interpolation classes (experimental, not yet used - but available now for scripts); * Many internal improvements, particularly around OpenCV/ImageOps",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/706:49,predict,prediction,49,https://qupath.github.io,https://github.com/qupath/qupath/pull/706,1,['predict'],['prediction']
Safety,Num clusters is always 0 with subcellular detection,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/788:42,detect,detection,42,https://qupath.github.io,https://github.com/qupath/qupath/issues/788,1,['detect'],['detection']
Safety,"OK, so should I discard the PR? If this is the only issue occuring with `NumericMeasurementList`, it means that this class doesn't have to be thread-safe, so performance can be saved by keeping the current implementation.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1444#issuecomment-1943759245:149,safe,safe,149,https://qupath.github.io,https://github.com/qupath/qupath/issues/1444#issuecomment-1943759245,1,['safe'],['safe']
Safety,"OK, the code left is just the middle button, without side-to-side tool selection and without the debounce code. One [comment I left in](https://github.com/qupath/qupath/pull/1037/files#diff-fd4ad143f25db1ea49822496a62940abb1e550675d0a394acb80298892dbf7e8R1079-R1081) is this:. > // As part of MouseEvent.ANY, both MOUSE_RELEASED and MOUSE_PRESSED can be generated (and detected) separately, so maybe worth adding MOUSE_RELEASED to ignoreTypes?. For me, pressing the middle button quickly is what generated extra MOUSE_RELEASED events, which would then need to be filtered somewhere within ; ```; 		stage.getScene().addEventFilter(MouseEvent.ANY, e -> {; 		}; ```; Instead, I added `MouseEvent.MOUSE_RELEASED` to your `ignoreTypes` but left [the original line](https://github.com/qupath/qupath/pull/1037/files#diff-fd4ad143f25db1ea49822496a62940abb1e550675d0a394acb80298892dbf7e8R1080) commented out. If this is OK, I'll remove the line and amend my comment to mention `MouseEvent.MOUSE_RELEASED` is to do with pressing the middle button multiple times.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1037#issuecomment-1313413034:369,detect,detected,369,https://qupath.github.io,https://github.com/qupath/qupath/pull/1037#issuecomment-1313413034,1,['detect'],['detected']
Safety,"Occasionally, QuPath hangs when selecting multiple objects when analyzing a large tissue image. The bug can be intermittent during 'normal use', but is reproducible with the following steps:. * Open a whole slide image; * Create a single, very large annotation; * Create a large number of detections within the annotation (at least tens/hundreds of thousands); this is easiest with the *Create tiles* command; * Draw several more smaller annotations within the large one; * In the *Annotation* tab, select multiple annotations; * Wait... then give up waiting and force-quit QuPath. The problem traces back to QuPath's attempt to synchronize the selected within QuPath’s object hierarchy with the objects shown in the JavaFX ```TreeView``` used in the *Hierarchy* tab. Basically, JavaFX’s ```TreeView``` is forced to do a rather slow check along all expanded nodes to look for objects... and if you have a single expanded node containing >~ 10 000 objects expanded within the ```TreeView``` then this can be *extremely slow*. It likely hasn't actually crashed… but it would take an unrealistically long time to become responsive again. The problem is intermittent because expanded nodes with only a few thousand objects in them (e.g. TMA cores) can be handled quite quickly. Additionally, large numbers of objects can be handled so long as the parent objects within the tree aren't expanded, or the objects are contained within multiple smaller annotations rather than a single, very large region. As such, TMA slides and core biopsies likely work (given that the objects are stored within smaller regions), while some whole face sections may be problematic depending on what processing is performed and how. Since the issue appears to be isolated to the display of large numbers of detections within a ```TreeView```, a straightforward fix in a future QuPath release may be to simply exclude detections from the ```TreeView``` by default, showing instead only TMA cores and annotations. In the meantim",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/41:289,detect,detections,289,https://qupath.github.io,https://github.com/qupath/qupath/issues/41,1,['detect'],['detections']
Safety,"Oh dear, sorry, I see now I didn't reply to this (although I was away from QuPath at the time and I think we discussed it elsewhere...). I recall at the time I wondered about how this would impact supporting RGB/non-RGB images with the same command and also maintaining scripting compatibility. In the meantime, the code has diverged rather a lot and other issues with _Simple Tissue Detection_ have emerged, e.g.; * https://github.com/qupath/qupath/issues/124; * https://github.com/qupath/qupath/issues/248. I'm reluctant to try to resolve the code conflicts to incorporate this small change that may complicate scripting compatibility whenever it looks like the whole simple detection command really needs a thorough overhaul. There are now also other ways to gain more control over tissue detection, e.g.; * https://petebankhead.github.io/qupath/scripting/2018/03/08/script-imagej-to-qupath.html; * the pixel classifier (not yet complete, but I hope it will become a 'standard' way). The pixel classifier is also being designed to support different kinds of classification, which could eventually also include a simple threshold applied to an original or transformed image. It has the benefit of allowing the classification to be applied at a higher resolution through tiling, and to interactively show preliminary results (e.g. with a threshold slider). I think that this is needed in the longer term, and _Simple tissue detection_ will move into retirement. Sorry again for not replying here sooner. If this change is still of interest to you, please feel free to reopen the issue. To integrate it, we'd need to; * update the code to be compatible with the current codebase; * test the impact on scripts created before/after the change",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/93#issuecomment-518571384:677,detect,detection,677,https://qupath.github.io,https://github.com/qupath/qupath/pull/93#issuecomment-518571384,2,['detect'],['detection']
Safety,"Oh no, please keep the PR for now!. I'll check it out in more detail soon - but you've demonstrated that there is a concurrency bug with the measurement list. It just wouldn't have arisen if the Delaunay command wasn't buggy too. Similarly, the performance probably wouldn't have changed noticeably if the Delaunay command wasn't problematic... so this may not be a major issue in other contexts. One thing to check would be 'Add smoothed measurements' with lots of cells, since this should add a lot of measurements in parallel - but I think only one thread should be accessing each measurement list. Therefore I hope synchronization doesn't cause substantial overhead. . In any case, I think `MeasurementList` implementations *should* be thread-safe - so we should address this in either v0.5.1 or v0.6.0.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1444#issuecomment-1944052771:747,safe,safe,747,https://qupath.github.io,https://github.com/qupath/qupath/issues/1444#issuecomment-1944052771,1,['safe'],['safe']
Safety,"Oh, definitely not too complicated, as we don't really know what the rest of the slides look like. Your method is far more robust, and if there are other dark blotches or other unwanted clumps of cell pellets/detritus on the images, a classifier would be able to pick that up, while simple tissue detection will simply look for ""anything"" that is ""dark."" . It does go to show how QuPath has multiple ways to accomplish the same task though, depending on your needs!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/121#issuecomment-349101867:297,detect,detection,297,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349101867,1,['detect'],['detection']
Safety,"Oh. I think I see... though I am not certain of how easy that will be. One thing to look into is smoothed measurements. _Analyze->Calculate features->Add smoothed features_. As long as your hotspots are roughly the same size, you should be able to get a smoothed measurement that peaks in small subsets of cells at the ""center"" of your hotspot. Unfortunately, I am not sure how to proceed from there without some kind of data. I am thinking you could perform a cluster analysis in R based on the XY coordinates.. or maybe a classifier. I am pretty sure there is no built in way for QuPath to handle this, but it sounds like the sort of thing that could definitely be done with scripting. Without scripting, you could do the _Add smoothed features_, and then _Measure->Show measurement maps_ and select one of your smoothed features (you may be able to do this without the smoothing, depending on your data/images). You should be able to visually find the hotspots, and could then use the ""Points tool"" to mark the center of each hot spot manually. Adding a different classification of spot for each type of marker would get you a set of points of various classifications, which you could then use to compare distances. If your images are fluorescent, and you can split the channels, you might be able to run simple tissue detection on each individual channel to get centroid coordinates for hotspots (sufficient gaussian blur). Also, if you were to simplify the question to ""how many immune cells are within X um of my hotspot"" you could generate the annotation, import it, then _Objects->Expand Annotations_ and count how many immune cells are within that expanded annotation (which could all be automated). It would no doubt be a bit trickier than that if you are dealing with overlapping hotspots. There may be other ways as well, but that's be best first stab going in blind.; If you are able to open a thread on the forum or share an image I might be able to be more specific.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/181#issuecomment-400134063:1322,detect,detection,1322,https://qupath.github.io,https://github.com/qupath/qupath/issues/181#issuecomment-400134063,1,['detect'],['detection']
Safety,"Ok first i ran this script in Qupath. selectAnnotations();; getDetectionObjects() each {detection -> detection.setName(detection.getParent().getName())}; removeMeasurements(qupath.lib.objects.PathCellObject, ""Cell: Channel 1 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 std dev"", ""Nucleus: Channel 2 max - Smoothed (FWHM 25 µm)"", ""Cell: Eccentricity"", ""Cytoplasm: Channel 4 mean"", ""Nucleus: Eccentricity"", ""Cell: Channel 3 min"", ""Cell: Channel 1 min"", ""Cell: Circularity - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 mean"", ""Cell: Channel 4 std dev"", ""Nucleus: Channel 3 range"", ""Cytoplasm: Channel 4 min - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 sum - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 range - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 range - Smoothed (FWHM 25 µm)"", ""Nucleus: Circularity - Smoothed (FWHM 25 µm)"", ""Cell: Channel 3 max"", ""Cytoplasm: Channel 4 std dev"", ""Nucleus: Channel 1 min - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 min"", ""Nucleus: Channel 4 mean - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 3 min"", ""Nucleus: Max caliper - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 sum"", ""Nearby detection counts (radius 25 µm)"", ""Cell: Channel 2 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 4 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 3 mean"", ""Cell: Max caliper - Smoothed (FWHM 25 µm)"", ""Cell: Channel 1 min - Smoothed (FWHM 25 µm)"", ""Smoothed denominator (local density, FWHM 25 µm)"", ""Cell: Channel 1 std dev"", ""Cell: Perimeter - Smoothed (FWHM 25 µm)"", ""Nucleus/Cell area ratio - Smoothed (FWHM 25 µm)"", ""Cell: Channel 3 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 1 mean"", ""Nucleus: Channel 3 max"", ""Cell: Max caliper"", ""Nucleus: Channel 3 sum - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 min"", ""Cytoplasm: Channel 4 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 max - Smoothed (FWHM 25 µm)"", ""Nucleus: Eccentricity - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 std dev"", ""N",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/16#issuecomment-391785100:88,detect,detection,88,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391785100,3,['detect'],['detection']
Safety,"Ok, I tested the ""Offline TMA Data Viewer"" (not sure what to call this method!). I exported TMA data (qptma) for all 6 TMA slides. I loaded one file in the TMA Data Viewer in a new QuPath instance which seem to load data for all the qptma files present in the folder ! is that expected behavior ?. With this method the table is very smooth. It makes sense to work offline if I want to look at the combined data from multiple TMAs after completing the cell detection and classification. I opened one of the qptma file using notepad. I did not see any measurements or survival data in the file content - however the TMA Data Viewer was able to populate all the columns including measurements. Where is the data being pulled from ? what kind of magic is this. I may also have discovered additional bug(s):. 1. I am seeing columnImage is null error in the log at loading - everything seem to work regardless. The same error is thrown everytime I toggle ""Group by ID"" as well.; ```; ERROR: QuPath exception: Cannot invoke ""javafx.scene.control.TreeTableColumn.setPrefWidth(double)"" because ""columnImage"" is null; java.lang.NullPointerException: Cannot invoke ""javafx.scene.control.TreeTableColumn.setPrefWidth(double)"" because ""columnImage"" is null; at qupath.lib.gui.tma.TMASummaryViewer.lambda$refreshTableData$66(TMASummaryViewer.java:1463); ```; 2. In the log I also noticed ```WARN: Unable to find censored column - survival data will be uncensored``` - not sure why ? ; ```; INFO: Update check for https://github.com/qupath/qupath; WARN: You need to enable the startup script in the Preferences if you want to run it; INFO: Starting QuPath with parameters: []; INFO: Update check for https://github.com/qupath/qupath-extension-stardist; INFO: Predicate set to: null; INFO: Parsed 84 from HS-1_Scan1.ome.tif.qptma (84 total); INFO: Parsed 84 from HS-2_Scan1.ome.tif.qptma (168 total); INFO: Parsed 84 from HS-3_Scan1.ome.tif.qptma (252 total); INFO: Parsed 84 from HS-4_Scan1.ome.tif.qptma (336 total)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1083#issuecomment-1289564901:456,detect,detection,456,https://qupath.github.io,https://github.com/qupath/qupath/issues/1083#issuecomment-1289564901,1,['detect'],['detection']
Safety,"Ok, looks like by first applying ""Analyze -> Cell analysis -> Cell detection"" I was able to generate features for Classification. Using ""Analyze -> Calculate features -> Add intensity features (experimental)"" did not provide features. Thanks a lot!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/63#issuecomment-293365471:67,detect,detection,67,https://qupath.github.io,https://github.com/qupath/qupath/issues/63#issuecomment-293365471,1,['detect'],['detection']
Safety,"Okay, I think I describe what I want to do. And I would like to do that as automatically as possible, so in qupath in a .groovy script, I guess:. 1) I have a folder with IHC-fluorescence images (DAPI + antibody staining) of tumors with stroma. In Qupath:; For every image of the folder:; 2) In QuPath - perform cell detection; 3) In Qupath - object classification with a pretrained classifier (tumor vs. stroma); 4) Export detections with annotation into .roi file. In Fiji:; For every image of the folder:; 5) open .roi file; 6) --> discriminate tumor and stroma; 7) perform DNA-damage focus analysis in tumor and stroma separately (algorithm potentially uses other Plugins); 8) Finished. So, I want to use quPath for what it does very, very good and fast, cell identification, segmentation and classification, and not for anything else. Scripting in FIJI is more or less easy for me, so once I have the .roi files, I can do almost anything with them there. Just, for the ""QuPath part"", I dont even know how to script those simple steps, because there is not much documentation, no Qupath API, so its hard for me to even get started. I am not a professional programmer, but a biologist with some (Python, Java, ImageJ) programming background,. So, do you think, something like this is possible?. Overall, its very sad that there is so limited possibilities for scripting and export of those objects. It kind of destroys all that nice classification features, because it cannot be integrated in practical workflows. I think, the project would profit a lot to improve there asap, because, the core functionality itself is very interesting for people. Segmentation is either too slow, too complex or not precise enough with other tools. Best regards and thank you; Philipp",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/182#issuecomment-401542503:316,detect,detection,316,https://qupath.github.io,https://github.com/qupath/qupath/issues/182#issuecomment-401542503,2,['detect'],"['detection', 'detections']"
Safety,"Okay. Will look forward to the new version.; Thank you for your help, Pete. Best regards,; Kathy Yee. From: Pete <notifications@github.com>; Reply-To: qupath/qupath <reply@reply.github.com>; Date: Tuesday, June 9, 2020 at 11:50 AM; To: qupath/qupath <qupath@noreply.github.com>; Cc: ""Kathleen T. Yee"" <KYee@umc.edu>, Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [qupath/qupath] Zoom In and Zoom Out (#518). I'll close this issue, v0.2.1 should be available next week containing this and some other minor fixes. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fissues%2F518%23issuecomment-641435861&data=02%7C01%7Ckyee%40umc.edu%7C9d731bc401b64e12fc1608d80c953380%7C78a0681ef0be47e280498616858818a5%7C0%7C0%7C637273182238802631&sdata=35kLxw2W6caULJz3%2BBpsA14p3ff4jQMudfZyvd2fDBk%3D&reserved=0>, or unsubscribe<https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAP4MNE2ZSFDWOSMQL5V6SOTRVZR43ANCNFSM4NYSD4CA&data=02%7C01%7Ckyee%40umc.edu%7C9d731bc401b64e12fc1608d80c953380%7C78a0681ef0be47e280498616858818a5%7C0%7C0%7C637273182238812636&sdata=euPaoon04N%2F82Kf22ZIMOfEzWDQjc4LmxotHQSNCcaA%3D&reserved=0>. Individuals who have received this information in error or are not authorized to receive it must promptly return or dispose of the information and notify the sender. Those individuals are hereby notified that they are strictly prohibited from reviewing, forwarding, printing, copying, distributing or using this information in any way.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/518#issuecomment-641438041:647,safe,safelinks,647,https://qupath.github.io,https://github.com/qupath/qupath/issues/518#issuecomment-641438041,2,['safe'],['safelinks']
Safety,"One idea may be to forego cell detection (at least as a first step), and instead create square tiles or superpixels, add intensity/texture features to them, and then classify these. There is then a *Tile classification to annotations* command to merge the classified tiles. Cells could optionally be detected inside the annotations at the end, if still required. Alternatively, you could use *Extensions &rarr; ImageJ &rarr; Send region to ImageJ* to get a (possibly heavily downsampled) version of the image into ImageJ. The cells will be passed along too on an ImageJ overlay, with colors and names set according to their original classification. Then it becomes an ImageJ scripting/macro problem to combine these into regions - maybe using distance or voronoi transforms. *Plugins &rarr; Send ROI to QuPath* can be use to send back annotations to QuPath, if they are needed. In the event that you don't really care about the cell boundaries, you can open up the *Point* tool (three circles) and choose *Convert detections to points* first to get centroids only before sending them to ImageJ. I'm not sure if either of these do what you need, and the second may be a bit overly complicated. Could you say a bit more about the aim?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/70#issuecomment-298747073:31,detect,detection,31,https://qupath.github.io,https://github.com/qupath/qupath/issues/70#issuecomment-298747073,3,['detect'],"['detected', 'detection', 'detections']"
Safety,"One other thing... I find that the easiest way to avoid detecting outside the annotation is to modify the ImageJ macro, rather than do post-processing in QuPath. You can take advantage of the fact that, for any non-rectangular region, QuPath sends the ROI to ImageJ as well. And so ImageJ's *Edit &rarr; Clear Outside* can help. (In practice, it can be a bit more tricky than that... you might need to complicate your macro with checks to see whether there is a ROI present in the first place, and you might need to use *Edit &rarr; Selection &rarr; Select None* and *Edit &rarr; Selection &rarr; Restore Selection* within your macro if you find that you need to do some processing prior to using *Clear Outside*.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/56#issuecomment-288508331:50,avoid,avoid,50,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288508331,2,"['avoid', 'detect']","['avoid', 'detecting']"
Safety,"One problem I have occasionally seen with CZI is that a request for the *entire* image is made whenever only a small part is needed. This inevitably causes memory problems, but I have not yet been able to investigate when and why this might happen only for specific images. In the meantime I'd rather avoid suggesting that a huge amount of memory is required to use QuPath; it shouldn't be. Certainly with less memory available there may be problems if running something especially intensive (e.g. cell detection, even subcellular detection) across very large regions, but in that case the easiest solution is simply to restrict the analysis to smaller regions. But yes, if you can spare a few more GB it would be very good to increase what is available to QuPath. For what it's worth, my laptop has 16 GB RAM and I give about 8 GB to QuPath, although I've also used 4 GB for analysis (or less for just browsing and annotation). There are also some more memory-related tips at https://github.com/qupath/qupath/wiki/Troubleshooting#setting-memory-limits. It would be good to confirm whether the trouble only occurs when working with cell detection on large regions (at least hundreds of thousands of cells). My suspicion is that this isn't the case, and it is more likely to be related to the current patchy support for CZI - which is something I hope can be improved within the next few months. But I could be wrong on this if the behavior is fine whenever only small regions are considered.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/112#issuecomment-343393030:301,avoid,avoid,301,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343393030,4,"['avoid', 'detect']","['avoid', 'detection']"
Safety,"One reason I ask is that, depending upon the expected localization, there might be an argument for making the intensity measurements in a very small circular/rectangular region at the highest resolution, so as to make a measurement just around the cell centroid - not across the full region. The other reason is that I'm currently quite interested in adding the ability to detect different stains by providing sample colors - without any color deconvolution step. I'm not sure how relevant or helpful it would be here though.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/155#issuecomment-371256921:373,detect,detect,373,https://qupath.github.io,https://github.com/qupath/qupath/issues/155#issuecomment-371256921,1,['detect'],['detect']
Safety,"Ooh, that is good to know! I hadn't realized the tissue detection did not use the colors at all. That nixes the entire first paragraph of my first comment!. And to add on to Peter's last comment, I frequently calculate tissue area in R after the fact, using a sum of the cell areas in each core, or create a second set of cells temporarily with a larger cell expansion if the density is low (large enough that the fake cells fill in most of the tissue space) to get a fairly accurate measure of the tissue area in order to generate a positive cells/mm^2 value. And if the significant yellowing is the primary culprit, a difference just +/- 1 on the threshold could make a huge difference as long as the background is consistent.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/53#issuecomment-282515393:56,detect,detection,56,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282515393,1,['detect'],['detection']
Safety,"Oooh, mergeAnnotations looks great. I was going to say that I have been trying to avoid selecting, but didn't realize there was an easy workaround for the merge in this case!; Edit: The first two worked for me as well.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/129#issuecomment-354865710:82,avoid,avoid,82,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354865710,1,['avoid'],['avoid']
Safety,"Oooh, that script would have been useful a few times! I have wanted the ability to split ROIs, though I don't recall why at the moment. If the tissue regions are visually distinct, this forum thread might also give you a way to automatically create the regions from your simple tissue detection, though it will never be perfect! Also, the more features you use, the larger sample size you will need, and I don't know how well that will work with your data set. Image quality/lighting also needs to be similar throughout :). https://groups.google.com/forum/#!topic/qupath-users/gm0YYJxSriA. edit: woah, I triggered some kind of title effect with the formatting.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/99#issuecomment-328362033:285,detect,detection,285,https://qupath.github.io,https://github.com/qupath/qupath/issues/99#issuecomment-328362033,1,['detect'],['detection']
Safety,"Ooops, I misread part of your question. I do not know of any way to merge the two detection measurements from either side of a square, if you figure it out please let me know!. The best suggestion I can offer there is to make your tile sizes as large as ImageJ can handle on a per-tile basis.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/56#issuecomment-286897156:82,detect,detection,82,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286897156,1,['detect'],['detection']
Safety,"Oops, I somehow missed the followup question. I don't use any particular packages just to calculate areas, it's pretty much just a use of the base sum function. I'm certain there are more elegant ways to do this using functions, but I only have basic programming experience so for loops it is!; ```; path = ""Your file path here""; setwd(path); outFile <-""test areas.csv"". #Replace .txt with whatever identifier will pick up all of the files you want to analyze. Detections or Annotations are common choices; file.names <- dir(path,pattern = "".txt""). #an empty frame to place data into; Areas <- data.frame(). #simple for loop to read each file and keep a sum of the cell areas.; for(i in 1:length(file.names)){; data.raw <- read_delim(file.names[i],""\t"", escape_double = FALSE, trim_ws = TRUE). #place the file names in the first column; Sample = tools::file_path_sans_ext(file.names[i]); Areas[i,1]<-Sample. #Sum of cell areas here. Add extra lines for mean of intensity/OD, etc; Areas[i,2]<-sum(data.raw$""Cell: Area""). }; Areas$""Area mm^2""<- Areas$V2/1000000. #set row names to F if you don't want a numbered list as the first column; write.csv(Areas, outFile, row.names=T); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/59#issuecomment-290314163:461,Detect,Detections,461,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-290314163,1,['Detect'],['Detections']
Safety,"Oops, my mistake. That's what I get for always posting as I wake up!. I have found them useful in SLIC classifications to automatically detect different types of tissue... and that is about it. Which ones are useful and why, I don't really know as I tend to feed them into classifiers and have not yet found a way to extract information from the classifier regarding which measurements were most useful. It was mostly trial and error based on what worked. Edit: The top discriminating features sounds like... a fantastic feature!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424748214:136,detect,detect,136,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424748214,1,['detect'],['detect']
Safety,"Oops, yes, he did say that in the first post. I think my wires got crossed while reading the forum post on automating the ImageJ macro runner across images. It is interesting that his import (and more importantly export) works for a single slide. I am still wondering if it not working in batch mode means that something isn't being given time to complete. @erexhepa When running it for a single slide, once all of the imported ROIs are in place, can you then use getDetectionObjects (on it's own as a separate script or menu command) to target anything? Does the Measure->Show detection measurements populate as soon as the script is complete?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/136#issuecomment-357388634:578,detect,detection,578,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357388634,1,['detect'],['detection']
Safety,Opening the same image in multiple viewers results in detections being wrongly shown in both,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1217:54,detect,detections,54,https://qupath.github.io,https://github.com/qupath/qupath/issues/1217,1,['detect'],['detections']
Safety,"Optimiziation of Positive Cell detection - example Ki67, in H DAB",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/46:31,detect,detection,31,https://qupath.github.io,https://github.com/qupath/qupath/issues/46,1,['detect'],['detection']
Safety,Out-of-bounds tiles can result in detected cells being in the wrong place,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1606:34,detect,detected,34,https://qupath.github.io,https://github.com/qupath/qupath/issues/1606,1,['detect'],['detected']
Safety,"PathCellObject, ""Cell: Channel 1 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 std dev"", ""Nucleus: Channel 2 max - Smoothed (FWHM 25 µm)"", ""Cell: Eccentricity"", ""Cytoplasm: Channel 4 mean"", ""Nucleus: Eccentricity"", ""Cell: Channel 3 min"", ""Cell: Channel 1 min"", ""Cell: Circularity - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 mean"", ""Cell: Channel 4 std dev"", ""Nucleus: Channel 3 range"", ""Cytoplasm: Channel 4 min - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 sum - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 range - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 range - Smoothed (FWHM 25 µm)"", ""Nucleus: Circularity - Smoothed (FWHM 25 µm)"", ""Cell: Channel 3 max"", ""Cytoplasm: Channel 4 std dev"", ""Nucleus: Channel 1 min - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 min"", ""Nucleus: Channel 4 mean - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 3 min"", ""Nucleus: Max caliper - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 sum"", ""Nearby detection counts (radius 25 µm)"", ""Cell: Channel 2 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 4 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 3 mean"", ""Cell: Max caliper - Smoothed (FWHM 25 µm)"", ""Cell: Channel 1 min - Smoothed (FWHM 25 µm)"", ""Smoothed denominator (local density, FWHM 25 µm)"", ""Cell: Channel 1 std dev"", ""Cell: Perimeter - Smoothed (FWHM 25 µm)"", ""Nucleus/Cell area ratio - Smoothed (FWHM 25 µm)"", ""Cell: Channel 3 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 1 mean"", ""Nucleus: Channel 3 max"", ""Cell: Max caliper"", ""Nucleus: Channel 3 sum - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 min"", ""Cytoplasm: Channel 4 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 max - Smoothed (FWHM 25 µm)"", ""Nucleus: Eccentricity - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 std dev"", ""N",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/16#issuecomment-391785100:1134,detect,detection,1134,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391785100,1,['detect'],['detection']
Safety,"Perhaps something making use of the hierarchy? The Detection Centroid Distances should apply to all detections **except for detections that are child objects of other detections**. ; This would exclude subcellular detections from the run, and would keep the logic working. However at that point it could work for both detections and cells?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1550#issuecomment-2283403451:51,Detect,Detection,51,https://qupath.github.io,https://github.com/qupath/qupath/issues/1550#issuecomment-2283403451,6,"['Detect', 'detect']","['Detection', 'detections']"
Safety,"Pete and Svidro:. That's got it! Thanks both so much for your help. . I have one final question. The subcellular spot detection seems to be picking up yellow in addition to red. After designating the ROI and doing a cell count, I used the Analyze > Preprocessing > Estimate stain vectors command, selected ""Auto"", then OK. The program picks up the red spots, beautifully, but also seems to pick up some aberrant yellow pigment. Here are a few images:; ![image](https://user-images.githubusercontent.com/36250970/36645494-c2c50a14-1a37-11e8-9932-2b15b61a5e31.png). ![image](https://user-images.githubusercontent.com/36250970/36645503-d0a0d780-1a37-11e8-9e32-3dca42a8ec52.png). Any thoughts on how to avoid detection of the yellow pigment?. Thanks again for this program and your help!!. Jim",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/146#issuecomment-368337080:118,detect,detection,118,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368337080,3,"['avoid', 'detect']","['avoid', 'detection']"
Safety,"Pete, . Thank you deeply for the complete explanation and information regarding this. . I will now consider this as closed myself, but will most likely continue (at my own risk, as you say) working on this feature as I sincerely do believe it to be useful, and will find a way without changing anything in QuPath. I am aware it will break at one point or another but for the benefit of our users it will be worth to maintain. . Thank you for all the time and effort explaining this to me, and for the scripting alternatives you have provided which I am sure we will be making use of. 😃",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/26#issuecomment-632682362:172,risk,risk,172,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632682362,1,['risk'],['risk']
Safety,Please avoid creating issues for anything other than bug reports; [use the forum instead](http://forum.image.sc/tags/qupath/).; ![image](https://user-images.githubusercontent.com/23145209/73910566-914ea000-4864-11ea-8072-8310ead5efb2.png),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/397#issuecomment-582753754:7,avoid,avoid,7,https://qupath.github.io,https://github.com/qupath/qupath/issues/397#issuecomment-582753754,1,['avoid'],['avoid']
Safety,Positive Cell Detection misses sections,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/828:14,Detect,Detection,14,https://qupath.github.io,https://github.com/qupath/qupath/issues/828,1,['Detect'],['Detection']
Safety,Positive Pixel Detection,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/611:15,Detect,Detection,15,https://qupath.github.io,https://github.com/qupath/qupath/issues/611,1,['Detect'],['Detection']
Safety,"Positive Pixel count does not work after simple tissue detection if checkbox ""single annotation"" is deactivated",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/111:55,detect,detection,55,https://qupath.github.io,https://github.com/qupath/qupath/issues/111,1,['detect'],['detection']
Safety,Positive cell detection,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/64:14,detect,detection,14,https://qupath.github.io,https://github.com/qupath/qupath/issues/64,1,['detect'],['detection']
Safety,Positive cell detection on multiple annotations,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/148:14,detect,detection,14,https://qupath.github.io,https://github.com/qupath/qupath/issues/148,1,['detect'],['detection']
Safety,"Positive cell detection only works on the first go. Other ways to do it involve using the Classify by specific feature option under the Classify menu and choosing your cutoff there, while choosing the cutoff for your specific measurement for the given cell type (IE choose tumor as the input, and then positive tumor or negative tumor as the output). You may have to create the extra classes. The other way involves a one line script that classifies as positive or negative by the value you input. . setCellIntensityClassifications(""Cytoplasm: DAB OD mean"", 0.15)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/64#issuecomment-293464289:14,detect,detection,14,https://qupath.github.io,https://github.com/qupath/qupath/issues/64#issuecomment-293464289,1,['detect'],['detection']
Safety,Positive cell detection setup parameters,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/226:14,detect,detection,14,https://qupath.github.io,https://github.com/qupath/qupath/issues/226,1,['detect'],['detection']
Safety,"Possibly controversial, possibly very welcome... Usually, the annotation line thickness remains constant at all zoom levels - whereas the detection line thickness increases and decreases when zooming in and out. This is partly to avoid having thick detection lines when zoomed out, and partly for performance reasons: we cache detections rendered at different resolutions. *However*, detections *are* painted 'live' (like annotations) when zooming in beyond full resolution. I find this can be annoying at times, because the default detection line thickness of 2 can be too much - and obscures details. I need to toggle detections on and off to see the pixels that overlap with the border, or else go to the preferences to reduce the line for some images... then go back to increase the line for the next images. So this PR causes detections to be painted more like annotations when upsampling. The result is that lines narrow to become subpixel when zooming in, and that it is possible to more accurately judge where the detection boundary really lies. Screenshots below, but they aren't the best examples - and it's better to play around with the behavior using different images to form an opinion as to whether this is better, worse, or pretty neutral. ## Previous. ![older-rendering](https://github.com/user-attachments/assets/4e637414-6e6a-46c3-9044-bb51db67fa6d). ## With this PR. ![new-rendering](https://github.com/user-attachments/assets/0fd890bc-76d2-4aff-885b-5d25580d0114)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1623:138,detect,detection,138,https://qupath.github.io,https://github.com/qupath/qupath/pull/1623,9,"['avoid', 'detect']","['avoid', 'detection', 'detections']"
Safety,"Potentially, with a bit of effort. It's easier if you can avoid needing to handle mouse clicks etc., and don't mind simply placing the circle at the center of the current field of view. You can always then move it afterwards if you need to refine the position manually, using the existing *Move* tool. A similar processing for creating a rectangle is described on [this blog post](https://petebankhead.github.io/qupath/scripting/2018/03/09/script-create-fixed-size-region.html). `RectangleROI` appears twice in that script. If you just replace it with `EllipseROI` in both places it should do the job (and of course change the `PathClass` bit if you want). The `sizeMicrons` value specified in the script should correspond to the diameter.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/158#issuecomment-376154987:58,avoid,avoid,58,https://qupath.github.io,https://github.com/qupath/qupath/issues/158#issuecomment-376154987,1,['avoid'],['avoid']
Safety,Predict tumor percentage,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/364:0,Predict,Predict,0,https://qupath.github.io,https://github.com/qupath/qupath/issues/364,1,['Predict'],['Predict']
Safety,"Preview & QuPath both look ok to me:. ![Screenshot 2020-10-23 at 20 49 48](https://user-images.githubusercontent.com/4690904/97047805-6bdc0080-1571-11eb-8a78-f2ec9652945c.png). I do have a homebrew install as well:. ![Screenshot 2020-10-23 at 20 52 12](https://user-images.githubusercontent.com/4690904/97048049-ba899a80-1571-11eb-8751-6dc0394469e5.png). ----. Thanks very much for the link, I'll check your build scripts - I think it is already safe to say they are a lot more sophisticated than anything used for QuPath! I'm afraid I'm one of the people who has spent too long with Java and Python... Do you think there would be any sense in trying to include libvips with QuPath? We could put some work into that from our side - especially if it would help us incorporate OpenSlide more reliably into QuPath while also giving access to some of libvips' other functionality (like faster image pyramid-writing?) - but I'm not sure if there are reasons that's a bad idea.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/627#issuecomment-715571233:446,safe,safe,446,https://qupath.github.io,https://github.com/qupath/qupath/issues/627#issuecomment-715571233,1,['safe'],['safe']
Safety,"Project contains total of 6 TMA slides. Each contains approximately ~80 cores. A few cores are marked as missing per slide due to not enough tissue or missing information. I have a total of approximately ~400 valid cores in the project, each slide may contain multiple cores per subject id. I tested the Measure -> show TMA measurements. This means I can only load the data for the active image. The table does work with a tiny bit of scrolling lag - very little. If I open the same image without detections the table is smooth. . I have about ~ 13 classes. I am working with 7 channel multiplex image hence each detection has 116 measurements (shape and intensity)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1083#issuecomment-1289206954:497,detect,detections,497,https://qupath.github.io,https://github.com/qupath/qupath/issues/1083#issuecomment-1289206954,2,['detect'],"['detection', 'detections']"
Safety,"Proposed fix for https://github.com/qupath/qupath/issues/654. Note that from the command line the exit code should be 0 if a script succeeded or 1 if an exception was thrown. Note that this applies to running the `script` subcommand for a single image. If an exception is thrown when attempting to apply the script to *multiple* images in a project, QuPath will attempt to recover and continue processing the next image. The exit code will then be 0.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/676:373,recover,recover,373,https://qupath.github.io,https://github.com/qupath/qupath/pull/676,1,['recover'],['recover']
Safety,"QP 0.2.0m2; ![image](https://user-images.githubusercontent.com/23145209/55431995-a375f880-5546-11e9-8ebd-a9f9aa4d29d9.png). Channel name disconnect between what is listed in the Compute Intensity Features dialog (channel names), channels listed for cell detection (here Channel 1,2 and 3), and channels listed after the Compute (here, Channel 0, 1 and 2). If channel names are going to be used in addition to the channel counts, it might be useful to add the channel counts to the dialog box as well [so the first line would read ""DAPI (Channel 1)""]. Minor: Menu says ""Add intensity features"" while dialog title is ""Compute intensity features""",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/301:254,detect,detection,254,https://qupath.github.io,https://github.com/qupath/qupath/issues/301,1,['detect'],['detection']
Safety,QuPath detection cytoplasm Inclusions,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/994:7,detect,detection,7,https://qupath.github.io,https://github.com/qupath/qupath/issues/994,1,['detect'],['detection']
Safety,"QuPath gives the tools to do all kinds of things, but some are easier than others. Distinct commands (e.g. cell detection) can be combined with others (e.g. classifying cells as positive or negative, interactive machine learning) for particular applications (e.g. scoring Ki-67). But these or other commands could be combined in different ways for different applications. QuPath doesn't have a 'Ki-67 scoring' algorithm in particular, but it has the pieces that can be used to create and customize one. _However_... there are a lot of things that I _wouldn't_ try with QuPath's built in commands only, and mitosis detection in H&E is one of them. I'd say the detection task is too difficult and specialized for QuPath's generic cell detection currently. Solving that is a substantial research project in itself (and the subject of some [grand challenges](https://mitos-atypia-14.grand-challenge.org)). That's one of the reasons why QuPath supports scripts and extensions: it's possible to create highly specialist algorithms elsewhere, and either integrate them into QuPath or at least visualize the results through QuPath. Therefore some of the ways in which QuPath can help are:; * for manual counting; * for exporting manual counts as 'ground truth' into a format that can be used to help create a new algorithm, using whatever image processing / machine learning / deep learning libraries and tools you like; * for visualizing the results of an algorithm directly in the context of a whole slide image (using QuPath's objects, classifications & visualization tools to help); * as the platform for running and sharing any algorithm you might create (if it's implemented as a QuPath script or extension). The first of these is pretty laborious, while the last three will take some effort and knowledge on the image analysis side. That's the side I come from... I created QuPath because I needed the tools myself to write new algorithms, and then to share them with pathologists and other researchers",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/205#issuecomment-414438828:112,detect,detection,112,https://qupath.github.io,https://github.com/qupath/qupath/issues/205#issuecomment-414438828,4,['detect'],['detection']
Safety,"QuPath has mostly been used with brightfield images stained with H&E or hematoxylin and DAB. Setting a third stain, or adapting to different stains, is not exactly as easy or intuitive as it could/should be (e.g. see [this discussion on Google Groups](https://groups.google.com/forum/#!topic/qupath-users/xfocO2S2kSQ)). Annoyances include:; * After setting a stain (e.g. hematoxylin) with one image type selected, switching the image type causes the values of that stain vector to be lost; * When setting a stain manually based on a small region of interest, double-clicking on the stain name gives the option to either set the stain from the vector or change its name... but not both; * The *Normalize OD colors* visualization option under *Brightness/Contrast* is particularly useful for the *Brightfield Other* image type, since it helps find areas where stain vectors could be set - but it doesn't appear for this image type; * It is possible in a script to set the image type to be (for example) *Brightfield H-DAB*, but give 3 different stain vectors; this image type should probably force the third vector to be the residual stain vector; * Commands such as *Create cytokeratin annotations* assume DAB will be used... this command could be considerably more general and useful than its name (and current implementation) suggests; * *Fast cell counts* has an option to detect on the sum of *Hematoxylin + DAB*... this can be quite useful, and may be worth adding to the general *Cell detection* command as another option; * There is no way to select previously-used stains... having a persistent list (similar to the classification list) would be nice",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/73:1375,detect,detect,1375,https://qupath.github.io,https://github.com/qupath/qupath/issues/73,2,['detect'],"['detect', 'detection']"
Safety,"Quick addition. Defining an area using a polygon no longer works for the in-built detection, just when running a stardist script:. ![image](https://github.com/qupath/qupath/assets/154437026/9e4ba23a-f54a-4742-8a5c-ec10b063f7f2). ```; ERROR: Error processing Polygon (7616, 10604, 2099, 1863); java.io.IOException: java.lang.InterruptedException; at qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:911); at qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.lib.images.servers.CroppedImageServer.readRegion(CroppedImageServer.java:90); at qupath.lib.images.servers.CroppedImageServer.readRegion(CroppedImageServer.java:39); at qupath.lib.images.servers.SparseImageServer.readTile(SparseImageServer.java:265); at qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:863); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:902); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:216); at qupath.lib.p",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583:82,detect,detection,82,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583,1,['detect'],['detection']
Safety,"Quick update: there are no longer any plans to make QuPath OpenJDK 15-compatible. The next release is intended to be >= March 2021, by which time OpenJDK 16 should be available and there is a risk things will have changed again. However, jpackage is an intended feature for 16 so should be more stable... and worth updating for. In the meantime, QuPath v0.2.* is only intended to be built with OpenJDK 14. QuPath's code should be compatible with Java 11; OpenJDK 14 is required only for jpackage. From an IDE, it should run with other Java versions.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/615#issuecomment-757141337:192,risk,risk,192,https://qupath.github.io,https://github.com/qupath/qupath/issues/615#issuecomment-757141337,1,['risk'],['risk']
Safety,"Qupath with tensorflow build (https://qupath.readthedocs.io/en/latest/docs/advanced/stardist.html) keeps closing while running Stardist on large images. I get the following error report in the QuPath directory (hs_err_pid1260.txt - first parts of error report included) - any idea what's wrong? I see maximum memory can only be set to 32 GB, even though 64 GB is available. # A fatal error has been detected by the Java Runtime Environment:; #; # EXCEPTION_ACCESS_VIOLATION (0xc0000005) at pc=0x00007ff9724d7c77, pid=1260, tid=17968; #; # JRE version: OpenJDK Runtime Environment AdoptOpenJDK (14.0.1+7) (build 14.0.1+7); # Java VM: OpenJDK 64-Bit Server VM AdoptOpenJDK (14.0.1+7, mixed mode, tiered, g1 gc, windows-amd64); # Problematic frame:; # C 0x00007ff9724d7c77; #; # No core dump will be written. Minidumps are not enabled by default on client versions of Windows; #; # If you would like to submit a bug report, please visit:; # https://github.com/AdoptOpenJDK/openjdk-support/issues; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. --------------- S U M M A R Y ------------. Command Line: -Djava.library.path=C:\Users\IT-bruker\Documents\GitHub\qupath\build\dist\QuPath-0.2.0-m12-SNAPSHOT\app;C:\Users\IT-bruker\Documents\GitHub\qupath\build\dist\QuPath-0.2.0-m12-SNAPSHOT -Djava.launcher.path=C:\Users\IT-bruker\Documents\GitHub\qupath\build\dist\QuPath-0.2.0-m12-SNAPSHOT -XX:MaxRAMPercentage=50 qupath.QuPath. Host: Intel(R) Xeon(R) W-2155 CPU @ 3.30GHz, 20 cores, 63G, Windows 10 , 64 bit Build 18362 (10.0.18362.778); Time: Mon May 18 12:40:22 2020 Vest-Europa (sommertid) elapsed time: 599 seconds (0d 0h 9m 59s). --------------- T H R E A D ---------------. Current thread (0x00000295c2dd7000): JavaThread ""ForkJoinPool.commonPool-worker-37"" daemon [_thread_in_native, id=17968, stack(0x000000f49ec00000,0x000000f49ed00000)]. Stack: [0x000000f49ec00000,0x000000f49ed00000], sp=0x000000f49ecfe350, free s",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/481:399,detect,detected,399,https://qupath.github.io,https://github.com/qupath/qupath/issues/481,1,['detect'],['detected']
Safety,R: Error running plugin: java.lang.OutOfMemoryError: Java heap space; java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: Java heap space; at java.base/java.util.concurrent.FutureTask.report(Unknown Source); at java.base/java.util.concurrent.FutureTask.get(Unknown Source); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:139); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:107); at qupath.lib.gui.PluginRunnerFX.runTasks(PluginRunnerFX.java:98); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:169); at qupath.lib.gui.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:192); at java.base/java.lang.Thread.run(Unknown Source); Caused by Java heap space at java.base/java.util.ArrayDeque.<init>(Unknown Source); at qupath.imagej.processing.Watershed$WatershedQueueWrapper.<init>(Watershed.java:242); at qupath.imagej.processing.Watershed.doWatershed(Watershed.java:83); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.doDetection(WatershedCellDetection.java:852); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:1063); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:303); at qupath.imagej.detect.cells.PositiveCellDetection$DetectorWrapper.runDetection(PositiveCellDetection.java:140); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Sourc,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/828#issuecomment-932330593:1317,detect,detect,1317,https://qupath.github.io,https://github.com/qupath/qupath/issues/828#issuecomment-932330593,1,['detect'],['detect']
Safety,Recover from NPE if colormap requested with a color missing,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/473:0,Recover,Recover,0,https://qupath.github.io,https://github.com/qupath/qupath/pull/473,1,['Recover'],['Recover']
Safety,Recover when going wild with the 'radius' slider and generating density maps,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/790:0,Recover,Recover,0,https://qupath.github.io,https://github.com/qupath/qupath/pull/790,1,['Recover'],['Recover']
Safety,"Reduce support to single-input, single-output models for now, to avoid a strict requirement for input names to be correct.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/809:65,avoid,avoid,65,https://qupath.github.io,https://github.com/qupath/qupath/pull/809,1,['avoid'],['avoid']
Safety,Redundancy in if-else condition of ImageWriteTools.java,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/816:0,Redund,Redundancy,0,https://qupath.github.io,https://github.com/qupath/qupath/issues/816,1,['Redund'],['Redundancy']
Safety,"Regarding the script, are you merging two different annotation classes two different ways? Or merging the same annotation twice? Are you running the cell detection command in the script immediately after the second merge? That could be a big problem if so. You have two merge statements, each done a different way. If you are actually running the script as is, you are probably running into the same problem as before, where one merge has not completed when the second starts running, and everything is getting ""bugged out."" If that is the case (and you are running your cell detection in the script right after the second merge), you may want the thread sleep command from https://github.com/qupath/qupath/issues/129. I am not certain, but I have a feeling that this has more to do with the shape of your annotation causing cell detection a problem than the merge statement. . When I have had something like this happen (cell detection starts running, but no cells show up in the annotation tab), it does not always show an error in the log, but the first thing to do would be to check the View->Show log to see if there is an error message there. If there is, great, that might be useful. On the other hand, if there is nothing, it may just be the cell detection not completing, but without causing any errors. . If none of the above helps, could you paste your .qpdata file as a .log file (rename the file extension), with ONLY the annotations saved. It should be quite small. I would like to try importing it onto another dummy whole slide image just to try running cell detection to see if the shape of the annotation is causing problems.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/147#issuecomment-365346916:154,detect,detection,154,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365346916,6,['detect'],['detection']
Safety,"Relates to; * https://github.com/qupath/qupath/issues/1444; * https://github.com/qupath/qupath/issues/1591 . and incorporates synchronization from; * https://github.com/qupath/qupath/pull/1466. ---. This substantially updates the `MeasurementList` API, while avoiding any serialization-breaking changes.; It also adds many new tests to help improve the robustness of both the `MeasurementList` directly and any associated `Map` view. Methods that were deprecated since v0.4.0 have now been removed, and there are 2 more deprecations.; The replacement methods have shorter names and should have reliable performance.; `MeasurementList` implementations should also now be threadsafe (if they prove not to be, please report a bug). Several other key changes:; * `getNames()` (previously `getMeasurementNames()`) returns a defensive copy of the measurement. Before, it would sometimes return an unmodifiable list that wrapped a list that could still change - and that was sometimes responsible for #1444 and #1591; * `List<Measurement> getMeasurements()` and `Measurement getByIndex(int)` now provide ways to access a snapshot of one or more measurements. Previously, `getMeasurementName(int)` and `getMeasurementValue(int)` were used - but when requesting these sequentially, there was no way to guarantee that the values were properly in sync.; * `String.intern()` is now used with all `MeasurementList` implementations. Previously, it was only used for the 'general' list used for annotations. It wasn't important if other lists were closed, but if they weren't then we could end up with huge numbers of duplicate strings greatly increasing memory use. In general, the goal of `MeasurementList` is to optimize mostly for memory use and good behavior.; Updating and querying measurements is generally rare enough that small computational costs (e.g. synchronization, defensive copying) shouldn't matter a great deal - but if we are to cope with millions of objects having hundreds of measurements each, ",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1592:259,avoid,avoiding,259,https://qupath.github.io,https://github.com/qupath/qupath/pull/1592,1,['avoid'],['avoiding']
Safety,"Relax the requirements that any image has to be a local file to work with Bio-Formats. For example, https://qupath.github.io/images/qupath-banner-web-logo.jpg can now be opened directly. This may become more important if Zarr support becomes available through Bio-Formats. One risk with this is that it will make adding an OMERO (or similar) image very slow, as Bio-Formats tries and fails to read it. To mitigate the problem, the image is tested based upon its URI path only - if no potentially-compatible reader is found then the image read won't be attempted. The option to read other URLs is turned off by default through the preferences.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/729:277,risk,risk,277,https://qupath.github.io,https://github.com/qupath/qupath/pull/729,1,['risk'],['risk']
Safety,Remove accidental use of Java 16 Stream.toList() and update Action to catch such problems earlier.; Increase available memory for testing to avoid errors on Apple Silicon.,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/797:141,avoid,avoid,141,https://qupath.github.io,https://github.com/qupath/qupath/pull/797,1,['avoid'],['avoid']
Safety,"Remove generic parameter and move prediction & blob functions to `AbstractDnnModel`. The motivations are:; - make it easier to implement `DnnModel`; - make it easier to handle memory management with the DeepJavaLibrary implementation. The second is because memory management seems to work best when using a `Translator` and not working directly with `NDList` inputs and outputs for prediction. This means that it's better to predict 'all at once' rather than across multiple methods (create blob, predict, convert output).",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1422:34,predict,prediction,34,https://qupath.github.io,https://github.com/qupath/qupath/pull/1422,4,['predict'],"['predict', 'prediction']"
Safety,Rename Object Classification submenu to Detection Classification,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1501:40,Detect,Detection,40,https://qupath.github.io,https://github.com/qupath/qupath/issues/1501,1,['Detect'],['Detection']
Safety,"Reopening this as it's very similar and still happening in QuPath 0.5.0; A user had an annotation inside which there was another annotation filled with detections (over 5000); When runing ""Delaunay cluster features 2D"" we ran into; ```; Error running plugin: java.util.ConcurrentModificationException; java.util.concurrent.ExecutionException: java.util.ConcurrentModificationException; at java.base/java.util.concurrent.FutureTask.report(Unknown Source); at java.base/java.util.concurrent.FutureTask.get(Unknown Source); at qupath.lib.plugins.AbstractTaskRunner.awaitCompletion(AbstractTaskRunner.java:147); at qupath.lib.plugins.AbstractTaskRunner.runTasks(AbstractTaskRunner.java:117); at qupath.lib.gui.TaskRunnerFX.runTasks(TaskRunnerFX.java:106); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:147); at qupath.lib.gui.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:177); at java.base/java.lang.Thread.run(Unknown Source); Caused by: java.util.ConcurrentModificationException; at java.base/java.util.ArrayList.checkForComodification(Unknown Source); at java.base/java.util.ArrayList.equals(Unknown Source); at java.base/java.util.WeakHashMap.matchesKey(Unknown Source); at java.base/java.util.WeakHashMap.get(Unknown Source); at java.base/java.util.Collections$SynchronizedMap.get(Unknown Source); at qupath.lib.measurements.NumericMeasurementList$AbstractNumericMeasurementList.getNameMap(NumericMeasurementList.java:142); at qupath.lib.measurements.NumericMeasurementList$AbstractNumericMeasurementList.close(NumericMeasurementList.java:133); at qupath.lib.measurements.NumericMeasurementList$FloatList.close(NumericMeasurementList.java:352); at qupath.opencv.features.DelaunayTriangulation.addClusterMeasurements(DelaunayTriangulation.java:466); at qupath.opencv.features.DelaunayClusteringPlugin$DelaunayRunnable.run(DelaunayClusteringPlugin.java:215); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concu",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1444:152,detect,detections,152,https://qupath.github.io,https://github.com/qupath/qupath/issues/1444,1,['detect'],['detections']
Safety,"Requesting access to all 3 channels for subcellular detections, useful when handling non-standard stains (Brightfield Other). It would be much easier than juggling around the detections and color vectors and re-inserting them into the project.; ![image](https://user-images.githubusercontent.com/23145209/56070489-ddac7a80-5d3c-11e9-9c0e-d86cccf87dea.png). :)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/304:52,detect,detections,52,https://qupath.github.io,https://github.com/qupath/qupath/issues/304,2,['detect'],['detections']
Safety,Require ability to sub-classify any detections according to intensity,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/16:36,detect,detections,36,https://qupath.github.io,https://github.com/qupath/qupath/issues/16,1,['detect'],['detections']
Safety,Resolve hierarchy is very slow for some TMA images with many detections,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/564:61,detect,detections,61,https://qupath.github.io,https://github.com/qupath/qupath/issues/564,1,['detect'],['detections']
Safety,"SLIC superpixel detection has stopped working in m3. It divides the large annotation into tiles, and then just stops. According to Svidro, it produces this error in the log: . ERROR: Error running plugin: java.lang.IllegalArgumentException: No boolean parameter with key 'doMerge'; at java.base/java.util.concurrent.FutureTask.report(Unknown Source); at java.base/java.util.concurrent.FutureTask.get(Unknown Source); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:193); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:157); at qupath.lib.gui.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:156); at qupath.lib.gui.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:185); at java.base/java.lang.Thread.run(Unknown Source); Caused by No boolean parameter with key 'doMerge' at qupath.lib.plugins.parameters.ParameterList.getBooleanParameterValue(ParameterList.java:379); at qupath.lib.plugins.parameters.ParameterList.getBooleanParameterValue(ParameterList.java:417); at qupath.imagej.superpixels.SLICSuperpixelsPlugin$SLICSuperpixelDetector.runDetection(SLICSuperpixelsPlugin.java:281); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:132); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/344:16,detect,detection,16,https://qupath.github.io,https://github.com/qupath/qupath/issues/344,4,"['Detect', 'detect']","['DetectionPluginTools', 'DetectionRunnable', 'detection']"
Safety,"See https://forum.image.sc/t/can-creating-detections-from-pixel-classifier-be-made-to-run-faster/96745/25 Bio-Formats 7.2.0 handles pyramid levels differently for SVS images, which would break compatibility with the metadata stored in QuPath projects. Basically, the levels stored in the project would override the levels that Bio-Formats expects to find. Consequence: if a project was created in v0.5.1 (or earlier), including SVS images read using Bio-Formats, these images could not be opened in v0.6.0. This PR logs a warning when this occurs, and uses the 'new' pyramid levels are used instead of the ones stored in the saved metadata.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1549:42,detect,detections-from-pixel-classifier-be-made-to-run-faster,42,https://qupath.github.io,https://github.com/qupath/qupath/pull/1549,1,['detect'],['detections-from-pixel-classifier-be-made-to-run-faster']
Safety,See https://forum.image.sc/t/qupath-wrongly-placed-detections-with-out-of-bounds-annotations/100914 for full details.,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1606:51,detect,detections-with-out-of-bounds-annotations,51,https://qupath.github.io,https://github.com/qupath/qupath/issues/1606,1,['detect'],['detections-with-out-of-bounds-annotations']
Safety,"See https://github.com/qupath/qupath/issues/587; These changes don't correct cells that 'go wrong' (with TopologyExceptions), but instead try to recover more gracefully - so that *all* cells are not lost.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/588:145,recover,recover,145,https://qupath.github.io,https://github.com/qupath/qupath/pull/588,1,['recover'],['recover']
Safety,"See original discussion at https://forum.image.sc/t/qupath-white-background/65030. The idea is that sometimes it makes sense for the background to be black, sometimes it makes sense for it to be white. Inverting the RGB image alone isn't enough, since this changes all the colors. However, a combination of RGB inversion plus inverting individual LUTs can achieve the effect of inverting the background but keeping the other colors similar. This avoids any need to define special LUTs. The end result makes a fluorescence image look a *bit* like a brightfield one. Although does potentially end up saturating more quickly and so is less informative in the end. For that reason, a warning appears. Inverting RGB images works slightly differently from other multichannel images, in that values are divided by two during the process to avoid most pixels ending up being black. I think this gives a more sensible-looking result when inverting a brightfield image, but the behavior may change based on feedback. Implementing this involved making substantial changes to `ImageDisplay` and associated classes, including introducing a new `ChannelDisplayMode` class. While doing this, I tried to improve the consistency within the Brightness/Contrast dialog for all combinations of inverted/not-inverted background and grayscale/color LUTs. ### Existing visualization. ![inverted screenshot black](https://user-images.githubusercontent.com/4690904/161815495-19db089a-b65a-457d-90d3-473cd15d8dd7.png). ### Inverted visualization. ![inverted screenshot](https://user-images.githubusercontent.com/4690904/161815522-10cea11c-4664-4815-ba15-ae65ad907940.png)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/945:446,avoid,avoids,446,https://qupath.github.io,https://github.com/qupath/qupath/pull/945,2,['avoid'],"['avoid', 'avoids']"
Safety,Set Javadoc viewer scrollbars to always use light mode to avoid this:; ; ![image](https://github.com/user-attachments/assets/633fa351-876f-4800-9414-dd9ea6858f15). This was done by redefining the main JavaFX CSS variable.,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1574:58,avoid,avoid,58,https://qupath.github.io,https://github.com/qupath/qupath/pull/1574,1,['avoid'],['avoid']
Safety,Set min logviewer width to avoid clipping,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1339:27,avoid,avoid,27,https://qupath.github.io,https://github.com/qupath/qupath/pull/1339,1,['avoid'],['avoid']
Safety,Simple Tissue Detection within an annotation,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/248:14,Detect,Detection,14,https://qupath.github.io,https://github.com/qupath/qupath/issues/248,1,['Detect'],['Detection']
Safety,Simple tissue detection for TMA does not work,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/53:14,detect,detection,14,https://qupath.github.io,https://github.com/qupath/qupath/issues/53,1,['detect'],['detection']
Safety,"Since it seems (from what I can tell) that all the commands within this menu work only on detections and not annotations, the submenu should be called Detection classification, so as not to give the impression that they work on annotations.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1501:90,detect,detections,90,https://qupath.github.io,https://github.com/qupath/qupath/issues/1501,2,"['Detect', 'detect']","['Detection', 'detections']"
Safety,"So I confirm that all access to any mutable variable should be synchronized. From ""Concurrency in Practice"":. > Whenever more than one thread accesses a given state variable, and one of them might write to it, they all must coordinate their access to it using synchronization. I can refactor `NumericMeasurementList` to make it thread-safe.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1444#issuecomment-1941504478:335,safe,safe,335,https://qupath.github.io,https://github.com/qupath/qupath/issues/1444#issuecomment-1941504478,1,['safe'],['safe']
Safety,"So I just had this problem on a project today! I can't post the data, but what I did was roughly what I described above, but with a slight twist. We had a purple cytoplasmic stain along with hematoxylin for the nuclei, and finally a DAB stain that was also nuclear. . I changed the DAB vector to the purple stain (in Analyze>Estimate Stain vectors) and created a hybrid vector between the DAB and hematoxylin for the hematoxylin vector. . I then ran a standard Cell Detection using ; 1. Hematoxylin OD for nuclei ; 2. Exclude DAB checked (DAB now being all of the background purple) and ; 3. a Threshold of .05; and obtained quite good results.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/46#issuecomment-276200635:466,Detect,Detection,466,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-276200635,1,['Detect'],['Detection']
Safety,"So I took a quick run at it, and came up with a few options.; First off, due to your somewhat off-white background, I would definitely use something like:; ```; setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.69602 0.66056 0.28145 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.47625 0.62539 0.61811 "", ""Background"" : "" 224 224 224 ""}');; ```. Next I drew a square that had some DAB and non DAB stained areas and tested the following **with the annotation selected**:; ```; runPlugin('qupath.imagej.detect.tissue.PositivePixelCounterIJ', '{""downsampleFactor"": 1, ""gaussianSigmaMicrons"": 0.5, ""thresholdStain1"": 0.1, ""thresholdStain2"": 0.2, ""addSummaryMeasurements"": true}');; ```. Alternatively you could try superpixels, which I like, but would also require a classification step. For now you can use the Measure->Show measurment maps command to look at what values you could use for a classifier. Again **with the annotation selected**:; ```; runPlugin('qupath.imagej.superpixels.SLICSuperpixelsPlugin', '{""sigmaMicrons"": 1.0, ""spacingMicrons"": 10.0, ""maxIterations"": 10, ""regularization"": 0.25, ""adaptRegularization"": false, ""useDeconvolved"": false}');; selectDetections();; runPlugin('qupath.lib.algorithms.IntensityFeaturesPlugin', '{""pixelSizeMicrons"": 0.25, ""region"": ""ROI"", ""tileSizeMicrons"": 25.0, ""colorOD"": true, ""colorStain1"": true, ""colorStain2"": true, ""colorStain3"": false, ""colorRed"": false, ""colorGreen"": false, ""colorBlue"": false, ""colorHue"": false, ""colorSaturation"": false, ""colorBrightness"": false, ""doMean"": true, ""doStdDev"": true, ""doMinMax"": false, ""doMedian"": false, ""doHaralick"": false, ""haralickDistance"": 1, ""haralickBins"": 32}');; ```. You can also choose a larger size for your SLICs if you want to do more of a tissue structure analysis. Smaller is usually better if you are looking for color differences though. Another options is just using the cell detection mentioned above:; ```; selectAn",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/157#issuecomment-372875465:577,detect,detect,577,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372875465,1,['detect'],['detect']
Safety,"So far I have figured out how to detect cells in my TMA, make classifiers and ""train"" them and get the results outputted nicely from it. ; However I would love to make cell detections withing different regions of my TMA, namely CD3 positive cells which are located in the stroma and those which are located in the tumor region. ; Does anybody have some advice? (@petebankhead great talk in Bern 2 weeks ago btw.); regards; frido",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/52:33,detect,detect,33,https://qupath.github.io,https://github.com/qupath/qupath/issues/52,2,['detect'],"['detect', 'detections']"
Safety,"Some UI and logging fixes, but main thing is simplifying how files and paths can be generated relative to a project - inspired by realizing how awkward it is when writing https://forum.image.sc/t/qupath-style-nuclear-expansion-after-stardist/73084/4. ```groovy; // Build the path but don't make any directories; def path1 = buildFilePath(PROJECT_BASE_DIR, ""something"", ""else"", ""text.txt""). // New method to build the path without needing PROJECT_BASE_DIR specified; def path2 = buildPathInProject(""something"", ""else"", ""text.txt""); println path1 == path2. // Previously then needed to call mkdirs(path)... but to pass the *parent* directory, not the full path with the file name. // Ways to avoid that:. // Build the parent directory path *and* make directories in one line; def pathDirectory = makePathInProject(""something"", ""else""). // Build the File object *and* make any required parent directories; def file = makeFileInProject(""something"", ""else"", ""entirely"", ""text.txt""); file.text = ""This should work""; ```",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1092:690,avoid,avoid,690,https://qupath.github.io,https://github.com/qupath/qupath/pull/1092,1,['avoid'],['avoid']
Safety,"Some assorted responses:. * You say 'QuPath did it again', but it’s not clear if QuPath is actually doing what it is supposed to in deleting objects. I already described that you should not do automated counts in the same region after manual counting. Did you read my explanation above? If it does not describe your situation, please be more specific. https://github.com/qupath/qupath/issues/112#issuecomment-342941759. * QuPath is written in Java, and is therefore limited by the amount of memory assigned to it on first startup, or under *Help &rarr; Show setup options*. Additional memory being available on the computer doesn’t change this; QuPath won't use it. * My best guess remains that the memory problems are related to the handling of CZI images - which is something I will investigate, but I have very little free time currently and it may take a while. It is not a format I have used much myself, and I have very little relevant data that I can use to test it properly. * If you want to investigate this yourself, try doing simple processing steps using images in another file format (e.g. Aperio or Hamamatsu - maybe from http://openslide.cs.cmu.edu/download/openslide-testdata/). If the problem persists then my guess is wrong, and it is not reliant on file format. But then if you describe your exact steps I may be able to reproduce the issue. * If you are optimizing positive classification settings, re-running the cell detection would be a horribly slow way to do it. Running this one-line script and adjusting the values should be *much* faster:; ```groovy; setCellIntensityClassifications('Nucleus: DAB OD mean', 0.2); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/112#issuecomment-344522051:1439,detect,detection,1439,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-344522051,1,['detect'],['detection']
Safety,"Sorry my suggestions haven't been more useful! Also, I do get an empty text file with Name only when I export detection files and there are no detections present. . Is there any chance you could perform a `def detections = getDetections()` and then print out detections.size to make sure that the detections are there to be exported, directly before the export? Just trying to eliminate possibilities. I haven't run into this problem on Windows yet, but would love to know what is causing it in case I do!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/136#issuecomment-357025283:110,detect,detection,110,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357025283,5,['detect'],"['detection', 'detections']"
Safety,"Sounds like a potential memory leak, but I'm not aware of any that would cause this. > I still have 15GB free. Is this available to QuPath, or only to the operating system? You can track QuPath's memory use with *View &rarr; Show memory monitor* (although this won't include anything JavaCPP does... which mostly means things connected with pixel/object classifiers). There are some instructions for making more memory available to QuPath [here](https://qupath.readthedocs.io/en/stable/docs/reference/faqs.html#set-max-memory). If you're comfortable digging deeper, [VisualVM](https://visualvm.github.io) is extremely helpful for tracking memory in any running Java application (and is what I'd use if I could replicate the issue). Apart from that, how are you running positive cell detection - interactively, or from a script? How do you define the regions within which cells are detected?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/828#issuecomment-932368906:783,detect,detection,783,https://qupath.github.io,https://github.com/qupath/qupath/issues/828#issuecomment-932368906,2,['detect'],"['detected', 'detection']"
Safety,"Strange... if you install gradle separately, then you can also use `gradle clean jpackage` (i.e. avoid relying upon gradle wrapper). I'm not sure if that'll help. I have limited experience using Linux, and none using CentOS. I don't know whether JavaFX 18 (used by QuPath now) is compatible with CentOS 7 so even if you overcome the building issue, I don't know if it will run.; * https://github.com/qupath/qupath/issues/825; * https://github.com/qupath/qupath/issues/949",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/950#issuecomment-1096162506:97,avoid,avoid,97,https://qupath.github.io,https://github.com/qupath/qupath/issues/950#issuecomment-1096162506,1,['avoid'],['avoid']
Safety,Subcellular detection - expand to 4 categories?,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/146:12,detect,detection,12,https://qupath.github.io,https://github.com/qupath/qupath/issues/146,1,['detect'],['detection']
Safety,Subcellular detection for all 3 BF channels,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/304:12,detect,detection,12,https://qupath.github.io,https://github.com/qupath/qupath/issues/304,1,['detect'],['detection']
Safety,Subcellular detections don't work for z-stacks or with missing pixel sizes,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/701:12,detect,detections,12,https://qupath.github.io,https://github.com/qupath/qupath/issues/701,1,['detect'],['detections']
Safety,Subcellular spot detection not working in ubuntu ?,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/328:17,detect,detection,17,https://qupath.github.io,https://github.com/qupath/qupath/issues/328,1,['detect'],['detection']
Safety,Superpixel annoations and detections,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/222:26,detect,detections,26,https://qupath.github.io,https://github.com/qupath/qupath/issues/222,1,['detect'],['detections']
Safety,"Support changing classifications for TMA cores via right-click. Previously this only worked for annotations. We could extend this to detections, but for now I don't want to make that *too* easy.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1613:133,detect,detections,133,https://qupath.github.io,https://github.com/qupath/qupath/pull/1613,1,['detect'],['detections']
Safety,Support hematoxylin cell detection where it is not the first stain,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/884:25,detect,detection,25,https://qupath.github.io,https://github.com/qupath/qupath/pull/884,1,['detect'],['detection']
Safety,TMA detection in CZI format fails also in WSI format with only 1 scene,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/48:4,detect,detection,4,https://qupath.github.io,https://github.com/qupath/qupath/issues/48,1,['detect'],['detection']
Safety,"Tests were failing when Gradle was run using Java 17 on Windows, e.g.; ```; org.opentest4j.AssertionFailedError: expected: <µm> but was: <Âµm>; 	at app//org.junit.jupiter.api.AssertionFailureBuilder.build(AssertionFailureBuilder.java:151); 	at app//org.junit.jupiter.api.AssertionFailureBuilder.buildAndThrow(AssertionFailureBuilder.java:132); 	at app//org.junit.jupiter.api.AssertEquals.failNotEqual(AssertEquals.java:197); 	at app//org.junit.jupiter.api.AssertEquals.assertEquals(AssertEquals.java:182); 	at app//org.junit.jupiter.api.AssertEquals.assertEquals(AssertEquals.java:177); 	at app//org.junit.jupiter.api.Assertions.assertEquals(Assertions.java:1145); 	at app//qupath.lib.images.writers.ome.zarr.TestOMEXMLCreator.Check_Pixel_Height_Unit(TestOMEXMLCreator.java:216); 	at java.base@21.0.4/java.lang.reflect.Method.invoke(Method.java:580); 	at java.base@21.0.4/java.util.ArrayList.forEach(ArrayList.java:1596); 	at java.base@21.0.4/java.util.ArrayList.forEach(ArrayList.java:1596); ```. I'm not convinced this is the right way to address it, and it shouldn't matter in practice since QuPath now assumes Java 21 (where UTF-8 is the default), but it helps avoid exceptions for users building with Gradle launched using an earlier Java version - which should be possible.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1643:1165,avoid,avoid,1165,https://qupath.github.io,https://github.com/qupath/qupath/pull/1643,1,['avoid'],['avoid']
Safety,"Thank yo for the reply and your re-repeat :) of what you had already told me. I admit that I am really bad at understanding this part. This is what I think I understand:. The approach we used creates an issue with the way `ImageDisplay` is currently implemented because saving display settings to the .qpdata file is not good practice? ; But doing this via scripting is OK because it's less important if scripts break upon QuPath updates?. The risk is that if these are made public, other people could call upon these methods, and that would break something in the GUI whenever changes will be made to the code?. Currently there is no other way than to use `ImageDisplay` to set these properties for the channels (and save and recall them) which is bad because this will be revised in the future?. Let me know what I got wrong there if you have time. I think that in the meantime I will test a script to do what we used to be able to do, and dive into the wonderful world of Reflection for my sake.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/26#issuecomment-632635935:444,risk,risk,444,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632635935,1,['risk'],['risk']
Safety,"Thank you Pete. Kathy. From: Pete <notifications@github.com>; Reply-To: qupath/qupath <reply@reply.github.com>; Date: Monday, June 8, 2020 at 12:11 PM; To: qupath/qupath <qupath@noreply.github.com>; Cc: ""Kathleen T. Yee"" <KYee@umc.edu>, Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [qupath/qupath] Zoom In and Zoom Out (#518). This looks like a simple bug, albeit one that has existed for some months at least - weirdly without being reported before. Should be fixed in the next minor release, but I first need to check it in more detail. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fissues%2F518%23issuecomment-640758278&data=02%7C01%7Ckyee%40umc.edu%7Cd4b7b44c44274db73a8308d80bcef036%7C78a0681ef0be47e280498616858818a5%7C0%7C1%7C637272330716768343&sdata=I6ByW3NeHWrDm7VTBAvpv2MpkhL6TLrhVIKQdriYgAA%3D&reserved=0>, or unsubscribe<https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAP4MNEYF5JGJNVJRBCHLL3DRVULSZANCNFSM4NYSD4CA&data=02%7C01%7Ckyee%40umc.edu%7Cd4b7b44c44274db73a8308d80bcef036%7C78a0681ef0be47e280498616858818a5%7C0%7C1%7C637272330716773334&sdata=3J8BiWMPaBCV6Q7lr8IOEGiTxaRqEaq2AUvxwH2crGY%3D&reserved=0>. Individuals who have received this information in error or are not authorized to receive it must promptly return or dispose of the information and notify the sender. Those individuals are hereby notified that they are strictly prohibited from reviewing, forwarding, printing, copying, distributing or using this information in any way.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/518#issuecomment-640759146:675,safe,safelinks,675,https://qupath.github.io,https://github.com/qupath/qupath/issues/518#issuecomment-640759146,2,['safe'],['safelinks']
Safety,"Thank you Svidro,. Thank you for your answer. I will try your suggested way. I didnt find your answer in the github chat. I am not familiar with ; github yet - didnt know, it is possible to have a conversation that does ; not appear in the issue. how did u do that?. Best. David. Am 29/01/2017 um 21:04 schrieb Svidro:; >; > My usual method for this type of situation would be to use ; > Analyze>Cell Analysis>Cell detection with ""make measurements"" checked ; > (using Hematoxylin OD since that is giving you the best cell detection).; >; > Then run Classify>Classify By Specific Feature with whatever cutoff ; > you were using in the positive cell detection that gave you good ; > positive/negative separation.; > classify ; > <https://cloud.githubusercontent.com/assets/23145209/22407407/a1b3e02c-e61a-11e6-8ab8-8929d9b98c32.JPG>; >; > It may not be exactly what you wanted, but it is not too many steps ; > and should give similar results, I believe. Note that the Classify By ; > Specific Feature does not show up in the workflow at this time, but I ; > seem to remember it being scriptable manually.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/46#issuecomment-275941788>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEcJu_dREsL0cqgibZHAb2Vy12MWjks5rXPDdgaJpZM4Lw1_o>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; Geschäftsführer:; - David Haumann, Thomas Schenker, Sergey Biniaminov. _________________________________; Diese E-Mail und jeder übermittelte Anhang enthält gesetz",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/46#issuecomment-276000050:415,detect,detection,415,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-276000050,3,['detect'],['detection']
Safety,"Thank you both for answering! @Svidro and @petebankhead ; I started all over again, so I don't have the workflow anymore. Nevertheless, what I meant was that I used indeed the pointing tool. I had two populations, one negative and one positive. After I ran the positive cell detection, the negative population was gone. And unfortunately, there is no undo button. My goal was indeed compare the manual counting and the automated counting. For optimization. I don't know whether the error is the lack of RAM, I checked and i have 3,3GB available. And I only have 4 ROI's in one image. When I run the analysis, I make sure nothing is selected and choose the option 'all annotation'. It might be, but it might be not, because sometimes it also does not analyse only 1 ROI, but other times it does. However, the log it says 'memory error'. the programs that are running on my computer besides Qupaht are google chrome (1tab), one note with an excel file, and file explorer. ![capture](https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG); ![capture2](https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG); ![capture3](https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG). I really don't know why sometimes it works or not, but i'll be more careful in what I'll do.; Unfortunately, there was also no backup file in the folder after the failure of saving.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/112#issuecomment-343227944:275,detect,detection,275,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343227944,1,['detect'],['detection']
Safety,"Thank you for taking your time into understanding our problem and coming up with possible alternative solutions!. I absolutely get your notes on the classifier. I assumed that the ObjectClassifier would _never_ need to read pixels because it currently only uses the detections' measurements. Surely the code must be changed in preparation of the advent of the `FeatureExtractor`. And for this, using `ProjectImageEntry.readHierarchy()` is probably the better option.; > [...] creating a classifier without needing to go through the UI [...]. I am not sure about this, though. You often want to leverage the live-update feature when creating a classifier. That is one of the most handy feature when tweaking a classifier. If that option was removed, it would be unfortunate. -------------------------. However i think you missed a point. The major issue this PR wants to address is the ability to a script in batch as fast as possible (and when it is possible); > an alternative approach [...] that doesn't involve any big API changes - and which can be used when you can know in advance that the image doesn't need to be accessed. Just to be clear, this PR's only API change is adding in [`ProjectImageEntry.java:L195`](https://github.com/qupath/qupath/pull/1488/files#diff-14ed5cabf5566ab4eb5d1ae31a25d75c8dd49e3c50e1cc05ce10ff21936b9a9fR195), where it adds a new public method `readImageData(boolean)` asking whether to read or not the image file. It also provides a default implementation `readImageData()` that always reads it, so that all previous code relied on this assumption don't break.; Furthermore, as you suggested the current approach can be used when _you know in advance_ that the image doesn't need to be accessed:; ![image](https://github.com/qupath/qupath/assets/34198340/3525d599-2609-422b-a5f8-64c1660d505c). Now, I agree this interface may not be the best one as it could easily just be a checkbox option in the ScriptEditor. For now, though, i think it is enough to enjoy the be",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1488#issuecomment-2022463076:266,detect,detections,266,https://qupath.github.io,https://github.com/qupath/qupath/pull/1488#issuecomment-2022463076,1,['detect'],['detections']
Safety,"Thank you for the feedback. Unfortunately it cannot be consistently reproduced. True, I am messing with the stain vectors, working with 2-plex brightfield IHC. Knowing it is just a matter of visualization and brightness/contrast and that does not affect analysis sounds safe to close this issue. Best wishes,; Carlos",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/464#issuecomment-622329244:270,safe,safe,270,https://qupath.github.io,https://github.com/qupath/qupath/issues/464#issuecomment-622329244,1,['safe'],['safe']
Safety,"Thank you for your reference, but I have some problems when I run it.; ----------------------------------------------------------------------; import qupath.lib.gui.ImageWriterTools; import qupath.lib.gui.QuPathGUI; import qupath.lib.gui.viewer.OverlayOptions; import qupath.lib.regions.RegionRequest; import qupath.lib.scripting.QPEx. // Aim for an output resolution of approx 20 µm/pixel; double requestedPixelSize = 20. // Create the output directory, if required; def path = QPEx.buildFilePath(QPEx.PROJECT_BASE_DIR, ""export""); QPEx.mkdirs(path). // Get the imageData & server; def imageData = QPEx.getCurrentImageData(); def server = imageData.getServer(); setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; runPlugin('qupath.imagej.detect.tissue.SimpleTissueDetection2', '{""threshold"": 162, ""requestedDownsample"": 1.0, ""minAreaPixels"": 100000.0, ""maxHoleAreaPixels"": 500.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}');. // Get the file name from the current server; def name = server.getShortServerName(). // We need to get the display settings (colors, line thicknesses, opacity etc.) from the current viewer, if available; def overlayOptions = QuPathGUI.getInstance() == null ? new OverlayOptions() : QuPathGUI.getInstance().getViewer().getOverlayOptions(). // Calculate downsample factor depending on the requested pixel size; double downsample = requestedPixelSize / server.getAveragedPixelSizeMicrons(); def request = RegionRequest.createInstance(imageData.getServerPath(), downsample, 0, 0, server.getWidth(), server.getHeight()). // Write output image, with and without overlay; def dir = new File(path); def fileImage = new File(dir, name + "".jpg""",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/216#issuecomment-420287639:943,detect,detect,943,https://qupath.github.io,https://github.com/qupath/qupath/issues/216#issuecomment-420287639,1,['detect'],['detect']
Safety,"Thank you very much for your help, but I have a new problem. How can I save the results to my local disk? ; ------------------------------------------script---------------------------------------; import static qupath.lib.scripting.QP.*; setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; runPlugin('qupath.imagej.detect.tissue.SimpleTissueDetection2', '{""threshold"": 162, ""requestedDownsample"": 1.0, ""minAreaPixels"": 100000.0, ""maxHoleAreaPixels"": 500.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}');; ---------------------------------------------error---------------------------------------; 04:25:18.186 [main] [INFO ] QuPath - Launching QuPath with args: /oamp/bio/QuPath/0.1.2/command/9624CE91-1DA8-40AE-89AC-41412BE756DB.jpg, -script, 2.groovy; Script result: false; ------------------------------------------------------------------------------------------; thanks!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/213#issuecomment-419363485:519,detect,detect,519,https://qupath.github.io,https://github.com/qupath/qupath/issues/213#issuecomment-419363485,1,['detect'],['detect']
Safety,"Thank you very much, Svidro, DHaumannHSA and petebankhead for your quick and helpful answers! Very much appreciated! I did not know tissue detection did not use colors! Very interesting! ; By ""manual"" I was referring to the section on TMA CD3 analysis. I followed all these steps precisely (including estimation of stain vectors). The setting is also on Brightfield. The values given for the background/whitespace at the bottom of the Image tab on the left are around 223,215,213 in my case. By playing around with these numbers in my settings I eventually managed to get better results that are ok to work with. Thank you very much everybody once again.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/53#issuecomment-282548616:139,detect,detection,139,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282548616,1,['detect'],['detection']
Safety,"Thank you, this was pretty fast!. Accordingly to my testing it works all okay and pretty safe. I think the idea to write as soon as something is being modified is worth it. The fact that now it requires that the images are opened & modified at least once is not a problem. I think we can put up with it for the time being and leave it for some future adjustment, if needed. However i think you got something off: it should be possible to write the imagedata if the server was never loaded. The problem is not that the image name is always written to the ImageData's file, as that does not make the metadata different from the old ones when the name was kept as is.; The issue is that, when writing the `.qpdata`, it wants to know the ImageServer unique identifier and summary. Both of these cannot have changed without the server being loaded first (the unique identifier possibly yes if it uses the filepath, but in that case moving the image folder after the ImageData was saved would have the same result).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1489#issuecomment-2276459548:89,safe,safe,89,https://qupath.github.io,https://github.com/qupath/qupath/pull/1489#issuecomment-2276459548,1,['safe'],['safe']
Safety,"Thank you. Alan. From: Pete <notifications@github.com>; Sent: Tuesday, April 28, 2020 12:38 AM; To: qupath/qupath <qupath@noreply.github.com>; Cc: Alan Jerusalmi <ajerusalmi@bioaihealth.com>; Mention <mention@noreply.github.com>; Subject: Re: [qupath/qupath] Issue staring QuPath 0.2.0 m9 or m10 (#458). @ajerusalmi<https://github.com/ajerusalmi> the error is caused by the old Weka extension being installed. This is compatible with v0.1.2, but not v0.2.0. Two things you can do:. * delete the Weka extension; to find its location, go to Edit → Preferences and check the 'QuPath user directory'; * use Edit → Reset preferences to reset the location of the user directory in QuPath, so the extension will not be found. I will close this issue since it is not a bug, however a change has been made for v0.2.0-m11 to enable QuPath to recover better in cases like this, see #454<https://github.com/qupath/qupath/issues/454>. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/458#issuecomment-620375806>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AO6FMERJ4NRH6754WL7Q6ELROZMSBANCNFSM4MSNUQHQ>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/458#issuecomment-620601601:832,recover,recover,832,https://qupath.github.io,https://github.com/qupath/qupath/issues/458#issuecomment-620601601,1,['recover'],['recover']
Safety,"Thank you. Of course I could not get these dimensions directly from the mirax file either (easily), but since the tiff file was generated 'as-is' from mirax, and since I know how these glass slides look like physically, the 'padded' version is 1:1 to the glass, so naturally what QuPath shows me is not something I consider the whole slide, thus cropped. I did consider these workarounds, but most of them include some effort from the pathologist's side - probably a no go. Re-generating the whole database of 5+years of data is something I would like to avoid. Thanks for the exhaustive list and your effort.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1278#issuecomment-1631311540:555,avoid,avoid,555,https://qupath.github.io,https://github.com/qupath/qupath/issues/1278#issuecomment-1631311540,1,['avoid'],['avoid']
Safety,"Thanks @MakarowMax, I haven't seen this error before but I am able to replicate it when I chance to the *Logistic Regression* classifier. I can change to *Artificial Neural Network* without problems. Is this also true for you?. It's curious because I am fairly sure I have used *Logistic Regression* without errors in the past; I'm not sure if it depends upon operating system or if any recent updates might be causing the trouble. In any case, the error occurs deep within OpenCV - and unfortunately there is no possibility to capture the exception within QuPath before the Java Virtual Machine shuts down. In the past, the only solution I could find to OpenCV errors like this has been to avoid calling the crashing code. In this case, that would mean removing the *Logistic Regression* option. I haven't found it to be terribly useful (even when it worked) so I don't think this would be a big loss; I personally prefer *Artificial Neural Network* (and sometimes *Random Trees*). *K Nearest Neighbor* really only makes sense when training using point annotations (when given a large number of samples it is too slow). What do you think? Does it happen to you with other classifier types as well?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/394#issuecomment-579836335:691,avoid,avoid,691,https://qupath.github.io,https://github.com/qupath/qupath/issues/394#issuecomment-579836335,1,['avoid'],['avoid']
Safety,"Thanks @MichaelSNelson! The main idea here is to support adding text but without really specifying what that has to be... so someone could use it in the way you describe for clustering, but could use it for something else entirely. The use cases I'm thinking of here are really; * teaching, where an object annotation could be some useful explanatory text; * recording thoughts... where an object (or full image) annotation could be some comment on the image or analysis, e.g. *'excluded because of quality issues'*, or *'annotated by Pete on a rainy Tuesday'* etc. But it could also be a link to a website, a GitHub repository, or even even the text for a script used for the processing. For these, it needs to display nicely - hence the html support. > Extra intention: make it possible to export a summary markdown report, including image thumbnails. This could be used to give a portable, readable summary of an entire project in html. That could be handy, e.g. when asking a pathologist to QC a lot of annotations. For analysis-oriented things like the clustering application, it's already technically possible to use; ```groovy; getSelectedObject().storeMetadataValue('My key', 'My value'); fireHierarchyUpdate(); ```; currently, but only because of Groovy's laxity (the methods are `protected`) - and it won't show up in any results tables. It will also have all the detections-suddenly-use-a-whole-lot-more-memory issue, so *really* isn't to be encouraged at the moment. Nevertheless, exposing access to the arbitrary metadata map an official part of the API could be another new feature.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1005#issuecomment-1180644703:1374,detect,detections-suddenly-use-a-whole-lot-more-memory,1374,https://qupath.github.io,https://github.com/qupath/qupath/issues/1005#issuecomment-1180644703,1,['detect'],['detections-suddenly-use-a-whole-lot-more-memory']
Safety,"Thanks @NicoKiaru that sounds pretty similar to what I've tried to do here. As far as I can see, my implementation is working ok so I'll stick with it for now. One minor difference is that my version restricts creating new readers to a single background thread, since I found that sometimes (although rarely) constructing many reader simultaneously had really bad performance, as all the constructors got stuck parsing XML. By ensuring readers are created sequentially, I avoid blocking for too long when tile reading is substantially faster than reader initializing: if a thread wants a reader, it puts in its request. If there's a reader available, it gets that immediately. If not (and the max reader limit isn't reached) a background thread goes off to create a new reader. The original thread will then wait for the next available reader - which *might* be the one initialized because of its request, but it might also be one that has since become available. Waiting time is minimized in any case. I also added some `Cleaner` support from Java 9 to handle the fact that it's easy to miss closing an `ImageServer` properly. PS. Since the recycling is really important, should you do it in a `finally` block?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/867#issuecomment-1002502877:472,avoid,avoid,472,https://qupath.github.io,https://github.com/qupath/qupath/pull/867#issuecomment-1002502877,1,['avoid'],['avoid']
Safety,"Thanks @Rylern and @alanocallaghan - good call making me right the tests, that helped identify and fix some bugs, and address some suboptimal behavior concerning rounding and out-of-range values. > Is there a reason for defining the BufferedImageNormalizer interface, instead of just using [Function<BufferedImage, BufferedImage>](https://docs.oracle.com/javase/8/docs/api/java/util/function/Function.html) or [UnaryOperator<BufferedImage>](https://docs.oracle.com/javase/8/docs/api/java/util/function/UnaryOperator.html)?. I've updated this to use [`BufferedImageOp`](https://docs.oracle.com/en/java/javase/21/docs/api/java.desktop/java/awt/image/BufferedImageOp.html), which then; 1. allows the classes to be used directly with [`Graphics2D.drawImage`](https://docs.oracle.com/en/java/javase/21/docs/api/java.desktop/java/awt/Graphics2D.html#drawImage(java.awt.image.BufferedImage,java.awt.image.BufferedImageOp,int,int)).; 2. makes it possible to control whether in-place image conversion is used. Potentially one of the other standard Java interfaces could be used, but I want to avoid giving the impression that it's a good idea to use arbitrary methods or lambda expressions. These can be convenient for testing, but will fail when images are added to a project - because we need the methods to be JSON-serializable. The JSON serialization is taken care of through the `ImageServers` class, and we have to explicitly register every normalization class so that it can be used within a project.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1554#issuecomment-2209250698:1084,avoid,avoid,1084,https://qupath.github.io,https://github.com/qupath/qupath/pull/1554#issuecomment-2209250698,1,['avoid'],['avoid']
Safety,"Thanks @Rylern this looks good & brings up a couple of minor questions for you, @alanocallaghan and @finglis; * How 'deep' should we search for extensions (i.e. how many sub-directories)?; * Should there be any way to override the depth?. Currently in this PR I think it will search 4 subdirectories deep, and there is no option to override this because the field is `final`. If it *wasn't* `final` then the following script should work:; ```groovy; // Prints, even though it's private; println qupath.lib.gui.ExtensionClassLoader.MAX_EXTENSION_JARS_DEPTH. // Try to set; qupath.lib.gui.ExtensionClassLoader.MAX_EXTENSION_JARS_DEPTH = 5. // Print again; println qupath.lib.gui.ExtensionClassLoader.MAX_EXTENSION_JARS_DEPTH; ```; and that would allow the user to sneakily adjust the depth in a startup script. I've sometimes found such sneaky scripts to be useful - mostly when a user wants to do something I hadn't thought to make in the public API - but I'm not sure if we want to permit or block it. Either way, the script only works because of Groovy's relaxed attitude to private variables - so it's risky for the user to do such things. If no one has strong opinions, I can just merge the PR as it currently is. But it's worth knowing that the choice of `final`/`non-final` has this implication, since Groovy is our scripting language.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1461#issuecomment-1934393163:1104,risk,risky,1104,https://qupath.github.io,https://github.com/qupath/qupath/pull/1461#issuecomment-1934393163,1,['risk'],['risky']
Safety,"Thanks @Svidro ; @bjtho08 note that v0.2.0-m2 uses a different location for user preferences to avoid conflicting with v0.1.3. Have you checked that the relevant preferences are the same, e.g. those under _tools &rarr; Multi-touch gestures_?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/188#issuecomment-479519382:96,avoid,avoid,96,https://qupath.github.io,https://github.com/qupath/qupath/issues/188#issuecomment-479519382,1,['avoid'],['avoid']
Safety,"Thanks @ajay1685 the PR above should address most of this, and a couple of other bugs I spotted (like measurements not updating if cores were moved on the image). Please let me know if you notice any significant problems with this. Because the TMA data viewer is unmaintained, I think there is an above-average risk of unreported/unnoticed bugs so I've added a warning now as well. You can double-click on it to make it go away. <img width=""1006"" alt=""TMA data viewer"" src=""https://user-images.githubusercontent.com/4690904/197327977-4298edd4-13f3-41d3-b99c-6f95be821ff9.png"">. In the longer term, I think it should be removed or rewritten. Rewritten would be preferable, but it's really a matter of capacity... as the software gets bigger, there are so many different parts to maintain and I haven't worked with TMAs myself in years.; (In that regard, new QuPath jobs to be advertised next week - please share them widely!). Regarding performance, I couldn't replicate any sluggishness - it was very smooth for me, but then I was only using 'toy' datasets based on generating a grid on a regular whole slide image. If you can provide more info to replicate the sluggishness then I could have a quick look into that, but for now I hope the main issues are fixed.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1083#issuecomment-1287672102:311,risk,risk,311,https://qupath.github.io,https://github.com/qupath/qupath/issues/1083#issuecomment-1287672102,1,['risk'],['risk']
Safety,"Thanks @tp81! It might take me a bit of time to look at this in detail, because I've switched focus temporarily to finish some papers. First thoughts: I've also had the issue of having to click on the viewer to activate it for backspace to work, I agree it would be best to avoid this. Minor concerns are; * it introduces public methods, and I'd rather reduce this as much as possible; * if it basically duplicates some code elsewhere, perhaps some refactoring elsewhere could promote reuse. There is also a bit of JavaFX/macOS weirdness when it comes to single-key accelerators (i.e. not requiring Cmd+Something to run a menu item). I'm not sure if it's relevant here but anything accelerator-related takes some extra cross-platform testing. I've assigned it to a v0.4.0 milestone to remind us to try to get this functionality in that release (tentatively planned for early next year).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/830#issuecomment-957188687:274,avoid,avoid,274,https://qupath.github.io,https://github.com/qupath/qupath/pull/830#issuecomment-957188687,1,['avoid'],['avoid']
Safety,"Thanks @zindy I'll try to have a look later. First thought is that I'd rather *not* have the second commit, unless you have a clear need for a public `getPreviouslySelectedTool()` method?. In general, I'd rather shrink the API and make it more stable, and avoid adding public methods just-in-case. But it could be added if it is really needed somewhere.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1037#issuecomment-1219437840:256,avoid,avoid,256,https://qupath.github.io,https://github.com/qupath/qupath/pull/1037#issuecomment-1219437840,1,['avoid'],['avoid']
Safety,"Thanks Benjamin, and I'm glad the macro functionality is useful!. I thought I knew the reason for the issues you are seeing, but upon quickly looking at the code I realise that I do not. There is an enigmatic statement [here](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L368) that color transforms are ```// Not supported in batch mode, so disable option to avoid confusion``` although I don't recall why... There's also a [hard-coded limit](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java#L229) whereby the macro runner rejects an image with more than 5000x5000 pixels... although the wisdom of this specific limit may also be questionable. I'll look into it, but at the minute it looks like both issues represent 'intended behavior, albeit not desired behavior (by the developer or anyone else)'. Not sure what the right word for that is. In the meantime, depending upon how happy you are with Groovy/Java/the ImageJ API, it would be possible to create a Groovy script to run in QuPath that grabs regions from the image, converts them into ```ImagePlus``` objects for ImageJ, performs whatever processing is required using ImageJ (or even OpenCV or other dependencies if you prefer), and optionally sends back results as the ```PathObjects``` that QuPath requires. There is considerably more effort involved in setting this up for the first time and learning the main methods required (IntelliJ is more or less essential to get auto-complete and link up to the source code), but has the reward of giving you far more ability to customize the analysis and how the results are returned. I have used this approach a lot. If you would like to try this out, the code within [```ImageJMacroRunner.java```](https://github.com/qupath/qupath/blob/master/qupath-extension-ij/src/main/java/qupath/imagej/plugins/ImageJMacroRunner.java) may help to get st",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/68#issuecomment-297931966:438,avoid,avoid,438,https://qupath.github.io,https://github.com/qupath/qupath/issues/68#issuecomment-297931966,1,['avoid'],['avoid']
Safety,"Thanks Svidro and ClnSchlssr - yes, it is mostly 'expected behavior'. You can also work around it slightly by drawing a polygon inside your annotation, and then switch to the brush tool to edit it (using the shortcuts 'p' and 'b' to switch tools). The polygon is able to create the new annotation, and when clicking inside the new polygon with the brush tool then it should be selected (rather than the original annotation). But I think locking annotations is the best solution, since this also prevents you from accidentally moving the annotation within which the tiles were created. Some commands (e.g. cell detection) automatically lock the annotations that they are run inside, but 'Create tiles' doesn't. It probably should. As Svidro mentions, the need for annotations to be completely inside other annotations to 'capture' further objects is really important... there is some explanation for it at https://github.com/qupath/qupath/wiki/Object-hierarchies",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/50#issuecomment-280862813:610,detect,detection,610,https://qupath.github.io,https://github.com/qupath/qupath/issues/50#issuecomment-280862813,1,['detect'],['detection']
Safety,"Thanks a lot for your answer. So running the following code when opening a new image is relatively painless:; `// Get access to the display info for each channel; def viewer = getCurrentViewer(); def channels = viewer.getImageDisplay().getAvailableChannels(). // Set the range for the 4 channelsf; channels[0].setMinDisplay(0); channels[0].setMaxDisplay(255); channels[1].setMinDisplay(0); channels[1].setMaxDisplay(255); channels[2].setMinDisplay(0); channels[2].setMaxDisplay(255); channels[3].setMinDisplay(0); channels[3].setMaxDisplay(255). // Set the LUT color for the first channel & repaint; channels[0].setLUTColor(0, 0, 255); channels[1].setLUTColor(255, 255, 255); channels[2].setLUTColor(0, 255, 0); channels[3].setLUTColor(255, 0, 0). // Ensure the updates are visible; viewer.repaintEntireImage(). // Usually a good idea to print something, so we know it finished; print 'Done!'`. Regarding the pink staining actually it doesn't look like it's the label. It might just be a very low resolution scan, probably brightfield used by the scanner to detect the coverslip and slide.; Do you think it would need a Bio-Formats update for QuPath to access the label image? Or is this something that could be implemented directly in QuPath? The label must be somewhere in the `.scn` as I can see it if I open the image in imageJ, or other softwares (Definiens, Halo, ImageScope...).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/191#issuecomment-409927029:1058,detect,detect,1058,https://qupath.github.io,https://github.com/qupath/qupath/issues/191#issuecomment-409927029,1,['detect'],['detect']
Safety,"Thanks again, Pete!. I've tried it now and it updates both um/pixel and magnification, but I can't get it to work with the further script - probably because I'm doing some beginner mistake in the script setup - my programming ""knowledge"" is limited to cut and paste:). I run this and get the following error log (see below):. // Set the magnification & pixel size (be cautious!!!); def metadata = getCurrentImageData().getServer().getOriginalMetadata(); metadata.magnification = 40; metadata.pixelWidthMicrons = 0.25; metadata.pixelHeightMicrons = 0.25. setImageType('BRIGHTFIELD_H_DAB');; Thread.sleep(100); setColorDeconvolutionStains('{""Name"" : ""H-DAB TMA40x"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.82788 0.53885 0.15571 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.15891 0.36799 0.91615 "", ""Background"" : "" 210 208 209 ""}');; Thread.sleep(100); runPlugin('qupath.imagej.detect.tissue.SimpleTissueDetection2', '{""threshold"": 224, ""requestedPixelSizeMicrons"": 20.0, ""minAreaMicrons"": 100000.0, ""maxHoleAreaMicrons"": 1000000.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": true, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}');; Thread.sleep(100); selectAnnotations();; Thread.sleep(100); runPlugin('qupath.imagej.detect.nuclei.WatershedCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 14.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.09, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}');; Thread.sleep(100). Error log:. INFO: Starting script at Thu Sep 27 09:20:09 CEST 2018; ERROR: QuPath exception; at com.sun.glass.ui.Application.checkEventThread(Application.java:443); at com.sun.glass.ui.View.getNativeView(View.java:449); at com.sun.glass.ui.win.WinAccessible.g",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:872,detect,detect,872,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['detect'],['detect']
Safety,"Thanks everyone for the feedback - I'll merge this for now to avoid making too much of a mess while merging other PRs, but might return to it later.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1072#issuecomment-1279727287:62,avoid,avoid,62,https://qupath.github.io,https://github.com/qupath/qupath/pull/1072#issuecomment-1279727287,1,['avoid'],['avoid']
Safety,"Thanks for considering the request. I think it would still be nice to be able to re-name within the hierarchy view. The pattern could be homologous to as in the ""Annotations"" view where under the ""Hierarchy"" view (right-click --> set-properties), so that users can predict and expect the behavior that they have already learned in the ""Annotations"" view ~ just as you suggested above.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/42#issuecomment-481330513:265,predict,predict,265,https://qupath.github.io,https://github.com/qupath/qupath/issues/42#issuecomment-481330513,1,['predict'],['predict']
Safety,"Thanks for doing this! I've looked through the proposed changes, thoughts are below:. * For `getAllObjects()`, I suggest replacing; ```java; return objList.parallelStream().filter(e -> e.getClass() != PathRootObject.class).toArray(PathObject[]::new);; ```; with; ```java; return objList.parallelStream().filter(e -> e != hierarchy.getRootObject()).toArray(PathObject[]::new);; ```; because *conceivably* the root object might one day be subclassed or someone may have smuggled a `PathRootObject` wrongly into the hierarchy. (One could also use `e.isRootObject()`, which would handle the case of multiple root objects differently - the main thing is to avoid relying on class equality). * `selectAllObjects()` appears in both `QP` and `Commands` - can these be harmonized to avoid repetition?. * Specify in the javadoc for `selectAllObjects` that the root object is excluded. * We should avoid `OperationNotSupportedException` (doesn't seem intended for this use). * I'm not sure `PathObjectTransform` needs a new class; it could be added to `QP`. At least, it is currently confusing that `transformObject(s)` exists both in `PathObjectTransform` and in `PathObjectTools` (even though I understand the rationale in keeping `PathObjectTools` distinct, since the new method works on a hierarchy). Relatedly:; * `transformObjects` should take a `PathObjectHierarchy` if it doesn't require an `ImageData`; * I think 2 variations should exist that accept an `AffineTransform` or an `AffineTransformation` - since a list of `Number` is harder for a user (even if helpful for scripting). Although then I wonder... would a builder become a better way to handle it?. * An important use case is when we may want to transform *all* the objects in a hierarchy *and maintain the hierarchical relationships*. I think this requires a separate code path that recursively transforms all child objects, assigning them to the appropriately-transformed new parent object.; * A similar use case would be wanting to transfor",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/666#issuecomment-787868344:652,avoid,avoid,652,https://qupath.github.io,https://github.com/qupath/qupath/pull/666#issuecomment-787868344,3,['avoid'],['avoid']
Safety,"Thanks for logging this after our chat about it, I agree QuPath should provide this option somewhere. I thought the LUT method was cleverer (and more effort to get working...), and it avoids some of the 'my image is all black' bug reports that otherwise ensue when exporting grayscale images that all have low pixel values and previewing them in the operating system's default viewer. But Iit is indeed a bit annoying that it requires setting the `mode` to `L` when using PIL - and also requires getting that option somehow passed through to PIL if using some library on top of it (like `imageio`). I'll try to get an optional alternative for the next QuPath release that can just output grayscale labelled images instead.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/993#issuecomment-1159781538:184,avoid,avoids,184,https://qupath.github.io,https://github.com/qupath/qupath/issues/993#issuecomment-1159781538,1,['avoid'],['avoids']
Safety,"Thanks for sharing this excellent program!! Is there a way to expand the subcellular detection categories to 4? Perhaps 1-3, 4-9, 10-15 and >15 spots per cell to correspond with the RNAscope scoring system? Thanks! Jim",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/146:85,detect,detection,85,https://qupath.github.io,https://github.com/qupath/qupath/issues/146,1,['detect'],['detection']
Safety,"Thanks for the answer! I already tried this but I only could differ in; tumor cells between positive and negative. Is it possible to differ also; between positive and negative cells in the other classes I created in the; same step?. Le 12 avr. 2017 5:36 AM, ""Svidro"" <notifications@github.com> a écrit :. > Positive cell detection only works on the first go. Other ways to do it; > involve using the Classify by specific feature option under the Classify; > menu and choosing your cutoff there, while choosing the cutoff for your; > specific measurement for the given cell type (IE choose tumor as the input,; > and then positive tumor or negative tumor as the output). You may have to; > create the extra classes. The other way involves a one line script that; > classifies as positive or negative by the value you input.; >; > setCellIntensityClassifications(""Cytoplasm: DAB OD mean"", 0.15); >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/64#issuecomment-293464289>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AaDxoxUmBjQg_4-trBFaetrGH61sBP2-ks5rvEapgaJpZM4M641S>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/64#issuecomment-293474681:321,detect,detection,321,https://qupath.github.io,https://github.com/qupath/qupath/issues/64#issuecomment-293474681,1,['detect'],['detection']
Safety,"Thanks for the beta suggestion, I will check it out! . I attached an example of the data - it does not seem too different from some of the examples online. . ![image](https://user-images.githubusercontent.com/1241691/40502889-50725814-5f5a-11e8-9ffb-3f662387fa64.png). Curious, do you offer or plan to offer a supervised learning-based object detection tool, sort of like Ilastik? I develop a 3D image segmentation tool ITK-SNAP (for MRIs, CTs) and we have been successful with using random forests for segmentation. User paints some examples and the software extrapolates to the rest of the image. Unlike Ilastik we don't have the user generate engineered features, but just train using neighboring intensity values and let the random forest figure out which features are important and which aren't. The random forest code (C++) is fairly self-contained in case it is of any interest:. https://sourceforge.net/p/c3d/git/ci/master/tree/itkextras/RandomForest/. Thanks again,; Paul",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/67#issuecomment-391804783:343,detect,detection,343,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-391804783,1,['detect'],['detection']
Safety,"Thanks for the clear description & example - could you have a look at the pull request to see if that resolves the problem? If you're able to test it with all your thousands of ROIs that would be great, in case any new badness has been introduced. My hope is that this will only be important for updating 'old' ROIs, since anything new created in v0.2.0 from now on will use JTS from an earlier stage and avoid the Shape &rarr; Geometry pain. (Side note is interesting, I'll check it out!)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/434#issuecomment-610230010:405,avoid,avoid,405,https://qupath.github.io,https://github.com/qupath/qupath/issues/434#issuecomment-610230010,1,['avoid'],['avoid']
Safety,"Thanks for the quick reply. I just want to run the simple tissue detection plugin and then save the result. `runPlugin('qupath.imagej.detect.tissue.SimpleTissueDetection2', '{""threshold"": 0, ""requestedDownsample"": 5.0, ""minAreaPixels"": 100000.0, ""maxHoleAreaPixels"": 5000.0, ""darkBackground"": true, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}');`. This is the automated script for my operation.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/200#issuecomment-411335497:65,detect,detection,65,https://qupath.github.io,https://github.com/qupath/qupath/issues/200#issuecomment-411335497,2,['detect'],"['detect', 'detection']"
Safety,"Thanks for the quick response. Converting to composite works. Is it an option to let QuPath do this automatically when the image type is set to Fluorescence? And for the standard ""Cell Detection"" the RGB Data was not a problem.; I overlooked the .cellConstrainScale(1.5) option.; You are right about the data not being the RAW data. This RAW data was lost by the researcher.; Thanks for the great program. We like QuPath a lot!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/686#issuecomment-804230107:185,Detect,Detection,185,https://qupath.github.io,https://github.com/qupath/qupath/issues/686#issuecomment-804230107,1,['Detect'],['Detection']
Safety,"Thanks for the the snapshot, it looks like this issue: https://github.com/qupath/qupath/issues/80. If so, then the detection is bad but the actual counts of what is detected should be correct. I'm afraid this is an inherent limitation of the background estimation used by QuPath's cell detection. I describe the reason in some more detail and make suggestions at https://github.com/qupath/qupath/issues/80#issuecomment-305385370",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/318#issuecomment-494726466:115,detect,detection,115,https://qupath.github.io,https://github.com/qupath/qupath/issues/318#issuecomment-494726466,3,['detect'],"['detected', 'detection']"
Safety,"Thanks for your answer. . For segmentation I use **DoG superpixel creator** which gives nice results on detecting individual nuclei. . Afterwards I try to use the one line macro as proposed in #85 : ; `saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle())`; to save the detected nuclei as separate image file. One exampel is shown in the follwoing screenshot (2 nuclei of interest):. ![01](https://user-images.githubusercontent.com/20478730/33028565-92f4738c-ce16-11e7-8fe5-88f1325027d2.PNG). However, the macro does only save annotations and segmented nculei are not classified as annotations (as objects/detections). . Is there a way to transfer the type/class of segmented nuclei to annotation type/class? This would make the macro work (I guess).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/118#issuecomment-345747414:104,detect,detecting,104,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-345747414,3,['detect'],"['detected', 'detecting', 'detections']"
Safety,"Thanks for your answer.; I tried to follow your tips, but I am a bit lost with the different steps and how to perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/56#issuecomment-286702227:127,Detect,Detect,127,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227,3,"['Detect', 'detect']","['Detect', 'Detection', 'detection']"
Safety,"Thanks for your answers and trying to open them. I think I have always used bioformats to open .scn images. Regarding the different ROIs, I have to say that previously, I have managed to open .scn images with different ROIs. In QuPath, they would open as different images in the image list tab, which is fine to work with. But the bug.scn file is not >300 ROIs, it is meant to be a normal slide scan, and for some reason it seems to detect each tile as an individual ROI. It is frustrating to see that it opens fine in ImageScope, but not in QuPath... if this is a bioformat issue perhaps I should post on the bioformat page then... ps: I appreciate that mrx and scn files are annoying to work with, but there are unfortunately very common file types in the research/academic world at least...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/300#issuecomment-483588755:433,detect,detect,433,https://qupath.github.io,https://github.com/qupath/qupath/issues/300#issuecomment-483588755,1,['detect'],['detect']
Safety,Thanks for your reply Pete. . I have classified the cells before creating a detection classifier. Still its void classifier after wards.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/63#issuecomment-531642422:76,detect,detection,76,https://qupath.github.io,https://github.com/qupath/qupath/issues/63#issuecomment-531642422,1,['detect'],['detection']
Safety,"Thanks to @crobbins327 for pointing out the problem and solution. Slightly modified from proposed code at https://github.com/qupath/qupath/pull/1039. Testing is somewhat convoluted. I originally (wrongly thought) that the *Create tiles* command used this method, but it doesn't. However it's used internally for plugin commands (like cell detection) - so is potentially quite important. Testing is difficult, but a script like this can help:; ```groovy; def annotation = getSelectedObject(); int s = 64; def size = qupath.lib.geom.ImmutableDimension.getInstance(s, s); def rois = RoiTools.computeTiledROIs(annotation.getROI(), size, size, true, 0); def newAnnotations = rois.collect {r -> PathObjects.createAnnotationObject(r)}; annotation.clearPathObjects(); annotation.addPathObjects(newAnnotations); fireHierarchyUpdate(); ```. Using a rather convoluted example, and reducing the `geometry.getNumPoints() > 1000` threshold in `RoiTools` to trigger the code, tiles were previously missing:. ![wrong](https://user-images.githubusercontent.com/4690904/185470614-92ab1d77-e1d4-47da-b53a-af569900469b.png). With the adapted code they are included:. ![right](https://user-images.githubusercontent.com/4690904/185470631-3f9a4c95-cb18-49b0-ae3b-f0250cc03cfd.png). The problem hadn't surfaced before, probably because (as @crobbins327 pointed out) the wrong key was used with the map, and so the 'optimization' of handling row/column geometries didn't do anything. With that in mind, if this turns out to cause problems then the whole method could just be simplified and the unnecessary attempt at optimization from https://github.com/qupath/qupath/commit/a3366633851740e0d675b118b48133ce61211101 removed. @crobbins327 could you check if the fix looks ok to you as well?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1043:339,detect,detection,339,https://qupath.github.io,https://github.com/qupath/qupath/pull/1043,1,['detect'],['detection']
Safety,"Thanks! Changing this solved it. I'm now trying to quantify the number of dots as a ratio of nuclear:cytoplasmic location. I'm using the script at the bottom of this page:. https://github.com/qupath/qupath/wiki/Spot-detection. This tells me the location of the spot when it is selected. However, I want to know the number of nuclear vs cytoplasmic dots when the cell is selected. I guess the nearest measure of this (using the above script) is just the Nuclear DAB OD mean vs Cytoplasmic DAB mean, but I'd like to know the actual number of dots as a nuclear:cytoplasmic ratio if possible?. Apologies if this is a simple question!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/119#issuecomment-346583086:216,detect,detection,216,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-346583086,1,['detect'],['detection']
Safety,Thanks! this indeed solve the issue. I guess it would be nice to have an option to force QuPath to draw the grid even if the cores are not detected in a similar manner to what the script does.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/53#issuecomment-476218275:139,detect,detected,139,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-476218275,1,['detect'],['detected']
Safety,"Thanks, I made a small change to reinstate the imports that had been converted to starred imports* & fixed a few of my old formatting/doc issues. I can't replicate the bug on my Mac - if I drag a URL from chrome, the dragboard contains both a URL and a String - but good if it solves the problem somewhere. *-I've consistently avoided them & convinced my IntelliJ to stop doing it automatically - can discuss later if we want to change that policy.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1338#issuecomment-1730992725:327,avoid,avoided,327,https://qupath.github.io,https://github.com/qupath/qupath/pull/1338#issuecomment-1730992725,1,['avoid'],['avoided']
Safety,"Thanks, I understand better now that the bug is connected to deserializing. I see that your JSON uses an 'old' (pre-v0.4) syntax:; ```json; { ""name"": ""Example"", ""parentClass"": {""name"": ""Parent""}, ""colorRGB"": 0}; ```; If I run the following in v0.4.3; ```groovy; def pc = getDerivedPathClass(getPathClass(""First""), ""Second""); println GsonTools.getInstance(true).toJson(pc); ```; I see; ```json; {; ""names"": [; ""First"",; ""Second""; ],; ""color"": [117, 210, 222]; }; ```; which was changed in v0.4 for better readability and easier support in other languages. Also, for deserializing you should use `gson = GsonTools.getInstance()` rather than `new Gson()`, because QuPath installs its own `TypeAdapters` to handle custom classes, including `PathClass`. So I implemented these changes in your script, randomizing the class names to avoid being thwarted by caching:; ```groovy; import qupath.lib.objects.classes.PathClass. for (useLegacyJson in [true, false]) {. String parentName = Math.random() as String; String childName = Math.random() as String; String json; if (useLegacyJson); json = """"""{ ""name"": ""${childName}"", ""parentClass"": {""name"": ""${parentName}""}, ""colorRGB"": 0}""""""; else; json = """"""{ ""names"": [""${parentName}"", ""${childName}""], ""color"": [0, 1, 2]}""""""; ; def gson = GsonTools.getInstance(); PathClass pathClass = gson.fromJson(json, PathClass.class); pathClass = PathClass.getSingleton(pathClass); PathClass parent1 = pathClass.getParentClass(); PathClass parent2 = PathClass.fromString(parentName); ; if (useLegacyJson); println ""With legacy JSON""; else; println ""With v0.4 JSON""; println(""getSingleton: "" + parent1.hashCode() + "" ("" + parent1 + "")""); println(""fromString: "" + parent2.hashCode() + "" ("" + parent2 + "")""); println(""Are equal: "" + (parent1===parent2)) ; println ""----------""; }; ```; From a typical run I see; ```; INFO: With legacy JSON; INFO: getSingleton: 1714766410 (0.07271672325316691); INFO: fromString: 2014375544 (0.07271672325316691); INFO: Are equal: false; INFO: --",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1286#issuecomment-1670267778:827,avoid,avoid,827,https://qupath.github.io,https://github.com/qupath/qupath/pull/1286#issuecomment-1670267778,1,['avoid'],['avoid']
Safety,"Thanks, I'll need to find time to explore this in more detail - it probably reveals an ugliness in how QuPath handles viewer interactions. I worry a bit about adding new event handlers, because it can become confusing which is called and when. Note that the move tool (as with other tools) defines a [`mousePressed(MouseEvent)`](https://github.com/qupath/qupath/blob/main/qupath-gui-fx/src/main/java/qupath/lib/gui/viewer/tools/MoveTool.java#L73) method. Conceivably, this or some other tool might do something with a middle button press. If so, then it might be hard to predict which method will actually be called. It's quite possible that both would be called. One way to ensure that one method is called before another `EventHandler` is to use an [`EventFilter`](https://docs.oracle.com/javafx/2/events/filters.htm)... although adding multiple event filters would presumably lead to the same kind of confusion regarding *their* order. For global application behavior that doesn't need to be customized, then I think it's best to include the logic in a single `EventHandler` or `EventFilter` rather than adding multiple ones. Having both an `EventFilter` and an `EventHandler` is fine because then we know the filter will be called first, but having more than one of either of them attached to a UI component is where the confusion starts. For that reason, my guess (without looking in detail!) is that the tool toggling should be implemented using an `EventFilter` attached to the scene (not viewer, because it's global to the application), somewhere [around here](https://github.com/qupath/qupath/blob/main/qupath-gui-fx/src/main/java/qupath/lib/gui/QuPathGUI.java#L1046). Where exactly would depend upon whether the middle click should switch the tool when the UI is blocked or not. Either way, you should probably make sure to consume the event after it has performed the switch. However I'm not sure... since I reached this conclusion by thinking about it rather than testing anything.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1037#issuecomment-1237195586:571,predict,predict,571,https://qupath.github.io,https://github.com/qupath/qupath/pull/1037#issuecomment-1237195586,1,['predict'],['predict']
Safety,"Thanks, can you try the QuPath v0.5.0 release candidate - https://github.com/qupath/qupath/releases/tag/v0.5.0-rc1 ?. This behaves different from v0.4.4, using OpenSlide to read the image. To me, it appears to behave properly - although has the limitation that if you add more than one of the dicom files, then the same image is effectively duplicated in the project. I'm not sure if that's expected or acceptable, but addressing it is probably not straightforward. Dicom is the only format I know that behaves in this way, and QuPath tries to avoid having to treat formats as a special case (relying upon OpenSlide or Bio-Formats to untangle the meaning of the image file paths provided).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1397#issuecomment-1773053854:544,avoid,avoid,544,https://qupath.github.io,https://github.com/qupath/qupath/issues/1397#issuecomment-1773053854,1,['avoid'],['avoid']
Safety,"Thanks, it is great to be able to go through the z-stacks. I find the viewer very responsive compared to other image analysis/viewing softwares!. The script to adjust fluorescence contrast is a fairly good/quick option to adjust the settings. One question though: is it possible to also adjust manually the default colours for each channels within the same script? I've tried something like `channels[0].setColor(color)` but it is not working.... do you know which code would do the trick?. Another question related to the `.scn` format. The first image is the label but appears all pink. Do you know a way of seeing the actual label? (which would normally display in other viewers, and wouldn't be pink). And the label doesn't seem recognised as a label by QuPath but is showing in the image list, I guess it could be possible to avoid this?. Many thanks",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/191#issuecomment-409745698:831,avoid,avoid,831,https://qupath.github.io,https://github.com/qupath/qupath/issues/191#issuecomment-409745698,1,['avoid'],['avoid']
Safety,"Thanks, the command is unfinished & needs more attention at some point, but the fact it works for 'below threshold' is probably why I've never seen the issue (and it seemed to work for me when I tried it). > Side note: Classify Detections, when working off of a loaded classifier, seems to try to do something, then fails with a whole lot of:; `WARN: Classification Unclassified is invalid! Will be set to null instead`. Does it fail or is it just wordy? Because warnings aren't errors, this alone does not necessarily mean it fails.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/403#issuecomment-588528261:228,Detect,Detections,228,https://qupath.github.io,https://github.com/qupath/qupath/issues/403#issuecomment-588528261,1,['Detect'],['Detections']
Safety,"Thanks, there seems to be an issue with Bio-Formats reading the files, either not recognising them as pyramidal or only extracting the lowest resolution level. The contents of the 'Image' tab would give more useful information about what exactly is being read. There were recently issues with Aperio files reported at https://github.com/ome/bioformats/issues/3757; QuPath v0.3.2 reverts back to Bio-Formats 6.7.0 to try to avoid this specific issue but perhaps something related is going wrong. Forcing OpenSlide to be used as the reader rather than Bio-Formats may help: https://forum.image.sc/t/problem-about-opening-some-svs-slides-in-qupath-v0-3-1-bio-formats-6-8-0/61404/14. Apart from that, I'd need an example failing image to be able to investigate further - but even then I'm not sure that this is a bug that can be fixed in QuPath. To get things working, it may require the problematic files to be supported in Bio-Formats. However... > If I run the code on the same image it just broke on again, it works fine. There is seemingly no regularity to which images it fails on, other than they seem to be "".tif"" files. I have never had this bug appear on previous versions of QuPath. That does sounds strange. Assuming it's true, then I'm probably wrong in attributing it to Bio-Formats and it could indeed be a QuPath bug. But I'm afraid I have no way to exploring or fixing it. It would be helpful to know which QuPath versions works and which fail to be able to identify the problem more precisely. If I had to make a complete guess, it *might* have some connection with https://github.com/qupath/qupath/issues/894; If so, it *might* already be fixed if you [build from source](https://qupath.readthedocs.io/en/stable/docs/reference/building.html). I'd be interested if that's the case, but I don't recommend to using the current snapshot version (subject to change at any moment) - so would suggest reverting to the last working version instead. But I really am guessing.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/932#issuecomment-1057108089:423,avoid,avoid,423,https://qupath.github.io,https://github.com/qupath/qupath/issues/932#issuecomment-1057108089,1,['avoid'],['avoid']
Safety,"Thanks, this definitely needs changed. My guess is it happened while I was trying to lift the limit of measured channels (previously it was fixed at 8). Now that channel names can be stored, do you think this should be used in the measurements, e.g. 'DAPI (C1)' rather than the number alone? If so, I'd say this should be consistent between intensity measurements & cell detection and both ought to be updated. Any classifiers that use older names would break, but that may not be so bad... inasmuch as it's not a good idea to reuse classifiers across versions (at least where there has been major changes in between). It _does_ mean that channel names must be correct from the start. So they should be more easily fix-able than they currently are. One concern I had about doing this was that channel names could be weird, or wrong, or duplicated, or empty... but perhaps appending 'C1', 'C2' etc. is enough to mitigate this potential issue. Or 'Channel 1' etc. but the names risk becoming even more long and unwieldy. > Additionally, I am not sure if this feature could be parallelized?. It already is... should should see a difference if you reduce the number of parallel threads to 1. Or is there something I've missed?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/301#issuecomment-479346732:371,detect,detection,371,https://qupath.github.io,https://github.com/qupath/qupath/issues/301#issuecomment-479346732,2,"['detect', 'risk']","['detection', 'risk']"
Safety,"Thanks, this is an interesting idea and certainly seems to help in the scenario you describe. I'm apprehensive about merging quickly because it would be quite a significant change, and add complexity when we're trying to reduce it. So it will take some thought and I'd like to understand the problem better. > This last change alone allowed, on my projects, to improve the time when creating an object classifier from ~10/15minutes to ~5seconds. Can you explain why it takes so long? Huge numbers of images? Slow file format, or is it where the images are stored?. > Additionally, allowed to modify `ObjectClassifierCommand` too so that it can read all detections' measurements in the training set without uselessly reading the image files. The [`ObjectClassifier`](https://qupath.github.io/javadoc/docs/qupath/lib/classifiers/object/ObjectClassifier.html) takes an `ImageData` by design because an object classifier *could* require pixel access... and this is very likely to be important in the future. This is because, when I rewrote object classifiers some years ago, I was thinking of future classifiers that will use deep learning models to classify based upon image patches - and not only measurements. That's why there is also a general [`FeatureExtractor`](https://qupath.github.io/javadoc/docs/qupath/opencv/ml/objects/features/FeatureExtractor.html) class. This all basically works, we just haven't yet had time to wrap it up for wider use. > You can now pass a `openImage` boolean to `ProjectImageEntry.readImageData()` that, when false, just avoids getting the default image server, but just uses an instance of `ImageServerStub`. While not identical, the current `ProjectImageEntry.readHierarchy()` is intended for when you need objects but not everything else. This already lets you access all measurements etc. without touching the image. You can then create a new `ImageData` with a dummy `ImageServer` if you need to. So an alternative approach might be to try to script creating a cl",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1488#issuecomment-2021998811:653,detect,detections,653,https://qupath.github.io,https://github.com/qupath/qupath/pull/1488#issuecomment-2021998811,1,['detect'],['detections']
Safety,"Thanks, this is some excellent detective work!. Closing in favor of https://github.com/qupath/qupath/pull/1476 for v0.5.1 because it is simpler (and written based on the info you posted here), but we may revisit it as this is more listener-friendly.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1462#issuecomment-1973332453:31,detect,detective,31,https://qupath.github.io,https://github.com/qupath/qupath/pull/1462#issuecomment-1973332453,1,['detect'],['detective']
Safety,"Thanks, this looks like a bug in the Bio-Formats extension. I can replicate the problem with the attached image. I've tracked it down to one line [here](https://github.com/qupath/qupath-bioformats-extension/blob/master/src/main/java/qupath/lib/images/servers/BioFormatsImageServer.java#L670) - presumably `mergeChannels` contains some logic to treat 4-channel 8-bit images are ARGB. If I open the image in ImageJ and save it as a multichannel image then all 4 channels are measured, as they should be. So it's not an inherent limitation in the cell detection. If I'm correct, most other combinations of channel numbers and bit-depths should be fine... It should be a fairly straightforward fix. I'm travelling at the moment, but will have a look soon.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/164#issuecomment-380835137:549,detect,detection,549,https://qupath.github.io,https://github.com/qupath/qupath/issues/164#issuecomment-380835137,1,['detect'],['detection']
Safety,"That is a tricky one. If your staining is DAB, have you tried _Analyze-> Cell Analysis->Cell+Membrane detection?_; Another option might be more of an area analysis. In other words, use QuPath to define areas (by SLICs/tiling) high in concentration of your membrane stain, then calculate the number of nuclei within those areas plus the average value of your membrane stain.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/227#issuecomment-428235577:102,detect,detection,102,https://qupath.github.io,https://github.com/qupath/qupath/issues/227#issuecomment-428235577,1,['detect'],['detection']
Safety,"That is correct, and as far as I know it is the only possible behavior for the simple tissue detection command. I have always added any extra annotations after that first step. . If you do not want that behavior, you could also create an ImageJ script that does something similar, and then run it on all existing annotations. Assuming the ImageJ script was set up correctly (downsampling to fit ImageJ's file size requirements, etc), you could use Thresholding+Analyze Particles and then return the created outlines as annotation objects. . That is actually more like what I do for fluorescent tissue detection, and it can work fairly well.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/248#issuecomment-441513852:93,detect,detection,93,https://qupath.github.io,https://github.com/qupath/qupath/issues/248#issuecomment-441513852,2,['detect'],['detection']
Safety,That is true for the TMA core export and my Tissue annotation but not for the txt output for all cells.; I'm referring to the Detection measurements for every core = single cells. Under the Name column it only says PathCellObject.; I've completed the cell analysis again and this is still the case.; Any suggestions appreciated.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/59#issuecomment-289505578:126,Detect,Detection,126,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-289505578,1,['Detect'],['Detection']
Safety,"That looks like the sort of thing that Simple Tissue Detection might work for with the correct settings. Something around 220 threshold maybe, with a medium requested pixel size and minimum area (keep setting these lower until you are picking up all of what you want). Also you will probably want to uncheck Single annotation. The requested pixel size is probably the most important measurement to play around with if you use this method. David beat me to it! His method is also probably better in the long run, though this gives another, slightly simpler method. I would also be careful about using too many features in your classifier, or at least make sure your training set is significantly larger than the number of features you use!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/121#issuecomment-349094523:53,Detect,Detection,53,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349094523,1,['Detect'],['Detection']
Safety,"That sounds like it might be possible, as long as the mitotic nuclei are distinct enough visually to easily distinguish, but in the case of the Ki67 detection, that was done with DAB staining so the same method would not work on H&E slides. It is simply detecting ""brown"" in the cell. Perhaps a higher Hematoxylin OD or something similar would work for your H&E slides. It sounds very similar to things done with deep learning already, but may be possible with either a scripted classifier or the classifier function in QuPath as long as you can give it a big enough training set. . Though, this seems like less of a QuPath technical issue, and more of a [question for the forum](https://groups.google.com/forum/#!forum/qupath-users).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/205#issuecomment-414434663:149,detect,detection,149,https://qupath.github.io,https://github.com/qupath/qupath/issues/205#issuecomment-414434663,2,['detect'],"['detecting', 'detection']"
Safety,"That's awesome. Thank you!. I will try to implement it with JTS, then.; However the implication is that ""Polygons do not contain their boundary"", correct? Does that mean that if I'm testing if a point `p` is inside the boundary or **on** the boundary, i should check that `JVT.Geometry.covers(p) || JVT.Geometry.intersects(p)`, right?. I'm saying this because of what the DE-9IM article says about the `contains`/`withIn` predicates; > This issue is caused by the final clause of the Contains definition above: ""at least one point of the interior of B lies in the interior of A"". For this case, the predicate Covers has more intuitive semantics (see definition), avoiding boundary considerations.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1492#issuecomment-2048226578:663,avoid,avoiding,663,https://qupath.github.io,https://github.com/qupath/qupath/pull/1492#issuecomment-2048226578,1,['avoid'],['avoiding']
Safety,"The ""Pixel value"" label has since been removed as well, to avoid wasting more vertical space.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1270#issuecomment-1600861461:59,avoid,avoid,59,https://qupath.github.io,https://github.com/qupath/qupath/pull/1270#issuecomment-1600861461,1,['avoid'],['avoid']
Safety,"The *Analyze &rarr; Calculate features &rarr; Add intensity features (experimental)* was introduced to replace the older *Haralick features* command, and is more flexible and capable. However, it is not restricted only to calculating features on detections, but can also be used for TMA cores and annotations. This ought to be good... except that it can be confusing whenever a user *wants* to calculate detection features (which is the expected 'normal' use), but happens to have another type of object selected at the time. Furthermore, it may even cause trouble because it does not automatically tile very large regions or give any warnings. Therefore it could cause crashes if used with very large objects selected.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/15:246,detect,detections,246,https://qupath.github.io,https://github.com/qupath/qupath/issues/15,2,['detect'],"['detection', 'detections']"
Safety,"The Brightness/Contrast dialog shows there are 4 channels, but 3 are turned off; the TMA dearrayer won't be affected by which channels are turned on/off there though. For such images, it uses [an average projection of all the channels](https://github.com/qupath/qupath/blob/v0.1.2/qupath-processing-ij/src/main/java/qupath/imagej/detect/dearray/TMADearrayerPluginIJ.java#L237). It will most likely have correctly auto-set the image type as 'Fluorescence', but it's always worth checking under the 'Image' tab (in case this was changed / the auto detection of image type was turned off).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/196#issuecomment-410631215:330,detect,detect,330,https://qupath.github.io,https://github.com/qupath/qupath/issues/196#issuecomment-410631215,2,['detect'],"['detect', 'detection']"
Safety,The TMA core is now included in the detection table in QuPath v0.2.0-m3 (and likely earlier milestones...).,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/59#issuecomment-518574610:36,detect,detection,36,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-518574610,1,['detect'],['detection']
Safety,"The backup will only show up, I think, if you have successfully saved the; file at least once. It isn't an autosave feature. Regarding the memory, 3.3 GB is quite low. For small scale testing I; usually got away with 16GB, and for larger projects 64+. I am not sure,; but you may be able to circumvent this somewhat by running each of your 4; ROIs in turn, and saving after each. On Nov 9, 2017 9:23 AM, ""Eline8"" <notifications@github.com> wrote:. > Thank you both for answering! @Svidro <https://github.com/svidro> and; > @petebankhead <https://github.com/petebankhead>; > I started all over again, so I don't have the workflow anymore.; > Nevertheless, what I meant was that I used indeed the pointing tool. I had; > two populations, one negative and one positive. After I ran the positive; > cell detection, the negative population was gone. And unfortunately, there; > is no undo button.; >; > My goal was indeed compare the manual counting and the automated counting.; > For optimization.; >; > I don't know whether the error is the lack of RAM, I checked and i have; > 3,3GB available. And I only have 4 ROI's in one image. When I run the; > analysis, I make sure nothing is selected and choose the option 'all; > annotation'. It might be, but it might be not, because sometimes it also; > does not analyse only 1 ROI, but other times it does. However, the log it; > says 'memory error'. the programs that are running on my computer besides; > Qupaht are google chrome (1tab), one note with an excel file, and file; > explorer.; >; > [image: capture]; > <https://user-images.githubusercontent.com/33484227/32604466-0266ac66-c54e-11e7-9a9b-ede61554510b.PNG>; > [image: capture2]; > <https://user-images.githubusercontent.com/33484227/32604472-05d80ef8-c54e-11e7-97d1-b1540f6ee388.PNG>; > [image: capture3]; > <https://user-images.githubusercontent.com/33484227/32604473-07eafa66-c54e-11e7-9aca-94fae7d0e9da.PNG>; >; > I really don't know why sometimes it works or not, but i'll be more; > careful",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/112#issuecomment-343229740:800,detect,detection,800,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343229740,1,['detect'],['detection']
Safety,"The behavior has been unchanged in v0.2.0 milestones for many months (without previous complaint) and it is now too late to make any substantial change before v0.2.0. QuPath v0.1.2 handled projects in a much simpler way, but this is insufficient for many recent and planned features for which a single local file path isn't enough to identify an image. v0.2.0 therefore stores both the absolute and relative paths. If the relative path to the project file is maintained, QuPath will show a dialog and prepopulate the necessary changes to the absolute paths to update the project. The user only has to accept these changes and the project will be updated. This should allow everything to be 'corrected' immediately when the project is opened. If the absolute paths were *not* updated, then resolving relative paths every time they are required would be rather a lot more complex, and could result in projects being silently updated in unexpected ways (e.g. when changing an image name, trigging the project file to be rewritten). The current behavior aims to strike a compromise between being easy to use and not causing unexpected problems. To avoid the 'update URIs' dialog in am multi-user setting, each user can duplicate the *project.qpproj* file and use the duplicate as their own view on it, i.e. they open and update the project file to contain the absolute paths relevant to them. To facilitate this, when dragging a project directory on top of QuPath one can choose the precise file to open from a drop-down list. There is also a *Recent Projects* option to reopen the last project. > **Please respect the request to use image.sc for questions and discussions, not GitHub.**; > ![bug report](https://user-images.githubusercontent.com/4690904/80976463-68b25400-8e1b-11ea-8c19-739a35dd4942.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/468#issuecomment-623497951:1144,avoid,avoid,1144,https://qupath.github.io,https://github.com/qupath/qupath/issues/468#issuecomment-623497951,1,['avoid'],['avoid']
Safety,"The cell recognition does not work for WatershedCellMembraneDetection via script. It executes it, but recognizes 0 cells or rarely times 1 cell. If you replace WatershedCellMembraneDetection with WatershedCellDetection, everything works fine. When called from the GUI, WatershedCellMembraneDetection also works fine. I have tried it under version 0.2.3. `runPlugin('qupath.imagej.detect.cells.WatershedCellMembraneDetection', '{""detectionImageBrightfield"": ""Hematoxylin"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}');`",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/624:380,detect,detect,380,https://qupath.github.io,https://github.com/qupath/qupath/issues/624,2,['detect'],"['detect', 'detectionImageBrightfield']"
Safety,"The core images are loaded in a background thread, and there is a 5 second timeout associated with this - see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L254). One possibility is that the timeout isn't generous enough in your case, and the cores are not being loaded fast enough. I don't know why that would be the case... it might be to do with the computer specifications, where the image is located (a network share?), or the access time required for the specific file format. Another option is that there are just too many cores. That is my best guess, since the scrollbar thumb on the right in your screenshot looks very small. There is a limit to the size of the cache used to store the TMA cores to reduce the risk of memory errors, see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L133) for the location in the code. Currently there is no way to increase the size of the cache through the user interface to support more cores in the grid view. Although, as is often the case, there is a way through a script. You could try running this to double the cache size to see if it helps.; ```groovy; qupath.lib.gui.commands.TMAGridView.MAX_CACHE_SIZE = 500; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/96#issuecomment-326105429:75,timeout,timeout,75,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-326105429,3,"['risk', 'timeout']","['risk', 'timeout']"
Safety,"The darkish background seems to be causing QuPath to estimate the wrong image type; double-click where it says 'Fluorescence' in the left tab of your screenshot, and change this to something more appropriate. Then reopen the cell detection command and the correct options should appear. (There is some more explanation of this at the start of the new [video tutorials](https://petebankhead.github.io/qupath/2018/08/22/qupath-video-tutorials.html))",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/226#issuecomment-426971226:230,detect,detection,230,https://qupath.github.io,https://github.com/qupath/qupath/issues/226#issuecomment-426971226,1,['detect'],['detection']
Safety,"The following image and script show the differences in how objects might be requested from the object hierarchy. The tests that each cell object passes contribute to the classification assigned, so that; * if two cells have the same color you can assume they were returned by the same methods; * if two cells have different colors, then at least one cell was returned by at least one method that didn't return the other cell (e.g. it intersects the selected ROI, but isn't completely covered by it). ![image](https://github.com/user-attachments/assets/ad4a2204-2b96-4d5c-bdda-629fccffe2f6). ```groovy; // Get hierarchy & selected object/ROI; def hierarchy = getCurrentHierarchy(); def selectedObject = getSelectedObject(); def roi = selectedObject.getROI(). // Total number of detections everywhere; def allDetections = getDetectionObjects(); println ""Num detections (all): \t${allDetections.size()}"". // Direct children of the selected object; def childObjects = selectedObject.getChildObjects(); println ""Num child objects: \t${childObjects.size()}"". // Get all detections for the region (rectangular bounding box, quick test); def region = ImageRegion.createInstance(roi); def regionObjects = hierarchy.getAllDetectionsForRegion(region, null); println ""Num in region bounds: \t${regionObjects.size()}"". // Detections within selected object, using hierarchy rules; def hierarchyWithin = hierarchy.getAllDetectionsForROI(roi); println ""Num 'within' ROI: \t${hierarchyWithin.size()}"". // Detections with nucleus (or main ROI) centroids within the selected object; def nucleusCentroidWithin = PathObjectTools.filterByROIContainsNucleusCentroid(roi, allDetections); println ""Num nucleus centroid in ROI: \t${nucleusCentroidWithin.size()}"". // Detections with centroids within the selected object; def centroidWithin = PathObjectTools.filterByROIContainsCentroid(roi, allDetections); println ""Num centroid in ROI: \t${centroidWithin.size()}"". // Detections with ROIs intersecting the selected object; def",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1563#issuecomment-2264806074:777,detect,detections,777,https://qupath.github.io,https://github.com/qupath/qupath/pull/1563#issuecomment-2264806074,2,['detect'],['detections']
Safety,"The goal of this PR was to find a good solution for [this issue](https://forum.image.sc/t/add-additional-channel-in-fluorescence-image-after-scanning/99174/) (in short, creating a new channel by linearly combining existing channels). . This was done by adding a new `ColorTransforms` called `LinearCombinationChannel` that applies a linear combination to the channels. The existing `ColorTransforms` were a bit refactored to remove the warnings and improve null safety (but their behaviors stay the same). Tests were added for all existing `ColorTransforms` and the new `LinearCombinationChannel`. Implementations for `hashCode` and `equals` in `ColorDeconvolutionStains` were also added because it was needed for unit tests.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1566:462,safe,safety,462,https://qupath.github.io,https://github.com/qupath/qupath/pull/1566,1,['safe'],['safety']
Safety,"The interface will generally use the second color vector as its detection channel for the subcellular detection, so make sure that color vector is set to your fast red. If you need to do 2 color, I recommend setting the image type to Brightfield Other, though that has its own dangers! You are not locked into using DAB. I think changing the name of the color vector also changes the description in the subcellular detection dialog.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/119#issuecomment-346389148:64,detect,detection,64,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-346389148,3,['detect'],['detection']
Safety,"The last commit adds a toolbar button to show detection 'connections' (neighbors based on a Delaunay triangulation):. ![image](https://github.com/user-attachments/assets/90878352-9335-4163-aa36-9f1517225b31). This was previously available under the *View* command, but only actively did anything if the *Delaunay cluster features 2D* command had been run. Now, it can be used at any time and will show connecting lines for cells (if available), or detections (if there are no cells). Currently, it is only a visual tool - using the new features require scripts such as those described above.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1597#issuecomment-2305236713:46,detect,detection,46,https://qupath.github.io,https://github.com/qupath/qupath/pull/1597#issuecomment-2305236713,2,['detect'],"['detection', 'detections']"
Safety,The last commit should avoid showing an error message unnecessarily.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/503#issuecomment-633205314:23,avoid,avoid,23,https://qupath.github.io,https://github.com/qupath/qupath/issues/503#issuecomment-633205314,1,['avoid'],['avoid']
Safety,"The latter will only provide features depending on what boxes are checked, and only for the detections you choose (cells, SLICS, whatever you happen to have selected, etc). I don't know that it will work if you just have large annotations, but if you choose annotations after running it, it will look ""inside"" all annotations for detections to apply the Calculate Features to. ; Edit: Whoops, nix that last part, finally got around to playing with it and reminding myself how it works. It will apply the measurements to the annotation, but if you are classifying detections, the measurements you created will not show up as they would only be part of the annotation itself, as Peter first said. You also need to have one or more ""Basic Features"" selected in order for it to generate something off of the Color Transforms you select.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/63#issuecomment-293368367:92,detect,detections,92,https://qupath.github.io,https://github.com/qupath/qupath/issues/63#issuecomment-293368367,3,['detect'],['detections']
Safety,"The main aim is to avoid naively and sequentially computing the intersection of every rectangular tile with an outer geometry.; This uses several tricks:; * Use a parallel stream when computing intersections using multiple tiles; * For large ROIs, compute intersections first for all tiles in either each row or column, so subsequent intersection calculations are simplified; * For large ROIs, create a prepared geometry first to check covers/intersects quickly; Results should be the same as using the previous sequential approach with RoiTools.computeTiledROIs; the old method remains to enable testing.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/782:19,avoid,avoid,19,https://qupath.github.io,https://github.com/qupath/qupath/pull/782,1,['avoid'],['avoid']
Safety,"The minus key on my main keyboard and the minus key on my number pad both cause; zooming-in / increased magnification. Both of my + keys don’t do anything. From: MicroscopyRA <notifications@github.com>; Reply-To: qupath/qupath <reply@reply.github.com>; Date: Monday, June 8, 2020 at 1:26 PM; To: qupath/qupath <qupath@noreply.github.com>; Cc: ""Kathleen T. Yee"" <KYee@umc.edu>, Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [qupath/qupath] Zoom In and Zoom Out (#518). Right, that was the first part, sorry for lack of clarity. Num lock on or off has no impact. ""The + and - keys no the num pad do nothing when I use them."". —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fissues%2F518%23issuecomment-640795671&data=02%7C01%7Ckyee%40umc.edu%7C3f6606e691e84856b92008d80bd9728c%7C78a0681ef0be47e280498616858818a5%7C0%7C0%7C637272375844340509&sdata=PdIW4tJzmYbxH24BlWci00hk0WXzvZf6SoWFDKxEnks%3D&reserved=0>, or unsubscribe<https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAP4MNEZE2DLPTDWWMJINGMLRVUUM3ANCNFSM4NYSD4CA&data=02%7C01%7Ckyee%40umc.edu%7C3f6606e691e84856b92008d80bd9728c%7C78a0681ef0be47e280498616858818a5%7C0%7C0%7C637272375844350502&sdata=80Q8pB3Tqf9csexrlxWph406VYzvfheP775lDTJ9y6Q%3D&reserved=0>. Individuals who have received this information in error or are not authorized to receive it must promptly return or dispose of the information and notify the sender. Those individuals are hereby notified that they are strictly prohibited from reviewing, forwarding, printing, copying, distributing or using this information in any way.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/518#issuecomment-640799956:759,safe,safelinks,759,https://qupath.github.io,https://github.com/qupath/qupath/issues/518#issuecomment-640799956,2,['safe'],['safelinks']
Safety,"The other option, if the stain is overlapping the nucleus significantly, is to just use the subcellular detection tool (again with a smaller cell expansion), and set a threshold based on the amount of area that shows up ""pink.""",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/83#issuecomment-314861290:104,detect,detection,104,https://qupath.github.io,https://github.com/qupath/qupath/issues/83#issuecomment-314861290,1,['detect'],['detection']
Safety,"The path is now a URI, which is useful in distinguishing between a local file and something else (e.g. image hosted with OMERO). Additionally, a URI might have some additional info (query or fragment) necessary to distinguish a specific image found within the same file. The critical thing is that the path should be unique for each image because it is used for caching image tiles, but it isn't safe to assume that it is a valid path to a local file. Probably `buildFilePath` happened to work before because the path _was_ usually a path to a local file (albeit sometimes with an extra identifier appended for Bio-Formats) but it wasn't really intended to. Its main purpose was to build paths relative to the project directory*. I'm not sure what the purpose of `buildFilePath(path)` is in your script, but it probably now needs replaced with something else. Otherwise, even if the URI thing was dealt with your script wouldn't work with OMERO-hosted files (and probably others read by Bio-Formats). > *-Although projects aren't now guaranteed to be local directories either, since a project is now an interface which would be implemented in some other way...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/289#issuecomment-474156600:396,safe,safe,396,https://qupath.github.io,https://github.com/qupath/qupath/issues/289#issuecomment-474156600,1,['safe'],['safe']
Safety,"The primary cell detection command under *Analyze &rarr; Cell analysis &rarr; Cell detection* is primarily intended for brightfield images. However, it ought also to work for fluorescence. Under some conditions it does, namely when:. * the *first* fluorescence channel contains a nuclear staining (e.g. DAPI); * the *Max background intensity* parameter is either set negative or very high, or *Background radius* is negative; * the *Threshold* value is set appropriately high. This is because, in the case of fluorescence data, the command only looks for the first available channel within which to detect nuclei. Furthermore, the *Max background intensity* and *Threshold* parameters, by default, are selected for optical density units... which can be far away from being sensible values for fluorescence. The command should be adapted to use more sensible defaults in the case of fluorescence images, and to permit the selection of alternative channels.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/14:17,detect,detection,17,https://qupath.github.io,https://github.com/qupath/qupath/issues/14,3,['detect'],"['detect', 'detection']"
Safety,"The reason I chose the more general 'Object classification' is thinking about the future. Even though the existing commends mostly focus on object classification for detections only, future commands might not be. And extensions might add commands to classify in a different way. For example, here's a script that adds a basic command to classify annotations based on the shape of the ROI:; ```groovy; import javafx.application.Platform; import javafx.scene.control.MenuItem; import qupath.lib.gui.QuPathGUI; import qupath.lib.gui.dialogs.Dialogs; import qupath.lib.objects.PathObject; import qupath.lib.objects.classes.PathClass. commandName = ""Classify annotations"". Platform.runLater {; installCommand(); Dialogs.showInfoNotification(commandName, ""Command installed!""); }. def installCommand() {; def menu = QuPathGUI.getInstance().getMenu(""Classify > Object classification"", false); def mi = menu.getItems(); .stream(); .filter(m -> commandName.equals(m.getText())); .findAny().orElse(null); if (mi == null) {; mi = new MenuItem(commandName); menu.getItems().add(mi); }; mi.setOnAction {e -> classifyAnnotations()}; }. def classifyAnnotations() {; def imageData = QuPathGUI.getInstance().getImageData(); def annotations = imageData == null ? [] : imageData.getHierarchy().getAnnotationObjects(); if (annotations.isEmpty()) {; Dialogs.showWarningNotification(""Classify annotations"", ""No annotations found!""); return; }; for (def annotation in annotations); classifySingleAnnotation(annotation); imageData.getHierarchy().fireObjectClassificationsChangedEvent(this, annotations); }. def classifySingleAnnotation(PathObject pathObject) {; def roiName = pathObject.getROI()?.getRoiName(); pathObject.setPathClass(PathClass.getInstance(roiName)); }; ```. I think it makes sense for such classifiers to be added to a single *Object classification* submenu, rather than split between *Detection* and *Annotation* (also, there might one day be a need to classify *TMA cores*, which don't fit into either cat",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1501#issuecomment-2075386110:166,detect,detections,166,https://qupath.github.io,https://github.com/qupath/qupath/issues/1501#issuecomment-2075386110,1,['detect'],['detections']
Safety,"The safest way is probably to use Docker or something similiar. ons. 22. sep. 2021, 17:38 skrev Pete ***@***.***>:. > Ah ok, then I'm afraid I have no idea and no way to reproduce the problem.; > It is working for me on all my test systems (but I haven't got CentOS; > installed anywhere).; >; > I can't see any obvious clues to a problem within QuPath's code from the; > error. The versions of Java, JavaFX and jpackage have been updated for; > v0.3.0, not sure if that is related.; >; > One option would be to try building from source; > <https://qupath.readthedocs.io/en/stable/docs/reference/building.html>; > using a different JDK, or launch using ./gradlew run (which would skip; > the jpackage part).; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/825#issuecomment-925047351>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AH7WSL62XZNUGJTSADEHNB3UDHZ6HANCNFSM5ERSPAHA>; > .; > Triage notifications on the go with GitHub Mobile for iOS; > <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>; > or Android; > <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.; >; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/825#issuecomment-925051403:4,safe,safest,4,https://qupath.github.io,https://github.com/qupath/qupath/issues/825#issuecomment-925051403,1,['safe'],['safest']
Safety,The script editor now has a new 'Insert' tab with the following commands:. Insert >; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Symbols >; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;µ; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Imports >; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;QP; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;QPEx; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;All default; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Classifiers >; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;Pixel classifiers _(This insert all pixel classifier names from the currently opened project in the script editor)_; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;Object classifiers _(This insert all object classifier names from the currently opened project in the script editor)_; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Measurements >; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;Detection _(This import all detection measurement names from the currently opened project in the script editor)_,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/722:1307,Detect,Detection,1307,https://qupath.github.io,https://github.com/qupath/qupath/pull/722,2,"['Detect', 'detect']","['Detection', 'detection']"
Safety,"The title of this issue is issue looks quite dramatic, but I don't understand what the error is at all. Can you explain further? Was cell detection applied to a brightfield image with the image type set to 'Fluorescence'?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/153#issuecomment-370398858:138,detect,detection,138,https://qupath.github.io,https://github.com/qupath/qupath/issues/153#issuecomment-370398858,1,['detect'],['detection']
Safety,"There are a couple of ways to approach this, and it somewhat depends on how you are handling your analysis and what you are analyzing. With more information I might be able to be more specific. If your DAB staining is cytoplasmic (immune markers?) and you are having trouble with accurate positivity due to the carbon spots, you can use subcellular detection to find the spots, then subtract out the contribution of the spots from that cell for a new mean OD. Use a color vector set like below, perform the subcellular detection on the ""black"" channel. With the area of black spots times the mean DAB contribution within each spot, you could create a sum which could then be deducted from the DAB stain within the cell (also mean times area). Specifics depend on staining!. Blue is often a great way of picking up these spots, but while you could alter your annotation area to exclude the black spots (SLICs/classify/merge, very processing intensive), your Cell Expansion can still allow the cytoplasm to occupy these areas outside of your annotation. `setColorDeconvolutionStains('{""Name"" : ""CarbonDetection"", ""Stain 1"" : ""Black"", ""Values 1"" : ""0.57132 0.63886 0.51521 "", ""Stain 2"" : ""NotBlack"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');`. You can change color vectors as much as you want throughout your experiment, so you do not need to change the image type to H&E, the above line in a script can be modified for whatever color vectors you want.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/172#issuecomment-387779230:349,detect,detection,349,https://qupath.github.io,https://github.com/qupath/qupath/issues/172#issuecomment-387779230,2,['detect'],['detection']
Safety,"There is a shape simplification step used when viewing annotations at a lower resolution, to avoid needing to paint all the vertices frequently. I'm not sure why it is failing in this case. Does the issue occur only when combined with your code, or also when QuPath is used alone?; Can you provide any steps to reproduce, or files containing annotations that exhibit this behavior?. Just in case, note that ROIs are supposed to be immutable - so if any exterior code violates that (e.g. by manipulating private fields with ROIs) then the result would be Bad.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/416#issuecomment-601616473:93,avoid,avoid,93,https://qupath.github.io,https://github.com/qupath/qupath/issues/416#issuecomment-601616473,1,['avoid'],['avoid']
Safety,"There should be a variety of ways to do this in a script. One would be selecting each annotation in turn using getAnnotationObjects() and looping through them. For each annotation you generate your detections, output detections, then clear detections.; Another way could be to use a loop to a classification for each annotation (Class1, Class2, etc) and then you will end up with one data file, but the detection entries would be easily separable based on the classification column.; In version 1.3, there is a column that names the parent annotation for each detection, which could also be used to select certain detections without creating a classification.; Version 1.3 installation instructions (it is a test version!) can be found here: https://petebankhead.github.io/qupath/2018/03/19/qupath-updates.html",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/225#issuecomment-427051030:198,detect,detections,198,https://qupath.github.io,https://github.com/qupath/qupath/issues/225#issuecomment-427051030,6,['detect'],"['detection', 'detections']"
Safety,"There's a description of how I've done it in the past in the [Scientific Reports paper](https://www.nature.com/articles/s41598-017-17204-5). In particular, see the [Supplementary material](https://static-content.springer.com/esm/art%3A10.1038%2Fs41598-017-17204-5/MediaObjects/41598_2017_17204_MOESM1_ESM.pdf) - especially around p 13. The supplementary material also shows a really elaborate script on p15... but actually it's *much* simpler now:; ```groovy; setCellIntensityClassifications('Cell: DAB OD max', 0.35); ```. However, all of that is too complicated If you are will to draw regions of interest, and don't need to bother with separating out epithelial/non-epithelial cells (which may be really difficult and not accurate enough in brightfield images for PD-L1). In that case, it should be much easier to simply run *Positive cell detection* as described [here](https://github.com/qupath/qupath/wiki/Detecting-objects). The only thing you should need to chnage is the measurement at the bottom (*Nucleus: DAB OD mean* probably isn't right, *Cell: DAB OD max* or *Cell: DAB OD mean* should do better).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/161#issuecomment-375336894:843,detect,detection,843,https://qupath.github.io,https://github.com/qupath/qupath/issues/161#issuecomment-375336894,2,"['Detect', 'detect']","['Detecting-objects', 'detection']"
Safety,"Thinking a bit more, a compromise option could be:; * keep the primary selected object if it's still selected in the new group, and; * set the primary selected object if there is only one object in the selection group, but not if there is more than one. Might be safer than selecting an object at random, and reduce the instances where the primary selected object is null slightly. What do you think?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/758#issuecomment-869219402:263,safe,safer,263,https://qupath.github.io,https://github.com/qupath/qupath/issues/758#issuecomment-869219402,1,['safe'],['safer']
Safety,"This PR proposes a moderately significant change to the `ImageServer` interface, which I'd like to discuss (and sanity-check) with the people most affected. @iwbh15 @NicoKiaru @lacan @ap-- @sdvillal @finglis (sorry if I have missed anyone...). The background is that pixels are currently accessed in QuPath via something like; ```java; RegionRequest request = RegionRequest.createInstance(server.getPath(), downsample, x, y, width, height);; BufferedImage img = server.readBufferedImage(request);; ```. Creating a `RegionRequest` made sense in the early days, since it was used for caching. It remains useful for accessing corresponding regions in paired images, or for creating requests from ROIs, and for avoiding a plethora of parameters (particularly if `z` and `t` indices should be returned as well). However, often it just feels like unnecessary overhead, e.g. when writing simple scripts... or accessing from another language, like Python. It is pretty easy to retrofit support for; ```java; BufferedImage img = server.readBufferedImage(downsample, x, y, width, height, z, t);; BufferedImage img2 = server.readBufferedImage(downsample, x, y, width, height);; ```; by simply adding default methods to the interface. I don't think this should break anything. However this leads to another consideration... `readBufferedImage` isn't a great name, since the method really returns an instance of whatever the generic parameter `T` stands for in `ImageServer<T>`. It happens that this is pretty much always `BufferedImage` in QuPath, but the original idea was that an `ImageServer` could exists that returns something else that might be more convenient (e.g. something from ImgLib2, or an OpenCV `Mat`). So rather than doubling-down on `server.readBufferedImage` I would like to switch to `server.readRegion(RegionRequest)` instead. This feels to me more accurate and intuitive. The tricky bit is not breaking everything else... like parts of paquo or warpy, and all existing scripts that need pixel",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1072:707,avoid,avoiding,707,https://qupath.github.io,https://github.com/qupath/qupath/pull/1072,1,['avoid'],['avoiding']
Safety,"This avoids the need to create a custom launch script as described at https://github.com/qupath/qupath/issues/628. While still not ideal, it gives an alternative way to avoid using system shared libraries with OpenSlide - which is known to be problematic because of pixman issues on Ubuntu LTS releases (including 20.04). This works by including a bash script in the jpackage image generated for Linux by default. It also works with; `./gradlew run -Pld-path=true`; and with; `./gradlew installDist -Pld-path=true`",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/783:5,avoid,avoids,5,https://qupath.github.io,https://github.com/qupath/qupath/pull/783,2,['avoid'],"['avoid', 'avoids']"
Safety,"This enable `ObjectMerger` and `OverlapFixer` to implement the same interface, and means they can easily be applied sequentially. Then the `PixelProcessor` class was updated to support an `ObjectProcessor` to handle detections made across tiles, rather than an `ObjectMerger` - since that gives more flexibility in dealing with the output.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1621:216,detect,detections,216,https://qupath.github.io,https://github.com/qupath/qupath/pull/1621,1,['detect'],['detections']
Safety,"This gets rid of the warnings about deprecation during startup. Only the Bio-Formats and OpenSlide servers relied upon this as a backup in case `ImageServer.close()`, and both now use `Cleaner`. Note that this should be more reliable anyway, since servers that wrapped other servers don't reliably call `close()` on the servers that they wrap. They arguably should, but if multiple servers wrap the same core server then there's a chance it is closed even while still in use... so it's safer to rely on the `Cleaner` (unfortunately). One way to test this is to run a script such as ; ```groovy; int n = 10; for (int i = 0; i < n; i++) {; def server = getProjectEntry().getServerBuilder().build(); println server; }; ```; for a project with an OpenSlide or Bio-Formats image open, and check the log for evidence that `Cleaner` was used (at debug level).",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1617:486,safe,safer,486,https://qupath.github.io,https://github.com/qupath/qupath/pull/1617,1,['safe'],['safer']
Safety,"This happens whenever QuPath is unable to detect any cores. There are a few reasons why this may occur:. * The *Image type* is wrong (e.g. set to fluorescence rather than brightfield) - this can be seen after clicking on the *Image* tab on the left. There is a screenshot [here](https://github.com/qupath/qupath/wiki/Preprocessing#viewing-the-default-stain-vectors).; * The specified TMA core diameter is either too large or too small. QuPath determines the expected TMA grid from 'complete' cores, which have a diameter within a small tolerance of the value set in the dialog box. If no cores fall within this tolerance, the grid cannot be found.; * The intensity threshold is either too high or too low (but it is automatically determined from the data, and I don't see any reason in your image why it would be determined wrongly). If the image type is set correctly, then I would try increasing and decreasing the *TMA core diameter* to see if this gives any improvements. If not, then there may be some issue happening internally when trying to read from the CZI file - although I have not seen such a problem before. The contents of *View &rarr; Show log* may be helpful to track down the problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/48#issuecomment-276482533:42,detect,detect,42,https://qupath.github.io,https://github.com/qupath/qupath/issues/48#issuecomment-276482533,1,['detect'],['detect']
Safety,"This includes Bio-Formats 6.9.0 for further testing. It still has an issue with some svs files, but adds dicom support - both should be documented if this remains in the next release. It also includes JavaFX 18, which fixes a bug that meant selecting all entries in a large table (e.g. a detection measurement table) was unusably slow.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/946:288,detect,detection,288,https://qupath.github.io,https://github.com/qupath/qupath/pull/946,1,['detect'],['detection']
Safety,"This involves several changes:; - Use toolchain rather than target version.; - This is required because Gradle can't currently be run using Java 16, and so the build script needs to be called using a different Java version than the one used to build QuPath. If Java 16 isn't available, Gradle will download it.; - Strip the version number from the application name.; - This is required to avoid package failures due to the .cfg file name being different. *Unfortunately, this may cause problems for users wanting multiple versions installed simultaneously.* The workaround is to rename/use the .zip installations on Windows.; - Explicitly specify the java.library.path to be $APPDIR; - This is required to load OpenSlide/JPen. The library path was previously set automatically by jpackage in Java 14 (but not 15).; - Explicitly use java-options in the cfg file when changing the memory settings; - Avoid setting the version on macOS; - Sadly, we cannot start a version number with 0. These changes should also address the issues that arose when building QuPath v0.2 with Java 14: https://github.com/qupath/qupath/issues/615. Several other changes were made:; - Update gradlew; - JavaCPP now uses platform plugin for better dependency management; - Guava version updated; - License report plugin updated; - include jdk.jsobject",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/685:389,avoid,avoid,389,https://qupath.github.io,https://github.com/qupath/qupath/pull/685,2,"['Avoid', 'avoid']","['Avoid', 'avoid']"
Safety,"This is a very provisional proof-of-concept showing how the measurement mapper could support more than detections. Note that it doesn't handle *dynamic* measurements. So if you want to use annotation shapes (for example), then it's necessary to use 'Analyze → Calculate features → Add shape features' first.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1664:103,detect,detections,103,https://qupath.github.io,https://github.com/qupath/qupath/pull/1664,1,['detect'],['detections']
Safety,"This is a very shoddy way of doing the detections per annotation, and is written for version 1.2 where the default names might not be unique. 1.3 could simply use the annotation name instead of incremental numbers. If the annotations were all uniquely (manually) named, that could potentially be used for the file name.; https://gist.github.com/Svidro/5e4c29630e8d2ef36988184987d1028f#file-export-detections-per-annotation-groovy. Note that this is very slow and poorly written :) It would be much more elegant to write out the detection measurements that had already been created by using getChildObjects... but this was something I could easily do!. Good luck and let me know if you have any questions.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/234#issuecomment-432762268:39,detect,detections,39,https://qupath.github.io,https://github.com/qupath/qupath/issues/234#issuecomment-432762268,3,['detect'],"['detection', 'detections', 'detections-per-annotation-groovy']"
Safety,This is as opposed to reporting it as an error.; See https://forum.image.sc/t/how-to-measure-the-staining-intensity-without-positive-cell-detection/66847/12,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1003:138,detect,detection,138,https://qupath.github.io,https://github.com/qupath/qupath/pull/1003,1,['detect'],['detection']
Safety,"This is intended behavior rather than a bug, although I'm not sure if it is the *right* intended behavior. The ability to load points wasn't really intended for this purpose - rather, it's an easy way to exchange points with other software (e.g. someone writes a Python script and wants to visualize detected locations within QuPath). The current implementation is agnostic regarding whether a name or classification is set during export. The current *best* way to export/import annotations is using a method described at https://qupath.readthedocs.io/en/latest/docs/advanced/exporting_annotations.html (probably GeoJSON). This should preserve the class (if not, then that *would* be a bug). With that in mind, I don't know if it's better to 1) add complexity to the save/load command to support classes, or 2) remove those buttons altogether (since I suspect it is rarely used for its original purpose, and points can be loaded by scripting anyway). What do you think?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/410#issuecomment-597049593:300,detect,detected,300,https://qupath.github.io,https://github.com/qupath/qupath/issues/410#issuecomment-597049593,1,['detect'],['detected']
Safety,"This is kinda related but probably deserves it's own question. But I was wondering if there was a way to show the child objects inside the viewer for Tiles?. Here is a picture of my object hierarchy and current viewer:; ![children objects of tiles are not shown in viewer](https://user-images.githubusercontent.com/28576964/185491229-dc4943de-b770-4f1f-8117-7141399bee4f.png). I want all the children objects (which are detections/tiles) to be shown inside each tile:; ![selected children objects of tiles are not shown in viewer](https://user-images.githubusercontent.com/28576964/185491329-3c2123ad-214e-41ba-b8f3-787496c100ea.png). I tried changing child objects from tiles to detections, but they won't show in the viewer unless I click on each of the children individually. Is there a setting I am missing to show all child objects inside of tiles?. Thank you again for your help. EDIT: Actually this works fine after reloading the data. Sorry, you can ignore this.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1043#issuecomment-1219943848:420,detect,detections,420,https://qupath.github.io,https://github.com/qupath/qupath/pull/1043#issuecomment-1219943848,2,['detect'],['detections']
Safety,"This is somewhat by design (in that the command history only logs things that are relevant to batch processing, and generally avoids GUI-related commands for showing/hiding things). Nevertheless, certainly there needs to be some way to script either the display or export of annotation measurements.... and currently there isn't. My feeling is that whenever you run *Show Annotation Measurements* this shouldn't be recorded (because it's purely a display thing, which shouldn't happen in a batch script), but if you press *Save* then the export of the annotation measurements should be recorded in the command history. What do you think? Would this do what you need, or do you think it's also necessary to be able to script showing the table as well?. In the meantime, my way to handle needing to run the same interactive command repeatedly across multiple images in a project is to open the images one at a time while keeping keep *View &rarr; Show command list* open, and turning off the *Auto close* option. It's not optimal, but at least that way there's no need to return to the menus too often. ![command_list](https://cloud.githubusercontent.com/assets/4690904/20482972/917901e2-afe7-11e6-9474-1818edb79985.png)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/25#issuecomment-261927806:126,avoid,avoids,126,https://qupath.github.io,https://github.com/qupath/qupath/issues/25#issuecomment-261927806,1,['avoid'],['avoids']
Safety,"This is the macro shown above, included as an example:; ```java; /*; * ImageJ macro to apply an automated threshold to detect a single region.; * You will need to return the active Roi to see the results in QuPath.; */. // Define method (e.g. ""Triangle"", ""Otsu""...); method = ""Otsu"";. // Check if the image has a property specifying a dark background; // Override this by setting the value to true or false; if (Property.get(""qupath.image.background"")==""dark""); darkBackground = true;; else; darkBackground = false;. // Ensure 8-bit grayscale; resetMinAndMax();; run(""8-bit"");. // Create Roi from threshold; if (darkBackground); setAutoThreshold(method + "" dark"");; else; setAutoThreshold(method);; run(""Create Selection"");; ```; This effectively makes it possible to apply any of ImageJ's auto thresholding methods to any region of an image (or the entire image) - adapting for brightfield or fluorescence based on the image type. The resolution and channel can be specified from within QuPath's UI when the region is being sent.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1682#issuecomment-2425148249:119,detect,detect,119,https://qupath.github.io,https://github.com/qupath/qupath/pull/1682#issuecomment-2425148249,1,['detect'],['detect']
Safety,"This is to avoid the current `JavadocViewer -> JavadocViewerCommand -> JavadocViewer` chain of objects, with the same class name in both `qupath.ui.javadocviewer.gui.viewer` and `qupath.lib.gui`. See https://github.com/qupath/javadoc-viewer/pull/6",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1562:11,avoid,avoid,11,https://qupath.github.io,https://github.com/qupath/qupath/pull/1562,1,['avoid'],['avoid']
Safety,"This is useful for cases when StarDist is used to bootstrap a nucleus annotation project, because it avoids any need for converting detections later.; If cell expansion is applied, the nucleus is added as a separate annotation below the expanded cell.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/728:101,avoid,avoids,101,https://qupath.github.io,https://github.com/qupath/qupath/pull/728,2,"['avoid', 'detect']","['avoids', 'detections']"
Safety,This isn't a bug - by default annotations created this way are 'locked' to reduce the risk of editing them accidentally. There is some more information about locking [here](https://github.com/qupath/qupath/wiki/Working-with-objects#editing--locking-objects). You can right-click on the image and choose *Annotations &rarr; Unlock* if you need to be able to edit a locked annotation.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/82#issuecomment-314169636:86,risk,risk,86,https://qupath.github.io,https://github.com/qupath/qupath/issues/82#issuecomment-314169636,1,['risk'],['risk']
Safety,"This isn't actually a bug... showing/hiding the names is an `overlay option`. These are not global, and none are persistent. They are like showing/hiding detections or annotations, which are also not persistent. There is probably an argument for making them persistent, but this gets tricky because multiple non-identical instances of [OverlayOptions](https://github.com/qupath/qupath/blob/42cedef3d9252f974f77d2af6d3d3445081406c9/qupath-gui-fx/src/main/java/qupath/lib/gui/viewer/OverlayOptions.java) can exist - in which case QuPath would need to distinguish between which options are persistent and which aren't. This would be doable, but would take a bit of thought. I don't really want to introduce several more persistent preferences at this stage, immediately before the stable release, when the current behavior is not actually buggy.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/499#issuecomment-632624472:154,detect,detections,154,https://qupath.github.io,https://github.com/qupath/qupath/issues/499#issuecomment-632624472,1,['detect'],['detections']
Safety,"This looks expected to me, and not a bug. The image will be opened using the server defined within the project. The script simply re-opens the same image using Bio-Formats. If you are generating a project, you can specify the *Image provider* to be Bio-Formats at that point, thereby avoiding the need to use the script at all.; https://qupath.readthedocs.io/en/latest/docs/tutorials/projects.html#add-images",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/658#issuecomment-754589459:284,avoid,avoiding,284,https://qupath.github.io,https://github.com/qupath/qupath/issues/658#issuecomment-754589459,1,['avoid'],['avoiding']
Safety,"This looks good and very useful! Nice touches with auto-updating the image name based on the delimiter, and auto-disabling the column include/exclude as needed :). Some small things:; * Beware invalid characters in the fields... if the filename contains commas, the entire table becomes shifted if exporting as .csv. It appears to work properly (at least in MS Excel) if the name is enclosed in ""inverted commas"". There are rules for this [here](https://en.wikipedia.org/wiki/Comma-separated_values#Basic_rules).; * Avoid including spaces when before/after the delimiter.; * Try to get the controls to align at the right, and fill the entire space at the bottom of the dialog. For example, for the combo boxes you'll need to set the max width to Double.MAX_VALUE and (assuming you're using a GridPane) some other grow/fill properties (I forget which).; * Rename 'Choose path' to 'Choose...' and 'Output File' to 'Output file' (for capitalization consistency), and add tooltip text to this row.; * Change 'Apply on' to 'Export type' or similar. Try adding 'Image' as an option, i.e. the root object, and perhaps also TMA cores. 'Image' should probably be the default.; * Add tooltip to the 'Output File' option (and rename to 'Output file' for consistency); * Fix the tooltip for 'Columns to exclude' (says 'include'); * Revise the javadocs for 'ProjectDialogs'; add for getSourceItems, and standardize for createImageChoicePane (i.e. use the `@param` tags). Not essential at this point, but after playing with it a bit I think there would be a way to improve the control even further: the choice of columns could be a CheckComboBox, which is populated *if* the user presses a *Populate* button. This needs to be an explicit choice, because it would require opening all the currently-selected images to figure out which column headings are available... and this may be slow. Perhaps not worth the effort for now, having this at all will be a major improvement!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/425#issuecomment-606125263:516,Avoid,Avoid,516,https://qupath.github.io,https://github.com/qupath/qupath/pull/425#issuecomment-606125263,1,['Avoid'],['Avoid']
Safety,"This makes `ContourTracing` much faster in some circumstances - especially when labeled images were involved. There are two main differences:; 1. Previously, the code would tend to loop through all pixels to generate the contour for each label; now it generates bounding boxes in a single loop, and then iterates only through the relevant bounding box for each label (when using `createROIs`); 2. The tracing algorithm has been replaced by a reliance on JTS's `Polygonizer` class; this was already used before, but now we rely on it more heavily. The second of these makes this *slightly* risky - I encountered exceptions and infinite loops along the way, so this needs to be tested very carefully.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1520:589,risk,risky,589,https://qupath.github.io,https://github.com/qupath/qupath/pull/1520,1,['risk'],['risky']
Safety,"This makes it possible to have more informative messages during processing, so that the user knows what is happening along the way (e.g. 'Detecting', 'Processing', 'Measuring'). PixelProcessor updated to use this to record the number of tiles being processed.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1650:138,Detect,Detecting,138,https://qupath.github.io,https://github.com/qupath/qupath/pull/1650,1,['Detect'],['Detecting']
Safety,"This relates to https://github.com/qupath/qupath/issues/1634. Because CUDA detection and PyTorch downloading is all performed by DeepJavaLibrary, we are very limited in what we can do on the QuPath side. Then there is the issue of how Java loads native library dependencies - and especially the platform-specific fun of how *sub*-dependencies are handled. And the potential interference of environment variables or other things that could be installed. It is, in short, hard. The page on the docs is currently our best 'general' approach to help with this, based on many hours trying to find something workable across computers: https://qupath.readthedocs.io/en/stable/docs/deep/gpu.html#gpu-support. We will continue to try to improve this, but I'll close the issue because I don't think there is any clearly-defined QuPath bug here that we can address. To try to avoid fragmenting the discussion in multiple places, I suggest posting on the forum. There are more users active on the forum who might potentially be able to help from their own experience, and there are already some related discussions, e.g. https://forum.image.sc/search?q=qupath%20gpu%20order%3Alatest",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1636#issuecomment-2346013057:75,detect,detection,75,https://qupath.github.io,https://github.com/qupath/qupath/issues/1636#issuecomment-2346013057,2,"['avoid', 'detect']","['avoid', 'detection']"
Safety,This requires:; * recording its use in the *Command history*; * easier scripting to create objects / apply classification; * easier export of predictions,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/463:142,predict,predictions,142,https://qupath.github.io,https://github.com/qupath/qupath/issues/463,1,['predict'],['predictions']
Safety,"This revises the approach in https://github.com/qupath/qupath/pull/1659 in the latest attempt to fix https://github.com/qupath/qupath-extension-omero/issues/25. ## Purpose. With this PR, RGB images that are set to have the type 'Fluorescence' now behave much more similarly to non-RGB images, and it is possible to set both channel names and colors. However all the other image type options remain, e.g. Brightfield H&E. If one of these is selected, then all channel name/color customisations are ignored - and the image behaves as a regular RGB. ## Risks & assumptions; * Querying channel names & colors for an RGB `ImageServer` is no longer guaranteed to return `Red`, `Green` or `Blue`; * Custom channel names for an RGB `ImageServer` are also not guaranteed to be represented in the viewer; rather, this only occurs if the image type is `Fluorescence`; * This does *not* provide a way to convert a BGR image to RGB from the perspective of any analysis. `ImageServer.readRegion()` requests should still return the same packed int (A)RGB image as before - the main difference is how things are rendered in the viewer.; * A pixel classifier that is trained on an image with custom RGB channel names will only work on an image with the same custom channel names*. > *-Caveat: this can give unexpected results if a pixel classifier is applied to two RGB images exist in a project, and one has different channel names. Then, if the classifier is applied successfully to one image, it can *appear* to work on the second image because cached tiles are used - so the mismatched channel names are not identified. ## Example. Example using the ImageJ 'Fluorescent Cells' image, flattened to RGB. ### Image type set to 'Fluorescence', channels adjusted; ![RGB-fluorescence](https://github.com/user-attachments/assets/d1118dc8-a661-4129-a0ec-9fab28550a31). ### Same image with type set to 'Other'; ![RGB-Other](https://github.com/user-attachments/assets/8e44ada9-33e5-4b54-8f0b-695c5849edfb)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1669:550,Risk,Risks,550,https://qupath.github.io,https://github.com/qupath/qupath/pull/1669,1,['Risk'],['Risks']
Safety,"This was causing trouble in https://forum.image.sc/t/how-can-display-more-than-one-images-in-qupath-viewer-using-scripting/96156/ initially because the width and height here zero, leading to an infinite downsample value... and persistent JavaFX complaints upon all interactions with the viewer. This happened when setting the viewer grid size and then *immediately* setting the image in the viewer; somehow this resulted in wrong values being calculated, and a non-invertible AffineTransform that caused trouble indefinitely. The workaround here avoids many repeated exceptions, although still results in the image being opened at full resolution rather than the expected (fitted) downsample.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1521:546,avoid,avoids,546,https://qupath.github.io,https://github.com/qupath/qupath/pull/1521,1,['avoid'],['avoids']
Safety,"This was the WatershedCellDetection, for some reason, I have gotten this type of tiling variability on ~10% of my files. . setImageType('UNSET');; setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; runPlugin('qupath.imagej.detect.tissue.SimpleTissueDetection2', '{""threshold"": 235, ""requestedPixelSizeMicrons"": 20.0, ""minAreaMicrons"": 10000.0, ""maxHoleAreaMicrons"": 1000000.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}');; runPlugin('qupath.imagej.detect.nuclei.WatershedCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 50.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; runClassifier('/Users/elijahedmondson/Desktop/Projects/MetH/classifiers/MetH.qpclassifier');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/80#issuecomment-305265833:428,detect,detect,428,https://qupath.github.io,https://github.com/qupath/qupath/issues/80#issuecomment-305265833,3,['detect'],"['detect', 'detectionImageBrightfield']"
Safety,TileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.lib.images.servers.CroppedImageServer.readRegion(CroppedImageServer.java:90); at qupath.lib.images.servers.CroppedImageServer.readRegion(CroppedImageServer.java:39); at qupath.lib.images.servers.SparseImageServer.readTile(SparseImageServer.java:265); at qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:863); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:902); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:216); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by null at java.base/java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(Unknown Source); at java.base/java.util.concurrent.locks.ReentrantLock.lockInterruptibly(Unknown Source); at java.base/java.util.concurrent.ArrayBlockingQueue.put(Unknown Source); at qupath.lib.images.servers.bi,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583:1890,detect,detect,1890,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583,1,['detect'],['detect']
Safety,Tissue detection using structure information,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/657:7,detect,detection,7,https://qupath.github.io,https://github.com/qupath/qupath/issues/657,1,['detect'],['detection']
Safety,"To answer your question, when I do the debug seting in imagej I can se ethat the threshold fails quite extremely. Perhaps it's becasue the threshold expects a light image on a dark bkrd. Or, it could be due to the other channels in my image, some of which are extremely noisy and really ought to be excluded from the threshold calculation. I think it would be useful if we could perform simple processing (brightness/contrast) on the core image before it's sent to imJ for core detection.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/196#issuecomment-411736810:478,detect,detection,478,https://qupath.github.io,https://github.com/qupath/qupath/issues/196#issuecomment-411736810,1,['detect'],['detection']
Safety,"To clarify, since you know more coding than I do, you are replacing an ROI of the exact same coordinates with a pathCellObject.; Here is the code from somewhere on the forum: https://gist.github.com/Svidro/5829ba53f927e79bb6e370a6a6747cfd#file-change-annotations-into-cell-objects-groovy. That script is designed to target second ""level"" annotations as it was written to ignore the top level annotation and convert hand drawn annotations within into cells. You will probably want to change line 8:. `def targets = getObjects{return it.getLevel()!=1 && it.isAnnotation()}`. to use something like ""getAnnotationObjects()"" if you do not have any annotation hierarchy.; If your area is too large, the subcellular detection may fail (it will be obvious if it happens, you get no segmentation). I have had it work successfully over very large areas, but on a whole slide, I had to create subdivisions. I am not 100% sure what the limits are. If you run into that problem, you could also create your annotation area, tile it, and then convert the tiles into cells.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/67#issuecomment-392080198:709,detect,detection,709,https://qupath.github.io,https://github.com/qupath/qupath/issues/67#issuecomment-392080198,1,['detect'],['detection']
Safety,"Trying to run v0.2.0m10 with the Google Cloud Healthcare API extension installed crashes ""silently"" QuPath. This is so because the extension has not been adapted to the new QuPath API, but one needs to look at the logs (or manually run java to get them on the CLI) to figure out. I think we could improve this by:; - Being resilient to extension errors at start time and list problematic ones with suggestions of how to look for help.; - Maybe introducing some sort of protocol for extensions to check if they are compatible with current QuPath (although this likely would add some overhead to extension maintainers). I see this would actually be a ""soft"" restriction asking the user whether to disable an extension or run it at her own risk.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/454:737,risk,risk,737,https://qupath.github.io,https://github.com/qupath/qupath/issues/454,1,['risk'],['risk']
Safety,"Unable to adjust/set max memory in QuPath, either in 0.1.2 or 0.2.0-m2. Running analysis on cell files fails, does not detect cell direction or anything. This still does work on v 0.1.1 with 0.50GB set... Steps to reproduce the behavior:; 1. Go to Help > Show Setup Options; 2. Change Maximum memory from the default of 1 to any number (computer has 32GB avail); 3. Click Apply; 4. Close QuPath and reopen; 5. Go to Help > Show Setup Options; still shows ""current maximum memory is 0.48GB (v 0.1.2) or 0.50GB (v 0.2.0-m2). **Expected behavior**; Expect Max memory to change to what was set. Installed on a separate computer and Max was set without issue. Verified in 0.2.0-m2 that the .cfg file does change each time, however it still only displays ""0.50GB"". **Screenshots**; ![image](https://user-images.githubusercontent.com/51007080/58358449-cc728580-7e33-11e9-9c66-5ec6cd67bb9a.png). ![image](https://user-images.githubusercontent.com/51007080/58358462-da280b00-7e33-11e9-9897-0bf811ddfa88.png). ![image](https://user-images.githubusercontent.com/51007080/58358468-deecbf00-7e33-11e9-9233-f658233afbcb.png). **Desktop (please complete the following information):**; - OS: Windows 10 Enterprise x64, latest build; - QuPath Version 0.1.2 & 0.2.0-m2. **Additional context**; It's possible this is occurring due to multiple upgrades. This computer looks like it was upgraded from Win 7 to Win 8 to Win 10, or just one of those to Win 10 (inherited support on this one). Also running Leica imaging software. Will most likely try a fresh re-install of the OS at this point to rule that out.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/321:119,detect,detect,119,https://qupath.github.io,https://github.com/qupath/qupath/issues/321,1,['detect'],['detect']
Safety,Unfortunately I only have a linux system... Does the ome.tif from the attached tar.gz in https://github.com/libvips/libvips/issues/3397 look fine in those viewers (exported with QuPath)? . Perhaps the image is exported differently on linux or maybe those viewers are able to detect and correct it.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1254#issuecomment-1481590484:275,detect,detect,275,https://qupath.github.io,https://github.com/qupath/qupath/issues/1254#issuecomment-1481590484,1,['detect'],['detect']
Safety,"Unless you can automate detection of the tumor area by texture for each (in which case you can handle every image independently anyway), I can't think of an easy way to do that with un-adjusted images within QuPath unless you already knew the X-Y shift and rotational angle change each time. That said, there is software out there that can automatically align whole slide samples, though this can often be a time consuming process (depending on the resolution/computer speed/etc). . This thread has some additional info: https://groups.google.com/forum/#!searchin/qupath-users/slidematch%7Csort:date/qupath-users/XNdaWK_9Ex4/-w8T4cqGBAAJ; and some other recommended free software: https://groups.google.com/forum/#!searchin/qupath-users/slidematch%7Csort:date/qupath-users/VLJL6UCXqEk/c9j-RCMVBAAJ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/171#issuecomment-384084486:24,detect,detection,24,https://qupath.github.io,https://github.com/qupath/qupath/issues/171#issuecomment-384084486,1,['detect'],['detection']
Safety,"Update logic related to reading/importing images, to try to have fewer errors and more informative messages logged when errors do occur. ## Improve checks for Bio-Formats image support. Throw an exception if unable to read a single pixel from a Bio-Formats image.; Accessing the pixel may introduce some overhead when importing images, but it avoids problems where metadata can be parsed yet the fact the image can't actually be read only becomes apparent later. This was causing trouble with .ndpi on Apple Silicon, because skipping the use of NDPIReader was causing a fallback to a regular TIFF reader... and this didn't recognize the image as pyramidal and couldn't read the pixels. So requesting Bio-Formats for .ndpi was both adding many (~12) images to a project (for the different pyramid levels), and not actually able to open them. Also fix the logic for determining which IFormatReader is used for a specified image. This was previously giving ImageReader rather than the specific reader, and therefore wasn't properly enabling the reader check to be skipped for readers generated in other threads. This also had an extra issue in Apple Silicon, because these checks could cause exceptions regarding unsupported libraries being logged, even if they weren't relevant to the image itself. ## Improve use of json with image servers. Make `JSONImageServerBuilder` genuinely useful by enabling it to read the server.json files stored within projects. This could potentially help in the future if attempting to recover data from a broken project. This involves estimating the ""builderType"" since that wasn't actually serialized within the server.json before. To simplify things in the future, the server.json now serializes the `ImageServer` and not the `ServerBuilder` - so that more information is present.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1402:343,avoid,avoids,343,https://qupath.github.io,https://github.com/qupath/qupath/pull/1402,2,"['avoid', 'recover']","['avoids', 'recover']"
Safety,"Update to use JTS 1.19.0. Introduce `-Djts.overlay=ng` by default.; Lots of evidence on the forum that this resolves thorny TopologyExceptions.; See https://forum.image.sc/t/stardist-error-message-topologyexception/67708/7 for more info. Avoid calling `geom.intersection(g)` twice in `RoiTools.clipToROI(ROI, Collection)`, which caused problems with OverlayNG.; This should fix https://github.com/qupath/qupath/issues/996",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/998:238,Avoid,Avoid,238,https://qupath.github.io,https://github.com/qupath/qupath/pull/998,1,['Avoid'],['Avoid']
Safety,"Upon further reflection, my understanding is that you likely ran positive cell detection in a ROI that was the 'parent object' for the negative point class - but not the positive class - which is why the negative points only disappeared*. When you run cell detection with a 'parent object' selected, then any 'child objects' inside it will automatically be deleted, and replaced with the detected cells. This is *usually* the right/most intuitive thing that should happen, and is not a bug. If this didn’t happen, then you if ran the cell detection command twice with the same parent selected, you would end up having every cell counted twice - not to mention the strange things that might happen with overlapping objects if you were to run other tiling/superpixel commands. It's not clear to me what was the purpose of doing manual counts followed by automated counts within the exact same region, but (as you've found) it is something that is not supported. You *could* do it the opposite way (i.e. automated counts followed by manual counts). However, if it was my goal to compare manual and automated cell counting then I would do the automatic counts in duplicate project and keep the data separated. Furthermore, you can do automated counts and then select 'Convert detections to points' within the 'Points tool' to initialize the (manually-editable) points that can subsequently be modified to generate 'semi-automated counts'. With regard to being unable to reopen a data file, this is something that has been reported some months ago (e.g. #58), but I'm not aware of it being an ongoing problem - or at least not one I have ever been able to reproduce. If QuPath fails to write a complete data file, then you should find that a '.qpdata.backup' file exits somewhere inside your project/data folder. If you strip the '.backup' data part from the file name, then it should be possible to recover the last saved version. > *-Information about the object hierarchy is at https://github.com/qupath",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/112#issuecomment-342941759:79,detect,detection,79,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342941759,4,['detect'],"['detected', 'detection']"
Safety,"Use multiple lines to better handle long lists.; Also include only measurements in the measurement list of detections (rather than from the ObservableMeasurementTable), since these are the most important for copy/paste.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/766:107,detect,detections,107,https://qupath.github.io,https://github.com/qupath/qupath/pull/766,1,['detect'],['detections']
Safety,"Used for deep learning optimization (StarDist algorithm); 1. Download model in OpenVINO Intermediate Representation format:; [dsb2018_heavy_augment.zip](https://mega.nz/file/IY92FbjK#ppzuYyjdxp9lPLZ2J6BnN6bCUFeZkRgbbolT4cSMI6w); [he_heavy_augment.zip](https://mega.nz/file/1U1wmTYR#HFLXGNjoAS3WR3E64-g7K3QT58cBxbrAJci2iD0EMkE); INT8: [he_heavy_augment_int8.zip](https://mega.nz/file/NMsgzJgZ#JseSxOTcOeqQbG2X9p3W2e-CXgJ6KjC8n1cs4QS49mY); INT8: [dsb2018_heavy_augment_int8.zip](https://mega.nz/file/oAkFDKBA#ZjVP4f2Il_tcjsc0iywpVRXLLvh8lBkkAD3wJ7rDdmQ). Performance:. | Intel(R) Core(TM) i7-6700K | **Test image**: OS-3.ndpi<br>**Model**: he_heavy_augment<br>**Tile size**: 1024x1024<br>**Number of tiles**: 2183 | **Test image**: LuCa-7color_Scan1.qptiff<br>**Model**: dsb2018_heavy_augment<br>**Tile size**: 1024x1024<br>**Number of tiles**: 936 |; |---|---|---|; | TensorFlow backend | 23:05 minutes | 14:20 minutes; | OpenVINO backend | 15:28 minutes (x1.5) | 10:39 minutes (x1.36); | OpenVINO backend (INT8) | 12:29 minutes (x1.87) | 8:43 (x1.68); | OpenVINO backend (INT8) + NormalizePercentileOp | 11:55 minutes (x1.99) | 8:27 minutes (x1.7). Build with OpenVINO:; ```; ./gradlew clean build createPackage -Puse_openvino=true; ```. Use `build` argument to enable OpenVINO backend:; ```groovy; def stardist = StarDist2D.builder(pathModel); .threshold(0.5) // Prediction threshold; .normalizePercentiles(1, 99) // Percentile normalization; .pixelSize(0.5) // Resolution for detection; .build(""openvino"") // or ""tensorflow"" to use TensorFlow backend. If empty, use any available backend; ```",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/665:1364,Predict,Prediction,1364,https://qupath.github.io,https://github.com/qupath/qupath/pull/665,2,"['Predict', 'detect']","['Prediction', 'detection']"
Safety,"WOW!; Thanks for the great answer!; Unfortunately I am not currently at home; I was only able to test it on my notebook, which sometimes crashes.; Still, thanks to You I got a very good result:; https://i.imgur.com/3eaQ7s1.jpg; All the positive areas are detected and the % of positive staining in selected area is also calculated (the main idea is to show that the expression of positive staining changes depending on the cancers grade).; I will only be able to take an adequate try in a couple of days.; Anyway, I am very grateful!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/157#issuecomment-373134413:255,detect,detected,255,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-373134413,1,['detect'],['detected']
Safety,Weird resizing bug when clicking into / out of a dialog created from `ParameterPanelFX` (e.g. the default cell detection) caused the font to change. Spotted by @finglis,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1390:111,detect,detection,111,https://qupath.github.io,https://github.com/qupath/qupath/pull/1390,1,['detect'],['detection']
Safety,"Well, clearly I didn't actually read the error message, sorry... looks like it's OpenCV and not OpenSlide that seems to be triggering the trouble.; Could you replace `openslide` with `opencv` in those last instructions...?. Or if you are feeling particularly bold you could also try switching to the `java9` branch on my fork, where I am trying out a different version of OpenCV - which might possibly avoid the problem entirely.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/150#issuecomment-368861735:402,avoid,avoid,402,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368861735,1,['avoid'],['avoid']
Safety,"Well, you can avoid both reflection and scripting if you go to [QPEx](https://github.com/qupath/qupath/blob/6ebd4a296e05b89bca3466a14a7d7cf79eb3fad4/qupath-gui-fx/src/main/java/qupath/lib/gui/scripting/QPEx.java#L336).... but no absolute promises that won't be broken in the future either :). Ok, I will explain some more and hope it will be sufficient. QuPath is divided into modules. This modular design is a work-in-progress, but it is essential to keep the design coherent/improve it where possible. `ImageDisplay` requires JavaFX. That means that using it in *any* module will bring in a (quite huge) JavaFX dependency to that module. That means the core modules (which are currently completely ignorant of JavaFX) cannot use `ImageDisplay`... or they suddenly become dependent upon a whole host of other stuff. This is problematic if wanting to use some QuPath jars in other contexts in the future. Of course, `ImageData` exists in a core module. Currently, these means that if serializing the `ImageDisplay` inside the `ImageData`, the `ImageData` ends up storing a JSON version of something that it cannot possibly de-json-ify. This is tolerable, but not ideal. More critically, it also means that nothing in core modules can really work with the current display or channel settings. Perhaps they would like to, e.g. to export RGB image regions. Ideally this would not be restricted to modules that have JavaFX access. It also complicates things like the ImageJ macro runner... currently, this can either be free from JavaFX or capable of incorporating color transforms/channel info - but not both. There are good reasons to want both https://github.com/qupath/qupath/issues/68. Also, it means that changing the brightness and contrast ultimately requires deserializing/serializing the whole data file - which might be large. There are likely far better/more efficient/faster ways to store these settings in a project, not the data file. This would not only be arguably a a better design, but ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/26#issuecomment-632668731:14,avoid,avoid,14,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632668731,1,['avoid'],['avoid']
Safety,"When importing images to a QuPath project, there is a space to input arguments. Inserting `--no-crop` there will avoid using the OpenSlide bounds. I don't consider this to be a bug, because other software *already* handles the bounds differently. For example, I remember that QuPath started cropping by default because failing to do so gave different image dimensions when using Bio-Formats and OpenSlide. Cropping actually improved consistency, and removed enormous amounts of unnecessary whitespace. The original commit is at https://github.com/qupath/qupath/commit/52c9c32fa2add760d1338b1b81b2c0c6eed8908b. I think it would be more problematic and inconsistent if QuPath started exporting coordinates with a different origin for some images from that seen in the viewer, and then if there was a wish to import the regions in a project where Bio-Formats (rather than OpenSlide) was the default then it wouldn't be easy to identify or fix the problem. > Exports should be wrt. the original image dimensions, so that other SW can work with the data without OpenSlide dependency. That doesn't work for the reasons given above (i.e. at least one other very popular image-reading library will 'crop' at least some relevant formats automatically anyway). I'm curious as to what other software this causes an issue with that doesn't use OpenSlide. > Or, the offset information should be exported along with annotations. May be preferable, but would be awkward because the annotation export aims to follow the GeoJSON spec. Potentially all objects would need to store that info, or else they would need to be export as a `FeatureCollection` with an additional custom property. The second sounds preferably, but would remain very QuPath-specific.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1278#issuecomment-1630759354:113,avoid,avoid,113,https://qupath.github.io,https://github.com/qupath/qupath/issues/1278#issuecomment-1630759354,1,['avoid'],['avoid']
Safety,"When splitting annotations by lines, my expectation is that the thickness will usually be 0. Supporting different units risks increasing the code complexity considerably, because the command must also be scriptable and then somehow the units need to incorporated into any script. Additionally, QuPath is moving towards greater generality. It is increasingly used for images where µm is an inappropriate unit, so I'm reluctant to add additional code that assumes µm as the only alternative to pixels. And a properly generic system will take a lot more effort to develop (not helped by the fact that Java has no built-in support for converting units... it's a recurring theme, e.g. [here](https://jcp.org/en/jsr/detail?id=385), but as far as I'm aware there are a multiple implementations and it's not clear which, if any, we should use). This also affects the sparse image server: at the point the dialog is shown, we don't know if the pixel size is available in µm for the regions that will be required to generate the server. Furthermore, the dialog itself is [auto-generated from a `ParameterList`](https://github.com/qupath/qupath/blob/main/qupath-extension-processing/src/main/java/qupath/process/gui/commands/CreateTrainingImageCommand.java#L90), which limits the ability to toggle between units. Added to that, I'm not terribly happy with the generation of 'dynamic' training images generally; the code is really complex (since the images can be quite heterogeneous), and performance can be poor whenever many images need to be accessed to create the final result. Therefore I wonder if creating a new command that defaults to writing the image as a new file would be preferable anyway. I'll leave this open for a while in case there are further comments, but my feeling is that the development-and-maintainence-time-to-benefit ratio isn't favorable enough to work on this in the core QuPath software; there are too many higher priorities, and if I'd rather focus efforts on simplicity, maintain",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1407#issuecomment-1783782932:120,risk,risks,120,https://qupath.github.io,https://github.com/qupath/qupath/issues/1407#issuecomment-1783782932,1,['risk'],['risks']
Safety,"When trying to run the simple tissue detection for TMA, as suggested in the manual, it won´t work (the detection lines being either very coarse or not even touching the tissue of the TMA core) no matter how I change the settings. Could this be due to the yellowish background (whitespace) of my slide? How can I change this?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/53:37,detect,detection,37,https://qupath.github.io,https://github.com/qupath/qupath/issues/53,2,['detect'],['detection']
Safety,"When you run the *Estimate stain vectors*, it is good to have the smallest region selected that contains 'a bit of everything' (red staining, nuclei, background - although probably not the yellow pigment here). If the region selected is large, then QuPath will need to scale it down and then may give a less good estimate. You can also set individual stains manually by drawing very small rectangles around an area containing the stain, and then double-clicking the name of the stain under the *Image* tab. Ideally, a really good estimate would allow you to set a higher intensity threshold and still detect what you want - but not what you don't. However it is quite possible that no settings really achieve this. Since I understand you are looking at counts - and not intensity values - you *could* set the image type to be *Brightfield (other)* and then this activates the 'third' stain color. You could then set that based upon a small rectangle drawn in a yellow area. QuPath will then try to separate this as an extra stain. This will certainly negatively impact intensity measurements, and I'm not sure if it's a good idea. Nevertheless, the meaningfulness of intensity measurements in this kind of image is probably pretty limited anyway, so it is perhaps worth a try to see if it results in much better detection of what you can see by eye really should be detected. In the future, I'm wondering if it would be better to create a machine learning approach in QuPath for tasks like this, i.e. something more 'learn-by-example' (like with training the tumor/stroma cell distinction), rather than relying on color deconvolution. I think the current approach may be too simple, because there are always little anomalies or artefacts that can play havoc with trying to set a threshold for detection. What do you think? Are there any other changes/additions that would help here?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/146#issuecomment-368339801:601,detect,detect,601,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368339801,4,['detect'],"['detect', 'detected', 'detection']"
Safety,"When you save the classifier, QuPath really just saves what it needs to apply the classification - but it doesn't store all the information about where exactly the training information came from. That's why you aren't able to load the classifier again and update it... not enough information has been saved in the ```.qpclassifier``` file to make that possible. The ```.qpclassifier``` file should therefore be considered 'locked-down', since you can't really change that classifier again directly. Fortunately, so long as you've saved the data for each image as you went along (including your annotations), you can work around this. To do so, you start by creating a new detection classifier and starting to train it by adding annotations and setting their classifications on any image. Then if you open each of the images you previously annotated for training, QuPath will look for any annotated regions and (optionally) add them to the training as well. Using this approach, you end up with a whole new classifier - but it can be based on the old training, plus whatever you want to add. This is ok if you only used one or two images for training in the past, but it could be a bit annoying if you annotated lots of images in a project. In this case, there is a shortcut that you can use. Click on *Advanced options* in the *Create detection classifier* window and select the ```More...``` button on the right. If you choose *Rebuild training from project* QuPath will then loop through *all* the images in the project and use any annotations it finds to train the new classifier. For your other question, the classifier is applied across the entire slide that is currently open - so that means that the classification will be updated for all TMA cores that are on the current slide (but *not* TMA cores that are on a different slide!). When you train the classifier and open a new image, you have the option to retain your training (i.e. continue to build a classifier, using all the information f",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/57#issuecomment-288491139:672,detect,detection,672,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288491139,1,['detect'],['detection']
Safety,"Whenever everything is classified as positive, it usually means the wording is not quite right in the description of the feature (which is going to be from your example, not the script). For example, if I change my fluorescent example to read ""Surbcellular:"" all of my spots become classified as 15+. For your brightfield images, it is probably something like Subcellular: DAB: etc. If you have trouble getting it just right, you can try using:; https://gist.github.com/Svidro/5e4c29630e8d2ef36988184987d1028f#file-print-a-list-of-detection-object-measurements; It will print out a list in your script window which you can directly copy and paste. Edit: I also fixed an incorrect ""pathCellObject"" that was in the Gist version of the script. Oops.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/146#issuecomment-366458274:531,detect,detection-object-measurements,531,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-366458274,1,['detect'],['detection-object-measurements']
Safety,"While there is still no way to classify easily by intensities through the GUI, starting from [v0.1.2](https://github.com/qupath/qupath/releases/tag/v0.1.2) several new functions make it very easy by scripting, e.g. [this one](https://github.com/qupath/qupath/blob/master/qupath-core-processing/src/main/java/qupath/lib/scripting/QP.java#L1156). For example, to classify all cells as negative, 1+, 2+ or 3+ according to nuclear DAB staining, you may use; ```groovy; setCellIntensityClassifications(""Nucleus: DAB OD mean"", 0.2, 0.4, 0.6); ```. Or to classify cells as positive or negative after running the new subcellular detection command, you could try; ```groovy; setCellIntensityClassifications(""Subcellular: DAB: Num spots estimated"", 2.5); ```. Finally, a more sophisticated example where the classifications for all cells are first reset, and then a reclassification according to intensity for tumor cells applied:; ```groovy; // Reset all existing intensity classifications; resetIntensityClassifications(). // Select all tumor objects; def tumor = getPathClass(""Tumor""); def tumorObjects = getObjects({p -> tumor.isAncestorOf(p.getPathClass())}). // Apply intensity classification; setIntensityClassifications(tumorObjects, ""Nucleus: DAB OD mean"", 0.2, 0.4, 0.6). // Fire an update event to see the results; fireHierarchyUpdate(); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/16#issuecomment-269880806:621,detect,detection,621,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-269880806,1,['detect'],['detection']
Safety,"With QuPath v0.2.0, I am having an issue with loading a detection classifier. The classifier is obtained from https://github.com/acsbal/Automated-TIL-scoring-QuPath-Classifier-for-Melanoma. When I try to locate and load the classifier, the classifier window doesn't show anything. With QuPath v0.1.2 this feature works as it should. Please advise.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/402:56,detect,detection,56,https://qupath.github.io,https://github.com/qupath/qupath/issues/402,1,['detect'],['detection']
Safety,"Would it be possible to allow all 3 stain vectors in Brightfield Other regardless of what they are named? Occasionally I have wanted to detect Hematoxylin within more complex samples as well, though I can get away with renaming it Htx. The logic isn't listed anywhere other than the code, so anyone else trying to get Hematoxylin subcellular detections in a 3-4 color brightfield image could struggle. Also, I _think_ black was actually the residual channel (there was a large amount of silver stain in the image), I renamed it thinking that I might get around ignoring the residual channel that way. If the program can somehow tell that was the residual channel without the name Residual or being in the 3rd position, that might have been it.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/304#issuecomment-518018293:136,detect,detect,136,https://qupath.github.io,https://github.com/qupath/qupath/issues/304#issuecomment-518018293,2,['detect'],"['detect', 'detections']"
Safety,"Wow, thanks, that replicates the issue for me too. This sounds like a bug / intuitive behavior within the Delaunay triangulation. It's concerning that measurements can be added multiple times to the same objects. It suggests that the results might not be fully deterministic, depending upon the status of the object hierarchy and precisely which annotations are selected. I'm reluctant to fix the underlying issue in a 0.0.x release, but we should try to replace the command entirely. An implementation with [`DelaunayTools`](https://github.com/qupath/qupath/blob/df81345068455f09f42f50e97dc7b69a591e27f7/qupath-core/src/main/java/qupath/lib/analysis/DelaunayTools.java#L77) should be cleaner than the current OpenCV-based one. **As I understand it, this shows that the existing Delaunay command should not be used for nested annotations that contain detections.**. Single annotations, or annotations arranged in a 'flat' way (so that the same detection is not a descendent of more than one selected annotation) should be ok.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1444#issuecomment-1943698902:851,detect,detections,851,https://qupath.github.io,https://github.com/qupath/qupath/issues/1444#issuecomment-1943698902,2,['detect'],"['detection', 'detections']"
Safety,"Yeah, I didn't come across that myself yet trying a few images, are we using a version of JTS that at least has the exception code to avoid infinite loops?. Aside from style it all looks good and correct to me, but I wouldn't necessarily use that as strong evidence that it is :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1520#issuecomment-2104178205:134,avoid,avoid,134,https://qupath.github.io,https://github.com/qupath/qupath/pull/1520#issuecomment-2104178205,1,['avoid'],['avoid']
Safety,"Yeah, I don't think it's possible without boxing - and better to avoid that. Although since they aren't identical, could you add a corresponding test for the doubles function?. It would also be good to extend the test to handle different channels... One a good way to do that is to create an RGB `BufferedImage` and then draw onto it with `Graphics2D`, after setting the foreground color to be `Color.GREEN` (for example). Similar code is at https://github.com/qupath/qupath/blob/67a1ed7ead8e28c54d120b21d08b7d41562eb8c3/qupath-core/src/test/java/qupath/lib/awt/common/TestBufferedImageTools.java#L176 but the type should be `BufferedImage.TYPE_INT_ARGB`. Sorry to keep adding more, but I think the code is looking good - and it'll be nice to have it more well-tested than many other methods.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1319#issuecomment-1711869385:65,avoid,avoid,65,https://qupath.github.io,https://github.com/qupath/qupath/pull/1319#issuecomment-1711869385,1,['avoid'],['avoid']
Safety,"Yeah, I was over-enthusiastic in converting `Collectors.toList()` to simply use `toList()` when updating to Java 17 - this problem has emerged a few times. See https://github.com/qupath/qupath/commit/1710f51e7846b9b85367da2a716a8b67c8805e92 for more info. The reason I didn't just undo it is that `Collectors.toList()` *also* seems to be wrong - at least inasmuch as it makes no guarantees of mutability: https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/stream/Collectors.html#toList(); So the fact it worked previously was kind of incidental or accidental. Therefore my thinking was that we could stick with `Stream.toList()` where that works, and then where mutability is required we use instead; ```java; stream.collect(Collectors.toCollection(ArrayList::new)); ```. I hadn't spotted this as a failure case, so we certainly should change it - but I think better to make the change that explicitly generates an `ArrayList` to avoid relying upon the happenstance of `Collectors.toList()` being mutable.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1282#issuecomment-1648260545:950,avoid,avoid,950,https://qupath.github.io,https://github.com/qupath/qupath/pull/1282#issuecomment-1648260545,1,['avoid'],['avoid']
Safety,"Yeah, I'm not generally a fan of very dockable UIs myself... and there's no native JavaFX support. Lots of docking makes me thing of complex IDEs, which I'd expect only a minority of QuPath users to feel comfortable with (I'm not sure if I'm even one of them, and I use complex IDEs all the time). An entire UI overhaul is certainly a good idea, but much more long term - I'm thinking here about stuff we could do within the next couple of weeks that would meaningfully improve the UX. Meanwhile, the PR shows me there are definite bugs with my proposed approach - at least when it comes to stuff like cell detection, when windows change focus before the processing is complete. The fact that is broken suggests the underlying code to run parallel tasks ought to be strengthened though, so I'm tempted to persist a bit longer with the PR - irrespective of whether we end up exposing the 'detachable viewer' part through the UI or not.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1317#issuecomment-1709739777:607,detect,detection,607,https://qupath.github.io,https://github.com/qupath/qupath/issues/1317#issuecomment-1709739777,1,['detect'],['detection']
Safety,"Yeah, I'm working with the detection measurements in R and can calculate IQR on those, but I was interested in the cell by cell pixel IQR values.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/236#issuecomment-433480694:27,detect,detection,27,https://qupath.github.io,https://github.com/qupath/qupath/issues/236#issuecomment-433480694,1,['detect'],['detection']
Safety,"Yep, just counting the direct children, one level below the annotation.; ![image](https://user-images.githubusercontent.com/23145209/51791450-15e9e700-2158-11e9-9eb8-18eb6b59e11e.png). Kinda shows it as well. Almost every annotation has one child annotation. Except one of the lowest ones, and some of those have 0 children. It doesn't matter if the objects are cells, it just counts direct child objects. Which is nice, since it prevents subcellular detections from being counted! That could get crazy.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/259#issuecomment-457855609:451,detect,detections,451,https://qupath.github.io,https://github.com/qupath/qupath/issues/259#issuecomment-457855609,1,['detect'],['detections']
Safety,"Yes - If I run the cell detection within each core (instead of within the annotation) then the core name is in the txt export. Thanks.; There are a couple of reasons that I would want to know which single cells are within my annotations, so the hierarchy export would be a useful enhancement in the future. ; Overall, great work!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/59#issuecomment-289692872:24,detect,detection,24,https://qupath.github.io,https://github.com/qupath/qupath/issues/59#issuecomment-289692872,1,['detect'],['detection']
Safety,"Yes, I did run into some of the same problems with the external measurements since the ImageJ macro runner takes squares, not the actual annotation. The advantage here is QuPath's heriarchy system, where everything ""outside"" of the annotation will show up separately (not underneath in the tree), and can be selected and deleted. Probably easier to do this after you go to the annotations tab, CTRL-A (or whatever to select all) and then go to the Objects menu and ""Merge annotations."" Then you get only one annotation and all of the external detections in the Hierarchy tab. This makes it easy to once again select all, deselect your annotation, and delete all of the ""outside"" detection areas. Downside, merging all of the tiles does NOT actually do what you might hope, and mesh them all into one contiguous annotation. It does add them all together, however, which lets you use the show annotation measurements to see the sum totals of all of your annotation tiles. You will see better after you do it once.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/56#issuecomment-286849866:543,detect,detections,543,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286849866,2,['detect'],"['detection', 'detections']"
Safety,"Yes, in a project, start from LuCa-7color_[17572,60173]_3x3component_data.tif, define two annotations with the Region class like this:; ![Screenshot from 2024-02-29 15-14-35](https://github.com/qupath/qupath/assets/60394504/b5c78607-282b-403f-9296-ace2af0a91ad). Then Classify, Training Images, Create Training images, default parameters, and it creates this image:; ![image](https://github.com/qupath/qupath/assets/60394504/1741642f-d89b-4790-bc4f-0fe5130a80c9). Then this script throws the error:. ```groovy; setImageType('FLUORESCENCE');; selectAnnotations();; runPlugin('qupath.imagej.detect.cells.WatershedCellDetection', '{""detectionImage"":""DAPI"",""requestedPixelSizeMicrons"":0.1,""backgroundRadiusMicrons"":4.0,""backgroundByReconstruction"":true,""medianRadiusMicrons"":1.0,""sigmaMicrons"":2.5,""minAreaMicrons"":11.0,""maxAreaMicrons"":400.0,""threshold"":1000.0,""watershedPostProcess"":true,""cellExpansionMicrons"":5.0,""includeNuclei"":true,""smoothBoundaries"":true,""makeMeasurements"":true}'); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1465#issuecomment-1971362682:589,detect,detect,589,https://qupath.github.io,https://github.com/qupath/qupath/pull/1465#issuecomment-1971362682,2,['detect'],"['detect', 'detectionImage']"
Safety,"Yes, it will try to select the object you already have created. If you want to draw within the annotation object (square) you have created, right click on it, drop down to Annotations, and select ""Lock."" Otherwise, it thinks you are trying to fill in the annotation you already have created. One way to see this is, with the annotation unlocked, hold down Alt and draw with the brush tool. You will see you are creating holes in your annotation now. One important thing to note when creating annotations within annotations, is that if your second brush tool annotation exits the first annotation, none of the detections within will be considered part of the brush tool annotation. This is probably most important when dealing with TMAs, because if the region you draw leaves the TMA circle, it is treated as being entirely outside!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/50#issuecomment-278506606:609,detect,detections,609,https://qupath.github.io,https://github.com/qupath/qupath/issues/50#issuecomment-278506606,1,['detect'],['detections']
Safety,"Yes, lots more things are package private now to try to trim things down and have fewer public things moving. The thinking with `ObjectMeasurements` is that it really should be tied to QuPath's built-in cell measurement command, since this is the only place it's currently used. But future cell detection commands deserve better measurements. Because the functionality is pretty limited, I'd suggest just copying the code into your own package if you want it. For similar functionality for other cell detection methods, I myself plan to use JTS - since this avoids ImageJ's need to rasterize things when making measurements. (Since this isn't a bug, I'd really rather use image.sc...)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/466#issuecomment-622346953:295,detect,detection,295,https://qupath.github.io,https://github.com/qupath/qupath/issues/466#issuecomment-622346953,3,"['avoid', 'detect']","['avoids', 'detection']"
Safety,"Yes, that is correct. Assuming you want to see what was detected, you'll need to use `writeImageRegionWithOverlay`. There's an example at https://gist.github.com/petebankhead/66e70e5deaa9c6e6a009ad027b135a0d",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/216#issuecomment-420282401:56,detect,detected,56,https://qupath.github.io,https://github.com/qupath/qupath/issues/216#issuecomment-420282401,1,['detect'],['detected']
Safety,"Yes, the trouble comes from the background estimate whenever a large region is broken up into tiles for processing. The technique QuPath is using to estimate the background is 'opening by reconstruction'; this starts out by estimating the background locally for every pixel, and then propagating this information throughout the tile. The propagation is helpful most of the time, since this handles cases where there may be quite a lot of texture in the background quite well; and usually it doesn't propagate very far. But it's not helpful all of the time... particularly where there are substantial differences in the amount of 'background' (or staining outside nuclei) within tiles and between neighboring tiles. So my suggestion would also be to either set the background radius very high, or set it to zero to turn off background estimation entirely. The second option is likely better if you can still find nucleus detection settings that work. Depending upon what you want to do next, you might also try the 'Fast cell counts' command. It is much simpler and does not provide nearly so much information, but it also does not handle background in the same way.... so gives an alternative.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/80#issuecomment-305385370:920,detect,detection,920,https://qupath.github.io,https://github.com/qupath/qupath/issues/80#issuecomment-305385370,1,['detect'],['detection']
Safety,"Yes, this is a known issue and intended behavior... but only because of a bug in OpenCV's Java bindings when QuPath was originally being developed, which meant any attempt to serialize a classifier was doomed to fail badly. Serializing the full training data and parameters required to rebuild the classifier was the only workaround I could find at the time. This is no longer a blocker thanks to updates in OpenCV and the switch to use JavaCPP. I've started to create entirely separate wrappers to support serializing/deserializing classifiers using JSON in the context of pixel classification. My proposed/intended fix is to use these with the detection classifier as well, but of course this will break backwards compatibility and I would therefore like to combine it with more thorough changes to how the detection classification works. Also, since the current approach is not critically broken I didn't want to start the task until everything was aligned to see it through to completion. Making the pixel classifier serializable/deserializable is a higher priority.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/343#issuecomment-515174436:646,detect,detection,646,https://qupath.github.io,https://github.com/qupath/qupath/issues/343#issuecomment-515174436,2,['detect'],['detection']
Safety,"Yes, this is important and should be addressed to avoid confusion. (I think _File &rarr; Revert_ can be used to 'update' the data by reading it from the [now changed] data file, but this isn't documented...)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/340#issuecomment-513528764:50,avoid,avoid,50,https://qupath.github.io,https://github.com/qupath/qupath/issues/340#issuecomment-513528764,1,['avoid'],['avoid']
Safety,"Yes, under the View → Zoom... → Zoom in/out is where I encountered the reverse behavior.; I am working on a Mac. From: Pete <notifications@github.com>; Reply-To: qupath/qupath <reply@reply.github.com>; Date: Monday, June 8, 2020 at 12:56 PM; To: qupath/qupath <qupath@noreply.github.com>; Cc: ""Kathleen T. Yee"" <KYee@umc.edu>, Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [qupath/qupath] Zoom In and Zoom Out (#518). I understand the issue is with the specific commands under View → Zoom... → Zoom in/out (I've tested only on a Mac, but assume the unexpected behavior is common across platforms - it was also weird in m10, but not v0.1.2... I didn't check any others). —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fissues%2F518%23issuecomment-640781128&data=02%7C01%7Ckyee%40umc.edu%7C96af0114123c4ccd238f08d80bd54a7d%7C78a0681ef0be47e280498616858818a5%7C0%7C0%7C637272357990082394&sdata=2kWkyYCdApiRUWM942pRiwOnNoXy8SWGjV0e%2FyE0DuE%3D&reserved=0>, or unsubscribe<https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAP4MNE5SPRUYX7RMNYZKOFTRVUQ5LANCNFSM4NYSD4CA&data=02%7C01%7Ckyee%40umc.edu%7C96af0114123c4ccd238f08d80bd54a7d%7C78a0681ef0be47e280498616858818a5%7C0%7C0%7C637272357990082394&sdata=pU%2BYSYbllDKbPfdTG%2FD921yLOmUpYsg0rDDoywDA3bE%3D&reserved=0>. Individuals who have received this information in error or are not authorized to receive it must promptly return or dispose of the information and notify the sender. Those individuals are hereby notified that they are strictly prohibited from reviewing, forwarding, printing, copying, distributing or using this information in any way.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/518#issuecomment-640783525:805,safe,safelinks,805,https://qupath.github.io,https://github.com/qupath/qupath/issues/518#issuecomment-640783525,2,['safe'],['safelinks']
Safety,"You are both correct. It’s a multi channel image, and some of the channels; are noisy. Secondly, in dev debug mode I can see that the initial threshold; fails. What should I do so that it just uses the red channel to find cores (I need; other colors downstream)?. On Mon, Aug 6, 2018 at 01:34 Pete <notifications@github.com> wrote:. > The Brightness/Contrast dialog shows there are 4 channels, but 3 are; > turned off; the TMA dearrayer won't be affected by which channels are; > turned on/off there though. For such images, it uses an average; > projection of all the channels; > <https://github.com/qupath/qupath/blob/v0.1.2/qupath-processing-ij/src/main/java/qupath/imagej/detect/dearray/TMADearrayerPluginIJ.java#L237>; > .; >; > It will most likely have correctly auto-set the image type as; > 'Fluorescence', but it's always worth checking under the 'Image' tab (in; > case this was changed / the auto detection of image type was turned off).; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/196#issuecomment-410631215>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AAcFTCZOP0VOb--7eOugusLtmVZlM1HUks5uN_-xgaJpZM4VvdxT>; > .; >; -- ; Rishi Rawat",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/196#issuecomment-410763976:676,detect,detect,676,https://qupath.github.io,https://github.com/qupath/qupath/issues/196#issuecomment-410763976,2,['detect'],"['detect', 'detection']"
Safety,"You can see the awkward way I do this on Windows via the link in my last post. Basically, as far as I can recall `System.loadLibrary` will check if a library is loaded, and if not then it will look on the Java library path for it. However if that library has a sub-dependency then the Java library path becomes irrelevant... and the search for sub-dependencies will be system dependent*. Therefore if you explicitly load the sub-dependencies first, they will already be available whenever `System.loadLibrary` is needed for the main library you wanted in the first place - and the less controllable, system-dependent search can be avoided. Somewhat inconveniently, in this case there are sub-dependencies and sub-dependencies of sub-dependencies... so figuring out the order in which they need to be loaded isn't entirely straightforward. It feels like there should be a far more elegant way to do this, but I haven't found it. *-This may mean searching in the directory from which QuPath was launched, so copying the library files there could be an easy workaround - I'm not entirely sure.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/355#issuecomment-527729451:631,avoid,avoided,631,https://qupath.github.io,https://github.com/qupath/qupath/issues/355#issuecomment-527729451,1,['avoid'],['avoided']
Safety,"You could try running the script below to brutally reset the histograms:; ```groovy; def display = getCurrentViewer().getImageDisplay(); display.cachedHistogramMaps.clear(); display.histogramMap.clear(); ```; It might help you avoid a restart, but I'm not sure...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/131#issuecomment-355843907:227,avoid,avoid,227,https://qupath.github.io,https://github.com/qupath/qupath/issues/131#issuecomment-355843907,1,['avoid'],['avoid']
Safety,"You may want to open a [forum ](https://groups.google.com/forum/#!forum/qupath-users)thread where you can show some examples. Most examples I have seen of identifying TILs in HE staining were using deep learning, but if you can figure out a way to identify them among the rest of your cells, you should be able to do it. Extracting the data into a single worksheet is fairly easy, and can been seen in the following two links:; https://petebankhead.github.io/qupath/scripting/2018/03/04/script-annotation-export.html; https://petebankhead.github.io/qupath/scripting/2018/03/05/script-annotation-results-merge.html. I generally use SLICs to classify sub-annotation areas, then merge them into annotations (after some smoothing) to separate out tissues for cell detection. Aand I got horribly distracted by laser problems and Pete beat me to it :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/262#issuecomment-458656502:760,detect,detection,760,https://qupath.github.io,https://github.com/qupath/qupath/issues/262#issuecomment-458656502,1,['detect'],['detection']
Safety,"You need an instance of [`PathClass`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core/src/main/java/qupath/lib/objects/classes/PathClass.java). *But*, you should never call the construction for `PathClass` directly. There is some explanation [here](https://groups.google.com/d/msg/qupath-users/44HBd-5nbaQ/VHbENs9TBAAJ). Something like this should work:; ```groovy; def tumor = getPathClass('Tumor'); def stroma = getPathClass('Stroma'); getAnnotationObjects().eachWithIndex { annotation , i ->; if (i % 2 == 0); annotation.setPathClass(tumor); else; annotation.setPathClass(stroma); }; fireHierarchyUpdate(); ```; But you can change the text to be whatever you want, rather than `Tumor` and `Stroma` (although probably best to avoid colons`:` in any name, since these are typically used to separate *sub*-classifications). Regarding finding available methods, I've just added a [blog post](https://petebankhead.github.io/qupath/scripting/2018/03/16/script-print-methods-and-fields.html) with a bit more info. If you are happy to use IntelliJ, that's probably easiest.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/158#issuecomment-373683258:737,avoid,avoid,737,https://qupath.github.io,https://github.com/qupath/qupath/issues/158#issuecomment-373683258,1,['avoid'],['avoid']
Safety,"You should get null for any tiles or annotations with no class set, and Tumor, or whatever class is set for any annotations with a set class. If the tiles do not have a class, they will return null. . If the tiles are detections, and have a parent annotation with a class name, you should be able to use something like for all detections, p= detection.getParent() followed by p.getPathClass() being assigned to a value in order to find out what the parent annotation's class was. I am not sure this works if you have converted all of the tiles to annotations (maybe it does!).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/62#issuecomment-293101449:218,detect,detections,218,https://qupath.github.io,https://github.com/qupath/qupath/issues/62#issuecomment-293101449,3,['detect'],"['detection', 'detections']"
Safety,"[OD](https://en.wikipedia.org/wiki/Absorbance) is usually used for brightfield images while intensity is used for fluorescence images due to the way the light is measured (how much passes through your sample versus how much is emitted). Sums and averages are exactly that based on all pixels, though usually applied to the detection area in question (a single SLIC, a single cell, or a single nucleus, etc). If you had a 2 pixel detection of 1 OD and 0.5 OD, it would have a OD sum of 1.5 and an average of 0.75. The distance value after the measurements using add intensity features determines how finely the features are calculated. Smaller values tend to take longer but be more accurate, and I almost always use my pixel size (height or width) for any _Add intensity features._. Smoothing, as far as I can tell, is a straight radius for inclusion, calculated from the centroid of the detection object to the centroid of all other detection objects. I tested this using the scale bar at 20um and two cells that were about 22um apart (center to center), and gradually expanded the radius until the smoothed features became a mix of the two (Nearby detection counts for each became 1). The radius is a hard limit, while the smoothing is applied over a FWHM gradient as mentioned in Pete's link. In that example, if the two cells were 22um apart and I performed a 22um smoothing, they would have less of an impact on each other's ""smoothed"" values than if they were only 5um apart. A cell with a centroid at 23um away would have 0 impact on another cell's measurements, while a cell that was 22um away would have about half of the impact of a cell that was almost right on top of the original cell. Every cell's smoothed features are calculated independently, imagine drawing a quick circle around each cell and calculating the smoothed features based on what centroids are inside that circle.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/185#issuecomment-404545796:323,detect,detection,323,https://qupath.github.io,https://github.com/qupath/qupath/issues/185#issuecomment-404545796,5,['detect'],['detection']
Safety,"\os\.OS-3.vsi.bfmemo `. The file was ; `D:\QMDownload\5\os\OS-3.vsi.bfmemo ; `. After a successful running, all the output was:; ```; 16:23:06.071 [main] [INFO ] qupath.QuPath - Launching QuPath with args: -image, D:\\QMDownload\\5\\os\\OS-3.vsi, -script, C:\\Users\\rmd\\AppData\\Local\\Temp\\tpd56d11ce_e4ba_481c_a046_3d19297b763a.groovy ; 16:23:06.151 [main] [WARN ] q.lib.images.servers.FileFormatInfo - Strange 'bits per sample' of 0 ; 16:23:06.211 [main] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1 ; WARNING: An illegal reflective access operation has occurred ; WARNING: Illegal reflective access by com.esotericsoftware.kryo.util.UnsafeUtil (file:/C:/Program%20Files/QuPath-0.2.0-m1/app/kryo-2.24.0.jar) to constructor java.nio.DirectByteBuffer(long,int,java.lang.Object) ; WARNING: Please consider reporting this to the maintainers of com.esotericsoftware.kryo.util.UnsafeUtil ; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations ; WARNING: All illegal access operations will be denied in a future release ; 16:23:07.141 [main] [WARN ] loci.formats.Memoizer - deleting invalid memo file: D:\QMDownload\5\os\.OS-3.vsi.bfmemo ; com.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 429; Serialization trace:; service (loci.formats.in.OperettaReader); readers (loci.formats.ImageReader); reader (loci.formats.DimensionSwapper); reader (loci.formats.FileStitcher); helper (loci.formats.in.FilePatternReader); readers (loci.formats.ImageReader) ; 	at com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:119) ; 	at com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:641) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:375) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:289) ; 	at com.esotericsoftware.kryo.Kry",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/287:1220,Unsafe,UnsafeUtil,1220,https://qupath.github.io,https://github.com/qupath/qupath/issues/287,1,['Unsafe'],['UnsafeUtil']
Safety,"a lot of badly-classified data that you then need to remember to ignore later. However, it does then require being able to estimate in advance which cores should be classified together. 4. If you want to use a separate classifier for every core, you could try a more drastic approach of exporting every core as a separate image. To do this, first dearray your slide. Then, you can use [Extension &rarr; ImageJ &rarr; ImageJ macro runner](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#running-macros) to export each image. You need a very simple macro, like the one below:; ```; saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle()); ```; where you’ll need to change the path to be something more suitable for your computer. It takes advantage of the fact that the ‘title’ of the image sent to ImageJ is the same as the TMA core, so using this as the filename can help you identify the core afterwards. > This may give you individual core images that are a bit big... you can change ""tif” to “jpg” to decrease the file size, or you can set the ""Downsample factor” value to 2 to export a lower-resolution image. The advantage of using “tif” is that the micron information is preserved, while if you use “jpg” then this is lost. After doing this export you can then import all your core images into a new project. You’ll almost certainly want to use scripting for batch processing in this case, and there will be another couple of things to do (e.g. apply dearraying to detect a single core in each image, or use *Objects &rarr; Create full image annotation* to give you a region in which to detect cells). ---. Personally, I think Option 1 is the ‘cleanest’ solution, but may be very time-consuming. All the others would give some kind of data management headache - but maybe it is worth it. Of course, there may also be more creative solutions that I haven’t considered. I would be interested to know what you choose in the end. Good luck!. Pete. PS. Thanks for the positive feedback!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/57#issuecomment-288818401:3999,detect,detect,3999,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401,2,['detect'],['detect']
Safety,"aMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 2443 nuclei detected (processing time: 2.11 seconds); INFO: Processing complete in 2.15 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 2443 nuclei detected (processing time: 3.01 seconds); INFO: Processing complete in 3.03 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Smoothing using TMA cores; INFO: Processing complete in 0.18 seconds; INFO: Completed!; INFO: ; qupath.lib.plugins.objects.SmoothFeaturesPlugin {""fwhmMicrons"": 25.0, ""smoothWithinClasses"": false, ""useLegacyNames"": false}; INFO: Measurement mapper limits for Smoothed: 25 µm: Nucleus/Cell area ratio: 0.12291267514228821, 0.4222889840602875; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418647572:4100,detect,detect,4100,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418647572,1,['detect'],['detect']
Safety,"actually there is. You can use a script that exporte your annotations. runs the simple tissue detection, re-imports your annotations, then substracts everything of simple tissue detection of your ROI. . Then finally you have your annotations with simple tissue detection inside. ; That requires quite some scripting.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/248#issuecomment-460298789:94,detect,detection,94,https://qupath.github.io,https://github.com/qupath/qupath/issues/248#issuecomment-460298789,3,['detect'],['detection']
Safety,add option to ProjectImageEntry.readImageData() to avoid accessing the file image,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1488:51,avoid,avoid,51,https://qupath.github.io,https://github.com/qupath/qupath/pull/1488,1,['avoid'],['avoid']
Safety,"age is as follows:; INFO: Selected style: Modena Light; INFO: Performing update check...; INFO: Starting QuPath with parameters: [N:\Faculty-of-Medicine-and-Health\LICAP\DATA\PTHY\Pathology\Breast Group\BCCTB Samples\Audits\BCN QA 2017\Frozen samples QuPath tumourstromaratio\Batch_2\Tumour\402428.svs]; INFO: Test reading thumbnail with openslide: passed (BufferedImage@5d207157: type = 1 DirectColorModel: rmask=ff0000 gmask=ff00 bmask=ff amask=0 IntegerInterleavedRaster: width = 193 height = 200 #Bands = 3 xOff = 0 yOff = 0 dataOffset[0] 0); INFO: Returning server: OpenSlide for N:\Faculty-of-Medicine-and-Health\LICAP\DATA\PTHY\Pathology\Breast Group\BCCTB Samples\Audits\BCN QA 2017\Frozen samples QuPath tumourstromaratio\Batch_2\Tumour\402428.svs; INFO: Estimating H & E staining; INFO: Image data set to ImageData: Brightfield (H&E), 402428; INFO: 1 region detected (processing time: 215.44 seconds); INFO: Processing complete in 215.63 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.tissue.SimpleTissueDetection2 {""threshold"": 219, ""requestedPixelSizeMicrons"": 2.0, ""minAreaMicrons"": 20.0, ""maxHoleAreaMicrons"": 200.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 114",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:1528,detect,detect,1528,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detect']
Safety,"ageReader.java:86); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:648); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:61); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:166); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:19); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:536); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:573); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:156); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:120); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:47); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:269); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); ERROR: IOException exception reading file:/Volumes/Storage/Work/SLIDESCANS/190512_OLYMPUS_YKA_Batch/CRUK_YKA_16.1D_tam_2_20190513.vsi#1: x=9728, y=34816, w=512, h=512, z=0, t=0, downsample=1; at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:199); at java.base/sun.nio.ch.FileChannelImpl.endBlocking(FileChannelImpl.java:162); at java.base/sun.nio.ch.FileChannelImpl.read",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:7861,Detect,DetectionPluginTools,7861,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['Detect'],['DetectionPluginTools']
Safety,"agej.superpixels.SLICSuperpixelsPlugin', '{""sigmaMicrons"": 1.0, ""spacingMicrons"": 10.0, ""maxIterations"": 10, ""regularization"": 0.25, ""adaptRegularization"": false, ""useDeconvolved"": false}');; selectDetections();; runPlugin('qupath.lib.algorithms.IntensityFeaturesPlugin', '{""pixelSizeMicrons"": 0.25, ""region"": ""ROI"", ""tileSizeMicrons"": 25.0, ""colorOD"": true, ""colorStain1"": true, ""colorStain2"": true, ""colorStain3"": false, ""colorRed"": false, ""colorGreen"": false, ""colorBlue"": false, ""colorHue"": false, ""colorSaturation"": false, ""colorBrightness"": false, ""doMean"": true, ""doStdDev"": true, ""doMinMax"": false, ""doMedian"": false, ""doHaralick"": false, ""haralickDistance"": 1, ""haralickBins"": 32}');; ```. You can also choose a larger size for your SLICs if you want to do more of a tissue structure analysis. Smaller is usually better if you are looking for color differences though. Another options is just using the cell detection mentioned above:; ```; selectAnnotations();; runPlugin('qupath.imagej.detect.nuclei.PositiveCellDetection', '{""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.25, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 15.0, ""maxAreaMicrons"": 60.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: DAB OD mean"", ""thresholdPositive1"": 0.2690789473684211, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');; ```. Which yielded the following for my square. You may want to tweak the DAB threshold value, and you can always create your own classifier as well based on more data than just the Nucleus DAB OD mean (https://github.com/qupath/qupath/wiki/Classifying-objects):; ![image](https://user-images.githubusercontent.com/23145209/37378645-52636d20-26ed-11e8-88ac-5401852cb5bc.png). It r",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/157#issuecomment-372875465:2040,detect,detect,2040,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-372875465,1,['detect'],['detect']
Safety,"ah right, Svidro! simple tissue detection is the much faster and more convenient way to do it! I was thinking to complicated ^-^",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/121#issuecomment-349097979:32,detect,detection,32,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349097979,1,['detect'],['detection']
Safety,"alse); def mi = menu.getItems(); .stream(); .filter(m -> commandName.equals(m.getText())); .findAny().orElse(null); if (mi == null) {; mi = new MenuItem(commandName); menu.getItems().add(mi); }; mi.setOnAction {e -> classifyAnnotations()}; }. def classifyAnnotations() {; def imageData = QuPathGUI.getInstance().getImageData(); def annotations = imageData == null ? [] : imageData.getHierarchy().getAnnotationObjects(); if (annotations.isEmpty()) {; Dialogs.showWarningNotification(""Classify annotations"", ""No annotations found!""); return; }; for (def annotation in annotations); classifySingleAnnotation(annotation); imageData.getHierarchy().fireObjectClassificationsChangedEvent(this, annotations); }. def classifySingleAnnotation(PathObject pathObject) {; def roiName = pathObject.getROI()?.getRoiName(); pathObject.setPathClass(PathClass.getInstance(roiName)); }; ```. I think it makes sense for such classifiers to be added to a single *Object classification* submenu, rather than split between *Detection* and *Annotation* (also, there might one day be a need to classify *TMA cores*, which don't fit into either category). Also, the top of the *Train object classifier* dialog makes it possible to select different types of objects to classify. <img width=""418"" alt=""Train object classifier"" src=""https://github.com/qupath/qupath/assets/4690904/d6977ca8-a018-4d33-bd7c-f31eed611749"">. Admittedly, these are all detections or subtypes of detection... but that's because I couldn't think of a good workflow to use them for annotations (since you're using annotations to train the classifier, how should QuPath distinguish between which annotations are for training and which should be classified...?). The internal representation of the object classifier is capable of specifying the type of object it should be applied to, even though we have no easy way to interactively create annotation classifiers through the user interface, or examples where that is actually used. Perhaps more usefully, w",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1501#issuecomment-2075386110:1880,Detect,Detection,1880,https://qupath.github.io,https://github.com/qupath/qupath/issues/1501#issuecomment-2075386110,1,['Detect'],['Detection']
Safety,ambda$detectObjects$10(StarDist2D.java:940); at java.base/java.util.stream.ReferencePipeline$2$1.accept(Unknown Source); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(Unknown Source); at java.base/java.util.stream.AbstractPipeline.evaluate(Unknown Source); at java.base/java.util.stream.ReferencePipeline.collect(Unknown Source); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:941); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:886); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$6(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:859); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$5(StarDist2D.java:812); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:812); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript.run(QuPathScript:48); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:331); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:161); at qupath.lib.gui.scripting.languages.DefaultScriptLanguage.execute(DefaultScriptLanguage.java:234); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:1179); at qupath.lib.gui.scripting.DefaultScriptEditor$3.run(DefaultScriptEditor.java:1545); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.co,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1635:1576,detect,detectObjectsImpl,1576,https://qupath.github.io,https://github.com/qupath/qupath/issues/1635,1,['detect'],['detectObjectsImpl']
Safety,"anCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: ",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:2723,detect,detected,2723,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"annotations, automaticly generated by simple tissue detection function cannot be trimmed with the ""alt+brush"" or ""alt+wand"" tool. ; Normally every annotation can be trimmed like that/reagions from annotation can be deleted. ; I you paint an adjacent second annotation, merge it with the annotations generated by simple tissue detection, trimming will work afterwards. ; I guess that is a bug, that trimming is not directly possible.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/82:52,detect,detection,52,https://qupath.github.io,https://github.com/qupath/qupath/issues/82,2,['detect'],['detection']
Safety,"apper.openBytes(ReaderWrapper.java:334); at loci.formats.ReaderWrapper.openBytes(ReaderWrapper.java:334); at loci.formats.gui.BufferedImageReader.openImage(BufferedImageReader.java:86); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:648); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:61); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:166); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:19); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:536); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:573); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:156); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:120); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:47); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:269); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); ERROR: IOException exception reading file:/Volumes/Storage/Work/SLIDESCANS/190512_OLYMPUS_YKA_Batch/CRUK_YKA_16.1D_tam_2_20190513.vsi#1: x=9728, y=34816, w=512, h=512, z=0, t=0, downsample=1; at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.e",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:7700,detect,detect,7700,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['detect'],['detect']
Safety,"as a script that doesn't follow the borders you drew quite so tightly, but will classify area by the nearest cell, seen here: https://gist.github.com/petebankhead/e23393125fa57fe91c67f5003cbea3e2. You may be looking for something more like superpixel segmentation and classification, however, if you want to create regions that follow the general tissue outline more closely. I have used this several times to create annotations that separate two different types of tissue, either based on texture or coloration. It can be a bit tricky, however, and requires a bit of troubleshooting and decisions on what measurements to apply to the SLICs. Based on your image, the difference is fairly clear-cut and you might be able to get away with something as simple as OD Sum.; The specific tool is _Analyze->Region Identification->Tiles and superpixels_ and then either DoG or SLIC Superpixel segmentation. I tend to prefer SLICs for tissue segementation. Note that this WILL remove all detections (your cells, in this case) and should generally be done before any cell creation in a script. Essentially it makes a jigsaw puzzle of the selected annotation based on the flow of the colors in the tissue. ; ![image](https://user-images.githubusercontent.com/23145209/47020475-4b6d4600-d10e-11e8-8ec7-fccdd85860c6.png). You can then apply color measurements to each of those tiles and then classify them. ; ![image](https://user-images.githubusercontent.com/23145209/47020737-e1a16c00-d10e-11e8-868c-9d1255766fce.png). Finally you could merge all classified SLICs (which are detections) back into annotations using the _Tile classifications to annotations_ in the same menu, and perform cell detection within the new annotations. These annotations will have your area measurements as normal. If you want to apply a sum of all Tumor etc areas to the parent annotation, that will require another script. I am pretty sure this is discussed in more detail on the forums somewhere including scripts. *Runs and hides*",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/229#issuecomment-430244183:985,detect,detections,985,https://qupath.github.io,https://github.com/qupath/qupath/issues/229#issuecomment-430244183,3,['detect'],"['detection', 'detections']"
Safety,ases of the StarDist extension: https://github.com/qupath/qupath-extension-stardist/releases; 3. Download pretrained models in .pb format; 4. Draw an annotation on a brightfield image; 5. Download the following script: https://github.com/MarkZaidi/Universal-StarDist-for-QuPath/blob/main/GPU_Multimodal%20StarDist%20Segmentation.groovy; 6. Run the script; 7. Observe the following error message:; ```; INFO: Performing detection on Brightfield image using single-channel trained model; INFO: [Annotation]; ERROR: OpenCV(4.6.0) D:\a\javacpp-presets\javacpp-presets\opencv\cppbuild\windows-x86_64-gpu\opencv-4.6.0\modules\dnn\src\cuda4dnn\csl\memory.hpp:54: error: (-217:Gpu API call) the provided PTX was compiled with an unsupported toolchain. in function 'cv::dnn::cuda4dnn::csl::ManagedPtr<float>::ManagedPtr'; in GPU_Multimodal StarDist Segmentation.groovy at line number -2. ERROR: org.bytedeco.opencv.opencv_dnn.Net.forward(Native Method); qupath.opencv.dnn.OpenCVDnn$OpenCVNetFunction.predict(OpenCVDnn.java:718); qupath.opencv.dnn.OpenCVDnn$OpenCVNetFunction.predict(OpenCVDnn.java:732); qupath.opencv.dnn.DnnModel.convertAndPredict(DnnModel.java:100); qupath.ext.stardist.StarDist2D.detectObjectsForTile(StarDist2D.java:1249); qupath.ext.stardist.StarDist2D.lambda$detectObjects$7(StarDist2D.java:934); java.base/java.util.stream.ReferencePipeline$7$1.accept(Unknown Source); java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); java.base/java.util.stream.AbstractTask.compute(Unknown Source); java.base/java.util.concurrent.CountedCompleter.exec(Unknown Source); java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); java.base/java.util.concurrent.ForkJo,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1180:2270,predict,predict,2270,https://qupath.github.io,https://github.com/qupath/qupath/issues/1180,1,['predict'],['predict']
Safety,"at hematoxylin should be used for detection, the first deconvolved channel is *always* used - regardless of whether it is actually the one corresponding to hematoxylin or not. This is hard-coded at https://github.com/qupath/qupath/blob/88c7cc45648c1d5b09a840bd1e497ea9a46453aa/qupath-core-processing/src/main/java/qupath/imagej/detect/cells/WatershedCellDetection.java#L231. **To Reproduce**; Steps to reproduce the behavior:; 1. Open a brightfield image e.g. *CMU-1-Small-Region.svs*; 2. Set type to *Brightfield (Other)*; 3. Set 2 or 3 stains, ensuring Hematoxylin is *not* the first; 4. Run *Cell detection* using hematoxylin image; 5. Inspect image to check which channel was really used for detection. **Expected behavior**; The minimal required changes are:; * Use the stain name to identify the hematoxylin image, don't just assume it's the first; * Log a clear warning or throw an exception if anything else is done / there is no hematoxylin available. Ideally, options to detect using any/all stains should be provided to the user. **Screenshots**; Using the following stains; ```groovy; setColorDeconvolutionStains('{""Name"" : ""Some other stains"", ""Stain 1"" : ""Something"", ""Values 1"" : ""0.11793 0.84247 0.52567"", ""Stain 2"" : ""Another"", ""Values 2"" : ""0.32293 0.56288 0.76084"", ""Stain 3"" : ""Hematoxylin "", ""Values 3"" : ""0.61203 0.70103 0.36602"", ""Background"" : "" 255 255 255""}');; ```; the detection looks as below; ![Screenshot 2021-12-26 at 07 51 32](https://user-images.githubusercontent.com/4690904/147402284-3dd60b6b-e301-4efc-850d-fb35f56ced0d.jpg); ![Screenshot 2021-12-26 at 07 51 39](https://user-images.githubusercontent.com/4690904/147402286-d946f166-c927-4d24-9b56-3fec4a54a192.jpg); ![Screenshot 2021-12-26 at 07 51 43](https://user-images.githubusercontent.com/4690904/147402287-b250b3f1-9891-45d7-a1bd-2aea942a185a.jpg); ![Screenshot 2021-12-26 at 07 51 55](https://user-images.githubusercontent.com/4690904/147402288-55dd97c1-6b3b-4c15-898f-84bc314cea2a.jpg). The detected nucl",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/878:1086,detect,detect,1086,https://qupath.github.io,https://github.com/qupath/qupath/issues/878,1,['detect'],['detect']
Safety,"ath/lib/images/ImageData;Lqupath/lib/regions/RegionRequest;)Ljava/awt/image/BufferedImage;+235; j qupath.lib.classifiers.pixel.PixelClassificationImageServer.readTile(Lqupath/lib/images/servers/TileRequest;)Ljava/awt/image/BufferedImage;+84; J 14172 c1 qupath.lib.images.servers.AbstractTileableImageServer.getTile(Lqupath/lib/images/servers/TileRequest;)Ljava/awt/image/BufferedImage; (133 bytes) @ 0x000001d52232b9dc [0x000001d52232b3e0+0x00000000000005fc]; J 14898 c1 qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(Lqupath/lib/regions/RegionRequest;)Ljava/awt/image/BufferedImage; (1110 bytes) @ 0x000001d522ceb264 [0x000001d522ce2920+0x0000000000008944]; j qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(Lqupath/lib/regions/RegionRequest;)Ljava/lang/Object;+2; j qupath.lib.gui.ml.PixelClassificationOverlay.lambda$requestTile$2(Lqupath/lib/images/servers/TileRequest;Lqupath/lib/images/servers/ImageServer;)V+32; j qupath.lib.gui.ml.PixelClassificationOverlay$$Lambda$1631.run()V+12; J 12931 c1 java.util.concurrent.Executors$RunnableAdapter.call()Ljava/lang/Object; java.base@13.0.1 (14 bytes) @ 0x000001d521d305d4 [0x000001d521d304c0+0x0000000000000114]; J 14612 c1 java.util.concurrent.FutureTask.run()V java.base@13.0.1 (123 bytes) @ 0x000001d52225e6fc [0x000001d52225e020+0x00000000000006dc]; j java.util.concurrent.ThreadPoolExecutor.runWorker(Ljava/util/concurrent/ThreadPoolExecutor$Worker;)V+92 java.base@13.0.1; j java.util.concurrent.ThreadPoolExecutor$Worker.run()V+5 java.base@13.0.1; j java.lang.Thread.run()V+11 java.base@13.0.1; v ~StubRoutines::call_stub. siginfo: EXCEPTION_ACCESS_VIOLATION (0xc0000005), reading address 0xffffffffffffffff. ...; ```; The crash doesn't happen consistently. **Expected behavior**; I want to see a live prediction of the classifier and save it. Then I want to apply the classifier to my images. **Desktop (please complete the following information):**; - OS: Windows 10; - QuPath Version 0.2.0 m8",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/394:5169,predict,prediction,5169,https://qupath.github.io,https://github.com/qupath/qupath/issues/394,1,['predict'],['prediction']
Safety,"categories). However, depending upon how the `Locale` is requested it can return different results. For me, the following Groovy script; ```groovy; import java.util.*; println Locale.getDefault(); println Locale.getDefault(Locale.Category.FORMAT); println Locale.getDefault(Locale.Category.DISPLAY); ```; prints; ```; INFO: en_GB; INFO: en_US; INFO: en_US; ```; It is curious that `Locale.getDefault()` returns something different from the others... and different from what QuPath allows to be specified. @iwbh15 noticed this caused a problem with the [QuPath Align extension](https://github.com/qupath/qupath-extension-align) and traced it back to `Locale` in [`GeometryTools`](https://github.com/qupath/qupath/blob/75ec9cebe5e3bc5843fc60b07b455ce1215e1fb9/qupath-core/src/main/java/qupath/lib/roi/GeometryTools.java#L139), used in conjunction with a `NumberFormat`. **To Reproduce**; The script above hints there is a problem. To see it in practice requires using QuPath on a computer that uses a different `Locale` and calling a method that relies upon `Locale.getDefault()` *and* uses decimals.... and being surprised. Basically, it's not *that* easy to reproduce in practice.; But at the risk of messing up QuPath's preferences. ```groovy; import java.util.*; import java.text.*. Locale.setDefault(Locale.GERMANY); Locale.setDefault(Locale.Category.FORMAT, Locale.US); println NumberFormat.getInstance(Locale.getDefault()).parse(""0,1234.56""); println NumberFormat.getInstance(Locale.getDefault(Locale.Category.FORMAT)).parse(""0,1234.56""); ```; prints the following; ```; INFO: 0.1234; INFO: 1234.56; ```; demonstrating the importance of being consistent. If you run this, be sure to restart QuPath afterwards and check the locale is as before. **Expected behavior**; QuPath should never use `Locale.getDefault()` internally - a category should always be provided. **Desktop (please complete the following information):**; - QuPath v0.3.0 for the alignment problem, but possibly earlier versions.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/886:1616,risk,risk,1616,https://qupath.github.io,https://github.com/qupath/qupath/issues/886,1,['risk'],['risk']
Safety,"cell detection always segments white areas instead of colored areas,why?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1545:5,detect,detection,5,https://qupath.github.io,https://github.com/qupath/qupath/issues/1545,1,['detect'],['detection']
Safety,chy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: ,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:2959,detect,detected,2959,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.lib.images.servers.CroppedImageServer.readRegion(CroppedImageServer.java:90); at qupath.lib.images.servers.CroppedImageServer.readRegion(CroppedImageServer.java:39); at qupath.lib.images.servers.SparseImageServer.readTile(SparseImageServer.java:265); at qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:863); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:902); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:216); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); ```,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583:4524,detect,detect,4524,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583,4,"['Detect', 'detect']","['DetectionPluginTools', 'DetectionRunnable', 'detect']"
Safety,convert annotations into detections. Counting in the annotations TAB is wrong,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/259:25,detect,detections,25,https://qupath.github.io,https://github.com/qupath/qupath/issues/259,1,['detect'],['detections']
Safety,"cripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1288); at qupath.lib.gui.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1237); at javafx.concurrent.Task$TaskCallable.call(Task.java:1425); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); Caused by Java heap space at ij.process.FloatProcessor.snapshot(FloatProcessor.java:240); at ij.process.FloatProcessor.convolve(FloatProcessor.java:1069); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.doDetection(WatershedCellDetection.java:600); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:997); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:362); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.cells.WatershedCellDetection {""det",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:3092,detect,detect,3092,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['detect'],['detect']
Safety,"ction.java:600); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:997); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:362); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.cells.WatershedCellDetection {""detectionImageFluorescence"": 1, ""requestedPixelSizeMicrons"": 0.1, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 0.9, ""minAreaMicrons"": 6.0, ""maxAreaMicrons"": 150.0, ""threshold"": 2000.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 3.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Training size: org.bytedeco.javacpp.opencv_core$Size[address=0x608000811620,position=0,limit=1,capacity=1,deallocator=org.bytedeco.javacpp.Pointer$NativeDeallocator[ownerAddress=0x608000811620,deallocatorAddress=0x13aaec9c0]]; INFO: Responses size: org.bytedeco.javacpp.opencv_core$Size[address=0x60800080d2a0,position=0,limit=1,capacity=1,deallocator=org.bytedeco.javacpp.Pointer$NativeDeallocator[ownerAddress=0x60800080d2a0,deallocatorAddress=0x13aaec9c0]]; INFO: RTrees classifier termination criteria: org.bytedeco.javacpp.opencv_core$TermCriteria[address=0x608000816130,position=0,limit=1,capacity=1,dea",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:4055,detect,detect,4055,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['detect'],['detect']
Safety,"dCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 2443 nuclei detected (processing time: 2.11 seconds); INFO: Processing complete in 2.15 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 2443 nuclei detected (processing time: 3.01 seconds); INFO: Processing complete in 3.03 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Smoothing using TMA cores; INFO: Processing complete in 0.18 seconds; INFO: Completed!; INFO: ; qupath.lib.plugins.objects.SmoothFeaturesPlugin {""fwhmMicrons"": 25.0, ""smoothWithinClasses"": false, ""useLegacyNames"": false}; INFO: Measurement mapper limits for Smoothed: 25 µm: Nucleus/Cell area ratio: 0.12291267514228821, 0.4222889840602875; INFO: Adding Area (AWT) to hierarchy; INFO: ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418647572:3975,detect,detected,3975,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418647572,1,['detect'],['detected']
Safety,dImageServer.java:90); at qupath.lib.images.servers.CroppedImageServer.readRegion(CroppedImageServer.java:39); at qupath.lib.images.servers.SparseImageServer.readTile(SparseImageServer.java:265); at qupath.lib.images.servers.AbstractTileableImageServer.lambda$prerequestTiles$2(AbstractTileableImageServer.java:462); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at qupath.lib.images.servers.AbstractTileableImageServer.prerequestTiles(AbstractTileableImageServer.java:464); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:295); at qupath.lib.images.servers.AbstractTileableImageServer.readRegion(AbstractTileableImageServer.java:60); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:863); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:902); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:216); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by null at java.base/java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(Unknown Source); at java.base/java.util.concurrent.locks.ReentrantLock.lockInterruptibly(Unknown Source); at java.base/java.util.concurrent.ArrayBlockingQueue.put(Unknown Source); at qupath.lib.images.servers.bioformats.BioFormatsImageServer$ReaderPool.openImage(BioFormatsImageServer.java:1411); at qupath.lib.images.servers.bioformats.BioForma,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583:2008,Detect,DetectionPluginTools,2008,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443#issuecomment-1864490583,2,['Detect'],"['DetectionPluginTools', 'DetectionRunnable']"
Safety,"dObjects(); println ""Num child objects: \t${childObjects.size()}"". // Get all detections for the region (rectangular bounding box, quick test); def region = ImageRegion.createInstance(roi); def regionObjects = hierarchy.getAllDetectionsForRegion(region, null); println ""Num in region bounds: \t${regionObjects.size()}"". // Detections within selected object, using hierarchy rules; def hierarchyWithin = hierarchy.getAllDetectionsForROI(roi); println ""Num 'within' ROI: \t${hierarchyWithin.size()}"". // Detections with nucleus (or main ROI) centroids within the selected object; def nucleusCentroidWithin = PathObjectTools.filterByROIContainsNucleusCentroid(roi, allDetections); println ""Num nucleus centroid in ROI: \t${nucleusCentroidWithin.size()}"". // Detections with centroids within the selected object; def centroidWithin = PathObjectTools.filterByROIContainsCentroid(roi, allDetections); println ""Num centroid in ROI: \t${centroidWithin.size()}"". // Detections with ROIs intersecting the selected object; def intersecting = PathObjectTools.filterByROIIntersects(roi, allDetections); println ""Num intersecting ROI: \t${intersecting.size()}"". // Detections with ROIs intersecting the selected object - accessed from region; // This should contain the same elements as intersecting (possibly in a different order); def intersecting2 = PathObjectTools.filterByROIIntersects(roi, regionObjects); assert intersecting.size() == intersecting2.size(); assert (intersecting as Set) == (intersecting2 as Set). // Detections with ROIs completely within the selected object; def completelyCovered = PathObjectTools.filterByROICovers(roi, allDetections); println ""Num completely covered: \t${completelyCovered.size()}"". // Set classifications for visualization; allDetections.each {it.classifications = []}; childObjects.each{it.classifications += ['child']}; regionObjects.each{it.classifications += ['region']}; hierarchyWithin.each{it.classifications += ['within']}; nucleusCentroidWithin.each{it.classif",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1563#issuecomment-2264806074:1943,Detect,Detections,1943,https://qupath.github.io,https://github.com/qupath/qupath/pull/1563#issuecomment-2264806074,1,['Detect'],['Detections']
Safety,"de until it does what I want. ```; import qupath.lib.objects.classes.PathClass; import qupath.lib.objects.classes.PathClassFactory; import qupath.lib.scripting.QP. // Parameters to modify; List<String> includeClassesWithName = [""Tumor"", ""Stroma""] as List<String>; def feature = ""Nucleus: DAB OD mean""; def threshold = 0.1; def feature2 = ""ROI: 0.50 µm per pixel: Hue: Mean""; //def threshold2 = 0; // Check what base classifications we should be worried about; // It's possible to specify 'All', or select specific classes and exclude others; def doAll = includeClassesWithName.contains(""All""); def includeClasses = [null]; //def Stroma = PathClassFactory.getPathClass(""Stroma""); def Positive = PathClassFactory.getPathClass(""Positive""); def Negative = PathClassFactory.getPathClass(""Negative""); //def DualPos = PathClassFactory.getPathClass(""Dual Positive""); if (!doAll) {; for (String n : includeClassesWithName); includeClasses.add(PathClassFactory.getPathClass(n)); }. // Loop through all detections; for (def pathObject : QP.getDetectionObjects()) {. // Get the base classification; PathClass baseClass = pathObject.getPathClass(); if (baseClass != null); baseClass = baseClass.getBaseClass(); else if (PathClassFactory.isPositiveClass(baseClass) || PathClassFactory.isNegativeClass(baseClass)); // In the event that we have a positive or negative classification that lacks a base class,; // this implies that the base class should be null; baseClass = ""Tumor""; // Apply classification, if required; if (doAll || includeClasses.contains(baseClass)) {. // Check if we have a measurement - if not, assign the base class; double val = pathObject.getMeasurementList().getMeasurementValue(feature); if (Double.isNaN(val)) {; pathObject.setPathClass(baseClass); continue; }; double val2 = pathObject.getMeasurementList().getMeasurementValue(feature2); if (Double.isNaN(val2)) {; pathObject.setPathClass(baseClass); continue; }. // Set positive or negative class; if (val >= threshold ){; pathObject.set",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/57#issuecomment-289248209:3092,detect,detections,3092,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-289248209,1,['detect'],['detections']
Safety,"dearray.TMADearrayerPluginIJ {""coreDiameterMM"": 0.7, ""labelsHorizontal"": ""1-16"", ""labelsVertical"": ""A-J"", ""labelOrder"": ""Row first"", ""densityThreshold"": 5, ""boundsScale"": 105}; INFO: Adding Rectangle to hierarchy; INFO: Requesting region for stain vector editing: ; INFO: 1932 nuclei detected (processing time: 3.82 seconds); INFO: Processing complete in 3.92 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 1165 nuclei detected (processing time: 3.94 seconds); INFO: Processing complete in 3.98 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Requesting region for stain vector editing: ; INFO: Adding Rectangle to hierarchy; INFO: Requesting region for stain vector editing: ; INFO: 989 nuclei detected (processing time: 1.90 seconds); INFO: Processing complete in 1.92 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackg",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418647572:2191,detect,detect,2191,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418647572,1,['detect'],['detect']
Safety,"define the part of an image and downsampling factor to use, and then writing that out... so the idea is the same. Therefore you could use that to modify the original tiling script. After importing ```ImageWriterTools``` at the top, the main thing to do is to change the contents of the ```try``` block, e.g. something like the following:. ```groovy. ...; import qupath.lib.gui.ImageWriterTools. ...; try {; // Put at top of file for neater code...; ext = "".jpg""; imageData = getCurrentImageData(); overlayOptions = getCurrentViewer().getOverlayOptions(); ; // Write out the region with overlay; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); File file = new File(dirOutput, name); ImageWriterTools.writeImageRegionWithOverlay(imageData, overlayOptions, request, file.getAbsolutePath()). // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); }; ...; ```; This should include all detections and annotations. If you need TMA cores to be displayed too, then some modification would be required... although then *File &rarr; Export TMA data* is usually a better choice in most cases. Note, here I set the output format to JPEG to get smaller file sizes. The original script wrote ImageJ TIFF images, which used lossless compression and had more image properties set (e.g. pixel sizes in microns) - at the cost of writing much larger files. If you want similar ImageJ TIFFs, but with the overlay drawn on top, then the changes are a bit more awkward and require going more into the details or how images are handled by Java and QuPath. The following should work (at least for RGB images):. ```groovy; ...; try {; // Read the image region; ImagePlus imp = server.readImagePlusRegion(request).getImage(false). // Get the hierarchy overlay (could put at top of the file); def hierarchyOverlay = getCurrentViewer().getOverlayLayer(qupath.lib.gui.viewer.overlays.HierarchyOverlay.class).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/44#issuecomment-273680833:1340,detect,detections,1340,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-273680833,1,['detect'],['detections']
Safety,"different keys: `ANNOTATION_DESCRIPTION` ([here](https://github.com/qupath/qupath/blob/75ec9cebe5e3bc5843fc60b07b455ce1215e1fb9/qupath-core/src/main/java/qupath/lib/objects/PathAnnotationObject.java#L74)) and `note` ([here](https://github.com/qupath/qupath/blob/88c7cc45648c1d5b09a840bd1e497ea9a46453aa/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMACommands.java#L122)) respectively. Neither key is ideal for a general purpose.; * I propose introducing a general `text` property. However, it's not totally clear if objects written by previous versions should automatically be updated. If they are, then the data files may not open properly in older QuPath versions.; * One reason for a simple, lower-case property name (e.g. `text`) is that it should be GeoJSON-friendly, and work sensibly as a key. But is there a better key? Via markdown/html, it's possible to smuggle in more than just text.; * Should other object types support text/descriptions?; * **Root objects**: I think yes. It provides a way to append arbitrary text to any image.; * **Detection objects**: Maybe... this would enforce a map being created, which could make each detection considerably more heavyweight. But perhaps it should be permitted, and users simply warned that it's not generally a good idea.; * Consider the sensibleness of the the current implementation, which will:; * Render text as if it's markdown (which shouldn't change anything for most plain text); * Render html directly if the text starts with `<html>`; * Load a web page if the text starts with `https://`. Might be of interest to @yli-hallila especially for https://github.com/yli-hallila/qupath-edu-extension. <img width=""1356"" alt=""Screenshot 2022-07-11 at 16 35 58"" src=""https://user-images.githubusercontent.com/4690904/178302423-15d42432-4af3-40bd-a36c-5f88ac128327.png"">. <img width=""1373"" alt=""Screenshot 2022-07-11 at 16 36 36"" src=""https://user-images.githubusercontent.com/4690904/178302461-a1ab1fb4-b8fa-47a5-94bf-63f89859ced1.png"">",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1005:1415,Detect,Detection,1415,https://qupath.github.io,https://github.com/qupath/qupath/issues/1005,2,"['Detect', 'detect']","['Detection', 'detection']"
Safety,"e caller, but has the advantage of allowing the same reader to be reused for different images / series. This might have some small improvements in performance (especially if initializing a reader is slow), but could be brittle and easy to get wrong. > * The `T getImage(int series);` function should be removed, and the `T getImage(TileRequest tileRequest, int[] channels, boolean isRGB, ColorModel colorModel, int series)` function should be used instead. Ideally yes. As the `HnE_3_1x1component_data.tif` example, shows, we don't know what kind of image will be returned by `getImage(int series)`, and so having a separate API that assumes a single-resolution, non-pyramidal, 2D image seems to add (rather than reduce) complexity. > However I didn't understand where the `OMEPixelParser` class would be in all of this. As seen with the `HnE_3_1x1component_data.tif` example, we don't know for sure what. I think we should go back to thinking about the *ideal* design here, based upon what needs to be reusable - and also what are the simplest and safest changes that can be made before the v0.5.0 release. My understanding of the original requirements is. 1. **Essential** The OMERO `Gateway` returns byte arrays in a format very similar to Bio-Formats, and the logic convert these into a `BufferedImage` (with suitable `ColorModel` etc.) is complex. This should be extracted from `BioFormatsImageServer` for reuse.; 2. **Nice to have** The `BioFormatsImageServer` also has a reader pool concept, which *might* be beneficial for the OMERO image server as well.; ; Achieving 1. requires a class to do the parsing, but doesn't necessarily require reader wrappers and reader pools at all. These seem to be where the main dangers lie, because Bio-Formats is complex to use in a multithreaded context. On the other hand, the parsing doesn't need to know anything about an `IFormatReader` - it just needs the minimal, immutable info required to convert bytes-to-BufferedImage. If you can extract the byte",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1287#issuecomment-1714232547:3408,safe,safest,3408,https://qupath.github.io,https://github.com/qupath/qupath/pull/1287#issuecomment-1714232547,1,['safe'],['safest']
Safety,"e diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's often not entirely clear which are the options you want on a first go. There is no *Undo*, but if you save before running the command, *File &rarr; Revert* can get you back to where you were. The end result is a rather 'blocky' classification, where the size of the blocks depends upon how large the tiles are that you created. But if you need to downsample your image 8 times to get good enough performance with the Weka plugin, then using tiles that are 8x8 pixels gives you just as good a resolution in the end. Furthermore, with QuPath you can add some other kinds of features, particularly Haralick texture features on color-deconvolved images, which can be a better fit for pathology applications compared to some of the Weka features (which may be better for other applications). And you can do other things in QuPath to help with efficiency, such as create a script to find all pixels with high intensity values (background?) and remove them - thereby allowing you to avoid the memory and computational requirements of storing and classifying them. Therefore while there is some overhead involved in QuPath using objects rather than pixels in the way that *ilastik* and *Trainable Weka segmentation* do, QuPath's use of objects is sufficiently efficient and optimized that I think it offers a viable alternative in many cases.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/56#issuecomment-288506877:3650,avoid,avoid,3650,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877,1,['avoid'],['avoid']
Safety,"e other components are often very tedious to write and hard to get working correctly; also, there is much; * overlap in the functionality required for different tasks.; * For these reasons, we provide several default implementations here, written to support different image; * representations.; * </p>; ```. In addition to handling lots of thorny issues around tiling and merging, it also simplifies parallel processing with a progress monitor. In general, you would; * Choose how you want your images represented (e.g. `BufferedImage`, `ImagePlus`, `Mat`); * Write a custom function to do whatever processing you want *or* use a built-in option; * Use an appropriate 'output-handler' to handle whatever output your function gives (e.g. new objects, measurements, classifications). ## Examples. The following examples show the idea - albeit not necessarily with very meaningful processing. ### Image processing with ImageJ. Applied to an image with some detections, this does some custom detections *inside* those detections, and classifies them according to a mean pixel value. ```groovy; import qupath.lib.experimental.pixels.*; import ij.*; import ij.process.*; import ij.plugin.filter.*. def runner = new qupath.lib.gui.PluginRunnerFX(getQuPath()); def imageData = getCurrentImageData(). def pathObjects = getSelectedObjects(); if (!pathObjects); pathObjects = getDetectionObjects(). def processor = ImageJProcessor.builder(this::process).build(); processor.processObjects(runner, imageData, pathObjects). // This is the main custom bit; // (Admittedly, the processing here is nonsense); def process(params) {; // Calculate mean for the region; // With ImageJ, the ROI should already be set; def imp = params.getImage(); assert imp.getRoi() != null; double mean = imp.getStatistics().mean; // Add mean as a measurement; def parent = params.getParent(); parent.measurements['My mean'] = mean; if (mean > 100); parent.classifications = ['High']; else; parent.classifications = ['Low']; // Smooth the",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1355:2021,detect,detections,2021,https://qupath.github.io,https://github.com/qupath/qupath/pull/1355,3,['detect'],['detections']
Safety,"e testing. As described by @carlocastoldi the server is loaded whenever *any* change to the metadata is made. The server can be loaded more often might be expected, sometimes for subtle, hard-to-address reasons. Some relevant facts:; * `ImageServerMetadata` *isn't usually saved with an image when it is first added to a project*. This only happens the first time the data file is saved.; * The `ImageServerMetadata` is updated as soon as an image is opened in a project to ensure that the name specified in the project matches that in the server metadata. This triggers the server to be loaded if; * The `ImageServerMetadata` isn't available, or; * The `ImageServerMetadata` is available, but contains the wrong name (e.g. the name was changed in a project, but then the data file wasn't saved afterwards); * *Run for project* will always force the `ImageServer` to be loaded, because it will always save the data - and this act of saving requires the `ImageServer`. So you can only get advantages if you avoid *Run for project*, e.g. by using *Run for project (without save)* instead.; * We can't rely on not saving if there have been no changes, because the script editor now automatically fires a hierarchy change after completion. This means QuPath *always* thinks that the script may have changed the `ImageData`, so `ImageData.isChanged()` returns true. We didn't used to do this, but then we had to keep telling users to add `fireHierarchyUpdate()` at the end of many otherwise simple-looking scripts, and that was a pain for everyone. This basically means that lazy-loading only works if the data for an image has been saved at least once, and the user hasn't messed around too much with image names within their project. The 'easy' way to trigger an image to be saved once is to do a 'Run for project' script - even if the script doesn't do anything. This should be enough to prompt the `ImageServerMetadata` to become embedded within the project. Although it should also usually happen in ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1489#issuecomment-2273821037:1072,avoid,avoid,1072,https://qupath.github.io,https://github.com/qupath/qupath/pull/1489#issuecomment-2273821037,1,['avoid'],['avoid']
Safety,"e the parent cell as each one is processed. I only know how to do the latter. You already have the loop for all cells from the previous example, and a loop for all clusters from the first. I will start with the loop for all clusters since I have some idea how that would work. Note that this does not summarize stain OD or actual spot area, just estimated spot count. It also only works if the second stain is labeled as DAB! After that, you should have the two values you need to get your ratio. ```; import qupath.lib.scripting.QP; def NuclearSum = ""Nuclear Spot Sum""; def CytoSum = ""Cytoplasmic Spot Sum"". //Probably not necessary when using putMeasurement, but I liked to have this loop for completeness, plus it will reset all values to zero when rerunning the script.; for (def cell : QP.getDetectionObjects()) {; def ml = cell.getMeasurementList(); ml.putMeasurement(NuclearSum, 0); ml.putMeasurement(CytoSum, 0); ml.closeList(); }; def clusters = getObjects({p -> p.class == qupath.imagej.detect.cells.SubcellularDetection.SubcellularObject.class}). // Loop through clusters; for (c in clusters) {; // Each subcellular detection can have one parent; def cell = c.getParent(). def ml = cell.getMeasurementList(); ; //Important note: This value (Num Spots) will be heavily influenced by the Estimated Spot Size when running the; //subcellular detection command. you may instead want to use the Area measurement which you can find; //by clicking on a subcellular detection; double thisCluster = c.getMeasurementList().getMeasurementValue(""Num spots""). //find out if this subcellular detection is nuclear or cytoplasmic, then add the area of that detection to the cell measurement; def location = c.getPathClass().getName(). if ([""Nuclear""].contains(location)) {; double nuclear = cell.getMeasurementList().getMeasurementValue(NuclearSum);; nuclear = nuclear+thisCluster; ml.putMeasurement(NuclearSum, nuclear); ml.closeList(); }; if ([""Cytoplasmic""].contains(location)) {; double cyto = cell.getM",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/119#issuecomment-347208202:1455,detect,detect,1455,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-347208202,1,['detect'],['detect']
Safety,"e without cropping, then the tiff dimensions will inevitably agree. `tiffinfo` is meaningful for .scn because the original format itself is tiff-based, so no conversion is needed. As shown in that example, it's possible that the true dimensions stored in the original file are the ones you get *after* cropping with OpenSlide's bounds, not before. I can't check the dimensions of any .mrxs image with other software as I don't have any viewer for mrxs files that isn't using OpenSlide (and ImageScope failed to open it). There is supposedly a free viewer from the company behind the .mrxs format, but it requires too much personal info to install so I don't want to use it. There are some [links here](https://qupath.readthedocs.io/en/0.4/docs/intro/formats.html#mrxs-3d-histech) that may help give some idea what it's not exactly my favorite file format for whole slide scans. I have seen examples of mrxs images where failing to crop results in very excessive padding (and the associated computational problems), so I still thing cropping / avoiding padding is the more appropriate choice for QuPath to make as a default... and the .scn example demonstrates that it's the right choice there. In conclusion, it sounds like:; * QuPath isn't doing anything weird or buggy - it's behaving as it should here; * You can use QuPath with your pyramidal tiffs, no matter how they are generated (as long as they can be opened by either OpenSlide and Bio-Formats); * You can use QuPath with the mrxs images used to generate tiffs if you do **one** of the following; * generate the tiffs to give the cropped/unpadded region, e.g.; * using [`libvips` and `autocrop`](https://github.com/openslide/openslide/wiki/OpenSlideAndVIPS#slide-bounds); * using QuPath itself (to write an ome-tiff); * import into QuPath with the `--no-crop` option; * correct the coordinates as required when switching between software depending upon whether it adds padding or not; * You *may* be able to use QuPath with other software a",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1278#issuecomment-1631272136:1402,avoid,avoiding,1402,https://qupath.github.io,https://github.com/qupath/qupath/issues/1278#issuecomment-1631272136,1,['avoid'],['avoiding']
Safety,"e.SimpleTissueDetection2 {""threshold"": 219, ""requestedPixelSizeMicrons"": 2.0, ""minAreaMicrons"": 20.0, ""maxHoleAreaMicrons"": 200.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); I",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:2541,detect,detected,2541,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"e: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Writing object hierarchy with 29994 object(s)...; INFO: Image data written to N:\Faculty-of-Medicine-and-Health\LICAP\DATA\PTHY\Pathology\Breast Group\BCCTB Samples\Audits\BCN QA 2017\Frozen samples QuPath tumourstromaratio\Batch_2\Tumour\402428.qpdata in 2.08 seconds; INFO: Training size: 33x5031; INFO: Responses size: 1x5031; INFO: RTrees classifier termination criteria: { type: 1, maxCount: 50, epsilon: 0.0}; ERROR: QuPath exception; at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$354(GlassViewEventHandler.java:416); at com.sun.javafx.t",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:4135,detect,detectionImageBrightfield,4135,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detectionImageBrightfield']
Safety,"e@77accd0e: type = 1 DirectColorModel: rmask=ff0000 gmask=ff00 bmask=ff amask=0 IntegerInterleavedRaster: width = 200 height = 193 #Bands = 3 xOff = 0 yOff = 0 dataOffset[0] 0); INFO: Returning server: OpenSlide for L:\basic\divg\CEMM-Lexor\SannetH\1. SANNE\Project 2. IHC Validation PICCOLO and COIN\Qupath PICCOLO\R-PICCOLO-16_CDX2-88_20x.tiff; INFO: Estimating H-DAB staining; INFO: Image data set to ImageData: Brightfield (H-DAB), R-PICCOLO-16_CDX2-88_20x; INFO: Will (re)compute TMA grid...; INFO: Processing complete in 1.26 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.dearray.TMADearrayerPluginIJ {""coreDiameterMM"": 0.7, ""labelsHorizontal"": ""1-16"", ""labelsVertical"": ""A-J"", ""labelOrder"": ""Row first"", ""densityThreshold"": 5, ""boundsScale"": 105}; INFO: Adding Rectangle to hierarchy; INFO: Requesting region for stain vector editing: ; INFO: 1932 nuclei detected (processing time: 3.82 seconds); INFO: Processing complete in 3.92 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 1165 nuclei detected (processing time: 3.94 seconds); INFO: Processing complete in 3.98 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418647572:1603,detect,detect,1603,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418647572,1,['detect'],['detect']
Safety,eap space; java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: Java heap space; at java.base/java.util.concurrent.FutureTask.report(Unknown Source); at java.base/java.util.concurrent.FutureTask.get(Unknown Source); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:139); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:107); at qupath.lib.gui.PluginRunnerFX.runTasks(PluginRunnerFX.java:98); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:169); at qupath.lib.gui.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:192); at java.base/java.lang.Thread.run(Unknown Source); Caused by Java heap space at java.base/java.util.ArrayDeque.<init>(Unknown Source); at qupath.imagej.processing.Watershed$WatershedQueueWrapper.<init>(Watershed.java:242); at qupath.imagej.processing.Watershed.doWatershed(Watershed.java:83); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.doDetection(WatershedCellDetection.java:852); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:1063); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:303); at qupath.imagej.detect.cells.PositiveCellDetection$DetectorWrapper.runDetection(PositiveCellDetection.java:140); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); ```,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/828#issuecomment-932330593:1438,detect,detect,1438,https://qupath.github.io,https://github.com/qupath/qupath/issues/828#issuecomment-932330593,7,"['Detect', 'detect']","['DetectionPluginTools', 'DetectionRunnable', 'DetectorWrapper', 'detect']"
Safety,"econds; INFO: Completed!; INFO: ; qupath.imagej.detect.tissue.SimpleTissueDetection2 {""threshold"": 219, ""requestedPixelSizeMicrons"": 2.0, ""minAreaMicrons"": 20.0, ""maxHoleAreaMicrons"": 200.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); I",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:2481,detect,detected,2481,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"ects' inside it will automatically be deleted, and replaced with the detected cells. This is *usually* the right/most intuitive thing that should happen, and is not a bug. If this didn’t happen, then you if ran the cell detection command twice with the same parent selected, you would end up having every cell counted twice - not to mention the strange things that might happen with overlapping objects if you were to run other tiling/superpixel commands. It's not clear to me what was the purpose of doing manual counts followed by automated counts within the exact same region, but (as you've found) it is something that is not supported. You *could* do it the opposite way (i.e. automated counts followed by manual counts). However, if it was my goal to compare manual and automated cell counting then I would do the automatic counts in duplicate project and keep the data separated. Furthermore, you can do automated counts and then select 'Convert detections to points' within the 'Points tool' to initialize the (manually-editable) points that can subsequently be modified to generate 'semi-automated counts'. With regard to being unable to reopen a data file, this is something that has been reported some months ago (e.g. #58), but I'm not aware of it being an ongoing problem - or at least not one I have ever been able to reproduce. If QuPath fails to write a complete data file, then you should find that a '.qpdata.backup' file exits somewhere inside your project/data folder. If you strip the '.backup' data part from the file name, then it should be possible to recover the last saved version. > *-Information about the object hierarchy is at https://github.com/qupath/qupath/wiki/Object-hierarchies But from a quick look it seems that 'point' objects do not behave in the way you might expect, in that it appears that a point object is the child of a region if the *first* point is inside that region - and adding subsequent points (inside or outside the region) doesn't change this rel",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/112#issuecomment-342941759:1272,detect,detections,1272,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342941759,1,['detect'],['detections']
Safety,"edCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:997); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:362); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.cells.WatershedCellDetection {""detectionImageFluorescence"": 1, ""requestedPixelSizeMicrons"": 0.1, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 0.9, ""minAreaMicrons"": 6.0, ""maxAreaMicrons"": 150.0, ""threshold"": 2000.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 3.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Training size: org.bytedeco.javacpp.opencv_core$Size[address=0x608000811620,position=0,limit=1,capacity=1,deallocator=org.bytedeco.javacpp.Pointer$NativeDeallocator[ownerAddress=0x608000811620,deallocatorAddress=0x13aaec9c0]]; INFO: Responses size: org.bytedeco.javacpp.opencv_core$Size[address=0x60800080d2a0,position=0,limit=1,capacity=1,deallocator=org.bytedeco.javacpp.Pointer$NativeDeallocator[ownerAddress=0x60800080d2a0,deallocatorAddress=0x13aaec9c0]]; INFO: RTrees classifier termination criteria: org.bytedeco.javacpp.opencv_core$TermCriteria[address=0x608000816130,position=0,limit=1,capacity=1,deallocator=org.bytedeco.javacpp.Pointer$NativeDeallocat",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:4093,detect,detectionImageFluorescence,4093,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['detect'],['detectionImageFluorescence']
Safety,"ei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 1165 nuclei detected (processing time: 3.94 seconds); INFO: Processing complete in 3.98 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Requesting region for stain vector editing: ; INFO: Adding Rectangle to hierarchy; INFO: Requesting region for stain vector editing: ; INFO: 989 nuclei detected (processing time: 1.90 seconds); INFO: Processing complete in 1.92 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 2443 nuclei detected (processing time: 2.11 seconds); INFO: Processing complete in 2.15 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 2443 nuclei detected ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418647572:2958,detect,detectionImageBrightfield,2958,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418647572,1,['detect'],['detectionImageBrightfield']
Safety,"eka segmentation* is ok. However, that might not be necessary. QuPath doesn't offer a pixel classifier like *Trainable Weka segmentation* or *ilastik*, but you can use QuPath's object classifiers to get a similar result. The process would be something like this:. * Create an annotation around an area of interest (e.g. manually, or with *Simple tissue detection*); * Run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* to create square tiles of any size (*don't* choose 'Make annotation tiles' in this case!); * Run *Analyze &rarr; Calculate features &rarr; Add Intensity features (experimental)* and choose a few color transforms along with *Mean* and *Compute Haralick features* from the bottom (and others if you like). If your square tiles are tiny, set *Region* to be either *Square tiles* or *Circular tiles* and choose a tile diameter depending upon how widely you want QuPath to look around each tile for calculating textures. Press *Run* and then choose *Process all: Detections*.; * Train a classifier as described [in the Wiki](https://github.com/qupath/qupath/wiki/Classifying-objects). Check out [this issue](https://github.com/qupath/qupath/issues/50) if you find the *Brush tool* isn't working for you.; * Optionally run *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Tile classifications to annotations*.... if you find it helpful. It's always best to save your data before doing this, since all the options have some kind of logic behind them... but it's often not entirely clear which are the options you want on a first go. There is no *Undo*, but if you save before running the command, *File &rarr; Revert* can get you back to where you were. The end result is a rather 'blocky' classification, where the size of the blocks depends upon how large the tiles are that you created. But if you need to downsample your image 8 times to get good enough performance with the Weka plugin, then using tiles that are 8x8 pixel",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/56#issuecomment-288506877:2154,Detect,Detections,2154,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-288506877,1,['Detect'],['Detections']
Safety,"ell: Circularity"", ""Cytoplasm: Channel 3 max - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 3 min - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 sum"", ""Nucleus: Channel 2 mean - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 3 mean"", ""Cell: Channel 3 std dev"", ""Cytoplasm: Channel 2 max"", ""Nucleus: Channel 3 min - Smoothed (FWHM 25 µm)"", ""Cytoplasm: Channel 1 min"", ""Nucleus: Channel 4 mean"", ""Nucleus: Channel 1 max"", ""Cell: Channel 3 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 range"", ""Cell: Area - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 4 max"", ""Nucleus: Perimeter"", ""Cytoplasm: Channel 2 mean"", ""Cytoplasm: Channel 4 max"", ""Cytoplasm: Channel 3 mean - Smoothed (FWHM 25 µm)"", ""Cell: Channel 1 max - Smoothed (FWHM 25 µm)"", ""Cell: Area"", ""Nucleus: Max caliper"", ""Cell: Channel 2 std dev - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 mean - Smoothed (FWHM 25 µm)"", ""Nucleus: Area - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 1 sum - Smoothed (FWHM 25 µm)"", ""Cell: Channel 2 max"", ""Nucleus: Channel 3 max - Smoothed (FWHM 25 µm)"", ""Nucleus/Cell area ratio"", ""Cytoplasm: Channel 1 std dev"", ""Cytoplasm: Channel 2 min - Smoothed (FWHM 25 µm)"", ""Cell: Min caliper"", ""Cell: Channel 3 mean - Smoothed (FWHM 25 µm)"", ""Nucleus: Channel 2 range"", ""Nucleus: Channel 2 min - Smoothed (FWHM 25 µm)"");. //create dectection results//; saveDetectionMeasurements('D:IFproject_0_19', ). this resulted in a text file being saved with the core name, then i opened it in excel and deleted all remaining columns until i was left with ""class"", ""cell channel 1 mean""-""cell channel 4 mean""; (I am not actually interested in channel 4, that is my nuclear stain).; i sorted the table by 'class' and separated tumor and stroma cell detections, i counted the number of detections for each class type and and summed the intensities for each channel. i divided the intensity for each channel by the totally number of detections in that class. Just to obtain a simple relative amount of the marker within that tissue type.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/16#issuecomment-391785100:5857,detect,detections,5857,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391785100,3,['detect'],['detections']
Safety,"equestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 1165 nuclei detected (processing time: 3.94 seconds); INFO: Processing complete in 3.98 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Requesting region for stain vector editing: ; INFO: Adding Rectangle to hierarchy; INFO: Requesting region for stain vector editing: ; INFO: 989 nuclei detected (processing time: 1.90 seconds); INFO: Processing complete in 1.92 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 2443 nuclei detected (processing time: 2.11 seconds); INFO: Processing complete in 2.15 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0,",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418647572:2794,detect,detected,2794,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418647572,1,['detect'],['detected']
Safety,"er with a training set and the classifier command, or creating your own, exact value, classifier. The slower way of doing this is creating your own classifier through the menu system, which Pete shows:; https://github.com/qupath/qupath/wiki/Object-classifications; about half way down the page. Using that setup, you can generate positive cells for each channel and a set of dual positive cells. My preferred method is using a script to classify. The following script is a toned down version of one Pete has posted elsewhere, but it generally gets the job done. Plus you can expand it out as much as you want using the code that is currently there. Want to classify based on two features? Add a ""def myNewFeature"" and a new ""double val2"" line inside the for loop. You can make the if statments as convoluted as you have the time or desire for, and it is much easier than changing things through the menu classification system.; ```. import qupath.lib.objects.classes.PathClass; import qupath.lib.objects.classes.PathClassFactory. def Positive = PathClassFactory.getPathClass(""Positive""); def Negative = PathClassFactory.getPathClass(""Negative""). //I honestly forget the exact text for the given fluorescence features; //but feature would be one of those; def feature = ""Channel 2: Mean intensity""; def threshold = 0.1; def threshold2 = 1.5. // Loop through all detections *** Change this to getCellObjects() or getTileObjects() if you have a mix of both and only want to classify one type; resetDetectionClassifications(); for (def pathObject : getDetectionObjects()) {. // Get the measurement value(s); double val = pathObject.getMeasurementList().getMeasurementValue(feature). // Set positive or negative class; if (val < threshold || val > threshold2){; pathObject.setPathClass(Positive); }else pathObject.setPathClass(Negative); }; ```; Hopefully that gets you started, let me know if you need anything else!; Edit: Oh, and _Measure->Show annotation measurements_ should get you the data you need",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/126#issuecomment-351212559:2458,detect,detections,2458,https://qupath.github.io,https://github.com/qupath/qupath/issues/126#issuecomment-351212559,1,['detect'],['detections']
Safety,"erience the trouble described in the original question (albeit not an error message). I'm not entirely sure where it is going wrong, but I assume that it is somehow connected to multithreading, and things not being done in quite the right order. I suspect it's also connected to the selection changing while other processing is happening. This will be triggering some activity in the thread responsible for the user interface. Here are three ways to try to work around this - hopefully at least one of them will work. ### Method 1 - Do everything in the application thread; As the *very* first line of your script (with no spaces above it), add; ```; guiscript=true; ```; to force the script to run in the same thread as the user interface. This can often help work around troublesome multithreading issues for scripts that run very quickly. It's probably not a good idea here because the processing is likely to take a while, and the GUI will be totally blocked. ### Method 2 - Pause briefly; Adding `Thread.sleep(time)` pauses the script for a specified number of milliseconds, which can be enough to get things on track.; ```groovy; selectObjects {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeSelectedAnnotations(); Thread.sleep(100); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```. ### Method 3 - Avoid depending on selections; If possible, it's usually good to avoid depending on objects being selected if you don't have to. Sometimes it's necessary (e.g. if you're running a command like cell detection, the annotations/TMA cores need to be selected for the command to work), but in this case there's an alternative:; ```groovy; annotations = getAnnotationObjects().findAll {it.isAnnotation() && it.getROI().getROIType() == 'Rectangle'}; mergeAnnotations(annotations); selectObjects {it.isAnnotation() && it.getPathClass() == getPathClass(""Tumor"")}; ```; For me all three of these methods seem to work, at least in my simple example.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/129#issuecomment-354864318:1767,Avoid,Avoid,1767,https://qupath.github.io,https://github.com/qupath/qupath/issues/129#issuecomment-354864318,3,"['Avoid', 'avoid', 'detect']","['Avoid', 'avoid', 'detection']"
Safety,ers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.createReader(BioFormatsImageServer.java:1265); at qupath.lib.images.servers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.getReaderForThread(BioFormatsImageServer.java:1191); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.getReader(BioFormatsImageServer.java:815); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:848); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:184); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:275); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:56); at qupath.lib.images.servers.ServerTools.getPaddedRequest(ServerTools.java:231); at qupath.opencv.ops.ImageOps$DefaultImageDataOp.apply(ImageOps.java:256); at qupath.tensorflow.stardist.StarDist2D.detectObjectsForTile(StarDist2D.java:807); at qupath.tensorflow.stardist.StarDist2D.lambda$detectObjects$5(StarDist2D.java:687); at java.base/java.util.stream.ReferencePipeline$7$1.accept(Unknown Source); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); at java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); at java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); at java.base/java.util.stream.AbstractTask.compute(Unknown Source); at java.base/java.util.concurrent.CountedCompleter.exec(Unknown Source); at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source); at java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source); at java.base/java.util.concurrent.ForkJoinPool.runWo,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/717:5425,detect,detectObjectsForTile,5425,https://qupath.github.io,https://github.com/qupath/qupath/issues/717,1,['detect'],['detectObjectsForTile']
Safety,"es.; If the scripts being run wants to access the images' pixels, it gracefully halts the execution of the all the following project entries too. _example_:; ```groovy; import qupath.imagej.tools.IJTools; import qupath.lib.images.PathImage; import ij.ImagePlus. var server = getCurrentServer(); var downsample = server.getDownsampleForResolution(Math.min(server.nResolutions()-1, 4)); PathImage<ImagePlus> pathImage = IJTools.convertToImagePlus(server, RegionRequest.createInstance(server, downsample)); ```; ""_Run for project (without saving and opening)_"":; ```; INFO: Starting script at Tue Mar 26 15:20:37 CET 2024; ERROR: The script tried to read pixels off an image while also requiring to run the script without accessing the image files.; WARN: Script cancelled with 53 image(s) remaining; INFO: Processed 54 images; INFO: Total processing time: 280 milliseconds; ```. ## HOW; Essentially this works by creating a `ImageServerStub` that extends `AbstractImageServer`. It retrieves metadata from the ProjectImageEntry itself (which in turn, i think, it gets them from the `.qpproj` file) and fails when `readRegion()` is being called. Additionally, it does not provide a server builder. This way, if the resulting image data are to be saved, the original ImageServer won't be overwritten/lost.; You can now pass a `openImage` boolean to `ProjectImageEntry.readImageData()` that, when false, just avoids getting the default image server, but just uses an instance of `ImageServerStub`. When running a `ProjectTask`, it will catch whether the script tried to access the image file. If it did, it stops the execution for the current image and all the following in the queue. ### Minor proposal; Finally, i'd like to discuss whether we could initially run all scripts with `ImageServerStub` by default and, only if they fail because they need to read the image files, run them with the correct ImageServer.; This point, however, is not really important and can be addressed in a future PR as well.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1488:2058,avoid,avoids,2058,https://qupath.github.io,https://github.com/qupath/qupath/pull/1488,1,['avoid'],['avoids']
Safety,"esenting+1 to +4 can be useful to distinguish populations with both high and low members versus a medium number of spots, but once you want to compare samples by a single number you might be better off with the spot count Mean/Median/Standard deviation, since those are all probably one or two lines of code. Plus I am not sure how well the new version of the H-score would compare to older publications, even if the math was adjusted to a 0-300 scale. I second using the Brightfield (other) when eliminating yellow areas like that for brightfield ISH. Sometimes once you have enough colors, though, you have to apply multiple sets of measurements to the ISH spots (select the subcellular detections, pick your color vectors, Add Intensity Measurements), and then filter them in a script, and update a ""Filtered Red Estimated Num spots"" or something like that. Two color brightfield ISH with red blood cells in the background gets to be a real pain. For a first pass you could try moving the color vectors in Estimate color vectors to something like :; ![image](https://user-images.githubusercontent.com/23145209/36652180-ed8010a8-1a61-11e8-8d09-d639962fd706.png); One vector picks up as much red as possible, and one to get ""the rest"" of what is in your sample. They do not need to be the same as when you did the cell detection. Picking up Groovy isn't bad if you understand programming basics like variables, if/for loops, etc. The main trick (for me) is learning the QuPath specific functions to use, and making use of either Gists, the forums, or IntelliJ to figure out how doable my plans actually are! I mostly just modify other people's scripts. I'm trying to fill out some of what I have learned in my Gists as I go along. On the image, it looks like you are missing quite a few of the smaller spots. If that isn't intentional, I would try turning off all of the check boxes, lowering the min spot size, and make use of the clusters as all of those get combined into the Num spots estimated.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/146#issuecomment-368380554:1459,detect,detection,1459,https://qupath.github.io,https://github.com/qupath/qupath/issues/146#issuecomment-368380554,1,['detect'],['detection']
Safety,"essing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:3377,detect,detected,3377,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"esult in substantial lag. Ideally it shouldn't, but if it does I wouldn't say it's necessarily a bug... since QuPath is already needing to do a *lot* of stuff to get acceptable performance across a wide range of scenarios. Specifically here:; * For a downsample >= 1, repainting detections caches tiles and multiple resolution levels for performance - this is why QuPath can handle millions of objects.; * For downsample < 1, repainting happens for all detections in the field of view (like for annotations) for improved appearance without nasty bitmap-upsampling artefacts. This is inevitably laggier than using cached tiles, but caching itself has considerable overhead in terms of memory and worse appearance. I think this tradeoff makes sense, since details really matter when viewing the image at high magnification but the number of objects visible should be limited (possibly thousands, but not millions). However it does mean that if you have a large enough monitor, many detections, and a downsample value slightly less than 1, performance there certainly can be a noticeable lag... and object connections make this worse by meaning that thousands more lines need to be rendered. However, investigating this revealed that QuPath was painting all the connections twice, which certainly wasn't helping things :). So the PR fixes the double-painting bug. Along the way, it adds a spatial cache that enables QuPath to be a bit smarter about which connections it paints. The main reason for this change is to overcome an issue with long connections sometimes being broken at some resolutions:. ### Old behavior:; ![connection_bug-1](https://user-images.githubusercontent.com/4690904/194024037-795fceaa-e542-4c67-8fa2-84e6a8aca691.png). ### New behavior:; ![connection_fix-1](https://user-images.githubusercontent.com/4690904/194024122-00080b78-b59b-4b8f-bf0d-aa990683268c.png). Together, I'm not certain whether or not you'll see a substantial improvement in performance - but these changes addres",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1069#issuecomment-1268167189:1181,detect,detections,1181,https://qupath.github.io,https://github.com/qupath/qupath/issues/1069#issuecomment-1268167189,1,['detect'],['detections']
Safety,"etURIs()[0]. def server = new qupath.lib.images.servers.bioformats.BioFormatsServerBuilder().buildServer(uri). // Get the current image and image name; def imageData = new ImageData(server); def name = server.getMetadata().getName(). def save_path = ""thumbnail_dir/"" + name + "".png"". def scale_factor = 8.0. // Save the entire image downsampled by a factor of scale_factor; def requestFull = RegionRequest.createInstance(server, scale_factor); writeImageRegion(server, requestFull, save_path); ```. I run it using the command line: . ```; qupath script -i ""31629 HE.bif"" image_thumbnail.groovy; ```. and the output is as follows:. ```; 11:36:08.817 [main] [INFO ] qupath.ScriptCommand - Setting tile cache size to 8030.00 MB (25.0% max memory); 11:36:09.171 [main] [WARN ] q.l.i.s.b.BioFormatsImageServer - Temp memoization directory created at /tmp/qupath-memo-14642445523855977691; 11:36:09.172 [main] [WARN ] q.l.i.s.b.BioFormatsImageServer - If you want to avoid this warning, either disable Bio-Formats memoization in the preferences or specify a directory to use; 11:36:09.363 [main] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1; TIFFReadDirectory: Warning, Unknown field with tag 34677 (0x8775) encountered.; 11:36:09.429 [main] [WARN ] q.l.i.s.o.OpenslideImageServer - Openslide: Property 'openslide.level[0].tile-width' not available, will return default value 256.0; 11:36:09.429 [main] [WARN ] q.l.i.s.o.OpenslideImageServer - Openslide: Property 'openslide.level[0].tile-height' not available, will return default value 256.0; 11:36:09.999 [main] [INFO ] qupath.lib.scripting.QP - Initializing type adapters; ```. Note the `TIFFReadDirectory` warning message in the middle of this. This strongly suggests that the OpenslideServer is actually being used rather than the BioFormats server, despite the explicit commands in the script to use BioFormats. **Expected behavior**; The BioFormats server should be used to open and read the image, as instructed. **Desktop (pl",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/658:1712,avoid,avoid,1712,https://qupath.github.io,https://github.com/qupath/qupath/issues/658,1,['avoid'],['avoid']
Safety,"eventually terminated with an OOM. This occurs because `ImageJServer` first opens the image as a virtual stack, then computes memory requirements/stack size. Based upon this, it may then open the same image as a regular `ImagePlus`. This should be unnecessary, and also temporarily doubles the memory requirements for 2D images because the original has not yet been closed. When investigating this, three other issues were noticed:. 1. The performance impact of using virtual stacks is *much* worse than I had expected, particularly for large 2D images that will frequently be cropped/duplicated. Extracting a region - even for a 2D plane - causes the data to be read from disk again.; 2. [`readBufferedImage(request)`](https://github.com/qupath/qupath/blob/75ec9cebe5e3bc5843fc60b07b455ce1215e1fb9/qupath-core-processing/src/main/java/qupath/imagej/images/servers/ImageJServer.java#L298) is synchronized - but the entire method does not need to be. This prevents calls to resize the extracted image being parallelized, even though this should be safe.; 3. Resizing is called once per channel, including for RGB images. However, in ImageJ's world the RGB image is treated as a single channel - and so any resizing is actually performed 3x rather than 1x. The last two operations seem to be entirely unnecessary. **To Reproduce**; The problem should occur when trying to open any large TIFF that has been written by ImageJ. If it is at the bounds of the available memory, this is likely to fail. If enough memory is available, it should succeed but perform badly. **Expected behavior**; `ImageJServer` should fully read 2D images - since using a virtual stack brings no benefits - and most multidimensional images, as long as they are small enough to fit comfortably in memory. Synchronization should be reduced, and resizing limited. It will sometimes still not be possible to open a non-pyramidal image via ImageJ directly. In this case, running `convert-ome` should be able to efficiently generate a",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/860:1519,safe,safe,1519,https://qupath.github.io,https://github.com/qupath/qupath/issues/860,1,['safe'],['safe']
Safety,"export mean values of ""detection measurement"" results by class",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/299:23,detect,detection,23,https://qupath.github.io,https://github.com/qupath/qupath/issues/299,1,['detect'],['detection']
Safety,ferencePipeline$2$1.accept(Unknown Source); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(Unknown Source); at java.base/java.util.stream.AbstractPipeline.evaluate(Unknown Source); at java.base/java.util.stream.ReferencePipeline.collect(Unknown Source); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:941); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:886); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$6(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:859); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$5(StarDist2D.java:812); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:812); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript.run(QuPathScript:48); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:331); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:161); at qupath.lib.gui.scripting.languages.DefaultScriptLanguage.execute(DefaultScriptLanguage.java:234); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:1179); at qupath.lib.gui.scripting.DefaultScriptEditor$3.run(DefaultScriptEditor.java:1545); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.uti,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1635:1657,detect,detectObjects,1657,https://qupath.github.io,https://github.com/qupath/qupath/issues/1635,1,['detect'],['detectObjects']
Safety,"g H & E staining; INFO: Image data set to ImageData: Brightfield (H&E), 402428; INFO: 1 region detected (processing time: 215.44 seconds); INFO: Processing complete in 215.63 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.tissue.SimpleTissueDetection2 {""threshold"": 219, ""requestedPixelSizeMicrons"": 2.0, ""minAreaMicrons"": 20.0, ""maxHoleAreaMicrons"": 200.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:2305,detect,detected,2305,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"g.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by null at qupath.lib.images.servers.BioFormatsImageServer.getTimePoint(BioFormatsImageServer.java:930); at qupath.imagej.images.servers.BufferedImagePlusServer.getTimePoint(BufferedImagePlusServer.java:173); at qupath.imagej.helpers.IJTools.calibrateImagePlus(IJTools.java:220); at qupath.imagej.images.servers.BufferedImagePlusServer.readImagePlusRegion(BufferedImagePlusServer.java:241); at qupath.imagej.detect.tissue.SimpleTissueDetection2$GlobalThresholder.runDetection(SimpleTissueDetection2.java:158); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:120); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); INFO: Processing complete in 4,20 seconds; INFO: Completed with error java.lang.NullPointerException; INFO: ; qupath.imagej.detect.tissue.SimpleTissueDetection2 {""threshold"": 224, ""requestedPixelSizeMicrons"": 20.0, ""minAreaMicrons"": 100000.0, ""maxHoleAreaMicrons"": 1000000.0, ""darkBackground"": false, ""smoothImage"": true,",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:11312,detect,detect,11312,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['detect'],['detect']
Safety,"ge as .tif files; import ij.IJ; import ij.ImagePlus; import qupath.lib.gui.ImageWriterTools; import qupath.imagej.helpers.IJTools. def imp = IJTools.convertToImagePlus(server, request).getImage(). import qupath.lib.images.servers.ImageServer; import qupath.lib.regions.RegionRequest; import qupath.lib.scripting.QP. import java.awt.image.BufferedImage. /*; * Adjustable parameters; */; int tileWidthPixels =1500 // Width of (final) output tile in pixels; int tileHeightPixels = tileWidthPixels // Width of (final) output tile in pixels; double downsample = 70 // Downsampling used when extracting tiles; String format = ""tif"" // Format of the output image - TIFF or ZIP is best for ImageJ to preserve pixel sizes; String dirOutput =('D:/QUPATH 2 - AT8/Exported Images' ) // BE SURE TO ADD AN OUTPUT DIRECTORY HERE!!!. int maxErrors = 20 // Maximum number of errors... to avoid trying something doomed forever; int minImageDimension = 16 // If a tile will have a width or height < minImageDimension, it will be skipped; // This is needed to avoid trying to read/write images that are too tiny to be useful (and may even cause errors). //-------------------------------------------------------. /*; * Processing; */. // Check we have an output directory; if (dirOutput == null) {; println(""Be sure to set the 'dirOutput' variable!""); return; }. // Initialize error counter; int nErrors = 0. // Get the image server; ImageServer<BufferedImage> serverOriginal = QP.getCurrentImageData().getServer(). // Get an ImagePlus server; ImagePlusServer server = ImagePlusServerBuilder.ensureImagePlusWholeSlideServer(serverOriginal). // Ensure convert the format to a file extension; String ext; if (format.startsWith(""."")); ext = format.substring(1).toLowerCase(); else; ext = format.toLowerCase(). // Extract useful variables; String path = server.getPath(); String serverName = serverOriginal.getShortServerName(); double tileWidth = tileWidthPixels * downsample; double tileHeight = tileHeightPixels * downsam",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/309:1168,avoid,avoid,1168,https://qupath.github.io,https://github.com/qupath/qupath/issues/309,2,['avoid'],['avoid']
Safety,"gons from the input.; 2. Identify intersecting and non-intersecting polygons; 3. Group all polygons that should potentially be merged, because they intersect (directly or indirectly) with other polygons in the group; each polygon should be represented in only one group; 4. Union all the polygon groups; 5. Combine all resulting polygons into a single polygon or multipolygon. This addressing the pixel classification performance bottleneck described at https://forum.image.sc/t/can-creating-detections-from-pixel-classifier-be-made-to-run-faster/96745. When implementing this, it became clear that extremely complex polygons couldn't be displayed in the viewer because generating an `Area` object failed (ultimately with out-of-memory error). Also, `PolygonROI.getGeometry()` was slow when called repeatedly because the geometry is recomputed each time. So the PR uses a `SoftReference` to avoid this, while still allowing references to be dropped when memory is low. When the geometry isn't needed, the overhead should be avoided. This PR also addresses this problem by using JTS' shape representation instead. ## To test. ### Union of many objects. A simple test:; * Detect cells in an image; * Run the following script. ```groovy; import qupath.lib.common.Timeit; import qupath.lib.roi.GeometryTools. import static qupath.lib.scripting.QP.*. def detections = getDetectionObjects(). List<GeometryTools> geoms = detections.collect {it.getROI().getGeometry()}. def timeit = new Timeit(); .start(); def geomUnion = GeometryTools.union(geoms); println timeit.stop(). double sumArea = geoms.sum {g -> g.getArea()}; println ""Sum area: \t${sumArea}""; println ""Num geometries: \t${geoms.size()}""; def roi = GeometryTools.geometryToROI(geomUnion, ImagePlane.getDefaultPlane()); def pathClass = getPathClass(""Merged geometries""); removeObjects(getAnnotationObjects().findAll(p -> p.getPathClass() == pathClass), true); addObject(PathObjects.createAnnotationObject(roi, pathClass)); ```. ### Pixel classifica",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1543:1207,avoid,avoided,1207,https://qupath.github.io,https://github.com/qupath/qupath/pull/1543,1,['avoid'],['avoided']
Safety,"hen resizing an integer image, pixels with an output slightly below the 'correct' value can sometimes become rounded down to the value below. This is unlikely to make any obvious difference in most cases, but it can be a significant problem when exporting a labeled image. Specifically, @SalmaDammak spotted that this impacts the `TileExporter` when using labeled images with resizing, causing some pixels to have the wrong labels in some cases (see https://github.com/qupath/qupath/pull/964). This effect shouldn't be seen when using nearest neighbor interpolation with OpenCV, as controlled by the boolean parameter to the `BufferedImageTools.resize` method. However, the `TileExporter` requests smooth interpolation - even though it shouldn't for labeled images (see [here](https://github.com/qupath/qupath/blob/v0.3.2/qupath-core/src/main/java/qupath/lib/images/writers/TileExporter.java#L870)). Therefore, there are two related issues:; * the behavior of `resize` needs to be improved to avoid the flooring error; * the `TileExporter` should switch to nearest neighbor resizing for labeled images. **To Reproduce**; The resizing issue can be reproduced without relying on the `TileExporter` class by running the following script:. ```groovy; import java.awt.image.BufferedImage; import java.awt.Color. // Create an image with a constant value; def img = new BufferedImage(150, 150, BufferedImage.TYPE_BYTE_GRAY); def g2d = img.createGraphics(); g2d.setColor(new Color(5, 5, 5)); g2d.fillRect(0, 0, img.getWidth(), img.getHeight()); g2d.dispose(). // Resize the image; def imgResized = BufferedImageTools.resize(img, img.getWidth()-1, img.getHeight()-1, true). // Show using ImageJ; def imp = IJTools.convertToUncalibratedImagePlus(""Original"", img); def impResized = IJTools.convertToUncalibratedImagePlus(""Resized"", imgResized); imp.show(); impResized.show(); ```. **Expected behavior**; The script above should show two images, with the pixel value of 5 everywhere. What is actually seen is this",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/974:1635,avoid,avoid,1635,https://qupath.github.io,https://github.com/qupath/qupath/issues/974,1,['avoid'],['avoid']
Safety,"his case it was not problematic that the green region extended outside of the tissue since there were no cells of interest in this “white space”. But ideally it would also fallow the “cut”. - I always start with lining the tumor border (blue) and then I extend it 500µm to get the green one. After this I perform the cell detection in the green one (but the blue one always disappears) after this I run the classifier and when this is completed I ‘expand’ my green annotation with -500µm to get the blue one again and after this I ‘expand the blue one with -500µm to get the black one. I think it may be better that the green and blue would be hollow rings around the outside of the black one. Since we want to measure cells in three different regions: in the tumor center (500 µm from the tumor border) (black), in the invasive front (area between the green and black annotation) and in the tumor (blue).But as of now I don’t know if it is possible to establish this?. - We want to count every immune cell in the tumor (+ and -) but not the tumor cells. In the beginning I tried “Positive cell detection” but when using this command, the software also counted a lot of cells that weren’t immune cells. That is why I switched to the classifier, I am very pleased with the results the classifier is giving me. We are scoring 7 different staining’s (70 samples per staining) and I would like to train the classifier for each staining but within a staining I would like to apply the same classifier for each sample. - In total it will be around 500 images. - I am just starting and trying some things out. I will try to create the annotations before cell detection, but as I have mentioned above: I start with the blue annotation and then I extend it 500µm to get the green one. But when I want to perform the cell detection the first annotation (blue) disappears. So I thought it was nog possible to perform a cell detection in overlapping annotation, or is there a way I can overcome this?. Thank you!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/198#issuecomment-411026150:1384,detect,detection,1384,https://qupath.github.io,https://github.com/qupath/qupath/issues/198#issuecomment-411026150,4,['detect'],['detection']
Safety,"hi！; I used mvn to deploy qupath in Linux and compiled the src/main/java/qupath/QuPath.java file for image detection. But I have encountered some problems that need your help, as follows; ------------------------------------------------------------------------------------------------------------; test environment:; **system**: CentOS7、java version ""1.8.0_131""; **work path**:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/qupath; **command**:; java -cp /oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/qupath/qupath-core-0.1.2.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/qupath/qupath-core-awt-0.1.2.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/qupath/qupath-core-processing-0.1.2.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/qupath/qupath-core-processing-awt-0.1.2.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/qupath/qupath-extension-ij-0.1.2.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/qupath/qupath-extension-input-0.1.2.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/qupath/qupath-extension-opencv-0.1.2.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/qupath/qupath-extension-openslide-0.1.2.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/qupath/qupath-extension-pen-0.1.2.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/qupath/qupath-extension-script-editor-0.1.2.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/qupath/qupath-gui-fx-0.1.2.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/qupath/qupath-processing-ij-0.1.2.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/qupath/qupath-processing-opencv-0.1.2.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/jars/commons-math3-3.6.1.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/jars/controlsfx-8.40.12.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/jars/flowless-0.4.5.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/jars/groovy-2.4.7.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/jars/groovy-jsr223-2.4.7.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/jars/gson-2.8.0.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/jars/ij-1.51g.jar:/oamp/bio/QuPath/0.1.2",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/213:107,detect,detection,107,https://qupath.github.io,https://github.com/qupath/qupath/issues/213,1,['detect'],['detection']
Safety,"hy.getAllDetectionsForRegion(region, null); println ""Num in region bounds: \t${regionObjects.size()}"". // Detections within selected object, using hierarchy rules; def hierarchyWithin = hierarchy.getAllDetectionsForROI(roi); println ""Num 'within' ROI: \t${hierarchyWithin.size()}"". // Detections with nucleus (or main ROI) centroids within the selected object; def nucleusCentroidWithin = PathObjectTools.filterByROIContainsNucleusCentroid(roi, allDetections); println ""Num nucleus centroid in ROI: \t${nucleusCentroidWithin.size()}"". // Detections with centroids within the selected object; def centroidWithin = PathObjectTools.filterByROIContainsCentroid(roi, allDetections); println ""Num centroid in ROI: \t${centroidWithin.size()}"". // Detections with ROIs intersecting the selected object; def intersecting = PathObjectTools.filterByROIIntersects(roi, allDetections); println ""Num intersecting ROI: \t${intersecting.size()}"". // Detections with ROIs intersecting the selected object - accessed from region; // This should contain the same elements as intersecting (possibly in a different order); def intersecting2 = PathObjectTools.filterByROIIntersects(roi, regionObjects); assert intersecting.size() == intersecting2.size(); assert (intersecting as Set) == (intersecting2 as Set). // Detections with ROIs completely within the selected object; def completelyCovered = PathObjectTools.filterByROICovers(roi, allDetections); println ""Num completely covered: \t${completelyCovered.size()}"". // Set classifications for visualization; allDetections.each {it.classifications = []}; childObjects.each{it.classifications += ['child']}; regionObjects.each{it.classifications += ['region']}; hierarchyWithin.each{it.classifications += ['within']}; nucleusCentroidWithin.each{it.classifications += ['nucleus-centroid']}; centroidWithin.each{it.classifications += ['roi-centroid']}; intersecting.each{it.classifications += ['intersecting']}; completelyCovered.each{it.classifications += ['covered']}; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1563#issuecomment-2264806074:2137,Detect,Detections,2137,https://qupath.github.io,https://github.com/qupath/qupath/pull/1563#issuecomment-2264806074,2,['Detect'],['Detections']
Safety,"i initially started with the detection measurements and manually summarized what i wanted to take from that on excel, but i have ~900 cores to analyze and thought their must be a more efficient way. Can this step be automated?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/16#issuecomment-391780670:29,detect,detection,29,https://qupath.github.io,https://github.com/qupath/qupath/issues/16#issuecomment-391780670,1,['detect'],['detection']
Safety,"icult to fill the image buffer. On the larger image I could quite easily cap out the image buffer around 5GB and then sometimes ran into errors. Although sometimes the program would simply go over the 5GB limit and everything would be fine. I am afraid I wasn't able to find anything usefully consistent. . Anyway, the error, whenever I ran into it looks familiar:. > ERROR: Error running plugin: java.lang.OutOfMemoryError: Java heap space; at java.util.concurrent.FutureTask.report(FutureTask.java:122); at java.util.concurrent.FutureTask.get(FutureTask.java:192); at qupath.lib.plugins.AbstractPluginRunner.awaitCompletion(AbstractPluginRunner.java:242); at qupath.lib.plugins.AbstractPluginRunner.runTasks(AbstractPluginRunner.java:204); at qupath.lib.plugins.PluginRunnerFX.runTasks(PluginRunnerFX.java:94); at qupath.lib.plugins.AbstractPlugin.runPlugin(AbstractPlugin.java:134); at qupath.lib.plugins.ParameterDialogWrapper$1.run(ParameterDialogWrapper.java:163); at java.lang.Thread.run(Thread.java:745); Caused by Java heap space at java.util.ArrayDeque.allocateElements(ArrayDeque.java:142); at java.util.ArrayDeque.<init>(ArrayDeque.java:198). Edit:; Actually this part might be more useful:. > INFO: Processing complete in 55.47 seconds; INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.05, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; ERROR: Error reading image region; at loci.formats.tiff.IFD.getIFDLongArray(IFD.java:411); at loci.formats.tiff.IFD.getStripByteCounts(IFD.java:805); at loci.formats.tiff.TiffParser.getTile(TiffParser.java:682)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/112#issuecomment-343336690:2296,detect,detect,2296,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-343336690,2,['detect'],"['detect', 'detectionImageBrightfield']"
Safety,"ierarchy. The tests that each cell object passes contribute to the classification assigned, so that; * if two cells have the same color you can assume they were returned by the same methods; * if two cells have different colors, then at least one cell was returned by at least one method that didn't return the other cell (e.g. it intersects the selected ROI, but isn't completely covered by it). ![image](https://github.com/user-attachments/assets/ad4a2204-2b96-4d5c-bdda-629fccffe2f6). ```groovy; // Get hierarchy & selected object/ROI; def hierarchy = getCurrentHierarchy(); def selectedObject = getSelectedObject(); def roi = selectedObject.getROI(). // Total number of detections everywhere; def allDetections = getDetectionObjects(); println ""Num detections (all): \t${allDetections.size()}"". // Direct children of the selected object; def childObjects = selectedObject.getChildObjects(); println ""Num child objects: \t${childObjects.size()}"". // Get all detections for the region (rectangular bounding box, quick test); def region = ImageRegion.createInstance(roi); def regionObjects = hierarchy.getAllDetectionsForRegion(region, null); println ""Num in region bounds: \t${regionObjects.size()}"". // Detections within selected object, using hierarchy rules; def hierarchyWithin = hierarchy.getAllDetectionsForROI(roi); println ""Num 'within' ROI: \t${hierarchyWithin.size()}"". // Detections with nucleus (or main ROI) centroids within the selected object; def nucleusCentroidWithin = PathObjectTools.filterByROIContainsNucleusCentroid(roi, allDetections); println ""Num nucleus centroid in ROI: \t${nucleusCentroidWithin.size()}"". // Detections with centroids within the selected object; def centroidWithin = PathObjectTools.filterByROIContainsCentroid(roi, allDetections); println ""Num centroid in ROI: \t${centroidWithin.size()}"". // Detections with ROIs intersecting the selected object; def intersecting = PathObjectTools.filterByROIIntersects(roi, allDetections); println ""Num intersecting RO",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1563#issuecomment-2264806074:1064,detect,detections,1064,https://qupath.github.io,https://github.com/qupath/qupath/pull/1563#issuecomment-2264806074,1,['detect'],['detections']
Safety,"il.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); Caused by Java heap space at ij.process.FloatProcessor.snapshot(FloatProcessor.java:240); at ij.process.FloatProcessor.convolve(FloatProcessor.java:1069); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.doDetection(WatershedCellDetection.java:600); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:997); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:362); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.cells.WatershedCellDetection {""detectionImageFluorescence"": 1, ""requestedPixelSizeMicrons"": 0.1, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 0.9, ""minAreaMicrons"": 6.0, ""maxAreaMicrons"": 150.0, ""threshold"": 2000.0, ""watershedPostProcess"": true, ""cellExpansio",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:3332,Detect,DetectionPluginTools,3332,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,2,['Detect'],"['DetectionPluginTools', 'DetectionRunnable']"
Safety,"in the *Hierarchy* tab. Basically, JavaFX’s ```TreeView``` is forced to do a rather slow check along all expanded nodes to look for objects... and if you have a single expanded node containing >~ 10 000 objects expanded within the ```TreeView``` then this can be *extremely slow*. It likely hasn't actually crashed… but it would take an unrealistically long time to become responsive again. The problem is intermittent because expanded nodes with only a few thousand objects in them (e.g. TMA cores) can be handled quite quickly. Additionally, large numbers of objects can be handled so long as the parent objects within the tree aren't expanded, or the objects are contained within multiple smaller annotations rather than a single, very large region. As such, TMA slides and core biopsies likely work (given that the objects are stored within smaller regions), while some whole face sections may be problematic depending on what processing is performed and how. Since the issue appears to be isolated to the display of large numbers of detections within a ```TreeView```, a straightforward fix in a future QuPath release may be to simply exclude detections from the ```TreeView``` by default, showing instead only TMA cores and annotations. In the meantime, hopefully this description of the issue might help anyone encountering it to know the cause, and look for workarounds for their uses. For example, if it is still required to analyze a single large region containing a large number of detections, then *Analyze &rarr; Region identification &rarr; Tiles & superpixels &rarr; Create tiles* has recently received an update to enable the creation of 'annotation tiles'. Using this, the larger annotation can be partitioned into smaller ones, which can then be processed separately. Some additional care is needed to ensure that the correct annotations are selected at the appropriate time using this method, but it can be used to avoid the performance issue before a longer term fix is available.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/41:1782,detect,detections,1782,https://qupath.github.io,https://github.com/qupath/qupath/issues/41,4,"['avoid', 'detect']","['avoid', 'detections']"
Safety,"ing by the downsample. However, the coordinates need to be integers - which makes me uneasy about what happens if the downsample is something like 4.23452345.; Should I be rounding or flooring when I scale up the coordinates?; And can I be sure that QuPath will do the right thing when it scales them back down, so that I get the original coordinates I wanted again...?. If not, then it seems I might get off-by-one errors and slightly unexpected results. If I want a 256 x 256 pixel region, I might end up with a 255 x 256 pixel region... which would be annoying. It seems that I can round or floor when scaling up, and then round or floor when scaling down, but I wasn't completely sure which I should be doing so I created a quick Python simulation to test what happens: https://gist.github.com/petebankhead/2d4a21cb69f3b68c8f8fa14475723647. Based on this, it seems I need to round in both directions... which was maybe a predictable conclusion for the more mathematically confident, but I wasn't sure of it's what QuPath does internally* and we can't count on users necessarily knowing that. (*However*, note that if the downsample is < 1 then all the methods fail...). I think it would be nice to resolve the ambiguity somehow, although adding an extra method; ```java; public T readLevel(int level, int x, int y, int width, int height, int z, int t);; ```; looks like a horrible explosion of ints. A possibly-simpler alternative might be to support something like this:; ```java; public T readScaledRegion(double downsample, int outputX, int outputY, int outputWidth, int outputHeight, int z, int t);; ```; where the coordinates are defined according to the output image, but the downsample isn't fixed to *have* to be a pyramidal level. Thinking about it, that could potentially be implemented more simply with another default method added to the interface that ultimately just called `readRegion`. The main trouble is that I don't know what to call the method. I'll keep thinking and try to ad",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1072#issuecomment-1278540089:1430,predict,predictable,1430,https://qupath.github.io,https://github.com/qupath/qupath/pull/1072#issuecomment-1278540089,1,['predict'],['predictable']
Safety,"ing e.g. a `sort_keys.txt` file with a list of the keys that are used. The purpose of `ResourceManager` (for me at least) is that it supports having several named resources, typically implementations of a specific serializable class. So we might have something like this:. ```java; class SortingKeys {; List<String> keys;. List<String> getKeys() {; return Collections.unmodifiableList(keys);; }. }. var sortingManager = project.getResources(""resources/sorting_keys"", SortingKeys.class, ""json"");; var sortKeys = sortingManager.contains(""sortKeys"") ? sortingManager.getResource(""sortKeys).getKeys() : Collections.emtpyList();; ```; but then it is still 'unconventional' to use a `Manager` when we only have a single resource with a fixed name (here, `""sortKeys""`). ---. What not use the alternative approach of extending the `Project` interface to implement [`MetadataStore`](https://github.com/qupath/qupath/blob/df21dcbaab953837d40aabd856d14b79faca6b7b/qupath-core/src/main/java/qupath/lib/objects/MetadataStore.java#L37) - or adding `String` metadata support similar to how it already works with [`ProjectImageEntry`](https://github.com/qupath/qupath/blob/df21dcbaab953837d40aabd856d14b79faca6b7b/qupath-core/src/main/java/qupath/lib/projects/ProjectImageEntry.java#L49)?. Then the UI can store keys as a list of strings easily, with any key of its choosing and the result serialized within the project. To me, a `Map<String, String>` feels simpler and more intuitive. The advantages I see of a `Manager` are:; 1. It avoids adding to the `project.qpproj` file size (in case someone attempts to add ridiculously-large strings); 2. The sort order wouldn't be lost if a project is saved in an older version of QuPath. But these are only an issue of the `Map` is serialized directly within `project.qpproj`. We *could* potentially overcome both of these by storing the `Map` in a separate `.json` file anyway within `resources/sorting` - without needing to rely on `Manager` to do so. What do you think?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1584#issuecomment-2283509470:2494,avoid,avoids,2494,https://qupath.github.io,https://github.com/qupath/qupath/pull/1584#issuecomment-2283509470,1,['avoid'],['avoids']
Safety,"ing macOS to verify whether the app or component has been altered, they don't verify the identity of the developer. This means that macOS can detect if the code has changed but has no way to confirm who signed the code or if it comes from a trusted source. Key concerns with ad-hoc signatures include:. No Developer Identity Verification: Ad-hoc signatures don’t provide information about the developer’s identity, unlike certificates from Apple, which are linked to verified developer accounts. This can pose security risks as it’s harder to establish trust in the source of the code. Limited Use Cases: Ad-hoc signing is typically used for specific scenarios, such as:; Unsigned code running on Apple Silicon, where macOS requires all code to be signed, even if it’s just ad-hoc.; Web Apps on macOS 14 Sonoma, where the code isn't distributed via traditional app distribution methods. Security Risks: Since there is no certification authority involved in ad-hoc signing, it is easier for malicious or unauthorized code to be signed ad-hoc and executed, which could expose the system to potential vulnerabilities. I would recommend moving away from ad-hoc certificates and following the Apple Developer guidelines on application creation & distribution. For example, here is a free GUI application called ""Apparency"" that will help explain issues and test your applications.; https://mothersruin.com/software/Apparency/. ![image](https://github.com/user-attachments/assets/d69830e4-e271-430a-987c-c58b1b708481); ![image](https://github.com/user-attachments/assets/4a03b7ba-c911-486b-91de-2d86d0eefc2c). I thought this post from Quinn “The Eskimo!” @ Developer Technical Support @ Apple would be good to share with your Mac development team:. Resolving Gatekeeper Problems | Apple Developer Forums:. The post titled ""Resolving Gatekeeper Problems"" on the Apple Developer Forums, written by Quinn ""The Eskimo!"" from Developer Technical Support at Apple is a comprehensive guide addressing common issue",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1672:1301,Risk,Risks,1301,https://qupath.github.io,https://github.com/qupath/qupath/issues/1672,1,['Risk'],['Risks']
Safety,ing script: https://github.com/MarkZaidi/Universal-StarDist-for-QuPath/blob/main/GPU_Multimodal%20StarDist%20Segmentation.groovy; 6. Run the script; 7. Observe the following error message:; ```; INFO: Performing detection on Brightfield image using single-channel trained model; INFO: [Annotation]; ERROR: OpenCV(4.6.0) D:\a\javacpp-presets\javacpp-presets\opencv\cppbuild\windows-x86_64-gpu\opencv-4.6.0\modules\dnn\src\cuda4dnn\csl\memory.hpp:54: error: (-217:Gpu API call) the provided PTX was compiled with an unsupported toolchain. in function 'cv::dnn::cuda4dnn::csl::ManagedPtr<float>::ManagedPtr'; in GPU_Multimodal StarDist Segmentation.groovy at line number -2. ERROR: org.bytedeco.opencv.opencv_dnn.Net.forward(Native Method); qupath.opencv.dnn.OpenCVDnn$OpenCVNetFunction.predict(OpenCVDnn.java:718); qupath.opencv.dnn.OpenCVDnn$OpenCVNetFunction.predict(OpenCVDnn.java:732); qupath.opencv.dnn.DnnModel.convertAndPredict(DnnModel.java:100); qupath.ext.stardist.StarDist2D.detectObjectsForTile(StarDist2D.java:1249); qupath.ext.stardist.StarDist2D.lambda$detectObjects$7(StarDist2D.java:934); java.base/java.util.stream.ReferencePipeline$7$1.accept(Unknown Source); java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); java.base/java.util.stream.AbstractTask.compute(Unknown Source); java.base/java.util.concurrent.CountedCompleter.exec(Unknown Source); java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source); java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source); java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source); java.base/java.util.con,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1180:2470,detect,detectObjectsForTile,2470,https://qupath.github.io,https://github.com/qupath/qupath/issues/1180,1,['detect'],['detectObjectsForTile']
Safety,into build/qupath; LICENSE PATH: /home/gordon/src/qupath/license-unknown.txt; > Task :clean; > Task :qupath-core:clean; > Task :qupath-core-processing:clean; > Task :qupath-experimental:clean; > Task :qupath-extension-bioformats:clean; > Task :qupath-extension-omero:clean; > Task :qupath-extension-openslide:clean; > Task :qupath-extension-pen:clean; > Task :qupath-extension-processing:clean; > Task :qupath-extension-script-editor:clean; > Task :qupath-extension-svg:clean; > Task :qupath-extension-tensorflow:clean UP-TO-DATE; > Task :qupath-gui-fx:clean. > Task :qupath-core:compileJava; Note: Some input files use or override a deprecated API.; Note: Recompile with -Xlint:deprecation for details.; Note: Some input files use unchecked or unsafe operations.; Note: Recompile with -Xlint:unchecked for details. > Task :qupath-core-processing:compileJava; Note: Some input files use or override a deprecated API.; Note: Recompile with -Xlint:deprecation for details.; Note: Some input files use unchecked or unsafe operations.; Note: Recompile with -Xlint:unchecked for details. > Task :qupath-gui-fx:compileJava; Note: Some input files use or override a deprecated API.; Note: Recompile with -Xlint:deprecation for details.; Note: Some input files use unchecked or unsafe operations.; Note: Recompile with -Xlint:unchecked for details. > Task :qupath-extension-processing:compileJava; Note: Some input files use or override a deprecated API.; Note: Recompile with -Xlint:deprecation for details. > Task :qupath-experimental:compileJava; Note: /home/gordon/src/qupath/qupath-experimental/src/main/java/qupath/lib/gui/align/ImageAlignmentPane.java uses or overrides a deprecated API.; Note: Recompile with -Xlint:deprecation for details. > Task :qupath-extension-bioformats:compileJava; > Task :qupath-extension-omero:compileJava; > Task :qupath-extension-openslide:compileJava; > Task :qupath-extension-pen:compileJava; > Task :qupath-extension-script-editor:compileJava; > Task :qupath-extension,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/484#issuecomment-630769356:2517,unsafe,unsafe,2517,https://qupath.github.io,https://github.com/qupath/qupath/issues/484#issuecomment-630769356,1,['unsafe'],['unsafe']
Safety,"ion.getROI(). tw = (int) roi.getBoundsWidth(); th = (int) roi.getBoundsHeight(). if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500) && (counter<10)){; //if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500)){; //print result; RegionRequest request = RegionRequest.createInstance(path, 4, (int) roi.getBoundsX(), (int) roi.getBoundsY(),(int) roi.getBoundsWidth(), (int) roi.getBoundsHeight(), 0, 0); ; ; // Read the image region; ImagePlus imp = serverIJ.readImagePlusRegion(request).getImage(true); IJ.run(imp, ""8-bit"", """");; IJ.run(imp, ""Median..."", ""radius=3"");; //IJ.run(imp, ""Median..."", ""radius=5"");; IJ.run(imp, ""Statistical Region Merging"", ""q=10 showaverages"");; IJ.run(imp, ""Invert"", """");; // python code for normalisation and structure convolution; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Set Measurements..."", ""area mean standard modal min centroid center bounding fit shape feret's integrated median skewness kurtosis add redirect=None decimal=3"");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Erode"", """");; IJ.run(imp, ""Erode"", """");; //getHistogram(values, counts, 256); IJ.run(imp, ""Analyze Particles..."", ""size=20-Infinity circularity=0.40-1.00 display clear summarize add in_situ"");; ; rm = RoiManager;; rm = RoiManager.getInstance(); ; ; if((rm==null) || (rm.getCount()<1)){; print(""No objects found""); }else{; //print rm.getCount(); //RoiManager.roiManager(""count""); //rm.runCommand(imp,""Measure"");; //rm.runCommand(imp,""Update"");; IJ.run(imp, ""Send Overlay to QuPath"", ""choose_object_type=Detection include_measurements"");. // Get a suitable file name; //String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); // Create an output file; //File file = new File(dirOutput, name); // Save the image; //IJ.save(imp, file.getAbsolutePath()); // Print progress; //imp.show() ; rm.reset() ; ; }; ; //counter++; imp2 = IJ.getImage();; imp2.close();; }; ; }. ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/136#issuecomment-357429324:2330,Detect,Detection,2330,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357429324,1,['Detect'],['Detection']
Safety,"is makes sense, but are there use cases where it would not be appropriate?. I can't think of any myself... however, if you run a command like; ```; selectAnnotations(); ```; then if there is more than 1 annotation available, the one that will become the 'primary' selected annotation is (from the user's perspectively) essentially random. Randomness doesn't feel good in this scenario, but neither does seemingly not having a selected object when you can plainly see that you definitely have selected object**s** (as is currently the case). > Or at least to me, this does not make sense. Not only does it quickly become more complex, but I personally don't believe a larger ROI is any more important than a smaller one. Perhaps it depends on the context. Good! Inasmuch as I don't like the idea much either. Its only benefit really is that it makes the choice non-random. I think sometimes it would 'feel' like the right choice, e.g. imagine if you have one large tissue annotation and two little annotations inside. I think making the large one the primary selection would feel somehow intuitive. But if, on the other hand, you have three annotations of similar size and importance I agree it doesn't make much sense. And it's probably better not to introduce too much predictable-but-dubious behavior, lest *someone* make it a key part of their workflow... So yeah, I think the size-based idea can be discarded. > I am not sure about null, but if having a primary selected object is important, not having one could throw a meaningful error rather than returning null. Hmmm, that sounds like it could work for code internal to QuPath, as long as it always checks both for `getSelectedObject()` and `getSelectedObjects()`. Although if calling either method in a script, the ambiguity and potential for confusion remains. Although then the question resurfaces, is it better to just leave things as they are?. In any case, the proposed change is implemented at https://github.com/qupath/qupath/pull/759",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/758#issuecomment-869217737:1305,predict,predictable-but-dubious,1305,https://qupath.github.io,https://github.com/qupath/qupath/issues/758#issuecomment-869217737,1,['predict'],['predictable-but-dubious']
Safety,"is that it makes the sub-class “Tumour: Positive” but not “Stroma: Positive” and I can’t understand how to create this. Many tanks again, I’ll work on the nuclei shape more extensively later on. Lucia. From: Svidro <notifications@github.com>; Reply-To: qupath/qupath <reply@reply.github.com>; Date: Thursday, 18 October 2018 at 19:40; To: qupath/qupath <qupath@noreply.github.com>; Cc: ""Montorsi, Lucia"" <lucia.montorsi@kcl.ac.uk>, Author <author@noreply.github.com>; Subject: Re: [qupath/qupath] Elongated nuclei not correctly detected (#231). For the nuclei, I would recommend starting a thread on the forum where you can post some pictures, that sounds like more of a image analysis problem. 20X might also be challenging with truly thin, elongated nuclei. Even more challenging if the Hamamatsu defaults to saving with JPEG compression (bad for analysis, great for file size). You can both classify regions and cellular populations, so you can subdivide your sample into ""tumor"" and ""stroma"" annotations first, and then perform positive cell detection within each of those (or however many classifications you want). Another option is using derived classes, so that you would first classify by tumor and stroma, then classify the cells as positive or negative within those classifications: https://github.com/qupath/qupath/wiki/Object-classifications<https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fwiki%2FObject-classifications&data=01%7C01%7Clucia.montorsi%40kcl.ac.uk%7Cc0fb04b4d26e44a6d0fa08d63529246a%7C8370cf1416f34c16b83c724071654356%7C0&sdata=UQryuEzaf5zSNRtDGv8hrkp%2FfCUaV5EV%2FABLyh8vxoY%3D&reserved=0>. Either way, you can then ignore the stromal positive cells in the data processing (merge populations) however you want, or create a step that re-classifies any Stroma-positive to Stroma-negative, etc. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://emea01.safelin",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/231#issuecomment-431292156:1178,detect,detection,1178,https://qupath.github.io,https://github.com/qupath/qupath/issues/231#issuecomment-431292156,1,['detect'],['detection']
Safety,"is there a solution for batch processing with qupath script?; below code partly work and export the original picture with detected cells overlay but it does not export the created density map overlay (which is showing in the content view). import qupath.imagej.tools.IJTools; import qupath.lib.gui.images.servers.RenderedImageServer; import qupath.lib.gui.viewer.overlays.HierarchyOverlay; import qupath.lib.regions.RegionRequest; import qupath.lib.analysis.heatmaps.ColorModels; import qupath.lib.analysis.heatmaps.ColorModels.DisplayBand; import qupath.lib.analysis.heatmaps.DensityMaps; import qupath.lib.analysis.heatmaps.DensityMaps.DensityMapBuilder; import qupath.lib.analysis.heatmaps.DensityMaps.DensityMapParameters ; import qupath.lib.analysis.heatmaps.DensityMaps;; import qupath.lib.objects.classes.PathClass;; import qupath.lib.analysis.heatmaps.ColorModels.ColorModelBuilder; import static qupath.lib.gui.scripting.QPEx.*. double downsample = 1; String path = buildFilePath(PROJECT_BASE_DIR, 'rendered', getProjectEntry().getImageName() +'-smc'+ '.png'); def viewer = getCurrentViewer(); def imageData = getCurrentImageData(); def options = viewer.getOverlayOptions(). def display = new qupath.lib.display.ImageDisplay(imageData); def params = new DensityMaps.DensityMapParameters(); def map = new DensityMaps.DensityMapBuilder(params); def server = new RenderedImageServer.Builder(imageData); .display(display); .downsamples(downsample); .layers(); .build(); ; // Write or display the rendered image; if (path != null) {; mkdirs(new File(path).getParent()); writeImage(server, path); } else; IJTools.convertToImagePlus(server, RegionRequest.createInstance(server)).getImage().show()",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1272#issuecomment-1636869774:122,detect,detected,122,https://qupath.github.io,https://github.com/qupath/qupath/issues/1272#issuecomment-1636869774,1,['detect'],['detected']
Safety,"ith consolidating the last portion of the code into a parallel stream, but it is not much faster than the original code for one parentROI. In my case, I want to calculate the intersections for multiple ROIs with the tile, so it was easier for me to write the code similar to the snippet below:. ```; //		have to make all these ""final"" temp variables.... probably a better way; 		double finalYMin = yMin;; 		double finalXMin = xMin;; 		boolean finalByColumn = byColumn;; 		Map<Integer, Geometry> finalColumnParents = columnParents;; 		boolean finalByRow = byRow;; 		Map<Integer, Geometry> finalRowParents = rowParents;; 		List<ROI> tileROIs = Collections.synchronizedList(new ArrayList<>());; 		var plane = parentROI.getImagePlane();; 		AtomicInteger nullInterExcepetions = new AtomicInteger(0);; 		IntStream.range(0, nx).parallel().forEach(xi -> {; 			double x = finalXMin + xi * w - overlap;; //			A very hacky way to consolidate the code into 1 loop.; //			Atomic Reference doesn't behave when getting hit by multiple streams setting potentially different values for each stream...; 			Geometry outerGeometryLocal = finalByColumn ? finalColumnParents.getOrDefault(xi, geometry) : geometry;; 			IntStream.range(0, ny).parallel().forEach(yi -> {; 				double y = finalYMin + yi * h - overlap;; 				Geometry geometryLocal = finalByRow ? finalRowParents.getOrDefault(yi, geometry) : outerGeometryLocal;. 				// Create the tile; 				var rect = GeometryTools.createRectangle(x, y, w + overlap * 2, h + overlap * 2);; 				Geometry inter = intersect(rect, geometryLocal);; 				if(inter==null) {; 					nullInterExcepetions.incrementAndGet();; 					return;; 				}; 				ROI roi = GeometryTools.geometryToROI(inter, plane);; 				tileROIs.add(roi);; 			});; 		});. 		if (nullInterExcepetions.get() > 0) {; 			logger.warn(""Tiles lost during tiling: {}"", nullInterExcepetions.get());; 			logger.warn(""You may be able to avoid tiling errors by calling 'Simplify shape' on any complex annotations first."");; 		}; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1043#issuecomment-1219923298:1973,avoid,avoid,1973,https://qupath.github.io,https://github.com/qupath/qupath/pull/1043#issuecomment-1219923298,1,['avoid'],['avoid']
Safety,"ity when we're trying to reduce it. So it will take some thought and I'd like to understand the problem better. > This last change alone allowed, on my projects, to improve the time when creating an object classifier from ~10/15minutes to ~5seconds. Can you explain why it takes so long? Huge numbers of images? Slow file format, or is it where the images are stored?. > Additionally, allowed to modify `ObjectClassifierCommand` too so that it can read all detections' measurements in the training set without uselessly reading the image files. The [`ObjectClassifier`](https://qupath.github.io/javadoc/docs/qupath/lib/classifiers/object/ObjectClassifier.html) takes an `ImageData` by design because an object classifier *could* require pixel access... and this is very likely to be important in the future. This is because, when I rewrote object classifiers some years ago, I was thinking of future classifiers that will use deep learning models to classify based upon image patches - and not only measurements. That's why there is also a general [`FeatureExtractor`](https://qupath.github.io/javadoc/docs/qupath/opencv/ml/objects/features/FeatureExtractor.html) class. This all basically works, we just haven't yet had time to wrap it up for wider use. > You can now pass a `openImage` boolean to `ProjectImageEntry.readImageData()` that, when false, just avoids getting the default image server, but just uses an instance of `ImageServerStub`. While not identical, the current `ProjectImageEntry.readHierarchy()` is intended for when you need objects but not everything else. This already lets you access all measurements etc. without touching the image. You can then create a new `ImageData` with a dummy `ImageServer` if you need to. So an alternative approach might be to try to script creating a classifier without needing to go through the UI, in a way that doesn't involve any big API changes - and which can be used when you can *know* in advance that the image doesn't need to be accessed.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1488#issuecomment-2021998811:1554,avoid,avoids,1554,https://qupath.github.io,https://github.com/qupath/qupath/pull/1488#issuecomment-2021998811,1,['avoid'],['avoids']
Safety,"lassifier trained for 3 classes, saved for both classification and probability output - then ran the script at the bottom. Using a Mac Studio (2022) with M1 Max and 32 GB RAM the processing time was:. | v0.3.0 | v0.4.0-SNAPSHOT |; | ------------- | ------------- |; | 593.9 s | 60.1 s |. Results identical as far as I can tell. So... quite a substantial difference :). Cell detection took close to 30s, with 326 498 cells detected,. ```groovy; def checkpoints = [:]. setImageType('BRIGHTFIELD_H_E'); setColorDeconvolutionStains('{""Name"" : ""H&E default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049"", ""Stain 2"" : ""Eosin"", ""Values 2"" : ""0.2159 0.8012 0.5581"", ""Background"" : "" 255 255 255""}'). clearAllObjects(). checkpoints << ['Tissue detection': System.currentTimeMillis()]. createAnnotationsFromPixelClassifier(""Tissue detection"", 10000.0, 0.0, ""INCLUDE_IGNORED""). checkpoints << ['Cell detection': System.currentTimeMillis()]. selectAnnotations(); runPlugin('qupath.imagej.detect.cells.WatershedCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 1.0, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}'). for (classifier in ['Some probability', 'Some classification']) {. // Create annotation measurements; checkpoints << [""Annotation measurements for $classifier"": System.currentTimeMillis()]; selectAnnotations(); addPixelClassifierMeasurements(classifier, classifier); ; // Create cell measurements; checkpoints << [""Cell measurements for $classifier"": System.currentTimeMillis()]; selectCells(); addPixelClassifierMeasurements(classifier, classifier); }; checkpoints << [""Done"": System.currentTimeMillis()]; resetSelection(); println 'Done!'. def entries = checkpoints.entrySet",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1076#issuecomment-1279692584:1080,detect,detect,1080,https://qupath.github.io,https://github.com/qupath/qupath/pull/1076#issuecomment-1279692584,1,['detect'],['detect']
Safety,"le(double, double, double, double)'; at qupath.ext.stardist.StarDist2D.lambda$detectObjects$10(StarDist2D.java:940); at java.base/java.util.stream.ReferencePipeline$2$1.accept(Unknown Source); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(Unknown Source); at java.base/java.util.stream.AbstractPipeline.evaluate(Unknown Source); at java.base/java.util.stream.ReferencePipeline.collect(Unknown Source); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:941); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:886); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$6(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:859); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$5(StarDist2D.java:812); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:812); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript.run(QuPathScript:48); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:331); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:161); at qupath.lib.gui.scripting.languages.DefaultScriptLanguage.execute(DefaultScriptLanguage.java:234); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:1179); at qupath.lib.gui.scripting.DefaultScriptEditor$3.run(DefaultScriptEditor.java:1545); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.u",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1635:1506,detect,detectObjects,1506,https://qupath.github.io,https://github.com/qupath/qupath/issues/1635,1,['detect'],['detectObjects']
Safety,"let@ciml.univ-mrs.fr>; Author <author@noreply.github.com>; Objet : Re: [qupath/qupath] resolution very bad with mrxs format (#187). The contents of TIFF images can be quite variable, some compatible and some not. QuPath doesn't handle the file formats itself, but rather uses OpenSlide, Bio-Formats or ImageJ. Because all three libraries 'think' they can handle TIFF files, and a decision is made based on a basic parsing of the metadata, I'm not sure which one will actually be trying (and failing) in your case. If you have the Bio-Formats extension installed, then you can customize whether or not it is used (or ignored) preferentially using the preferences described at the bottom of this page: https://github.com/qupath/qupath-bioformats-extension. By either always using Bio-Formats or never using Bio-Formats for .tif, you might have more success in reading this specific TIFF in QuPath. Regarding 'a way to calculate the intensity for fluorescence above a threshold' do you want the mean fluorescence intensity, or something else? I would expect that the mean is quite dependent on the threshold value chosen. In any case, there's currently no built-in command to get exactly this in QuPath directly, and you may need to rely on ImageJ. Four ways you might approach this are:. * Using Send region to ImageJ interactively; * Via an ImageJ macro run through QuPath; * Using a Groovy script, somewhat like this one<https://petebankhead.github.io/qupath/scripting/2018/03/08/script-imagej-to-qupath.html>; * Using a script, macro or Simple tissue detection to generate the QuPath annotation first, then within QuPath calling Analyze → Calculate features → Add intensity features (experimental). —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/187#issuecomment-407034348>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AnjxC6_wpAcAAwaZNs36171_gwZkNzouks5uJburgaJpZM4VYHCt>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/187#issuecomment-407035378:1813,detect,detection,1813,https://qupath.github.io,https://github.com/qupath/qupath/issues/187#issuecomment-407035378,1,['detect'],['detection']
Safety,"ll trigger a lot of costly checks and events. Calling `addObjects` and passing a list should do much better. So the loop above could become; ```groovy; def pathObjects = []; for (i = 0; i <num_rois; i++) {; // The rest of the stuff, as above; pathObjects << new PathDetectionObject(roi); }; addObjects(pathObjects); ```; If this still doesn't perform well enough, and you don't mind deleting anything that might already exist on the hierarchy, using the following instead of `addObjects()` should perform better still:; ```groovy; clearAllObjects(); getCurrentHierarchy().getRootObject().addPathObjects(pathObjects); fireHierarchyUpdate(); ```. Anyhow, the reason I think that it should work one way or another is that you can generate similar numbers of vertices running the cell detection in QuPath itself. In that case, various tricks are used to help, e.g.; * Contours are smoothed after detection, and then simplified to reduce the numbers of vertices that need to be drawn; * Image tiles representing the objects are drawn on demand and cached - similar to having a pyramidal image, but one where the tiles are quickly created only when needed; * When viewing the image at a sufficiently low resolution, QuPath will check if a detection is well represented by a single pixel or rectangle and just draw that instead (to avoid the effort of handling all the vertices). You could do the polygon simplification on the OpenCV side, perhaps with `approxPolyDP`, or else on the QuPath side after already generating the polygon, using [`ShapeSimplifier.simplifyPolygon(PolygonROI polygon, final double altitudeThreshold)`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core/src/main/java/qupath/lib/roi/experimental/ShapeSimplifier.java#L145). Despite all that, I haven't tried doing this exact conversion before and my guess is that you might have a problem with having really really huge text files. If that's the case then it could be the bottleneck... but that can be solved too if necessary.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/81#issuecomment-357045269:1404,detect,detection,1404,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-357045269,3,"['avoid', 'detect']","['avoid', 'detection']"
Safety,"ll was returned by at least one method that didn't return the other cell (e.g. it intersects the selected ROI, but isn't completely covered by it). ![image](https://github.com/user-attachments/assets/ad4a2204-2b96-4d5c-bdda-629fccffe2f6). ```groovy; // Get hierarchy & selected object/ROI; def hierarchy = getCurrentHierarchy(); def selectedObject = getSelectedObject(); def roi = selectedObject.getROI(). // Total number of detections everywhere; def allDetections = getDetectionObjects(); println ""Num detections (all): \t${allDetections.size()}"". // Direct children of the selected object; def childObjects = selectedObject.getChildObjects(); println ""Num child objects: \t${childObjects.size()}"". // Get all detections for the region (rectangular bounding box, quick test); def region = ImageRegion.createInstance(roi); def regionObjects = hierarchy.getAllDetectionsForRegion(region, null); println ""Num in region bounds: \t${regionObjects.size()}"". // Detections within selected object, using hierarchy rules; def hierarchyWithin = hierarchy.getAllDetectionsForROI(roi); println ""Num 'within' ROI: \t${hierarchyWithin.size()}"". // Detections with nucleus (or main ROI) centroids within the selected object; def nucleusCentroidWithin = PathObjectTools.filterByROIContainsNucleusCentroid(roi, allDetections); println ""Num nucleus centroid in ROI: \t${nucleusCentroidWithin.size()}"". // Detections with centroids within the selected object; def centroidWithin = PathObjectTools.filterByROIContainsCentroid(roi, allDetections); println ""Num centroid in ROI: \t${centroidWithin.size()}"". // Detections with ROIs intersecting the selected object; def intersecting = PathObjectTools.filterByROIIntersects(roi, allDetections); println ""Num intersecting ROI: \t${intersecting.size()}"". // Detections with ROIs intersecting the selected object - accessed from region; // This should contain the same elements as intersecting (possibly in a different order); def intersecting2 = PathObjectTools.filterByROI",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1563#issuecomment-2264806074:1309,Detect,Detections,1309,https://qupath.github.io,https://github.com/qupath/qupath/pull/1563#issuecomment-2264806074,1,['Detect'],['Detections']
Safety,"lls from the previous example, and a loop for all clusters from the first. I will start with the loop for all clusters since I have some idea how that would work. Note that this does not summarize stain OD or actual spot area, just estimated spot count. It also only works if the second stain is labeled as DAB! After that, you should have the two values you need to get your ratio. ```; import qupath.lib.scripting.QP; def NuclearSum = ""Nuclear Spot Sum""; def CytoSum = ""Cytoplasmic Spot Sum"". //Probably not necessary when using putMeasurement, but I liked to have this loop for completeness, plus it will reset all values to zero when rerunning the script.; for (def cell : QP.getDetectionObjects()) {; def ml = cell.getMeasurementList(); ml.putMeasurement(NuclearSum, 0); ml.putMeasurement(CytoSum, 0); ml.closeList(); }; def clusters = getObjects({p -> p.class == qupath.imagej.detect.cells.SubcellularDetection.SubcellularObject.class}). // Loop through clusters; for (c in clusters) {; // Each subcellular detection can have one parent; def cell = c.getParent(). def ml = cell.getMeasurementList(); ; //Important note: This value (Num Spots) will be heavily influenced by the Estimated Spot Size when running the; //subcellular detection command. you may instead want to use the Area measurement which you can find; //by clicking on a subcellular detection; double thisCluster = c.getMeasurementList().getMeasurementValue(""Num spots""). //find out if this subcellular detection is nuclear or cytoplasmic, then add the area of that detection to the cell measurement; def location = c.getPathClass().getName(). if ([""Nuclear""].contains(location)) {; double nuclear = cell.getMeasurementList().getMeasurementValue(NuclearSum);; nuclear = nuclear+thisCluster; ml.putMeasurement(NuclearSum, nuclear); ml.closeList(); }; if ([""Cytoplasmic""].contains(location)) {; double cyto = cell.getMeasurementList().getMeasurementValue(CytoSum);; cyto = cyto+thisCluster; ml.putMeasurement(CytoSum, cyto); ml.clo",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/119#issuecomment-347208202:1585,detect,detection,1585,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-347208202,1,['detect'],['detection']
Safety,"locationtech.jts.geom.Geometry qupath.lib.roi.GeometryTools.createRectangle(double, double, double, double)'; java.lang.NoSuchMethodError: 'org.locationtech.jts.geom.Geometry qupath.lib.roi.GeometryTools.createRectangle(double, double, double, double)'; at qupath.ext.stardist.StarDist2D.lambda$detectObjects$10(StarDist2D.java:940); at java.base/java.util.stream.ReferencePipeline$2$1.accept(Unknown Source); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(Unknown Source); at java.base/java.util.stream.AbstractPipeline.evaluate(Unknown Source); at java.base/java.util.stream.ReferencePipeline.collect(Unknown Source); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:941); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:886); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$6(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:859); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$5(StarDist2D.java:812); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:812); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript.run(QuPathScript:48); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:331); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:161); at qupath.lib.gui.scripting.languages.DefaultScriptLanguage.execute(DefaultScriptLanguage.java:234); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(De",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1635:1287,detect,detectObjectsImpl,1287,https://qupath.github.io,https://github.com/qupath/qupath/issues/1635,1,['detect'],['detectObjectsImpl']
Safety,"lowing error log (see below):. // Set the magnification & pixel size (be cautious!!!); def metadata = getCurrentImageData().getServer().getOriginalMetadata(); metadata.magnification = 40; metadata.pixelWidthMicrons = 0.25; metadata.pixelHeightMicrons = 0.25. setImageType('BRIGHTFIELD_H_DAB');; Thread.sleep(100); setColorDeconvolutionStains('{""Name"" : ""H-DAB TMA40x"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.82788 0.53885 0.15571 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.15891 0.36799 0.91615 "", ""Background"" : "" 210 208 209 ""}');; Thread.sleep(100); runPlugin('qupath.imagej.detect.tissue.SimpleTissueDetection2', '{""threshold"": 224, ""requestedPixelSizeMicrons"": 20.0, ""minAreaMicrons"": 100000.0, ""maxHoleAreaMicrons"": 1000000.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": true, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}');; Thread.sleep(100); selectAnnotations();; Thread.sleep(100); runPlugin('qupath.imagej.detect.nuclei.WatershedCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 14.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.09, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}');; Thread.sleep(100). Error log:. INFO: Starting script at Thu Sep 27 09:20:09 CEST 2018; ERROR: QuPath exception; at com.sun.glass.ui.Application.checkEventThread(Application.java:443); at com.sun.glass.ui.View.getNativeView(View.java:449); at com.sun.glass.ui.win.WinAccessible.get_HostRawElementProvider(WinAccessible.java:672); at com.sun.glass.ui.win.WinAccessible.UiaRaiseAutomationEvent(Native Method); at com.sun.glass.ui.win.WinAccessible.sendNotification(WinAccessible.java:287); at javafx.scene.Node.notifyAccessibleAttributeChanged(Node.java:9604); at javafx.scene",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:1292,detect,detect,1292,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['detect'],['detect']
Safety,"ls are child objects of their annotations!; tumorAnnos = getAnnotationObjects().findAll{it.getPathClass() == getPathClass(""Tumor"")}; tumorCells = getCellObjects().findAll{it.getParent().getPathClass() == getPathClass(""Tumor"")}. //Remove the tumor annotations and their cells; removeObjects(tumorAnnos,false); removeObjects(tumorCells,false); //Analyze->Spatial analysis->Detect centroid distances 2D. detectionCentroidDistances(true); //Add everything back, and make sure the hierarchy is resolved!; addObjects(tumorAnnos); addObjects(tumorCells); resolveHierarchy(); ```. The code works most of the time. Probably 70%? I lack my usual variety of computers to test out whether it is based on my computer - but I do have a project file hosted online I can make available to run the test. Errors include: Null pointer exception popup in the lower right,. INFO: Starting script at Sat Jun 05 20:54:28 CDT 2021; WARN: Resolving hierarchy that contains 3 annotations and 1236 detections - this may be slow!; ERROR: QuPath exception; WARN: Resolving hierarchy that contains 3 annotations and 1236 detections - this may be slow!; INFO: Script run time: 0.25 seconds; The log file is not hugely informative on that one. Alternatively, I sometimes see a TMA core error. ```; ERROR: QuPath exception: Cannot invoke ""qupath.lib.objects.PathObject.isTMACore()"" because ""child"" is null; at qupath.lib.gui.panes.PathObjectHierarchyView$PathObjectTreeItem.getChildren(PathObjectHierarchyView.java:516); at qupath.lib.gui.panes.PathObjectHierarchyView$PathObjectTreeItem.isLeaf(PathObjectHierarchyView.java:544); at javafx.controls/javafx.scene.control.skin.TreeCellSkin.updateDisclosureNode(Unknown Source); at javafx.controls/javafx.scene.control.skin.TreeCellSkin.updateChildren(Unknown Source); at javafx.controls/javafx.scene.control.skin.LabeledSkinBase.lambda$new$5(Unknown Source); at javafx.controls/com.sun.javafx.scene.control.LambdaMultiplePropertyChangeListenerHandler.lambda$new$1(Unknown Source); at j",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/744:1622,detect,detections,1622,https://qupath.github.io,https://github.com/qupath/qupath/issues/744,2,['detect'],['detections']
Safety,"lusters from the first. I will start with the loop for all clusters since I have some idea how that would work. Note that this does not summarize stain OD or actual spot area, just estimated spot count. It also only works if the second stain is labeled as DAB! After that, you should have the two values you need to get your ratio. ```; import qupath.lib.scripting.QP; def NuclearSum = ""Nuclear Spot Sum""; def CytoSum = ""Cytoplasmic Spot Sum"". //Probably not necessary when using putMeasurement, but I liked to have this loop for completeness, plus it will reset all values to zero when rerunning the script.; for (def cell : QP.getDetectionObjects()) {; def ml = cell.getMeasurementList(); ml.putMeasurement(NuclearSum, 0); ml.putMeasurement(CytoSum, 0); ml.closeList(); }; def clusters = getObjects({p -> p.class == qupath.imagej.detect.cells.SubcellularDetection.SubcellularObject.class}). // Loop through clusters; for (c in clusters) {; // Each subcellular detection can have one parent; def cell = c.getParent(). def ml = cell.getMeasurementList(); ; //Important note: This value (Num Spots) will be heavily influenced by the Estimated Spot Size when running the; //subcellular detection command. you may instead want to use the Area measurement which you can find; //by clicking on a subcellular detection; double thisCluster = c.getMeasurementList().getMeasurementValue(""Num spots""). //find out if this subcellular detection is nuclear or cytoplasmic, then add the area of that detection to the cell measurement; def location = c.getPathClass().getName(). if ([""Nuclear""].contains(location)) {; double nuclear = cell.getMeasurementList().getMeasurementValue(NuclearSum);; nuclear = nuclear+thisCluster; ml.putMeasurement(NuclearSum, nuclear); ml.closeList(); }; if ([""Cytoplasmic""].contains(location)) {; double cyto = cell.getMeasurementList().getMeasurementValue(CytoSum);; cyto = cyto+thisCluster; ml.putMeasurement(CytoSum, cyto); ml.closeList(); }; ; } ; println(""Done summarizing""). ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/119#issuecomment-347208202:1807,detect,detection,1807,https://qupath.github.io,https://github.com/qupath/qupath/issues/119#issuecomment-347208202,4,['detect'],['detection']
Safety,mageServer.java:1265); at qupath.lib.images.servers.bioformats.BioFormatsImageServer$BioFormatsReaderManager.getReaderForThread(BioFormatsImageServer.java:1191); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.getReader(BioFormatsImageServer.java:815); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:848); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:184); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:275); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:56); at qupath.lib.images.servers.ServerTools.getPaddedRequest(ServerTools.java:231); at qupath.opencv.ops.ImageOps$DefaultImageDataOp.apply(ImageOps.java:256); at qupath.tensorflow.stardist.StarDist2D.detectObjectsForTile(StarDist2D.java:807); at qupath.tensorflow.stardist.StarDist2D.lambda$detectObjects$5(StarDist2D.java:687); at java.base/java.util.stream.ReferencePipeline$7$1.accept(Unknown Source); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); at java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); at java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); at java.base/java.util.stream.AbstractTask.compute(Unknown Source); at java.base/java.util.concurrent.CountedCompleter.exec(Unknown Source); at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source); at java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source); at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source); at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unkn,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/717:5516,detect,detectObjects,5516,https://qupath.github.io,https://github.com/qupath/qupath/issues/717,1,['detect'],['detectObjects']
Safety,mages.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:56); at qupath.lib.gui.viewer.overlays.PixelClassificationOverlay.lambda$requestTile$5(PixelClassificationOverlay.java:547); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by Physical memory usage is too high: physicalBytes (16451M) > maxPhysicalBytes (16384M) at org.bytedeco.javacpp.Pointer.deallocator(Pointer.java:712); at org.bytedeco.javacpp.Pointer.init(Pointer.java:126); at org.bytedeco.opencv.opencv_core.Mat.allocate(Native Method); at org.bytedeco.opencv.opencv_core.Mat.<init>(Mat.java:241); at qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predictWithLock(OpenCVClassifiers.java:468); at qupath.opencv.ml.OpenCVClassifiers$ANNClassifierCV.predictWithLock(OpenCVClassifiers.java:1425); at qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predict(OpenCVClassifiers.java:442); at qupath.opencv.ops.ImageOps$ML$StatModelOp.apply(ImageOps.java:2812); at qupath.opencv.ops.ImageOps$Core$SequentialMultiOp.apply(ImageOps.java:2294); at qupath.opencv.ops.ImageOps$ChannelImageDataOp.apply(ImageOps.java:424); at qupath.opencv.ml.pixel.OpenCVPixelClassifier.applyClassification(OpenCVPixelClassifier.java:104); at qupath.lib.classifiers.pixel.PixelClassificationImageServer.readTile(PixelClassificationImageServer.java:299); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:184); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:238); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:56,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856:1908,predict,predictWithLock,1908,https://qupath.github.io,https://github.com/qupath/qupath/issues/856,1,['predict'],['predictWithLock']
Safety,main/GPU_Multimodal%20StarDist%20Segmentation.groovy; 6. Run the script; 7. Observe the following error message:; ```; INFO: Performing detection on Brightfield image using single-channel trained model; INFO: [Annotation]; ERROR: OpenCV(4.6.0) D:\a\javacpp-presets\javacpp-presets\opencv\cppbuild\windows-x86_64-gpu\opencv-4.6.0\modules\dnn\src\cuda4dnn\csl\memory.hpp:54: error: (-217:Gpu API call) the provided PTX was compiled with an unsupported toolchain. in function 'cv::dnn::cuda4dnn::csl::ManagedPtr<float>::ManagedPtr'; in GPU_Multimodal StarDist Segmentation.groovy at line number -2. ERROR: org.bytedeco.opencv.opencv_dnn.Net.forward(Native Method); qupath.opencv.dnn.OpenCVDnn$OpenCVNetFunction.predict(OpenCVDnn.java:718); qupath.opencv.dnn.OpenCVDnn$OpenCVNetFunction.predict(OpenCVDnn.java:732); qupath.opencv.dnn.DnnModel.convertAndPredict(DnnModel.java:100); qupath.ext.stardist.StarDist2D.detectObjectsForTile(StarDist2D.java:1249); qupath.ext.stardist.StarDist2D.lambda$detectObjects$7(StarDist2D.java:934); java.base/java.util.stream.ReferencePipeline$7$1.accept(Unknown Source); java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); java.base/java.util.stream.AbstractTask.compute(Unknown Source); java.base/java.util.concurrent.CountedCompleter.exec(Unknown Source); java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source); java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source); java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source); java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source). ```. **Expected behavior**,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1180:2552,detect,detectObjects,2552,https://qupath.github.io,https://github.com/qupath/qupath/issues/1180,1,['detect'],['detectObjects']
Safety,"mo!” @ Developer Technical Support @ Apple would be good to share with your Mac development team:. Resolving Gatekeeper Problems | Apple Developer Forums:. The post titled ""Resolving Gatekeeper Problems"" on the Apple Developer Forums, written by Quinn ""The Eskimo!"" from Developer Technical Support at Apple is a comprehensive guide addressing common issues related to Gatekeeper on macOS. Gatekeeper is a security feature designed to ensure that only trusted software runs on a user's Mac, and the post focuses on helping developers troubleshoot and resolve issues that may arise in this context.; The post identifies four common Gatekeeper problems that developers may encounter:. 1. App blocked by a dangling load command path.; 2. Broken code signature.; 3. Lack of notarization.; 4. Command-line tool blocked by Gatekeeper. For each of these issues, the post provides detailed steps and guidance on how developers can resolve them. The emphasis is on the importance of passing Gatekeeper checks to maintain customer trust and avoid potential loss of customers.; Key points covered in the post include:. • Verification of Code Signature: Developers are advised to use the codesign tool to verify that their code is signed correctly. The post provides examples of command-line usage to check for issues such as missing or invalid sealed resources.; • Notarization Issues: Gatekeeper requires that apps be notarized, and the post guides developers on how to identify and resolve notarization problems. It includes information on checking system logs for specific entries related to notarization issues.; • Hash Mismatch: In cases where there's a hash mismatch, the post provides guidance based on the file type (e.g., zip archive, signed disk image, installer package) and recommends specific actions to address the problem.; • Command-line Tool Blocking Bug: A known bug in macOS is acknowledged, where double-clicking a command-line tool in Finder may lead to it being blocked by Gatekeeper. Worka",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1672:3080,avoid,avoid,3080,https://qupath.github.io,https://github.com/qupath/qupath/issues/1672,1,['avoid'],['avoid']
Safety,"n be made before the v0.5.0 release. My understanding of the original requirements is. 1. **Essential** The OMERO `Gateway` returns byte arrays in a format very similar to Bio-Formats, and the logic convert these into a `BufferedImage` (with suitable `ColorModel` etc.) is complex. This should be extracted from `BioFormatsImageServer` for reuse.; 2. **Nice to have** The `BioFormatsImageServer` also has a reader pool concept, which *might* be beneficial for the OMERO image server as well.; ; Achieving 1. requires a class to do the parsing, but doesn't necessarily require reader wrappers and reader pools at all. These seem to be where the main dangers lie, because Bio-Formats is complex to use in a multithreaded context. On the other hand, the parsing doesn't need to know anything about an `IFormatReader` - it just needs the minimal, immutable info required to convert bytes-to-BufferedImage. If you can extract the bytes-to-BufferedImage logic in an entirely threadsafe way, and leave as much as possible of `BioFormatsImageServer` as it is, then that could be the safest way to make a v0.5.0 update and help with the OMERO extension. In general, I am cautious about about extensive refactoring of `BioFormatsImageServer` because I've written so many subtly broken versions of it myself throughout in QuPath's history :) It's really hard to get 'right'; the previous version was messy, but the code seemed to work pretty reliably (well, except for [this...](https://forum.image.sc/t/qupath-stardist-extension-error-with-large-images/80221/19)). ---. I realise it's *incredibly hard* (/ impossible) to write this without failing examples, and most public examples *won't* fail because we get lucky with the different series types. My guess is that .czi is one of the more awkward formats. Based on that, I found another failing example here: https://zenodo.org/record/7149674. Specifically, check out the label and macro images with the PR vs. in QuPath v0.4.4. In this case, the problem is ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1287#issuecomment-1714232547:4505,safe,safest,4505,https://qupath.github.io,https://github.com/qupath/qupath/pull/1287#issuecomment-1714232547,1,['safe'],['safest']
Safety,"nRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Requesting region for stain vector editing: ; INFO: Adding Rectangle to hierarchy; INFO: Requesting region for stain vector editing: ; INFO: 989 nuclei detected (processing time: 1.90 seconds); INFO: Processing complete in 1.92 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 2443 nuclei detected (processing time: 2.11 seconds); INFO: Processing complete in 2.15 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 2443 nuclei detected (processing time: 3.01 seconds); INFO: Processing complete in 3.03 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Optical density sum"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 4",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418647572:3382,detect,detected,3382,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418647572,1,['detect'],['detected']
Safety,"nce I have tif images that are twice as big that can be opened without problem. . I have tested both on Windows 10 and Ubuntu 18. Here is the log from a Windows machine:; INFO: Bio-Formats version 6.3.0; INFO: Loaded extension Bio-Formats server options (Bio-Formats 6.3.0) (22 ms); INFO: Loaded extension Experimental commands (18 ms); INFO: Loaded extension ImageJ extension (58 ms); INFO: Loaded extension JPen extension (22 ms); INFO: Loaded extension OpenCV extensions (3 ms); INFO: Loaded extension Rich script editor extension (373 ms); INFO: OpenSlide version 3.4.1; INFO: Selected style: null; INFO: Performing update check...; WARN: No changelog found - will not check for updates; INFO: Starting QuPath with parameters: []; WARN: Unable to obtain full image format info for file:/D:/pDST/eHE-PDS18-015016-leica.tif (class java.util.NoSuchElementException); WARN: Temp memoization directory created at C:\Users\DanielH\AppData\Local\Temp\qupath-memo-13737650391880953912; WARN: If you want to avoid this warning, either disable Bio-Formats memoization in the preferences or specify a directory to use; ERROR: *** One or more readers is misbehaving. See the debug output for more information. e.g.:; loci.formats.in.APLReader@578b4451 -> java.lang.NullPointerException('null') ***; WARN: Removing alpha channel; WARN: Removing alpha channel; ERROR: QuPath exception: Java heap space; at java.desktop/sun.awt.image.IntegerInterleavedRaster.getDataElements(Unknown Source); at qupath.lib.display.ChannelDisplayInfo$RGBDirectChannelInfo.getRGBIntBuffer(ChannelDisplayInfo.java:539); at qupath.lib.display.ChannelDisplayInfo$RBGColorTransformInfo.getValues(ChannelDisplayInfo.java:707); at qupath.lib.display.ImageDisplay$HistogramManager.ensureChannels(ImageDisplay.java:902); at qupath.lib.display.ImageDisplay.updateHistogramMap(ImageDisplay.java:573); at qupath.lib.display.ImageDisplay.setImageData(ImageDisplay.java:144); at qupath.lib.gui.viewer.QuPathViewer.setImageData(QuPathViewer.java",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/382:1184,avoid,avoid,1184,https://qupath.github.io,https://github.com/qupath/qupath/issues/382,1,['avoid'],['avoid']
Safety,"ocessing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Writing object hierarchy with 29994 object(s)...; INFO: Image data written to N:\Faculty-",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:3614,detect,detected,3614,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"ocessing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:3318,detect,detected,3318,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,odeTile(CellSensReader.java:1042); at loci.formats.in.CellSensReader.openBytes(CellSensReader.java:549); at loci.formats.FormatReader.openBytes(FormatReader.java:884); at loci.formats.ImageReader.openBytes(ImageReader.java:444); at loci.formats.ReaderWrapper.openBytes(ReaderWrapper.java:334); at loci.formats.ReaderWrapper.openBytes(ReaderWrapper.java:334); at loci.formats.gui.BufferedImageReader.openImage(BufferedImageReader.java:86); at qupath.lib.images.servers.bioformats.BioFormatsImageServer.readTile(BioFormatsImageServer.java:648); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:61); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:166); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:19); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:536); at qupath.imagej.helpers.IJTools.convertToImagePlus(IJTools.java:573); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:156); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:120); at qupath.imagej.objects.PathImagePlus.getImage(PathImagePlus.java:47); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:269); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); ```,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:10970,detect,detect,10970,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,4,"['Detect', 'detect']","['DetectionPluginTools', 'DetectionRunnable', 'detect']"
Safety,"of settings that were used in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often don't. For example, you could simply detect cells within the TMA core directly. This can give you some measurements (e.g. percentages of positive cells, H-scores), but not others (e.g. tissue area, p",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/53#issuecomment-282469327:1178,detect,detection,1178,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327,1,['detect'],['detection']
Safety,"ol over thickness?).; * *'Add intensity features'* tries to handle the tricky problem of arbitrarily large ROIs, by tiling. It is easier to code more imaginative feature measurements if we can assume that all pixels and binary mask can fit easily into RAM.; * *'Add intensity features'* does *not* handle the different cell compartments currently (i.e. nucleus, cytoplasm, cell, membrane). **Additional context**; In writing this, it's not clear to me if we should replace *'Add intensity features'* and *'Add shape features'* with a single, better command at the same time as trying to solve this issue. A few extra considerations and complexities:; * We need to be able to handle color transforms (e.g. color deconvolution); * We need to consider the resolution at which the measurements are calculated; * We need to think a lot about the measurement names; specifically, these need to be unique (since they are effectively stored in a map), and efficiently encode the key info (e.g. compartment, resolution, measurement type). An occasional complaint is that QuPath's cell detection and the StarDist extension use different naming conventions. This was a conscious decision, because the measurements weren't expected to be directly comparable - and so shouldn't be used interchangeably (e.g. when training a cell classifier). But I don't think it was necessarily a *good* decision. With default cell detection, you'd get; ```; Nucleus: Hematoxylin OD mean; ```; but with StarDist (i.e. `ObjectMeasurements`) you woul dhave; ```; Hematoxylin: Nucleus: Mean; ```. Both share the idea of splitting parts with colons... but inconsistently in most respects. If we had a better convention, then this might also be useful to show measurements in a *grouped* way. I suspect grouping first by compartment would be more sensible than by stain. The closest comparable measurement from *'Add intensity features'* would be; ```; ROI: 2.00 µm per pixel: Hematoxylin: Mean; ```; which also groups... confusingly.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1551:2612,detect,detection,2612,https://qupath.github.io,https://github.com/qupath/qupath/issues/1551,2,['detect'],['detection']
Safety,on-omero:clean; > Task :qupath-extension-openslide:clean; > Task :qupath-extension-pen:clean; > Task :qupath-extension-processing:clean; > Task :qupath-extension-script-editor:clean; > Task :qupath-extension-svg:clean; > Task :qupath-extension-tensorflow:clean UP-TO-DATE; > Task :qupath-gui-fx:clean. > Task :qupath-core:compileJava; Note: Some input files use or override a deprecated API.; Note: Recompile with -Xlint:deprecation for details.; Note: Some input files use unchecked or unsafe operations.; Note: Recompile with -Xlint:unchecked for details. > Task :qupath-core-processing:compileJava; Note: Some input files use or override a deprecated API.; Note: Recompile with -Xlint:deprecation for details.; Note: Some input files use unchecked or unsafe operations.; Note: Recompile with -Xlint:unchecked for details. > Task :qupath-gui-fx:compileJava; Note: Some input files use or override a deprecated API.; Note: Recompile with -Xlint:deprecation for details.; Note: Some input files use unchecked or unsafe operations.; Note: Recompile with -Xlint:unchecked for details. > Task :qupath-extension-processing:compileJava; Note: Some input files use or override a deprecated API.; Note: Recompile with -Xlint:deprecation for details. > Task :qupath-experimental:compileJava; Note: /home/gordon/src/qupath/qupath-experimental/src/main/java/qupath/lib/gui/align/ImageAlignmentPane.java uses or overrides a deprecated API.; Note: Recompile with -Xlint:deprecation for details. > Task :qupath-extension-bioformats:compileJava; > Task :qupath-extension-omero:compileJava; > Task :qupath-extension-openslide:compileJava; > Task :qupath-extension-pen:compileJava; > Task :qupath-extension-script-editor:compileJava; > Task :qupath-extension-svg:compileJava; > Task :compileJava; > Task :processResources; > Task :classes; > Task :copyChangelog; > Task :qupath-core:processResources; > Task :qupath-core:classes; > Task :qupath-core:jar; > Task :qupath-core-processing:processResources; > Task :qupa,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/484#issuecomment-630769356:2775,unsafe,unsafe,2775,https://qupath.github.io,https://github.com/qupath/qupath/issues/484#issuecomment-630769356,1,['unsafe'],['unsafe']
Safety,"on: null; at java.base/java.util.ArrayList$Itr.checkForComodification(Unknown Source); at java.base/java.util.ArrayList$Itr.next(Unknown Source); at java.base/java.util.Collections$UnmodifiableCollection$1.next(Unknown Source); at java.base/java.util.AbstractCollection.addAll(Unknown Source); at qupath.lib.objects.PathObjectTools.getAvailableFeatures(PathObjectTools.java:2026); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript$_run_closure1.doCall(QuPathScript:11); at QuPathScript$_run_closure1.doCall(QuPathScript); at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(Unknown Source); at java.base/java.lang.reflect.Method.invoke(Unknown Source); at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:343); at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:328); at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:279); at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1008); at groovy.lang.Closure.call(Closure.java:433); at groovy.lang.Closure.call(Closure.java:412); at groovy.lang.Closure.run(Closure.java:505); at java.base/java.lang.Thread.run(Unknown Source); ```. **Expected behavior**; The code runs without any exception. **Desktop (please complete the following information):**; - OS: macOS (but probably all); - QuPath Version: v0.5.1. **Additional context**; This seems to only occur with detections. The underlying issue in this specific case seems to be that these can return an unmodifiable list of measurement names, but when this is used by `PathObjectTools.getAvailableFeatures(Collection)` the underlying list is being modified. A fix may require revising `MeasurementList` more thoroughly to improve its robustness. > Edit: The original 'failing' script I posted here was failing because `pathObjects` was being modified... the version after I ended the issue fails in the 'right' place to show the issue I was trying to report.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1591:2595,detect,detections,2595,https://qupath.github.io,https://github.com/qupath/qupath/issues/1591,1,['detect'],['detections']
Safety,"ons everywhere; def allDetections = getDetectionObjects(); println ""Num detections (all): \t${allDetections.size()}"". // Direct children of the selected object; def childObjects = selectedObject.getChildObjects(); println ""Num child objects: \t${childObjects.size()}"". // Get all detections for the region (rectangular bounding box, quick test); def region = ImageRegion.createInstance(roi); def regionObjects = hierarchy.getAllDetectionsForRegion(region, null); println ""Num in region bounds: \t${regionObjects.size()}"". // Detections within selected object, using hierarchy rules; def hierarchyWithin = hierarchy.getAllDetectionsForROI(roi); println ""Num 'within' ROI: \t${hierarchyWithin.size()}"". // Detections with nucleus (or main ROI) centroids within the selected object; def nucleusCentroidWithin = PathObjectTools.filterByROIContainsNucleusCentroid(roi, allDetections); println ""Num nucleus centroid in ROI: \t${nucleusCentroidWithin.size()}"". // Detections with centroids within the selected object; def centroidWithin = PathObjectTools.filterByROIContainsCentroid(roi, allDetections); println ""Num centroid in ROI: \t${centroidWithin.size()}"". // Detections with ROIs intersecting the selected object; def intersecting = PathObjectTools.filterByROIIntersects(roi, allDetections); println ""Num intersecting ROI: \t${intersecting.size()}"". // Detections with ROIs intersecting the selected object - accessed from region; // This should contain the same elements as intersecting (possibly in a different order); def intersecting2 = PathObjectTools.filterByROIIntersects(roi, regionObjects); assert intersecting.size() == intersecting2.size(); assert (intersecting as Set) == (intersecting2 as Set). // Detections with ROIs completely within the selected object; def completelyCovered = PathObjectTools.filterByROICovers(roi, allDetections); println ""Num completely covered: \t${completelyCovered.size()}"". // Set classifications for visualization; allDetections.each {it.classifications = []}",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1563#issuecomment-2264806074:1741,Detect,Detections,1741,https://qupath.github.io,https://github.com/qupath/qupath/pull/1563#issuecomment-2264806074,1,['Detect'],['Detections']
Safety,"ons() TMA grid object isEditable property remains false (i.e. TMA grid circles cannot be rearranged etc). **To Reproduce**; Steps to reproduce the behavior:. setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049"", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759"", ""Background"" : "" 255 255 255""}');. //De-array TMA; runPlugin('qupath.imagej.detect.dearray.TMADearrayerPluginIJ', '{""coreDiameterMM"": 1.2, ""labelsHorizontal"": ""1-16"", ""labelsVertical"": ""A-J"", ""labelOrder"": ""Row first"", ""densityThreshold"": 5, ""boundsScale"": 105}');; selectTMACores();. //Detect cells using some method such as DAB; runPlugin('qupath.imagej.detect.cells.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.0, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": false, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Cell: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');. clearDetections();; fireHierarchyUpdate();; getTMACoreList().each{; println(it.isEditable());; };. INFO: false; INFO: false; INFO: false. **Expected behavior**; As the definition of isEditable() is ""TMA core cannot be edited if it contains any detections,"" I would expect TMA to be editable if you clear detections. Or there could be a setEditable() method to override. **Screenshots**; If applicable, add screenshots to help explain your problem. **Desktop (please complete the following information):**; - OS: Windows 10 10.0; - QuPath Version 0.3.2. **Additional context**; I was not able to find mentions of this issue using the search term of 'clearDetections()'",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1021:2541,detect,detections,2541,https://qupath.github.io,https://github.com/qupath/qupath/issues/1021,2,['detect'],['detections']
Safety,"opic is really about loading training data to create classifiers, not classifiers themselves, so I will hide these posts to avoid distraction). —; Reply to this email directly, view it on GitHub<https://secure-web.cisco.com/1S_KCvGqBkfLiU4jUNxk9Bycpt04YwO2EwOrgjo7gUjY2EmjAMNPYCK9KZ3g1BcPOjN1yFkyZLgJnmGWBrpfDiblAR5l3lwK7LfMcHNHJqtYoWGQYJ9WYQ6dCoewz0Xk9P5-ZDRFW4OknOTxChetxm4Bs7LEng-ebDLB6a6AAXrEy8mWNCALTRoJs81HHMcvnMhDSjonYiBRlurLnCnBJZ4a9YvcrT8TplefFlZKST3NVLHrWPL3RgIyoJsDosp8GVf6MH94rRAHuopZp9J5pOcqjQmwnlC51e34AFYd1-8yRTnj7X0qzcw7aHtnILPwFXQIqYdBTGMqf-iZSDUUexg/https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fissues%2F493%23issuecomment-1791280813>, or unsubscribe<https://secure-web.cisco.com/16fbsI3bTg2IXBtZ19rtjLXO9mTw2FP1PcVHSk2XFBBZjPYBQWKvTLiqsGr7UCwdHhDGRsg9tR1qzmQGBIyUICyyRtVvGvh-eu_HtL8Iyt807-ztz3U-i887buKPXzn2O2YTuhy7Xwb13QKvs-TXcflZ21x0cz69j7BIZd4l-aFk4r0Kw89JYQAASuY7o5O0vLb801LbUikLbLtblZgMPHiBe_SrbHoAccvQxrwkY0sMyvxdP_sq89PM0YloMPcUZfoeyvQt8mkLvXp5q2fymfiSTMaZDZDyzknBIzrUh60kAx4knbh5x28AHq2RAZ6YnA3Au7RGuJTZ8YYt7B4VE6g/https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FA5G6YB3KO5IO3F2PMFLETCDYCPOOXAVCNFSM4NF3XJJKU5DIOJSWCZC7NNSXTN2JONZXKZKDN5WW2ZLOOQ5TCNZZGEZDQMBYGEZQ>.; You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>; The information in this e-mail is intended only for the person to whom it is addressed. If you believe this e-mail was sent to you in error and the e-mail contains patient information, please contact the Mass General Brigham Compliance HelpLine at https://www.massgeneralbrigham.org/complianceline <https://www.massgeneralbrigham.org/complianceline> .; Please note that this e-mail is not secure (encrypted). If you do not wish to continue communication over unencrypted e-mail, please notify the sender of this message immediately. Continuing to send or respond to e-mail after receiving this message means you understand and accept this risk and wish to continue to communicate over unencrypted e-mail.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/493#issuecomment-1791396738:4378,risk,risk,4378,https://qupath.github.io,https://github.com/qupath/qupath/issues/493#issuecomment-1791396738,1,['risk'],['risk']
Safety,"otation(PathObject pathObject) {; def roiName = pathObject.getROI()?.getRoiName(); pathObject.setPathClass(PathClass.getInstance(roiName)); }; ```. I think it makes sense for such classifiers to be added to a single *Object classification* submenu, rather than split between *Detection* and *Annotation* (also, there might one day be a need to classify *TMA cores*, which don't fit into either category). Also, the top of the *Train object classifier* dialog makes it possible to select different types of objects to classify. <img width=""418"" alt=""Train object classifier"" src=""https://github.com/qupath/qupath/assets/4690904/d6977ca8-a018-4d33-bd7c-f31eed611749"">. Admittedly, these are all detections or subtypes of detection... but that's because I couldn't think of a good workflow to use them for annotations (since you're using annotations to train the classifier, how should QuPath distinguish between which annotations are for training and which should be classified...?). The internal representation of the object classifier is capable of specifying the type of object it should be applied to, even though we have no easy way to interactively create annotation classifiers through the user interface, or examples where that is actually used. Perhaps more usefully, we plan to enable the use of deep learning models for classification - and these don't have the complication of needing annotations for training. Much of the code to enable this has already been written, but we need to figure out how best to link it up to the user interface and provide meaningful models for the feature to be useful. When it *is* useful, I expect it to become *very* useful. QuPath's best features probably don't exist yet, but we try to design the software thinking far enough into the future so that they can be added... For that reason, if the fact that most commands under *Object classification* currently only work for detections is confusing, I think we need some other way to resolve that confusion.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1501#issuecomment-2075386110:3522,detect,detections,3522,https://qupath.github.io,https://github.com/qupath/qupath/issues/1501#issuecomment-2075386110,1,['detect'],['detections']
Safety,"otations. You can go through and set all the ‘Missing’ cores to be available, and all the available cores to be ‘Missing’. Then train up a new classifier, and export the results again.; This way you can use multiple classifiers. It’s not very elegant at all, and I’m not sure that I would recommend it… but it is an option.; > If you try this, you could toggle the ‘Missing’ status in a script or manually. If you do it manually, I’d suggest opening the ‘Hierarchy’ tab on the left of the screen, and selecting the first core. Make sure you have clicked somewhere inside the main viewer to activate it, then use the arrow keys to move around the TMA grid, and press ‘backspace’ to toggle the ‘Missing’ status. Because the default settings mean that selected cores are shown as yellow, rather than dark/light blue, having the ‘Hierarchy’ tab open is useful to show you whether the selected core is missing or not. 3. You could do something similar to the above, but set the ‘missing’ status before cell detection… so you end up without any cells in the cores that shouldn’t be included. This helps avoid generating a lot of badly-classified data that you then need to remember to ignore later. However, it does then require being able to estimate in advance which cores should be classified together. 4. If you want to use a separate classifier for every core, you could try a more drastic approach of exporting every core as a separate image. To do this, first dearray your slide. Then, you can use [Extension &rarr; ImageJ &rarr; ImageJ macro runner](https://github.com/qupath/qupath/wiki/Working-with-ImageJ#running-macros) to export each image. You need a very simple macro, like the one below:; ```; saveAs(""tif"", ""/Users/peteb/Desktop/export/"" + getTitle()); ```; where you’ll need to change the path to be something more suitable for your computer. It takes advantage of the fact that the ‘title’ of the image sent to ImageJ is the same as the TMA core, so using this as the filename can help y",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/57#issuecomment-288818401:2403,detect,detection,2403,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288818401,1,['detect'],['detection']
Safety,"ouble, double, double, double)'; java.lang.NoSuchMethodError: 'org.locationtech.jts.geom.Geometry qupath.lib.roi.GeometryTools.createRectangle(double, double, double, double)'; at qupath.ext.stardist.StarDist2D.lambda$detectObjects$10(StarDist2D.java:940); at java.base/java.util.stream.ReferencePipeline$2$1.accept(Unknown Source); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(Unknown Source); at java.base/java.util.stream.AbstractPipeline.evaluate(Unknown Source); at java.base/java.util.stream.ReferencePipeline.collect(Unknown Source); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:941); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:886); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$6(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:859); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$5(StarDist2D.java:812); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:812); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript.run(QuPathScript:48); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:331); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:161); at qupath.lib.gui.scripting.languages.DefaultScriptLanguage.execute(DefaultScriptLanguage.java:234); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:1179); at qupath.lib.gui.scripting.DefaultScriptEdito",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1635:1368,detect,detectObjects,1368,https://qupath.github.io,https://github.com/qupath/qupath/issues/1635,1,['detect'],['detectObjects']
Safety,"oud.githubusercontent.com/assets/4690904/20858862/a6a5f5e4-b946-11e6-823c-82dccca3a0ba.png"">. This doesn't force any particular choice... along it at least raises the issue. ### What *should* QuPath do?; This remains an open question - with feedback and ideas welcome. My current suspicion is that QuPath *should* enforce the use of one Locale consistently throughout the application. If so, this would likely have to be ```Locale.US``` - because this is [guaranteed to exist](https://docs.oracle.com/javase/7/docs/api/java/util/Locale.html#getAvailableLocales()). This will enforce an internal consistency, which is less likely to be troubled by whether or not the programmer of some component or extension parses their numbers in a different way. It *may* still be helpful to optionally export data for a specific Locale - but this would need to be explicitly selected (every time?), for ease of importing results into other software. However, providing this option would require some more thought and planning for at least two reasons:. * Some exported data should also be reimported into QuPath, e.g. exported TMA data might be imported to use the *TMA data viewer* - in this case the correct Locale needs to be used for importing as well.; * There are different ways to export, both in terms of saving or copying values to the clipboard. Any 'smart' behavior in one place risks lulling a user into a false sense of security that the Locale they unthinkingly expect will always be used. In short, it's a thorny issue. For now, the best approach is to use a Locale that formats uses dots rather than commas as the decimal mark... and then pay close attention whenever the exported results are imported elsewhere. ### Immediate plans. I am considering making the first half the change suggested above in the next update, i.e. to force the use of the US Locale. There is too much that is unclear or untested whenever different Locales may be used. However comments are welcome on the wisdom of this.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/29:7201,risk,risks,7201,https://qupath.github.io,https://github.com/qupath/qupath/issues/29,1,['risk'],['risks']
Safety,"path.opencv.dnn.OpenCVDnn$OpenCVNetFunction.predict(OpenCVDnn.java:732); qupath.opencv.dnn.DnnModel.convertAndPredict(DnnModel.java:100); qupath.ext.stardist.StarDist2D.detectObjectsForTile(StarDist2D.java:1249); qupath.ext.stardist.StarDist2D.lambda$detectObjects$7(StarDist2D.java:934); java.base/java.util.stream.ReferencePipeline$7$1.accept(Unknown Source); java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); java.base/java.util.stream.AbstractTask.compute(Unknown Source); java.base/java.util.concurrent.CountedCompleter.exec(Unknown Source); java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source); java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source); java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source); java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source). ```. **Expected behavior**; The script should run without any error, yielding cell detections within the annotation. **Desktop (please complete the following information):**; - OS: Windows 10; - QuPath Version: 0.4.0, built from source on 2022-12-07; - StarDist Extension Version: 0.4.0 (reproducible with 0.3.2 as well). **Additional context**; The changelog of 0.4.0 points to two separate issues that were marked as resolved, which could be linked to this issue:; https://github.com/qupath/qupath/issues/841; https://github.com/qupath/qupath-extension-stardist/issues/11. Given that issue #841 was marked as resolved 5 days ago, it could be linked to that. Perhaps there were some changes to the API such that closing of the model should be scripted differently?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1180:3619,detect,detections,3619,https://qupath.github.io,https://github.com/qupath/qupath/issues/1180,1,['detect'],['detections']
Safety,"perform them. 1/ Detect tissue using : `Analyze>Preprocessing>Simple Tissue Detection` ✓ ; 2/ Split it into multiple tiles : `Analyze>Region Identification>Tiles & Super Pixels` then select `Make annotation tiles` and `Remove parents annotation` ✓ ; 3/ Sending each tile to ImageJ for thresholding : `Extensions->ImageJ->ImageJ Macro runner`; So at this step, I am not sure how to perform that. As an example, I set the following into the Image Macro runner:; ```; run(""8-bit"");; setAutoThreshold(""Huang dark"");; //setThreshold(187, 255);; setOption(""BlackBackground"", false);; run(""Convert to Mask"");; run(""Analyze Particles..."", "" show=Overlay display clear"");; ```; Then I selected `Send ROI to ImageJ`, `Clear Current child Object` and `Create detection object from ImageJ overlay`. ![image](https://cloud.githubusercontent.com/assets/1775952/23943366/7c26ced2-096f-11e7-9cb9-f8ca32c9e1eb.png). To run it on the wholde slide, I selected all the annotation and pressed `Run`. Is that the correct way ?. And after running, indeed it worked:; ![image](https://cloud.githubusercontent.com/assets/1775952/23943815/fe38edd2-0970-11e7-9b84-b3cf189a51b3.png). For some reason, the background has also been selected, although it was outside of the tile.; -My first question is how to avoid that?. -Second question, all detected objects are by tile, is there a way to merge the connected one?. And finally, it works tile by tile, but in case I would like to perform the Weka segmentation (which could be done easily thanks to the bridge you made via an ImageJ Macro), since the weka segmentation perform filtering (gqussian, hessian etc...), ideally, I would like to process the tile with a little bit of extra border so for example a gaussian filter with a kernel of 4 will take into account the pixel outside of the tile. But right now, it will only take into account the pixels inside the tile. Anyway, thanks a lot for your help, I am going to play more with QuPath to test all the other possibilities!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/56#issuecomment-286702227:1389,avoid,avoid,1389,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286702227,2,"['avoid', 'detect']","['avoid', 'detected']"
Safety,"processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Writing object hierarchy with 29994 object(s)...; INFO: Image data written to N:\Faculty-of-Medicine-and-Health\LICAP\DATA\PTHY\Pathology\Breast Group\BCCTB Samples\Audits\BCN QA 2017\Frozen samples QuPath tumourstromaratio\Batch_2\Tumour\402428.qpdata in 2.08 seconds; INFO: Training size: 33x5031; INFO: Responses size: 1x50",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:3852,detect,detected,3852,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Writing object hierarchy with 29994 object(s)...; INFO: Image data written to N:\Faculty-of-Medicine-and-Health\LICAP\DATA\PTHY\Pathology\Breast Gro",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:3674,detect,detected,3674,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Writing object hierarchy with 29994 object(s)...; INFO: Image data written to N:\Faculty-of-Medicine-and-Health\LICAP\DATA\PTHY\Pathology\Breast Group\BCCTB Samples\Audits\BCN QA 2017\Frozen samples QuPath tumourstromaratio\Batch_2\Tumour\402428.qpdata in 2.08 seconds; INFO: Training size: 33x5031; INFO: Responses size: 1x5031; INFO: RTrees classifier termination criteria: { type: 1",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:3911,detect,detected,3911,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Writing object hierarchy with 29994 object(s)...; INFO: Image data written to N:\Faculty-of-Medicine-and-Health\LICAP\DATA\PTHY\Pathology\Breast Group\BCCTB Samples\Audits\BCN QA 2017\Frozen samples QuPath tu",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:3734,detect,detected,3734,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Writing object hierarchy with 29994 object(s)...; INFO: Image data written to N:\Faculty-of-Medicine-and-Health\LICAP\DATA\PTHY\Pathology\Breast Group\BCCTB Samples\Audits\BCN QA 2017\Frozen samples QuPath tumourstromaratio\Batch_2\Tumour\402428.qpdata in 2.08 seconds; INFO: Training size: 33x5031; INFO: Responses size: 1x5031; INFO: RTrees classifier termination criteria: { type: 1, maxCount: 50, epsilon: 0.0}; ERROR: QuPath exception; at ",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:3970,detect,detected,3970,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"ptEditor.executeScript(DefaultScriptEditor.java:1166); at qupath.lib.gui.scripting.DefaultScriptEditor$3.run(DefaultScriptEditor.java:1534); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by Cannot invoke ""java.awt.image.BufferedImage.getSampleModel()"" because ""img"" is null at qupath.imagej.tools.IJTools.convertToUncalibratedImagePlus(IJTools.java:791); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:864); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:902); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:216); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); ```; 6. Error repeats per tile. **Expected behavior**; To recognise bounds or the image in ""create full image annotation"" command, excluding what the error is calling ""null"" regions. **Screenshots**; ![image](https://github.com/qupath/qupath/assets/154437026/e0daa716-19b8-47f9-b337-aa02cb1e44e9). ![image](https://github.com/qupath/qupath/assets/154437026/990ad117-5649-4e15-b376-8bce56d722bb). **Desktop (please complete the following information):**; - OS: Windows 1",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443:3497,Detect,DetectionPluginTools,3497,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443,1,['Detect'],['DetectionPluginTools']
Safety,qupath fails to detect cells across entire TMA,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/294:16,detect,detect,16,https://qupath.github.io,https://github.com/qupath/qupath/issues/294,1,['detect'],['detect']
Safety,"rage of additional metadata, i.e. pixel sizes and coordinates.; */. import ij.IJ; import ij.ImagePlus; import qupath.imagej.images.servers.ImagePlusServer; import qupath.imagej.images.servers.ImagePlusServerBuilder; import qupath.lib.images.servers.ImageServer; import qupath.lib.regions.RegionRequest; import qupath.lib.scripting.QP. import java.awt.image.BufferedImage. /*; * Adjustable parameters; */; int tileWidthPixels = 5000 // Width of (final) output tile in pixels; int tileHeightPixels = tileWidthPixels // Width of (final) output tile in pixels; double downsample = 10 // Downsampling used when extracting tiles; String format = ""tif"" // Format of the output image - TIFF or ZIP is best for ImageJ to preserve pixel sizes; String dirOutput = ""G:\\Image Dump"" // BE SURE TO ADD AN OUTPUT DIRECTORY HERE!!!. int maxErrors = 20 // Maximum number of errors... to avoid trying something doomed forever; int minImageDimension = 1000 // If a tile will have a width or height < minImageDimension, it will be skipped; // This is needed to avoid trying to read/write images that are too tiny to be useful (and may even cause errors). //-------------------------------------------------------. /*; * Processing; */. // Check we have an output directory; if (dirOutput == null) {; println(""Be sure to set the 'dirOutput' variable!""); return; }. // Initialize error counter; int nErrors = 0. // Get the image server; ImageServer<BufferedImage> serverOriginal = QP.getCurrentImageData().getServer(). // Get an ImagePlus server; ImagePlusServer server = ImagePlusServerBuilder.ensureImagePlusWholeSlideServer(serverOriginal). // Ensure convert the format to a file extension; String ext; if (format.startsWith(""."")); ext = format.substring(1).toLowerCase(); else; ext = format.toLowerCase(). // Extract useful variables; String path = server.getPath(); String serverName = serverOriginal.getShortServerName(); double tileWidth = tileWidthPixels * downsample; double tileHeight = tileHeightPixels * downsa",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/85#issuecomment-315148862:1343,avoid,avoid,1343,https://qupath.github.io,https://github.com/qupath/qupath/issues/85#issuecomment-315148862,2,['avoid'],['avoid']
Safety,ransformPadded(Lorg/bytedeco/opencv/opencv_core/Mat;)Lorg/bytedeco/opencv/opencv_core/Mat; (64 bytes) @ 0x00000295ed0a7154 [0x00000295ed0a6c40+0x0000000000000514]; J 15720 c1 qupath.opencv.ops.ImageOps$PaddedOp.apply(Lorg/bytedeco/opencv/opencv_core/Mat;)Lorg/bytedeco/opencv/opencv_core/Mat; (35 bytes) @ 0x00000295ed1d409c [0x00000295ed1d3fa0+0x00000000000000fc]; J 15713 c1 qupath.opencv.ops.ImageOps$Core$SequentialMultiOp.apply(Lorg/bytedeco/opencv/opencv_core/Mat;)Lorg/bytedeco/opencv/opencv_core/Mat; (42 bytes) @ 0x00000295ed5c8654 [0x00000295ed5c8300+0x0000000000000354]; J 15744 c1 qupath.opencv.ops.ImageOps$DefaultImageDataOp.apply(Lqupath/lib/images/ImageData;Lqupath/lib/regions/RegionRequest;)Lorg/bytedeco/opencv/opencv_core/Mat; (74 bytes) @ 0x00000295ed0532ac [0x00000295ed052e20+0x000000000000048c]; J 14791 c2 qupath.tensorflow.stardist.StarDist2D.detectObjectsForTile(Lqupath/opencv/ops/ImageDataOp;Lqupath/lib/images/ImageData;Lqupath/lib/regions/RegionRequest;ZLorg/locationtech/jts/geom/Geometry;)Ljava/util/List; (146 bytes) @ 0x00000295f4f057b8 [0x00000295f4f05760+0x0000000000000058]; J 15706 c1 qupath.tensorflow.stardist.StarDist2D.lambda$detectObjects$1(Lqupath/lib/images/ImageData;Ljava/util/Collection;Lorg/locationtech/jts/geom/Geometry;Lqupath/lib/images/servers/TileRequest;)Ljava/util/stream/Stream; (36 bytes) @ 0x00000295ed75f334 [0x00000295ed75f160+0x00000000000001d4]; J 15743 c1 qupath.tensorflow.stardist.StarDist2D$$Lambda$2526.apply(Ljava/lang/Object;)Ljava/lang/Object; (24 bytes) @ 0x00000295ee0909ac [0x00000295ee090840+0x000000000000016c]; J 15156 c1 java.util.stream.ReferencePipeline$7$1.accept(Ljava/lang/Object;)V java.base@14.0.1 (127 bytes) @ 0x00000295edec35a4 [0x00000295edec34a0+0x0000000000000104]; J 15667 c2 java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Ljava/util/function/Consumer;)V java.base@14.0.1 (127 bytes) @ 0x00000295f51c2d44 [0x00000295f51c2c00+0x0000000000000144]; J 11772 c2 java.util.stream.AbstractPipeline.wrap,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/481:4198,detect,detectObjectsForTile,4198,https://qupath.github.io,https://github.com/qupath/qupath/issues/481,1,['detect'],['detectObjectsForTile']
Safety,rce); at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(Unknown Source); at java.base/java.util.stream.AbstractPipeline.evaluate(Unknown Source); at java.base/java.util.stream.ReferencePipeline.collect(Unknown Source); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:941); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:886); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$6(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:823); at qupath.ext.stardist.StarDist2D.detectObjectsImpl(StarDist2D.java:859); at qupath.ext.stardist.StarDist2D.lambda$detectObjects$5(StarDist2D.java:812); at qupath.ext.stardist.StarDist2D.runInPool(StarDist2D.java:849); at qupath.ext.stardist.StarDist2D.detectObjects(StarDist2D.java:812); at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321); at QuPathScript.run(QuPathScript:48); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:331); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:161); at qupath.lib.gui.scripting.languages.DefaultScriptLanguage.execute(DefaultScriptLanguage.java:234); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:1179); at qupath.lib.gui.scripting.DefaultScriptEditor$3.run(DefaultScriptEditor.java:1545); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source). ```. Best; Ofra,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1635:1795,detect,detectObjects,1795,https://qupath.github.io,https://github.com/qupath/qupath/issues/1635,1,['detect'],['detectObjects']
Safety,"read] [INFO ] q.l.i.servers.ImageServerProvider - Returning server: ImageJ server for /home/bl/Documents/IMG_5_11_sq.png; 02:40:14.153 [JavaFX Application Thread] [INFO ] qupath.lib.gui.viewer.QuPathViewer - Image data set to ImageData: Fluorescence, IMG_5_11_sq; 02:40:22.852 [JavaFX Application Thread] [INFO ] q.lib.scripting.DefaultScriptEditor - Loading script file /home/bl/ip/QuPath/app/TestJep.groovy; 02:40:28.109 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean red (from Java): 86.81525; 02:40:28.121 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean green (from Java): 72.492275; 02:40:28.124 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean blue (from Java): 68.141675; 02:40:28.624 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Started JEP: jep.Jep@6bc4b2e2; ImportError: numpy.core.multiarray failed to import; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f930536d03f, pid=27357, tid=0x00007f932091e700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-2ubuntu0.16.04.2-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [jep.so+0x1a03f] convert_jndarray_pyndarray+0x5bf; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/bl/ip/QuPath/app/hs_err_pid27357.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. [1]+ Aborted (core dumped) ./QuPath; ```. I am thinking that this might be worth bringing up with the JEP developers. I am going to spend a little more time playing with J",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/27#issuecomment-262870405:9427,detect,detected,9427,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405,1,['detect'],['detected']
Safety,"resulting polygons into a single polygon or multipolygon. This addressing the pixel classification performance bottleneck described at https://forum.image.sc/t/can-creating-detections-from-pixel-classifier-be-made-to-run-faster/96745. When implementing this, it became clear that extremely complex polygons couldn't be displayed in the viewer because generating an `Area` object failed (ultimately with out-of-memory error). Also, `PolygonROI.getGeometry()` was slow when called repeatedly because the geometry is recomputed each time. So the PR uses a `SoftReference` to avoid this, while still allowing references to be dropped when memory is low. When the geometry isn't needed, the overhead should be avoided. This PR also addresses this problem by using JTS' shape representation instead. ## To test. ### Union of many objects. A simple test:; * Detect cells in an image; * Run the following script. ```groovy; import qupath.lib.common.Timeit; import qupath.lib.roi.GeometryTools. import static qupath.lib.scripting.QP.*. def detections = getDetectionObjects(). List<GeometryTools> geoms = detections.collect {it.getROI().getGeometry()}. def timeit = new Timeit(); .start(); def geomUnion = GeometryTools.union(geoms); println timeit.stop(). double sumArea = geoms.sum {g -> g.getArea()}; println ""Sum area: \t${sumArea}""; println ""Num geometries: \t${geoms.size()}""; def roi = GeometryTools.geometryToROI(geomUnion, ImagePlane.getDefaultPlane()); def pathClass = getPathClass(""Merged geometries""); removeObjects(getAnnotationObjects().findAll(p -> p.getPathClass() == pathClass), true); addObject(PathObjects.createAnnotationObject(roi, pathClass)); ```. ### Pixel classification. One approach to test with CMU-1.svs is to save the following pixel classifier:; * [Nuclei.json](https://github.com/user-attachments/files/15809355/Nuclei.json). and run a simple script to generate detections in a large region, e.g.; ```groovy; createDetectionsFromPixelClassifier(""Nuclei"", 5.0, 5.0, ""SPLIT""); ```",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1543:1533,detect,detections,1533,https://qupath.github.io,https://github.com/qupath/qupath/pull/1543,3,['detect'],['detections']
Safety,"rialization quite easy if it's required in a script anyway... except if things are circular. Which brings me to... * `exportObjectsAsSerialized` looks like it doesn't actually use the transformed list; it also potentially allows circular references via parents/children, which could be confusing and/or buggy. I don't think we need this method if we are discouraging serialization (although I could be wrong... especially if we find a way to use it internally for convenience). * *If* `importObjectsFromSerialized` is in the public API, I think it should handle things other than lists, e.g. individual objects, arrays of objects, collections. But I'd prefer to expose it in the public API only if its benefits are clear enough. * It looks like `.qpdata` is being used for serialized object lists. We really shouldn't add a new file type with the same extension. Rather, we *can* read objects from an existing `.qpdata` file using [`PathIO.readHierarchy(File)`](https://github.com/qupath/qupath/blob/43aad4ecda893a7eb03c30774e64da5b9547bc86/qupath-core/src/main/java/qupath/lib/io/PathIO.java#L410) - this should work even if the server is unavailable itself. The ability to import from old `.qpdata` files is important, but I'd like to avoid encouraging anyone to write `.qpdata` files other than those handled internally within projects (to make it easier for us to replace the format in the future). * A common use case will be transferring objects between images in the same project. Ideally this would be possible without exporting/importing, but rather simply choosing the project entry for import. Internally, this can use [`ProjectImageEntry.readHierarchy()`](https://github.com/qupath/qupath/blob/43aad4ecda893a7eb03c30774e64da5b9547bc86/qupath-core/src/main/java/qupath/lib/projects/ProjectImageEntry.java#L210).; * Adding this to the UI is tricky, since navigating long lists of project entries is awkward.... could it be supported by dragging an entry from the project list onto a viewer?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/666#issuecomment-787868344:4019,avoid,avoid,4019,https://qupath.github.io,https://github.com/qupath/qupath/pull/666#issuecomment-787868344,1,['avoid'],['avoid']
Safety,ries from /home/gordon/src/qupath/maven/repo/org/openslide/openslide/3.4.1_2/openslide-3.4.1_2-natives-linux.jar into build/qupath; Extracting native libraries from /home/gordon/src/qupath/maven/repo/net/sourceforge/jpen/jpen/2-150301/jpen-2-150301-natives-linux.jar into build/qupath; LICENSE PATH: /home/gordon/src/qupath/license-unknown.txt; > Task :clean; > Task :qupath-core:clean; > Task :qupath-core-processing:clean; > Task :qupath-experimental:clean; > Task :qupath-extension-bioformats:clean; > Task :qupath-extension-omero:clean; > Task :qupath-extension-openslide:clean; > Task :qupath-extension-pen:clean; > Task :qupath-extension-processing:clean; > Task :qupath-extension-script-editor:clean; > Task :qupath-extension-svg:clean; > Task :qupath-extension-tensorflow:clean UP-TO-DATE; > Task :qupath-gui-fx:clean. > Task :qupath-core:compileJava; Note: Some input files use or override a deprecated API.; Note: Recompile with -Xlint:deprecation for details.; Note: Some input files use unchecked or unsafe operations.; Note: Recompile with -Xlint:unchecked for details. > Task :qupath-core-processing:compileJava; Note: Some input files use or override a deprecated API.; Note: Recompile with -Xlint:deprecation for details.; Note: Some input files use unchecked or unsafe operations.; Note: Recompile with -Xlint:unchecked for details. > Task :qupath-gui-fx:compileJava; Note: Some input files use or override a deprecated API.; Note: Recompile with -Xlint:deprecation for details.; Note: Some input files use unchecked or unsafe operations.; Note: Recompile with -Xlint:unchecked for details. > Task :qupath-extension-processing:compileJava; Note: Some input files use or override a deprecated API.; Note: Recompile with -Xlint:deprecation for details. > Task :qupath-experimental:compileJava; Note: /home/gordon/src/qupath/qupath-experimental/src/main/java/qupath/lib/gui/align/ImageAlignmentPane.java uses or overrides a deprecated API.; Note: Recompile with -Xlint:deprecation for d,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/484#issuecomment-630769356:2250,unsafe,unsafe,2250,https://qupath.github.io,https://github.com/qupath/qupath/issues/484#issuecomment-630769356,1,['unsafe'],['unsafe']
Safety,"rintln ""imageData != Null""; }. def server = imageData.getServer(); ```; 2. Run the script referencing an image on the command line: ; ```; ./QuPath-0.2.0 -i=myimage.svs script myscript.groovy; ```; 3. See error:; imageData == Null; NullPointerException at line 11: Cannot invoke method getServer() on null object. **Expected behavior**; I would expect that if the command line arguments were changed to the new format the script processing would work the same as 0.2.0-m9 and earlier. The script editor seems to work just fine. Example working output from 0.2.0-m9 is shown below: . 10:23:10.593 [main] [INFO ] qupath.QuPath - Launching QuPath with args: -image, myimage.svs, -script, myscript.groovy; 10:23:11.387 [main] [WARN ] q.l.i.s.b.BioFormatsImageServer - Temp memoization directory created at /var/folders/9_/b0xrdp2d1bsbzlmwp3xff2g00000gn/T/qupath-memo-8955966830564346412; 10:23:11.388 [main] [WARN ] q.l.i.s.b.BioFormatsImageServer - If you want to avoid this warning, either disable Bio-Formats memoization in the preferences or specify a directory to use; 10:23:11.563 [main] [WARN ] q.l.i.s.ImageServerMetadata$ImageResolutionLevel - Calculated downsample values differ for x & y for level 4: x=70.0 and y=70.10548523206751 - will use value 70.05274261603375; 10:23:11.573 [main] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.codehaus.groovy.vmplugin.v7.Java7$1 (file:/Applications/QuPath-0.2.0-m9.app/Contents/app/groovy-2.5.9.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class,int); WARNING: Please consider reporting this to the maintainers of org.codehaus.groovy.vmplugin.v7.Java7$1; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; imageData != Null. **Desktop (please complete the following information",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/511:2237,avoid,avoid,2237,https://qupath.github.io,https://github.com/qupath/qupath/issues/511,1,['avoid'],['avoid']
Safety,"riptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by null at qupath.lib.images.servers.BioFormatsImageServer.getTimePoint(BioFormatsImageServer.java:930); at qupath.imagej.images.servers.BufferedImagePlusServer.getTimePoint(BufferedImagePlusServer.java:173); at qupath.imagej.helpers.IJTools.calibrateImagePlus(IJTools.java:220); at qupath.imagej.images.servers.BufferedImagePlusServer.readImagePlusRegion(BufferedImagePlusServer.java:241); at qupath.imagej.detect.tissue.SimpleTissueDetection2$GlobalThresholder.runDetection(SimpleTissueDetection2.java:158); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:120); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); INFO: Processing complete in 4,20 seconds; INFO: Completed with error java.lang.NullPointerException; INFO: ; qupath.imagej.detect.tissue.SimpleTissueDetection2 {""threshold"": 224, ""requestedPixelSizeMicrons"": 20.0, ""minAreaMicrons"": 100000.0, ""maxHoleAreaMicrons"": 1000000.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": true, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:11436,Detect,DetectionPluginTools,11436,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,4,"['Detect', 'detect']","['DetectionPluginTools', 'DetectionRunnable', 'detect']"
Safety,"riptEngineImpl.java:161); at qupath.lib.gui.scripting.languages.DefaultScriptLanguage.execute(DefaultScriptLanguage.java:234); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:1166); at qupath.lib.gui.scripting.DefaultScriptEditor$3.run(DefaultScriptEditor.java:1534); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by Cannot invoke ""java.awt.image.BufferedImage.getSampleModel()"" because ""img"" is null at qupath.imagej.tools.IJTools.convertToUncalibratedImagePlus(IJTools.java:791); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:864); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:902); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:216); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); ```; 6. Error repeats per tile. **Expected behavior**; To recognise bounds or the image in ""create full image annotation"" command, excluding what the error is calling ""null"" regions. **Screenshots**; ![image](https://github.com/qupath/qupath/assets/154437026/e0daa716-19b8-47f9-b337-aa02cb1e44e9). ![ima",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443:3336,detect,detect,3336,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443,1,['detect'],['detect']
Safety,"rizontal"": ""1-16"", ""labelsVertical"": ""A-J"", ""labelOrder"": ""Row first"", ""densityThreshold"": 5, ""boundsScale"": 105}; INFO: Adding Rectangle to hierarchy; INFO: Requesting region for stain vector editing: ; INFO: 1932 nuclei detected (processing time: 3.82 seconds); INFO: Processing complete in 3.92 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 1165 nuclei detected (processing time: 3.94 seconds); INFO: Processing complete in 3.98 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Requesting region for stain vector editing: ; INFO: Adding Rectangle to hierarchy; INFO: Requesting region for stain vector editing: ; INFO: 989 nuclei detected (processing time: 1.90 seconds); INFO: Processing complete in 1.92 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": fals",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418647572:2230,detect,detectionImageBrightfield,2230,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418647572,1,['detect'],['detectionImageBrightfield']
Safety,"rocessing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadi",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:3258,detect,detected,3258,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"s a continual fight to avoid very expensive processing every time an object changed - because `resolveHierarchy()` was effectively being called automatically, and lots of things needed to update. I thinks this shows event system is *very* overdue a major revision. > I'm sure there is reason behind it, but here a hierarchy changed event is emitted, instead of an object added event. From your post and my failing memory, I suspect that the idea was that the 'object added' event would just handle a single object, but if multiple objects were added then we fired a more general structure change event. I guess this was because, when adding a single object, we knew that it could only affect ancestor and descendent objects in QuPath v0.1.2 and earlier. But if we changed multiple objects, then all the *potential* auto-resolved parent/child relationships between objects would be too complex to decipher. Instead, it was easier and safer to fire an event that basically said: _'something big changed, don't try to figure out exactly what, but just update to handle the hierarchy as it now is'_. I'm reluctant to switch to `addObjects` firing an event that doesn't include all the objects that were added, in case there is any legacy code that might be sensitive to the change. Which leads to... > So, [this condition](https://github.com/qupath/qupath/blob/3544e613b40fd123236936d76e2cb5ee08d855f7/qupath-gui-fx/src/main/java/qupath/lib/gui/UndoRedoManager.java#L474) is true, the event is ignored, and the UndoRedoManager doesn't update its state. It looks like I failed to recognize that ; ```java; event.getChangedObjects().stream().allMatch(p -> p instanceof ParallelTileObject); ```; would return true when `getChangedObjects().isEmpty()`. What it be sufficient to change the problematic condition to this?. ```java; // Try to avoid calling too often; 		if (undoingOrRedoing || event.isChanging() || maxUndoHierarchySize.get() <= 0); 			return;. 		// During processing, we have ParallelTileObjec",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1578#issuecomment-2276091306:1190,safe,safer,1190,https://qupath.github.io,https://github.com/qupath/qupath/pull/1578#issuecomment-2276091306,1,['safe'],['safer']
Safety,"s in context; * Added 'Advanced' features, including optional PCA and selecting a 'Boundary' classification; * Ability to save & reload classifiers (format may change!); * New 'Create threshold classifier' command (replaces old simple threshold command); * Improved 'Dark' theme (available in the preferences); * Scripting Improvements; * Changed syntax highlighting - for better behavior with the 'Dark' theme; * Core classes can now be auto-imported (use Ctrl-Shift to cycle through code-completions); * More helpful error messages for common errors; * New setPixelSizeMicrons(double, double) scripting method; * New replaceClassification(String, String) scripting method; * Warning when applying 'Run for project' to an image currently open; * Major ROI revisions; * Area ROIs 'snap' to pixel coordinates by default (can be changed in the preferences); * New GeometryROI replaces AWTAreaROI; * 'Distance to annotations 2D' now supports line and point ROIs; * Increased use of Java Topology Suite for Geometry calculations; * Removed older interfaces (PathShape, PathPoints, PathArea, PathLine and TranslatableROI), moved more methods into ROI directly; * Zoom in further for more accurate pixel-wise annotations; * Revised cell detection & other detection commands that use tiling; * Bigger tile overlap & improved contour smoothing in cell detection (note: this will impact results!); * Wand tool improvements; * Change wand color modes in Edit -> Preferences; * Press Ctrl (Cmd) while using Wand to select identical pixel values (useful with classification overlays); * Renamed & improved 'Create simple thresholder', support image smoothing; * New 'Memory monitor' and 'Show input display' commands in 'View' menu; * Summary measurements are displayed for the full image when no objects are selected; * Added 'saveImageMeasurement' scripting command; * Revised how images are written; * Moved 'ImageWriterTools' to core module, updated 'ImageWriter' interface; * Changed 'File -> Export regions.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/370:1586,detect,detection,1586,https://qupath.github.io,https://github.com/qupath/qupath/pull/370,3,['detect'],['detection']
Safety,"s is a feature proposal for consideration and discussion**_. ## Feature request. **Is your feature request related to a problem? Please describe.**; Some aspects of QuPath require having a project. This can result in the user having to create a project they don't want, just to explore some feature quickly. Then they have to delete the project folder afterwards - or have it linger, with lots of `untitled folder` polluting their desktops. **Describe the solution you'd like**; The proposal here is to *always* have a project in QuPath. If one isn't chosen by the user, QuPath behaves as if it still has a 'temporary' project, using a temp directory if needed. This temp project should automatically be deleted after QuPath is closed. **Describe alternatives you've considered**; 1. We could keep the current behavior... although it is a bit annoying.; 2. We could make it possible to create a project for the currently-open image, rather than requiring the decision to make a project to happen *before* starting any kind of analysis. **Additional context**. Advantages of the 'temp project' approach:; * It should become possible to work on multiple images (and saved pixel/object classifiers) during a quick QuPath session, without having to create a new project folder explicitly. ; * Greater consistency in QuPath's behaviour. For example, it would mean we can _always_ handle drag & drop of multiple images (noted by @lauranicolass); * The user can decide to make a temp project permanent *after* having done some work; if they choose to save their changes, the temp folder is copied to their chosen location. Risks/Disadvantages:; * It needs to be **very clear** to the user what is what is happening, due to the potential for data loss if someone thinks they have a persistent project, but really only has a temp project.; * The assumption is that we can always write a temp directory. I'm not sure if we need to handle cases where we don't write anything to disk at all.; * Added complexity.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1453:1622,Risk,Risks,1622,https://qupath.github.io,https://github.com/qupath/qupath/issues/1453,1,['Risk'],['Risks']
Safety,"s); 12:35:12.234 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension ImageJ extension (34 ms); Warning: Could not load Loader: java.lang.UnsatisfiedLinkError: no jnijavacpp in java.library.path: [/home/gordon/src/qupath/build/dist/QuPath-0.2.0-m12/lib/app, /home/gordon/src/qupath/build/dist/QuPath-0.2.0-m12/bin]; 12:35:12.248 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension JPen extension (13 ms); May 26, 2020 12:35:12 PM jpen.provider.NativeLibraryLoader$4 run; INFO: loading JPen 2-150301 JNI library: jpen-2-4-x86_64 ...; May 26, 2020 12:35:12 PM jpen.provider.NativeLibraryLoader$4 run; INFO: jpen-2-4-x86_64 loaded; Warning: Could not load Pointer: java.lang.UnsatisfiedLinkError: no jnijavacpp in java.library.path: [/home/gordon/src/qupath/build/dist/QuPath-0.2.0-m12/lib/app, /home/gordon/src/qupath/build/dist/QuPath-0.2.0-m12/bin]; #; # A fatal error has been detected by the Java Runtime Environment:; [thread 50032 also had an error]; #; # SIGSEGV (0xb) at pc=0x00007f6271c2df1e, pid=49988, tid=50030; #; # JRE version: OpenJDK Runtime Environment AdoptOpenJDK (14.0.1+7) (build 14.0.1+7); # Java VM: OpenJDK 64-Bit Server VM AdoptOpenJDK (14.0.1+7, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # C [libc.so.6+0x8af1e] __libc_malloc+0x11e; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/lib/systemd/systemd-coredump %P %u %g %s %t %c %h"" (or dumping to /home/gordon/src/qupath/core.49988); #; # An error report file with more information is saved as:; # /home/gordon/src/qupath/hs_err_pid49988.log; [thread 50020 also had an error]; #; # If you would like to submit a bug report, please visit:; # https://github.com/AdoptOpenJDK/openjdk-support/issues; #; [1] 49988 abort (core dumped) ./build/dist/QuPath-0.2.0-m12/bin/QuPath-0.2.0-m12; ```. The build I currently have with `-Ptensorflow-cpu=true` is working, including the wand tool and stardist.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/484#issuecomment-634101819:2457,detect,detected,2457,https://qupath.github.io,https://github.com/qupath/qupath/issues/484#issuecomment-634101819,2,"['abort', 'detect']","['abort', 'detected']"
Safety,"s, each one a TMA. I analyzed all of them about 6 months ago, exported the data I needed to excel, and analyzed it there. However, I wanted to add another variable to analyze the data by, and opened the QuPath project to add a variable to the TMA data grid.;  ; After doing this with the first five images, I saved one and clicked to open the next one, and went to the bathroom while it loaded. When I returned, it was telling me to select an image type, and I realized it had deleted all the annotations and detections. Upon further inspection, it had deleted all the detections and annotations on all of the images except the one I had just been editing, and showed the rest as new and unopened images. ;  ; I closed without saving and reopened, and then two had the detections and annotations restored. I've continued closing and reopening the project, and a different number of images have annotations each time. I have tried downloading the newest version of QuPath, after which there were 5 images with annotations and detections restored and one with only annotations restored. Since updating, the same data is the same every time I reopen it. I have also tried updating and restarting my computer. I have no idea how or why this happened or how to get my data back. This is many hours of work, and I'm scared to start my new project, if this is a possible outcome.;  ; **To Reproduce**; I'm sorry, but I have no idea.;  ; **Expected behavior**; Normally, when I go from one image to another, I save one and then the next one opens the old annotations and detections.;  ; **Screenshots**; <img width=""1264"" alt=""Screenshot 2023-09-04 at 6 43 43 PM"" src=""https://github.com/qupath/qupath/assets/79068467/16ab2d72-a5ad-4910-b1eb-c1fc0a9c8842"">; This is a list of images, you can see that it shows five on this view as opened and the rest as new. ;  ; **Desktop (please complete the following information):**;  - OS:  macOS Ventura Version 13.5.1 (22G90);  - QuPath Version: currently Version: 0.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1313:1107,detect,detections,1107,https://qupath.github.io,https://github.com/qupath/qupath/issues/1313,1,['detect'],['detections']
Safety,"scn file are pyramidal. I only selected the ""only tissue"" images (corresponding to the maximum magnification/resolution) to run the project on. ; ![selected for project](https://user-images.githubusercontent.com/47432131/53500012-2949e400-3a6f-11e9-8ebe-f29757c2d817.JPG); There are no objects in the Hierarchy or on the image; ![hierarchy](https://user-images.githubusercontent.com/47432131/53500109-50a0b100-3a6f-11e9-8577-d70b98b49a08.JPG); However, the script is running and detecting objects as you can see in the script editor. I added the ""merging annotation results"" script and now the merged txt file has all the annotations, although the single txt files still don't. Which is fine, since I only want the merged file.; ![exported txt file](https://user-images.githubusercontent.com/47432131/53500335-bbea8300-3a6f-11e9-9e55-76e6e881da5f.JPG); Now I want to know if there was a way to have the original image name exported with the annotations instead of the maximum resolution image name.; ![image name](https://user-images.githubusercontent.com/47432131/53500384-d45a9d80-3a6f-11e9-82ce-83c16e53627f.JPG); And if you could help me modify the merging annotation script so that instead of prompting for a directory file it saves the merged annotations on the project file directly. Do I have to replace; def dirResults = QuPathGUI.getSharedDialogHelper().promptForDirectory(); with; def dirResults = buildFilePath(PROJECT_BASE_DIR, 'annotation results'); ?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/268#issuecomment-467906370:479,detect,detecting,479,https://qupath.github.io,https://github.com/qupath/qupath/issues/268#issuecomment-467906370,1,['detect'],['detecting']
Safety,"se a convenient Groovy syntax, e.g.; ```groovy; getProject().metadata['key'] = 'value'; getProjectEntry().metadata['key'] = 'value'; getSelectedObject().metadata['key'] = 'value'; ```. ## Don't use metadata too much!; For `PathObject`, the metadata is generated lazily on demand - so imposes no overhead if it isn't needed. This means that *it's generally a bad idea to start adding metadata to detections* - especially if we may have a huge number.; It introduces considerable overhead to store a `Map` for each object.; This is typically find for other kinds of `PathObject`, but we don't want to store millions of additional maps if they are not needed. ## Use `""_key""` format for internal use; A documented convention for `MinimalMetadataStore` is to use `""_""` as the first character for metadata values that are used internally. The practical implication is that values starting with `""_""` aren't typically shown to the user, e.g. within measurement tables. ## Thread safety; The maps returned by `DefaultProject` and its image entries are synchronized. The map returned by `PathObject.getMetadata()` is currently *not* thread-safe. This can be confirmed with the following script:; ```groovy; def pathObject = PathObjects.createAnnotationObject(ROIs.createEmptyROI()). // Control synchronization; boolean doSynchronize = true. // Make sure we have no metadata at the start; pathObject.metadata.clear(); int before = pathObject.metadata.size(). java.util.stream.IntStream.range(0, 1000); .parallel(); .forEach(i -> {; def map = pathObject.metadata; if (doSynchronize) {; synchronized (map) {; map[UUID.randomUUID().toString()] = ""Yes""; }; } else {; map[UUID.randomUUID().toString()] = ""Yes""; }. }); ; int after = pathObject.metadata.size(); print ""Metadata added: ${after - before}""; ```; If using `synchronized (map)` for the updates, then 1000 values should be added. But otherwise, you will likely see fewer values at the end. > It is probably worth synchronizing the map in a future version.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1587:1292,safe,safety,1292,https://qupath.github.io,https://github.com/qupath/qupath/pull/1587,2,['safe'],"['safe', 'safety']"
Safety,"sed in that example - in particular, note that the default 'Requested pixel size' is large (20) in the first screenshot showing tissue detection, and the boundary is very coarse and inaccurate for the TMA core. In the second screenshot, this value is low (4), and the boundary is much better. The description is:. > For detecting large areas of tissue, e.g. a whole face section, you probably want a large value, e.g. 20 µm. For small regions of tissue, e.g. a TMA core, you probably want a smaller value, e.g. 2-5 µm. These values depend upon the pixel size information being stored in the image; if you are working with an image where that information is missing (e.g. a JPEG, a PNG) or incorrect then that would cause trouble. Apart from that, if you could provide any screenshots showing your results then this would help identify what is wrong. If the background is particularly dark and yellow then it *could* be the problem, because *Simple tissue detection* works by converting your image to grayscale first, and then applies a threshold to find darker or lighter pixels (this is why it's 'simple'... it doesn't use color information in any smarter way than that). If the background is dark enough, maybe this grayscale image doesn't have good enough contrast for the detection to work. But usually this isn't the case. If that does turn out that something more sophisticated is needed, then there would be other ways to detect the tissue that can be adapted to your particular images (e.g. with an ImageJ macro). But since these would require considerably more effort, it would be worth it to try to find *Simple tissue detection* settings that work well enough first. Finally, depending upon what you want to do you might not need to detect the tissue at all - I often don't. For example, you could simply detect cells within the TMA core directly. This can give you some measurements (e.g. percentages of positive cells, H-scores), but not others (e.g. tissue area, positive cell density).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/53#issuecomment-282469327:1499,detect,detection,1499,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282469327,5,['detect'],"['detect', 'detection']"
Safety,"ser-images.githubusercontent.com/16352785/33573958-c45aa460-d937-11e7-8d4f-1d13d89a5e61.png). Change the image type in the image tab into ""Brightfield H&E"". ; Then feed it with statistics. ; Analyse > Calculate features > add intensity features. Use these checkboxes: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574028-0b866eb4-d938-11e7-820d-3629d339a516.png). and run it for detections. . Next step is to train a classifier to detect the spheroids: First create a class ""Spheroid"" in the annotation tab by rightclick onto the list of classes: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574089-3396762e-d938-11e7-8665-d2eef84ae60b.png). Then use the polygon and draw a circle around spheroids can set class of the polygon to ""Spheproid""; and paint polygon in the whitespace and set class to other or whitespace: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574170-7e522f3c-d938-11e7-9a84-d75add61bf04.png). Now go to menue ""Classify"" > ""create detection classifier"". ; Press advanced options and then ""use all"". Then build and apply. ; ![grafik](https://user-images.githubusercontent.com/16352785/33574202-9c0ac8a4-d938-11e7-822b-a9706b8cf600.png). The first result looks like that: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574227-a943d70e-d938-11e7-84a0-f4aef4baa9b1.png). after enough training you can convert the spheroid reagions into real regions of interest and afterwards for example count cells: . That is done by: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574256-c49afc1c-d938-11e7-8dfc-f03f1967c133.png). choose only spheroids to be converted to roi: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574300-e2ee9d72-d938-11e7-9130-871b14ac3036.png). The image looks like that now: ; ![grafik](https://user-images.githubusercontent.com/16352785/33574325-f333fc72-d938-11e7-961f-0bafbeda1595.png). the brown areas are the speroid ROIs. ; You can now rund celldetect",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/121#issuecomment-349092952:1262,detect,detection,1262,https://qupath.github.io,https://github.com/qupath/qupath/issues/121#issuecomment-349092952,1,['detect'],['detection']
Safety,"servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:184); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:238); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:56); at qupath.lib.gui.viewer.overlays.PixelClassificationOverlay.lambda$requestTile$5(PixelClassificationOverlay.java:547); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); ```. **To Reproduce**; Steps to reproduce the behavior:; 1. Open OS-1.ndpi on an M1 Mac, set to have a maximum of 4GB RAM for QuPath; 2. Start training a pixel classifier (default resolution and settings); 3. Zoom out to force preview classification across the full image; 4. Open the log & await the error; * If no error appears, adjust training annotations if needed to create a new classifier (it usually doesn't take long); 5. Check Activity Monitor to confirm that QuPath does not seem to be using a particularly large amount of memory. **Expected behavior**; Pixel classification continues without error for as long as its real memory use remains reasonable. **Desktop (please complete the following information):**; - OS: macOS, ARM; - QuPath Version 0.3.0. **Additional context**; Following the suggestion in https://github.com/bytedeco/javacpp/issues/516 a workaround is to add the line ; ```; java-options=-Dorg.bytedeco.javacpp.maxPhysicalBytes=0; ```; at the end of the *QuPath.app/Contents/app/QuPath.cfg* file. This turns off the check that reports the error, but could be risky to introduce as a default - so this Issue was created to document the problem for now, and a workaround where needed.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856:4495,risk,risky,4495,https://qupath.github.io,https://github.com/qupath/qupath/issues/856,1,['risk'],['risky']
Safety,severe cell detection error - hard to reproduce,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/153:12,detect,detection,12,https://qupath.github.io,https://github.com/qupath/qupath/issues/153,1,['detect'],['detection']
Safety,"simple tissue detection cannot be trimmed by ""Alt+Brush"" - bug",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/82:14,detect,detection,14,https://qupath.github.io,https://github.com/qupath/qupath/issues/82,1,['detect'],['detection']
Safety,simple tissue detection on ndpi and tiffs generates artefacts in image corners,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/124:14,detect,detection,14,https://qupath.github.io,https://github.com/qupath/qupath/issues/124,1,['detect'],['detection']
Safety,"ssets/ad4a2204-2b96-4d5c-bdda-629fccffe2f6). ```groovy; // Get hierarchy & selected object/ROI; def hierarchy = getCurrentHierarchy(); def selectedObject = getSelectedObject(); def roi = selectedObject.getROI(). // Total number of detections everywhere; def allDetections = getDetectionObjects(); println ""Num detections (all): \t${allDetections.size()}"". // Direct children of the selected object; def childObjects = selectedObject.getChildObjects(); println ""Num child objects: \t${childObjects.size()}"". // Get all detections for the region (rectangular bounding box, quick test); def region = ImageRegion.createInstance(roi); def regionObjects = hierarchy.getAllDetectionsForRegion(region, null); println ""Num in region bounds: \t${regionObjects.size()}"". // Detections within selected object, using hierarchy rules; def hierarchyWithin = hierarchy.getAllDetectionsForROI(roi); println ""Num 'within' ROI: \t${hierarchyWithin.size()}"". // Detections with nucleus (or main ROI) centroids within the selected object; def nucleusCentroidWithin = PathObjectTools.filterByROIContainsNucleusCentroid(roi, allDetections); println ""Num nucleus centroid in ROI: \t${nucleusCentroidWithin.size()}"". // Detections with centroids within the selected object; def centroidWithin = PathObjectTools.filterByROIContainsCentroid(roi, allDetections); println ""Num centroid in ROI: \t${centroidWithin.size()}"". // Detections with ROIs intersecting the selected object; def intersecting = PathObjectTools.filterByROIIntersects(roi, allDetections); println ""Num intersecting ROI: \t${intersecting.size()}"". // Detections with ROIs intersecting the selected object - accessed from region; // This should contain the same elements as intersecting (possibly in a different order); def intersecting2 = PathObjectTools.filterByROIIntersects(roi, regionObjects); assert intersecting.size() == intersecting2.size(); assert (intersecting as Set) == (intersecting2 as Set). // Detections with ROIs completely within the selected",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1563#issuecomment-2264806074:1488,Detect,Detections,1488,https://qupath.github.io,https://github.com/qupath/qupath/pull/1563#issuecomment-2264806074,1,['Detect'],['Detections']
Safety,"ssing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Writing object hierarchy with 2",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:3557,detect,detected,3557,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"ssing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:3436,detect,detected,3436,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"ssing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""mak",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:3497,detect,detected,3497,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"st intuitive thing that should happen, and is not a bug. If this didn’t happen, then you if ran the cell detection command twice with the same parent selected, you would end up having every cell counted twice - not to mention the strange things that might happen with overlapping objects if you were to run other tiling/superpixel commands. It's not clear to me what was the purpose of doing manual counts followed by automated counts within the exact same region, but (as you've found) it is something that is not supported. You *could* do it the opposite way (i.e. automated counts followed by manual counts). However, if it was my goal to compare manual and automated cell counting then I would do the automatic counts in duplicate project and keep the data separated. Furthermore, you can do automated counts and then select 'Convert detections to points' within the 'Points tool' to initialize the (manually-editable) points that can subsequently be modified to generate 'semi-automated counts'. With regard to being unable to reopen a data file, this is something that has been reported some months ago (e.g. #58), but I'm not aware of it being an ongoing problem - or at least not one I have ever been able to reproduce. If QuPath fails to write a complete data file, then you should find that a '.qpdata.backup' file exits somewhere inside your project/data folder. If you strip the '.backup' data part from the file name, then it should be possible to recover the last saved version. > *-Information about the object hierarchy is at https://github.com/qupath/qupath/wiki/Object-hierarchies But from a quick look it seems that 'point' objects do not behave in the way you might expect, in that it appears that a point object is the child of a region if the *first* point is inside that region - and adding subsequent points (inside or outside the region) doesn't change this relationship. This is potentially a bug... or at least unintuitive behavior that may well change in a future release.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/112#issuecomment-342941759:1895,recover,recover,1895,https://qupath.github.io,https://github.com/qupath/qupath/issues/112#issuecomment-342941759,1,['recover'],['recover']
Safety,"st on GPUs. Tested with RTX 3090 and GTX 1660 Ti GPUs. I have a version of QuPath built on 2022-11-21 which has no problem running StarDist on the GPU, so it's likely tied to any commits between this period. Issue taken from forum post: https://forum.image.sc/t/stardist-gpu-support-unknown-error/74779. **To Reproduce**; Steps to reproduce the behavior:; 1. Build QuPath from source using the following command:; ```; git clone https://github.com/qupath/qupath; cd qupath; ./gradlew clean jpackage -Pcuda-redist; ```; 2. Install either the 0.3.2 or 0.4.0 releases of the StarDist extension: https://github.com/qupath/qupath-extension-stardist/releases; 3. Download pretrained models in .pb format; 4. Draw an annotation on a brightfield image; 5. Download the following script: https://github.com/MarkZaidi/Universal-StarDist-for-QuPath/blob/main/GPU_Multimodal%20StarDist%20Segmentation.groovy; 6. Run the script; 7. Observe the following error message:; ```; INFO: Performing detection on Brightfield image using single-channel trained model; INFO: [Annotation]; ERROR: OpenCV(4.6.0) D:\a\javacpp-presets\javacpp-presets\opencv\cppbuild\windows-x86_64-gpu\opencv-4.6.0\modules\dnn\src\cuda4dnn\csl\memory.hpp:54: error: (-217:Gpu API call) the provided PTX was compiled with an unsupported toolchain. in function 'cv::dnn::cuda4dnn::csl::ManagedPtr<float>::ManagedPtr'; in GPU_Multimodal StarDist Segmentation.groovy at line number -2. ERROR: org.bytedeco.opencv.opencv_dnn.Net.forward(Native Method); qupath.opencv.dnn.OpenCVDnn$OpenCVNetFunction.predict(OpenCVDnn.java:718); qupath.opencv.dnn.OpenCVDnn$OpenCVNetFunction.predict(OpenCVDnn.java:732); qupath.opencv.dnn.DnnModel.convertAndPredict(DnnModel.java:100); qupath.ext.stardist.StarDist2D.detectObjectsForTile(StarDist2D.java:1249); qupath.ext.stardist.StarDist2D.lambda$detectObjects$7(StarDist2D.java:934); java.base/java.util.stream.ReferencePipeline$7$1.accept(Unknown Source); java.base/java.util.ArrayList$ArrayListSpliterator.forEa",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1180:1698,detect,detection,1698,https://qupath.github.io,https://github.com/qupath/qupath/issues/1180,1,['detect'],['detection']
Safety,stardist/releases; 3. Download pretrained models in .pb format; 4. Draw an annotation on a brightfield image; 5. Download the following script: https://github.com/MarkZaidi/Universal-StarDist-for-QuPath/blob/main/GPU_Multimodal%20StarDist%20Segmentation.groovy; 6. Run the script; 7. Observe the following error message:; ```; INFO: Performing detection on Brightfield image using single-channel trained model; INFO: [Annotation]; ERROR: OpenCV(4.6.0) D:\a\javacpp-presets\javacpp-presets\opencv\cppbuild\windows-x86_64-gpu\opencv-4.6.0\modules\dnn\src\cuda4dnn\csl\memory.hpp:54: error: (-217:Gpu API call) the provided PTX was compiled with an unsupported toolchain. in function 'cv::dnn::cuda4dnn::csl::ManagedPtr<float>::ManagedPtr'; in GPU_Multimodal StarDist Segmentation.groovy at line number -2. ERROR: org.bytedeco.opencv.opencv_dnn.Net.forward(Native Method); qupath.opencv.dnn.OpenCVDnn$OpenCVNetFunction.predict(OpenCVDnn.java:718); qupath.opencv.dnn.OpenCVDnn$OpenCVNetFunction.predict(OpenCVDnn.java:732); qupath.opencv.dnn.DnnModel.convertAndPredict(DnnModel.java:100); qupath.ext.stardist.StarDist2D.detectObjectsForTile(StarDist2D.java:1249); qupath.ext.stardist.StarDist2D.lambda$detectObjects$7(StarDist2D.java:934); java.base/java.util.stream.ReferencePipeline$7$1.accept(Unknown Source); java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(Unknown Source); java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source); java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source); java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(Unknown Source); java.base/java.util.stream.AbstractTask.compute(Unknown Source); java.base/java.util.concurrent.CountedCompleter.exec(Unknown Source); java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source); java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source); java.base/java.util.concurre,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1180:2345,predict,predict,2345,https://qupath.github.io,https://github.com/qupath/qupath/issues/1180,1,['predict'],['predict']
Safety,starting TMA detection ends up in on cirle in the middle of the image. Looks like that: ; ![image](https://cloud.githubusercontent.com/assets/16352785/22471404/8a804fe4-e7d2-11e6-8c46-1cc888be4422.png),MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/48:13,detect,detection,13,https://qupath.github.io,https://github.com/qupath/qupath/issues/48,1,['detect'],['detection']
Safety,t qupath.lib.gui.viewer.overlays.PixelClassificationOverlay.lambda$requestTile$5(PixelClassificationOverlay.java:547); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by Physical memory usage is too high: physicalBytes (16451M) > maxPhysicalBytes (16384M) at org.bytedeco.javacpp.Pointer.deallocator(Pointer.java:712); at org.bytedeco.javacpp.Pointer.init(Pointer.java:126); at org.bytedeco.opencv.opencv_core.Mat.allocate(Native Method); at org.bytedeco.opencv.opencv_core.Mat.<init>(Mat.java:241); at qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predictWithLock(OpenCVClassifiers.java:468); at qupath.opencv.ml.OpenCVClassifiers$ANNClassifierCV.predictWithLock(OpenCVClassifiers.java:1425); at qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predict(OpenCVClassifiers.java:442); at qupath.opencv.ops.ImageOps$ML$StatModelOp.apply(ImageOps.java:2812); at qupath.opencv.ops.ImageOps$Core$SequentialMultiOp.apply(ImageOps.java:2294); at qupath.opencv.ops.ImageOps$ChannelImageDataOp.apply(ImageOps.java:424); at qupath.opencv.ml.pixel.OpenCVPixelClassifier.applyClassification(OpenCVPixelClassifier.java:104); at qupath.lib.classifiers.pixel.PixelClassificationImageServer.readTile(PixelClassificationImageServer.java:299); at qupath.lib.images.servers.AbstractTileableImageServer.getTile(AbstractTileableImageServer.java:184); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:238); at qupath.lib.images.servers.AbstractTileableImageServer.readBufferedImage(AbstractTileableImageServer.java:56); at qupath.lib.gui.viewer.overlays.PixelClassificationOverlay.lambda$requestTile$5(PixelClassific,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856:2007,predict,predictWithLock,2007,https://qupath.github.io,https://github.com/qupath/qupath/issues/856,1,['predict'],['predictWithLock']
Safety,"t release; * [x ] I've checked for existing GitHub issues describing the same problem. ## Bug report. **Describe the bug**; A clear and concise description of what the bug is.; After running clearDetections() TMA grid object isEditable property remains false (i.e. TMA grid circles cannot be rearranged etc). **To Reproduce**; Steps to reproduce the behavior:. setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049"", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759"", ""Background"" : "" 255 255 255""}');. //De-array TMA; runPlugin('qupath.imagej.detect.dearray.TMADearrayerPluginIJ', '{""coreDiameterMM"": 1.2, ""labelsHorizontal"": ""1-16"", ""labelsVertical"": ""A-J"", ""labelOrder"": ""Row first"", ""densityThreshold"": 5, ""boundsScale"": 105}');; selectTMACores();. //Detect cells using some method such as DAB; runPlugin('qupath.imagej.detect.cells.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.0, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": false, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Cell: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');. clearDetections();; fireHierarchyUpdate();; getTMACoreList().each{; println(it.isEditable());; };. INFO: false; INFO: false; INFO: false. **Expected behavior**; As the definition of isEditable() is ""TMA core cannot be edited if it contains any detections,"" I would expect TMA to be editable if you clear detections. Or there could be a setEditable() method to override. **Screenshots**; If applicable, add screenshots to help explain your problem. **Desktop (pleas",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1021:1736,detect,detectionImageBrightfield,1736,https://qupath.github.io,https://github.com/qupath/qupath/issues/1021,1,['detect'],['detectionImageBrightfield']
Safety,"t, we knew that it could only affect ancestor and descendent objects in QuPath v0.1.2 and earlier. But if we changed multiple objects, then all the *potential* auto-resolved parent/child relationships between objects would be too complex to decipher. Instead, it was easier and safer to fire an event that basically said: _'something big changed, don't try to figure out exactly what, but just update to handle the hierarchy as it now is'_. I'm reluctant to switch to `addObjects` firing an event that doesn't include all the objects that were added, in case there is any legacy code that might be sensitive to the change. Which leads to... > So, [this condition](https://github.com/qupath/qupath/blob/3544e613b40fd123236936d76e2cb5ee08d855f7/qupath-gui-fx/src/main/java/qupath/lib/gui/UndoRedoManager.java#L474) is true, the event is ignored, and the UndoRedoManager doesn't update its state. It looks like I failed to recognize that ; ```java; event.getChangedObjects().stream().allMatch(p -> p instanceof ParallelTileObject); ```; would return true when `getChangedObjects().isEmpty()`. What it be sufficient to change the problematic condition to this?. ```java; // Try to avoid calling too often; 		if (undoingOrRedoing || event.isChanging() || maxUndoHierarchySize.get() <= 0); 			return;. 		// During processing, we have ParallelTileObjects changing to show which part of the image is being handled; 		// - but we don't want to record these; 		if (!event.getChangedObjects().isEmpty() && event.getChangedObjects().stream().allMatch(p -> p instanceof ParallelTileObject)); 			return;; ```. From a quick try, I think that's enough to fix #1487 but you're deeper into the code than me. The `ParallelTileObjects` are the squares that appear during certain commands, like cell detection, to indicate what is happening. I expect that we could *dramatically* simplify `PathObjectHierarchyEvent` for future versions - but if we can make undo/redo less bad with a small change, that would be excellent.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1578#issuecomment-2276091306:2089,avoid,avoid,2089,https://qupath.github.io,https://github.com/qupath/qupath/pull/1578#issuecomment-2276091306,2,"['avoid', 'detect']","['avoid', 'detection']"
Safety,"t> Collection<T> filterByROIIntersectsNucleus(ROI roi, Collection<T> pathObjects); public static <T extends PathObject> Collection<T> filterByROIContainsNucleusCentroid(ROI roi, Collection<T> pathObjects); ```. In case you just want to check if objects are present quickly - but don't necessarily need the objects themselves - you can use:. ```java; // Old method, deprecated; public boolean hasObjectsForRegion(Class<? extends PathObject> cls, ImageRegion region). // New methods; public boolean hasObjectsForRegion(ImageRegion region); public boolean hasAnnotationsForRegion(ImageRegion region); public boolean hasDetectionsForRegion(ImageRegion region); ```. These should effectively report whether `getXXXForRegion` would return an empty collection or not, without needing to generate that collection. ### Accessing objects with point ROIs; This simply accesses objects then filters by ROI type. ```java; // Old method, deprecated; public synchronized Collection<PathObject> getPointObjects(Class<? extends PathObject> cls). // New methods; public Collection<PathObject> getAllPointObjects(); public Collection<PathObject> getAllPointAnnotations() ; ```; This should be sufficiently obscure that there is no need to have separate methods to request point objects of more classes. If you *really* need point detections, for example. filtering the resulting collection should be straightforward, e.g.; ```java; var pointAnnotations = hierarchy.getAllPointObjects().stream().filter(PathObject::isDetection).toList();; ```. ---. To support these changes, `GeometryROI.contains(x, y)` was also updated to make use of an [`IndexedPointInAreaLocator`](https://locationtech.github.io/jts/javadoc/org/locationtech/jts/algorithm/locate/IndexedPointInAreaLocator.html) for complex geometries - enabling centroid tests to benefit from performance improvements with no special logic required outside the `ROI` class itself. Also, some deprecated methods - and deprecated classes that used them - were removed.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1563:6153,detect,detections,6153,https://qupath.github.io,https://github.com/qupath/qupath/pull/1563,1,['detect'],['detections']
Safety,"tTools.java); 	2. Suppressed default constructor for non-instantiability; - BufferedImageTools; 	1. Created tests (TestBufferedImageTools.java); 	2. Suppressed default constructor for non-instantiability; 	3. Added 'breaks' to switch statement in setValues(...). <h1>qupath.lib.classifiers</h1>. - CompositeClassifier. 	1. Created tests (TestCompositeClassifier.java); 	2. Added comment in classifyPathObjects() to clarify the value of the returned int; - PathClassifierTools; 	1. Suppressed default constructor for non-instantiability; 	2. Fixed bug that did not handle missing measurement values (NaN) in setIntensityClassification(...). Now reset the PathClass to the non intensity ancestor class of the current object's one.; 	3. Throws an Exception if supplying an empty or null measurement name in setIntensityClassification(), as it can't perform classification without a measurement.; - PathIntensityClassifier; 	1. getRequiredMeasurements() with null measurement now returns an empty list to avoid NPE when calling getRequiredMeasurements() in CompositeClassifier; 	2. Fixed bug that did not handle missing measurement values (NaN) in setIntensityClassification(...). Now it does not change the class of the object if measurement is missing. Why? Because if we run a CompositeClassifier, one classifier's classification shouldn't be reset by the next one. <h1>qupath.lib.common</h1>. - ColorTools; 	1. Suppressed default constructor for non-instantiability.; 	2. Made class final.; - GeneralTools; 	1. Suppressed default constructor for non-instantiability.; 	2. Made class final.; 	3. Added some tests to existing tests.; 	4. Fixed blankString(...), which did not use the 'trim' param and was always trimming the input String.; 	5. Fixed isMultipartExtension(...) to account for String of length == 1.; 	6. almostTheSame(...) now relies on Apache common's equalsWithRelativeTolerance() method.; 	7. toURI(...) called with an empty String would return a path leading to QuPath's core module.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/687:1584,avoid,avoid,1584,https://qupath.github.io,https://github.com/qupath/qupath/pull/687,1,['avoid'],['avoid']
Safety,"tes"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INFO: 2 nuclei detected (processing time: 0.47 seconds); INFO: 1697 nuclei detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 7",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:2783,detect,detected,2783,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"tfield (H&E), 402428; INFO: 1 region detected (processing time: 215.44 seconds); INFO: Processing complete in 215.63 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.tissue.SimpleTissueDetection2 {""threshold"": 219, ""requestedPixelSizeMicrons"": 2.0, ""minAreaMicrons"": 20.0, ""maxHoleAreaMicrons"": 200.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INF",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:2362,detect,detected,2362,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"th.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:1166); at qupath.lib.gui.scripting.DefaultScriptEditor$3.run(DefaultScriptEditor.java:1534); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); Caused by Cannot invoke ""java.awt.image.BufferedImage.getSampleModel()"" because ""img"" is null at qupath.imagej.tools.IJTools.convertToUncalibratedImagePlus(IJTools.java:791); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:864); at qupath.imagej.tools.IJTools.convertToImagePlus(IJTools.java:902); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:216); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:112); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source); at java.base/java.util.concurrent.FutureTask.run(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); ```; 6. Error repeats per tile. **Expected behavior**; To recognise bounds or the image in ""create full image annotation"" command, excluding what the error is calling ""null"" regions. **Screenshots**; ![image](https://github.com/qupath/qupath/assets/154437026/e0daa716-19b8-47f9-b337-aa02cb1e44e9). ![image](https://github.com/qupath/qupath/assets/154437026/990ad117-5649-4e15-b376-8bce56d722bb). **Desktop (please complete the following ",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1443:3454,Detect,DetectionPluginTools,3454,https://qupath.github.io,https://github.com/qupath/qupath/issues/1443,2,['Detect'],"['DetectionPluginTools', 'DetectionRunnable']"
Safety,"thanks again @petebankhead. That was the issue. I'm posting the code in case somebody else is interested. . ```; if( (tw>400) && (tw>400) && (roi.getScaledArea(pixelWidth, pixelHeight)>9500) && (counter<10)){; RegionRequest request = RegionRequest.createInstance(path, 4, (int) roi.getBoundsX(), (int) roi.getBoundsY(),(int) roi.getBoundsWidth(), (int) roi.getBoundsHeight(), 0, 0); ; ; // Read the image region; ImagePlus imp = serverIJ.readImagePlusRegion(request).getImage(true); IJ.run(imp, ""8-bit"", """");; IJ.run(imp, ""Median..."", ""radius=3"");. IJ.run(imp, ""Statistical Region Merging"", ""q=10 showaverages"");; IJ.run(imp, ""Invert"", """");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Set Measurements..."", ""area mean standard modal min centroid center bounding fit shape feret's integrated median skewness kurtosis add redirect=None decimal=3"");; IJ.run(imp, ""Make Binary"", """");; IJ.run(imp, ""Erode"", """");; IJ.run(imp, ""Erode"", """");. // code for normalisation and preprocessing prior to segmentation. IJ.run(imp, ""Analyze Particles..."", ""size=20-Infinity circularity=0.40-1.00 display clear summarize add in_situ"");. RoiManager manager = RoiManager.getInstance();; if (manager == null); manager = new RoiManager(). if((manager==null) || (manager.getCount()<1)){; print(""No object detected""); }else{; ; // call IJ roi to qupath roi conversion; def ijROIs = QUPath_Send_Overlay_to_QuPath.createPathObjectsFromROIs(imp,; manager.getRoisAsArray(),; serverOriginal,; (double) 4,; true,true,0,0,0). for (annotationIJ in ijROIs) {; def roiIter = annotationIJ.getROI(); def pathObject3 = new PathDetectionObject(roiIter); addObject(pathObject3); }. manager.reset(); ; }; ; //print QP.detectionObjects.lastIndexOf(); ; counter++; imp2 = IJ.getImage();; imp2.close(); ; }; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/136#issuecomment-357668235:1284,detect,detected,1284,https://qupath.github.io,https://github.com/qupath/qupath/issues/136#issuecomment-357668235,2,['detect'],"['detected', 'detectionObjects']"
Safety,"through channels; for (def channel in server.getMetadata().getChannels()) {; // Extract the channel name; def channelName = channel.name; ; // Skip some channels; if ('DAPI' in channelName || 'Autofluorescence' in channelName); continue; ; // Create a classification name from the channel; // Here, I take the first bit up until any whitespace; def classificationName = channelName.split()[0]. // Define the measurement we want; def measurementName = ""Cell: $channelName mean""; ; // Calculate some threshold from the measurement; // Here, just the mean; double threshold = cells.measurements[measurementName].average(); ; // Append a classification to all the cells above the threshold; cells.each { cell ->; if (cell.measurements[measurementName] > threshold); cell.classifications += [classificationName]; }; }. // Figure update (could do this automatically...); fireHierarchyUpdate(); ```. Closer inspection reveals a few Groovy tricks at work:. * `List.each { }` as a shorter alternative to for loops; * Avoid explicitly calling getters (e.g. `channel.name` rather than `channel.getName()`, `cell.measurements` rather than `cell.getMeasurements()` or - previously in QuPath - `cell.getMeasurementList()`; * Getting from a map using `map[key]` syntax (rather than `map.get(key)`; * Calling a method on a list to get it applied to all elements... so `cells.measurements[measurementName].average()` first extracts all the measurements, then averages them; * Sneakily applying a `setClassifications()` again by accessing it like a property - and using collection concatenation with `=+` to join the old classifications to the new ones; * this works in the opposite direction, with `-=` to remove one or more classifications. The changes have been made without introducing any changes to QuPath's data files, since `PathClass` and `MeasurementList` are still doing the main work, it's just that there are now alternative ways to interact with them. They are designed to map well with Groovy tricks, whi",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1094#issuecomment-1289456235:1902,Avoid,Avoid,1902,https://qupath.github.io,https://github.com/qupath/qupath/pull/1094#issuecomment-1289456235,1,['Avoid'],['Avoid']
Safety,"time when I run a script, a temp file was generated in QuPath 0.2.0 but not 0.1.2. From the echo, Bioformats tries to delete the temp file, but the file path has one additional dot before the filename, so the deletion failed:. `6:23:09.798 [main] [WARN ] loci.formats.Memoizer - file deletion failed D:\QMDownload\5\os\.OS-3.vsi.bfmemo `. The file was ; `D:\QMDownload\5\os\OS-3.vsi.bfmemo ; `. After a successful running, all the output was:; ```; 16:23:06.071 [main] [INFO ] qupath.QuPath - Launching QuPath with args: -image, D:\\QMDownload\\5\\os\\OS-3.vsi, -script, C:\\Users\\rmd\\AppData\\Local\\Temp\\tpd56d11ce_e4ba_481c_a046_3d19297b763a.groovy ; 16:23:06.151 [main] [WARN ] q.lib.images.servers.FileFormatInfo - Strange 'bits per sample' of 0 ; 16:23:06.211 [main] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1 ; WARNING: An illegal reflective access operation has occurred ; WARNING: Illegal reflective access by com.esotericsoftware.kryo.util.UnsafeUtil (file:/C:/Program%20Files/QuPath-0.2.0-m1/app/kryo-2.24.0.jar) to constructor java.nio.DirectByteBuffer(long,int,java.lang.Object) ; WARNING: Please consider reporting this to the maintainers of com.esotericsoftware.kryo.util.UnsafeUtil ; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations ; WARNING: All illegal access operations will be denied in a future release ; 16:23:07.141 [main] [WARN ] loci.formats.Memoizer - deleting invalid memo file: D:\QMDownload\5\os\.OS-3.vsi.bfmemo ; com.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 429; Serialization trace:; service (loci.formats.in.OperettaReader); readers (loci.formats.ImageReader); reader (loci.formats.DimensionSwapper); reader (loci.formats.FileStitcher); helper (loci.formats.in.FilePatternReader); readers (loci.formats.ImageReader) ; 	at com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:119) ; 	at com.esotericsoftware.kryo.Kryo.rea",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/287:983,Unsafe,UnsafeUtil,983,https://qupath.github.io,https://github.com/qupath/qupath/issues/287,1,['Unsafe'],['UnsafeUtil']
Safety,"time: 215.44 seconds); INFO: Processing complete in 215.63 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.tissue.SimpleTissueDetection2 {""threshold"": 219, ""requestedPixelSizeMicrons"": 2.0, ""minAreaMicrons"": 20.0, ""maxHoleAreaMicrons"": 200.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); IN",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:2421,detect,detected,2421,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Safety,"tions and detections. Upon further inspection, it had deleted all the detections and annotations on all of the images except the one I had just been editing, and showed the rest as new and unopened images. ;  ; I closed without saving and reopened, and then two had the detections and annotations restored. I've continued closing and reopening the project, and a different number of images have annotations each time. I have tried downloading the newest version of QuPath, after which there were 5 images with annotations and detections restored and one with only annotations restored. Since updating, the same data is the same every time I reopen it. I have also tried updating and restarting my computer. I have no idea how or why this happened or how to get my data back. This is many hours of work, and I'm scared to start my new project, if this is a possible outcome.;  ; **To Reproduce**; I'm sorry, but I have no idea.;  ; **Expected behavior**; Normally, when I go from one image to another, I save one and then the next one opens the old annotations and detections.;  ; **Screenshots**; <img width=""1264"" alt=""Screenshot 2023-09-04 at 6 43 43 PM"" src=""https://github.com/qupath/qupath/assets/79068467/16ab2d72-a5ad-4910-b1eb-c1fc0a9c8842"">; This is a list of images, you can see that it shows five on this view as opened and the rest as new. ;  ; **Desktop (please complete the following information):**;  - OS:  macOS Ventura Version 13.5.1 (22G90);  - QuPath Version: currently Version: 0.4.4, unfortunately, I didn't check the old version before updating;  ; **Additional context**; The only thing I think *could* be a contributing factor is that the image files are large, and my Mac automatically offloads them to the cloud if I haven't opened them for a few days. When I want to work on the project, I redownload the images from the cloud, and have never had an issue viewing my old annotations on those images before. All of the images are currently downloaded, and there is no consis",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1313:1645,detect,detections,1645,https://qupath.github.io,https://github.com/qupath/qupath/issues/1313,1,['detect'],['detections']
Safety,"tive cells in different images and combining the results could potentially cause practical problems in terms of partially overlapping cells, which might have differing positive/negative classifications depending upon staining localization and intensity... resulting in a confusing or unexpected result. Therefore, to avoid this situation, it is not supported. I would suggest applying your detection using optical density sum, but adjusting the other parameters to try to obtain a better result. In particular, . * Increasing/decreasing 'Threshold' under *Intensity parameters*; * Either increasing 'Background radius', or setting the value to zero (to eliminate background subtraction altogether) - this is mostly relevant if the cells in the image is particularly large or densely-packed. Use of the brightness/contrast tool (as described [here](https://github.com/qupath/qupath/wiki/Changing-colors#the-brightnesscontrast-tool)) to separate stains, along with the pixel intensity values shown in the bottom right of the viewer, can help figure out appropriate values for the intensity threshold. This can also help you see how cleanly the hematoxylin and DAB have been separated. If the stain separation is not particularly good, the documentation on [Estimating stain vectors](https://github.com/qupath/qupath/wiki/Preprocessing#estimate-stain-vectors) and [CD3 analysis](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis#estimate-stain-vectors-watch) show how this may be improved. Your other option for Ki67 would be to use *Fast cell counts* - as documented for [CD3](https://github.com/qupath/qupath/wiki/TMA-CD3-analysis). This gives another method of detection that may sometimes perform better (and sometimes less well). But since it only creates a single point for each cell (rather than detecting the full cell), it is best used for defined regions of interest... when you don't need to use the full cell information to train QuPath to distinguish between tumor and non-tumor cells.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/46#issuecomment-275932246:1816,detect,detection,1816,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-275932246,2,['detect'],"['detecting', 'detection']"
Safety,"to make that possible. The ```.qpclassifier``` file should therefore be considered 'locked-down', since you can't really change that classifier again directly. Fortunately, so long as you've saved the data for each image as you went along (including your annotations), you can work around this. To do so, you start by creating a new detection classifier and starting to train it by adding annotations and setting their classifications on any image. Then if you open each of the images you previously annotated for training, QuPath will look for any annotated regions and (optionally) add them to the training as well. Using this approach, you end up with a whole new classifier - but it can be based on the old training, plus whatever you want to add. This is ok if you only used one or two images for training in the past, but it could be a bit annoying if you annotated lots of images in a project. In this case, there is a shortcut that you can use. Click on *Advanced options* in the *Create detection classifier* window and select the ```More...``` button on the right. If you choose *Rebuild training from project* QuPath will then loop through *all* the images in the project and use any annotations it finds to train the new classifier. For your other question, the classifier is applied across the entire slide that is currently open - so that means that the classification will be updated for all TMA cores that are on the current slide (but *not* TMA cores that are on a different slide!). When you train the classifier and open a new image, you have the option to retain your training (i.e. continue to build a classifier, using all the information from the old slide that you are closing and also the new slide that you are opening) or not (i.e. discard all the training information from the slide that was previously open). Again, the ```More...``` button can be useful. You can use it to find out how many objects have been used for training for each image in the project (*Show traini",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/57#issuecomment-288491139:1335,detect,detection,1335,https://qupath.github.io,https://github.com/qupath/qupath/issues/57#issuecomment-288491139,1,['detect'],['detection']
Safety,"tor$ProjectTask.call(DefaultScriptEditor.java:1237); at javafx.concurrent.Task$TaskCallable.call(Task.java:1425); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); Caused by Java heap space at ij.process.FloatProcessor.snapshot(FloatProcessor.java:240); at ij.process.FloatProcessor.convolve(FloatProcessor.java:1069); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.doDetection(WatershedCellDetection.java:600); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:997); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:362); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.cells.WatershedCellDetection {""detectionImageFluorescence"": 1, ""requestedPixelSizeMicrons"": 0.1, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0,",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:3214,detect,detect,3214,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['detect'],['detect']
Safety,"trate both removing and adding objects, ideally for new coders (dun dun dunnn). The setting is a small rectangular annotation with cells generated inside of it, which is also divided into tumor/stroma annotations.; image. The purpose of the script is to remove the cells in one area, run an analysis that adds measurements based only on the cells in the second area, and then restore the cells that were removed. ```; //Load the LuCa object data before running!; resolveHierarchy() //let's make sure all of the cells are child objects of their annotations!; tumorAnnos = getAnnotationObjects().findAll{it.getPathClass() == getPathClass(""Tumor"")}; tumorCells = getCellObjects().findAll{it.getParent().getPathClass() == getPathClass(""Tumor"")}. //Remove the tumor annotations and their cells; removeObjects(tumorAnnos,false); removeObjects(tumorCells,false); //Analyze->Spatial analysis->Detect centroid distances 2D. detectionCentroidDistances(true); //Add everything back, and make sure the hierarchy is resolved!; addObjects(tumorAnnos); addObjects(tumorCells); resolveHierarchy(); ```. The code works most of the time. Probably 70%? I lack my usual variety of computers to test out whether it is based on my computer - but I do have a project file hosted online I can make available to run the test. Errors include: Null pointer exception popup in the lower right,. INFO: Starting script at Sat Jun 05 20:54:28 CDT 2021; WARN: Resolving hierarchy that contains 3 annotations and 1236 detections - this may be slow!; ERROR: QuPath exception; WARN: Resolving hierarchy that contains 3 annotations and 1236 detections - this may be slow!; INFO: Script run time: 0.25 seconds; The log file is not hugely informative on that one. Alternatively, I sometimes see a TMA core error. ```; ERROR: QuPath exception: Cannot invoke ""qupath.lib.objects.PathObject.isTMACore()"" because ""child"" is null; at qupath.lib.gui.panes.PathObjectHierarchyView$PathObjectTreeItem.getChildren(PathObjectHierarchyView.java:516)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/744:1052,detect,detectionCentroidDistances,1052,https://qupath.github.io,https://github.com/qupath/qupath/issues/744,1,['detect'],['detectionCentroidDistances']
Safety,"tyle: Modena Light; INFO: Performing update check...; INFO: Starting QuPath with parameters: []; ERROR: Openslide: Property not available: openslide.objective-power; INFO: Test reading thumbnail with openslide: passed (BufferedImage@77accd0e: type = 1 DirectColorModel: rmask=ff0000 gmask=ff00 bmask=ff amask=0 IntegerInterleavedRaster: width = 200 height = 193 #Bands = 3 xOff = 0 yOff = 0 dataOffset[0] 0); INFO: Returning server: OpenSlide for L:\basic\divg\CEMM-Lexor\SannetH\1. SANNE\Project 2. IHC Validation PICCOLO and COIN\Qupath PICCOLO\R-PICCOLO-16_CDX2-88_20x.tiff; INFO: Estimating H-DAB staining; INFO: Image data set to ImageData: Brightfield (H-DAB), R-PICCOLO-16_CDX2-88_20x; INFO: Will (re)compute TMA grid...; INFO: Processing complete in 1.26 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.dearray.TMADearrayerPluginIJ {""coreDiameterMM"": 0.7, ""labelsHorizontal"": ""1-16"", ""labelsVertical"": ""A-J"", ""labelOrder"": ""Row first"", ""densityThreshold"": 5, ""boundsScale"": 105}; INFO: Adding Rectangle to hierarchy; INFO: Requesting region for stain vector editing: ; INFO: 1932 nuclei detected (processing time: 3.82 seconds); INFO: Processing complete in 3.92 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: 1165 nuclei detected (processing time: 3.94 seconds); INFO: Processing complete in 3.98 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigma",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418647572:1478,detect,detected,1478,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418647572,1,['detect'],['detected']
Safety,"uPath-0.2.0-m8 -Xmx8192M -XX:MaxRAMPercentage=50 qupath.QuPath. Host: Intel(R) Core(TM) i5-9400 CPU @ 2.90GHz, 6 cores, 15G, Windows 10 , 64 bit Build 18362 (10.0.18362.329); Time: Tue Jan 28 18:35:40 2020 W. Europe Standard Time elapsed time: 148 seconds (0d 0h 2m 28s). --------------- T H R E A D ---------------. Current thread (0x000001d550e5e800): JavaThread ""classifier-overlay6"" daemon [_thread_in_native, id=7376, stack(0x0000002279b00000,0x0000002279c00000)]. Stack: [0x0000002279b00000,0x0000002279c00000], sp=0x0000002279bf9e20, free space=999k; Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code); C 0x0000000000cb5b26. Java frames: (J=compiled Java code, j=interpreted, Vv=VM code); j org.bytedeco.opencv.opencv_ml.LogisticRegression.predict(Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;I)F+0; j qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predictWithLock(Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;)V+11; j qupath.opencv.ml.OpenCVClassifiers$AbstractOpenCVClassifierML.predict(Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;)V+14; j qupath.opencv.ml.OpenCVClassifiers$LogisticRegressionClassifier.predict(Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;Lorg/bytedeco/opencv/opencv_core/Mat;)V+4; j qupath.opencv.ml.pixel.OpenCVPixelClassifier.applyClassification(Lqupath/lib/images/ImageData;Lqupath/lib/regions/RegionRequest;)Ljava/awt/image/BufferedImage;+235; j qupath.lib.classifiers.pixel.PixelClassificationImageServer.readTile(Lqupath/lib/images/servers/TileRequest;)Ljava/awt/image/BufferedImage;+84; J 14172 c1 qupath.lib.images.servers.AbstractTileableImageServer.getTile(Lqupath/lib/images/servers/TileRequest;)Ljava/awt/image/BufferedImage; (133 bytes) @ 0x000001d52232b9dc [0x000001d52232b3e0+0x00000000000005fc]; J 14898 c1 qupath.lib.imag",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/394:2776,predict,predictWithLock,2776,https://qupath.github.io,https://github.com/qupath/qupath/issues/394,1,['predict'],['predictWithLock']
Safety,"ub.io/qupath/2018/03/19/qupath-updates.html#classification-lists-are-stored-in-projects. ### Current situation (v0.1.2) & planned changes; Currently, the class list is saved in the preferences - and not any individual project or data file. In the next release, I plan that the class list will be saved in the preferences as _also_ in the project. Furthermore, it will be possible to import class lists from different projects. I hadn't realised when I was writing it at first how long or complex the class lists would become... and I understand that losing a long list can be very frustrating. ### The class list & object classes in the image; The classes actually applied in the image _don't_ need to correspond to the class list. The purpose of the class list is only to provide a way to assign classes to annotations manually. It's very possible to have objects with other classes in the image; this happens often (e.g. with 'Positive cell detection' you can get cells with 'Positive' and 'Negative' classes - but these don't need to appear in the class list for it to work). ### The uniqueness of classes; If you create a new class in the class list and it has _exactly_ the same name as a previous one, then it should refer to _exactly_ the same class. If the class doesn't exist, it will be created. But if it exists anywhere in the image, then the existing class with that name will be used. This is important for how QuPath does things. Unfortunately, the rule is _very_ strict. Any difference in class name (e.g. different capitalization, spaces) results in a different class. So it is necessary to be very careful when doing this. > I _think_ the color for the class is random. I may have changed that for the next version to make the color pseudo-random, but consistently the same if the same name is typed (making it easier to identify discrepancies). I'll have to check the code to make sure if I made this change or only thought about it... ### What to do in the short term; There are t",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/243#issuecomment-437784159:1081,detect,detection,1081,https://qupath.github.io,https://github.com/qupath/qupath/issues/243#issuecomment-437784159,1,['detect'],['detection']
Safety,"ug (it you're not sure, please use [image.sc](https://forum.image.sc/tags/qupath) instead); * [ x] I've checked https://qupath.github.io for a new release that might already have fixed the issue; * [ x] I've checked the [Changelog](https://github.com/qupath/qupath/blob/master/CHANGELOG.md) to see if the bug has already been fixed in the next release; * [x ] I've checked for existing GitHub issues describing the same problem. ## Bug report. **Describe the bug**; A clear and concise description of what the bug is.; After running clearDetections() TMA grid object isEditable property remains false (i.e. TMA grid circles cannot be rearranged etc). **To Reproduce**; Steps to reproduce the behavior:. setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049"", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759"", ""Background"" : "" 255 255 255""}');. //De-array TMA; runPlugin('qupath.imagej.detect.dearray.TMADearrayerPluginIJ', '{""coreDiameterMM"": 1.2, ""labelsHorizontal"": ""1-16"", ""labelsVertical"": ""A-J"", ""labelOrder"": ""Row first"", ""densityThreshold"": 5, ""boundsScale"": 105}');; selectTMACores();. //Detect cells using some method such as DAB; runPlugin('qupath.imagej.detect.cells.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.0, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": false, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Cell: DAB OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6, ""singleThreshold"": true}');. clearDetections();; fireHierarchyUpdate();; getTMACoreList().each{; println(it.isEditable());; };. INFO: false; INFO: false",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1021:1416,detect,detect,1416,https://qupath.github.io,https://github.com/qupath/qupath/issues/1021,1,['detect'],['detect']
Safety,"ugh I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:. // Print the current memory situation. def runtime = Runtime.getRuntime(). double scale = 1.0/1024.0/1024.0. print 'Max memory (MB): ' + (runtime.maxMemory() * scale). print 'Total memory (MB): ' + (runtime.totalMemory() * scale). print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache. javafx.application.Platform.runLater {. getCurrentViewer().getImageRegionStore().cache.clear(). System.gc(). }. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/qupath/qupath/issues/130#issuecomment-355845333>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AhgDyN_FkkG6m9PVrCtutL6J2PYQHVfHks5tIRihgaJpZM4RUCsS>.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/130#issuecomment-355877016:2172,detect,detection,2172,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355877016,1,['detect'],['detection']
Safety,"ultiple viewers, but I don't know of any cases where it did - because QuPath locks the UI when plugins run, and this seemed to be working ok. So this PR also includes a new design greatly simplifies `PluginRunner` to simple run tasks in parallel with progress notification - with some special logic for `PathTask` implementations. Alongside that,; ```java; PathPlugin.runPlugin(PluginRunner pluginRunner, String arg); ```; has been updated to; ```java; PathPlugin.runPlugin(PluginRunner pluginRunner, ImageData<T> imageData, String arg)`; ```; so that there's no need to request the `ImageData` from the plugin runner - and it's possible to ensure this remains unchanged while all the work of the plugin is completex, no matter what might go on in the UI. Early indications are that the code is just simpler and more robust. However, it's still a core change that *could* potentially have broken lots of things, so most analysis-related commands ought to be checked (e.g. cell detection, or anything else involving `PathPlugin`). ## ImageJ, macOS & menubars. The ImageJ macro runner was an implementation of `PathPlugin`. When exploring how this was affected, I dug into a longstanding bug since QuPath's beginning: basically, ImageJ and QuPath's menus don't play together nicely on macOS: https://github.com/qupath/qupath/issues/6. Shortcuts/accelerators are particularly badly affected: the QuPath ones either don't work, or would trigger both the accelerator within QuPath *and* within ImageJ. This PR attempts to finally fix this, by; 1. overriding any system menubar request from QuPath while ImageJ is running, so that QuPath's menu becomes 'demoted' to within the app; 2. blocking ImageJ's last menubar whenever it no longer has any focussed stage (i.e. whenever a JavaFX window is activated). This seems to work on macOS, but the menubar thing failed badly on Windows - so now is *only* applied with Mac. @alanocallaghan @Rylern it would be good if you could check what happens on Linux if yo",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1318:2497,detect,detection,2497,https://qupath.github.io,https://github.com/qupath/qupath/pull/1318,1,['detect'],['detection']
Safety,"ulty is with how the [hierarchy](https://github.com/qupath/qupath/wiki/Object-hierarchies) handles annotations that overlap... that can make knowing that's inside what a bit awkward, and not always very intuitive. There may be a manual way to do want you want through the user interface, but I suspect it could be quite laborious. Since this looks like it could be generally useful for others as well, my mind always turns to whether it would be cleaner to write a script or add a new command to the software instead... I have a few questions to check if I understand correctly what you need:; * What are the final outputs you want? Is it the number of immune cells per mm^2 or something else?; * Is it problematic that the green region extends outside the tissue?; * Do you have a strong opinion on having the outer areas (here, green and blue) containing _everything_ (i.e. black nested inside blue, then blue inside green), or would it be acceptable/preferable if each area was independent and non-overlapping (i.e. the black area would be one polygon, but the green and blue would be more like 'hollow rings' around the outside)?; * Does the _Positive cell detection_ work directly (e.g. if you've got hematoxylin and DAB staining, and you just need a count based on cells where DAB is evident), or do you really need a classifier?; * If you _do_ need a classifier, do you need to train it new for every image - or do you plan to train it once, and then apply the same classifier for every image?; * Roughly how many images do you need to analyze in this way? (e.g. tens, hundreds, thousands... to get a rough idea of how automated the approach ultimately needs to be); * Have you already got a lot of existing annotations / cells that you need to reuse, or are you just starting? Usually adding new annotations when there are already a lot of cells can be _very_ slow, and it might be easier to create the annotations first before doing the cell detection. But potentially either way could work.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/198#issuecomment-411011755:1971,detect,detection,1971,https://qupath.github.io,https://github.com/qupath/qupath/issues/198#issuecomment-411011755,1,['detect'],['detection']
Safety,"upath-0.1.2/deploy/jars/openslide-3.4.1_2-natives-osx.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/jars/openslide-3.4.1_2-natives-windows.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/jars/reactfx-2.0-M4u1.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/jars/richtextfx-0.6.10.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/jars/slf4j-api-1.7.20.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/jars/undofx-1.2.jar:/oamp/bio/QuPath/0.1.2/qupath-0.1.2/deploy/jars/wellbehavedfx-0.1.1.jar:./ QuPath /oamp/bio/QuPath/0.1.2/command/9624CE91-1DA8-40AE-89AC-41412BE756DB.jpg -script 2.groovy; ----------------------------------------------------------------------------------------------------------------; **2.groovy**:; setImageType('BRIGHTFIELD_H_DAB');; setColorDeconvolutionStains('{""Name"" : ""H-DAB default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049 "", ""Stain 2"" : ""DAB"", ""Values 2"" : ""0.26917 0.56824 0.77759 "", ""Background"" : "" 255 255 255 ""}');; runPlugin('qupath.imagej.detect.tissue.SimpleTissueDetection2', '{""threshold"": 162, ""requestedDownsample"": 1.0, ""minAreaPixels"": 100000.0, ""maxHoleAreaPixels"": 500.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}');; ------------------------------------------------------------------------------------------------------------------; **error**:; 21:52:15.344 [main] [INFO ] QuPath - Launching QuPath with args: /oamp/bio/QuPath/0.1.2/command/9624CE91-1DA8-40AE-89AC-41412BE756DB.jpg, -script, 2.groovy; 21:52:15.600 [main] [ERROR] QuPath - Error running script!; javax.script.ScriptException: javax.script.ScriptException: groovy.lang.MissingMethodException: No signature of method: org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.setImageType() is applicable for argument types: (java.lang.String) values: [BRIGHTFIELD_H_DAB]; 	at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScri",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/213:4447,detect,detect,4447,https://qupath.github.io,https://github.com/qupath/qupath/issues/213,1,['detect'],['detect']
Safety,"ureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); Caused by Java heap space at ij.process.FloatProcessor.snapshot(FloatProcessor.java:240); at ij.process.FloatProcessor.convolve(FloatProcessor.java:1069); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.doDetection(WatershedCellDetection.java:600); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:997); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:362); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); INFO: Completed with error java.lang.OutOfMemoryError: Java heap space; INFO: ; qupath.imagej.detect.cells.WatershedCellDetection {""detectionImageFluorescence"": 1, ""requestedPixelSizeMicrons"": 0.1, ""backgroundRadiusMicrons"": 0.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 0.9, ""minAreaMicrons"": 6.0, ""maxAreaMicrons"": 150.0, ""threshold"": 2000.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 3.0, ""includeNuclei"":",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:3375,Detect,DetectionPluginTools,3375,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['Detect'],['DetectionPluginTools']
Safety,"using MSYS2 building openslide is simply calling ./configure && make &&; make install avoiding winbuild.sh/cross compilation. Did you rebuild pixman; or other openslide dependencies from source on Linux?. Am So., 17. Jan. 2021 um 18:52 Uhr schrieb Pete <notifications@github.com>:. > @kwiechen <https://github.com/kwiechen> thanks for the suggestion, I; > haven't looked into this - what would it involve and what would it solve?; > Currently, 'official' Windows builds are available for OpenSlide and seem; > to work fine. It is portability on Mac/Linux that poses the biggest problem; > (especially since pixman included in the last LTS Ubuntu release causes; > trouble).; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/qupath/qupath/issues/629#issuecomment-761851656>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AEG6ZGYDJUF6JH7JKL7LHRDS2MPVPANCNFSM4S6NHNUA>; > .; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/629#issuecomment-761857622:86,avoid,avoiding,86,https://qupath.github.io,https://github.com/qupath/qupath/issues/629#issuecomment-761857622,1,['avoid'],['avoiding']
Safety,"ut the classification: the different pieces (e.g. subclassifications) and the color; this is used internally; 2. The 'classification' is simply a `String` representation of the `PathClass`; it can represent the key pieces (with a colon delimiter for subclassifications), but *not* the color; 3. The 'classifications' are a set that represents the different part of the classification, but *not* the color; this is intended for cases when you'd really like to have *multiple* classifications, and what to treat the 'derived' parts of a classification as if they are basically separate classifications (e.g. `CD3: CD8`). In Groovy, checking if a cell has the derived classification ""Tumor: Positive"", and setting it to ""Tumor: Negative"" if not, would look like this:; ```groovy; // Original Java way (used in QuPath for all of the early years); if (pathObject.getPathClass() != getPathClass(""Tumor: Positive"")) {; pathObject.setPathClass(getPathClass(""Tumor: Negative"")); }. // Using Groovy's way to avoid get/set; if (pathObject.pathClass != getPathClass(""Tumor: Positive"")) {; pathObject.pathClass = getPathClass(""Tumor: Negative""); }. // With strings; if (pathObject.classification != ""Tumor: Positive"") {; pathObject.classification = ""Tumor: Negative""; }. // With classifications; if (pathObject.classifications != [""Tumor: Positive""] as Set) {; pathObject.classifications = [""Tumor"", ""Negative""]; }; ```; I think the working with string is a bit less cumbersome and confusing than needing to add lots of `getPathClass()` lines. But it is more powerful with tricks like this. ```groovy; // Set all cells to be classified as 'Tumor'; getCellObjects().each {it.classification = 'Tumor'}. // And 'Negative' as a (sub?) classification to all cells; getCellObjects().each {it.classifications += 'Negative'}. // Remove 'Negative' as a (sub?) classification from all cells; getCellObjects().each {it.classifications -= 'Negative'}. // Select all the objects classification *exactly* as tumor; selectObject",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1593:1704,avoid,avoid,1704,https://qupath.github.io,https://github.com/qupath/qupath/pull/1593,1,['avoid'],['avoid']
Safety,"v0.2.0-m11 now tries to recover more gracefully when this happens. It can't resolve the problematic overlap, but at least it doesn't lose the other cells. I'll close this issue because I think it is now as fixed as it is going to be (the whole overlapping code may be revised before v1.0.0), but feel free to reopen if you find it reoccurs.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/459#issuecomment-621609187:24,recover,recover,24,https://qupath.github.io,https://github.com/qupath/qupath/issues/459#issuecomment-621609187,1,['recover'],['recover']
Safety,va:697); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.gui.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1288); at qupath.lib.gui.scripting.DefaultScriptEditor$ProjectTask.call(DefaultScriptEditor.java:1237); at javafx.concurrent.Task$TaskCallable.call(Task.java:1425); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); Caused by Java heap space at ij.process.FloatProcessor.snapshot(FloatProcessor.java:240); at ij.process.FloatProcessor.convolve(FloatProcessor.java:1069); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.doDetection(WatershedCellDetection.java:600); at qupath.imagej.detect.cells.WatershedCellDetection$WatershedCellDetector.runDetection(WatershedCellDetection.java:997); at qupath.imagej.detect.cells.WatershedCellDetection$CellDetector.runDetection(WatershedCellDetection.java:362); at qupath.lib.plugins.DetectionPluginTools$DetectionRunnable.run(DetectionPluginTools.java:123); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); at java.base/java.lang.Thread.run(Thread.java:834); INFO: Complete,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/316#issuecomment-493938867:2971,detect,detect,2971,https://qupath.github.io,https://github.com/qupath/qupath/issues/316#issuecomment-493938867,1,['detect'],['detect']
Safety,"ver: ImageJ server for /home/bl/Documents/IMG_5_11_sq.png; 02:40:14.153 [JavaFX Application Thread] [INFO ] qupath.lib.gui.viewer.QuPathViewer - Image data set to ImageData: Fluorescence, IMG_5_11_sq; 02:40:22.852 [JavaFX Application Thread] [INFO ] q.lib.scripting.DefaultScriptEditor - Loading script file /home/bl/ip/QuPath/app/TestJep.groovy; 02:40:28.109 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean red (from Java): 86.81525; 02:40:28.121 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean green (from Java): 72.492275; 02:40:28.124 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Mean blue (from Java): 68.141675; 02:40:28.624 [richscripteditor-1] [INFO ] q.lib.scripting.DefaultScriptEditor - Started JEP: jep.Jep@6bc4b2e2; ImportError: numpy.core.multiarray failed to import; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f930536d03f, pid=27357, tid=0x00007f932091e700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-2ubuntu0.16.04.2-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [jep.so+0x1a03f] convert_jndarray_pyndarray+0x5bf; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/bl/ip/QuPath/app/hs_err_pid27357.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. [1]+ Aborted (core dumped) ./QuPath; ```. I am thinking that this might be worth bringing up with the JEP developers. I am going to spend a little more time playing with JEP by itself in order to see if I run into any similar issues.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/27#issuecomment-262870405:10319,Abort,Aborted,10319,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405,1,['Abort'],['Aborted']
Safety,"was running a script but it never finishes. ```; setImageType('BRIGHTFIELD_H_E');; setColorDeconvolutionStains('{""Name"" : ""H&E default"", ""Stain 1"" : ""Hematoxylin"", ""Values 1"" : ""0.65111 0.70119 0.29049"", ""Stain 2"" : ""Eosin"", ""Values 2"" : ""0.2159 0.8012 0.5581"", ""Background"" : "" 244 244 244""}');; createSelectAllObject(true);; runPlugin('qupath.imagej.detect.cells.PositiveCellDetection', '{""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true, ""thresholdCompartment"": ""Nucleus: Eosin OD mean"", ""thresholdPositive1"": 0.2, ""thresholdPositive2"": 0.4, ""thresholdPositive3"": 0.6000000000000001, ""singleThreshold"": true}');. ```; If I run individually, exit, restart and run another it always works. It is when I try to run this on multiple slides without restarting that I run into trouble.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/828#issuecomment-939591061:352,detect,detect,352,https://qupath.github.io,https://github.com/qupath/qupath/issues/828#issuecomment-939591061,2,['detect'],"['detect', 'detectionImageBrightfield']"
Safety,"wnsample, xi, yi, wi, hi, z, 0). // Check if we requesting a region that is too small; if (wi / downsample < minImageDimension) {; // Only print warning if we've not skipped this before; if (y > 0); println(""Image dimension < "" + minImageDimension + "" - skipping column""); continue; }. // Surround with try/catch in case the server gives us trouble; try {; // Put at top of file for neater code...; ext = "".jpg""; imageData = getCurrentImageData(); overlayOptions = getCurrentViewer().getOverlayOptions(); ; // Write out the region with overlay; String name = String.format(""%s (d=%.2f, x=%d, y=%d, w=%d, h=%d, z=%d).%s"", serverName, downsample, xi, yi, wi, hi, z, ext); File file = new File(dirOutput, name); ImageWriterTools.writeImageRegionWithOverlay(imageData, overlayOptions, request, file.getAbsolutePath()). // Print progress; counter++; println(""Written tile "" + counter + "" to "" + file.getAbsolutePath()); }; catch (Exception e) {; // Check if we have had a sufficient number of errors to just give up; nErrors++;; if (nErrors > maxErrors) {; println(""Maximum number of errors exceeded - aborting...""); return; }; e.printStackTrace(); }; }; }; }. ```. The error is on line 91 when I try to access the ImagePlusServer server, which obviously doesn't exist anymore. . ```; ERROR: Error at line 7: No such property: server for class: Script48. ERROR: Script error; at org.codehaus.groovy.runtime.ScriptBytecodeAdapter.unwrap(ScriptBytecodeAdapter.java:65); at org.codehaus.groovy.runtime.callsite.PogoGetPropertySite.getProperty(PogoGetPropertySite.java:51); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callGroovyObjectGetProperty(AbstractCallSite.java:309); at Script48.run(Script48.groovy:8); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:317); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:155); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:767); at qupath.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/309:4245,abort,aborting,4245,https://qupath.github.io,https://github.com/qupath/qupath/issues/309,1,['abort'],['aborting']
Safety,"y to create margins for the; annotations. I do not run out of memory, but using the memory monitor I; notice a sawtooth pattern whe is the freezes happen. Perhaps it will run better if run from the command line since it no longer; will have to compete with the application thread?. I will set up a more powerful computer tomorrow. Perhaps that will handle; the problem. 7. feb. 2019 20:46 skrev ""Pete"" <notifications@github.com>:. It's hard to tell much here without a clearer idea of what 'a lot of rather; large and complex annotations' means, but it may very well be that there; are too many vertices that that slows down the rendering too much (on the; JavaFX application thread, same as the menus and rest of the GUI). If so it; isn't really a bug, but more pushing QuPath with a different application; than that for which it was previously designed/optimized... See https://github.com/qupath/qupath/wiki/Types-of-object for differences; in object types, and why it's not really intended to have very large; numbers of annotations. You might try having fewer vertices somehow, perhaps with *Objects →; Simplify annotation shape* or splitting larger annotations into smaller; ones (since annotations outside the field of view do not need to be; rendered). Or write a script that periodically converts annotations you; won't need to change any more into detections. Or try to leave parts of the; image that are particularly complex *unannotated*, and then interpret the; unannotated region appropriately later. (I was actually looking into this today for completely different reasons,; and may be able to improve the annotation handling somewhat... but it; doesn't help you now). —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub; <https://github.com/qupath/qupath/issues/267#issuecomment-461569891>, or mute; the thread; <https://github.com/notifications/unsubscribe-auth/Af9pL416T51gEDAwcX1cjYHyo1TwguiQks5vLIKAgaJpZM4anysq>; .",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/267#issuecomment-461575920:1543,detect,detections,1543,https://qupath.github.io,https://github.com/qupath/qupath/issues/267#issuecomment-461575920,1,['detect'],['detections']
Safety,"ylib; jniopencv_ml : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_ml.dylib; opencv_imgproc@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_imgproc.405.dylib; jniopencv_dnn : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_dnn.dylib; jnijavacpp : 	/Users/pbankhea/.javacpp/cache/javacpp-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/javacpp/macosx-x86_64/libjnijavacpp.dylib; jniopenblas : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libjniopenblas.dylib; quadmath@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libquadmath.0.dylib; openblas_nolapack@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libopenblas_nolapack.0.dylib; opencv_core@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_core.405.dylib; jniopenblas_nolapack : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libjniopenblas_nolapack.dylib; jniopencv_imgproc : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libjniopencv_imgproc.dylib; openblas@.0 : 	/Users/pbankhea/.javacpp/cache/openblas-0.3.19-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/openblas/macosx-x86_64/libopenblas.0.dylib; opencv_dnn@.405 : 	/Users/pbankhea/.javacpp/cache/opencv-4.5.5-1.5.7-SNAPSHOT-macosx-x86_64.jar/org/bytedeco/opencv/macosx-x86_64/libopencv_dnn.405.dylib; ```. The `-Dorg.bytedeco.javacpp.maxPhysicalBytes=0` workaround does avoid the problem, but I haven't implemented it.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980:3200,avoid,avoid,3200,https://qupath.github.io,https://github.com/qupath/qupath/issues/856#issuecomment-1023042980,1,['avoid'],['avoid']
Safety,"zeMicrons"": 2.0, ""minAreaMicrons"": 20.0, ""maxHoleAreaMicrons"": 200.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: 271 nuclei detected (processing time: 5.71 seconds); INFO: 233 nuclei detected (processing time: 5.78 seconds); INFO: 0 nuclei detected (processing time: 0.23 seconds); INFO: 872 nuclei detected (processing time: 6.63 seconds); INFO: 1695 nuclei detected (processing time: 9.49 seconds); INFO: 1145 nuclei detected (processing time: 10.39 seconds); INFO: 3294 nuclei detected (processing time: 11.72 seconds); INFO: 1267 nuclei detected (processing time: 12.33 seconds); INFO: 470 nuclei detected (processing time: 6.69 seconds); INFO: 4076 nuclei detected (processing time: 13.59 seconds); INFO: 0 nuclei detected (processing time: 1.42 seconds); INFO: 394 nuclei detected (processing time: 3.38 seconds); INFO: 510 nuclei detected (processing time: 8.89 seconds); INFO: 2086 nuclei detected (processing time: 8.28 seconds); INFO: 1500 nuclei detected (processing time: 14.11 seconds); INFO: 0 nuclei detected (processing time: 0.17 seconds); INFO: 2245 nuclei detected (processing time: 12.13 seconds); INFO: 3727 nuclei detected (processing time: 15.92 seconds); INFO: 490 nuclei detected (processing time: 5.58 seconds); INFO: 125 nuclei detected (processing time: 1.06 seconds); INFO: 509 nuclei detected (processing time: 12.45 seconds); INFO: 2235 nuclei detected (processing time: 12.80 seconds); INFO: 681 nuclei detected (processing time: 6.41 seconds); INF",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:2602,detect,detected,2602,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['detect'],['detected']
Security," * 'Requesting attention', e.g. forcing the app to the front; * A small, unobtrusive progress bar that can be 'always on top' (even if QuPath isn't). I'm not sure adding one option to the batch script dialog will be enough to solve the problem, and adding many becomes a lot more clutter and effort to maintain. To overcome that, my initial idea was to provide the option of adding a 'batch script listener' to the script editor. . So you could add a listener using something like this (in Groovy):; ```groovy; def scriptEditor = getQuPath().getScriptEditor(); scriptEditor.addBatchScriptListener(e -> {; if (e.isLastScript()) {; // Do something... beep, email, whatever; java.awt.Toolkit.defaultToolkit.beep(); }; }); ```. The thing is that the listeners would be cumulative, so you'd likely want to just add one on startup and leave it (rather than add multiple listeners and then have them all firing when scripts are run). But then it becomes harder to turn it on/off the listener's behavior. Nevertheless, this approach would make it possible to add small extensions that offer different kinds of behavior, controlled via preferences or something else. So you could have a preference allowing the user to choose the audio file they want played on completion, for example.... but still, remembering to turn the option on and off could be a pain, since it wouldn't be easy to incorporate it as a checkbox in the batch processing dialog itself. While writing this, another option I've thought of is to make more info about the current script accessible within the script itself. So it might look like this:. ```groovy; if (getScriptInfo().isBatchProcessing() && getScriptInfo().isLastScript()) {; // Do something... beep, email, whatever; java.awt.Toolkit.defaultToolkit.beep(); }; ```. So any notification would be something pasted at the end of the script itself. It's like @MichaelSNelson's approach except avoids worrying so much about the last file being uniquely named. What do you all think?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1029#issuecomment-1200084804:1903,access,accessible,1903,https://qupath.github.io,https://github.com/qupath/qupath/issues/1029#issuecomment-1200084804,1,['access'],['accessible']
Security, -> show views-> show TMA grid view_; 3. Set the tile size to large; 4. Narrow the window below the tile width; 5. An error may appear. **Expected behavior**; No error. **Screenshots**. **Desktop (please complete the following information):**; Windows v0.5.0. **Additional context**. ```; 14:54:59.317	[JavaFX Application Thread]	ERROR	qupath.lib.gui.QuPathUncaughtExceptionHandler	/ by zero	java.lang.ArithmeticException: / by zero; 	at qupath.lib.gui.commands.PathObjectGridView$QuPathGridView.layoutChildren(PathObjectGridView.java:588); 	at javafx.scene.Parent.layout(Parent.java:1208); 	at javafx.scene.Parent.layout(Parent.java:1215); 	at javafx.scene.Parent.layout(Parent.java:1215); 	at javafx.scene.Parent.layout(Parent.java:1215); 	at javafx.scene.Parent.layout(Parent.java:1215); 	at javafx.scene.Scene.doLayoutPass(Scene.java:594); 	at javafx.scene.Scene$ScenePulseListener.pulse(Scene.java:2596); 	at com.sun.javafx.tk.Toolkit.lambda$runPulse$2(Toolkit.java:398); 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:399); 	at com.sun.javafx.tk.Toolkit.runPulse(Toolkit.java:397); 	at com.sun.javafx.tk.Toolkit.firePulse(Toolkit.java:427); 	at com.sun.javafx.tk.quantum.QuantumToolkit.pulse(QuantumToolkit.java:592); 	at com.sun.javafx.tk.quantum.PaintCollector.liveRepaintRenderJob(PaintCollector.java:327); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$ViewEventNotification.run(GlassViewEventHandler.java:889); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$ViewEventNotification.run(GlassViewEventHandler.java:849); 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:399); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleViewEvent$15(GlassViewEventHandler.java:931); 	at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:424); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleViewEvent(GlassViewEventHandler.java:930); 	at com.sun.glass.ui.View.handleViewEven,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1473:1309,secur,security,1309,https://qupath.github.io,https://github.com/qupath/qupath/issues/1473,1,['secur'],['security']
Security," 0D 51 66 A1 55 BD 6B .Z......"".Qf...k; 00D0: D9 2E 4A 4F 9B 78 15 9B 53 1D 03 91 48 A0 92 D2 ..JO.x..S...H...; 00E0: 0A 26 24 32 18 15 C1 2B 1E 00 64 37 CE D4 34 29 .&$2...+..d7..4(; ; }; },; ]; }; ]; }; ); javax.net.ssl|DEBUG|29|Thread-9|2020-04-13 21:28:52.416 NOVT|null:-1|Received alert message (; ""Alert"": {; ""level"" : ""fatal"",; ""description"": ""handshake_failure""; }; ); javax.net.ssl|ERROR|29|Thread-9|2020-04-13 21:28:52.417 NOVT|null:-1|Fatal (HANDSHAKE_FAILURE): Received fatal alert: handshake_failure (; ""throwable"" : {; javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure; 	at java.base/sun.security.ssl.Alert.createSSLException(Unknown Source); 	at java.base/sun.security.ssl.Alert.createSSLException(Unknown Source); 	at java.base/sun.security.ssl.TransportContext.fatal(Unknown Source); 	at java.base/sun.security.ssl.Alert$AlertConsumer.consume(Unknown Source); 	at java.base/sun.security.ssl.TransportContext.dispatch(Unknown Source); 	at java.base/sun.security.ssl.SSLTransport.decode(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.decode(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.readHandshakeRecord(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.startHandshake(Unknown Source); 	at java.base/sun.net.www.protocol.https.HttpsClient.afterConnect(Unknown Source); 	at java.base/sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream(Unknown Source); 	at java.base/sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(Unknown Source); 	at shaded.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.com.google.api.client.auth.oauth2.TokenRequest.executeUnparsed(TokenRequest.j",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/436:11831,secur,security,11831,https://qupath.github.io,https://github.com/qupath/qupath/issues/436,1,['secur'],['security']
Security," 12:07:40.563 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; 12:07:41.084 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale FORMAT set to en_US; 12:07:41.086 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale DISPLAY set to en_US; 12:07:41.115 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Tile cache size: 4096.00 MB; 12:07:41.218 [JavaFX Application Thread] [WARN ] qupath.lib.gui.QuPathGUI - No directory set for log files! None will be written.; 12:07:41.225 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - QuPath build: Version: 0.2.0-m1; Build time: 2019-03-08, 17:51; Latest commit tag: v0.0.1-beta-561-gfb062c1. (QuPath-0.2.0-m1:8210): Gdk-WARNING **: XSetErrorHandler() called with a GDK error trap pushed. Don't do that.; 12:07:42.748 [JavaFX Application Thread] [INFO ] q.l.i.s.b.BioFormatsOptionsExtension - Bio-Formats version 6.0.0; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.codehaus.groovy.vmplugin.v7.Java7$1 (file:/home/joelrv/software/opt/QuPath/qupath_0.2.0-m1/app/groovy-2.5.6.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class,int); WARNING: Please consider reporting this to the maintainers of org.codehaus.groovy.vmplugin.v7.Java7$1; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 12:07:43.276 [JavaFX Application Thread] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1; 12:07:43.360 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: null; 12:07:43.360 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 12:07:43.365 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 12:08:18.669 [JavaFX Application Thread] [WARN ] q.l.i",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/279:1405,access,access,1405,https://qupath.github.io,https://github.com/qupath/qupath/issues/279,2,['access'],['access']
Security," 1E 6D 06 82 66 F6 F7 8E 2B .h..gw..m..f...+; 0090: 35 9A 85 F6 09 72 7C 5B 3C CC 87 59 84 CF 96 68 5....r.[<..Y...h; 00A0: 6B D5 81 4C 74 B9 A7 91 98 49 0B 12 3F 8C E1 52 k..Lt....I..?..R; 00B0: E3 B3 53 B9 78 ED 29 56 82 E3 13 31 16 C0 6A A7 ..S.x.)V...1..j.; 00C0: F8 5A 8F FE 94 77 14 0A 22 0D 51 66 A1 55 BD 6B .Z......"".Qf...k; 00D0: D9 2E 4A 4F 9B 78 15 9B 53 1D 03 91 48 A0 92 D2 ..JO.x..S...H...; 00E0: 0A 26 24 32 18 15 C1 2B 1E 00 64 37 CE D4 34 29 .&$2...+..d7..4(; ; }; },; ]; }; ]; }; ); javax.net.ssl|DEBUG|29|Thread-9|2020-04-13 21:28:52.416 NOVT|null:-1|Received alert message (; ""Alert"": {; ""level"" : ""fatal"",; ""description"": ""handshake_failure""; }; ); javax.net.ssl|ERROR|29|Thread-9|2020-04-13 21:28:52.417 NOVT|null:-1|Fatal (HANDSHAKE_FAILURE): Received fatal alert: handshake_failure (; ""throwable"" : {; javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure; 	at java.base/sun.security.ssl.Alert.createSSLException(Unknown Source); 	at java.base/sun.security.ssl.Alert.createSSLException(Unknown Source); 	at java.base/sun.security.ssl.TransportContext.fatal(Unknown Source); 	at java.base/sun.security.ssl.Alert$AlertConsumer.consume(Unknown Source); 	at java.base/sun.security.ssl.TransportContext.dispatch(Unknown Source); 	at java.base/sun.security.ssl.SSLTransport.decode(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.decode(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.readHandshakeRecord(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.startHandshake(Unknown Source); 	at java.base/sun.net.www.protocol.https.HttpsClient.afterConnect(Unknown Source); 	at java.base/sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream(Unknown Source); 	at java.base/sun.net.www.protocol.https.HttpsURLConnectionImpl.ge",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/436:11537,secur,security,11537,https://qupath.github.io,https://github.com/qupath/qupath/issues/436,1,['secur'],['security']
Security, 3. Set the tile size to large; 4. Narrow the window below the tile width; 5. An error may appear. **Expected behavior**; No error. **Screenshots**. **Desktop (please complete the following information):**; Windows v0.5.0. **Additional context**. ```; 14:54:59.317	[JavaFX Application Thread]	ERROR	qupath.lib.gui.QuPathUncaughtExceptionHandler	/ by zero	java.lang.ArithmeticException: / by zero; 	at qupath.lib.gui.commands.PathObjectGridView$QuPathGridView.layoutChildren(PathObjectGridView.java:588); 	at javafx.scene.Parent.layout(Parent.java:1208); 	at javafx.scene.Parent.layout(Parent.java:1215); 	at javafx.scene.Parent.layout(Parent.java:1215); 	at javafx.scene.Parent.layout(Parent.java:1215); 	at javafx.scene.Parent.layout(Parent.java:1215); 	at javafx.scene.Scene.doLayoutPass(Scene.java:594); 	at javafx.scene.Scene$ScenePulseListener.pulse(Scene.java:2596); 	at com.sun.javafx.tk.Toolkit.lambda$runPulse$2(Toolkit.java:398); 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:399); 	at com.sun.javafx.tk.Toolkit.runPulse(Toolkit.java:397); 	at com.sun.javafx.tk.Toolkit.firePulse(Toolkit.java:427); 	at com.sun.javafx.tk.quantum.QuantumToolkit.pulse(QuantumToolkit.java:592); 	at com.sun.javafx.tk.quantum.PaintCollector.liveRepaintRenderJob(PaintCollector.java:327); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$ViewEventNotification.run(GlassViewEventHandler.java:889); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$ViewEventNotification.run(GlassViewEventHandler.java:849); 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:399); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleViewEvent$15(GlassViewEventHandler.java:931); 	at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:424); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleViewEvent(GlassViewEventHandler.java:930); 	at com.sun.glass.ui.View.handleViewEvent(View.java:535); 	at com.sun.glass.,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1473:1348,Access,AccessController,1348,https://qupath.github.io,https://github.com/qupath/qupath/issues/1473,1,['Access'],['AccessController']
Security," 91 98 49 0B 12 3F 8C E1 52 k..Lt....I..?..R; 00B0: E3 B3 53 B9 78 ED 29 56 82 E3 13 31 16 C0 6A A7 ..S.x.)V...1..j.; 00C0: F8 5A 8F FE 94 77 14 0A 22 0D 51 66 A1 55 BD 6B .Z......"".Qf...k; 00D0: D9 2E 4A 4F 9B 78 15 9B 53 1D 03 91 48 A0 92 D2 ..JO.x..S...H...; 00E0: 0A 26 24 32 18 15 C1 2B 1E 00 64 37 CE D4 34 29 .&$2...+..d7..4(; ; }; },; ]; }; ]; }; ); javax.net.ssl|DEBUG|29|Thread-9|2020-04-13 21:28:52.416 NOVT|null:-1|Received alert message (; ""Alert"": {; ""level"" : ""fatal"",; ""description"": ""handshake_failure""; }; ); javax.net.ssl|ERROR|29|Thread-9|2020-04-13 21:28:52.417 NOVT|null:-1|Fatal (HANDSHAKE_FAILURE): Received fatal alert: handshake_failure (; ""throwable"" : {; javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure; 	at java.base/sun.security.ssl.Alert.createSSLException(Unknown Source); 	at java.base/sun.security.ssl.Alert.createSSLException(Unknown Source); 	at java.base/sun.security.ssl.TransportContext.fatal(Unknown Source); 	at java.base/sun.security.ssl.Alert$AlertConsumer.consume(Unknown Source); 	at java.base/sun.security.ssl.TransportContext.dispatch(Unknown Source); 	at java.base/sun.security.ssl.SSLTransport.decode(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.decode(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.readHandshakeRecord(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.startHandshake(Unknown Source); 	at java.base/sun.net.www.protocol.https.HttpsClient.afterConnect(Unknown Source); 	at java.base/sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream(Unknown Source); 	at java.base/sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(Unknown Source); 	at shaded.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.com.goog",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/436:11681,secur,security,11681,https://qupath.github.io,https://github.com/qupath/qupath/issues/436,1,['secur'],['security']
Security," > Hi David,; > Since this is through GitHub, I don't have any your contact address to ; > get in touch privately, and any email replies to this thread are shown ; > here <https://github.com/qupath/qupath/issues/45> (can also ; > edit/delete through that link). However, if you'd like to follow up on ; > this maybe you could send me a private message on ResearchGate?; > Thanks,; > Pete; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/45#issuecomment-275047111>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEfakb3PrwmDrXw9e2ycOiIbRa12rks5rVwcggaJpZM4Lrcx8>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; Geschäftsführer:; - David Haumann, Thomas Schenker, Sergey Biniaminov. _________________________________; Diese E-Mail und jeder übermittelte Anhang enthält gesetzlich geschützte; und vertrauliche Informationen. Wenn diese E-Mail nicht für Sie bestimmt ist,; bitten wir Sie, sie an uns zurückzusenden und anschließend von Ihrem Computersystem; zu löschen. Nicht für Sie bestimmte E-Mails und Anhänge dürfen Sie weder nutzen; noch verarbeiten oder Dritten zugänglich machen, gleich in welcher Form. This email including any attachments contains privileged and confidential; information. If you are not an intended recipient, please return the email; to us and then delete it from your computer system. You may neither use nor; edit any such emails including attachments received due to an error in; transmission, nor make them accessible to third parties in any manner whatsoever.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/45#issuecomment-275055657:1810,confidential,confidential,1810,https://qupath.github.io,https://github.com/qupath/qupath/issues/45#issuecomment-275055657,2,"['access', 'confidential']","['accessible', 'confidential']"
Security," GUI:; We can see that the path was a combination of two paths, this is the problem. >> RMD_slide2ims_Entry; 23:18:18.288 [main] [INFO ] qupath.QuPath - Launching QuPath with args: -image, D:\\QMDownload\\5\\Leica_scn\\Leica-Fluorescence-1.scn, -script, D:\\QMDownload\\5\\tpc9321172_2c3b_4e82_b55c_7ae4380fda4b.groovy ; 23:18:18.368 [main] [ERROR] q.lib.images.servers.FileFormatInfo - Checking Big TIFF images currently not supported!!! ; 23:18:18.428 [main] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1 ; WARNING: An illegal reflective access operation has occurred ; WARNING: Illegal reflective access by com.esotericsoftware.kryo.util.UnsafeUtil (file:/C:/Program%20Files/QuPath-0.2.0-m1/app/kryo-2.24.0.jar) to constructor java.nio.DirectByteBuffer(long,int,java.lang.Object) ; WARNING: Please consider reporting this to the maintainers of com.esotericsoftware.kryo.util.UnsafeUtil ; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations ; WARNING: All illegal access operations will be denied in a future release ; 23:18:19.436 [main] [WARN ] loci.formats.Memoizer - deleting invalid memo file: D:\QMDownload\5\Leica_scn\.Leica-Fluorescence-1.scn.bfmemo ; com.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 458; Serialization trace:; service (loci.formats.in.OperettaReader); readers (loci.formats.ImageReader); reader (loci.formats.DimensionSwapper); reader (loci.formats.FileStitcher); helper (loci.formats.in.FilePatternReader); readers (loci.formats.ImageReader) ; 	at com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:119) ; 	at com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:641) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:375) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:289) ; 	at com.es",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/280#issuecomment-472915452:1005,access,access,1005,https://qupath.github.io,https://github.com/qupath/qupath/issues/280#issuecomment-472915452,3,['access'],['access']
Security," I run in QuPath 0.1.2,error appeared:. print(getQuPath().getBuildString()). ERROR: Error at line 15: No signature of method: org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.getQuPath() is applicable for argument types: () values: []; Possible solutions: getAt(java.lang.String), getClass(). ERROR: Script error; at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.callGlobal(GroovyScriptEngineImpl.java:415); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.access$000(GroovyScriptEngineImpl.java:97); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl$2.invokeMethod(GroovyScriptEngineImpl.java:329); at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:69); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:52); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:154); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:158); at Script7.run(Script7.groovy:15); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/282#issuecomment-473503394:1535,access,access,1535,https://qupath.github.io,https://github.com/qupath/qupath/issues/282#issuecomment-473503394,1,['access'],['access']
Security," Zoom from MicroDimensions is Windows-only, I suspect it may be using the Windows-only software libraries provided by [Zeiss](http://www.zeiss.com/microscopy/int/products/microscope-software/zen/czi.html) and [3D Histech](http://www.3dhistech.com/downloads). Since these are not open source (as far as I am aware), they [wouldn't be compatible with QuPath's GPL license](https://www.gnu.org/licenses/gpl-faq.html#GPLAndPlugins). Therefore including them would require a change to QuPath's license, and result in extra functionality being available on Windows but not on other platforms... and for these reasons it would really be a last resort. Nevertheless, if you or anyone at your place of work would like to give it a try, creating such an extension may be a [reasonable solution for internal use](https://www.gnu.org/licenses/gpl-faq.html#GPLRequireSourcePostedPublic). The biggest effort required is likely to be in being able to access the pixels from the native libraries within Java, but if that problem is solved then I could certainly help with the relatively small final step of integrating the result with QuPath. Still, hopefully Bio-Formats will be able to provide a solution for `*.czi` files in the near future - I'll post an update here and [Google Groups](https://groups.google.com/d/forum/qupath-users) whenever I see it. If so, that only leaves non-RGB `*.mrxs`. There may be a way to merge separated monochrome TIFFs into a single multi-channel TIFF using [Bio-Formats](http://www.openmicroscopy.org/site/support/bio-formats5.2/supported-formats.html)... although I'm not sure. Alternatively, [Pannoramic Viewer](http://www.3dhistech.com/pannoramic_viewer) may have alternative export options not present in CaseViewer. If neither of these approaches are suitable, I can imagine a new custom image reader within QuPath that is able to automatically concatenate the multiple channels of a TIFF, assuming that they are stored in the same directory with a standard naming scheme (e",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/12#issuecomment-258467053:1067,access,access,1067,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258467053,1,['access'],['access']
Security," ```; ./QuPath-0.2.0 -i=myimage.svs script myscript.groovy; ```; 3. See error:; imageData == Null; NullPointerException at line 11: Cannot invoke method getServer() on null object. **Expected behavior**; I would expect that if the command line arguments were changed to the new format the script processing would work the same as 0.2.0-m9 and earlier. The script editor seems to work just fine. Example working output from 0.2.0-m9 is shown below: . 10:23:10.593 [main] [INFO ] qupath.QuPath - Launching QuPath with args: -image, myimage.svs, -script, myscript.groovy; 10:23:11.387 [main] [WARN ] q.l.i.s.b.BioFormatsImageServer - Temp memoization directory created at /var/folders/9_/b0xrdp2d1bsbzlmwp3xff2g00000gn/T/qupath-memo-8955966830564346412; 10:23:11.388 [main] [WARN ] q.l.i.s.b.BioFormatsImageServer - If you want to avoid this warning, either disable Bio-Formats memoization in the preferences or specify a directory to use; 10:23:11.563 [main] [WARN ] q.l.i.s.ImageServerMetadata$ImageResolutionLevel - Calculated downsample values differ for x & y for level 4: x=70.0 and y=70.10548523206751 - will use value 70.05274261603375; 10:23:11.573 [main] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.codehaus.groovy.vmplugin.v7.Java7$1 (file:/Applications/QuPath-0.2.0-m9.app/Contents/app/groovy-2.5.9.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class,int); WARNING: Please consider reporting this to the maintainers of org.codehaus.groovy.vmplugin.v7.Java7$1; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; imageData != Null. **Desktop (please complete the following information):**; - OS: [macOS]; - QuPath Version [0.2.0-m10 and greater]. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/511:2670,access,access,2670,https://qupath.github.io,https://github.com/qupath/qupath/issues/511,5,['access'],['access']
Security, com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDispatcher.java:59); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:58); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$DnDGesture.fireEvent(Scene.java:3057); at javafx.scene.Scene$DnDGesture.processTargetDrop(Scene.java:3283); at javafx.scene.Scene$DropTargetListener.drop(Scene.java:2997); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.lambda$handleDragDrop$2(GlassSceneDnDEventHandler.java:108); at java.base/java.security.AccessController.doPrivileged(Unknown Source); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragDrop(GlassSceneDnDEventHandler.java:104); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragDrop$11(GlassViewEventHandler.java:766); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:412); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragDrop(GlassViewEventHandler.java:765); at com.sun.glass.ui.View.handleDragDrop(View.java:713); at com.sun.glass.ui.View.notifyDragDrop(View.java:1042); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:174); at java.base/java.lang.Thread.run(Unknown Source); Caused by null at qupath.lib.projects.DefaultProject.loadPathClasses(DefaultProject.java:1130); at qupath.lib.projects.DefaultProject.loadProject(DefaultProject.java:1086); at qupath.lib.projects.DefaultProject.loadFromFile(DefaultProject.java:17,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/613#issuecomment-708516373:2022,Access,AccessController,2022,https://qupath.github.io,https://github.com/qupath/qupath/issues/613#issuecomment-708516373,1,['Access'],['AccessController']
Security," detected (processing time: 11.44 seconds); INFO: 379 nuclei detected (processing time: 5.13 seconds); INFO: 721 nuclei detected (processing time: 8.30 seconds); INFO: 364 nuclei detected (processing time: 6.80 seconds); INFO: 157 nuclei detected (processing time: 4.19 seconds); INFO: 521 nuclei detected (processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Writing object hierarchy with 29994 object(s)...; INFO: Image data written to N:\Faculty-of-Medicine-and-Health\LICAP\DATA\PTHY\Pathology\Breast Group\BCCTB Samples\Audits\BCN QA 2017\Frozen samples QuPath tumourstromaratio\Batch_2\Tumour\402428.qpdata in 2.08 seconds; INFO: Training size: 33x5031; INFO: Responses size: 1x5031; INFO: RTrees classifier termination criteria: { type: 1, maxCount: 50, epsilon: 0.0}; ERROR: QuPath exception; at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$354(GlassViewEventHandler.java:416); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:415); at com.sun.glass.ui.View.handleMouseEvent(View.java:555); at com.sun.glass.ui.View.notifyMouse(View.java:937); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$null$148(WinApplication.java:191); at java.lang.Thread.run(Thread.java:745); Caused by std::exception: bad allocation ",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:4691,Audit,Audits,4691,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['Audit'],['Audits']
Security, error ; ; 	at org.codehaus.groovy.control.ErrorCollector.failIfErrors(ErrorCollector.java:311) ; 	at org.codehaus.groovy.control.ErrorCollector.addFatalError(ErrorCollector.java:151) ; 	at org.codehaus.groovy.control.ErrorCollector.addError(ErrorCollector.java:121) ; 	at org.codehaus.groovy.control.ErrorCollector.addError(ErrorCollector.java:133) ; 	at org.codehaus.groovy.control.SourceUnit.addError(SourceUnit.java:325) ; 	at org.codehaus.groovy.antlr.AntlrParserPlugin.transformCSTIntoAST(AntlrParserPlugin.java:224) ; 	at org.codehaus.groovy.antlr.AntlrParserPlugin.parseCST(AntlrParserPlugin.java:190) ; 	at org.codehaus.groovy.control.SourceUnit.parse(SourceUnit.java:226) ; 	at org.codehaus.groovy.control.CompilationUnit$1.call(CompilationUnit.java:196) ; 	at org.codehaus.groovy.control.CompilationUnit.applyToSourceUnits(CompilationUnit.java:965) ; 	at org.codehaus.groovy.control.CompilationUnit.doPhaseOperation(CompilationUnit.java:647) ; 	at org.codehaus.groovy.control.CompilationUnit.processPhaseOperations(CompilationUnit.java:623) ; 	at org.codehaus.groovy.control.CompilationUnit.compile(CompilationUnit.java:600) ; 	at groovy.lang.GroovyClassLoader.doParseClass(GroovyClassLoader.java:390) ; 	at groovy.lang.GroovyClassLoader.access$300(GroovyClassLoader.java:89) ; 	at groovy.lang.GroovyClassLoader$5.provide(GroovyClassLoader.java:330) ; 	at groovy.lang.GroovyClassLoader$5.provide(GroovyClassLoader.java:327) ; 	at org.codehaus.groovy.runtime.memoize.ConcurrentCommonCache.getAndPut(ConcurrentCommonCache.java:147) ; 	at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:325) ; 	at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:309) ; 	at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:251) ; 	at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.getScriptClass(GroovyScriptEngineImpl.java:331) ; 	at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:153) ; 	... 1 common frames omitted . ```,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/286:4593,access,access,4593,https://qupath.github.io,https://github.com/qupath/qupath/issues/286,1,['access'],['access']
Security," object of a hierarchy to transform the entire hierarchy easily and intuitively.; ; * I don't think we should give a serialize export option in the menus. We should move away from Java serialization as much as possible, and discourage anyone from use it; we should still support it for import though. Groovy make serialization quite easy if it's required in a script anyway... except if things are circular. Which brings me to... * `exportObjectsAsSerialized` looks like it doesn't actually use the transformed list; it also potentially allows circular references via parents/children, which could be confusing and/or buggy. I don't think we need this method if we are discouraging serialization (although I could be wrong... especially if we find a way to use it internally for convenience). * *If* `importObjectsFromSerialized` is in the public API, I think it should handle things other than lists, e.g. individual objects, arrays of objects, collections. But I'd prefer to expose it in the public API only if its benefits are clear enough. * It looks like `.qpdata` is being used for serialized object lists. We really shouldn't add a new file type with the same extension. Rather, we *can* read objects from an existing `.qpdata` file using [`PathIO.readHierarchy(File)`](https://github.com/qupath/qupath/blob/43aad4ecda893a7eb03c30774e64da5b9547bc86/qupath-core/src/main/java/qupath/lib/io/PathIO.java#L410) - this should work even if the server is unavailable itself. The ability to import from old `.qpdata` files is important, but I'd like to avoid encouraging anyone to write `.qpdata` files other than those handled internally within projects (to make it easier for us to replace the format in the future). * A common use case will be transferring objects between images in the same project. Ideally this would be possible without exporting/importing, but rather simply choosing the project entry for import. Internally, this can use [`ProjectImageEntry.readHierarchy()`](https://github.com",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/666#issuecomment-787868344:3444,expose,expose,3444,https://qupath.github.io,https://github.com/qupath/qupath/pull/666#issuecomment-787868344,1,['expose'],['expose']
Security," public static <T extends PathObject> Collection<T> filterByROICoversNucleus(ROI roi, Collection<T> pathObjects); public static <T extends PathObject> Collection<T> filterByROIIntersectsNucleus(ROI roi, Collection<T> pathObjects); public static <T extends PathObject> Collection<T> filterByROIContainsNucleusCentroid(ROI roi, Collection<T> pathObjects); ```. In case you just want to check if objects are present quickly - but don't necessarily need the objects themselves - you can use:. ```java; // Old method, deprecated; public boolean hasObjectsForRegion(Class<? extends PathObject> cls, ImageRegion region). // New methods; public boolean hasObjectsForRegion(ImageRegion region); public boolean hasAnnotationsForRegion(ImageRegion region); public boolean hasDetectionsForRegion(ImageRegion region); ```. These should effectively report whether `getXXXForRegion` would return an empty collection or not, without needing to generate that collection. ### Accessing objects with point ROIs; This simply accesses objects then filters by ROI type. ```java; // Old method, deprecated; public synchronized Collection<PathObject> getPointObjects(Class<? extends PathObject> cls). // New methods; public Collection<PathObject> getAllPointObjects(); public Collection<PathObject> getAllPointAnnotations() ; ```; This should be sufficiently obscure that there is no need to have separate methods to request point objects of more classes. If you *really* need point detections, for example. filtering the resulting collection should be straightforward, e.g.; ```java; var pointAnnotations = hierarchy.getAllPointObjects().stream().filter(PathObject::isDetection).toList();; ```. ---. To support these changes, `GeometryROI.contains(x, y)` was also updated to make use of an [`IndexedPointInAreaLocator`](https://locationtech.github.io/jts/javadoc/org/locationtech/jts/algorithm/locate/IndexedPointInAreaLocator.html) for complex geometries - enabling centroid tests to benefit from performance improvements ",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1563:5652,Access,Accessing,5652,https://qupath.github.io,https://github.com/qupath/qupath/pull/1563,2,"['Access', 'access']","['Accessing', 'accesses']"
Security," subclasses may be removed entirely, in favor of using a single `PathObject` class. Along the way, the API should become easier to understand and to use. ## What has changed. One of the main times when the specific Java class remains relevant is when querying objects from `PathObjectHierarchy` using one of the following methods:; ```java; public Collection<PathObject> getObjectsForROI(Class<? extends PathObject> cls, ROI roi). public Collection<PathObject> getObjectsForRegion(Class<? extends PathObject> cls, ImageRegion region, Collection<PathObject> pathObjects). public boolean hasObjectsForRegion(Class<? extends PathObject> cls, ImageRegion region). public synchronized Collection<PathObject> getPointObjects(Class<? extends PathObject> cls); ```. This PR deprecates these methods, and provides alternatives that do not require Java classes to be specified. ### Accessing objects for a `ROI`; This provides a way to access objects within (in some sense!) a specified ROI:; ```java; // Old method, discouraged (but not yet deprecated); public Collection<PathObject> getObjectsForROI(Class<? extends PathObject> cls, ROI roi). // New methods; public Collection<PathObject> getAllObjectsForROI(ROI roi); public Collection<PathObject> getAnnotationsForROI(ROI roi); public Collection<PathObject> getTilesForROI(ROI roi); public Collection<PathObject> getCellsForROI(ROI roi); public Collection<PathObject> getAllDetectionsForROI(ROI roi); ```. **There is an important (and possibly-unexpected) subtlety here!**. The new methods follow the original in *returning objects using QuPath's 'hierarchy' rules*:; * An annotation is 'within' a ROI if it is *completely contained* by the ROI; * A detection is 'within' a ROI if *its centroid* is within the ROI. Note that these methods take a `ROI` as input and not a `PathObject`: they aren't using the parent/child relationships between objects when deciding what to return. However they do correspond with how QuPath determines dynamic measurements (e",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1563:1332,Access,Accessing,1332,https://qupath.github.io,https://github.com/qupath/qupath/pull/1563,2,"['Access', 'access']","['Accessing', 'access']"
Security," the image data and project from the current QuPath UI, if available. This could potentially be confusing sometimes, e.g. if the following script was used with 'Run for project' it might print different image datas each time:; ```groovy; println ""Now: ${getCurrentImageData()}""; // runLater will be called in the application thread after the script has completed; Platform.runLater {; // This runs after the current image has been reset!; // Previously returned null, now returns current image in the viewer ; // (or null if there is no image open); println ""Later: ${getCurrentImageData()}""; }; ```. If you want to access the original image data later, you need to keep a reference to it, e.g.:; ```groovy; def imageData = getCurrentImageData(); println ""Now: $imageData""; Platform.runLater {; // This shows the same image data as original; // because the reference has been retained; println ""Later: $imageData""; }; ```. This still requires some caution, because if you retain a reference you need to access everything through that - and not via the 'default' methods in `QP`. For example, you need to get annotations with `imageData.getHierarchy().getAnnotationObjects()` rather than simply `getAnnotationObjects()`.; ```groovy; def imageData = getCurrentImageData(); println ""Now: $imageData""; Platform.runLater {; println ""Original of annotations 1: ${imageData.getHierarchy().getAnnotationObjects().size()}""; println ""Current viewer's number of annotations 1: ${getAnnotationObjects().size()}""; }; ```. For more normal use this shouldn't matter, because the script won't continue doing stuff after it has run to completion... but for advanced use that creates a UI that *shouldn't* use the current image in the viewer then it's important to know what's going on. **Reason for the change:** QuPath sets the 'current' image data and project in `QP` when a script is launched (for the scripting thread only) and resets then when the script has completed. This alone makes `QP` fairly useless outsi",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1078:5975,access,access,5975,https://qupath.github.io,https://github.com/qupath/qupath/pull/1078,1,['access'],['access']
Security," to https://github.com/openmicroscopy/bioformats/issues/2811. I don't see any way to resolve it within QuPath, and it requires a fix on the Bio-Formats side. If you just need to check what the label shows, you could try the script I posted at https://github.com/qupath/qupath/issues/141#issuecomment-358951720 - but it really is a terrible hack, which at best shows an image that looks a bit more plausible. As @rleigh-codelibre points out at https://github.com/openmicroscopy/bioformats/issues/2811#issuecomment-359474813 it doesn't restore the _right_ pixels, merely ones that are less obviously wrong. At best, it might be enough to see more or less what the image should contain without needing to open a new application... but it isn't a proper solution. When I look at the images you posted above with `tiffinfo`, it's clear that the _Photometric Interpretation_ stored in the file really is _YCbCr_ and my hack-y script overrides this. ---. For setting the color, you could try this:; ```groovy; // Set the LUT color for the first channel & repaint; def viewer = getCurrentViewer(); def channels = viewer.getImageDisplay().getAvailableChannels(). channels[0].setLUTColor(50, 200, 250). viewer.repaintEntireImage(); ```; where the three numbers are red, green & blue values (0-255). On a related note, `tiffinfo` also shows the file contains this for the main image:; ```; <channelSettings>; <channel index=""0"" name=""DAPI"" rgb=""#0000ff"" counterstain=""true"" spacingZ=""1000"" />; <channel index=""1"" name=""DsRED"" rgb=""#ffffff"" spacingZ=""1000"" />; <channel index=""2"" name=""Spectrum Green"" rgb=""#00ff00"" spacingZ=""1000"" />; <channel index=""3"" name=""Spectrum Far Red"" rgb=""#ff0000"" spacingZ=""1000"" />; </channelSettings>; ```; I can't see anywhere that Bio-Formats has parsed the channel names and colors, and this isn't currently accessible to QuPath. If the `LeicaSCNReader` were to be updated, and it was possible to get that information included, it could be handy in improving the default colors.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/191#issuecomment-409882684:1874,access,accessible,1874,https://qupath.github.io,https://github.com/qupath/qupath/issues/191#issuecomment-409882684,1,['access'],['accessible']
Security,"![image](https://user-images.githubusercontent.com/52460788/71204451-24f4ee80-226e-11ea-85e3-745eb9e8fe69.png). When I try to open projects that I have already successfully worked on using the 0.2.0-m2 milestone, the project itself will open but I cannot open any of the images from the project. I figured maybe the milestone version was outdated and so I tried downloading milestone 8 but now my project will not open at all and I get the message shown above. What can I do to access my old projects?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/388:478,access,access,478,https://qupath.github.io,https://github.com/qupath/qupath/issues/388,1,['access'],['access']
Security,"## Bug report. **Describe the bug**; After installing QuPath x64 on an M1 mac, everything works as intended. It is in the Applications folder and can be found using `CMD+Space`; However, it does not show up on the Launchpad. We tried ; https://www.quora.com/Why-are-the-apps-I-download-on-my-Mac-not-showing-up-on-launchpad-They-re-accessible-via-finder-only-in-the-applications-folder; but the command line that was suggested did not change the behaviour. **To Reproduce**; Steps to reproduce the behavior:; 1. Have QuPath 0.4.3 installed; 2. Notice how it can be found in the Launchpad; 3. Download and install QuPath 0.5.0-x64 for MacOS; 4. Notice QuPath 0.5.0-x64 in the Applications folder; 5. Try to find QuPath 0.5.0 in the Launchpa. **Expected behavior**; With previous versions of QuPath, it would automatically show up on the Launchpad. **Desktop**; - OS: MacOS Sonoma 14.2.1; - QuPath Version: 0.5.0. While definitely not a dealbreaker, it was an interesting behaviour to notice. It might be linked to there being two QuPath versions existing, however the user said that this had not been an issue in the past.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1448:332,access,accessible-via-finder-only-in-the-applications-folder,332,https://qupath.github.io,https://github.com/qupath/qupath/issues/1448,1,['access'],['accessible-via-finder-only-in-the-applications-folder']
Security,"## Bug report. **Describe the bug**; Bio-Formats can support more ways of handling channels than QuPath can currently read.; Specifically, this includes multiple channels with multiple samples-per-pixel in each channel. The effective number of channels comes from adding all the samples across all the channels. This problem turned up with a polarised light scan in CZI format: https://forum.image.sc/t/qupath-cant-open-polarized-light-scans/65951. **To Reproduce**; Awkward... Can likely only be reproduced using an image where; ```; metadata.getChannelCount(series) < nChannels; ```; and where the extra channels can be accessed via `metadata.getChannelSamplesPerPixel(series, channelInd)`. **Expected behavior**; QuPath properly opens all channel combinations supported by Bio-Formats. **Desktop (please complete the following information):**; - OS: All; - QuPath Version v0.3.2 and all previous. **Additional context**; When this occurs, we could have mixed modes... like brightfield & something else. So a satisfying fix might require supporting multi-modal images.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/956:622,access,accessed,622,https://qupath.github.io,https://github.com/qupath/qupath/issues/956,1,['access'],['accessed']
Security,"## Bug report. **Describe the bug**; Cluster features added using *Delaunay cluster features 2D* can be wrong whenever the measurement lists differ amongst objects. This happens because the measurement index (rather than name) is used to access measurements. **To Reproduce**; See https://forum.image.sc/t/cluster-mean-centroids-incorrect-in-qupath-0-2-1/40064 for details. **Expected behavior**; Cluster measurements are correct even if objects contain different measurement lists. **Additional context**; The Delaunay command is likely to be rewritten in a future version, but a short-term fix is still required.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/552:238,access,access,238,https://qupath.github.io,https://github.com/qupath/qupath/issues/552,1,['access'],['access']
Security,"## Bug report. **Describe the bug**; Exporting annotations across multiple z-slices can fail, in that annotations are drawn on more slices than they should. **To Reproduce**; Steps to reproduce the behavior:; 1. Create a QuPath project containing the ImageJ sample image 'Confocal Series' (accessed via *File &rarr; Open Samples*; 2. Import the attached .geojson file (rename .txt to .geojson) - can import via drag & drop; * [confocal-series-small.txt](https://github.com/qupath/qupath/files/11531594/confocal-series-small.txt) ; 4. Attempt export using the script below:. ```groovy; double downsample = 1.0. def imageData = getCurrentImageData(). def labelServer = new LabeledImageServer.Builder(imageData); .downsample(downsample) // Choose server resolution; this should match the resolution at which tiles are exported; .useInstanceLabels(); .useAnnotations(); .multichannelOutput(false) // If true, each label refers to the channel of a multichannel binary image (required for multiclass probability); .build(). def path = buildFilePath(PROJECT_BASE_DIR, ""labels.tif""); writeImage(labelServer, path); ```. **Expected behavior**; A TIFF stack is written that contains 3 annotations on different z-slices. **Screenshots**; All 3 annotations are included on slices where only one should appear. <img width=""410"" alt=""Screenshot 2023-05-22 at 14 39 46"" src=""https://github.com/qupath/qupath/assets/4690904/e5a8bd59-e49f-4af2-9202-3bf704df6e1a"">. **Desktop (please complete the following information):**; - OS: macOS (probably all); - QuPath Version: 0.4.3. **Additional context**; Problem first noticed when replying to https://forum.image.sc/t/exporting-annotations-for-all-z-stack/81393/3",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1267:290,access,accessed,290,https://qupath.github.io,https://github.com/qupath/qupath/issues/1267,1,['access'],['accessed']
Security,"## Bug report. **Describe the bug**; I am not sure if it's a bug or an intended behaviour, but I have a recurrent ""problem"" with the max display setting of fluorescent channels when viewing them and trying to find the best viewing settings. ; I have 16 bit images (.vsi) scanned on an olympus VS120. When opening them in QuPath, the first thing I usually do is to run a script to set the min and max display:; ```; // Get access to the display info for each channel; def viewer = getCurrentViewer(); def channels = viewer.getImageDisplay().availableChannels(). // Set the range for the 4 channels; channels[0].setMinDisplay(500); channels[0].setMaxDisplay(30000); channels[1].setMinDisplay(500); channels[1].setMaxDisplay(30000); channels[2].setMinDisplay(500); channels[2].setMaxDisplay(30000); channels[3].setMinDisplay(500); channels[3].setMaxDisplay(20000); ```. In theory it should be possible to use a maximum value of 65,536 if I am not mistaken, for 16 bit images. However, if I want to fine tune this setting and open the ""Brightness & Contrast"" tool, I am not able to go to the maximum theoritical value. ; If I start playing with the ""Max display"" side of the bar, it automatically ""clips"" the range to a certain value usually relatively low, making the signal way too strong in most cases (not sure how that value is calculated?), and there is no going back using this ""Brightness & Contrast"" tool. ; The only way of adjusting this value is to re-use the script. It is fine and can be done, but I was wondering if it would be possible to modify QuPath to prevent the software from this behaviour? I don't remember having such problem when using 8-bit Versa images, but I think I had the same issue using 32-bit vectra images. **Desktop (please complete the following information):**; - OS: Windows, macOS; - QuPath Version 0.2.0m3 (and before too)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/352:422,access,access,422,https://qupath.github.io,https://github.com/qupath/qupath/issues/352,1,['access'],['access']
Security,"## Bug report. **Describe the bug**; Initial bug report and steps to reproduce at https://forum.image.sc/t/qupath-script-cannot-access-java-library-and-project-data-simultanely/63388. The problem is that a class cannot be loaded from an extension far for multiple images in a project. When I tried, the first image 'worked' but all subsequent images failed with the error; ```; It looks like you have tried to import a class ‘qupath.ext.biop.cellpose.CellposeSetup’ that doesn’t exist!; MultipleCompilationErrorsException at line 7: startup failed:; Script2.groovy: 8: unable to resolve class qupath.ext.biop.cellpose.CellposeSetup; ```. **Expected behavior**; Extension jars are available for all images in the project when running from the command line, similar to how they are available when running through the GUI. **Desktop (please complete the following information):**; - OS: All; - QuPath v0.3.2 (earlier versions had other extension classpath problems). **Additional context**; The problem originates at https://github.com/qupath/qupath/blob/main/qupath-app/src/main/java/qupath/QuPath.java#L299 when a new `ExtensionClassLoader` instance is created. We need to instead use `QuPathGUI.getExtensionClassLoader()` consistently, since this is also requested within `DefaultScriptEditor`, e.g. [here](https://github.com/qupath/qupath/blob/7090e8137825f8f7dbc623c20bc62030c5c7db65/qupath-gui-fx/src/main/java/qupath/lib/gui/scripting/DefaultScriptEditor.java#L479). But if doing that, it may make more sense to add an `ExtensionClassLoader.getInstance()` method to avoid relying on `QuPathGUI.class` altogether.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/914:128,access,access-java-library-and-project-data-simultanely,128,https://qupath.github.io,https://github.com/qupath/qupath/issues/914,1,['access'],['access-java-library-and-project-data-simultanely']
Security,"## Bug report. **Describe the bug**; QuPath's viewer doesn't (really) support ICC profiles. This makes the display colors inconsistent with that seen in other viewers, for some file formats. **To Reproduce**; Steps to reproduce the behavior:; 1. Open an SVS image in QuPath; 2. Compare with the same SVS image opened in ImageScope (with ICC profile turned on). **Expected behavior**; QuPath would ideally provide an option to view the image with the ICC profile applied. This should *only* affect the viewer; analysis itself should not be impacted. *However*, it may be worth considering whether to add an `ImageServer` implementation that applies an ICC profile as well, since this might potentially be used as a way to do color standardisation (relevant e.g. for deep learning).; If this is done, then the information must be accessible to the viewer so that any embedded ICC profile isn't applied twice. **Screenshots**; See https://forum.image.sc/t/color-discrepancy-qupath-x-imagescope-leica-gt450/57948. **Desktop (please complete the following information):**; - OS: All; - QuPath Version: all until v0.3.2 (current). **Additional context**; For further discussion, see https://forum.image.sc/t/color-discrepancy-qupath-x-imagescope-leica-gt450/57948. There is some experimental (and hidden) support for ICC profiles accessible in QuPath via scripting, e.g. see https://github.com/qupath/qupath/blob/main/qupath-gui-fx/src/main/java/qupath/lib/gui/viewer/QuPathViewer.java#L2178; However, performance is really poor and it is not really usable at this time. Any implementation should be considered alongside gamma adjustment, see https://github.com/qupath/qupath/issues/981",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/982:828,access,accessible,828,https://qupath.github.io,https://github.com/qupath/qupath/issues/982,2,['access'],['accessible']
Security,"## Bug report. **Describe the bug**; When I open one of my scripts located in the script directory (directly from the menu) I get the following error messages:. ```; INFO: Loading script file C:\***script.groovy; ERROR: QuPath exception; at javafx.scene.control.skin.MenuButtonSkinBase.lambda$new$7(MenuButtonSkinBase.java:188); at com.sun.javafx.application.PlatformImpl.lambda$runLater$10(PlatformImpl.java:428); at java.base/java.security.AccessController.doPrivileged(Unknown Source); at com.sun.javafx.application.PlatformImpl.lambda$runLater$11(PlatformImpl.java:427); at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:96); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:174); at java.base/java.lang.Thread.run(Unknown Source); ```; I can still use the script editor, just need to close the warning.; I've tried changing directory or resaving the scripts but it didn't change anything... **Desktop (please complete the following information):**; - OS: Windows; - QuPath Version 0.2.0-m3",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/349:433,secur,security,433,https://qupath.github.io,https://github.com/qupath/qupath/issues/349,2,"['Access', 'secur']","['AccessController', 'security']"
Security,"## Bug report. **Describe the bug**; When training an object classifier multiple times, different results can be seen. This only happens (I *think*) whenever the image has been reopened: training is consistent if the image is not closed in the meantime. **To Reproduce**; Steps to reproduce the behavior:; 1. Open an image and detect some cells; 2. Train an object classifier with 2 small annotations & default settings; 3. Save the data and close the image; 4. Reopen the image, and train a new classifier with the same annotations and settings; 5. Observe that the classifications (probably) change... indicating that the classifier must be somehow different. **Expected behavior**; Training the same classifier with the same data *and the same RNG seed* should give the same results. **Desktop (please complete the following information):**; - OS: macOS (all presumably); - QuPath v0.3.2 (presumably some before as well). **Additional context**; See https://forum.image.sc/t/how-to-measure-the-staining-intensity-without-positive-cell-detection/66847/14 for the first report of related behaviour*. I'm labelling this as a bug despite my efforts to claim it isn't one :). All relevant RNGs should be properly seeded. I believe the problem occurs because the order of the objects used for training isn't deterministic, because `HashSets` and the like are used along the way.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1016:1329,Hash,HashSets,1329,https://qupath.github.io,https://github.com/qupath/qupath/issues/1016,1,['Hash'],['HashSets']
Security,"## Bug report. **Describe the bug**; When using QuPath v0.3.0-rc1 at the EMBO Advanced Methods in Bioimage Analysis course, density maps worked for most people - but not for all. Even a restart didn't help. Curiously, setting the density radius to 0 shows *something*. This suggests the problems arise during image filtering, which uses the JavaCPP presets for OpenCV. **To Reproduce**; I wish I knew. It might be hardware-dependent (or some other system conflict), but at this point I don't see the issue on any computer I have access to. **Expected behavior**; Consistency across computers where QuPath runs. **Desktop (please complete the following information):**; - OS: Windows 8, Windows 10 (so far); - QuPath Version 0.3.0-rc1. **Additional context**; My guess is that it is may be related to OpenCV, since QuPath is using OpenCV to apply filters and thereby calculate local densities. However, classifiers still seem to work - so not everything is broken, adding to the mystery. **Any more insights from anyone experiencing the bug would be very welcome!**",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/776:529,access,access,529,https://qupath.github.io,https://github.com/qupath/qupath/issues/776,1,['access'],['access']
Security,"## Bug report. **Describe the bug**; When working in a project and the computer or software crashes, you can later not access the file anymore that you were working on in the project. Meaning you loose all annotations and such. . **To Reproduce**; Steps to reproduce the behavior:; 1. Use your project with multiple files; 2. turn off your pc without saving or something error related; 3. Open the project again; 4. Try to open the image you were working in; 5. See error. ![image](https://user-images.githubusercontent.com/66477655/83880620-b46c5c00-a73f-11ea-9f5e-5c9c0ce802d0.png). **Expected behavior**; That the image is still accesible from an old version of the project. **Screenshots**. ![image](https://user-images.githubusercontent.com/66477655/83880655-c0f0b480-a73f-11ea-94ce-c4b19533e37d.png). **Desktop (please complete the following information):**; - OS: Windows; - QuPath Version 0.2.0",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/512:119,access,access,119,https://qupath.github.io,https://github.com/qupath/qupath/issues/512,1,['access'],['access']
Security,"## Bug report; QuPath 0.3 will not open on a CentOS 7 machine. Qupath 0.2.3 works fine in the same machine. I attach the full log. Steps to reproduce the behavior:; Execute the .sh file from the terminal. **Expected behavior**; To open the graphical interface. **Log**; OpenJDK 64-Bit Server VM warning: Option --illegal-access is deprecated and will be removed in a future release.; Sep 22, 2021 2:59:18 PM com.sun.javafx.application.PlatformImpl startup; WARNING: Unsupported JavaFX configuration: classes were loaded from 'unnamed module @37052337'; *** Error in `/home/xxx/QuPath-0.3/bin/QuPath': free(): invalid pointer: 0x00007f726889bbc0 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x81679)[0x7fa4aa191679]; /usr/lib64/libstdc++.so.6(_ZNSt6locale5_Impl16_M_install_facetEPKNS_2idEPKNS_5facetE+0x142)[0x7f7268605ed2]; /usr/lib64/libstdc++.so.6(_ZNSt6locale5_ImplC1Em+0x1e3)[0x7f7268606323]; /usr/lib64/libstdc++.so.6(+0x71295)[0x7f7268607295]; /lib64/libpthread.so.0(+0x61cb)[0x7fa4a9ad31cb]; /usr/lib64/libstdc++.so.6(+0x712e1)[0x7f72686072e1]; /usr/lib64/libstdc++.so.6(_ZNSt6localeC2Ev+0x13)[0x7f7268607323]; /usr/lib64/libstdc++.so.6(_ZNSt8ios_base4InitC2Ev+0xbc)[0x7f726860417c]; /usr/lib64/dri/swrast_dri.so(+0x85930)[0x7f726bbe8930]; /lib64/ld-linux-x86-64.so.2(+0xf973)[0x7fa4aa9f3973]; /lib64/ld-linux-x86-64.so.2(+0x1454e)[0x7fa4aa9f854e]; /lib64/ld-linux-x86-64.so.2(+0xf784)[0x7fa4aa9f3784]; /lib64/ld-linux-x86-64.so.2(+0x13b3b)[0x7fa4aa9f7b3b]; /lib64/libdl.so.2(+0xeeb)[0x7fa4aa7e0eeb]; /lib64/ld-linux-x86-64.so.2(+0xf784)[0x7fa4aa9f3784]; /lib64/libdl.so.2(+0x14ed)[0x7fa4aa7e14ed]; /lib64/libdl.so.2(dlopen+0x31)[0x7fa4aa7e0f81]; /lib64/libGLX_system.so.0(+0x4444c)[0x7f726ecdd44c]; /lib64/libGLX_system.so.0(+0x4374a)[0x7f726ecdc74a]; /lib64/libGLX_system.so.0(+0x1f138)[0x7f726ecb8138]; /lib64/libGLX_system.so.0(+0x1a9d2)[0x7f726ecb39d2]; /lib64/libGLX_system.so.0(+0x1b7c6)[0x7f726ecb47c6]; /lib64/libGLX.so.0(glXChooseFBConfig+0x31)[0x7f726f5df6b1]; /home/xxx/.op",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/825:321,access,access,321,https://qupath.github.io,https://github.com/qupath/qupath/issues/825,1,['access'],['access']
Security,"## Feature request. **Is your feature request related to a problem? Please describe.**; Currently setting stain vectors or adjusting pre-set ones (like H&E) requires scripting and being run for each image open (or project) to ensure they are all the same. This can get complicated particularly when dealing with multiple different brightfield (other) stain types in one project.; Additionally the ability to share these stain vectors would be useful, other than sharing the script. . **Describe the solution you'd like**; This request is for a way to create these custom stain vectors and retain them within QuPath either as a setting or within the project. ; Additionally, being able to share them with others and allow for them to be imported into QuPath via drag and drop would be very beneficial. . **Describe alternatives you've considered**; Scripting is currently the best option for doing this, but this makes it less accessible to users that are not familiar with scripting. Additionally, the scripting method would require additional processing steps that could be reduced. . **Additional context**; May of missed key design points from discussion, feel free to edit/add!; Spoke about the same sharing functionality being used for fluorescent images but would only really be useful for those with many channels (which also currently uses scripting to set).",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1247:926,access,accessible,926,https://qupath.github.io,https://github.com/qupath/qupath/issues/1247,1,['access'],['accessible']
Security,"## Feature request. **Is your feature request related to a problem? Please describe.**; QuPath is commonly used for annotation, and the annotations need to be shared with others. My approach is generally to zip up a project folder. The trouble with this is that it's necessary to then:; * Send the zipped project; * Send the original images; * Unzip the project; * Open the unzipped project in QuPath; * Match the URIs to the new image locations. **Describe the solution you'd like**; It would be nice to have a command to *Export project for sharing* that can do the zipping itself. This could include options:; * Include thumbnails; * Since thumbnails can be regenerated automatically by QuPath, removing them can reduce the zipped file size; * Include original images; * This would involve copying the image files directly into a subdirectory of the project, and updating the URIs to make the project fully self-contained. **Describe alternatives you've considered**; The main alternative is to stick with the current method: document the zipping/unzipping process, but don't add anything to QuPath to help. **Additional context**; Some considerations:; * If there are many images, or they are huge, then including them in the zip file might become problematic; * We need to take care with zipping/unzipping (e.g. ensuring we don't allow names with `..` for security reasons, or use an established and secure library implementation); * This approach only really works with the current, filesystem-based project approach. Any command might not be relevant if projects are stored some other way.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1248:1361,secur,security,1361,https://qupath.github.io,https://github.com/qupath/qupath/issues/1248,2,['secur'],"['secure', 'security']"
Security,"## Feature request. Previous QuPath releases could use Bio-Formats' memoization to help with creating new file readers, at least when the initialization time was slow: https://bio-formats.readthedocs.io/en/latest/developers/matlab-dev.html#improving-reading-performance. This wasn't available in QuPath v0.4.0-v0.4.2 because we switched to Java 17, and [memoization was broken there](https://github.com/ome/bioformats/issues/3659#issuecomment-805134072). This is fixed in Bio-Formats 6.12.0, so we can reinstate it again. ### Effects of memoization. When opening an image with Bio-Formats, QuPath uses multiple Bio-Formats readers to access pixels in parallel. Each reader needs to be initialized. Generally this is fast, but sometimes (e.g. with certain files or file types) it is slow. In one particularly bad case (a very large .czi file) I've seen it take minutes. Memoization makes it possible to create `.bfmemo` files the first time a reader is created, so that subsequent readers can use these for faster initialization. ### Turning on memoization. Because memoization involves writing files to disk, users might not always want it. QuPath provides two preferences to control this:. * **Bio-Formats memoization time (ms)** If less than 0, don't use memoization. If >= 0, create a memoization file only if initialization of a reader takes longer than the specified milliseconds. If initialization is fast anyway, memoization is pretty pointless.; * **Bio-Formats memoization directory** If specified, store memoization files in here. Then they are persistent, and available when QuPath is reopened. *Otherwise*, store any memoization files in a temporary directory and delete the directory when QuPath is shut down. ### Default behavior. The default behavior (at least in v0.3.0 - v0.4.2) was to specify a memoization time of 500 ms, and not to specify a directory (i.e. only use temporary files). Upon inspection, it seems that this still creates temporary directories even if no `.bfmemo` fil",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1236:634,access,access,634,https://qupath.github.io,https://github.com/qupath/qupath/issues/1236,1,['access'],['access']
Security,"## IMPORTANT!. This section is **only** for bug reports, which **must** follow the template below. Please post any other questions to the official QuPath forum at https://forum.image.sc/tags/qupath. If in doubt, use [image.sc](https://forum.image.sc/tags/qupath). This helps us keep things organized. ## Before we begin... Before submitting your bug report, please check the following:. * [x ] I've definitely found a bug (it you're not sure, please use [image.sc](https://forum.image.sc/tags/qupath) instead); * [x ] I've checked https://qupath.github.io for a new release that might already have fixed the issue; * [x ] I've checked the [Changelog](https://github.com/qupath/qupath/blob/master/CHANGELOG.md) to see if the bug has already been fixed in the next release; * [x ] I've checked for existing GitHub issues describing the same problem. ## Bug report. **Describe the bug**; QuPath uses Apache commons-text version 1.9, which exposes a known critical vulnerability ( see https://nvd.nist.gov/vuln/detail/CVE-2022-42889 ). **Expected behavior**; Should use commons-text 1.10, which has fixed the issue. **Additional context**; Users in enterprises may be forced to remove QuPath from their computers, even if the vulnerability is not exploitable.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1141:936,expose,exposes,936,https://qupath.github.io,https://github.com/qupath/qupath/issues/1141,1,['expose'],['exposes']
Security,"## WHAT; This PR improves performance when running a script that does not need to access the image files on multiple images.; Additionally, allowed to modify `ObjectClassifierCommand` too so that it can read all detections' measurements in the training set without uselessly reading the image files.; This last change alone allowed, on my projects, to improve the time when creating an object classifier from ~10/15minutes to ~5seconds.; I feel like this change is useful when a laboratory works with large projects with image locations being on a remote server. This is also possible thanks to QuPath's amazing design choice to never directly modify images.; If the scripts being run wants to access the images' pixels, it gracefully halts the execution of the all the following project entries too. _example_:; ```groovy; import qupath.imagej.tools.IJTools; import qupath.lib.images.PathImage; import ij.ImagePlus. var server = getCurrentServer(); var downsample = server.getDownsampleForResolution(Math.min(server.nResolutions()-1, 4)); PathImage<ImagePlus> pathImage = IJTools.convertToImagePlus(server, RegionRequest.createInstance(server, downsample)); ```; ""_Run for project (without saving and opening)_"":; ```; INFO: Starting script at Tue Mar 26 15:20:37 CET 2024; ERROR: The script tried to read pixels off an image while also requiring to run the script without accessing the image files.; WARN: Script cancelled with 53 image(s) remaining; INFO: Processed 54 images; INFO: Total processing time: 280 milliseconds; ```. ## HOW; Essentially this works by creating a `ImageServerStub` that extends `AbstractImageServer`. It retrieves metadata from the ProjectImageEntry itself (which in turn, i think, it gets them from the `.qpproj` file) and fails when `readRegion()` is being called. Additionally, it does not provide a server builder. This way, if the resulting image data are to be saved, the original ImageServer won't be overwritten/lost.; You can now pass a `openImage` boolean to `P",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1488:82,access,access,82,https://qupath.github.io,https://github.com/qupath/qupath/pull/1488,2,['access'],['access']
Security,(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$KeyHandler.process(Scene.java:4058); at javafx.scene.Scene$KeyHandler.access$1500(Scene.java:4004); at javafx.scene.Scene.processKeyEvent(Scene.java:2121); at javafx.scene.Scene$ScenePeerListener.keyEvent(Scene.java:2595); at com.sun.javafx.tk.quantum.GlassViewEventHandler$KeyEventNotification.run(GlassViewEventHandler.java:217); at com.sun.javafx.tk.quantum.GlassViewEventHandler$KeyEventNotification.run(GlassViewEventHandler.java:149); at java.base/java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleKeyEvent$1(GlassViewEventHandler.java:248); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:390); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleKeyEvent(GlassViewEventHandler.java:247); at com.sun.glass.ui.View.handleKeyEvent(View.java:547); at com.sun.glass.ui.View.notifyKey(View.java:971); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:174); at java.base/java.lang.Thread.run(Thread.java:834),MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/314:15393,secur,security,15393,https://qupath.github.io,https://github.com/qupath/qupath/issues/314,2,"['Access', 'secur']","['AccessController', 'security']"
Security,(GradleBuildController.java:57); at org.gradle.internal.invocation.GradleBuildController$3.create(GradleBuildController.java:85); at org.gradle.internal.invocation.GradleBuildController$3.create(GradleBuildController.java:78); at org.gradle.internal.work.DefaultWorkerLeaseService.withLocks(DefaultWorkerLeaseService.java:189); at org.gradle.internal.work.StopShieldingWorkerLeaseService.withLocks(StopShieldingWorkerLeaseService.java:40); at org.gradle.internal.invocation.GradleBuildController.doBuild(GradleBuildController.java:78); at org.gradle.internal.invocation.GradleBuildController.run(GradleBuildController.java:57); at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:31); at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); at org.gradle.launcher.exec.BuildOutcomeReportingBuildActionRunner.run(BuildOutcomeReportingBuildActionRunner.java:63); at org.gradle.tooling.internal.provider.ValidatingBuildActionRunner.run(ValidatingBuildActionRunner.java:32); at org.gradle.launcher.exec.BuildCompletionNotifyingBuildActionRunner.run(BuildCompletionNotifyingBuildActionRunner.java:39); at org.gradle.launcher.exec.RunAsBuildOperationBuildActionRunner$3.call(RunAsBuildOperationBuildActionRunner.java:51); at org.gradle.launcher.exec.RunAsBuildOperationBuildActionRunner$3.call(RunAsBuildOperationBuildActionRunner.java:45); at org.gradle.internal.operations.DefaultBuildOperationExecutor$CallableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:416); at org.gradle.internal.operations.DefaultBuildOperationExecutor$CallableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:406); at org.gradle.internal.operations.DefaultBuildOperationExecutor$1.execute(DefaultBuildOperationExecutor.java:165); at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:250); at org.gradle.internal.operations.DefaultBuildOperationExecutor.exec,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/427:7271,Validat,ValidatingBuildActionRunner,7271,https://qupath.github.io,https://github.com/qupath/qupath/issues/427,1,['Validat'],['ValidatingBuildActionRunner']
Security,"(processing time: 5.53 seconds); INFO: Processing complete in 34.91 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""cellExpansionMicrons"": 5.0, ""includeNuclei"": true, ""smoothBoundaries"": true, ""makeMeasurements"": true}; INFO: Writing object hierarchy with 29994 object(s)...; INFO: Image data written to N:\Faculty-of-Medicine-and-Health\LICAP\DATA\PTHY\Pathology\Breast Group\BCCTB Samples\Audits\BCN QA 2017\Frozen samples QuPath tumourstromaratio\Batch_2\Tumour\402428.qpdata in 2.08 seconds; INFO: Training size: 33x5031; INFO: Responses size: 1x5031; INFO: RTrees classifier termination criteria: { type: 1, maxCount: 50, epsilon: 0.0}; ERROR: QuPath exception; at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$354(GlassViewEventHandler.java:416); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:415); at com.sun.glass.ui.View.handleMouseEvent(View.java:555); at com.sun.glass.ui.View.notifyMouse(View.java:937); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$null$148(WinApplication.java:191); at java.lang.Thread.run(Thread.java:745); Caused by std::exception: bad allocation at org.opencv.ml.StatModel.train_0(Native Method); at org.opencv.ml.StatModel.train(StatModel.java:74); at qupath.opencv.classify.OpenCvClassifier.createAndTrainClassifier(OpenCvClassifier.java:250); at qupath.opencv.classify.ParameterizableOpenCvClassifier.createAndTrainClassifier(ParameterizableOpenCvCla",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:4975,secur,security,4975,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['secur'],['security']
Security,); at org.gradle.internal.invocation.GradleBuildController$3.create(GradleBuildController.java:85); at org.gradle.internal.invocation.GradleBuildController$3.create(GradleBuildController.java:78); at org.gradle.internal.work.DefaultWorkerLeaseService.withLocks(DefaultWorkerLeaseService.java:189); at org.gradle.internal.work.StopShieldingWorkerLeaseService.withLocks(StopShieldingWorkerLeaseService.java:40); at org.gradle.internal.invocation.GradleBuildController.doBuild(GradleBuildController.java:78); at org.gradle.internal.invocation.GradleBuildController.run(GradleBuildController.java:57); at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:31); at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); at org.gradle.launcher.exec.BuildOutcomeReportingBuildActionRunner.run(BuildOutcomeReportingBuildActionRunner.java:63); at org.gradle.tooling.internal.provider.ValidatingBuildActionRunner.run(ValidatingBuildActionRunner.java:32); at org.gradle.launcher.exec.BuildCompletionNotifyingBuildActionRunner.run(BuildCompletionNotifyingBuildActionRunner.java:39); at org.gradle.launcher.exec.RunAsBuildOperationBuildActionRunner$3.call(RunAsBuildOperationBuildActionRunner.java:51); at org.gradle.launcher.exec.RunAsBuildOperationBuildActionRunner$3.call(RunAsBuildOperationBuildActionRunner.java:45); at org.gradle.internal.operations.DefaultBuildOperationExecutor$CallableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:416); at org.gradle.internal.operations.DefaultBuildOperationExecutor$CallableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:406); at org.gradle.internal.operations.DefaultBuildOperationExecutor$1.execute(DefaultBuildOperationExecutor.java:165); at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:250); at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecu,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/427:7303,Validat,ValidatingBuildActionRunner,7303,https://qupath.github.io,https://github.com/qupath/qupath/issues/427,1,['Validat'],['ValidatingBuildActionRunner']
Security,"* Add `--illegal-access=permit` Java option, intended to work around bugs such as https://github.com/qupath/qupath/issues/717 (and the inability to set project entry metadata, spotted by @Svidro); * Avoid using paragraph folding, new in RichTextFX 0.10.6, which could result in script editor exceptions (thanks to @melvingelbard for spotting that)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/721:17,access,access,17,https://qupath.github.io,https://github.com/qupath/qupath/pull/721,1,['access'],['access']
Security,"* Further reduce memory use with ImageOps / ImageDataOp; * Fix multithreading ImageOps color deconvolution bug; * Allow the number of live prediction threads to be adjusted with pixel classifiers; * Reduce the length of the server path used with pixel classifiers (could cause performance issues for some classifiers, e.g. Trees, with long JSON representations); * Add extra checks in DelaunayTools to reduce risk of trying to access a coordinate that isn't there",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/808:427,access,access,427,https://qupath.github.io,https://github.com/qupath/qupath/pull/808,1,['access'],['access']
Security,"* Include missing commons dependency; * Support changing image quality in the args array; * Make sure passwords don't filter through to server args (doesn't seem possible anyway, but add an extra check)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/709:102,password,passwords,102,https://qupath.github.io,https://github.com/qupath/qupath/pull/709,1,['password'],['passwords']
Security,"* Update JavaCPP/OpenCV. This includes Apple Silicon support if built with a compatible JDK (but OpenSlide/Bio-Formats still won't work).; * Update Picocli; * Remove `SecurityManager` reference in `ThreadTools`, because it is deprecated for removal in Java 17",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/913:167,Secur,SecurityManager,167,https://qupath.github.io,https://github.com/qupath/qupath/pull/913,1,['Secur'],['SecurityManager']
Security,"* Update to Bio-Formats 6.9.1; * Fix https://github.com/qupath/qupath/issues/956; * Work around https://github.com/qupath/qupath/issues/957. Memoization will need to be revisited in the future. Here, it is disabled when using using Java 17+ because it doesn't work and logs many errors (somehow related to JEP 403). This behavior can be overridden by adding; ```; java-options=-Dqupath.bioformats.allow.memoization=true; ```; to the QuPath.cfg file (i.e. set the system property), but it likely won't help until there is a new Bio-Formats release. Relatedly, the qupath-app build.gradle now only adds `--illegal-access=permit` for Java 16, since it's the only version where it makes a difference. The easiest way to get QuPath with memoization is therefore to use; ```; gradlew jpackage -Ptoolchain=16; ```",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/958:612,access,access,612,https://qupath.github.io,https://github.com/qupath/qupath/pull/958,1,['access'],['access']
Security,"**Describe the bug**; I erroneously set requestedPixelSize = 0 instead of downsample = 0 in my exporting script that I adapted from [the docs](https://qupath.readthedocs.io/en/0.2/docs/advanced/exporting_annotations.html), the script didn't error but instead, after about a day running and my RAM filling up to about 20GB I realized my mistake. I suspect requestedPixelSize = 0 causes an infinite loop somewhere or the divide by zero on lines 378 and 379 of TileExporter are handled strangely. **To Reproduce**; In the script from [the docs](https://qupath.readthedocs.io/en/0.2/docs/advanced/exporting_annotations.html) set equestedPixelSize = 0 . **Expected behavior**; It would be nice to have some input validation or a way to raise an exception for this use case. . **Desktop (please complete the following information):**; OS: Windows 7; QuPath Version 0.2.3",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/777:708,validat,validation,708,https://qupath.github.io,https://github.com/qupath/qupath/issues/777,1,['validat'],['validation']
Security,"**Description**; When I attempt to install QuPath 0.3.0 on Windows 10, the text of QuPath is unreadable (please see screenshot below). **To Reproduce**; Steps to reproduce the behavior:; 1. Download QuPath from https://github.com/qupath/qupath/releases/download/v0.3.0/QuPath-0.3.0-Windows.msi.; 2. Bypass Windows Defender security alerts.; 3. Run the installer.; 4. Open QuPath 0.3.0. **Screenshots**. ![image](https://user-images.githubusercontent.com/43010710/146222250-0d831aa3-f959-4bec-95d4-6af049cf994e.png). **Desktop**; - OS: Windows; - QuPath Version: 0.3.0. **Hash**; The SHA256 hash of the file I downloaded is:; ```; certutil -hashfile QuPath-0.3.0-Windows.msi SHA256; SHA256 hash of QuPath-0.3.0-Windows.msi:; d3661adca21ab8ea31acfa5d150345fb4b46a983526803fce3869f520949965e; ```; However, I cannot find the hash of the file from the GitHub API: https://api.github.com/repos/qupath/qupath/releases (see [here](https://stackoverflow.com/questions/29671303/where-to-get-md5-hashes-from-a-github-release)).",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/866:323,secur,security,323,https://qupath.github.io,https://github.com/qupath/qupath/issues/866,7,"['Hash', 'hash', 'secur']","['Hash', 'hash', 'hashes-from-a-github-release', 'hashfile', 'security']"
Security,"**To Reproduce**; Steps to reproduce the behavior:; 1. Make a directory and add a QuPath Extension; 2. Within Edit > Preferences > QuPath user Directory and set it to your created directory above.; 2. Close QuPath And Reopen; 3. **Go to Help > Installed Extensions, the extension is not there.**; 4. Drag and Drop extension into QuPath; 5. QuPath says ""No Extensions Directory is set"" (So it is not the user directory?) and offers to create it at C:\Users\username; 6. Set the Extension directory to where it was created in step 1; 7. Now Extension is loaded but inside an 'extensions' directory. **Expected behavior**; When the `User Directory` is set (Which I guess used to be called `Extensions Directory`, which is no longer in preferences), and restarting QuPath, all extensions from that directory should be loaded.; Moreover the location of the Extension Directory should be accessible somewhere in the preferences.; We would expect the Extensions directory be independent from the User Directory. This seems like a non-braking change as there is no documentation on how to load extensions in QuPath 0.2.0 in readthedocs and most people are not using extensions (Except us). **Additional Remarks**; As a core facility, Extensions make little sense on a 'per user' basis, especially given how complex and supposedly independent they are from each other, or from the individual user's needs. For us they are more suitably used like in ImageJ: All extensions (or plugins) are loaded by ImageJ/Fiji regardless of the currently logged in user. This ensures a streamlined experience for all our users without intervention on our side. We see that we can load or save preferences, so we can do this for each user as needed, but it makes it more tedious for us to distribute and debug issues when such settings are per-user. **Desktop (please complete the following information):**; - Windows 10 x64; - QuPath Version .2.0-m12. Thank you for your time.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/500:882,access,accessible,882,https://qupath.github.io,https://github.com/qupath/qupath/issues/500,1,['access'],['accessible']
Security,", 3dnowpref, sse, sse2, sse3, ssse3, sse4.1, sse4.2, popcnt, lzcnt, tsc, tscinvbit, avx, avx2, aes, erms, clmul, bmi1, bmi2, rtm, adx, fma, vzeroupper, clflush, clflushopt; Processor Information for all 6 processors :; Max Mhz: 3000, Current Mhz: 3000, Mhz Limit: 3000. Memory: 4k page, system-wide physical 7966M (772M free); TotalPageFile size 23838M (AvailPageFile size 7045M); current process WorkingSet (physical memory assigned to process): 3284M, peak: 3876M; current process commit charge (""private bytes""): 6219M, peak: 6444M. vm_info: OpenJDK 64-Bit Server VM (17.0.8+7) for windows-amd64 JRE (17.0.8+7), built on Jul 18 2023 21:02:32 by ""admin"" with MS VC++ 16.7 (VS2019). END. From: Pete ***@***.***>; Sent: Thursday, November 2, 2023 2:08 PM; To: qupath/qupath ***@***.***>; Cc: Farias Da Guarda, Suzete Nascimento ***@***.***>; Mention ***@***.***>; Subject: Re: [qupath/qupath] Load training in object classifier -> QuPath crashes (#493). External Email - Use Caution. @suzeteguarda<https://secure-web.cisco.com/15zJZ1AC2HfUFv9L0mLItqMCfEQMcq1aVBJmggNtWQuQ1aMdkxQL4M8DQsziZIjbQclRsiUgnd4btBVr7WmNM9GAmb5IdGegWqzsNoLW7i0t8ZduDtcd418DQ9BIIDpRAJC02UjlE2keamNPfGPyTA13hxoJ6aI6fRjs8P6PPD3ag1gjsZJuHqXh28XIp9ClIy6uiD9WiE2a29pnEogefoBAUSjm8iBfMR0HcxqAtG_TdnAk0f4Y8BA4E5sVwzFhbDhm_alns-l7jx4c65825lN1brlaamgEFYOcr-bx0yB5-ONuFLKVRdD6nCGWcI1iPAsoohE7nnVhyPIYtURWpKQ/https%3A%2F%2Fgithub.com%2Fsuzeteguarda> you could try posting your question on the forum at https://forum.image.sc/tag/qupath<https://secure-web.cisco.com/13_E9lRMQxY8xtZmKYPnw2mmwaiElPiHzTIMUOwQH_-6FzgRz4LkCsf_cFjrfUWLwo9750a0MmRr_eXTVN0eusQkomn-qYLuoCcVIKhtD0lyGLisH8Fxc-WFZwGzOR3GcJ4WLvQ2nVTFF7JEFSGly69C9pq9zGxJ69U6IM5ck9ofp9vkUV14NNMWH0h1u9pMUi3qXwaLEHdnCfRaAU7pipTjdj7etnYxMl6fke2A03VF49uEY6P4XmHIM3ote076fSVZpQqVTzYq0orKjFBwoKIbptcmC4XxHSSCRt900YIULIVQAtzU62qtHv_TEqaLa9vgoz2qhsY9NbYDfMfFPtA/https%3A%2F%2Fforum.image.sc%2Ftag%2Fqupath>. The error is that there isn't enough memory, but without having the classifier and ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/493#issuecomment-1791396738:1360,secur,secure-web,1360,https://qupath.github.io,https://github.com/qupath/qupath/issues/493#issuecomment-1791396738,1,['secur'],['secure-web']
Security,"- Now allows 3 different kinds of OMERO URLs (i.e. ""Webgateway"", ""Webclient"", ""iViewer""); - Handles import of multiple images in a single URL; - Handles whole projects/datasets import; - Safer password handling; - Clearer warning/error messages when Exceptions occur",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/479:193,password,password,193,https://qupath.github.io,https://github.com/qupath/qupath/pull/479,1,['password'],['password']
Security,.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:238); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:191); at com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDispatcher.java:59); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:58); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$DnDGesture.fireEvent(Scene.java:2933); at javafx.scene.Scene$DnDGesture.processTargetDrop(Scene.java:3159); at javafx.scene.Scene$DnDGesture.access$6400(Scene.java:2909); at javafx.scene.Scene$DropTargetListener.drop(Scene.java:2873); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.lambda$handleDragDrop$309(GlassSceneDnDEventHandler.java:95); at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragDrop(GlassSceneDnDEventHandler.java:92); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragDrop$363(GlassViewEventHandler.java:700); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragDrop(GlassViewEventHandler.java:699); at com.sun.glass.ui.View.handleDragDrop(View.java:712); at com.sun.glass.ui.View.notifyDragDrop(View.java:1037); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$null$148(WinApplication.java:191); at java.lang.Thread.run(Thread.java:745); ERROR: Unable to build whole ,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/351:3121,access,access,3121,https://qupath.github.io,https://github.com/qupath/qupath/issues/351,1,['access'],['access']
Security,.application.PlatformImpl.lambda$runLater$11(PlatformImpl.java:427); at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:96); at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); at com.sun.glass.ui.gtk.GtkApplication.lambda$runLoop$11(GtkApplication.java:277); at java.base/java.lang.Thread.run(Thread.java:834); ERROR: QuPath exception; at qupath.lib.gui.viewer.QuPathViewer.updateSuggestedOverlayColorFromThumbnail(QuPathViewer.java:996); at qupath.lib.gui.viewer.QuPathViewer.getSuggestedOverlayColor(QuPathViewer.java:1005); at qupath.lib.gui.viewer.QuPathViewer.paintViewer(QuPathViewer.java:1665); at qupath.lib.gui.viewer.QuPathViewer.paintCanvas(QuPathViewer.java:413); at qupath.lib.gui.viewer.QuPathViewerPlus.paintCanvas(QuPathViewerPlus.java:249); at qupath.lib.gui.viewer.QuPathViewer.lambda$repaint$4(QuPathViewer.java:501); at com.sun.javafx.application.PlatformImpl.lambda$runLater$10(PlatformImpl.java:428); at java.base/java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.application.PlatformImpl.lambda$runLater$11(PlatformImpl.java:427); at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:96); at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); at com.sun.glass.ui.gtk.GtkApplication.lambda$runLoop$11(GtkApplication.java:277); at java.base/java.lang.Thread.run(Thread.java:834); INFO: TiffDelegateReader initializing /home/joelrv/Downloads/test_pyramid.tif; INFO: Reading IFDs; INFO: Populating metadata; INFO: Checking comment style; INFO: Populating OME metadata; INFO: No memoization file generated for /home/joelrv/Downloads/test_pyramid.tif; INFO: Returning server: Bio-Formats for /home/joelrv/Downloads/test_pyramid.tif; ERROR: QuPath exception; ERROR: java.lang.OutOfMemoryError: Java heap space; WARN: Fallback to requesting thumbnail directly...; ERROR: QuPath exception; WARN: Tile request exception; ERROR: QuPath exception; at qupath.lib.gui.viewer.QuPathView,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/279#issuecomment-472375699:8412,Access,AccessController,8412,https://qupath.github.io,https://github.com/qupath/qupath/issues/279#issuecomment-472375699,1,['Access'],['AccessController']
Security,".com/qupath/qupath/blob/master/qupath-core/src/main/java/qupath/lib/roi/PolygonROI.java) for polygons. The most useful constructor is:; ```groovy; public PolygonROI(float[] x, float[] y, int c, int z, int t); ```; For ```c```, ```z``` and ```t``` (channel, z-slide & time point) you can probably use ```-1```, ```0```, ```0``` by default. . After creating your polygon ROI, then create a [```PathAnnotationObject```](https://github.com/qupath/qupath/blob/master/qupath-core/src/main/java/qupath/lib/objects/PathAnnotationObject.java) with the ROI:; ```groovy; public PathAnnotationObject(ROI pathROI); ```. and finally you can add this annotation to the hierarchy simply with; ```groovy; addObject(annotation); ```. I have some memory of Aperio ImageScope having a concept of layers, and also 'negative' regions; I don't know if this would also be in your XML. If so, these may not have exact matches inside QuPath, but there are various tricks you could use if you find they are needed (e.g. combining or subtracting ROIs, adding them to the hierarchy in different ways, setting names, classifications or colors etc.). If you haven't already, I suggest checking out the Wiki for [Writing custom scripts](https://github.com/qupath/qupath/wiki/Writing-custom-scripts) and [Advanced scripting with IntelliJ](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ), which can help with writing the code and accessing the QuPath source. Finally, it may also be useful to know that, if you want to use any other Java libraries to help, then you can drag the required Jar file onto QuPath to copy it into QuPath's extensions directory. Even if the Jar isn't a 'real' QuPath extension, this means that it will still be available on QuPath's classpath when running the script. This could be useful if your XML parsing code is already contained in a Jar, or if you want to add another library (e.g. ```groovy-xml.jar```) to help with scripting the parsing. Hopefully that helps to get started.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/61#issuecomment-290912225:2148,access,accessing,2148,https://qupath.github.io,https://github.com/qupath/qupath/issues/61#issuecomment-290912225,1,['access'],['accessing']
Security,".dispatchBubblingEvent(CompositeEventDispatcher.java:59); 	at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:58); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); 	at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); 	at javafx.event.Event.fireEvent(Event.java:198); 	at javafx.scene.Scene$DnDGesture.fireEvent(Scene.java:3144); 	at javafx.scene.Scene$DnDGesture.processTargetEnterOver(Scene.java:3316); 	at javafx.scene.Scene$DropTargetListener.dragEnter(Scene.java:3024); 	at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.lambda$handleDragEnter$0(GlassSceneDnDEventHandler.java:83); 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:399); 	at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragEnter(GlassSceneDnDEventHandler.java:77); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragEnter$9(GlassViewEventHandler.java:733); 	at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:424); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragEnter(GlassViewEventHandler.java:732); 	at com.sun.glass.ui.View.handleDragEnter(View.java:684); 	at com.sun.glass.ui.View.notifyDragEnter(View.java:1020); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$runLoop$11(GtkApplication.java:316); 	at java.base/java.lang.Thread.run(Thread.java:833); 13:36:13.428 [JavaFX Application Thread] [ERROR] q.l.g.QuPathUncaughtExceptionHandler - setDropCompleted can be called only from DRAG_DROPPED handler (see full stack trace above, or use 'debug' log level); 13:36:13.788 [JavaFX Application Threa",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1338#issuecomment-1727641846:1823,Access,AccessController,1823,https://qupath.github.io,https://github.com/qupath/qupath/pull/1338#issuecomment-1727641846,1,['Access'],['AccessController']
Security,.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$MouseHandler.process(Scene.java:3890); at javafx.scene.Scene.processMouseEvent(Scene.java:1885); at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2618); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:409); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:299); at java.base/java.security.AccessController.doPrivileged(Unknown Source); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$2(GlassViewEventHandler.java:447); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:412); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:446); at com.sun.glass.ui.View.handleMouseEvent(View.java:556); at com.sun.glass.ui.View.notifyMouse(View.java:942); at com.sun.glass.ui.mac.MacView.notifyMouse(MacView.java:127). The annotations were all created using earlier versions (all of them were created in m9). Annotations that I create in m10 are editable.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/456#issuecomment-619374801:3795,secur,security,3795,https://qupath.github.io,https://github.com/qupath/qupath/issues/456#issuecomment-619374801,2,"['Access', 'secur']","['AccessController', 'security']"
Security,.lib.gui.QuPathUncaughtExceptionHandler	/ by zero	java.lang.ArithmeticException: / by zero; 	at qupath.lib.gui.commands.PathObjectGridView$QuPathGridView.layoutChildren(PathObjectGridView.java:588); 	at javafx.scene.Parent.layout(Parent.java:1208); 	at javafx.scene.Parent.layout(Parent.java:1215); 	at javafx.scene.Parent.layout(Parent.java:1215); 	at javafx.scene.Parent.layout(Parent.java:1215); 	at javafx.scene.Parent.layout(Parent.java:1215); 	at javafx.scene.Scene.doLayoutPass(Scene.java:594); 	at javafx.scene.Scene$ScenePulseListener.pulse(Scene.java:2596); 	at com.sun.javafx.tk.Toolkit.lambda$runPulse$2(Toolkit.java:398); 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:399); 	at com.sun.javafx.tk.Toolkit.runPulse(Toolkit.java:397); 	at com.sun.javafx.tk.Toolkit.firePulse(Toolkit.java:427); 	at com.sun.javafx.tk.quantum.QuantumToolkit.pulse(QuantumToolkit.java:592); 	at com.sun.javafx.tk.quantum.PaintCollector.liveRepaintRenderJob(PaintCollector.java:327); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$ViewEventNotification.run(GlassViewEventHandler.java:889); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$ViewEventNotification.run(GlassViewEventHandler.java:849); 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:399); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleViewEvent$15(GlassViewEventHandler.java:931); 	at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:424); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleViewEvent(GlassViewEventHandler.java:930); 	at com.sun.glass.ui.View.handleViewEvent(View.java:535); 	at com.sun.glass.ui.View.notifyResize(View.java:875); 	at com.sun.glass.ui.win.WinView.notifyResize(WinView.java:91); 	at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); 	at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:185); 	at java.base/java.lang.Thread.run(Thread.java:840); ```,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1473:1903,secur,security,1903,https://qupath.github.io,https://github.com/qupath/qupath/issues/1473,3,"['Access', 'secur']","['AccessController', 'security']"
Security,".more stuff...]. Current thread (0x00007f594d8d5540): JavaThread ""tile-exporter10"" daemon [_thread_in_vm, id=314754, stack(0x00007f4ec1aaf000,0x00007f4ec1bb0000)]. Stack: [0x00007f4ec1aaf000,0x00007f4ec1bb0000], sp=0x00007f4ec1bac3d0, free space=1012k; Native frames: (J=compiled Java code, A=aot compiled Java code, j=interpreted, Vv=VM code, C=native code); C [libc.so.6+0x9a23b] __libc_malloc+0x12b. Java frames: (J=compiled Java code, j=interpreted, Vv=VM code); J 758 java.lang.ClassLoader.defineClass1(Ljava/lang/ClassLoader;Ljava/lang/String;[BIILjava/security/ProtectionDomain;Ljava/lang/String;)Ljava/lang/Class; java.base@16.0.2 (0 bytes) @ 0x00007f594243a6f0 [0x00007f594243a640+0x00000000000000b0]; J 754 c1 java.lang.ClassLoader.defineClass(Ljava/lang/String;[BIILjava/security/ProtectionDomain;)Ljava/lang/Class; java.base@16.0.2 (43 bytes) @ 0x00007f593b0f1dc4 [0x00007f593b0f1a80+0x0000000000000344]; J 939 c1 java.security.SecureClassLoader.defineClass(Ljava/lang/String;[BIILjava/security/CodeSource;)Ljava/lang/Class; java.base@16.0.2 (16 bytes) @ 0x00007f593b150c8c [0x00007f593b150bc0+0x00000000000000cc]; J 739 c1 jdk.internal.loader.BuiltinClassLoader.defineClass(Ljava/lang/String;Ljdk/internal/loader/Resource;)Ljava/lang/Class; java.base@16.0.2 (121 bytes) @ 0x00007f593b0e9acc [0x00007f593b0e8c20+0x0000000000000eac]; J 653 c1 jdk.internal.loader.BuiltinClassLoader.findClassOnClassPathOrNull(Ljava/lang/String;)Ljava/lang/Class; java.base@16.0.2 (64 bytes) @ 0x00007f593b0be434 [0x00007f593b0bd460+0x0000000000000fd4]; J 3884 c1 jdk.internal.loader.BuiltinClassLoader.loadClassOrNull(Ljava/lang/String;Z)Ljava/lang/Class; java.base@16.0.2 (143 bytes) @ 0x00007f593b6e8024 [0x00007f593b6e71c0+0x0000000000000e64]; J 632 c1 jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(Ljava/lang/String;Z)Ljava/lang/Class; java.base@16.0.2 (40 bytes) @ 0x00007f593b0b206c [0x00007f593b0b1a60+0x000000000000060c]; J 631 c1 java.lang.ClassLoader.loadClass(Ljava/lang/String;)Ljav",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/932#issuecomment-1057931302:1500,secur,security,1500,https://qupath.github.io,https://github.com/qupath/qupath/issues/932#issuecomment-1057931302,1,['secur'],['security']
Security,"0f4Y8BA4E5sVwzFhbDhm_alns-l7jx4c65825lN1brlaamgEFYOcr-bx0yB5-ONuFLKVRdD6nCGWcI1iPAsoohE7nnVhyPIYtURWpKQ/https%3A%2F%2Fgithub.com%2Fsuzeteguarda> you could try posting your question on the forum at https://forum.image.sc/tag/qupath<https://secure-web.cisco.com/13_E9lRMQxY8xtZmKYPnw2mmwaiElPiHzTIMUOwQH_-6FzgRz4LkCsf_cFjrfUWLwo9750a0MmRr_eXTVN0eusQkomn-qYLuoCcVIKhtD0lyGLisH8Fxc-WFZwGzOR3GcJ4WLvQ2nVTFF7JEFSGly69C9pq9zGxJ69U6IM5ck9ofp9vkUV14NNMWH0h1u9pMUi3qXwaLEHdnCfRaAU7pipTjdj7etnYxMl6fke2A03VF49uEY6P4XmHIM3ote076fSVZpQqVTzYq0orKjFBwoKIbptcmC4XxHSSCRt900YIULIVQAtzU62qtHv_TEqaLa9vgoz2qhsY9NbYDfMfFPtA/https%3A%2F%2Fforum.image.sc%2Ftag%2Fqupath>. The error is that there isn't enough memory, but without having the classifier and knowing how much memory you have, I can't really guess what could be responsible. (This topic is really about loading training data to create classifiers, not classifiers themselves, so I will hide these posts to avoid distraction). —; Reply to this email directly, view it on GitHub<https://secure-web.cisco.com/1S_KCvGqBkfLiU4jUNxk9Bycpt04YwO2EwOrgjo7gUjY2EmjAMNPYCK9KZ3g1BcPOjN1yFkyZLgJnmGWBrpfDiblAR5l3lwK7LfMcHNHJqtYoWGQYJ9WYQ6dCoewz0Xk9P5-ZDRFW4OknOTxChetxm4Bs7LEng-ebDLB6a6AAXrEy8mWNCALTRoJs81HHMcvnMhDSjonYiBRlurLnCnBJZ4a9YvcrT8TplefFlZKST3NVLHrWPL3RgIyoJsDosp8GVf6MH94rRAHuopZp9J5pOcqjQmwnlC51e34AFYd1-8yRTnj7X0qzcw7aHtnILPwFXQIqYdBTGMqf-iZSDUUexg/https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fissues%2F493%23issuecomment-1791280813>, or unsubscribe<https://secure-web.cisco.com/16fbsI3bTg2IXBtZ19rtjLXO9mTw2FP1PcVHSk2XFBBZjPYBQWKvTLiqsGr7UCwdHhDGRsg9tR1qzmQGBIyUICyyRtVvGvh-eu_HtL8Iyt807-ztz3U-i887buKPXzn2O2YTuhy7Xwb13QKvs-TXcflZ21x0cz69j7BIZd4l-aFk4r0Kw89JYQAASuY7o5O0vLb801LbUikLbLtblZgMPHiBe_SrbHoAccvQxrwkY0sMyvxdP_sq89PM0YloMPcUZfoeyvQt8mkLvXp5q2fymfiSTMaZDZDyzknBIzrUh60kAx4knbh5x28AHq2RAZ6YnA3Au7RGuJTZ8YYt7B4VE6g/https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FA5G6YB3KO5IO3F2PMFLETCDYCPOOXAVCNFSM4NF3XJJKU5DIOJSWCZC7NNSXTN2JONZXKZKDN5W",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/493#issuecomment-1791396738:2646,secur,secure-web,2646,https://qupath.github.io,https://github.com/qupath/qupath/issues/493#issuecomment-1791396738,1,['secur'],['secure-web']
Security,"1 2B 1E 00 64 37 CE D4 34 29 .&$2...+..d7..4(; ; }; },; ]; }; ]; }; ); javax.net.ssl|DEBUG|29|Thread-9|2020-04-13 21:28:52.416 NOVT|null:-1|Received alert message (; ""Alert"": {; ""level"" : ""fatal"",; ""description"": ""handshake_failure""; }; ); javax.net.ssl|ERROR|29|Thread-9|2020-04-13 21:28:52.417 NOVT|null:-1|Fatal (HANDSHAKE_FAILURE): Received fatal alert: handshake_failure (; ""throwable"" : {; javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure; 	at java.base/sun.security.ssl.Alert.createSSLException(Unknown Source); 	at java.base/sun.security.ssl.Alert.createSSLException(Unknown Source); 	at java.base/sun.security.ssl.TransportContext.fatal(Unknown Source); 	at java.base/sun.security.ssl.Alert$AlertConsumer.consume(Unknown Source); 	at java.base/sun.security.ssl.TransportContext.dispatch(Unknown Source); 	at java.base/sun.security.ssl.SSLTransport.decode(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.decode(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.readHandshakeRecord(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.startHandshake(Unknown Source); 	at java.base/sun.net.www.protocol.https.HttpsClient.afterConnect(Unknown Source); 	at java.base/sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream(Unknown Source); 	at java.base/sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(Unknown Source); 	at shaded.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.com.google.api.client.auth.oauth2.TokenRequest.executeUnparsed(TokenRequest.java:283); 	at shaded.com.google.api.client.auth.oauth2.TokenRequest.execute(TokenRequest.java:307); 	at shaded.com.google.api.client.auth",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/436:11968,secur,security,11968,https://qupath.github.io,https://github.com/qupath/qupath/issues/436,1,['secur'],['security']
Security,"4); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$MouseHandler.process(Scene.java:3856); at javafx.scene.Scene.processMouseEvent(Scene.java:1851); at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2584); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:409); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:299); at java.base/java.security.AccessController.doPrivileged(Unknown Source); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$2(GlassViewEventHandler.java:447); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:412); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:446); at com.sun.glass.ui.View.handleMouseEvent(View.java:556); at com.sun.glass.ui.View.notifyMouse(View.java:942); at com.sun.glass.ui.mac.MacView.notifyMouse(MacView.java:127); ```; The `Threshold` command works fine and seems to divide the annotation according to the slightly visible overlay, and so does the `Export map` command (so all good).; _________; ### If the value is >= 10; Clicking on `Find hotspot`, `Threshold` and `Export map` directly gives me the long open_cv error message copied above. It might be important to note that when the density radius value is switched back and forth between > and < 10, the density map overlay stops updating someti",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/776#issuecomment-872890572:4738,Access,AccessController,4738,https://qupath.github.io,https://github.com/qupath/qupath/issues/776#issuecomment-872890572,1,['Access'],['AccessController']
Security,"4); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$MouseHandler.process(Scene.java:3862); at javafx.scene.Scene.processMouseEvent(Scene.java:1849); at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2590); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:409); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:299); at java.base/java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$2(GlassViewEventHandler.java:447); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:412); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:446); at com.sun.glass.ui.View.handleMouseEvent(View.java:556); at com.sun.glass.ui.View.notifyMouse(View.java:942); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:174); at java.base/java.lang.Thread.run(Unknown Source). **Expected behavior**; In the past, I had no issues. I was able to use scripts and they were running succesfully. **Desktop (please complete the following information):**; - OS: [e.g. Windows 10]; - QuPath Version [e.g. 0.2.0(m4 or m5)]. **Additional context**; I closed and re-started QuPath. The error remains. I went from m4 to m5, still the same. ; ",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/373:4048,Access,AccessController,4048,https://qupath.github.io,https://github.com/qupath/qupath/issues/373,1,['Access'],['AccessController']
Security,4); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$MouseHandler.process(Scene.java:3897); at javafx.scene.Scene.processMouseEvent(Scene.java:1878); at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2623); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:411); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:301); at java.base/java.security.AccessController.doPrivileged(Unknown Source); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$2(GlassViewEventHandler.java:450); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:424); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:449); at com.sun.glass.ui.View.handleMouseEvent(View.java:557); at com.sun.glass.ui.View.notifyMouse(View.java:943); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:184); at java.base/java.lang.Thread.run(Unknown Source); Caused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: OpenCV(4.5.3) D:\a\javacpp-presets\javacpp-presets\opencv\cppbuild\windows-x86_64\opencv-4.5.3\modules\core\src\channels.cpp:141: error: (-215:Assertion failed) i1 >= 0 && j < ndsts && dst[j].depth() == depth in function 'cv::mixChannels'. at java.base/java.util.concurren,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/947:9079,Access,AccessController,9079,https://qupath.github.io,https://github.com/qupath/qupath/issues/947,1,['Access'],['AccessController']
Security,"5B 3C CC 87 59 84 CF 96 68 5....r.[<..Y...h; 00A0: 6B D5 81 4C 74 B9 A7 91 98 49 0B 12 3F 8C E1 52 k..Lt....I..?..R; 00B0: E3 B3 53 B9 78 ED 29 56 82 E3 13 31 16 C0 6A A7 ..S.x.)V...1..j.; 00C0: F8 5A 8F FE 94 77 14 0A 22 0D 51 66 A1 55 BD 6B .Z......"".Qf...k; 00D0: D9 2E 4A 4F 9B 78 15 9B 53 1D 03 91 48 A0 92 D2 ..JO.x..S...H...; 00E0: 0A 26 24 32 18 15 C1 2B 1E 00 64 37 CE D4 34 29 .&$2...+..d7..4(; ; }; },; ]; }; ]; }; ); javax.net.ssl|DEBUG|29|Thread-9|2020-04-13 21:28:52.416 NOVT|null:-1|Received alert message (; ""Alert"": {; ""level"" : ""fatal"",; ""description"": ""handshake_failure""; }; ); javax.net.ssl|ERROR|29|Thread-9|2020-04-13 21:28:52.417 NOVT|null:-1|Fatal (HANDSHAKE_FAILURE): Received fatal alert: handshake_failure (; ""throwable"" : {; javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure; 	at java.base/sun.security.ssl.Alert.createSSLException(Unknown Source); 	at java.base/sun.security.ssl.Alert.createSSLException(Unknown Source); 	at java.base/sun.security.ssl.TransportContext.fatal(Unknown Source); 	at java.base/sun.security.ssl.Alert$AlertConsumer.consume(Unknown Source); 	at java.base/sun.security.ssl.TransportContext.dispatch(Unknown Source); 	at java.base/sun.security.ssl.SSLTransport.decode(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.decode(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.readHandshakeRecord(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.startHandshake(Unknown Source); 	at java.base/sun.net.www.protocol.https.HttpsClient.afterConnect(Unknown Source); 	at java.base/sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream(Unknown Source); 	at java.base/sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(Unknown Source); 	at shaded.com.google.api.client.http.java",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/436:11610,secur,security,11610,https://qupath.github.io,https://github.com/qupath/qupath/issues/436,1,['secur'],['security']
Security,"82 E3 13 31 16 C0 6A A7 ..S.x.)V...1..j.; 00C0: F8 5A 8F FE 94 77 14 0A 22 0D 51 66 A1 55 BD 6B .Z......"".Qf...k; 00D0: D9 2E 4A 4F 9B 78 15 9B 53 1D 03 91 48 A0 92 D2 ..JO.x..S...H...; 00E0: 0A 26 24 32 18 15 C1 2B 1E 00 64 37 CE D4 34 29 .&$2...+..d7..4(; ; }; },; ]; }; ]; }; ); javax.net.ssl|DEBUG|29|Thread-9|2020-04-13 21:28:52.416 NOVT|null:-1|Received alert message (; ""Alert"": {; ""level"" : ""fatal"",; ""description"": ""handshake_failure""; }; ); javax.net.ssl|ERROR|29|Thread-9|2020-04-13 21:28:52.417 NOVT|null:-1|Fatal (HANDSHAKE_FAILURE): Received fatal alert: handshake_failure (; ""throwable"" : {; javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure; 	at java.base/sun.security.ssl.Alert.createSSLException(Unknown Source); 	at java.base/sun.security.ssl.Alert.createSSLException(Unknown Source); 	at java.base/sun.security.ssl.TransportContext.fatal(Unknown Source); 	at java.base/sun.security.ssl.Alert$AlertConsumer.consume(Unknown Source); 	at java.base/sun.security.ssl.TransportContext.dispatch(Unknown Source); 	at java.base/sun.security.ssl.SSLTransport.decode(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.decode(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.readHandshakeRecord(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.startHandshake(Unknown Source); 	at java.base/sun.net.www.protocol.https.HttpsClient.afterConnect(Unknown Source); 	at java.base/sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream(Unknown Source); 	at java.base/sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(Unknown Source); 	at shaded.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.com",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/436:11757,secur,security,11757,https://qupath.github.io,https://github.com/qupath/qupath/issues/436,1,['secur'],['security']
Security,":; # C [libc.so.6+0x9a23b] __libc_malloc+0x12b. [...more stuff...]. Current thread (0x00007f594d8d5540): JavaThread ""tile-exporter10"" daemon [_thread_in_vm, id=314754, stack(0x00007f4ec1aaf000,0x00007f4ec1bb0000)]. Stack: [0x00007f4ec1aaf000,0x00007f4ec1bb0000], sp=0x00007f4ec1bac3d0, free space=1012k; Native frames: (J=compiled Java code, A=aot compiled Java code, j=interpreted, Vv=VM code, C=native code); C [libc.so.6+0x9a23b] __libc_malloc+0x12b. Java frames: (J=compiled Java code, j=interpreted, Vv=VM code); J 758 java.lang.ClassLoader.defineClass1(Ljava/lang/ClassLoader;Ljava/lang/String;[BIILjava/security/ProtectionDomain;Ljava/lang/String;)Ljava/lang/Class; java.base@16.0.2 (0 bytes) @ 0x00007f594243a6f0 [0x00007f594243a640+0x00000000000000b0]; J 754 c1 java.lang.ClassLoader.defineClass(Ljava/lang/String;[BIILjava/security/ProtectionDomain;)Ljava/lang/Class; java.base@16.0.2 (43 bytes) @ 0x00007f593b0f1dc4 [0x00007f593b0f1a80+0x0000000000000344]; J 939 c1 java.security.SecureClassLoader.defineClass(Ljava/lang/String;[BIILjava/security/CodeSource;)Ljava/lang/Class; java.base@16.0.2 (16 bytes) @ 0x00007f593b150c8c [0x00007f593b150bc0+0x00000000000000cc]; J 739 c1 jdk.internal.loader.BuiltinClassLoader.defineClass(Ljava/lang/String;Ljdk/internal/loader/Resource;)Ljava/lang/Class; java.base@16.0.2 (121 bytes) @ 0x00007f593b0e9acc [0x00007f593b0e8c20+0x0000000000000eac]; J 653 c1 jdk.internal.loader.BuiltinClassLoader.findClassOnClassPathOrNull(Ljava/lang/String;)Ljava/lang/Class; java.base@16.0.2 (64 bytes) @ 0x00007f593b0be434 [0x00007f593b0bd460+0x0000000000000fd4]; J 3884 c1 jdk.internal.loader.BuiltinClassLoader.loadClassOrNull(Ljava/lang/String;Z)Ljava/lang/Class; java.base@16.0.2 (143 bytes) @ 0x00007f593b6e8024 [0x00007f593b6e71c0+0x0000000000000e64]; J 632 c1 jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(Ljava/lang/String;Z)Ljava/lang/Class; java.base@16.0.2 (40 bytes) @ 0x00007f593b0b206c [0x00007f593b0b1a60+0x000000000000060c]; J 631 c1 java",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/932#issuecomment-1057931302:1442,Secur,SecureClassLoader,1442,https://qupath.github.io,https://github.com/qupath/qupath/issues/932#issuecomment-1057931302,1,['Secur'],['SecureClassLoader']
Security,"; ```; qupath.lib.images.servers.bioformats.BioFormatsImageServer$ReaderPool.openImage(Lqupath/lib/images/servers/TileRequest;IIZLjava/awt/image/ColorModel;)Ljava/awt/image/BufferedImage;+249; ```; which is definitely a new line connected with how tiles are paralleled in QuPath's Bio-Formats reading since v0.3.1. However, the bigger context is very mysterious:; ```; # Problematic frame:; # C [libc.so.6+0x9a23b] __libc_malloc+0x12b. [...more stuff...]. Current thread (0x00007f594d8d5540): JavaThread ""tile-exporter10"" daemon [_thread_in_vm, id=314754, stack(0x00007f4ec1aaf000,0x00007f4ec1bb0000)]. Stack: [0x00007f4ec1aaf000,0x00007f4ec1bb0000], sp=0x00007f4ec1bac3d0, free space=1012k; Native frames: (J=compiled Java code, A=aot compiled Java code, j=interpreted, Vv=VM code, C=native code); C [libc.so.6+0x9a23b] __libc_malloc+0x12b. Java frames: (J=compiled Java code, j=interpreted, Vv=VM code); J 758 java.lang.ClassLoader.defineClass1(Ljava/lang/ClassLoader;Ljava/lang/String;[BIILjava/security/ProtectionDomain;Ljava/lang/String;)Ljava/lang/Class; java.base@16.0.2 (0 bytes) @ 0x00007f594243a6f0 [0x00007f594243a640+0x00000000000000b0]; J 754 c1 java.lang.ClassLoader.defineClass(Ljava/lang/String;[BIILjava/security/ProtectionDomain;)Ljava/lang/Class; java.base@16.0.2 (43 bytes) @ 0x00007f593b0f1dc4 [0x00007f593b0f1a80+0x0000000000000344]; J 939 c1 java.security.SecureClassLoader.defineClass(Ljava/lang/String;[BIILjava/security/CodeSource;)Ljava/lang/Class; java.base@16.0.2 (16 bytes) @ 0x00007f593b150c8c [0x00007f593b150bc0+0x00000000000000cc]; J 739 c1 jdk.internal.loader.BuiltinClassLoader.defineClass(Ljava/lang/String;Ljdk/internal/loader/Resource;)Ljava/lang/Class; java.base@16.0.2 (121 bytes) @ 0x00007f593b0e9acc [0x00007f593b0e8c20+0x0000000000000eac]; J 653 c1 jdk.internal.loader.BuiltinClassLoader.findClassOnClassPathOrNull(Ljava/lang/String;)Ljava/lang/Class; java.base@16.0.2 (64 bytes) @ 0x00007f593b0be434 [0x00007f593b0bd460+0x0000000000000fd4]; J 3884 c1 jdk.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/932#issuecomment-1057931302:1061,secur,security,1061,https://qupath.github.io,https://github.com/qupath/qupath/issues/932#issuecomment-1057931302,1,['secur'],['security']
Security,"; at javafx.base/javafx.collections.WeakListChangeListener.onChanged(Unknown Source); at javafx.base/com.sun.javafx.collections.ListListenerHelper$Generic.fireValueChangedEvent(Unknown Source); at javafx.base/com.sun.javafx.collections.ListListenerHelper.fireValueChangedEvent(Unknown Source); at javafx.base/javafx.collections.ObservableListBase.fireChange(Unknown Source); at javafx.base/javafx.collections.ListChangeBuilder.commit(Unknown Source); at javafx.base/javafx.collections.ListChangeBuilder.endChange(Unknown Source); at javafx.base/javafx.collections.ObservableListBase.endChange(Unknown Source); at javafx.base/javafx.collections.ModifiableObservableListBase.setAll(Unknown Source); at qupath.lib.gui.panes.AnnotationPane.hierarchyChanged(AnnotationPane.java:382); at qupath.lib.gui.panes.AnnotationPane.lambda$hierarchyChanged$7(AnnotationPane.java:352); at javafx.graphics/com.sun.javafx.application.PlatformImpl.lambda$runLater$10(Unknown Source); at java.base/java.security.AccessController.doPrivileged(Unknown Source); at javafx.graphics/com.sun.javafx.application.PlatformImpl.lambda$runLater$11(Unknown Source); at javafx.graphics/com.sun.glass.ui.InvokeLaterDispatcher$Future.run(Unknown Source); at javafx.graphics/com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at javafx.graphics/com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(Unknown Source); at java.base/java.lang.Thread.run(Unknown Source); ```; I am at a loss. The script never seems to actual fail, despite the errors. No objects end up missing, the measurements are created in the correct cells. Sometimes it will run 7 times in a row. Sometimes it will fail 3 times in a row with the same error.; The region itself is small and shouldn’t cause any problems for my computer.; image; Just the upper left corner of the LuCa FoV image. I have tried adding fireHierarchyUpdates() everywhere I can think or, and tried Thread.sleep(1000) along with setting the number of CPU cores to 1, as well, with no c",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/744:7009,Access,AccessController,7009,https://qupath.github.io,https://github.com/qupath/qupath/issues/744,1,['Access'],['AccessController']
Security,"================================================; [ERROR PART]; def text = new File(xml_file).getText(); def list = new XmlSlurper().parseText(text). [ERROR]; ERROR: Script error; at org.codehaus.groovy.runtime.ScriptBytecodeAdapter.unwrap(ScriptBytecodeAdapter.java:53); at org.codehaus.groovy.runtime.callsite.PogoGetPropertySite.getProperty(PogoGetPropertySite.java:52); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callGroovyObjectGetProperty(AbstractCallSite.java:307); at Script4.run(Script4.groovy:33); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ERROR: Error: startup failed:; Script5.groovy: 30: unable to resolve class XmlSlurper ; @ line 30, column 12.; def list = new XmlSlurper().parseText(text); ^. 1 error; ==================================================================. My question is how can I use that class in Windows.. At Mac, It worked fine after I copied 'groovy-xml-2.5.2.jar' into extensions folder. However, the structure of Qupath at windows is quite different from Mac. And I have no idea where to put 'groovy-xml-2.5.2.jar'. Thanks!!!",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/238:1356,access,access,1356,https://qupath.github.io,https://github.com/qupath/qupath/issues/238,1,['access'],['access']
Security,"> > Can I ask how did you edited cfg file in terminal?; > ; > First, locate `.cfg` file. On a Mac, you’ll need to right-click on QuPath.app and choose Show package contents. The config file is inside the Contents/app directory. Open the terminal, type ` sudo nano pathtoqupath/QuPath-0.2.3.cfg`. Enter password and edit this line at the end: `java-options=-XX:MaxRAMPercentage=50`. In my case I set it to 85 instead of 50 % of available RAM. That's great. It worked! Thanks so much :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/490#issuecomment-1431663502:302,password,password,302,https://qupath.github.io,https://github.com/qupath/qupath/issues/490#issuecomment-1431663502,1,['password'],['password']
Security,"> > When does the `getAssociatedImage(String)` function of `qupath.lib.images.servers.ImageServer` is used? I don't think I was able to test it; > ; > It is used with _View → Show slide label_ - but is really only relevant for some file formats (although useful when relevant).; > ; > It's inspired by the 'associated images' provided by [OpenSlide here](https://openslide.org/api/python/#openslide.OpenSlide.associated_images) - since otherwise QuPath would have had no way to provide access to the label etc. But it doesn't map so easily to images from other readers, including Bio-Formats, which doesn't identify label images as being different. Do you know a way to test it? This *Show slide label* window always indicates ""No label available"" with the images I have. Apart from that, I think this pull request can be merged. The bio-format and omero ice image servers seem to be working with these new changes. I may still have to clean the code a bit but I think having the OMERO extension working properly is more important for now.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1287#issuecomment-1706263104:486,access,access,486,https://qupath.github.io,https://github.com/qupath/qupath/pull/1287#issuecomment-1706263104,1,['access'],['access']
Security,"> About the rest, am I correct if a recap of what you ask is:; > * Metadata parsing is fragmented between `BioFormatsImageServer` and `OMEReaderWrapper` / `OMETileReader`. This should not happen. Metadata should be requested only once and not lazily. Yes. See https://downloads.openmicroscopy.org/images/Vectra-QPTIFF/perkinelmer/PKI_fields/ and `HnE_3_1x1component_data.tif` for an example where it is a problem. This contains a 32-bit float image, along with an 8-bit thumbnail. If I try to open the thumbnail with this PR it fails, I believe because it is using a mixture of metadata (i.e. assuming that it has enough bytes for 32-bit data, and failing with an `ArrayIndexOutOfBoundsException`. > * One tile reader should support accessing only one `series`. Possibly - it is one option to overcome the issue. Currently, the implementation of `BioFormatsReaderWrapper` in this PR has two `getPixelValues()` methods. One of them sets the series and then resets it back to its original value, the other sets it but doesn't reset it. Without the reset, then the reader has changed into a different state - and the values returned by any call that requests metadata from the reader are subject to giving different results *(example at the end of this post)*. Additionally, both methods are potentially broken in a multithreading context because there is no synchronization done on the reader. . Excessive synchronization could harm performance. Forbidding the series and ID to be changed anywhere inside the class - *and* forbidding the reader from being accessed outside (i.e. not providing a `getReader()` option) - would reduce the need for synchronization, but probably not eliminate it because I am not sure that Bio-Formats guarantees that pixels can be accessed simultaneously from different threads even if the series and ID aren't changed. The alternative is to synchronize everything that uses the reader, and then taking care to design the class in such a way that it's not possible to get a",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1287#issuecomment-1714232547:733,access,accessing,733,https://qupath.github.io,https://github.com/qupath/qupath/pull/1287#issuecomment-1714232547,1,['access'],['accessing']
Security,"> Another weird behaviour (not sure if this is intended) of the new version: if I drag an drop fluorescent images (.scn or .vsi) (not tried with chromogenic) to qupath without having pre-created a project, it only opens the label/macro image without letting me access to higher resolution images.... There's an explanation [here](https://forum.image.sc/t/third-milestone-on-the-path-to-qupath-v0-2-0/27953/7). > Yes forcing doesn't really change anything. Something odd going on... I eventually manage to open things and create a project to work on but sometimes it requires several attempts of closing the software and opening it again.. bit random.; I've tried the same files on 0.2.0 m2 and m3. This happens only in m3. I might have seen similar behavior some weeks ago, but rarely and it hasn't reappeared for me so that I thought it was resolved. Basically, QuPath wasn't using Bio-Formats when it should have been... sometimes. I haven't managed to find a way to reproduce it, but will keep looking. In m3, the type of the ImageServer is stored in the project to ensure that the same one is used again in the future (i.e. not OpenSlide once, then Bio-Formats the next time). Therefore if it fails to get the right type the first time, the image won't open the next time either. > Regarding the projects, would it not be possible for QuPath to create some sort of temporary project automatically when it requires it? which would be deleted if the image gets closed. I think this has the potential to make things more confusing... in this case, I think a better solution is to present a dialog enabling the image to be selected whenever multiple images are in the same file _and_ a project is not being used (like when the Bio-Formats plugin is used with Fiji). But implementing this takes time I don't currently have.... and I'd rather encourage people to use projects anyway in general (although of course these need to work...).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/348#issuecomment-518120494:261,access,access,261,https://qupath.github.io,https://github.com/qupath/qupath/issues/348#issuecomment-518120494,1,['access'],['access']
Security,"> But does the Macro image show anything? Or is it there?. Thanks. I can indeed see it under the Image tab under ""Series 1 (label)"" (I did not know about this). But access from the pull down menu and label pop-up viewer is not working, which remains an issue.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/643#issuecomment-731459267:165,access,access,165,https://qupath.github.io,https://github.com/qupath/qupath/issues/643#issuecomment-731459267,1,['access'],['access']
Security,"> Can I ask how did you edited cfg file in terminal?. First, locate `.cfg` file. On a Mac, you’ll need to right-click on QuPath.app and choose Show package contents.; The config file is inside the Contents/app directory.; Open the terminal, type ` sudo nano pathtoqupath/QuPath-0.2.3.cfg`. Enter password and edit this line at the end:; `java-options=-XX:MaxRAMPercentage=50`. In my case I set it to 85 instead of 50 % of available RAM.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/490#issuecomment-1430091897:296,password,password,296,https://qupath.github.io,https://github.com/qupath/qupath/issues/490#issuecomment-1430091897,1,['password'],['password']
Security,"> However, based on the exception, I think the problem is that the [names ArrayList of the AbstractNumericMeasurementList class](https://github.com/qupath/qupath/blob/13bdeed047b4d05f35f47308b36b48c0f2bb3a24/qupath-core/src/main/java/qupath/lib/measurements/NumericMeasurementList.java#L102) is accessed from multiple threads without synchronization. Using a CopyOnWriteArrayList instead of an ArrayList may solve this issue. I think the list shouldn't be directly accessed elsewhere, and the `put` method (which calles `list.add`) is synchronized. Maybe the issue is that the `clear()` method isn't synchronized?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1444#issuecomment-1936207910:295,access,accessed,295,https://qupath.github.io,https://github.com/qupath/qupath/issues/1444#issuecomment-1936207910,2,['access'],['accessed']
Security,"> I can ask them to share a QuPath project if it's useful to you. That would be useful because I was not able to replicate the issue (on MacOS, I will try on Linux later). However, based on the exception, I think the problem is that the [names ArrayList of the AbstractNumericMeasurementList class](https://github.com/qupath/qupath/blob/13bdeed047b4d05f35f47308b36b48c0f2bb3a24/qupath-core/src/main/java/qupath/lib/measurements/NumericMeasurementList.java#L102) is accessed from multiple threads without synchronization. Using a `CopyOnWriteArrayList` instead of an `ArrayList` may solve this issue.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1444#issuecomment-1936164001:465,access,accessed,465,https://qupath.github.io,https://github.com/qupath/qupath/issues/1444#issuecomment-1936164001,1,['access'],['accessed']
Security,"> I can't replicate the bug on my Mac - if I drag a URL from chrome, the dragboard contains both a URL and a String - but good if it solves the problem somewhere. Yeah I suspect it's a Linux issue, either way I think trying to handle Strings as URLs is about the best we can do, as long as it shows the right kind of error. > *-I've consistently avoided [starred imports] & convinced my IntelliJ to stop doing it automatically - can discuss later if we want to change that policy. I don't pay any heed to imports; they're automatically hidden for me. The only strong argument I've been exposed to on the topic was that having a) a license and b) every imported class/static method right at the top of the file means that every file you open, you need to page down a couple of times before reading any code. If there was a risk of ambiguity I might be more concerned, but I think when there's a collision Java forces you to use a fully qualified name?. Anyways I think the license and imports are auto-hidden for me, so this doesn't really matter",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1338#issuecomment-1731105750:586,expose,exposed,586,https://qupath.github.io,https://github.com/qupath/qupath/pull/1338#issuecomment-1731105750,1,['expose'],['exposed']
Security,> I have access to the first user files. I don't understand which files. I couldn't see which screenshot in the PDF demonstrated there was a problem.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1108#issuecomment-1309256243:9,access,access,9,https://qupath.github.io,https://github.com/qupath/qupath/issues/1108#issuecomment-1309256243,1,['access'],['access']
Security,"> I'm apprehensive about trying to make the code too clever, and confusing people more by the menu changing when they click it. Yeah that makes sense! Maybe context sensitive isn't the way to go. Thank you for considering it though! :). > If the core issue is that the common things are too hard to access, would simply moving Show/hide higher up the menu be a solution?. This could definitely work as well. I would be super happy to have a one menu access for ""Add/Remove"", in the same vibe as ""Estimate stain vectors"" was given its own high-leven location instead of a submenu.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1644#issuecomment-2406685530:299,access,access,299,https://qupath.github.io,https://github.com/qupath/qupath/issues/1644#issuecomment-2406685530,2,['access'],['access']
Security,"> It is a slightly scary change to make since it is so core. Yes, i get it. It's better being cautious here!. > When ImageServer metadata is written in a project and when it isn't (I see it missing sometimes, which has previously been irrelevant since it's generated when the ImageServer is built... but becomes much more important if the server isn't necessarily built). what I would say that in that case it would load the server, read the metadata and write them in the `.qpproj` file for future accesses. I wouldn't assure that `ImageData.getServerMetadata()` never loads the image server. It avoids it as long as it is possible, otherwise it will. > What happens when a script changes the metadata, but the server itself hasn't been read (e.g. setting channel names or pixel size). Again, if `ImageData.updateServerMetadata()` i would actually load the server()+update `qpproj` file. Avoid doing it lazily, as that would easily lead to unexpected states for the users. > How exceptions are handled when lazy loading fails. What's wrong in behaving the same as when an exception occurs while creating an `ImageServer`?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1489#issuecomment-2271091629:499,access,accesses,499,https://qupath.github.io,https://github.com/qupath/qupath/pull/1489#issuecomment-2271091629,1,['access'],['accesses']
Security,"> Okay, I think I describe what I want to do. And I would like to do that as automatically as possible, so in qupath in a .groovy script, I guess:; > ; > I have a folder with IHC-fluorescence images (DAPI + antibody staining) of tumors with stroma; > In Qupath:; > For every image of the folder:; > 2) In QuPath - perform cell detection; > 3) In Qupath - object classification with a pretrained classifier (tumor vs. stroma); > 4) Export detections with annotation into .roi file. Ok, you don't describe your images being whole slide images - so I assume they can be read into ImageJ fully and without problems. In that case, you might try this QuPath script:; https://gist.github.com/petebankhead/8d541effc8898d6a07edd4ed95b6929c. Keep in mind that a `.roi` file contains a single region; as far as I'm aware, a `.zip` file is needed for all the QuPath objects to be represented in a way ImageJ can access all in one go. > So, I want to use quPath for what it does very, very good and fast, cell identification, segmentation and classification, and not for anything else. Scripting in FIJI is more or less easy for me, so once I have the .roi files, I can do almost anything with them there. Just, for the ""QuPath part"", I dont even know how to script those simple steps, because there is not much documentation, no Qupath API, so its hard for me to even get started. I am not a professional programmer, but a biologist with some (Python, Java, ImageJ) programming background,. Ok, but please keep in mind that ImageJ has existed in some form for more than 30 years, and has had input from many fantastically knowledgeable people both in terms of development and documentation. There has been a huge amount of volunteer effort, alongside many components and plugins developed as part of larger, funded projects. On the other hand, QuPath was created and documented essentially by one person and has only been available for a couple of years. The same person also wrote all the wiki, the [blog](https:",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/182#issuecomment-401546472:900,access,access,900,https://qupath.github.io,https://github.com/qupath/qupath/issues/182#issuecomment-401546472,1,['access'],['access']
Security,"> One option for Show/Hide would be to have the right click menu be context sensitive:; > ; > * If one or multiple classifications are selected and visible, the context menu becomes ""Hide selected classes"" (Instead of show/Hide > Hide classes in viewer); > * If one or multiple classifications are selected and hidden, the context menu becomes ""Show selected classes"" (Instead of show/Hide > Show classes in viewer). What about if multiple classifications are selected, some shown and some hidden?. I'm apprehensive about trying to make the code too clever, and confusing people more by the menu changing when they click it. If the core issue is that the common things are too hard to access, would simply moving `Show/hide` higher up the menu be a solution?. My hesitation with that is that currently the top part of the menu (above the divider) is all concerned with adding/removing classifications. So `Show/Hide` would have to go to the *very* top, to avoid interrupting this logical grouping... and, as you say, spacebar does that job, so `Add/Remove` might be needed more often.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1644#issuecomment-2358972679:685,access,access,685,https://qupath.github.io,https://github.com/qupath/qupath/issues/1644#issuecomment-2358972679,1,['access'],['access']
Security,"> So solving this will likely require any any info you can get from VisualVM's CPU sampling. Since I wasn't sure which outputs to provide you with from VisualVM, I made a quick recording of the profiling as it ran while QuPath was loading the project: https://youtu.be/_GHn556qEAk. I wasn't able to get the profiler to work, despite installing a 64 bit version of Java 17, but the sampler and all other tools seemed to work. I've uploaded the thread and heap dumps to: https://drive.google.com/drive/folders/1akRolrnUwbryc3YMSRR_aXhJ5H6AgBWO?usp=sharing. > QuPath shouldn't be regenerating thumbnails when a project is opened, and it shouldn't be remembering anything (other than the preferences) across relaunches.; v0.4.0 should generating missing thumbnails only, and do so in a background thread that doesn't block. Both v0.3 and v0.4 will try to access the thumbnail images in the project when it is opened; this could potentially block the UI, because it needs to be done in the UI thread (and there can only be one). However these should generally be small JPEGs so I've never known that to be a problem. Therefore I'd only expect this to be troublesome if there is some other reason why access to the disk is exceptionally slow. Based on my limited interpretation of the VisualVM results, I'd say that you're right. The lowest-level QuPath method I could find which was responsible for the ~4 minute load time is `qupath.lib.io.UriUpdater$SingleUriItem.getStatus()` which invokes `java.nio.file.File.exists()`. ![image](https://user-images.githubusercontent.com/52012166/203870112-0ecd0822-7efd-4360-af2e-0858b8a03df7.png). My guess is that there is some kind of checking going on, comparing the URI listed in the project, with the file path, to verify that each project entry is pointing to the correct image, and that's what's taking up CPU time. > I couldn't really tell what was going on in the video, partly because the analysis pane was closed - and when the image was opened I couldn't ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1154#issuecomment-1326872166:851,access,access,851,https://qupath.github.io,https://github.com/qupath/qupath/issues/1154#issuecomment-1326872166,1,['access'],['access']
Security,"> Synchronizing getNameMap() might fix it?. I think **all** access to `names` should be synchronized. If it's not the case, lines 207 and 241 could be executed at the same time for example. But this may drops the performances of the class. I will read more about concurrency in Java to exactly know what to do in such situations. Switching to `CopyOnWriteArrayList` is not necessary if all access are synchronized.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1444#issuecomment-1936371496:60,access,access,60,https://qupath.github.io,https://github.com/qupath/qupath/issues/1444#issuecomment-1936371496,2,['access'],['access']
Security,"> That is a very large classifier. Do you get the same error with both ANN and Decision Trees? When removing one scale?. Yep, I get the same error for both ANN and Decision Trees. When I drop scales until one succeeds, the other succeeds also. >Is there any chance you can replicate the problem with a more manageable/minimal dataset - preferably of publicly-accessible images?. Understandable; I'm working on creating a dataset from images that be publicly available regardless at the I2K conference. Will post a link shortly.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/947#issuecomment-1092033821:359,access,accessible,359,https://qupath.github.io,https://github.com/qupath/qupath/issues/947#issuecomment-1092033821,1,['access'],['accessible']
Security,"> When does the `getAssociatedImage(String)` function of `qupath.lib.images.servers.ImageServer` is used? I don't think I was able to test it. It is used with *View &rarr; Show slide label* - but is really only relevant for some file formats (although useful when relevant). It's inspired by the 'associated images' provided by [OpenSlide here](https://openslide.org/api/python/#openslide.OpenSlide.associated_images) - since otherwise QuPath would have had no way to provide access to the label etc. But it doesn't map so easily to images from other readers, including Bio-Formats, which doesn't identify label images as being different.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1287#issuecomment-1691948394:476,access,access,476,https://qupath.github.io,https://github.com/qupath/qupath/pull/1287#issuecomment-1691948394,1,['access'],['access']
Security,"> the same first user credentials were used to install both QuPath's. I guess maybe that's the issue. . QuPath is using Java's `Preferences` class: https://docs.oracle.com/en/java/javase/11/docs/api/java.prefs/java/util/prefs/Preferences.html. Specifically, it's going through `Preferences.userRoot()`, which according to Java's docs should be *'the root preference node for the calling user'*: https://github.com/qupath/qupath/blob/main/qupath-gui-fx/src/main/java/qupath/lib/gui/prefs/PathPrefs.java#L475. I think the Cellpose extension is doing the same. I've no idea what miniconda does, or if it's relevant here. I'm not sure what happens when the credentials used for installation are different from those used to run the software - but providing an .exe in addition to an .msi is intended to help in scenarios when one isn't suitable (usually a lack of admin access for installation). Based on all that, do you still think QuPath should be doing something differently?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1108#issuecomment-1302330711:866,access,access,866,https://qupath.github.io,https://github.com/qupath/qupath/issues/1108#issuecomment-1302330711,1,['access'],['access']
Security,"> try accessing the images some other way before opening them in QuPath (e.g. through Windows Explorer), in case 'pre-warning' the OS is somehow useful. I think this is it! I opened the folder containing the images in explorer, and set the thumbnail size to ""large icons"" via `view > large icons`. This would generate thumbnails for all files that are currently displayed on screen. After those were generated, I scrolled down, so that the remaining files would also have their thumbnails generated. Then, I launched the QuPath project in 0.4.1, and the load time was nearly instantaneous. Which, while resolving the issue, also means that the issue exists outside of QuPath. So, for some reason, the thumbnail previews are lost after a period of time, and don't seem to coincide with closing the folder or restarting the computer. The first thing I attempted to preserve thumbnails was to ensure ""Always show icons, never thumbnails"" in the folder options was unchecked, however it already was by default:; ![image](https://user-images.githubusercontent.com/52012166/211071879-ac70ef62-925f-4fe5-8ec3-10763d391393.png); Toggling this field didn't seem to have any impact on project loading performance, since in either case, the thumbnails were already generated (just replaced with an icon if the box is checked).; Next, under Windows performance options, I noticed ""save taskbar thumbnail previews"" was unchecked by default. I've checked it, and so far, I don't seem to have trouble loading projects that already have thumbnails generated in explorer. ; ![image](https://user-images.githubusercontent.com/52012166/211072664-c211658b-7aa6-435d-8067-830b4e1620b1.png). I'll continue to test other projects and rebooting my computer, to confirm if this has resolved the issue. TL;DR: **Check ""save taskbar thumbnail previews"" under Windows performance options. Subsequent loads of the project should now be much faster**. EDIT: So far, this fix persists after rebooting the system. EDIT 2: I've opened",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1154#issuecomment-1373971580:6,access,accessing,6,https://qupath.github.io,https://github.com/qupath/qupath/issues/1154#issuecomment-1373971580,1,['access'],['accessing']
Security,"@mezwick Hashes aren't currently generated or made available. Making a release remains a fairly laborious and manual process. Although the builds themselves are now generated automatically using GitHub Actions, I have to download and check these run on each platform and then upload again. And write all the release notes, tag the version etc. There can also be some extra renaming required, since `jpackage` (used for the build) has some awkwardness connected to artefact naming and 0.x.x versions that affects some platforms but not others (e.g. I think macOS forbids 0.x.x versions, so this needs worked around; also, it needs to be possible for people to have multiple versions installed for reproducibility). It's already a real pain to do, and I don't want to add any more manual steps if I can avoid it. It would be strongly preferable to automate the whole process a bit more, using [Upload to Release](https://github.com/marketplace/actions/upload-to-release) to avoid the download/upload requirement, and somehow include hashes (e.g. using the links from @KrisJanssen's last post) at that point. This seems to me at least a bit awkward to set up though, since the upload action is only triggered when a release is made. The [build workflow](https://github.com/qupath/qupath/blob/v0.3.2/.github/workflows/jpackage.yml) would have to be quite a bit more complex (e.g. to handle cross-platform filenames/content types for the builds, as well as different artefact compression methods). I'd also still need to retain the ability to check the release manually on each platform *before* the release itself is created, because creating the release is what triggers any update notifications... and after the release has been tagged is a bad time to identify some platform-specific breakage. These tend to happen with every release, e.g. because some dialog ends up misbehaving on Ubuntu but looks fine everywhere else. I strongly suspect I'd mess it up quite a few times before (hopefully) getting i",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1027#issuecomment-1208071371:9,Hash,Hashes,9,https://qupath.github.io,https://github.com/qupath/qupath/issues/1027#issuecomment-1208071371,2,"['Hash', 'hash']","['Hashes', 'hashes']"
Security,"@petebankhead : I can certainly understand you need to carefully balance workload. As our organization is somewhat rigorous regarding this topic I have looked into things further and it seems you mercifully use an accessible installer solution and as such I have been able to build it from source in full. This way, we can perform static code review and use an internally built binary, currently removing the need to obtain the hash from you.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1027#issuecomment-1208463614:214,access,accessible,214,https://qupath.github.io,https://github.com/qupath/qupath/issues/1027#issuecomment-1208463614,2,"['access', 'hash']","['accessible', 'hash']"
Security,"@petebankhead Hi, thanks for the prompt and clear response. Their website is a little unclear about obtaining the data. There is a link on their page to a directory listing where you can download individual images. You unfortunately have to sign in to their site I believe to access this. These files are listed [here](http://ptak.felk.cvut.cz/Medical/dataset_ANHIR/images/), and the password can be seen on [this page](https://anhir.grand-challenge.org/Download/) after signing in. Edit: It's worth noting that this happens with many images, and the example is just one of them.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/459#issuecomment-620643098:276,access,access,276,https://qupath.github.io,https://github.com/qupath/qupath/issues/459#issuecomment-620643098,2,"['access', 'password']","['access', 'password']"
Security,"@petebankhead and @melvingelbard , sorry for the late response. I will use image.sc for feature requests if that is more suitable. (I thought it might be easy for you to track features and interlink them with commit ids here). I can access the numbers by double clicking, thanks for pointing that out. That should help a little. It would be nice to see at least 2 decimal places near the slider for the 32 float images (with low intensity values). I am not sure if it will hurt to have 2 decimal places when the values are greater than 10, or will it somehow affect the usability of the slider. Your suggestion might be better, to have 2 decimal places when the value is < 10, and 1 decimal place otherwise. Thanks for looking into this.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/669#issuecomment-786174872:233,access,access,233,https://qupath.github.io,https://github.com/qupath/qupath/issues/669#issuecomment-786174872,1,['access'],['access']
Security,"@saudet since my machine is CentOS 7, I decided to build the code from scratch (as you can see in my Stackoverflow error). Running what you mentioned on the binary file found in tar of the QuPath results in this other error:. ```; drwxrwxrwt. 62 root root 20K Apr 11 18:07 ..; -rw-r--r--. 1 jalal cs-grad 152M Apr 11 18:10 gradle-7.4.2-all.zip; drwxr-xr-x. 8 jalal cs-grad 4.0K Apr 11 19:16 .; -rw-r--r--. 1 jalal cs-grad 6.4K Apr 11 19:16 EGFR SSM TCGA LUAD.csv; [jalal@goku downloads]$ cd QuPath/; [jalal@goku QuPath]$ ls; total 4.0K; drwxr-xr-x. 4 jalal cs-grad 66 Jan 17 03:51 lib; drwxr-xr-x. 2 jalal cs-grad 49 Jan 17 03:51 bin; drwxr-xr-x. 4 jalal cs-grad 40 Jan 17 03:51 .; drwxr-xr-x. 8 jalal cs-grad 4.0K Apr 11 19:16 ..; [jalal@goku QuPath]$ cd bin/; [jalal@goku bin]$ JAVA_TOOL_OPTIONS=-Dorg.bytedeco.javacpp.nopointergc=true ./QuPath; Picked up JAVA_TOOL_OPTIONS: -Dorg.bytedeco.javacpp.nopointergc=true; OpenJDK 64-Bit Server VM warning: Option --illegal-access is deprecated and will be removed in a future release.; Apr 11, 2022 8:47:07 PM com.sun.javafx.application.PlatformImpl startup; WARNING: Unsupported JavaFX configuration: classes were loaded from 'unnamed module @60975100'; 20:47:08.384 [JavaFX Application Thread] [INFO ] qupath.lib.common.ThreadTools - Setting parallelism to 11; 20:47:08.673 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - QuPath build: Version: 0.3.2; Build time: 2022-01-17, 08:49; Latest commit tag: '71884c6'; 20:47:08.674 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Setting tile cache size to 8024.00 MB (25.0% max memory). (QuPath:8487): Gdk-WARNING **: 20:47:09.200: XSetErrorHandler() called with a GDK error trap pushed. Don't do that.; 20:47:09.626 [JavaFX Application Thread] [INFO ] qupath.lib.scripting.QP - Initializing type adapters; *** Error in `./QuPath': free(): invalid pointer: 0x00007f79411f0c80 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x81329)[0x7f82287f5329]; /lib64/libstdc++.so.6(_",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018:969,access,access,969,https://qupath.github.io,https://github.com/qupath/qupath/issues/949#issuecomment-1095746018,1,['access'],['access']
Security,"A_WITH_AES_256_GCM_SHA384(0x009D), TLS_RSA_WITH_AES_128_GCM_SHA256(0x009C), TLS_RSA_WITH_AES_256_CBC_SHA256(0x003D), TLS_RSA_WITH_AES_128_CBC_SHA256(0x003C), TLS_RSA_WITH_AES_256_CBC_SHA(0x0035), TLS_RSA_WITH_AES_128_CBC_SHA(0x002F), TLS_EMPTY_RENEGOTIATION_INFO_SCSV(0x00FF)]"",; ""compression methods"" : ""00"",; ""extensions"" : [; ""server_name (0)"": {; type=host_name (0), value=oauth2.googleapis.com; },; ""status_request (5)"": {; ""certificate status type"": ocsp; ""OCSP status request"": {; ""responder_id"": <empty>; ""request extensions"": {; <empty>; }; }; },; ""supported_groups (10)"": {; ""versions"": [ffdhe2048, ffdhe3072, ffdhe4096, ffdhe6144, ffdhe8192]; },; ""ec_point_formats (11)"": {; ""formats"": [uncompressed]; },; ""signature_algorithms (13)"": {; ""signature schemes"": [rsa_pss_rsae_sha256, rsa_pss_rsae_sha384, rsa_pss_rsae_sha512, rsa_pss_pss_sha256, rsa_pss_pss_sha384, rsa_pss_pss_sha512, rsa_pkcs1_sha256, rsa_pkcs1_sha384, rsa_pkcs1_sha512, dsa_sha256, rsa_sha224, dsa_sha224, rsa_pkcs1_sha1, dsa_sha1]; },; ""signature_algorithms_cert (50)"": {; ""signature schemes"": [rsa_pss_rsae_sha256, rsa_pss_rsae_sha384, rsa_pss_rsae_sha512, rsa_pss_pss_sha256, rsa_pss_pss_sha384, rsa_pss_pss_sha512, rsa_pkcs1_sha256, rsa_pkcs1_sha384, rsa_pkcs1_sha512, dsa_sha256, rsa_sha224, dsa_sha224, rsa_pkcs1_sha1, dsa_sha1]; },; ""status_request_v2 (17)"": {; ""cert status request"": {; ""certificate status type"": ocsp_multi; ""OCSP status request"": {; ""responder_id"": <empty>; ""request extensions"": {; <empty>; }; }; }; },; ""extended_master_secret (23)"": {; <empty>; },; ""supported_versions (43)"": {; ""versions"": [TLSv1.3, TLSv1.2, TLSv1.1, TLSv1]; },; ""psk_key_exchange_modes (45)"": {; ""ke_modes"": [psk_dhe_ke]; },; ""key_share (51)"": {; ""client_shares"": [ ; {; ""named group"": ffdhe2048; ""key_exchange"": {; 0000: 5A 82 F4 1B 76 97 99 EF 78 C0 FC C3 7B 7F 05 B2 Z...v...x.......; 0010: 50 B4 7A AD 65 C5 33 1C 68 9F E6 8C 04 C0 E6 BA P.z.e.3.h.......; 0020: F0 10 C3 D1 97 0C 4C 87 CE 46 11 7B F5 7F C7 3C ......L..F",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/436:8504,certificate,certificate,8504,https://qupath.github.io,https://github.com/qupath/qupath/issues/436,2,['certificate'],['certificate']
Security,"Actually, looking at Ilaskit, I would probably start with trying to run that through QuPath (point the ImageJ plugins directory to the correct place in Preferences). Some modules are not compatible, but if that one is, it would probably be the way to go for segmentation. If it works, just find the largest tiles ImageJ can handle at a time, assuming you can store your training set for QuPath to access on each call.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/56#issuecomment-286559987:397,access,access,397,https://qupath.github.io,https://github.com/qupath/qupath/issues/56#issuecomment-286559987,1,['access'],['access']
Security,Add gradle checksum plugin,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1368:11,checksum,checksum,11,https://qupath.github.io,https://github.com/qupath/qupath/pull/1368,1,['checksum'],['checksum']
Security,"Ah yes! Forgot about the hashes, should be an easy fix",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1366#issuecomment-1747765767:25,hash,hashes,25,https://qupath.github.io,https://github.com/qupath/qupath/pull/1366#issuecomment-1747765767,1,['hash'],['hashes']
Security,"Ah, I was also using the OpenSlide example to see if it worked. If you can somehow send me an example file with the problem I'd be happy to investigate. Although it sounds like it is outside the domain of QuPath, which depends on either OpenSlide or Bio-Formats to access the pixels. (If it looks ok when opened by Bio-Formats in Fiji (www.fiji.sc) then it might be a QuPath thing again, although not one I've seen before.)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/141#issuecomment-358746900:265,access,access,265,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358746900,1,['access'],['access']
Security,"Ah, sorry, I probably should have mentioned, it might not be your laptop...; One of the dangers with using Positive Pixel detection is the strain it puts on the program when updating the screen with many very finely defined areas. I would recommend turning OFF all detection visualizations, then moving the screen to the location you want to see, then turning detection visualizations back on (might be the D or H key? I don't have access right now and forget). Turn them off again before you want to move the screen to a new position. It is somewhat cumbersome, but usually prevents my program from crashing. . In fact, the program is not usually crashing, but just very slowly rendering the entire image again. Though depending on your system it might sometimes take an hour or so! If you use Superpixels or Cell detection, this is not usually a problem.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/157#issuecomment-373141585:432,access,access,432,https://qupath.github.io,https://github.com/qupath/qupath/issues/157#issuecomment-373141585,1,['access'],['access']
Security,"Ah, thanks @melvingelbard - so it *is* OpenCV-related. That's really good to know, seems to confirm my suspicions although I have no clue why. It also seems to be specifically the `org.bytedeco.opencv.global.opencv_imgproc` class - assuming object classifiers are working, then `opencv_core` and `opencv_ml` must be ok. If you still have access to the computer, you could check if pixel classifiers work - since they use `opencv_imgproc` as well. If they do, perhaps the problem is more restricted. If launched from a command line, there might be more detailed errors emitted at some point. On Windows, that can be done simply by using the console exe launcher. On a Mac, it means running something like this from a terminal `/Applications/QuPath.app/Contents/MacOS/QuPath` (exact path might need changed).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/776#issuecomment-873087104:338,access,access,338,https://qupath.github.io,https://github.com/qupath/qupath/issues/776#issuecomment-873087104,1,['access'],['access']
Security,"An alternative could be to smuggle in an implementation of stored sorting with a `Manager`, but that seems like a bit of abuse of the existing facilities. The obvious way to make one change that permits any future extensions is to add a `Map<[String?], [Object?]>`, but that's got its own set of problems (security would be a big one).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1537#issuecomment-2140050177:306,secur,security,306,https://qupath.github.io,https://github.com/qupath/qupath/issues/1537#issuecomment-2140050177,1,['secur'],['security']
Security,"As I mentioned (each time you brought this up :) ) the approach you have taken creates a dependency on `ImageDisplay` that I *really* do not want to be stuck with. It creates an awkward confusion between the GUI and core code that will be a maintenance headache, and would greatly complicate trying to implement a better design later. I added the alternative scripting methods that I linked to before precisely because you asked for it. Running that for a project is the solution I propose. It uses `ImageDisplay` internally (because it has to), but doesn't expose this publicly. Romain's comment wasn't a question, it seemed you had a solution you were satisfied with, and I received no reply to the changes I made for you except for 👍 so it remains very unclear to me what you want...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/26#issuecomment-632627020:558,expose,expose,558,https://qupath.github.io,https://github.com/qupath/qupath/issues/26#issuecomment-632627020,1,['expose'],['expose']
Security,"Attempt to resolve https://github.com/qupath/qupath/issues/744. The underlying problem is that concurrent modification exceptions occurred whenever nDescendants() was called by the UI thread while another thread was adding/removing objects. Adding *more* synchronization to try to overcome this resulted in deadlocks. This commit tries to resolve the issue in two ways:; - Making the childList a synchronized collection (actually a Set); - Reducing synchronization on the PathObject itself, and synchonizing more sparingly on the childList. This is hopefully sufficient to avoid simply counting objects in one thread interfering with adding/removing objects in another. Since most adding/removing access is via a PathObjectHierarchy, counting is (I think...) the main concurrency risk, and the resulting code should be more robust. Along the way, the childList was also given a better default capacity.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/750:697,access,access,697,https://qupath.github.io,https://github.com/qupath/qupath/pull/750,1,['access'],['access']
Security,"B 53 1D 03 91 48 A0 92 D2 ..JO.x..S...H...; 00E0: 0A 26 24 32 18 15 C1 2B 1E 00 64 37 CE D4 34 29 .&$2...+..d7..4(; ; }; },; ]; }; ]; }; ); javax.net.ssl|DEBUG|29|Thread-9|2020-04-13 21:28:52.416 NOVT|null:-1|Received alert message (; ""Alert"": {; ""level"" : ""fatal"",; ""description"": ""handshake_failure""; }; ); javax.net.ssl|ERROR|29|Thread-9|2020-04-13 21:28:52.417 NOVT|null:-1|Fatal (HANDSHAKE_FAILURE): Received fatal alert: handshake_failure (; ""throwable"" : {; javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure; 	at java.base/sun.security.ssl.Alert.createSSLException(Unknown Source); 	at java.base/sun.security.ssl.Alert.createSSLException(Unknown Source); 	at java.base/sun.security.ssl.TransportContext.fatal(Unknown Source); 	at java.base/sun.security.ssl.Alert$AlertConsumer.consume(Unknown Source); 	at java.base/sun.security.ssl.TransportContext.dispatch(Unknown Source); 	at java.base/sun.security.ssl.SSLTransport.decode(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.decode(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.readHandshakeRecord(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.startHandshake(Unknown Source); 	at java.base/sun.net.www.protocol.https.HttpsClient.afterConnect(Unknown Source); 	at java.base/sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream(Unknown Source); 	at java.base/sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(Unknown Source); 	at shaded.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.com.google.api.client.auth.oauth2.TokenRequest.executeUnparsed(TokenRequest.java:283); 	at shaded.com.google.api.client.auth.oauth2.TokenRequest.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/436:11899,secur,security,11899,https://qupath.github.io,https://github.com/qupath/qupath/issues/436,1,['secur'],['security']
Security,B; input=broken_image.tif; output=broke_omage.ome.tif; QuPath convert-ome $input $output \; --pyramid-scale=$scale \; --tile-size=$tile \; --compression=$comp \; --parallelize; ```; Output (truncated); ```; 20:39:42.582 [main] [INFO ] q.l.i.s.b.BioFormatsServerOptions - Setting max Bio-Formats readers to 2; 20:39:43.272 [main] [ERROR] loci.formats.tiff.TiffParser - Error reading IFD type at: 14; 20:39:43.274 [main] [ERROR] loci.formats.tiff.TiffParser - Error reading IFD type at: 14; 20:39:43.275 [main] [ERROR] loci.formats.tiff.TiffParser - Error reading IFD type at: 14; ...; 20:39:43.604 [main] [ERROR] q.l.i.writers.ome.ConvertCommand - Unable to open file:broken_image.tif; java.io.IOException: Unable to open file:broken_image.tif; at qupath.lib.images.servers.ImageServers.buildServer(ImageServers.java:306); at qupath.lib.images.writers.ome.ConvertCommand.run(ConvertCommand.java:147); at picocli.CommandLine.executeUserObject(CommandLine.java:2026); at picocli.CommandLine.access$1500(CommandLine.java:148); at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2461); at picocli.CommandLine$RunLast.handle(CommandLine.java:2453); at picocli.CommandLine$RunLast.handle(CommandLine.java:2415); at picocli.CommandLine$AbstractParseResultHandler.execute(CommandLine.java:2273); at picocli.CommandLine$RunLast.execute(CommandLine.java:2417); at picocli.CommandLine.execute(CommandLine.java:2170); at qupath.QuPath.main(QuPath.java:202); Suppressed: java.io.IOException: Unable to build ImageServer for file:/scratch/a56/jr9959/tmp/xenium-images/unassigned/230629_Xenium_ID4369_Primary_3962_LA-Spots/230629_Xenium_ID4369_Primary_3962_LA-Spot000001.tif with requested provider qupath.imagej.images.servers.ImageJServerBuilder; at qupath.lib.images.servers.ImageServerBuilder$DefaultImageServerBuilder.buildOriginal(ImageServerBuilder.java:369); at qupath.lib.images.servers.ImageServerBuilder$AbstractServerBuilder.build(ImageServerBuilder.java:174),MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1451:2012,access,access,2012,https://qupath.github.io,https://github.com/qupath/qupath/issues/1451,1,['access'],['access']
Security,"BUG:. WSI image will pixelate when trying to access deeper levels of magnification. Tested the soft in two different Macs with the same OS and the same happens. . To reproduce:. 1- Select Open and then the WSI image in .tif format.; 2- Two files are available: Image and the Mask. Select the Image and select Open.; 3- A dialogue will appear to select type of Image: select bright filed H&E; 4- Scroll with the mouse to activate zoom or with right-click, select display and then different levels of zoom. . Expected behavior; With the scroll, zoom should access higher levels of magnification and the image should not be pixelated. Cells must be able to be seen. . Desktop; MACOS Monterey 12.4, 2GHZ Core i5 (2 cores), 8GB 1867 MHZ DDR3, Intel iris 540 1036 MB; QuPath version 0.3.2, Max memory JVM may try to use: 4096 MB. ![DD0F3384-7024-455E-98AC-3916959D9B95](https://user-images.githubusercontent.com/53937441/170973697-316e32c0-6f1f-4de1-9d3e-d6a6134a34e3.jpeg)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/973:45,access,access,45,https://qupath.github.io,https://github.com/qupath/qupath/issues/973,2,['access'],['access']
Security,"Below is the command-line output if I run from command line instead of GUI:; We can see that the path was a combination of two paths, this is the problem. >> RMD_slide2ims_Entry; 23:18:18.288 [main] [INFO ] qupath.QuPath - Launching QuPath with args: -image, D:\\QMDownload\\5\\Leica_scn\\Leica-Fluorescence-1.scn, -script, D:\\QMDownload\\5\\tpc9321172_2c3b_4e82_b55c_7ae4380fda4b.groovy ; 23:18:18.368 [main] [ERROR] q.lib.images.servers.FileFormatInfo - Checking Big TIFF images currently not supported!!! ; 23:18:18.428 [main] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1 ; WARNING: An illegal reflective access operation has occurred ; WARNING: Illegal reflective access by com.esotericsoftware.kryo.util.UnsafeUtil (file:/C:/Program%20Files/QuPath-0.2.0-m1/app/kryo-2.24.0.jar) to constructor java.nio.DirectByteBuffer(long,int,java.lang.Object) ; WARNING: Please consider reporting this to the maintainers of com.esotericsoftware.kryo.util.UnsafeUtil ; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations ; WARNING: All illegal access operations will be denied in a future release ; 23:18:19.436 [main] [WARN ] loci.formats.Memoizer - deleting invalid memo file: D:\QMDownload\5\Leica_scn\.Leica-Fluorescence-1.scn.bfmemo ; com.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 458; Serialization trace:; service (loci.formats.in.OperettaReader); readers (loci.formats.ImageReader); reader (loci.formats.DimensionSwapper); reader (loci.formats.FileStitcher); helper (loci.formats.in.FilePatternReader); readers (loci.formats.ImageReader) ; 	at com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:119) ; 	at com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:641) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:375) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$Obje",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/280#issuecomment-472915452:631,access,access,631,https://qupath.github.io,https://github.com/qupath/qupath/issues/280#issuecomment-472915452,2,['access'],['access']
Security,"Bio-Formats Extension (0.0.4) does not show up in Extensions menu, cannot be accessed",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/12:77,access,accessed,77,https://qupath.github.io,https://github.com/qupath/qupath/issues/12,1,['access'],['accessed']
Security,"Bio-Formats server options (Bio-Formats 6.2.0) (20 ms); 10:11:48.235 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Experimental commands (19 ms); 10:11:48.278 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension ImageJ extension (42 ms); 10:11:48.290 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension JPen extension (12 ms); 10:11:48.294 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension OpenCV extensions (3 ms); Oct 13, 2019 10:11:48 AM jpen.provider.NativeLibraryLoader$4 run; INFO: loading JPen 2-150301 JNI library: jpen-2-4-x86_64 ...; Oct 13, 2019 10:11:48 AM jpen.provider.NativeLibraryLoader$4 run; INFO: jpen-2-4-x86_64 loaded; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.codehaus.groovy.vmplugin.v7.Java7$1 (file:/usr/local/src/QuPath-0.2.0-m4/app/groovy-2.5.7.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class,int); WARNING: Please consider reporting this to the maintainers of org.codehaus.groovy.vmplugin.v7.Java7$1; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 10:11:48.594 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Rich script editor extension (300 ms); 10:11:48.603 [JavaFX Application Thread] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1; 10:11:48.698 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: null; 10:11:48.698 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 10:11:48.704 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []. (QuPath-0.2.0-m4:17581): Gdk-WARNING **: 10:11:48.706: XSetErrorHandler() called with a GDK error trap pushed. Don't do that.; ```",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/369:3148,access,access,3148,https://qupath.github.io,https://github.com/qupath/qupath/issues/369,3,['access'],['access']
Security,"Brilliant, thanks @zindy! Very reassuring to have any fixes validated, I hope v0.4.2 can last longer than v0.4.0 and v0.4.1 :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1202#issuecomment-1381855920:60,validat,validated,60,https://qupath.github.io,https://github.com/qupath/qupath/issues/1202#issuecomment-1381855920,1,['validat'],['validated']
Security,"C 0F 18 07 0B 00 77 F3 32 E2 ......<.....w.2.; 0080: DC 68 9D F2 67 77 DF 1E 6D 06 82 66 F6 F7 8E 2B .h..gw..m..f...+; 0090: 35 9A 85 F6 09 72 7C 5B 3C CC 87 59 84 CF 96 68 5....r.[<..Y...h; 00A0: 6B D5 81 4C 74 B9 A7 91 98 49 0B 12 3F 8C E1 52 k..Lt....I..?..R; 00B0: E3 B3 53 B9 78 ED 29 56 82 E3 13 31 16 C0 6A A7 ..S.x.)V...1..j.; 00C0: F8 5A 8F FE 94 77 14 0A 22 0D 51 66 A1 55 BD 6B .Z......"".Qf...k; 00D0: D9 2E 4A 4F 9B 78 15 9B 53 1D 03 91 48 A0 92 D2 ..JO.x..S...H...; 00E0: 0A 26 24 32 18 15 C1 2B 1E 00 64 37 CE D4 34 29 .&$2...+..d7..4(; ; }; },; ]; }; ]; }; ); javax.net.ssl|DEBUG|29|Thread-9|2020-04-13 21:28:52.416 NOVT|null:-1|Received alert message (; ""Alert"": {; ""level"" : ""fatal"",; ""description"": ""handshake_failure""; }; ); javax.net.ssl|ERROR|29|Thread-9|2020-04-13 21:28:52.417 NOVT|null:-1|Fatal (HANDSHAKE_FAILURE): Received fatal alert: handshake_failure (; ""throwable"" : {; javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure; 	at java.base/sun.security.ssl.Alert.createSSLException(Unknown Source); 	at java.base/sun.security.ssl.Alert.createSSLException(Unknown Source); 	at java.base/sun.security.ssl.TransportContext.fatal(Unknown Source); 	at java.base/sun.security.ssl.Alert$AlertConsumer.consume(Unknown Source); 	at java.base/sun.security.ssl.TransportContext.dispatch(Unknown Source); 	at java.base/sun.security.ssl.SSLTransport.decode(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.decode(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.readHandshakeRecord(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.startHandshake(Unknown Source); 	at java.base/sun.net.www.protocol.https.HttpsClient.afterConnect(Unknown Source); 	at java.base/sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream(Unknown So",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/436:11464,secur,security,11464,https://qupath.github.io,https://github.com/qupath/qupath/issues/436,1,['secur'],['security']
Security,Can we deploy qupath instance on cloud and access it from web url?,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/576:43,access,access,43,https://qupath.github.io,https://github.com/qupath/qupath/issues/576,1,['access'],['access']
Security,Can't access WSI levels in MACOS Monterey 12.4,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/973:6,access,access,6,https://qupath.github.io,https://github.com/qupath/qupath/issues/973,1,['access'],['access']
Security,"Changelog:; ------------; * Positive cell detection supports different stainings (including multiplexed images); * Cell detection & the intensity measurement command use channel names rather than numbers; * (Note that channel order is still important when scripting the intensity measurement command); * Big changes to memory management; * Improved tile caching (using Guava) & more control; * Specify the proportion of available memory for tile caching in the preferences; * New options when importing images to a project; * 'Pyramidalize' large, single-resolution images; * Rotate images on import (90 degree increments); * Specify the image reading library (e.g. Bio-Formats, OpenSlide); * Improved resolution of paths to missing or moved images within projects; * New 'Search' button allows recursive search for missing images; * Improved 'Measurement map' behavior and colormap support; * Specify line cap when expanding line annotations; * For why this matters, see https://github.com/qupath/qupath/issues/228#issuecomment-518552859; * 'Send region to ImageJ' improvements; * Only send objects within the field of view as an overlay; * Set lookup tables where possible; * Support arbitrary small regions (can now send a 1x1 pixel image); * New preferences to specify viewer font size (scalebar, location text); * Code formatting is asynchronous (causes small delay, but reduces errors); * Project scripts are back... accessible from the 'Automate' menu; * More bugs fixed and others improvements, including; * Exceptions when generating some viewer/window snapshots; * Resolving relative URIs on Mac/Linux - https://github.com/qupath/qupath/issues/346; * SLIC bug - https://github.com/qupath/qupath/issues/344",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/353:1423,access,accessible,1423,https://qupath.github.io,https://github.com/qupath/qupath/pull/353,1,['access'],['accessible']
Security,"Cheers, I put literally zero thought into what we need and not, though some of it definitely looked fishy. I figured it wasn't worth thinking about if it wasn't going to work in principle anyways. The associated image class is useless yeah, it's just a String with a getBufferedImage method. No idea why they use a String -> String HashMap for that. Also renamed ""Openslide"" to ""OpenSlide"" in the server(builder) classes for consistency, which I hope doesn't break anything",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1325#issuecomment-1715236828:332,Hash,HashMap,332,https://qupath.github.io,https://github.com/qupath/qupath/pull/1325#issuecomment-1715236828,1,['Hash'],['HashMap']
Security,"Closing this issue after discussion with @melvingelbard... it's not something we plan to do, and would be very apprehensive about including the change even if someone else implemented it. As I mentioned above, the consistency thing has some (partly historic) reasons. We only started adding spinners recently; the underlying rationale has been that sliders are used when the range is known in advance, spinners are used when it's not... New commands will endeavour to apply this rule more consistently, and old commands will either be either removed or updated. Regarding spinners and mouse wheel input, I think this really would need to be implemented in JavaFX directly. There are ostensibly easy ways to add support by attaching a scroll listener, in my experience to date this can open a whole can of worms... basically, scroll events can differ a lot depending upon the input device/platform (not to mention 'natural' scrolling in some cases, which can flip the direction). Therefore I think the risk is too high of creating something that inadvertently makes the user experience *worse* for many, and we would have no way to test all the relevant platforms to check this. I presume the JavaFX developers have reasons for not implementing this directly yet - perhaps related to the reason I give. But in any case, they would have access to potentially more platform-specific information to enable a robust implementation. For these reasons, I'm afraid I don't think we can/should act on this feature request.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/495#issuecomment-641183465:1335,access,access,1335,https://qupath.github.io,https://github.com/qupath/qupath/issues/495#issuecomment-641183465,1,['access'],['access']
Security,"Closing this now... still not possible to rename in the *Hierarchy* view (sorry), but at least in v0.2.0 one can now access a consistent annotations menu by right-clicking on the viewer. This gives another way to set the properties, in addition to choosing from the *Annotations* tab or pressing `Enter`.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/42#issuecomment-632222754:117,access,access,117,https://qupath.github.io,https://github.com/qupath/qupath/issues/42#issuecomment-632222754,1,['access'],['access']
Security,"CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDispatcher.java:59); 	at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:58); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); 	at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); 	at javafx.event.Event.fireEvent(Event.java:198); 	at javafx.scene.Scene$DnDGesture.fireEvent(Scene.java:3144); 	at javafx.scene.Scene$DnDGesture.processTargetEnterOver(Scene.java:3316); 	at javafx.scene.Scene$DropTargetListener.dragEnter(Scene.java:3024); 	at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.lambda$handleDragEnter$0(GlassSceneDnDEventHandler.java:83); 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:399); 	at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragEnter(GlassSceneDnDEventHandler.java:77); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragEnter$9(GlassViewEventHandler.java:733); 	at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:424); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragEnter(GlassViewEventHandler.java:732); 	at com.sun.glass.ui.View.handleDragEnter(View.java:684); 	at com.sun.glass.ui.View.notifyDragEnter(View.java:1020); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$runLoop$11(GtkApplication.java:316); 	at java.base/java.lang.Thread.run(Thread.java:833); 13:36:13.428 [JavaFX Application Thread] [ERROR] q.l.g.QuPathUncaughtExceptionHandler - setDropCompleted can be called only from DRAG_DROPPED handler (see full stack trace above, or use 'debug' log level); 13:36:13.788 [J",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1338#issuecomment-1727641846:1793,Access,AccessController,1793,https://qupath.github.io,https://github.com/qupath/qupath/pull/1338#issuecomment-1727641846,1,['Access'],['AccessController']
Security,"ConstructorAccessorImpl.newInstance(Unknown Source); at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Unknown Source); at java.base/java.lang.reflect.Constructor.newInstance(Unknown Source); at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(Unknown Source); at java.base/java.util.ServiceLoader$ProviderImpl.get(Unknown Source); at java.base/java.util.ServiceLoader$3.next(Unknown Source); at qupath.lib.images.servers.ImageServerProvider.getInstalledImageServerBuilders(ImageServerProvider.java:104); at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1601); at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:1059); at qupath.lib.gui.QuPathApp.start(QuPathApp.java:60); at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$9(LauncherImpl.java:846); at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$12(PlatformImpl.java:455); at com.sun.javafx.application.PlatformImpl.lambda$runLater$10(PlatformImpl.java:428); at java.base/java.security.AccessController.doPrivileged(Unknown Source); at com.sun.javafx.application.PlatformImpl.lambda$runLater$11(PlatformImpl.java:427); at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:96); at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); at com.sun.glass.ui.gtk.GtkApplication.lambda$runLoop$11(GtkApplication.java:277); at java.base/java.lang.Thread.run(Unknown Source); 17:02:49.461 [JavaFX Application Thread] [INFO ] q.l.i.s.o.OpenslideServerBuilder - If you want to use OpenSlide, you'll need to get the native libraries (either building from source or with a packager manager); and add them to your system PATH, including openslide-jni.; 17:02:49.798 [qupathgui-1] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 17:02:49.798 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 17:02:52.272 [qupathgui-1] [INFO ] qupath.lib.gui.QuPathGUI - Current version 0.2.3, latest stable releas",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/615#issuecomment-725509556:1936,secur,security,1936,https://qupath.github.io,https://github.com/qupath/qupath/issues/615#issuecomment-725509556,1,['secur'],['security']
Security,"Dear Dr. Bankhead,. First of all: this is an incredible piece of software! We are exploring its multiple possibilities with great excitement. Thank you very much for making it publicly available. Among others, we are working with a lot of Zeiss *.czi and 3D Histech *.mrxs multichannel fluorescence whole slide images. The default version of QuPath can open the *.mrxs files, but only in the most coarse resolution. So I installed the Bio-Formats extension and it does show up in the ""Help/Installed Extensions ""dialogue. However, it does not appear in the ""Extensions"" Menu. Only ImageJ is accessible in this menu. Best regards,. Arnulf Mayer, University Medical Center Mainz, Germany",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/12:591,access,accessible,591,https://qupath.github.io,https://github.com/qupath/qupath/issues/12,1,['access'],['accessible']
Security,"Dear Pete,. Sounds good. From the outside, maybe I can give two remarks that might be helpful to consider:. Because QuPath is your ""baby"", you are thinking a lot about how to include outside functionality (ImageJ) into QuPath. At the same time, you say rightly, ImageJ has much more documentation and support, and more users and more diverse users. Maybe it might be a good project to access QuPath from ImageJ, either the whole GUI, but even better, just its functional structures, by writing a ImageJ Plugin. And I guess, you would not necessarily need to do that yourself, because it might be easier to find someone to help, because there is more people experienced with writing ImageJ Plugins. QuPath itself is really good for Digital Pathology, and Digital Pathology is booming. A lot of people probably already gave you very positive feedback. This means, there must be ways to get more funding for that project and then you can actually hire people to do the programming. But somehow I think, you might have thought about that already. If there is anything I can help with (unfortunately not programming a software), I would like to support.; Best Philipp",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/182#issuecomment-401763074:385,access,access,385,https://qupath.github.io,https://github.com/qupath/qupath/issues/182#issuecomment-401763074,1,['access'],['access']
Security,"Dear Pete,. When trying to label a Z-Stack with a Dell Active Pen (MI8AH) everything works fine for 50-100 objects in multiple planes (using the polygon tool). Then I get this error message:. ERROR: QuPath exception; ERROR: QuPath exception: Too many touch points reported; at javafx.scene.Scene$ScenePeerListener.touchEventNext(Scene.java:2815); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleNextTouchEvent$26(GlassViewEventHandler.java:1324); at java.base/java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleNextTouchEvent$27(GlassViewEventHandler.java:1287); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:412); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleNextTouchEvent(GlassViewEventHandler.java:1286); at com.sun.glass.ui.View.handleNextTouchEvent(View.java:580); at com.sun.glass.ui.View.notifyNextTouchEvent(View.java:1055); at com.sun.glass.ui.TouchInputSupport.notifyNextTouchEvent(TouchInputSupport.java:142); at com.sun.glass.ui.win.WinGestureSupport.notifyNextTouchEvent(WinGestureSupport.java:58); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:174); at java.base/java.lang.Thread.run(Unknown Source); ERROR: QuPath exception. There is no crash. No data lost.; QuPath 0.2.0m5 (on Windows 10) ""just"" refuses to accept new input by my pen.; I can still go on using the mouse.; Thus, it is neither major nor urgent. I also tested: If I save close & reopen I can continue with the same file and the pen. Thanks a lot & Kind regards. Tobias",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/372:481,secur,security,481,https://qupath.github.io,https://github.com/qupath/qupath/issues/372,2,"['Access', 'secur']","['AccessController', 'security']"
Security,"Dear Pete,. thank you very much for your fast reply!. Regarding *.mrxs files, the problems occur only with multichannel fluorescence images. Brightfield images open without a problem. Here is an example:. ![brightfield_example](https://cloud.githubusercontent.com/assets/23238491/19998070/e2515342-a26a-11e6-8f3d-8c2746210dc1.jpg). Indeed, as we can see, OpenSlide is used to access the *.mrxs file. Regarding the fluorescence files, all of the requirements that you stated above are fulfilled for my files. QuPath opens them using ImageJ. When I use ImageJ (or in my case, Fiji) to open them directly, the behaviour is the same: access is only possbile at the most coarse resolution. Both *.czi and *.mrxs can be exported as tiff files from their viewers (ZEN2 and CaseViewer). The monochrome tiffs can be opened in QuPath. However, when I joined three of these monochrome files in an RGB file, my first attempt at opening it in QuPath failed. I am going to keep experimenting. However, I wanted to point out that the technology to open multichannel *.czi and *.mrxs files already exists because it is implemented in a free viewer application called ""Zoom v2.0.0"", available from MicroDimensions (https://micro-dimensions.com/zoom/). We have been providing some slides for them over the last years to test their algorithms. They might be interested in a scientific cooperation. We can also provide test slides (image data) via our file transfer system for you if you give me an e-mail address. Best regards,. Arnulf",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/12#issuecomment-258370511:376,access,access,376,https://qupath.github.io,https://github.com/qupath/qupath/issues/12#issuecomment-258370511,2,['access'],['access']
Security,"Dear QuPath developers,. Quite some time ago a user of `paquo` reported a bug with network share URIs on windows, see: https://github.com/bayer-science-for-a-better-life/paquo/issues/65. This PR get's rid of the immediate issue in ImageServerProvider.getServerBuilders, but I'm not sure if there's more bugs further downstream using network share URIs. The fix boils down to using `java.nio.Paths.get(uri).toFile()` instead of `java.io.File(uri)` directly. (see: https://github.com/bayer-science-for-a-better-life/paquo/issues/65#issuecomment-970711915). I am currently unable to test this myself due to lack of access to a windows machine. . Cheers,; Andreas 😃",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1049:612,access,access,612,https://qupath.github.io,https://github.com/qupath/qupath/pull/1049,1,['access'],['access']
Security,Dispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$ClickGenerator.postProcess(Scene.java:3470); at javafx.scene.Scene$ClickGenerator.access$8100(Scene.java:3398); at javafx.scene.Scene$MouseHandler.process(Scene.java:3766); at javafx.scene.Scene$MouseHandler.access$1500(Scene.java:3485); at javafx.scene.Scene.impl_processMouseEvent(Scene.java:1762); at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2494); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:380); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:294); at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$354(GlassViewEventHandler.java:416); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:415); at com.sun.glass.ui.View.handleMouseEvent(View.java:555); at com.sun.glass.ui.View.notifyMouse(View.java:937); at com.sun.glass.ui.w,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/35:9538,access,access,9538,https://qupath.github.io,https://github.com/qupath/qupath/issues/35,2,['access'],['access']
Security,"Dispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); 	at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); 	at javafx.event.Event.fireEvent(Event.java:198); 	at javafx.scene.Scene$MouseHandler.process(Scene.java:3757); 	at javafx.scene.Scene$MouseHandler.access$1500(Scene.java:3485); 	at javafx.scene.Scene.impl_processMouseEvent(Scene.java:1762); 	at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2494); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:352); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:275); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$300(GlassViewEventHandler.java:388); 	at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:387); 	at com.sun.glass.ui.View.handleMouseEvent(View.java:555); 	at com.sun.glass.ui.View.notifyMouse(View.java:937); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:40:13.846 [JavaFX Application Thread] [INFO ] q.l.i.servers.ImageServerProvider - Returning server: ImageJ server for /home/bl/Documents/IMG_5_11_sq.png; 02:40:14.153 [JavaFX Application Thread] [INFO ] qupath.lib.gui.viewer.QuPathViewer - Image data set to ImageData: Fluorescence, IMG_5_11_sq; 02:40:22.852 [JavaFX Application Thread] [INFO ] q.lib",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/27#issuecomment-262870405:7793,Access,AccessController,7793,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405,1,['Access'],['AccessController']
Security,"Dispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); 	at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); 	at javafx.event.Event.fireEvent(Event.java:198); 	at javafx.scene.Scene$MouseHandler.process(Scene.java:3757); 	at javafx.scene.Scene$MouseHandler.access$1500(Scene.java:3485); 	at javafx.scene.Scene.impl_processMouseEvent(Scene.java:1762); 	at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2494); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:352); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:275); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$300(GlassViewEventHandler.java:388); 	at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:387); 	at com.sun.glass.ui.View.handleMouseEvent(View.java:555); 	at com.sun.glass.ui.View.notifyMouse(View.java:937); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 09:32:08.265 [JavaFX Application Thread] [WARN ] q.l.i.servers.OpenslideServerBuilder - Unable to open /data/CAMELYON16/Train_Tumor/Tumor_005.tif with OpenSlide: null; 09:32:08.265 [JavaFX Application Thread] [ERROR] q.l.i.servers.ImageServerProvider - Unable to build whole slide server - check your classpath for a suitable library (e.g. OpenSlide, Bi",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/65:6312,Access,AccessController,6312,https://qupath.github.io,https://github.com/qupath/qupath/issues/65,1,['Access'],['AccessController']
Security,"Do these colors look more plausible to you?. ![scn_tile](https://user-images.githubusercontent.com/4690904/35150761-7e875fbe-fd13-11e7-98c2-21a026638c2b.jpg). My suspicion is that the photometric interpretation is causing the trouble. Here's a (very hack-y) QuPath script that looks to pull out some tiles after having switched the photometric interpretation from Y_CB_CR to RGB. ```groovy; import ij.ImagePlus; import ij.process.ColorProcessor; import loci.formats.in.LeicaSCNReader; import loci.formats.tiff.IFD; import loci.formats.tiff.PhotoInterp; import loci.formats.tiff.TiffParser; import qupath.lib.images.servers.BioFormatsImageServer; import qupath.lib.scripting.QPEx. // Access the current image; def server = QPEx.getCurrentImageData().getServer() as BioFormatsImageServer. // Try to get the TIFF parser (this takes a bit of a search?); // Assume that we have a LeicaSCNReader somewhere; def reader = server.manager.getPrimaryReader(server, server.filePath); while (!(reader instanceof LeicaSCNReader)); reader = reader.getReader(); reader = reader as LeicaSCNReader; def tiffParser = reader.tiffParser as TiffParser. // Get tile size; int w = reader.getOptimalTileWidth(); int h = reader.getOptimalTileHeight(). // Loop through the IFDs and see if we can extract an image, somehow; for (ifd in tiffParser.getIFDs()) {; try {; // Check the original photometric interpretation; print 'Original photometric interpretation: ' + (ifd.getPhotometricInterpretation()); // Hack to artificially set it to RGB; ifd.putIFDValue(IFD.PHOTOMETRIC_INTERPRETATION, PhotoInterp.RGB.code); def bytes = tiffParser.getTile(ifd, null, 0, 0); // Convert to an ImageJ image for display; int[] rgb = new int[w*h]; for (int i = 0; i < w*h; i++) {; int r = bytes[i]; int g = bytes[w*h+i]; int b = bytes[w*h*2+i]; rgb[i] = (r << 16) + (g << 8) + b; }; def cp = new ColorProcessor(w, h, rgb); new ImagePlus(""Tile"", cp).show(); } catch (Exception e) {; print e.getLocalizedMessage(); }; }; ```. If this is correct, h",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/141#issuecomment-358951720:683,Access,Access,683,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358951720,1,['Access'],['Access']
Security,"Does the View->Show log give you any information when this happens? . I am not sure in your case, but if you are running the full script I wonder if it isn't the cell detection rather than the classifier that is erroring out. I don't believe the classifier runs in tiles, it should apply to the entire image at once, and only after the cell detection part of the script is completed. Memory might be an issue there, though there used to be some possible edge cases with very small tiles (where the tile clips the edge of the tissue and a very tiny region is generated) causing problems. I usually was able to get around that by changing the Simple Tissue detection settings, as it was incredibly rare. The logs should help determine what is happening. You said randomly, so this means you can't reproduce it on any single slide running it twice? Are the images QuPath is accessing stored across a potentially busy or slow network?. As an aside, you are running both a classifier in the cell detection (Positive cell detection with three thresholds), and again with a trained classifier?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/130#issuecomment-355477217:871,access,accessing,871,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355477217,1,['access'],['accessing']
Security,"EHdnCfRaAU7pipTjdj7etnYxMl6fke2A03VF49uEY6P4XmHIM3ote076fSVZpQqVTzYq0orKjFBwoKIbptcmC4XxHSSCRt900YIULIVQAtzU62qtHv_TEqaLa9vgoz2qhsY9NbYDfMfFPtA/https%3A%2F%2Fforum.image.sc%2Ftag%2Fqupath>. The error is that there isn't enough memory, but without having the classifier and knowing how much memory you have, I can't really guess what could be responsible. (This topic is really about loading training data to create classifiers, not classifiers themselves, so I will hide these posts to avoid distraction). —; Reply to this email directly, view it on GitHub<https://secure-web.cisco.com/1S_KCvGqBkfLiU4jUNxk9Bycpt04YwO2EwOrgjo7gUjY2EmjAMNPYCK9KZ3g1BcPOjN1yFkyZLgJnmGWBrpfDiblAR5l3lwK7LfMcHNHJqtYoWGQYJ9WYQ6dCoewz0Xk9P5-ZDRFW4OknOTxChetxm4Bs7LEng-ebDLB6a6AAXrEy8mWNCALTRoJs81HHMcvnMhDSjonYiBRlurLnCnBJZ4a9YvcrT8TplefFlZKST3NVLHrWPL3RgIyoJsDosp8GVf6MH94rRAHuopZp9J5pOcqjQmwnlC51e34AFYd1-8yRTnj7X0qzcw7aHtnILPwFXQIqYdBTGMqf-iZSDUUexg/https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fissues%2F493%23issuecomment-1791280813>, or unsubscribe<https://secure-web.cisco.com/16fbsI3bTg2IXBtZ19rtjLXO9mTw2FP1PcVHSk2XFBBZjPYBQWKvTLiqsGr7UCwdHhDGRsg9tR1qzmQGBIyUICyyRtVvGvh-eu_HtL8Iyt807-ztz3U-i887buKPXzn2O2YTuhy7Xwb13QKvs-TXcflZ21x0cz69j7BIZd4l-aFk4r0Kw89JYQAASuY7o5O0vLb801LbUikLbLtblZgMPHiBe_SrbHoAccvQxrwkY0sMyvxdP_sq89PM0YloMPcUZfoeyvQt8mkLvXp5q2fymfiSTMaZDZDyzknBIzrUh60kAx4knbh5x28AHq2RAZ6YnA3Au7RGuJTZ8YYt7B4VE6g/https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FA5G6YB3KO5IO3F2PMFLETCDYCPOOXAVCNFSM4NF3XJJKU5DIOJSWCZC7NNSXTN2JONZXKZKDN5WW2ZLOOQ5TCNZZGEZDQMBYGEZQ>.; You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>; The information in this e-mail is intended only for the person to whom it is addressed. If you believe this e-mail was sent to you in error and the e-mail contains patient information, please contact the Mass General Brigham Compliance HelpLine at https://www.massgeneralbrigham.org/complianceline <https://www.massgeneralbrigham.org/complianc",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/493#issuecomment-1791396738:3120,secur,secure-web,3120,https://qupath.github.io,https://github.com/qupath/qupath/issues/493#issuecomment-1791396738,1,['secur'],['secure-web']
Security,EventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$MouseHandler.process(Scene.java:3757); at javafx.scene.Scene$MouseHandler.access$1500(Scene.java:3485); at javafx.scene.Scene.impl_processMouseEvent(Scene.java:1762); at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2494); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:380); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:294); at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$354(GlassViewEventHandler.java:416); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:415); at com.sun.glass.ui.View.handleMouseEvent(View.java:555); at com.sun.glass.ui.View.notifyMouse(View.java:937); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$null$148(WinApplication.java:191); at java.lang.Thread.run(Thread.java:745),MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/422:3072,secur,security,3072,https://qupath.github.io,https://github.com/qupath/qupath/issues/422,2,"['Access', 'secur']","['AccessController', 'security']"
Security,EventDispatcher.java:58); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$MouseHandler.process(Scene.java:3757); at javafx.scene.Scene$MouseHandler.access$1500(Scene.java:3485); at javafx.scene.Scene.impl_processMouseEvent(Scene.java:1762); at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2494); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:380); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:294); at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$354(GlassViewEventHandler.java:416); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:415); at com.sun.glass.ui.View.handleMouseEvent(View.java:555); at com.sun.glass.ui.View.notifyMouse(View.java:937); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$null$148(WinApplication.java:191); at java.lang.Thread.run(Thread.java:745),MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/330:5716,secur,security,5716,https://qupath.github.io,https://github.com/qupath/qupath/issues/330,2,"['Access', 'secur']","['AccessController', 'security']"
Security,EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:238); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:191); at com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDispatcher.java:59); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:58); ERROR: QuPath exception; at qupath.lib.gui.viewer.QuPathViewer.updateSuggestedOverlayColorFromThumbnail(QuPathViewer.java:996); at qupath.lib.gui.viewer.QuPathViewer.getSuggestedOverlayColor(QuPathViewer.java:1005); at qupath.lib.gui.viewer.QuPathViewer.paintViewer(QuPathViewer.java:1665); at qupath.lib.gui.viewer.QuPathViewer.paintCanvas(QuPathViewer.java:413); at qupath.lib.gui.viewer.QuPathViewerPlus.paintCanvas(QuPathViewerPlus.java:249); at qupath.lib.gui.viewer.QuPathViewer.lambda$repaint$4(QuPathViewer.java:501); at com.sun.javafx.application.PlatformImpl.lambda$runLater$10(PlatformImpl.java:428); at java.base/java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.application.PlatformImpl.lambda$runLater$11(PlatformImpl.java:427); at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:96); at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); at com.sun.glass.ui.gtk.GtkApplication.lambda$runLoop$11(GtkApplication.java:277); at java.base/java.lang.Thread.run(Thread.java:834); ERROR: QuPath exception; at qupath.lib.gui.viewer.QuPathViewer.updateSuggestedOverlayColorFromThumbnail(QuPathViewer.java:996); at qupath.lib.gui.viewer.QuPathViewer.getSuggestedOverlayColor(QuPathViewer.java:1005); at qupath.lib.gui.viewer.QuPathViewer.paintViewer(QuPathViewer.java:1665); at qupath.lib.gui.viewer.QuPathViewer.paintCanvas(QuPathViewer.java:413); at qupath.lib.gui.viewer.QuPathViewerPlus.paintCanvas(QuPathViewerPlus.java:249); at qupath.lib.gui.viewer.QuPathViewer.lambda$repaint$4(QuPathViewer.java:501); at com.sun.javafx.application.PlatformImpl.lambda$runL,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/279#issuecomment-472375699:7348,secur,security,7348,https://qupath.github.io,https://github.com/qupath/qupath/issues/279#issuecomment-472375699,1,['secur'],['security']
Security,"Every time when I run a script, a temp file was generated in QuPath 0.2.0 but not 0.1.2. From the echo, Bioformats tries to delete the temp file, but the file path has one additional dot before the filename, so the deletion failed:. `6:23:09.798 [main] [WARN ] loci.formats.Memoizer - file deletion failed D:\QMDownload\5\os\.OS-3.vsi.bfmemo `. The file was ; `D:\QMDownload\5\os\OS-3.vsi.bfmemo ; `. After a successful running, all the output was:; ```; 16:23:06.071 [main] [INFO ] qupath.QuPath - Launching QuPath with args: -image, D:\\QMDownload\\5\\os\\OS-3.vsi, -script, C:\\Users\\rmd\\AppData\\Local\\Temp\\tpd56d11ce_e4ba_481c_a046_3d19297b763a.groovy ; 16:23:06.151 [main] [WARN ] q.lib.images.servers.FileFormatInfo - Strange 'bits per sample' of 0 ; 16:23:06.211 [main] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1 ; WARNING: An illegal reflective access operation has occurred ; WARNING: Illegal reflective access by com.esotericsoftware.kryo.util.UnsafeUtil (file:/C:/Program%20Files/QuPath-0.2.0-m1/app/kryo-2.24.0.jar) to constructor java.nio.DirectByteBuffer(long,int,java.lang.Object) ; WARNING: Please consider reporting this to the maintainers of com.esotericsoftware.kryo.util.UnsafeUtil ; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations ; WARNING: All illegal access operations will be denied in a future release ; 16:23:07.141 [main] [WARN ] loci.formats.Memoizer - deleting invalid memo file: D:\QMDownload\5\os\.OS-3.vsi.bfmemo ; com.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 429; Serialization trace:; service (loci.formats.in.OperettaReader); readers (loci.formats.ImageReader); reader (loci.formats.DimensionSwapper); reader (loci.formats.FileStitcher); helper (loci.formats.in.FilePatternReader); readers (loci.formats.ImageReader) ; 	at com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:119) ; 	at com.esotericsoftware.kryo.Kry",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/287:882,access,access,882,https://qupath.github.io,https://github.com/qupath/qupath/issues/287,2,['access'],['access']
Security,"Excellent, thanks - can confirm that; ```; ./gradlew clean run; ```; doesn't include the javadocs, but; ```; ./gradlew clean getJavadocs run; ```; does. And they are also included with; ```; ./gradlew clean jpackage; ```; Only minor comment is that `getJavadocs` doesn't seem a very gradle-ish task name and isn't so descriptive (use `gradlew tasks` to see all those that are available). What do you think of; ```; assembleJavadocs Copies the Javadoc jars to a directory for access within QuPath; ```; ?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1518#issuecomment-2097819235:475,access,access,475,https://qupath.github.io,https://github.com/qupath/qupath/pull/1518#issuecomment-2097819235,1,['access'],['access']
Security,Extended Validation Code Signing Certificate,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1605:9,Validat,Validation,9,https://qupath.github.io,https://github.com/qupath/qupath/issues/1605,2,"['Certificate', 'Validat']","['Certificate', 'Validation']"
Security,"FO: Completed!; INFO: ; qupath.imagej.superpixels.SLICSuperpixelsPlugin {""sigmaMicrons"": 1.0, ""spacingMicrons"": 5.0, ""maxIterations"": 20, ""regularization"": 0.9, ""adaptRegularization"": true}; INFO: Processing complete in 4.87 seconds; INFO: Completed!; ERROR: QuPath exception; at java.base/java.util.LinkedHashMap$LinkedHashIterator.nextNode(LinkedHashMap.java:719); at java.base/java.util.LinkedHashMap$LinkedKeyIterator.next(LinkedHashMap.java:741); at java.base/java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1045); at qupath.lib.gui.viewer.PathHierarchyPaintingHelper.paintSpecifiedObjects(PathHierarchyPaintingHelper.java:161); at qupath.lib.gui.viewer.overlays.HierarchyOverlay.paintOverlay(HierarchyOverlay.java:219); at qupath.lib.gui.viewer.QuPathViewer.paintViewer(QuPathViewer.java:1670); at qupath.lib.gui.viewer.QuPathViewer.paintCanvas(QuPathViewer.java:413); at qupath.lib.gui.viewer.QuPathViewerPlus.paintCanvas(QuPathViewerPlus.java:249); at qupath.lib.gui.viewer.QuPathViewer.lambda$repaint$4(QuPathViewer.java:501); at com.sun.javafx.application.PlatformImpl.lambda$runLater$10(PlatformImpl.java:428); at java.base/java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.application.PlatformImpl.lambda$runLater$11(PlatformImpl.java:427); at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:96); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:174); at java.base/java.lang.Thread.run(Thread.java:834); INFO: ; qupath.lib.algorithms.IntensityFeaturesPlugin {""pixelSizeMicrons"": 0.227, ""region"": ""ROI"", ""tileSizeMicrons"": 25.0, ""channel1"": true, ""channel2"": true, ""channel3"": true, ""doMean"": true, ""doStdDev"": false, ""doMinMax"": false, ""doMedian"": true, ""doHaralick"": false, ""haralickMin"": 0.0, ""haralickMax"": 1.0, ""haralickDistance"": 1, ""haralickBins"": 32}; INFO: Processing complete in 0.34 seconds; INFO: Completed!`",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/307#issuecomment-484610786:1955,secur,security,1955,https://qupath.github.io,https://github.com/qupath/qupath/issues/307#issuecomment-484610786,2,"['Access', 'secur']","['AccessController', 'security']"
Security,"Fantastic, that's a relief, thanks!; I saw those errors tile width/height too, only with MRXS files... but yes, they don't seem to cause trouble. For reference, this is what happened:; I recompiled OpenSlide for Mac back for v0.0.7, to address issues related to opening MRXS files with certain types of compression (possibly BMP or PNG). However, I appear to have accidentally included the previous versions of the library + dependencies in the Mac download, possibly because the machine on which I finally compiled the Mac version of QuPath for distribution had cached the original libraries, which had the same version number (since they traced back to the same version of OpenSlide). So v0.1.1 was the first download to actually contain the Mac OpenSlide updates intended for v0.0.7. And it turned out that those updates were missing a couple of required files, but which were available on my development machines... lulling me into a false sense of security that all was well. Anyhow, I've now repackaged OpenSlide + dependencies, added in the license notices for the additional required files, and bumped up the version number to 3.1.4_2 to make it clear which OpenSlide should be included in all future versions of QuPath compiled for Mac - regardless of machine. Outcome:; * OpenSlide included with the Mac distribution of v0.1.1 should be able to handle slightly more kinds of image than previous versions... but in the overwhelming majority of cases, it will look the same; * None of this matters for QuPath running on anything other than Mac; * I was never going to figure out there was a problem on my own, since it was working for me... so thanks for letting me know!",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/32#issuecomment-265679401:953,secur,security,953,https://qupath.github.io,https://github.com/qupath/qupath/issues/32#issuecomment-265679401,1,['secur'],['security']
Security,Files in project are not accessible anymore after software has an abnormal shutdown,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/512:25,access,accessible,25,https://qupath.github.io,https://github.com/qupath/qupath/issues/512,1,['access'],['accessible']
Security,"Fixed by ; * https://github.com/qupath/qupath/pull/1124; * https://github.com/qupath/qupath/pull/1125. Extra comment on the memory: the limit affects Java, but JavaCPP can potentially access more memory. Therefore the most memory-hungry thing (pixel classification) isn't strictly subject to the same limit. It should still be possible to specify the memory in the preferences on Windows/Linux, but this needs checked.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/986#issuecomment-1308396263:184,access,access,184,https://qupath.github.io,https://github.com/qupath/qupath/issues/986#issuecomment-1308396263,1,['access'],['access']
Security,"Fixes to coincide with https://github.com/qupath/qupath-fxtras/pull/11 Deprecate direct access to the `Preferences` object, since this can be invalidated by a call to reset (and then stops being usable).",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1331:88,access,access,88,https://qupath.github.io,https://github.com/qupath/qupath/pull/1331,1,['access'],['access']
Security,"Fixes to undo this fix:; * https://github.com/qupath/qupath/issues/1337. It turned out to be problematic in subtle ways. The main one was that there were strange permissions issues *that only emerged when the package was downloaded and installed* (not built locally). Basically, QuPath could no longer open images within its own project *unless* it had 'seen' them before in almost any interactive way (e.g. the images were opened via drag & drop, or even pasted into the script editor). When that was the case, the image opened fine consistently - and across restarts of QuPath, but not of the OS as a whole. For images QuPath hadn't seen, `new File(path).canRead()` would return false and there seemed to be no code-based way to convince it otherwise. The image-reading library didn't matter: OpenSlide, Bio-Formats, ImageJ all failed. Setting full disk access seemed promising, but ultimately didn't work consistently. The only workaround was to launch QuPath via a terminal, avoiding `launchd`. The hint that this was to blame came from; ```; tccutil reset SystemPolicyAllFiles QuPath-0.5; ```; producing an error and a report that the .plist had been modified... so macOS *knew*. Reverting this plist changes (and using Java 17) was sufficient to get things working again. The noticeable difference is that, when first trying to open an image, a system dialog pops up to ask whether QuPath can have access to Documents/Desktop/Downloads - which never happened with the change. Along the way, I learned that; * https://github.com/qupath/qupath/issues/1358. first emerged in JavaFX 20.0.1 so this PR also reverts to JavaFX 20 for now. I wanted to use Java 20 as well, but it complained when trying to build the `.pkg` from an existing `.app` because it didn't like the `app/.jpackage.xml` so that's why we're back on 17 for now.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1379:856,access,access,856,https://qupath.github.io,https://github.com/qupath/qupath/pull/1379,2,['access'],['access']
Security,"For 1. you didn't need to install OpenSlide yourself - just excluding/disabling Bio-Formats is enough, and QuPath should default to using OpenSlide. This has support for at least [some .scn](https://openslide.org/formats/leica/) files, but not necessarily all of them and I guess not yours. > Note: This is true for Windows, Mac and some variations of Linux. The default version of OpenSlide might not work currently on all kinds of Linux. For 2. I fully understand you need the full-resolution image; my point is that it may not be the full-resolution image that you have opened. If there are multiple images in the file and you drag it onto QuPath, then one of these multiple images will be displayed - but it might not be the full-resolution image you want. I describe in my last answer how you can access the other images in the file from within QuPath (either under the 'Image' tab or through a project). Nevertheless, if you need to rely on Bio-Formats then the 'pink' issue has to be resolved, and the problem appears to be in Bio-Formats and not QuPath. If it hasn't been fixed yet, then if you are able to export your image in another format (e.g. .svs) then this may help.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/141#issuecomment-435651179:802,access,access,802,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-435651179,1,['access'],['access']
Security,"Forcing it to use the red channel would require modifying the code for the dearrayer. This would not be easy to do in a straightforward way that doesn't break existing scripts for other users. It is difficult to help you further without access to your image, and just a screenshot showing one channel and no illustration of what 'the initial threshold fails' looks like. Did you use the script that I wrote for you when you asked a similar question in #77 ? You didn't reply. Can it not be used in this case?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/196#issuecomment-410767203:237,access,access,237,https://qupath.github.io,https://github.com/qupath/qupath/issues/196#issuecomment-410767203,1,['access'],['access']
Security,"Good way to win my support with the password ;). Ok, it took a while but I am reasonably sure it's a Bio-Formats issue. I also couldn't find a problem with the `RandomAccessInputStream`, but it turns out that this isn't the code that's being called; rather it calls instead ; https://github.com/ome/ome-common-java/blob/94fe420a95f7859839e09e84185bc31107ba0b72/src/main/java/loci/common/RandomAccessInputStream.java#L590. I didn't trace through the (rather more complicated) logic but I can confirm with a debugger that this consistently returns a NULL at the end of the image name with the `SISReader`... including for other SIS files that I found posted on image.sc. Taking QuPath (mostly) out of the equation, this script demonstrates that the null occurs:; ```groovy; import loci.formats.MetadataTools. def path = ""/path/to/image.tif"". def reader = new loci.formats.ImageReader(); reader.setMetadataStore(MetadataTools.createOMEXMLMetadata()); reader.setId(path). def name = reader.getMetadataStore().getImageName(0); println ""Name: ${name} (length = ${name?.length()})""; if (name && name[-1] == (char)0); println 'NULL found to terminate string'; ```. With that in mind, I think it may be worth reporting to the Bio-Formats team to see if they consider this to be wrong or not. On the QuPath side, it *could* check for NULL at the point when the image name is requested from Bio-Formats. I feel like this would remove any weirdness at its source. It might be possible to smuggle a NULL into the results table some other way, but I don't see an obvious path to achieving that... so I don't think the copy-to-clipboard thing should be changed.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/573#issuecomment-664566676:36,password,password,36,https://qupath.github.io,https://github.com/qupath/qupath/issues/573#issuecomment-664566676,1,['password'],['password']
Security,"Good! To answer your question:. ```QP``` is inside the 'core' modules, which means it doesn't know anything about the GUI. ```QPEx``` is a subclass of ```QP``` that lives inside the GUI module - which has access to all the core modules too. Therefore ```QPEx``` adds extra GUI-related methods (e.g. to request the QuPathGUI instance, or viewers) that aren't available within ```QP```. *Potentially*, if you only rely on ```QP```, you could run a script headlessly, and completely independent of the QuPath GUI. If instead you run your scripts from QuPath directly, then you may as well use ```QPEx```. It should do the same, but also give you access to more stuff if you need it.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/102#issuecomment-332441466:205,access,access,205,https://qupath.github.io,https://github.com/qupath/qupath/issues/102#issuecomment-332441466,2,['access'],['access']
Security,Gson-related method was previously emitted:; WARNING: Illegal reflective access by com.google.gson.internal.reflect.UnsafeReflectionAccessor caused by AffineTransform,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/537:73,access,access,73,https://qupath.github.io,https://github.com/qupath/qupath/pull/537,1,['access'],['access']
Security,"Haha, I mean the ability to have access to a list! It has always been something I missed in more complex classifiers. . Thanks for the link, it has been a while since i used Weka, but I may give that a try the next time I want to trim down or adjust my input selection.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424771491:33,access,access,33,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424771491,1,['access'],['access']
Security,"Hello everyone. Is it possible to run Qupath software on a server. I mean, if I have a collection of digital slides on an internal server (inside an organisation), is it possible to run it from different client PCs as if it were a web viewer? to access and analize digital slides?; Thank you.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/100:246,access,access,246,https://qupath.github.io,https://github.com/qupath/qupath/issues/100,1,['access'],['access']
Security,"Hello, . I was interested in using qupath.imagej.detect.cells.ObjectMeasurements in a package I am creating separately, but this class is currently package-private.; https://github.com/qupath/qupath/blob/c5cc1895f5ff6ff94b2431b4b2ede7fad78b071f/qupath-core-processing/src/main/java/qupath/imagej/detect/cells/ObjectMeasurements.java#L42. Would it be possible to have access to this class outside the package? I can use it in a script within QuPath without issues, but not in Java... . Thank you for any help/comments. . All the best. Oli",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/466:367,access,access,367,https://qupath.github.io,https://github.com/qupath/qupath/issues/466,1,['access'],['access']
Security,"Hello, we are using it on a Windows machine and Macs (with Big Sur, Catalina and Mojave OS). When sharing screen on Teams from windows, it is great. When sharing screen on teams (or Zoom) from Mac, the main view is shared, but the ""box"" that shows the adjustments as they are being made (brightness etc) is not shared with any of the three Macs (with different OS) we tried. I have given full disk access etc as much as I could figure it, but maybe there are settings I haven't identified. It will be great if we can solve this; thanks,; christos",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/693:398,access,access,398,https://qupath.github.io,https://github.com/qupath/qupath/issues/693,1,['access'],['access']
Security,"Hi @MarkZaidi I agree with @MichaelSNelson that that sounds like a very large classifier... large enough that I think it would be reasonable for QuPath not to support it, although ideally it wouldn't fail with an exception. I can't really feasibly use the 'steps to reproduce'. Is there any chance you can replicate the problem with a more manageable/minimal dataset - preferably of publicly-accessible images?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/947#issuecomment-1092019624:392,access,accessible,392,https://qupath.github.io,https://github.com/qupath/qupath/issues/947#issuecomment-1092019624,1,['access'],['accessible']
Security,"Hi @vladpopovici . There's more info about this behavior on the user forum [here](https://forum.image.sc/t/qupath-is-cropping-white-background-in-whole-slide-image-how-to-avoid-this-behavior/40853/2). Basically, you'll need to get the bounding box coordinates from OpenSlide. You can do this either from within a Groovy script in QuPath, or later by accessing OpenSlide through Python. Pete. PS. I'll close this as an issue because the [forum](http://forum.image.sc/tag/qupath) is really the best place for non-bug-related QuPath questions. PPS. Nice to see QuPath could be useful for you, I recognize your name from [this](https://doi.org/10.1093/bioinformatics/btx027) :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/820#issuecomment-919160755:350,access,accessing,350,https://qupath.github.io,https://github.com/qupath/qupath/issues/820#issuecomment-919160755,1,['access'],['accessing']
Security,"Hi Adam, the problem is access to the images - for which I can see you're using a custom extension, and not something that's part of QuPath itself. I got an email about this issue a while back; the conclusion then was that if you can access the .svs image files directly, rather than via the extension, the problem should go away. I'll close the issue here because it isn't really within QuPath itself. If you can send me an email (or track me down on ResearchGate, LinkedIn, Twitter or elsewhere) then I can discuss it further there. The missing annotations thing is a bit of a mystery, and may or may not be connected. If you can find a way to reproduce it please let me know.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/174#issuecomment-390186531:24,access,access,24,https://qupath.github.io,https://github.com/qupath/qupath/issues/174#issuecomment-390186531,2,['access'],['access']
Security,"Hi Georgia,; Could you try using _Edit &rarr; Reset Preferences_?; If that resolves the issue then I think the QuPath isn't able to find some path to scripts. I'm not sure why (maybe a directory is missing or located on a server that isn't accessible?) and it shouldn't cause an error like this so I'll investigate anyway on the QuPath side.; If the doesn't resolve it then I'm not sure what the problem could be.... does it happen with all projects or just one?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/373#issuecomment-549758228:240,access,accessible,240,https://qupath.github.io,https://github.com/qupath/qupath/issues/373#issuecomment-549758228,1,['access'],['accessible']
Security,"Hi Sorry for the delay, I replicated the steps with a clean installation no plugins and saw the same access to the files. I went to the registry and it shows the paths for the first user that installed QuPath, . did a quick search and it seems that it can be a problem with the msix packages, ; https://techcommunity.microsoft.com/t5/msix/registry-keys-created-after-installation-and-left-behind-after/m-p/1802357. [QuPath Clean installation.pdf](https://github.com/qupath/qupath/files/9973964/QuPath.Clean.installation.pdf)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1108#issuecomment-1309180858:101,access,access,101,https://qupath.github.io,https://github.com/qupath/qupath/issues/1108#issuecomment-1309180858,1,['access'],['access']
Security,"Hi Svidro,; thank you for your suggestions. The problem is, that I need all the 4 channels to analyze co-expression of markers. Hence, exporting every image twice is not feasible (and too slow). ; Could you explain to me why is it so problematic to access more than 3 channels? . Cheers,; Mario",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/49#issuecomment-278264549:249,access,access,249,https://qupath.github.io,https://github.com/qupath/qupath/issues/49#issuecomment-278264549,1,['access'],['access']
Security,"Hi again,. I compiled the pete-java11 branch (after some ubuntu debugging). Sadly I had to compile it on a local laptop with low memory (until I get back to the lab). So take this into account (the log suggest that RAM is the problem on this machine). Here are my file links:. cropped : https://owncloud.ulb.ac.be/index.php/s/ReltLIepwxOZ2RK; fullsize : https://owncloud.ulb.ac.be/index.php/s/VhuHZheRNHgdUqk; PASSWORD: qupathBug ; Expires: march 17 2019. On my main machine I noticed that when opening the cropped version, qupath opens it after some minutes of intensive cpu calculations. This seems to suggest that qupath is precomputing something instead of directly opening the file. I tried opening my files and those from NHPatterson. As of yet it seems to still not be working. LOG DUMP; ```; INFO: Bio-Formats version 6.0.0; ERROR: Could not load OpenSlide native libraries; at java.base/java.lang.ClassLoader.loadLibrary(ClassLoader.java:2660); at java.base/java.lang.Runtime.loadLibrary0(Runtime.java:829); at java.base/java.lang.System.loadLibrary(System.java:1867); at org.openslide.OpenSlideJNI.<clinit>(OpenSlideJNI.java:55); at org.openslide.OpenSlide.<clinit>(OpenSlide.java:53); at qupath.lib.images.servers.openslide.OpenslideServerBuilder.<clinit>(OpenslideServerBuilder.java:87); at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490); at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:779); at java.base/java.util.ServiceLoader$ProviderImpl.get(ServiceLoader.java:721); at java.base/java.util.ServiceLoader$3.next(ServiceLoader.java:1394); at qupath.lib.images.servers.ImageServerProvider.getIn",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/279#issuecomment-472375699:410,PASSWORD,PASSWORD,410,https://qupath.github.io,https://github.com/qupath/qupath/issues/279#issuecomment-472375699,1,['PASSWORD'],['PASSWORD']
Security,"Hi all, . I have pushed a solution to this on my fork this morning (link [here)](https://github.com/melvingelbard/qupath-forked/tree/scriptArgs). It uses Picocli to parse the unmatched args (as @zindy mentioned I believe), which are then accessible through the `args` variable in the current running script. `args` is a simple `String[]`, so no fancy further parsing is performed on it. Not sure whether that was the original plan..; What do you think of this implementation?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/647#issuecomment-741805565:238,access,accessible,238,https://qupath.github.io,https://github.com/qupath/qupath/pull/647#issuecomment-741805565,1,['access'],['accessible']
Security,"Hi, ; I was hoping someone could help me out here. I am currently trying to set up and building QuPath on Eclipse and I keep running into a compilation error in multiple GUI classes. They're all the same errors: refresh() has private access/is not visible in javafx.scene.control.TableView. ; I am very confused especially because I have not made any changes to the code and so if someone could help me out, that would be great! ; Thanks in advance!",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/87:234,access,access,234,https://qupath.github.io,https://github.com/qupath/qupath/issues/87,1,['access'],['access']
Security,"Hi, I'm getting the following bug when launching QuPath from a ssh server:. WARNING: Unsupported JavaFX configuration: classes were loaded from 'unnamed module @62379589'; Exception in thread ""main"" java.lang.UnsupportedOperationException: Unable to open DISPLAY; at com.sun.glass.ui.gtk.GtkApplication.lambda$new$5(GtkApplication.java:165); at java.base/java.security.AccessController.doPrivileged(Unknown Source); at com.sun.glass.ui.gtk.GtkApplication.<init>(GtkApplication.java:163); at com.sun.glass.ui.gtk.GtkPlatformFactory.createApplication(GtkPlatformFactory.java:40); at com.sun.glass.ui.Application.run(Application.java:145); at com.sun.javafx.tk.quantum.QuantumToolkit.startup(QuantumToolkit.java:290); at com.sun.javafx.application.PlatformImpl.startup(PlatformImpl.java:292); at com.sun.javafx.application.PlatformImpl.startup(PlatformImpl.java:162); at com.sun.javafx.application.LauncherImpl.startToolkit(LauncherImpl.java:651); at com.sun.javafx.application.LauncherImpl.launchApplication1(LauncherImpl.java:671); at com.sun.javafx.application.LauncherImpl.lambda$launchApplication$2(LauncherImpl.java:196); at java.base/java.lang.Thread.run(Unknown Source). Anyone knows why this is happening?. Using latest version QuPath and JDK 17, but nothing seems to work",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1547:360,secur,security,360,https://qupath.github.io,https://github.com/qupath/qupath/issues/1547,2,"['Access', 'secur']","['AccessController', 'security']"
Security,"Hi, had similar issues as we have multiple backups of our files on different external hardrives. It is possible however to reassign the letter of each hardrive by going into administrative tools, see below. Open the Start menu, and type ""Administrative Tools"" in the search box. Click it in the list that appears and then double-click ""Computer Management."" Enter your administrator password if Windows asks for it. Click the ""Disk Management"" link, and then click your external hard drive's assigned disk. Right-click the disk and click ""Change Drive Letters and Paths."". Click the ""Change"" button and click ""Assign the Following Drive Letter."" Click the new letter to assign to your external hard drive and click ""OK"" to save your change. This way as long as the files and folder structures within the hardrive remain the same all that you need to change is the letter of the hardrive so that it is the same as the original that it was stored on.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/114#issuecomment-487867515:383,password,password,383,https://qupath.github.io,https://github.com/qupath/qupath/issues/114#issuecomment-487867515,1,['password'],['password']
Security,"Hi, joining a bit late.... part of one of the suggestions above contained:; ```groovy; getDetectionObjects().parallelStream().forEach({Polygon ->; img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, Polygon.getROI())); ImageIO.write(img, 'JPEG', new File(dirOutput, Polygon.getName() + '.jpg')); }); ```. If you want to keep that kind of concise way of looping, `eachWithIndex` might help. The corresponding part might look something like this:; ```groovy; getDetectionObjects().eachWithIndex {pathObject, index ->; def img = server.readBufferedImage(RegionRequest.createInstance(path, downsample, pathObject.getROI())); def name = pathObject.getDisplayedName() + '_' + index + '.jpg'; ImageIO.write(img, 'JPEG', new File(dirOutput, name)); }; ```. I also used `getDisplayedName()`; if no name has been set, this will try to come up with something else useful for that object (e.g. the classification). And I added `def`, which you don't really need but it keeps the variables local (otherwise you could likely access them after the loop).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/118#issuecomment-346934805:1037,access,access,1037,https://qupath.github.io,https://github.com/qupath/qupath/issues/118#issuecomment-346934805,1,['access'],['access']
Security,"Hi, this looks to be the same issue as #74 . It should only affect images that are being read with ImageJ, because of the way in which a cropped region is extracted (when you're unlucky, a second thread might call ```setRoi``` at an inopportune moment). One potential quick fix in the code could be to make [this method](https://github.com/qupath/qupath/blob/v0.1.2/qupath-extension-ij/src/main/java/qupath/imagej/images/servers/ImageJServer.java#L175) synchronized, although this could be refined a bit further. To the best of my knowledge, images accessed any other way (including all whole slide images) should be unaffected. This should be fixed in the next QuPath update. In the meantime, restricting the number of threads should work too.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/110#issuecomment-336955291:549,access,accessed,549,https://qupath.github.io,https://github.com/qupath/qupath/issues/110#issuecomment-336955291,1,['access'],['accessed']
Security,"Hi,. I'm getting an error when loading my classifier, which has previously been working absolutely fine. I am able to bypass the issue on closing and reopening the file. This has been happening for 2 days. I have copied and pasted the classifier for my colleague to use, however she's now getting the same error but it won't resolve for her on reopening the file. Is there something we're doing wrong or is this a software problem? Can you let me know how I can fix it/when the issue will be resolved?. Thanks,. Cam. The error message is as follows:; INFO: Selected style: Modena Light; INFO: Performing update check...; INFO: Starting QuPath with parameters: [N:\Faculty-of-Medicine-and-Health\LICAP\DATA\PTHY\Pathology\Breast Group\BCCTB Samples\Audits\BCN QA 2017\Frozen samples QuPath tumourstromaratio\Batch_2\Tumour\402428.svs]; INFO: Test reading thumbnail with openslide: passed (BufferedImage@5d207157: type = 1 DirectColorModel: rmask=ff0000 gmask=ff00 bmask=ff amask=0 IntegerInterleavedRaster: width = 193 height = 200 #Bands = 3 xOff = 0 yOff = 0 dataOffset[0] 0); INFO: Returning server: OpenSlide for N:\Faculty-of-Medicine-and-Health\LICAP\DATA\PTHY\Pathology\Breast Group\BCCTB Samples\Audits\BCN QA 2017\Frozen samples QuPath tumourstromaratio\Batch_2\Tumour\402428.svs; INFO: Estimating H & E staining; INFO: Image data set to ImageData: Brightfield (H&E), 402428; INFO: 1 region detected (processing time: 215.44 seconds); INFO: Processing complete in 215.63 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.tissue.SimpleTissueDetection2 {""threshold"": 219, ""requestedPixelSizeMicrons"": 2.0, ""minAreaMicrons"": 20.0, ""maxHoleAreaMicrons"": 200.0, ""darkBackground"": false, ""smoothImage"": true, ""medianCleanup"": true, ""dilateBoundaries"": false, ""smoothCoordinates"": true, ""excludeOnBoundary"": false, ""singleAnnotation"": true}; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; INFO: Adding Area (AWT) to hierarchy; ",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160:748,Audit,Audits,748,https://qupath.github.io,https://github.com/qupath/qupath/issues/160,1,['Audit'],['Audits']
Security,"Hi,. Is it possible to export ""contours"" delineating different cell types from one another in quPath (or possible to access some data which might make that easy enough to script? I realize that quPath strives at doing the classification it on a cell-cell basis, but possibly iso-lines from heatmaps produced by the ""Add Smoothed Features"" command would do the trick. Best,; Colin",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/70:117,access,access,117,https://qupath.github.io,https://github.com/qupath/qupath/issues/70,1,['access'],['access']
Security,"Hi,. we've scanned fluorescence slides in MRXS format. The scans have 4 color channels (DAPI, FITC, TRITC, Cy5). But when opened with Qupath, we can only access the first 3 (mislabeled as RGB).; I guess this is more an issue with openslide rather than Qupath, but I couldn't find any information about that on the openslide page and wanted to check. Best regards,; Mario",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/49:154,access,access,154,https://qupath.github.io,https://github.com/qupath/qupath/issues/49,1,['access'],['access']
Security,"Hi:. The latest release of the QuPath v0.5.1:. [QuPath-v0.5.1-Mac-arm64.pkg](https://github.com/qupath/qupath/releases/download/v0.5.1/QuPath-v0.5.1-Mac-arm64.pkg); [QuPath-v0.5.1-Mac-x64.pkg](https://github.com/qupath/qupath/releases/download/v0.5.1/QuPath-v0.5.1-Mac-x64.pkg). The issue with Mac applications that use ad-hoc signatures is that, while they provide a code signing digest (or cdhash) allowing macOS to verify whether the app or component has been altered, they don't verify the identity of the developer. This means that macOS can detect if the code has changed but has no way to confirm who signed the code or if it comes from a trusted source. Key concerns with ad-hoc signatures include:. No Developer Identity Verification: Ad-hoc signatures don’t provide information about the developer’s identity, unlike certificates from Apple, which are linked to verified developer accounts. This can pose security risks as it’s harder to establish trust in the source of the code. Limited Use Cases: Ad-hoc signing is typically used for specific scenarios, such as:; Unsigned code running on Apple Silicon, where macOS requires all code to be signed, even if it’s just ad-hoc.; Web Apps on macOS 14 Sonoma, where the code isn't distributed via traditional app distribution methods. Security Risks: Since there is no certification authority involved in ad-hoc signing, it is easier for malicious or unauthorized code to be signed ad-hoc and executed, which could expose the system to potential vulnerabilities. I would recommend moving away from ad-hoc certificates and following the Apple Developer guidelines on application creation & distribution. For example, here is a free GUI application called ""Apparency"" that will help explain issues and test your applications.; https://mothersruin.com/software/Apparency/. ![image](https://github.com/user-attachments/assets/d69830e4-e271-430a-987c-c58b1b708481); ![image](https://github.com/user-attachments/assets/4a03b7ba-c911-486b-91de-2d86d0e",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1672:827,certificate,certificates,827,https://qupath.github.io,https://github.com/qupath/qupath/issues/1672,2,"['certificate', 'secur']","['certificates', 'security']"
Security,Hi; Computer: Dell Latitude with touchpad. No graphics tablet/pen used at the moment. The firs error message was created using the wand. While playing around with the bit a bit I managed to get a slightly different error message... `ERROR: QuPath exception: Points of LinearRing do not form a closed linestring; at org.locationtech.jts.geom.LinearRing.validateConstruction(LinearRing.java:90); at org.locationtech.jts.geom.LinearRing.<init>(LinearRing.java:85); at org.locationtech.jts.geom.GeometryFactory.createLinearRing(GeometryFactory.java:356); at org.locationtech.jts.geom.GeometryFactory.createLinearRing(GeometryFactory.java:343); at org.locationtech.jts.util.GeometricShapeFactory.createEllipse(GeometricShapeFactory.java:231); at qupath.lib.gui.viewer.tools.BrushTool.createShape(BrushTool.java:489); at qupath.lib.gui.viewer.tools.BrushTool.getUpdatedObject(BrushTool.java:326); at qupath.lib.gui.viewer.tools.BrushTool.mouseDragged(BrushTool.java:302); at qupath.lib.gui.viewer.tools.AbstractPathTool.lambda$registerTool$0(AbstractPathTool.java:333); at com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:238); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:191); at com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDispatcher.java:59); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:58); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchCha,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/380#issuecomment-561071266:352,validat,validateConstruction,352,https://qupath.github.io,https://github.com/qupath/qupath/issues/380#issuecomment-561071266,1,['validat'],['validateConstruction']
Security,"Hmmm, this isn't a scenario I ever had to deal with myself... it looks like an unfortunate limitation of how the project arranges ```.qpdata``` files simply according to the image name stored for the entry in the image. There's no 'good' way to fix it currently, unless you're willing to put all your images in separate projects... which would kind of defeat the purpose of using a project. So you could try this as a workaround:. ```groovy; guiscript=true. // Get QuPath & project; def qupath = getQuPath(); def project = qupath.getProject(). // Loop through images, setting the name; // (actually accessing a private field... therefore 'bad'); project.getImageList().each {; def path = it.getServerPath(); int ind = path.lastIndexOf(':'); def scene = path[ind+1..-1]; def name = new File(path[0..ind-2]).getName(); it.putMetadataValue('Slide_ID', name); it.imageName = name + ' (' + scene + ')'; print it.imageName; }. // Need to set to null first to force update; qupath.setProject(null); qupath.setProject(project). // Be very careful is you use this to write the project!; // The logic is a bit weird and it will probably overwrite ; // the existing project - so duplicate your .qpproj file to be safer; //qupath.lib.projects.ProjectIO.writeProject(project); ```. Basically, this should rename the images in the project to include both the original file name and the scene. This should then be used by QuPath when arranging the ```.qpdata``` files afterwards. It won't automatically update the names of any existing data files - this would have to be done manually. It has the added bonus of setting the 'Slide_ID' keyword; if you right-click on the project, you can then choose to *Sort by &rarr; Slide ID*.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/103#issuecomment-332598953:599,access,accessing,599,https://qupath.github.io,https://github.com/qupath/qupath/issues/103#issuecomment-332598953,1,['access'],['accessing']
Security,"Hmmm, well the problem certainly seems to be related to OpenCV being unable to load. Perhaps the binaries from JavaCPP are not supported on your system? But then it would be weird if the pre-build QuPath can use them (e.g. via the wand tool, pixel/object classifiers)... Is there any reason you need to build from source, rather than use the pre-built binaries?. Since I'm unable to replicate the problem on any computer I have access to, I'm really not sure I can help much further. Anything else I suggest to try would be a complete guess.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/484#issuecomment-633265261:428,access,access,428,https://qupath.github.io,https://github.com/qupath/qupath/issues/484#issuecomment-633265261,1,['access'],['access']
Security,"How bad is this really...?. I remember from conversations with @melvingelbard that validating numbers in a text field is far from straightforward... at least if trying to handle `+-.,e`. These might be used for valid numbers, but at the point they are typed the text may not be a valid number. He wrote [this method](https://github.com/qupath/qupath-fxtras/blob/007d91581049d7fd9439fd233211dcecf44d8fef/src/main/java/qupath/fx/utils/FXUtils.java#L260) to help sort that. ControlsFX doesn't handle this so well: you can see it in the preference pane, built using ControlsFX. Find a numeric field, e.g. `Brush diameter`. You can type `50` but you *cannot* type `-50` in the usual way. But you *can* type `50` and then go back to add the `-` (or even `+`). It seems to use a validation that is much too eager. I find this to be more annoying and problematic, so the `ParameterPanelFX` errs on the side of 'type anything, it's up to you for it to make sense'. The main thing is that we shouldn't through exceptions too quickly. But you could try switching the parameter pane to use Melvin's method linked above and see if it behaves better. In any case, I think a solution belongs in `qupath-fxtras` since it is so fiddly. For the number of bins, you can set an upper limit on the parameter - but this will have the effect of using a slider instead. That might be fine in this case; if you need more customisation, then it'd be better to avoid `Parameter` altogether and just got straight to JavaFX (which could be preferable for the measurement table histograms since then it'd be easier to make the selections persistent).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1541#issuecomment-2162178336:83,validat,validating,83,https://qupath.github.io,https://github.com/qupath/qupath/issues/1541#issuecomment-2162178336,2,['validat'],"['validating', 'validation']"
Security,"However, I haven't got that to work with _all_ plugins and functionality of Fiji because of conflicts in dependencies... or perhaps just because I don't know enough about the ImageJ2 API. That might well be solvable if it turns out to be necessary, but it hasn't been something I've needed myself or anyone else has asked for yet (that I recall). Direct export of ROIs only wouldn't help most QuPath applications, for the reasons outlined above (i.e. most are for whole slide images, in which case you'll need to scale the image as well - and then exporting the pixels as well as the ROIs is necessary, which _is_ possible). But I appreciate that it makes sense in your case. Just to be clear: you should be able to run the script unchanged across your entire folder if you just add all the images to a QuPath project, and choose _Run &rarr; Run for project (without save)_ from the QuPath script editor. Because that script doesn't make changes, there's no point saving the (same) results after running the script to update the `.qpdata` files... although it also shouldn't matter if you do. Regarding documentation, at the time of the QuPath's release I was in the process of leaving the university where I wrote it, and lacked the time and resources to document the API and find somewhere to host it; also, I didn't consider it stable enough at that point anyway, and planned to continue working on it. For reasons largely beyond my control this wasn't possible, unfortunately, but you can access a lot of the existing Javadocs through setting up scripting with IntelliJ (and indeed a similar process works to set up IntelliJ for Groovy scripting with Fiji). In a couple of months I will start a new position and be able to manage QuPath as a more active open source project - and be a bit stricter with myself about compiling the Javadocs and finding a home for them. In the meantime, there is some additional documentation and developments described on [my blog](https://petebankhead.github.io).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/182#issuecomment-401622161:2012,access,access,2012,https://qupath.github.io,https://github.com/qupath/qupath/issues/182#issuecomment-401622161,1,['access'],['access']
Security,"I am sorry, I must have missed this message!. In my case, I was thinking to help extensions I use to take full advantage of this new feature. Specifically, I was looking into [`qupath-extension-abba`](), but the only thing stopping me from being able to port it is that [it checks](https://github.com/BIOP/qupath-extension-abba/blob/main/src/main/java/qupath/ext/biop/abba/AtlasImporter.java#L203) whether the current image is rotated or not. If it is, it applies a transformation to the imported ROIs. I guess interrogating specific image server is unfeasible (i.e. using `rotated_server.getRotation()`), however we could perhaps avoid requesting for the server if it can't be interrogated. Hence why I was thinking to expose the builders: extensions/scripts can decide whether to make the server concrete based on their implementation.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1489#issuecomment-2396452661:720,expose,expose,720,https://qupath.github.io,https://github.com/qupath/qupath/pull/1489#issuecomment-2396452661,1,['expose'],['expose']
Security,"I attempted to replicate this on a standard system (Win10 Pro, no active directory, no abnormal group policy) and was not able to. The normal user with the admin installed QuPath was not able to access any of the admin folders, nor could they see projects that had been opened/created by the admin user.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1108#issuecomment-1309474176:195,access,access,195,https://qupath.github.io,https://github.com/qupath/qupath/issues/1108#issuecomment-1309474176,1,['access'],['access']
Security,"I did this with `egrep -rl ""Files\.exists\(\w+\)"" | xargs sed -E -i 's/Files\.exists\((\w+)\)/\1.toFile().exists()/g'` so there's a non-zero chance I missed some usages (anything with a method or field access in the something of `Files.exists(something)` will be missed) and a small chance I broke something, but I didn't want the regex to get too complex. Based on apparently slow performance, see; https://rules.sonarsource.com/java/RSPEC-3725/. https://github.com/qupath/qupath-extension-wsinfer/pull/30; https://github.com/qupath/qupath/issues/1154#issuecomment-1327044045",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1298:202,access,access,202,https://qupath.github.io,https://github.com/qupath/qupath/pull/1298,1,['access'],['access']
Security,"I do not have access to a TMA at the moment but are those cores set to ""missing"" (they would have a lighter core outline)?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/96#issuecomment-326020294:14,access,access,14,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-326020294,1,['access'],['access']
Security,"I don't recall any memoization-related changes in v0.3.0-SNAPSHOT, except for the fact it will be using a different JDK and updated version of Bio-Formats itself. Unless I'm missing a key part, the git blame suggests the memoization code was last changed 2 years ago. v0.2 made a change from v0.1.2 to no longer store the .bfmemo files in the same directory as the image, because this was causing problems for some users and confusion with new files being generated unexpectedly. Since v0.2, you can specify a memoization directory in the preferences, and also a memoization time in ms. If the time is <= 0, then no memoization files should be created. Otherwise, a file will be [generated either in the specified directory or in a temp directory](https://github.com/qupath/qupath/blob/dev-0.3/qupath-extension-bioformats/src/main/java/qupath/lib/images/servers/bioformats/BioFormatsImageServer.java#L1314). Could it be that you have a directory set in the preferences? If you don't, I would expect the memoization files to be temporary and automatically removed. In any case, the warning you see has been [logged by Bio-Formats](https://github.com/ome/bioformats/blob/25645389e076a7bd0011e04c4dd8982c0f0614ed/components/formats-bsd/src/loci/formats/Memoizer.java#L923). I don't know why it is unable to delete the file, but my guess is that it relates in some way to https://github.com/ome/bioformats/issues/3659 and the fact QuPath is now using Java 16. This is likely to cause various memoization problems involving kyro. I can think of two potential workarounds:; * Add `--illegal-access=warn` to the Java options for QuPath (based on [this](https://openjdk.java.net/jeps/396)); * Turn off memoization entirely, at least by default. I'm not sure which is preferable; neither feels great. I think you should be able to try the first option by editing the `.cfg` file - if you try, please let me know if it works",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/717#issuecomment-828490219:1585,access,access,1585,https://qupath.github.io,https://github.com/qupath/qupath/issues/717#issuecomment-828490219,1,['access'],['access']
Security,"I don't think changing the extension of .qpdata files works here, and this may be the source of not being able to access it - would need to zip up the original file. But note that the cell count is never shown when an annotation is *classified* in that location in QuPath v0.1.2. It's also not an ideal place to get this number, because it is not actually a cell count but rather a count of the number of *direct child objects*. This should be the same as the cell count if there are no other objects (e.g. nested annotations), but otherwise it may not be. In my own QuPath fork I've added a detection count to the main built-in measurements for all annotations, which looks deeper through the hierarchy to get all cells - even if they are inside nested annotations. This works also for unclassified cells, but in v0.1.2 counts are only provided if the cells are classified. As a workaround in v0.1.2 you could set your cells to have any arbitrary class, e.g.; ```groovy; getCellObjects().each { it.setPathClass(getPathClass('My cell')) }; fireHierarchyUpdate(); ```; Then they should at least appear in any annotation measurement tables.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/147#issuecomment-365536462:114,access,access,114,https://qupath.github.io,https://github.com/qupath/qupath/issues/147#issuecomment-365536462,1,['access'],['access']
Security,"I edited the code to try that but I still got the following error: . ````; ERROR: Error: startup failed:; Script53.groovy: 45: unable to resolve class ImagePlusServer ; @ line 45, column 17.; ImagePlusServer server = ImagePlusServerBuilder.ensureImagePlusWholeSlideServer(serverOriginal); ^. 1 error. ERROR: Script error; at org.codehaus.groovy.control.ErrorCollector.failIfErrors(ErrorCollector.java:311); at org.codehaus.groovy.control.CompilationUnit.applyToSourceUnits(CompilationUnit.java:980); at org.codehaus.groovy.control.CompilationUnit.doPhaseOperation(CompilationUnit.java:647); at org.codehaus.groovy.control.CompilationUnit.compile(CompilationUnit.java:596); at groovy.lang.GroovyClassLoader.doParseClass(GroovyClassLoader.java:390); at groovy.lang.GroovyClassLoader.access$300(GroovyClassLoader.java:89); at groovy.lang.GroovyClassLoader$5.provide(GroovyClassLoader.java:330); at groovy.lang.GroovyClassLoader$5.provide(GroovyClassLoader.java:327); at org.codehaus.groovy.runtime.memoize.ConcurrentCommonCache.getAndPut(ConcurrentCommonCache.java:147); at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:325); at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:309); at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:251); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.getScriptClass(GroovyScriptEngineImpl.java:331); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:153); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:767); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:697); at qupath.lib.gui.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.gui.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1034); at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515); at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/309#issuecomment-484643330:781,access,access,781,https://qupath.github.io,https://github.com/qupath/qupath/issues/309#issuecomment-484643330,1,['access'],['access']
Security,"I explored a bit more, and it turns out that I had already done most of the difficult part in storing annotation descriptions, and what remains is to make them accessible. I had a quick look (the code is on my fork of QuPath) and can add descriptions to both the images and the annotations. Currently, the annotation descriptions are just displayed as a tooltip under the 'Annotations' tab; they need a better home eventually. I won't get a chance to look further for at least the next few days, but to answer your questions:. > Do you save description data to the image files or to the qpproj file?. Currently to the `.qpproj` file. This is just JSON and can be opened in any text editor. > Are the annotations stored to the project or to the image?. In the `.qpdata` file. This is a binary file, which is in a trickier format (using Java serialization). Potentially these files can be large and complex, storing the relationship between millions of objects (annotations, cells...). But in your case they might be very small, and easily parse-able in a script.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/144#issuecomment-364498226:160,access,accessible,160,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-364498226,1,['access'],['accessible']
Security,"I guess that is some GLX problem. X11 forwarding with GL has its own set of quirks. This might be of interest:; askubuntu.com/questions/745135/how-to-enable-indirect-glx-contexts-iglx-in-ubuntu-14-04-lts-with-nvidia-gfx. BTW, we are running a similar setup but use xrdp to provide remote access to Windows and Linux machines via RDP. It works with qupath (but graphic output is not accelerated, of course).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/109#issuecomment-360180072:288,access,access,288,https://qupath.github.io,https://github.com/qupath/qupath/issues/109#issuecomment-360180072,1,['access'],['access']
Security,"I had a quick look on my local version of the code, where I've been exploring new things. Here's a screenshot:. ![image_descriptions](https://user-images.githubusercontent.com/4690904/35859449-04d0dfd2-0b38-11e8-9696-f549f97208d4.jpg). I've added the description to the 'Project' tab rather than the 'Image' tab, so that it can be accessible without actually opening the image at all. In this instance, the description that is shown depends upon which image entry is *selected* (i.e. blue), which is potentially different from the image that is actually opened. The 'opened' image is now highlighted with bold text to make it clearer (n this case, they are the same image). I hope that feels intuitive, but I guess it needs tested. My reason for doing it that way is that I thought it would be useful to give the option of checking the description before deciding whether or not to open the image. I've also been looking into several other changes, including the ability to set metadata values for individual images (you can see the options on the popup menu). This means a project can have multiple image sets, and you can sort them to get a tree-like structure. (Admittedly it's a small tree, since it only goes one level deep...). Do these changes look like they would help for your applications?. Adding descriptions to annotations would be a more 'core' change, that would affect the .qpdata files. So I'll need to think a bit more about how to achieve it, although I certainly agree it could be very useful.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/144#issuecomment-363409447:331,access,accessible,331,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-363409447,1,['access'],['accessible']
Security,"I had the issue of not being able to delete extensions when QuPath was running. Somewhere in the loading process of the extension the ClassLoader (?) was never closed which left the operating system thinking that the file is still open by some process. I just closed the ClassLoader after initializing the extension, which allowed me to then delete the extension. . Unsure if closing the ClassLoader has consequences such as not being access the Resource files or such?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1419#issuecomment-1803479767:435,access,access,435,https://qupath.github.io,https://github.com/qupath/qupath/pull/1419#issuecomment-1803479767,1,['access'],['access']
Security,"I had wanted to play with something like this for a while now, and this post finally got me going! It took some time as I am not great with Java, but I have put together a two part system that is independent of the .qpdata file, though you could certainly enhance it's usefulness with annotations. To start (assuming you have a project with an image), you would create an ""Explore"" (capitalized) folder within your project folder, at the same level as the ""data"" folder. Then run the ""Location file creator"" and select the views that you would want the student to cycle through, in order, while writing a text file referencing each location (which will be labeled 1,2,3, etc.).; Once you have both the text file and the object file saved to your Explore folder, anyone currently looking at an image should be able to run the Slide Explore script which takes the text file and the object file with the views, and allows the user to read and cycle through the various views that were set up. I created a sample for JP2K-33003-1 if anyone wants to try it out and give some feedback. Once I am a little better with Java, I would like to change the Next/Previous buttons into hyperlinks in the text, but I am not quite there yet :). Scripts at: https://gist.github.com/Svidro/86fb224d69484ae5955631ce68d27054. The test image can be accessed at: http://openslide.cs.cmu.edu/download/openslide-testdata/Aperio/JP2K-33003-1.svs; The "".log"" file needs to be renamed to "".obj"" as I cannot post that file directly otherwise. I am sure there are a lot of improvements that could be made, and any feedback is welcome. [JP2K-33003-1.txt](https://github.com/qupath/qupath/files/1715587/JP2K-33003-1.txt). [JP2K-33003-1.log](https://github.com/qupath/qupath/files/1715588/JP2K-33003-1.log)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/144#issuecomment-364849591:1327,access,accessed,1327,https://qupath.github.io,https://github.com/qupath/qupath/issues/144#issuecomment-364849591,1,['access'],['accessed']
Security,"I have an issue with certain ome.tiff images not opening in QuPath. In the command line console, Im receiving the Java error: NegativeArraySizeException and when I try to edit in the command line, it will not allow me to and I dont know how to access that. If you have any help or advice to get these images open, please let me know",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/437#issuecomment-1410779242:244,access,access,244,https://qupath.github.io,https://github.com/qupath/qupath/issues/437#issuecomment-1410779242,1,['access'],['access']
Security,"I keep getting the following error while installing QuPath on MacOS Big Sur v 11.6.; Nothing shows up in the security settings, so it's not the normal case of being blocked and needing to approve installation in settings.; What can be done?. Thanks; <img width=""438"" alt=""Screen Shot 2021-10-21 at 9 36 33 AM"" src=""https://user-images.githubusercontent.com/11299568/138761171-413c2c15-f636-49cf-9f2a-ca22deca134c.png"">",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/832:109,secur,security,109,https://qupath.github.io,https://github.com/qupath/qupath/issues/832,1,['secur'],['security']
Security,"I like it! Seems to work well. Tiny thing: it looks like `Pattern pattern = Pattern.compile(""[a-zA-Z&&[^Ee]]+"");` is called on every validation of the text field. Since `Pattern` instances are immutable (according to the javadocs), I think this should be initialized outside as a `private final static` variable to avoid the unnecessary overhead.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/668#issuecomment-791375357:133,validat,validation,133,https://qupath.github.io,https://github.com/qupath/qupath/pull/668#issuecomment-791375357,1,['validat'],['validation']
Security,"I marked the comments that I completely understood as resolved. About the rest, am I correct if a recap of what you ask is:; * Metadata parsing is fragmented between `BioFormatsImageServer` and `OMEReaderWrapper` / `OMETileReader`. This should not happen. Metadata should be requested only once and not lazily. * One tile reader should support accessing only one `series`. * The `T getImage(int series);` function should be removed, and the `T getImage(TileRequest tileRequest, int[] channels, boolean isRGB, ColorModel colorModel, int series)` function should be used instead. However I didn't understand where the `OMEPixelParser` class would be in all of this.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1287#issuecomment-1713942917:344,access,accessing,344,https://qupath.github.io,https://github.com/qupath/qupath/pull/1287#issuecomment-1713942917,1,['access'],['accessing']
Security,"I may have to wait until I get home for this to actually work correctly, or Pete can fix it, but mostly you want to change the way you choose the objects you get, since I don't know if you have several annotations, or one giant merged annotation. A script from a while back here: https://gist.github.com/Svidro/68dd668af64ad91b2f76022015dd8a45#file-cell-summary-measurements-to-annotation-groovy; Shows how to add the sum of the positive areas to the annotation, though I don't recall at the moment how to access the annotation's area in a script. I'm sure I have done it before, but most of my QuPath stuff is at home (~8 hours from now). All you would need at the end of this script (within each annotation loop) is to divide your new value by the total area and multiply by 100, if desired. Be very careful doing this, however, as little things like your cell expansion radius can have a dramatic effect on this value depending on the density of your cells! And sometimes depending on the perimeter of your annotation as the cells can stretch outside of your annotation.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/159#issuecomment-375386261:506,access,access,506,https://qupath.github.io,https://github.com/qupath/qupath/issues/159#issuecomment-375386261,1,['access'],['access']
Security,"I originally saved the classifier in a shared folder on our work network.. my colleague and I both copied and pasted the file from there onto our desktops (to make it faster to locate when loading it through QuPath). I've had no problems with it at all prior to this week! My colleague has now left but I'll ask her to try it from the shared folder tomorrow and see if that fixes the issue. I've just tried loading it from the original folder but having the same issue fixable by closing and reopening. . The error message that pops up says: 'QuPath has encountered a problem, sorry. If you can replicate it, please notify a developer. java.security.PrivelegedActionException: java.lang.Exception: std::exception: bad allocation'. Thanks both for your help! Pete I will email you the qpclassifier file now.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/160#issuecomment-375345642:641,secur,security,641,https://qupath.github.io,https://github.com/qupath/qupath/issues/160#issuecomment-375345642,1,['secur'],['security']
Security,"I really like your draft. It seems the most beautiful, design-wise. The `ImageServerStub` solution in the end may just work as a helper for writing ""good"" fast scripts, exposing exactly where the image files are absolutely needed. I made a small comment on your draft PR about the metadata, as i feel that is an important info to access *offline*. But in the end, if that was sorted out, that solution would be a drop-in replacement to mine. As you said, at last it will come down to which one is the most maintainable. I see pros and cons in both: `ImageServerStub` offers a solution that is segregated in one file, but then requires to punch multiple small holes in QP interface in order to use it; `lazy-server` distributes the code responsibility to multiple classes and requires to be careful in future development of QuPath so that it does not end up requesting for the server when it is not really useful. In the latter case it is due to the solution having a silent behaviour. However, since everything is managed internally in the lazy approach, in the future it may create less problems surging from punching holes in QuPath's interface. Ultimately, I think your solution is better maintainable-wise, granted that a few things are managed:; * have the retrieval of the image server be loud in logs. Perhaps even with some traceback to what portion of code triggered it?; * expose a `getCurrentMetadata()` function to avoid having to do `getServer().getMetadata()`; * check qupath code that requested for the server but may not need it.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1488#issuecomment-2032062846:330,access,access,330,https://qupath.github.io,https://github.com/qupath/qupath/pull/1488#issuecomment-2032062846,2,"['access', 'expose']","['access', 'expose']"
Security,I recently found resources like this:. Release hash:; https://github.com/MCJack123/ghaction-Generate-Release-Hashes. Release signing:; https://wiki.debian.org/Creating%20signed%20GitHub%20releases (which equally allows one to verify a given download),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1027#issuecomment-1200433309:47,hash,hash,47,https://qupath.github.io,https://github.com/qupath/qupath/issues/1027#issuecomment-1200433309,2,"['Hash', 'hash']","['Hashes', 'hash']"
Security,"I think both read and write access should be synchronized. Right now, [line 142](https://github.com/qupath/qupath/blob/13bdeed047b4d05f35f47308b36b48c0f2bb3a24/qupath-core/src/main/java/qupath/lib/measurements/NumericMeasurementList.java#L142) and [line 241](https://github.com/qupath/qupath/blob/13bdeed047b4d05f35f47308b36b48c0f2bb3a24/qupath-core/src/main/java/qupath/lib/measurements/NumericMeasurementList.java#L241) can be executed at the same time.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1444#issuecomment-1936234982:28,access,access,28,https://qupath.github.io,https://github.com/qupath/qupath/issues/1444#issuecomment-1936234982,1,['access'],['access']
Security,"I think that I hadn't really appreciated that using the list as key in the map would result in `equals` being called and checking all elements. The purpose was to ensure that identical string lists aren't duplicated for all objects - since there can be millions, which could easily cost hundreds of MB overhead. Basically, we'd like measurements to be accessible like `Map<String, double>`, but that doesn't exist in Java, and `Map<String, Double>` would have much more overhead. Therefore instead we use `List<String>` and either `float[]` or `double[]`, where entries in the list correspond to entries in the array. *Most* of the time, objects will have the same keys/strings - but this isn't enforced (and won't be true when measurements are being added, since the list will be growing). Therefore we want to be able to check when lists are duplicated, and use one instead. The current design is probably very suboptimal, but it's quite core to QuPath (for performance, memory use and serialization) so any major change would need to be very carefully checked.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1444#issuecomment-1943353414:352,access,accessible,352,https://qupath.github.io,https://github.com/qupath/qupath/issues/1444#issuecomment-1943353414,1,['access'],['accessible']
Security,"I think you're right about the pink image not being the label, but are you able to access the label through ImageJ using Bio-Formats, or some other way? When I open it with Fiji, I can't see a label for either of the two images linked to above. If a label is found, it should appear in QuPath under the 'Image' tab and 'Associated images'.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/191#issuecomment-409928556:83,access,access,83,https://qupath.github.io,https://github.com/qupath/qupath/issues/191#issuecomment-409928556,1,['access'],['access']
Security,"I understand, it is hard to capture the idea. Overall I see that after installing QuPath using the "".msi"" in two different users in the same computer when opening QuPath in the second one I notice that I have access to the first user files. . I'll proceed to close this ticket, Thanks",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1108#issuecomment-1309223445:209,access,access,209,https://qupath.github.io,https://github.com/qupath/qupath/issues/1108#issuecomment-1309223445,1,['access'],['access']
Security,I was also wondering how to do this. Looking into the doc how it could be programatically accessed for read/write operations. I will keep updated if I find something,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/122#issuecomment-349589480:90,access,accessed,90,https://qupath.github.io,https://github.com/qupath/qupath/issues/122#issuecomment-349589480,1,['access'],['accessed']
Security,"I'd rather not expose more than necessary. What would it solve?. (I seem to have introduced a big bug in `PathIO`, so currently working on this... v0.6.0-SNAPSHOT isn't in a very usable state right now)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1489#issuecomment-2278151773:15,expose,expose,15,https://qupath.github.io,https://github.com/qupath/qupath/pull/1489#issuecomment-2278151773,1,['expose'],['expose']
Security,"I'll merge the PR anyway, because it solves the problem of not being able to access the log message counts - so that bit is great. The minimum size looks good too, so if there's a way to enforce it as the minimum rather than preferred then that would be useful in a future PR.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1339#issuecomment-1731213439:77,access,access,77,https://qupath.github.io,https://github.com/qupath/qupath/pull/1339#issuecomment-1731213439,1,['access'],['access']
Security,"I'm afraid my access to systems running Linux is pretty limited, but I hope to give it a bit more attention in a few weeks... In the meantime, I'd suggest trying to build QuPath from source. You could try it from the main repo here (which [involves eclipse + Maven in a fairly cumbersome way](https://github.com/qupath/qupath/issues/84)), or from my fork [here](https://github.com/petebankhead/qupath). On my fork I've tried to greatly streamline the process of building the software using [Gradle](https://github.com/petebankhead/qupath#building-qupath-with-gradle), which should also make it easier to investigate the changes that may be necessary to get it to really work cross-platform. This might also help: https://github.com/qupath/qupath/issues/51",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/150#issuecomment-368320960:14,access,access,14,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368320960,1,['access'],['access']
Security,"I'm afraid not. QuPath give access to a range of classifiers from OpenCV and (optionally, with the extension installed) Weka - any parallelization would need to happen in those libraries, and depending on the algorithm might not help much. QuPath is also designed to make it possible to add new classifiers, so potentially newer, faster ones might be added one day... if someone makes them. I'd suggest trying to reduce your number of training objects and/or features. In the case of cells (for example), neighboring cells often have very similar features and including many similar cells probably doesn't help much... and it may even cause harm, by requiring even more training objects to learn something else. There are discussions about training classifiers [here](https://groups.google.com/d/msg/qupath-users/MpsK44RCZcE/xE3nX4aJCAAJ) and [here](https://groups.google.com/d/msg/qupath-users/qM_JtrEW1dI/Jeb5iMRnAQAJ). I also discuss a bit about improving the results when using the same training objects but fewer features [here](https://youtu.be/uj28wJSmntU?list=PL4ta8RxZklWk_O_Z7K0bZlhmHtaH73vlh). I do plan to make some changes that should improve how quickly an existing classifier is reloaded (even if it does not change the training time), described [here](https://groups.google.com/d/msg/qupath-users/EkQNKOqUBVE/UqB0tcL8AQAJ). But it's a fairly substantial change and a matter of finding enough time...",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/206#issuecomment-416021080:28,access,access,28,https://qupath.github.io,https://github.com/qupath/qupath/issues/206#issuecomment-416021080,1,['access'],['access']
Security,"I'm afraid that would be tricky... you'll definitely need access to the raw pixels. To achieve this after detection, it's best _not_ to choose _Smooth boundaries_ in the cell detection parameters, to keep the contours as close as possible to their original shapes... then you could potentially loop through every cell, extract the pixels for the cell, create a binary mask for the nucleus and another for the cell, and work from there. Or alternatively you could write an entirely new cell detection (e.g. with ImageJ or OpenCV). Another option would be to look at exporting the pixels, and the cell ROIs as labelled images (with unique integer labels for each cell). Then you can potentially tackle the task in Python or R. Whichever way you choose it's not entirely straightforward, and calculating the values efficiently for large numbers of cells would be a further challenge. So... it's technically possible, but would require quite a lot of effort.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/236#issuecomment-433483920:58,access,access,58,https://qupath.github.io,https://github.com/qupath/qupath/issues/236#issuecomment-433483920,1,['access'],['access']
Security,"I'm afraid that, as an open-source project, we don't have the time or resources to provide code signing certificates at this time. We'd potentially need certificates for all operating systems, and it's not something we can work on right now. We provide full instructions to build QuPath from the source code, so if it helps your IT department could build a version themselves, rather than relying on the downloads here: https://qupath.readthedocs.io/en/stable/docs/reference/building.html",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1605#issuecomment-2312201023:104,certificate,certificates,104,https://qupath.github.io,https://github.com/qupath/qupath/issues/1605#issuecomment-2312201023,2,['certificate'],['certificates']
Security,"I'm travelling and without access to a proper computer this week, but will try to write a brief description when I get back. I have used smoothed features often, but not really the other two. There is more information on smoothed features at https://github.com/qupath/qupath/wiki/Classifying-objects",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/185#issuecomment-403948004:27,access,access,27,https://qupath.github.io,https://github.com/qupath/qupath/issues/185#issuecomment-403948004,1,['access'],['access']
Security,"I've repeated the issue several times but not always (I know this doesn't make sense but I don't know how to explain it). Here is an example of error message that I have been getting when it has not worked:. ```; INFO: Bio-Formats version 6.2.0; INFO: Loaded extension Bio-Formats server options (Bio-Formats 6.2.0) (17 ms); INFO: Loaded extension Experimental commands (9 ms); INFO: Loaded extension ImageJ extension (49 ms); INFO: Loaded extension JPen extension (15 ms); INFO: Loaded extension OpenCV extensions (2 ms); INFO: Loaded extension Rich script editor extension (161 ms); INFO: OpenSlide version 3.4.1; INFO: Selected style: null; INFO: Performing update check...; INFO: Starting QuPath with parameters: []; INFO: Project set to Project: 190804; WARN: Unable to obtain full image format info for file:/C:/pathtoimage***.scn (null)WARN: Unable to open file:/C:/pathtoimage***.scn with OpenSlide: Couldn't locate TIFF directory for quickhash; WARN: Unable to open UriImageSupport (class qupath.lib.images.servers.openslide.OpenslideServerBuilder) support=2.5builders=1; WARN: Unable to open file:/C:/pathtoimage***.scn with OpenSlide: Couldn't locate TIFF directory for quickhash; ```. Seems like it tried to open with openslide while it should have used bioformats?. Another weird behaviour (not sure if this is intended) of the new version: if I drag an drop fluorescent images (.scn or .vsi) (not tried with chromogenic) to qupath without having pre-created a project, it only opens the label/macro image without letting me access to higher resolution images....",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/348#issuecomment-518022687:1538,access,access,1538,https://qupath.github.io,https://github.com/qupath/qupath/issues/348#issuecomment-518022687,1,['access'],['access']
Security,"If you want help with a particular project, please post more information over at https://groups.google.com/forum/#!forum/qupath-users. I would recommend at least copy of your workflow script (https://github.com/qupath/qupath/wiki/Workflows) so we know what you have tried and/or are trying. And perhaps some small jpeg images so we know what you are looking at (if allowed by confidentiality).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/161#issuecomment-375335956:376,confidential,confidentiality,376,https://qupath.github.io,https://github.com/qupath/qupath/issues/161#issuecomment-375335956,1,['confidential'],['confidentiality']
Security,"If you wanted to use all of the images. I would generally use either a random sub-selection, or eyeball it and include as much variation as possible. Strongly positive, strongly negative, a few weird ones. Then build the training from that, and save it as a .qpclassifier. Then start a new project for the whole set of images. At that point you only need to use runClassifier(""C:\\here is my path\\here is my classifier.qpclassifier) in a script to access the classification. . The primary reason to keep the old project separate is in case you decide the classifier needs tweaking or an additional class, or whatever. Then you can go back to the classifier project, add in some new training objects, rebuild training from project, and create another classifier file. Run that file on the ""real"" project, and compare results.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/360#issuecomment-530545951:449,access,access,449,https://qupath.github.io,https://github.com/qupath/qupath/issues/360#issuecomment-530545951,1,['access'],['access']
Security,"Impl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$MouseHandler.process(Scene.java:3851); at javafx.scene.Scene$MouseHandler.access$1200(Scene.java:3579); at javafx.scene.Scene.processMouseEvent(Scene.java:1849); at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2588); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:397); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:295); at java.base/java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$2(GlassViewEventHandler.java:434); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:390); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:433); at com.sun.glass.ui.View.handleMouseEvent(View.java:556); at com.sun.glass.ui.View.notifyMouse(View.java:942); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:174); at java.base/java.lang.Thread.run(Thread.java:834). ******Desktop (please complete the following information)**; - OS: Windows 10 (home) - 64 bits - Hardware: Intel I5, CPU 250 Ghz, Memória RAM (8gb) ; - QuPath Version [(v0.2.0-m2)]. I imagine the answer is simple but I can not solve this problem.; Best Regards; Marcos Souza",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/312:4404,secur,security,4404,https://qupath.github.io,https://github.com/qupath/qupath/issues/312,2,"['Access', 'secur']","['AccessController', 'security']"
Security,Improved methods to access objects from PathObjectHierarchy,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1563:20,access,access,20,https://qupath.github.io,https://github.com/qupath/qupath/pull/1563,1,['access'],['access']
Security,"In the `QuPath.cfg` file of your installation, under `[JavaOptions]`, the exact line to add is; ```; java-options=--illegal-access=warn; ```; I've just tried this and it has resolved another problem that I expect to be related (the inability to add metadata to project entries in the current v0.3.0-SNAPSHOT).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/717#issuecomment-829898314:124,access,access,124,https://qupath.github.io,https://github.com/qupath/qupath/issues/717#issuecomment-829898314,1,['access'],['access']
Security,"In the meantime, I see at the bottom of the panel on the left *Image list (3)*. If you double-click on that, you should see another two images - and you can double click on each of them to see how they look. From the few .scn files I've seen, the 'default' that opens up usually isn't the whole slide scan that you probably want, and it's necessary to go to the *Image list* to access it. You can also remove the Bio-Formats extension from your QuPath extensions directory, so as to let OpenSlide have a go. Maybe it has more success.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/141#issuecomment-358634515:378,access,access,378,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358634515,1,['access'],['access']
Security,Include checksums when using jpackage.; Update gradle wrapper for Java 21 support (when available).,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1369:8,checksum,checksums,8,https://qupath.github.io,https://github.com/qupath/qupath/pull/1369,1,['checksum'],['checksums']
Security,"Indeed I had only one of the 2 `.jar` files in the folder. Sorry about this and thanks a lot for your help. I also see 3 images. 1 is thumbnail, 1 is low-resolution pre-scan, the other is high magnification scan. The default contrasts settings are indeed very bad with these images, but it's fine once adjusted. I guess the high number of pixels with 0 values would come from empty regions... Is it possible somehow to set predefined values that would work by default on every similar files in the future? (forcing QuPath not to auto adjust would probably do the trick..., or to ignore those 0 values when adjusting the settings). These images can contain sometimes a maximum projection + z-stacks (it is the case of the biggest of the 2 images for example). Do you know if it is possible to access these z-stacks? Do you know how it would chose the stack? It seem to be taking the maximum projection by default be haven't checked enough images to be sure.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/191#issuecomment-409243439:792,access,access,792,https://qupath.github.io,https://github.com/qupath/qupath/issues/191#issuecomment-409243439,1,['access'],['access']
Security,Is an sha256 hash available for the current Qupath (0.3.2) release? (specifically the windows distribution?),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1027#issuecomment-1207982738:13,hash,hash,13,https://qupath.github.io,https://github.com/qupath/qupath/issues/1027#issuecomment-1207982738,1,['hash'],['hash']
Security,"It certainly is, although there are different methods for doing so. It mostly involves how much overlap you want your users to have in terms of annotations.; 1. Have all images on a server, and all QuPath projects on the client computers. This means each person will have access to the same images, but will not share any cell generation or annotations. Safest and easiest to set up, but probably least useful.; 2. Map the same network drive to the image location on all client computers (say, S: drive for your server), and use the same shared QuPath directory (say, Q: drive) created for each project on every computer. This would mean that every user would have access to all images and modifications done through QuPath, but there are some fairly heavy caveats here.; 2A. There is NO file copy protection AT ALL. All users would have equal access to overwriting the current .qpdata file, and for all I know, they might attempt to save two different versions at the same time, creating a mess. ; 2B. If your .qpdata files are large (can get up to 3GB or so fairly easily with SLICs) you may have network bandwidth problems accessing both images and data files. Actually, access to the images alone could be problematic depending on your hardware. Multiple users accessing data on a single hard drive through a 1gigabit network connection can cause slowdowns in refresh rate.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/100#issuecomment-328936155:272,access,access,272,https://qupath.github.io,https://github.com/qupath/qupath/issues/100#issuecomment-328936155,6,['access'],"['access', 'accessing']"
Security,"It looks likely that the data file is corrupt; unfortunately, without access to this we would not be able to replicate the issue. You can find the file under *Open directory... &rarr; Project entry...*; it will be called data.qpdata. This issue may be related: https://github.com/qupath/qupath/issues/512; See also the reference to a .bkp file that may be created when saving. You may also simply move/delete the data.qpdata file. This will remove all image data for that image from the project, so you'd then have to generate the superpixels again.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/607#issuecomment-693259996:70,access,access,70,https://qupath.github.io,https://github.com/qupath/qupath/issues/607#issuecomment-693259996,1,['access'],['access']
Security,"It might be... there's no built-in option to do so, but see https://github.com/qupath/qupath/issues/57#issuecomment-288491139 for possible workarounds (which in your case would really involve duplicating and merging your projects). The following script _might_ work; as far as I know it does the right thing, but I haven't exactly tested it very much:; ```groovy; // Paths to training files (here, both relative to the current project); paths = [; buildFilePath(PROJECT_BASE_DIR, 'training', 'my_training.qptrain'),; buildFilePath(PROJECT_BASE_DIR, 'training', 'my_training2.qptrain'),; ]. // Path to output training file; pathOutput = buildFilePath(PROJECT_BASE_DIR, 'training', 'merged.qptrain'). // Count mostly helps to ensure we're adding with unique keys; count = 0. // Loop through training files; def result = null; for (path in paths) {; // .qptrain files just have one object but class isn't public, so ; // we take the first one that is deserialized; new File(path).withObjectInputStream {; saved = it.readObject(); }; // Add the training objects, appending an extra number which ; // (probably, unless very unfortunate with image names?) means they are unique; map = new HashMap<>(saved.getMap()); if (result == null) {; result = saved; result.clear(); }; for (entry in map.entrySet()); result.put(entry.getKey() + '-' + count, entry.getValue()); count++; }. // Check how big the map is & what it contains; print result.size(); print result.getMap().keySet().each { println it }. // Write out a new training file; new File(pathOutput).withObjectOutputStream {; it.writeObject(result); }; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/256#issuecomment-455564256:1183,Hash,HashMap,1183,https://qupath.github.io,https://github.com/qupath/qupath/issues/256#issuecomment-455564256,1,['Hash'],['HashMap']
Security,It seems YouTube changed the access settings a while ago - they should be visible again now. (Note that the wiki hasn't been updated since QuPath v0.1.2 - the current documentation is at https://qupath.readthedocs.io/ ),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/955#issuecomment-1105367880:29,access,access,29,https://qupath.github.io,https://github.com/qupath/qupath/issues/955#issuecomment-1105367880,1,['access'],['access']
Security,"It should be possible to do the conversion. In v0.2.0-m2 you can get the key information with; ```groovy; print getCurrentServer().dumpMetadata(); ```; or, very unofficially (i.e. by accessing private fields...), this:; ```groovy; def x = getCurrentServer().boundsX; def y = getCurrentServer().boundsY; ```. The next step would be to apply a translation... the affine transform [here](https://forum.image.sc/t/interactive-image-alignment/23745/9?u=petebankhead) shows one way to approach that. Although in general you can translate a ROI with; ```groovy; translated = roi.translate(-100, -200); ```; so long as the `TranslatableROI` interface is implemented (I think it always is....)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/291#issuecomment-477356033:183,access,accessing,183,https://qupath.github.io,https://github.com/qupath/qupath/issues/291#issuecomment-477356033,1,['access'],['accessing']
Security,"It sounds like a memory issue to me too, although I'm not certain. Hopefully the log can help. I plan to write a better script to help explore memory issues soon, but in the meantime you could try this very basic one:; ```groovy; // Print the current memory situation; def runtime = Runtime.getRuntime(); double scale = 1.0/1024.0/1024.0; print 'Max memory (MB): ' + (runtime.maxMemory() * scale); print 'Total memory (MB): ' + (runtime.totalMemory() * scale); print 'Used memory (MB): ' + ((runtime.totalMemory() - runtime.freeMemory()) * scale). // Try to reclaim whatever memory we can, including emptying the tile cache; javafx.application.Platform.runLater {; getCurrentViewer().getImageRegionStore().cache.clear(); System.gc(); }; ```. The top bit gives some numbers on current memory usage. Roughly, the 'max' is what QuPath/Java is allowed to use, the 'total' is what it is currently claiming the right to access (which might change over time, potentially increasing towards the 'max' as required), and the 'used' value is what is currently needed. The second bit of the script then tries to bring down the 'used' value by clearing out the cache of image tiles and reclaiming whatever memory if can. So if you run the script twice in a row, the 'used' memory value should generally be lower the second time, assuming you had previously been browsing around the image (and therefore filling up the tile cache). Running this script before running the cell detection might increase the chances of it ending successfully. If it still sometimes fails, but it looks like a memory problem, then either increasing the memory limit or decreasing the number of parallel threads could help - see https://github.com/qupath/qupath/wiki/Troubleshooting for more info.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/130#issuecomment-355845333:914,access,access,914,https://qupath.github.io,https://github.com/qupath/qupath/issues/130#issuecomment-355845333,1,['access'],['access']
Security,"It wasn't, but it will be now. I have rarely looked at the label myself, but if it is useful then I will think some more about a way to access it more quickly.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/36#issuecomment-268778034:136,access,access,136,https://qupath.github.io,https://github.com/qupath/qupath/issues/36#issuecomment-268778034,1,['access'],['access']
Security,"It's a long time since I wrote that bit (and I probably should have used `Set.of(...)` instead of the `HashSet`...), but I'm not sure that adding `MOUSE_RELEASED` would be correct. The purpose of the `EventFilter` in general is to block UI events under some circumstances, e.g. when a script is running. We'd want mouse pressed & released events to be blocked (and not ignored... since ignoring them would let them through. I realise that's not entirely intuitive naming...). To make minimal changes I think you'd just need to check for the event you want and leave the rest as it was, e.g.; ```java; ...; } else if (e.getEventType() == MouseEvent.MOUSE_CLICKED && e.getButton() == MouseButton.MIDDLE) {; ...; }; ```. (Not certain I've understood, since that comment is only from reading - not running)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1037#issuecomment-1313439231:103,Hash,HashSet,103,https://qupath.github.io,https://github.com/qupath/qupath/pull/1037#issuecomment-1313439231,1,['Hash'],['HashSet']
Security,"It's not possible to try an additional classifier directly through the user interface, but that is just because the functionality the user interface gives access to is necessarily very limited. QuPath gives the tools to solve many problems like this, but constructing the specific solutions could still take a lot of work. It is hard to judge without seeing any images, but it sounds like one or more research projects to figure out how to approach the analysis, develop the techniques and write the necessary code. There is no built-in command to do all of what is needed here, but that is why it is also possible to write scripts and extensions for QuPath.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/254#issuecomment-453001561:155,access,access,155,https://qupath.github.io,https://github.com/qupath/qupath/issues/254#issuecomment-453001561,1,['access'],['access']
Security,"Library(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$173(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$48(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:748); 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Light; 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 13:20:08.256 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 13:20:17.509 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Calling Platform.exit();; ```. In Centos 6, I found some information about the error message ""j java.lang.Object.<clinit>()V+0"" : this may be a stack problem. I tried to change the thread stack size with -Xss in QuPath.cfg [JVMOptions], but I can not do it : . ```; 13:11:03.460 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; QuPath Error invoking method.; QuPath Failed to launch JVM; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/150#issuecomment-368857650:2982,Xss,Xss,2982,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650,1,['Xss'],['Xss']
Security,"Lots of scripting-related improvements, along with some major refactoring and a bit of changed behavior. ## Prompts when 'Run for project' includes a currently-open image. Using 'Run for project' with an image that is currently open is a common source of confusion in QuPath. This operations on the saved data files in the project, but the changes aren't automatically reflected in the viewer. These changes update the message shown to the user when this may be affected:. <img width=""601"" alt=""Open images message"" src=""https://user-images.githubusercontent.com/4690904/196366026-b771f014-be4b-4f07-8185-55af6745e7d2.png"">. And a prompt automatically appears when the scripting is complete, inviting the user to reload the data to see any changes:. <img width=""375"" alt=""Prompt to reload"" src=""https://user-images.githubusercontent.com/4690904/196366065-23f2a1f7-0146-41a9-a8ba-367d11605d12.png"">. ## New `ScriptAttributes` to access file and batch info. Several [attributes](https://github.com/qupath/qupath/commit/a1d40fb6647454a4500cb305d19e2f8698caa2fa) are now set when scripts are run, which can be queried in Groovy via `getProperty(attribute)`. Examples:. ```groovy; // The number of images being processed in batch (e.g. with 'Run for project'); int batchSize = getProperty(ScriptAttributes.BATCH_SIZE). // The 0-based index for the current image being processed; int batchIndex = getProperty(ScriptAttributes.BATCH_INDEX). // Query if this is the last image being processed in a batch; boolean batchLast = getProperty(ScriptAttributes.BATCH_LAST). // The file path for the script file (or null if not available); // (Note that the file contents may differ from the script if there are unsaved changes); String filePath = getProperty(ScriptAttributes.FILE_PATH); ```. The inspiration is from https://github.com/qupath/qupath/issues/1029. These changes make useful things possible, e.g.; * take action to notify the user at the end of long-running batch processing; * access other scripts or ",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1078:928,access,access,928,https://qupath.github.io,https://github.com/qupath/qupath/pull/1078,1,['access'],['access']
Security,"Major improvements when using pixel classification (and some other commands) through:; - More frequent use of PointerScope to keep memory in check; - New ThreadTools methods to set/get parallel threads, so this value is accessible within core modules; - Multithreading within ContourTracing uses ThreadTools value to enable memory use to be better controlled (rather than a parallel stream, which could get out of control); - ContourTracing also now parallelized geometry manipulations whenever applying multiple thresholds to an ImageServer. Much of this prompted by @MarkZaidi's benchmarking thread at https://forum.image.sc/t/designing-a-qupath-workstation/54849. Along the way, a small bug fix to DensityMaps scripting.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/781:220,access,accessible,220,https://qupath.github.io,https://github.com/qupath/qupath/pull/781,1,['access'],['accessible']
Security,"Makes the ""Select project images"" window for pixel and object classifier resizable so image names can be viewed without scrolling. To access: Classify -> Object classification -> train object classifier -> load training button . Other `listSelectionView` uses within QuPath are resizable windows already (eg. script editor -> run -> run for project).",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1512:134,access,access,134,https://qupath.github.io,https://github.com/qupath/qupath/pull/1512,1,['access'],['access']
Security,Manager.dispatchBubblingEvent(EventHandlerManager.java:191); at com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDispatcher.java:59); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:58); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$MouseHandler.process(Scene.java:3856); at javafx.scene.Scene.processMouseEvent(Scene.java:1851); at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2584); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:409); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:299); at java.base/java.security.AccessController.doPrivileged(Unknown Source); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$2(GlassViewEventHandler.java:447); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:412); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:446); at com.sun.glass.ui.View.handleMouseEvent(View.java:556); at com.sun.glass.ui.View.notifyMouse(View.java:942); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:174); at java.base/java.lang.Thread.run(Unknown Source); ```,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/752#issuecomment-866148194:5151,secur,security,5151,https://qupath.github.io,https://github.com/qupath/qupath/issues/752#issuecomment-866148194,2,"['Access', 'secur']","['AccessController', 'security']"
Security,"Manjaro KDE Edition, Kernel 4.19.69-1-MANJARO, Intel i7-4790, 16GB RAM, . Extracted from tar.xz using `tar -xf `into /usr/local/src/ and tried to run app as sudo using `./QuPath-0.2.0-m4`. App starts up but the start dialogue box (""Welcome to QuPath v0.2.0-m4!"") will not close. Close ('x') button and minimize are displaying in the window but not the maximise button and these buttons are unresponsive on both the welcome window and the main program window. . Also tried extracting and running from GUI (Dolphin) but same issue occurred. . No menu items are accessible and the windows are non-responsive. Cannot drag or drop items into QuPath to open images. Simply frozen on the initial x2 windows of the application. From terminal output may be an issue with a gtk module?. Pasting Terminal Output from `sudo ./QuPath-0.2.0-m4` command:. ```; 10:11:46.562 [main] [INFO ] qupath.QuPath - Launching QuPath with args: ; Gtk-Message: 10:11:46.750: Failed to load module ""appmenu-gtk-module""; 10:11:46.955 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale FORMAT set to en_US; 10:11:46.956 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Locale DISPLAY set to en_US; 10:11:47.045 [JavaFX Application Thread] [WARN ] qupath.lib.gui.QuPathGUI - No directory set for log files! None will be written.; 10:11:47.048 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - QuPath build: Version: 0.2.0-m4; Build time: 2019-08-20, 20:38; Latest commit tag: 'e9b60579'; 10:11:47.051 [JavaFX Application Thread] [INFO ] qupath.lib.gui.prefs.PathPrefs - Setting tile cache size to 1996.50 MB (25.0% max memory). (QuPath-0.2.0-m4:17581): Gdk-WARNING **: 10:11:47.691: XSetErrorHandler() called with a GDK error trap pushed. Don't do that.; 10:11:48.207 [JavaFX Application Thread] [INFO ] q.l.i.s.b.BioFormatsOptionsExtension - Bio-Formats version 6.2.0; 10:11:48.216 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Loaded extension Bio-Formats ",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/369:559,access,accessible,559,https://qupath.github.io,https://github.com/qupath/qupath/issues/369,1,['access'],['accessible']
Security,"No, it does look like a separate threading issue in my opinion. I just thought of mentioning it in case someone else experienced the same. I can only see this threading bug happen with the MacBook Pro I have access to, which is the same computer having the original OpenCV issue..",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/776#issuecomment-874159943:208,access,access,208,https://qupath.github.io,https://github.com/qupath/qupath/issues/776#issuecomment-874159943,1,['access'],['access']
Security,"Ofcourse!; I see from the log now that all the objects were unclassified.; So I understand why I don't see any colours. But as the structures are quiet different I would think that it should be able to come up whit a classifier right?; ![image](https://user-images.githubusercontent.com/36917491/45081418-75871d80-b0f7-11e8-9ed9-373228da976e.png). Log-file:; INFO: Selected style: Modena Light; INFO: Performing update check...; INFO: Starting QuPath with parameters: []; ERROR: Openslide: Property not available: openslide.objective-power; INFO: Test reading thumbnail with openslide: passed (BufferedImage@77accd0e: type = 1 DirectColorModel: rmask=ff0000 gmask=ff00 bmask=ff amask=0 IntegerInterleavedRaster: width = 200 height = 193 #Bands = 3 xOff = 0 yOff = 0 dataOffset[0] 0); INFO: Returning server: OpenSlide for L:\basic\divg\CEMM-Lexor\SannetH\1. SANNE\Project 2. IHC Validation PICCOLO and COIN\Qupath PICCOLO\R-PICCOLO-16_CDX2-88_20x.tiff; INFO: Estimating H-DAB staining; INFO: Image data set to ImageData: Brightfield (H-DAB), R-PICCOLO-16_CDX2-88_20x; INFO: Will (re)compute TMA grid...; INFO: Processing complete in 1.26 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.dearray.TMADearrayerPluginIJ {""coreDiameterMM"": 0.7, ""labelsHorizontal"": ""1-16"", ""labelsVertical"": ""A-J"", ""labelOrder"": ""Row first"", ""densityThreshold"": 5, ""boundsScale"": 105}; INFO: Adding Rectangle to hierarchy; INFO: Requesting region for stain vector editing: ; INFO: 1932 nuclei detected (processing time: 3.82 seconds); INFO: Processing complete in 3.92 seconds; INFO: Completed!; INFO: ; qupath.imagej.detect.nuclei.WatershedCellDetection {""detectionImageBrightfield"": ""Hematoxylin OD"", ""requestedPixelSizeMicrons"": 0.5, ""backgroundRadiusMicrons"": 8.0, ""medianRadiusMicrons"": 0.0, ""sigmaMicrons"": 1.5, ""minAreaMicrons"": 10.0, ""maxAreaMicrons"": 400.0, ""threshold"": 0.1, ""maxBackground"": 2.0, ""watershedPostProcess"": true, ""excludeDAB"": false, ""cellExpansionMicrons"": 0.0, ""includeNuclei"": true, ""smoot",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/210#issuecomment-418647572:879,Validat,Validation,879,https://qupath.github.io,https://github.com/qupath/qupath/issues/210#issuecomment-418647572,1,['Validat'],['Validation']
Security,"Oh no, please keep the PR for now!. I'll check it out in more detail soon - but you've demonstrated that there is a concurrency bug with the measurement list. It just wouldn't have arisen if the Delaunay command wasn't buggy too. Similarly, the performance probably wouldn't have changed noticeably if the Delaunay command wasn't problematic... so this may not be a major issue in other contexts. One thing to check would be 'Add smoothed measurements' with lots of cells, since this should add a lot of measurements in parallel - but I think only one thread should be accessing each measurement list. Therefore I hope synchronization doesn't cause substantial overhead. . In any case, I think `MeasurementList` implementations *should* be thread-safe - so we should address this in either v0.5.1 or v0.6.0.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1444#issuecomment-1944052771:569,access,accessing,569,https://qupath.github.io,https://github.com/qupath/qupath/issues/1444#issuecomment-1944052771,1,['access'],['accessing']
Security,"Ok. So this is intended. I guess there is no plan for a ""convert to 0.2.0"" for older projects that may benefit from the new features. Is there an easy way to access the x, y dimensions of the whole slide image without the bounding box in order to calculate the translation?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/291#issuecomment-475032443:158,access,access,158,https://qupath.github.io,https://github.com/qupath/qupath/issues/291#issuecomment-475032443,1,['access'],['access']
Security,"Okay. Will look forward to the new version.; Thank you for your help, Pete. Best regards,; Kathy Yee. From: Pete <notifications@github.com>; Reply-To: qupath/qupath <reply@reply.github.com>; Date: Tuesday, June 9, 2020 at 11:50 AM; To: qupath/qupath <qupath@noreply.github.com>; Cc: ""Kathleen T. Yee"" <KYee@umc.edu>, Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [qupath/qupath] Zoom In and Zoom Out (#518). I'll close this issue, v0.2.1 should be available next week containing this and some other minor fixes. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fissues%2F518%23issuecomment-641435861&data=02%7C01%7Ckyee%40umc.edu%7C9d731bc401b64e12fc1608d80c953380%7C78a0681ef0be47e280498616858818a5%7C0%7C0%7C637273182238802631&sdata=35kLxw2W6caULJz3%2BBpsA14p3ff4jQMudfZyvd2fDBk%3D&reserved=0>, or unsubscribe<https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAP4MNE2ZSFDWOSMQL5V6SOTRVZR43ANCNFSM4NYSD4CA&data=02%7C01%7Ckyee%40umc.edu%7C9d731bc401b64e12fc1608d80c953380%7C78a0681ef0be47e280498616858818a5%7C0%7C0%7C637273182238812636&sdata=euPaoon04N%2F82Kf22ZIMOfEzWDQjc4LmxotHQSNCcaA%3D&reserved=0>. Individuals who have received this information in error or are not authorized to receive it must promptly return or dispose of the information and notify the sender. Those individuals are hereby notified that they are strictly prohibited from reviewing, forwarding, printing, copying, distributing or using this information in any way.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/518#issuecomment-641438041:1403,authoriz,authorized,1403,https://qupath.github.io,https://github.com/qupath/qupath/issues/518#issuecomment-641438041,1,['authoriz'],['authorized']
Security,"One more thing: should we expose the builders in `qupath.lib.images.servers.ImageServers.*` so that you can test what kind of `ImageServer` is being used, if the builder is available?",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1489#issuecomment-2278093823:26,expose,expose,26,https://qupath.github.io,https://github.com/qupath/qupath/pull/1489#issuecomment-2278093823,1,['expose'],['expose']
Security,"One of the things I have often preferred about QuPath is how neatly it arranges most of the windows into a single UI, where I don't have to fight with ""is what I want to use on top and accessible"" like with Fiji and MicroManager etc. . If implemented, there really should be ways to quickly and easily organize the windows, like the Tile and Cascade options in Fiji. > Is there a need to have the same image open in multiple viewers?. This has been one of the things I have often wanted to be able to do for multiplex images (along with synchronize for panning). Having the same image open, but with different sets of channels visible in each MultiView. . It was something I remember being able to do in earlier versions that has since been removed.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1317#issuecomment-1708749225:185,access,accessible,185,https://qupath.github.io,https://github.com/qupath/qupath/issues/1317#issuecomment-1708749225,1,['access'],['accessible']
Security,"Organizations who would like to use your tool might want to verify the binaries you distribute are not being tampered with in transet. One easy way to make that easy (as opposed to have such organizations build your tool from scratch) would be to publish the binaries with MD5/SHA1 hashes on the releases page. You would make the life of IT employees in such organizations a whole lot easier!. Thanks,. Kris",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1027:282,hash,hashes,282,https://qupath.github.io,https://github.com/qupath/qupath/issues/1027,1,['hash'],['hashes']
Security,ParameterPanelFX does not validate text field input,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1541:26,validat,validate,26,https://qupath.github.io,https://github.com/qupath/qupath/issues/1541,1,['validat'],['validate']
Security,Please consider posting hash information for .msi and standalone .exe,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1027:24,hash,hash,24,https://qupath.github.io,https://github.com/qupath/qupath/issues/1027,1,['hash'],['hash']
Security,"Preview & QuPath both look ok to me:. ![Screenshot 2020-10-23 at 20 49 48](https://user-images.githubusercontent.com/4690904/97047805-6bdc0080-1571-11eb-8a78-f2ec9652945c.png). I do have a homebrew install as well:. ![Screenshot 2020-10-23 at 20 52 12](https://user-images.githubusercontent.com/4690904/97048049-ba899a80-1571-11eb-8751-6dc0394469e5.png). ----. Thanks very much for the link, I'll check your build scripts - I think it is already safe to say they are a lot more sophisticated than anything used for QuPath! I'm afraid I'm one of the people who has spent too long with Java and Python... Do you think there would be any sense in trying to include libvips with QuPath? We could put some work into that from our side - especially if it would help us incorporate OpenSlide more reliably into QuPath while also giving access to some of libvips' other functionality (like faster image pyramid-writing?) - but I'm not sure if there are reasons that's a bad idea.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/627#issuecomment-715571233:829,access,access,829,https://qupath.github.io,https://github.com/qupath/qupath/issues/627#issuecomment-715571233,1,['access'],['access']
Security,"QuPath does not include any code that directly relates to the GPU - everything happens through OpenCV/JavaCPP (and sometimes also PyTorch/TensorFlow/DJL). If you search for `the provided PTX was compiled with an unsupported toolchain` you should find lots of discussions separately from QuPath; it seems that the issue is normally related to the driver. I tried to replicate the issue with the only Windows computer I have access to (including a GeForce 1060) and could not - it runs without errors, and `DnnTools.isCudaAvailable()` returns true. > Given that issue https://github.com/qupath/qupath/issues/841 was marked as resolved 5 days ago, it could be linked to that. Perhaps there were some changes to the API such that closing of the model should be scripted differently?. I don't think that can be relevant here. I'm not sure that there is any bug here that can be fixed within QuPath. I have seen such error messages before, but the solution was always to update my graphics card driver. Have you tried this?. Note that QuPath v0.4.0 gives a range of options for deep learning, but CUDA incompatibilities will mean that probably not all can work at once (e.g. I could get PyTorch with GPU acceleration today by installing CUDA 11.7, but TensorFlow seems to require 11.3... I'm not sure there's a combination that gets both working together). I don't see that there's really anything much more we can do apart from simply removing the option of GPU acceleration altogether and not documenting it as an option - but that seems a shame when often it does work. > I have a version of QuPath built on 2022-11-21 which has no problem running StarDist on the GPU, so it's likely tied to any commits between this period. Because QuPath doesn't directly access the GPU, please check the .jar files within each installation. I don't know what the problem could be, unless it is somehow related to the inclusion of some Deep Java Library dependencies - or if you have other extensions installed that are",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1180#issuecomment-1341628127:423,access,access,423,https://qupath.github.io,https://github.com/qupath/qupath/issues/1180#issuecomment-1341628127,1,['access'],['access']
Security,"QuPath should (i.e. has in the past) compile fine under Linux, with the required native libraries. However, no distribution for Linux is available under _Releases_ yet. This should happen, but requires gaining access to a suitable Linux machine soon to arrange and test it...",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/2:210,access,access,210,https://qupath.github.io,https://github.com/qupath/qupath/issues/2,1,['access'],['access']
Security,"QuPath tries to have as few customizations as possible for specific file formats (almost none...), relying only on what OpenSlide and Bio-Formats provide. If images in the same format end up opening differently in QuPath, then it is most likely because there is something in the file that causes OpenSlide or Bio-Formats to handle them differently*. The Bio-Formats and OpenSlide teams have done an incredible job in support many formats to date, but of course they are under no obligation to do so. Unlike the software developed by the vendors themselves, who have access to the full details of their proprietary formats, open projects often need to make educated guesses to try to figure out how to read the files. In my opinion, if someone has a proprietary file format then it should be up to them to help ensure it is supported in open software... _if_ they want that to be possible. It's perfectly legitimate for them to decide that they don't want their format to be open, but in that case potential customers for whom this matters need to find this out.... ideally before paying a lot of money for something they will be unable to use fully. Presumably Bio-Formats don't have a specification for the .scn format (on the website it is listed as [something they would like to have](https://docs.openmicroscopy.org/bio-formats/6.0.1/formats/leica-scn.html)) and they have also [blogged on mrxs](http://blog.openmicroscopy.org/file-formats/community/2016/01/06/format-support/). It seems really unfortunate that formats that are common in the research community aren't always well supported in open software. Ultimately it's really only the people behind the formats that can change this... I hope that greater awareness of the underlying reasons might help the research community exert pressure in the right direction - in the way that the Bio-Formats blog post describes. >*-Although it is always possible that there is a bug in QuPath causing the trouble... but if some work and some don't, wit",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/300#issuecomment-483601172:566,access,access,566,https://qupath.github.io,https://github.com/qupath/qupath/issues/300#issuecomment-483601172,1,['access'],['access']
Security,"Recently my laboratory had to move all its files from a Samba storage server to a linux one, accessible only through SFTP/SSH.; For this reason my colleagues' Windows PCs were forced to use [`sshfs-win`](https://github.com/winfsp/sshfs-win) in order to mount the remote storage when loading images from QuPath. Everything seem to work as intended, however saving projects (and probably other files too) is problematic. This is not a problem of QuPath itself, but rather [a know problem](https://github.com/winfsp/sshfs-win/issues/349) of `sshfs-win` not (yet) supporting Windows' `GetFileInformationByHandle` to retrieve file identifiers.; These identifiers are actively used by Java's Windows' filesystem provider to check whether two files [are the same](https://github.com/openjdk/jdk/blob/cbfddf4e1d3ff8dddb95bcb9242b31c175b768fc/src/java.base/windows/classes/sun/nio/fs/WindowsFileAttributes.java#L349) when requesting for a [`copy()`](https://github.com/openjdk/jdk/blob/cbfddf4e1d3ff8dddb95bcb9242b31c175b768fc/src/java.base/windows/classes/sun/nio/fs/WindowsFileCopy.java#L126) or [`move()`](https://github.com/openjdk/jdk/blob/cbfddf4e1d3ff8dddb95bcb9242b31c175b768fc/src/java.base/windows/classes/sun/nio/fs/WindowsFileCopy.java#L363) operation.; All this PR does is to use `Files.deleteIfExists()` instead of calling `copy()` and `move()` with `StandardCopyOption.REPLACE_EXISTING`. Semantically the result is the same. I know that the issue is not on QuPath's side, however since the fix is very small on yourside i was hoping you would accept this PR anyway. It may come handy to other people in similar scenarios that don't know how to takle the problem",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1449:93,access,accessible,93,https://qupath.github.io,https://github.com/qupath/qupath/pull/1449,1,['access'],['accessible']
Security,"Requesting access to all 3 channels for subcellular detections, useful when handling non-standard stains (Brightfield Other). It would be much easier than juggling around the detections and color vectors and re-inserting them into the project.; ![image](https://user-images.githubusercontent.com/23145209/56070489-ddac7a80-5d3c-11e9-9c0e-d86cccf87dea.png). :)",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/304:11,access,access,11,https://qupath.github.io,https://github.com/qupath/qupath/issues/304,1,['access'],['access']
Security,Security Concern when installing QuPath using .msi,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1108:0,Secur,Security,0,https://qupath.github.io,https://github.com/qupath/qupath/issues/1108,1,['Secur'],['Security']
Security,"See discussion at https://github.com/qupath/qupath/issues/1317. This PR has become much more extensive and cover a few (unexpectedly) interrelated issues. ## Viewer grids & detached viewers. The PR aims to improve the use of multiple viewers more generally:. * The *View &rarr; Multi-view...* main menu and *Multi-view* popup menu (accessed by right-click on a viewer) now contain commands to set a fixed grid size of viewers: 1x1, 1x2, 2x1, 2x2, 3x3.; * This makes it much easier to create a viewer grid for common sizes, without needing multiple steps to add rows/columns.; * Text and icons show the expected grid shapes so they should be easy to interpret; * New commands are added to *Detach viewer from the grid* and subsequently to *Attach viewer to the grid*, so that viewers can be moved to their own floating windows and back again. ## PathPlugin & PluginRunner. When making the above changes, it became clear that a major refactoring & simplification of `PathPlugin` and `PluginRunner` was needed. The original problem was that `PluginRunnerFX` proved to be buggy with detached windows, because the `ImageData` being handled was accessed via `PluginRunner.getImageData()`. In most cases that's fine, but `PluginRunnerFX` was always returning the *current* `ImageData` from QuPath, and if this *changed* before the plugin was complete (and had fired any hierarchy updates / logged any workflow steps) then exceptions or unexpected behavior could occur. It might conceivably have happened previously when using multiple viewers, but I don't know of any cases where it did - because QuPath locks the UI when plugins run, and this seemed to be working ok. So this PR also includes a new design greatly simplifies `PluginRunner` to simple run tasks in parallel with progress notification - with some special logic for `PathTask` implementations. Alongside that,; ```java; PathPlugin.runPlugin(PluginRunner pluginRunner, String arg); ```; has been updated to; ```java; PathPlugin.runPlugin(PluginR",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1318:332,access,accessed,332,https://qupath.github.io,https://github.com/qupath/qupath/pull/1318,1,['access'],['accessed']
Security,Shorten Classifications menu for easier access,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1644:40,access,access,40,https://qupath.github.io,https://github.com/qupath/qupath/issues/1644,1,['access'],['access']
Security,"Slightly off QuPath- I don't know what scanner you are using, but if you have access to it, I think most should have a brightfield compensation image adjustment setting (it takes a picture of a blank slide and adjusts). We had some yellowing in ours after some software updates, and that took care of the background.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/53#issuecomment-282609510:78,access,access,78,https://qupath.github.io,https://github.com/qupath/qupath/issues/53#issuecomment-282609510,1,['access'],['access']
Security,"So I confirm that all access to any mutable variable should be synchronized. From ""Concurrency in Practice"":. > Whenever more than one thread accesses a given state variable, and one of them might write to it, they all must coordinate their access to it using synchronization. I can refactor `NumericMeasurementList` to make it thread-safe.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1444#issuecomment-1941504478:22,access,access,22,https://qupath.github.io,https://github.com/qupath/qupath/issues/1444#issuecomment-1941504478,3,['access'],"['access', 'accesses']"
Security,"Sorry @MichaelSNelson I entirely missed this until @finglis mentioned it :). > One of the things I have often preferred about QuPath is how neatly it arranges most of the windows into a single UI, where I don't have to fight with ""is what I want to use on top and accessible"" like with Fiji and MicroManager etc.; > ; > If implemented, there really should be ways to quickly and easily organize the windows, like the Tile and Cascade options in Fiji. I strongly agree - if you try https://github.com/qupath/qupath/pull/1318 I'd be curious as to whether you think it gets the balance ok. > > Is there a need to have the same image open in multiple viewers?; > ; > This has been one of the things I have often wanted to be able to do for multiplex images (along with synchronize for panning). Having the same image open, but with different sets of channels visible in each MultiView.; > ; > It was something I remember being able to do in earlier versions that has since been removed. I don't remember that ever being there by design, but it certainly could have been there as a bug :)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1317#issuecomment-1713712459:264,access,accessible,264,https://qupath.github.io,https://github.com/qupath/qupath/issues/1317#issuecomment-1713712459,1,['access'],['accessible']
Security,"Thank You for the quick response, will do!. > On 22 Mar 2018, at 15:56, Svidro <notifications@github.com> wrote:; > ; > If you want help with a particular project, please post more information over at https://groups.google.com/forum/#!forum/qupath-users <https://groups.google.com/forum/#!forum/qupath-users>; > I would recommend at least copy of your workflow script (https://github.com/qupath/qupath/wiki/Workflows <https://github.com/qupath/qupath/wiki/Workflows>) so we know what you have tried and/or are trying.; > ; > And perhaps some small jpeg images so we know what you are looking at (if allowed by confidentiality).; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub <https://github.com/qupath/qupath/issues/161#issuecomment-375335956>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Aj62c1nfD8q8Q2p2iSVzMVUc7IyXMSaWks5tg7uagaJpZM4S3MDO>.; >",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/161#issuecomment-375336673:610,confidential,confidentiality,610,https://qupath.github.io,https://github.com/qupath/qupath/issues/161#issuecomment-375336673,1,['confidential'],['confidentiality']
Security,"Thank you Pete. Kathy. From: Pete <notifications@github.com>; Reply-To: qupath/qupath <reply@reply.github.com>; Date: Monday, June 8, 2020 at 12:11 PM; To: qupath/qupath <qupath@noreply.github.com>; Cc: ""Kathleen T. Yee"" <KYee@umc.edu>, Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [qupath/qupath] Zoom In and Zoom Out (#518). This looks like a simple bug, albeit one that has existed for some months at least - weirdly without being reported before. Should be fixed in the next minor release, but I first need to check it in more detail. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fissues%2F518%23issuecomment-640758278&data=02%7C01%7Ckyee%40umc.edu%7Cd4b7b44c44274db73a8308d80bcef036%7C78a0681ef0be47e280498616858818a5%7C0%7C1%7C637272330716768343&sdata=I6ByW3NeHWrDm7VTBAvpv2MpkhL6TLrhVIKQdriYgAA%3D&reserved=0>, or unsubscribe<https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAP4MNEYF5JGJNVJRBCHLL3DRVULSZANCNFSM4NYSD4CA&data=02%7C01%7Ckyee%40umc.edu%7Cd4b7b44c44274db73a8308d80bcef036%7C78a0681ef0be47e280498616858818a5%7C0%7C1%7C637272330716773334&sdata=3J8BiWMPaBCV6Q7lr8IOEGiTxaRqEaq2AUvxwH2crGY%3D&reserved=0>. Individuals who have received this information in error or are not authorized to receive it must promptly return or dispose of the information and notify the sender. Those individuals are hereby notified that they are strictly prohibited from reviewing, forwarding, printing, copying, distributing or using this information in any way.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/518#issuecomment-640759146:1427,authoriz,authorized,1427,https://qupath.github.io,https://github.com/qupath/qupath/issues/518#issuecomment-640759146,1,['authoriz'],['authorized']
Security,"Thank you both for your response. I would preferably like to run the software on the mac but have access to PC too if this is more suitable . The original files I wanted to work with were TMAs with multiple scenes but I cannot even open a jpg file. I am at home now and I am on my mac and it is still not opening the jpg files. . Thank you for looking into addressing the qupath bio-formats extension. In the meantime, should I need to download any extensions to run the software on the mac? I know in your tutorial for start ups you suggest you do but I have had no joy with this . Thank you again",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/135#issuecomment-357053806:98,access,access,98,https://qupath.github.io,https://github.com/qupath/qupath/issues/135#issuecomment-357053806,1,['access'],['access']
Security,"Thanks @MichaelSNelson! The main idea here is to support adding text but without really specifying what that has to be... so someone could use it in the way you describe for clustering, but could use it for something else entirely. The use cases I'm thinking of here are really; * teaching, where an object annotation could be some useful explanatory text; * recording thoughts... where an object (or full image) annotation could be some comment on the image or analysis, e.g. *'excluded because of quality issues'*, or *'annotated by Pete on a rainy Tuesday'* etc. But it could also be a link to a website, a GitHub repository, or even even the text for a script used for the processing. For these, it needs to display nicely - hence the html support. > Extra intention: make it possible to export a summary markdown report, including image thumbnails. This could be used to give a portable, readable summary of an entire project in html. That could be handy, e.g. when asking a pathologist to QC a lot of annotations. For analysis-oriented things like the clustering application, it's already technically possible to use; ```groovy; getSelectedObject().storeMetadataValue('My key', 'My value'); fireHierarchyUpdate(); ```; currently, but only because of Groovy's laxity (the methods are `protected`) - and it won't show up in any results tables. It will also have all the detections-suddenly-use-a-whole-lot-more-memory issue, so *really* isn't to be encouraged at the moment. Nevertheless, exposing access to the arbitrary metadata map an official part of the API could be another new feature.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1005#issuecomment-1180644703:1502,access,access,1502,https://qupath.github.io,https://github.com/qupath/qupath/issues/1005#issuecomment-1180644703,1,['access'],['access']
Security,"Thanks @charleshugo QuPath's object classifiers aren't intended to be trained with so many cells. I would strongly recommend using far fewer and smaller training annotations. The actual `RTrees` classifiers are implemented in C++ (by OpenCV). After QuPath has generated the training data, the training itself is performed inside OpenCV and in accessible to QuPath. As far as I am aware, this is single-threaded in OpenCV and cannot be changed in QuPath. Similarly, JSON generation and parsing is performed with the help of the Gson library, so performance depends somewhat on Gson. GeoJSON is a standard for representing geometries; I think it solves a different problem from Parquet. In QuPath, it is primarily intended to facilitate exchanging annotations, where choosing an existing open format is strongly desirable for interoperability (rather than trying to define a new standard others have to follow). Performance should not be an issue with several hundred/thousand objects (the common scenario), but it will inevitably be slow to export to export millions of cells as GeoJSON. If you don't need geometry information, you could export much more efficiently features/classifications/centroids only (e.g. through [a measurement table](https://qupath.readthedocs.io/en/stable/docs/tutorials/exporting_measurements.html)). Alternatively, if you need a highly optimized solution or a custom format then you can implement one using a QuPath script or extension. I'd like to close this issue because I think there is no bug in QuPath. The best place for discussing the use of the software or suggested improvements is http://forum.image.sc/tag/qupath. >If you'd like to add a separate GitHub issue for the minimized windows, please fill in the bug report template. I have seen some issues on Ubuntu with Windows not being in the correct place, but not on Windows or macOS. I cannot tell if it is a problem that QuPath can solve, or if it is an issue in JavaFX. But the issue I have seen does not mak",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/831#issuecomment-950106875:343,access,accessible,343,https://qupath.github.io,https://github.com/qupath/qupath/issues/831#issuecomment-950106875,1,['access'],['accessible']
Security,"Thanks a lot for your answer. So running the following code when opening a new image is relatively painless:; `// Get access to the display info for each channel; def viewer = getCurrentViewer(); def channels = viewer.getImageDisplay().getAvailableChannels(). // Set the range for the 4 channelsf; channels[0].setMinDisplay(0); channels[0].setMaxDisplay(255); channels[1].setMinDisplay(0); channels[1].setMaxDisplay(255); channels[2].setMinDisplay(0); channels[2].setMaxDisplay(255); channels[3].setMinDisplay(0); channels[3].setMaxDisplay(255). // Set the LUT color for the first channel & repaint; channels[0].setLUTColor(0, 0, 255); channels[1].setLUTColor(255, 255, 255); channels[2].setLUTColor(0, 255, 0); channels[3].setLUTColor(255, 0, 0). // Ensure the updates are visible; viewer.repaintEntireImage(). // Usually a good idea to print something, so we know it finished; print 'Done!'`. Regarding the pink staining actually it doesn't look like it's the label. It might just be a very low resolution scan, probably brightfield used by the scanner to detect the coverslip and slide.; Do you think it would need a Bio-Formats update for QuPath to access the label image? Or is this something that could be implemented directly in QuPath? The label must be somewhere in the `.scn` as I can see it if I open the image in imageJ, or other softwares (Definiens, Halo, ImageScope...).",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/191#issuecomment-409927029:118,access,access,118,https://qupath.github.io,https://github.com/qupath/qupath/issues/191#issuecomment-409927029,2,['access'],['access']
Security,"Thanks for the detailed response Peter. That's a great starting point. ; As a follow up, is there a good place to learn about how to access QuPath data from the groovy scripting interface? Perhaps a list of the available data stored in various objects and the methods that can be used to access them? The examples are a great start, and have been very good at interpreting the kinds of things we're hoping to do, but it can be hard to go beyond them (short of diving deeper into the QuPath code itself).; The software has been very impressive so far - great interface and the scripting capability makes it feel quite extensible. Best,; Colin",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/44#issuecomment-273939189:133,access,access,133,https://qupath.github.io,https://github.com/qupath/qupath/issues/44#issuecomment-273939189,2,['access'],['access']
Security,Thanks for the reply. I think I actually figured out why it wasn't working before. The refresh method's accessibility was changed in javafx from Java 8u60 and onwards. I didn't realize but I was running an older JRE on Eclipse and thus the compilation error.,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/87#issuecomment-316820068:104,access,accessibility,104,https://qupath.github.io,https://github.com/qupath/qupath/issues/87#issuecomment-316820068,1,['access'],['accessibility']
Security,"Thanks for your answer, no worries.; I have additional questions regarding .scn files:. - Using the following script:; `// Get access to the display info for each channel; def viewer = getCurrentViewer(); def channels = viewer.getImageDisplay().getAvailableChannels(); // Set the range for the 4 channelsf; channels[0].setMinDisplay(0); channels[0].setMaxDisplay(255); channels[1].setMinDisplay(0); channels[1].setMaxDisplay(255); channels[2].setMinDisplay(0); channels[2].setMaxDisplay(255); channels[3].setMinDisplay(0); channels[3].setMaxDisplay(255); // Set the LUT color for the first channel & repaint; channels[0].setLUTColor(0, 0, 255); channels[1].setLUTColor(255, 255, 255); channels[2].setLUTColor(0, 255, 0); channels[3].setLUTColor(255, 0, 0); // Ensure the updates are visible; viewer.repaintEntireImage(); // Usually a good idea to print something, so we know it finished; print 'Done!'`. I tried ""Run for Project"" to get the settings applied on all the images within the project, it seems to be doing it as the prompt iterates the list of images, but when I open another image of the project, the view settings remain unchanged... Is there a trick?. - If I open a batch of images as a project, QuPath opens all images, including the pink one and the low res scan. I then delete these low-res images one by one as I am not able to press ctrl+click to select several at the same time and then deleting them all. Would there be a quicker way?. - some images have different ""high resolution"" scans because several regions have been selected during the slide scan. When opening chromogenic images, there is no problem and QuPath handles it well within a single image. But with fluorescent images, they appear as individual images in the image list... would it be possible to have them all opened within the same image by any chance?. - regarding your recent blog post, the script to update measurement names does not work with these images (unless there is something to edit in the script?)",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/191#issuecomment-411572502:127,access,access,127,https://qupath.github.io,https://github.com/qupath/qupath/issues/191#issuecomment-411572502,1,['access'],['access']
Security,"Thanks!. * Where should we place the `ReaderPool` and `ReaderWrapper` classes? Currently there are in the `servers.bioformats` package, but they are not specific to bio-format. `ReaderPool` seems to be currently - it still has quite a lot of `loci.*` imports, which would prevent it from moving to a more core QuPath module. I think that's fine because it makes sense for the OMERO extension to depend upon the Bio-Formats one - at least for raw pixel access via ICE, since many other dependencies are shared. And if we follow the advice of [accessing pixels by Zarr](https://forum.image.sc/t/java-gateway-authentication-using-the-json-api/84307/8) then we might still have a Bio-Formats dependency via `OMEZarrReader` [as described here](https://forum.image.sc/t/getting-started-with-ome-zarr-in-java/85333). * Should I refactor the BioFormatImageServer to use the best practises we have been discussing? I see this file has a few warnings and the constructor takes 500 lines. Yes, that would be good. But we can merge sooner if it helps. * I will now try to use `ReaderPool` and `ReaderWrapper` in the OMERO extension, so I may have to change a few things if I realize that theses classes are not completely generic. I don't think you need to worry too much about making them very generic - just to work well enough for Bio-Formats and OMERO. They both have a quite different way of returning pixel arrays that I haven't seen elsewhere. Based on the recent forum discussion, I have the impression that the current working Zarr support for Java uses [n5-zarr](https://github.com/saalfeldlab/n5-zarr), which in turn relates to (I think...) imglib2. Since we already plan to explore imglib2, there's a chance that a lot of QuPath's `ImageServer` and image reading code may be replaced if we find better approaches with imglib2.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1287#issuecomment-1691869139:452,access,access,452,https://qupath.github.io,https://github.com/qupath/qupath/pull/1287#issuecomment-1691869139,3,"['access', 'authenticat']","['access', 'accessing', 'authentication-using-the-json-api']"
Security,"Thanks!. For the TMA data viewer troubles, to be honest I entirely forgot that the *Import from current project (experimental)* option is there... it probably isn't a very good idea. I'd suggest doing the following instead:; * Use *File &rarr; Export TMA data* for each of your images, using the same output directory (it's also scriptable); * Drag the export directory into the TMA data viewer. That way, the data viewer doesn't need to bother with QuPath objects (potentially hundreds of MB per TMA), nor with accessing the whole slide scans. Rather, it will work with small, exported JPEGs and parsed text files, and hopefully behave much better.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/117#issuecomment-343394860:512,access,accessing,512,https://qupath.github.io,https://github.com/qupath/qupath/issues/117#issuecomment-343394860,1,['access'],['accessing']
Security,"Thanks, I remain confused because I can see you're using https://github.com/BIOP/qupath-extension-cellpose - which is developed separately by another group. That's where all the CellPose/Miniconda things arise, since they aren't part of QuPath. Your steps don't mention installing the extension, miniconda or Cellpose though, so I can't tell when or why any problem occurs. Also, if the files are accessible via Windows Explorer / the file chooser then I also don't know see where this would be a QuPath problem... so I remain unclear that there is any bug here, at least in QuPath. @lacan may be able to help from the CellPose extension side, or the community forum may be a better place for the discussion that spreads across different software: https://forum.image.sc/tag/qupath",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1108#issuecomment-1302320391:397,access,accessible,397,https://qupath.github.io,https://github.com/qupath/qupath/issues/1108#issuecomment-1302320391,1,['access'],['accessible']
Security,"Thanks, could you describe in more detail what this fixes?. Can you provide any minimal example of the bug - ideally [with a unit test](https://github.com/qupath/qupath/blob/main/qupath-core/src/test/java/qupath/lib/objects/classes/TestPathClass.java)?. Based on the other thread I tried running; ```groovy; pc1 = QP.getPathClass(""Right""); pc2 = QP.getDerivedPathClass(pc1, ""hello"").getParentClass(); println pc1 === pc2; println pc1.hashCode(); println pc2.hashCode(); ```; but that behaved properly, so I'm not sure what exactly is wrong.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1286#issuecomment-1670011437:434,hash,hashCode,434,https://qupath.github.io,https://github.com/qupath/qupath/pull/1286#issuecomment-1670011437,2,['hash'],['hashCode']
Security,"Thanks, that would be good - it sounds like it would be difficult and time-consuming for anyone else to replicate the problem, and might not be possible if it turns out to be something more specific to your system. So solving this will likely require any any info you can get from VisualVM's CPU sampling. I'll try to write up info about VisualVM + QuPath at some point, but there are brief instructions at https://forum.image.sc/t/designing-a-qupath-workstation/54849/14. QuPath shouldn't be regenerating thumbnails when a project is opened, and it shouldn't be remembering anything (other than the preferences) across relaunches. v0.4.0 should generating missing thumbnails only, and do so in a background thread that doesn't block. Both v0.3 and v0.4 will try to access the thumbnail images in the project when it is opened; this *could* potentially block the UI, because it needs to be done in the UI thread (and there can only be one). However these should generally be small JPEGs so I've never known that to be a problem. Therefore I'd only expect this to be troublesome if there is some other reason why access to the disk is exceptionally slow. I couldn't really tell what was going on in the video, partly because the analysis pane was closed - and when the image was opened I couldn't really see how or when that happened. For slightly more info in the log, you can switch the log level in the preferences from `INFO` to `DEBUG`. Not sure if that will help narrow things down or not.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1154#issuecomment-1326026753:766,access,access,766,https://qupath.github.io,https://github.com/qupath/qupath/issues/1154#issuecomment-1326026753,2,['access'],['access']
Security,"Thanks, the screenshot suggests it's the `Files.exists()` check that is so slow. QuPath is probably calling this quite a lot, because it's usually really inexpensive - and *not* calling it leaves open the (admittedly small) possibility that the file has been deleted between calls. I could try to cut down on this, but I'm skeptical that it will help because it sounds a lot like it's only the first call that is slow. In fact, I'd be curious as to whether accessing each file is slow or just the first one on the disk. That should be relatively easy to test by creating a much smaller project and comparing the speed. Either way, it sounds like the problem lurks in the realm of Java, the operating system, and the hard drive. I'm not sure if there's much can be done about it in QuPath. I'd suggest:. * try accessing the images some other way before opening them in QuPath (e.g. through Windows Explorer), in case 'pre-warning' the OS is somehow useful; * try copying the images to a local drive (if possible); * try timing a simple script with a file on the same disk, e.g. ```groovy; import java.nio.file.*; var path = '/path/to/some/file'; println ""Exists: ${Files.exists(Paths.get(path))}""; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1154#issuecomment-1327044045:457,access,accessing,457,https://qupath.github.io,https://github.com/qupath/qupath/issues/1154#issuecomment-1327044045,2,['access'],['accessing']
Security,"Thanks, this is an interesting idea and certainly seems to help in the scenario you describe. I'm apprehensive about merging quickly because it would be quite a significant change, and add complexity when we're trying to reduce it. So it will take some thought and I'd like to understand the problem better. > This last change alone allowed, on my projects, to improve the time when creating an object classifier from ~10/15minutes to ~5seconds. Can you explain why it takes so long? Huge numbers of images? Slow file format, or is it where the images are stored?. > Additionally, allowed to modify `ObjectClassifierCommand` too so that it can read all detections' measurements in the training set without uselessly reading the image files. The [`ObjectClassifier`](https://qupath.github.io/javadoc/docs/qupath/lib/classifiers/object/ObjectClassifier.html) takes an `ImageData` by design because an object classifier *could* require pixel access... and this is very likely to be important in the future. This is because, when I rewrote object classifiers some years ago, I was thinking of future classifiers that will use deep learning models to classify based upon image patches - and not only measurements. That's why there is also a general [`FeatureExtractor`](https://qupath.github.io/javadoc/docs/qupath/opencv/ml/objects/features/FeatureExtractor.html) class. This all basically works, we just haven't yet had time to wrap it up for wider use. > You can now pass a `openImage` boolean to `ProjectImageEntry.readImageData()` that, when false, just avoids getting the default image server, but just uses an instance of `ImageServerStub`. While not identical, the current `ProjectImageEntry.readHierarchy()` is intended for when you need objects but not everything else. This already lets you access all measurements etc. without touching the image. You can then create a new `ImageData` with a dummy `ImageServer` if you need to. So an alternative approach might be to try to script creating a cl",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1488#issuecomment-2021998811:939,access,access,939,https://qupath.github.io,https://github.com/qupath/qupath/pull/1488#issuecomment-2021998811,1,['access'],['access']
Security,"Thanks, this script only works because Groovy permits access to package-private classes/constructors/methods, e.g. [`ChannelTransformFeatureServer`](https://github.com/qupath/qupath/blob/8136994f8e6ef2f3a33a72467fd7c71c35977ad6/qupath-core/src/main/java/qupath/lib/images/servers/ChannelTransformFeatureServer.java#L52) and [`ExtractChannel`](https://github.com/qupath/qupath/blob/8136994f8e6ef2f3a33a72467fd7c71c35977ad6/qupath-core/src/main/java/qupath/lib/images/servers/ColorTransforms.java#L262). So this couldn't be used (easily) from Java. In my mind, `TransformedServerBuilder` was intended to be the main way to create a new server that applies transforms so that users don't need to learn about other classes. It also limits the main source to [one page on the javadocs](https://qupath.github.io/javadoc/docs/qupath/lib/images/servers/TransformedServerBuilder.html). Similarly, static methods of `ColorTransforms` can be used [here](https://qupath.github.io/javadoc/docs/qupath/lib/images/servers/ColorTransforms.html). To further simplify the script, I'd suggest concatenating lists rather than streams - since this is likely more intuitive for more people. And you can use [`server.nChannels()`](https://qupath.github.io/javadoc/docs/qupath/lib/images/servers/ImageServer.html#nChannels()) instead of needing to query the metadata and get the size of the channels list. So you might use; ```groovy; def channels = getCurrentServer().getMetadata().getChannels().collect {c -> ColorTransforms.createChannelExtractor(c.name)}; channels += [ColorTransforms.createLinearChannelCombination(coeffs)]; ```; but I think something like this is more readable to more people; ```groovy; def channels = []; for (int c = 0; c < server.nChannels(); c++); channels.add(ColorTransforms.createChannelExtractor(c.name)); channels.add(ColorTransforms.createLinearChannelCombination(coeffs)); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1566#issuecomment-2260153194:54,access,access,54,https://qupath.github.io,https://github.com/qupath/qupath/pull/1566#issuecomment-2260153194,1,['access'],['access']
Security,That is the file in question:; https://box.med.uni-heidelberg.de/s/qjr7vvn7P9akLMx; Password for access: QuPathrocks1!; It was created using Olympus' cell^F software and is a so-called SIS-TIFF (Olympus' own TIFF variant),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/573#issuecomment-664551831:84,Password,Password,84,https://qupath.github.io,https://github.com/qupath/qupath/issues/573#issuecomment-664551831,2,"['Password', 'access']","['Password', 'access']"
Security,"The _Add Delaunay cluster features_ command has the potential to be very useful, but is currently incomplete. The most obvious issue is that it creates an overlay that can have a considerable negative impact on repainting speed. Furthermore, this overlay cannot be removed from the GUI - the only way to get rid of it is to run the command again with _Show overlay_ unchecked. ![delaunay_overlay](https://cloud.githubusercontent.com/assets/4690904/19434507/b4b85914-945d-11e6-8a6d-f2de2129e7e3.jpg). The issue remains because solving it properly is likely to require a few different things:; - Providing access to all overlays within the GUI, allowing them to be turned on/off/deleted; - Deciding on the most important Delaunay features to use; - Designing an appropriate data structure to store Delaunay information (possibly in a way that can be serialized?). It is also important to remove the overlay from the plugin itself, since this introduces a very unhealthy GUI dependency. Rather, a data structure to represent the Delaunay information ought to be defined in a core module, and then the overlay code kept separate within the GUI module. Consideration also needs to be given to whether the calculations should be updated as objects are added/removed, or (more likely) not.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/7:604,access,access,604,https://qupath.github.io,https://github.com/qupath/qupath/issues/7,1,['access'],['access']
Security,"The core images are loaded in a background thread, and there is a 5 second timeout associated with this - see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L254). One possibility is that the timeout isn't generous enough in your case, and the cores are not being loaded fast enough. I don't know why that would be the case... it might be to do with the computer specifications, where the image is located (a network share?), or the access time required for the specific file format. Another option is that there are just too many cores. That is my best guess, since the scrollbar thumb on the right in your screenshot looks very small. There is a limit to the size of the cache used to store the TMA cores to reduce the risk of memory errors, see [here](https://github.com/qupath/qupath/blob/v0.1.2/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/TMAGridView.java#L133) for the location in the code. Currently there is no way to increase the size of the cache through the user interface to support more cores in the grid view. Although, as is often the case, there is a way through a script. You could try running this to double the cache size to see if it helps.; ```groovy; qupath.lib.gui.commands.TMAGridView.MAX_CACHE_SIZE = 500; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/96#issuecomment-326105429:507,access,access,507,https://qupath.github.io,https://github.com/qupath/qupath/issues/96#issuecomment-326105429,1,['access'],['access']
Security,"The files that mismatch are things like `C:\Users\alano\Application Data`, which doesn't seem to exist, at least when I paste it into explorer I get `[directory] is not accessible. Access is denied`, and they're not visible when viewing the parent dir in explorer or cmd. Somewhat bizarre behaviour, can chalk it up to Windows I think",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1298#issuecomment-1691770235:169,access,accessible,169,https://qupath.github.io,https://github.com/qupath/qupath/pull/1298#issuecomment-1691770235,2,"['Access', 'access']","['Access', 'accessible']"
Security,"The goal of this PR was to find a good solution for [this issue](https://forum.image.sc/t/add-additional-channel-in-fluorescence-image-after-scanning/99174/) (in short, creating a new channel by linearly combining existing channels). . This was done by adding a new `ColorTransforms` called `LinearCombinationChannel` that applies a linear combination to the channels. The existing `ColorTransforms` were a bit refactored to remove the warnings and improve null safety (but their behaviors stay the same). Tests were added for all existing `ColorTransforms` and the new `LinearCombinationChannel`. Implementations for `hashCode` and `equals` in `ColorDeconvolutionStains` were also added because it was needed for unit tests.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1566:619,hash,hashCode,619,https://qupath.github.io,https://github.com/qupath/qupath/pull/1566,1,['hash'],['hashCode']
Security,"The minus key on my main keyboard and the minus key on my number pad both cause; zooming-in / increased magnification. Both of my + keys don’t do anything. From: MicroscopyRA <notifications@github.com>; Reply-To: qupath/qupath <reply@reply.github.com>; Date: Monday, June 8, 2020 at 1:26 PM; To: qupath/qupath <qupath@noreply.github.com>; Cc: ""Kathleen T. Yee"" <KYee@umc.edu>, Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [qupath/qupath] Zoom In and Zoom Out (#518). Right, that was the first part, sorry for lack of clarity. Num lock on or off has no impact. ""The + and - keys no the num pad do nothing when I use them."". —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fissues%2F518%23issuecomment-640795671&data=02%7C01%7Ckyee%40umc.edu%7C3f6606e691e84856b92008d80bd9728c%7C78a0681ef0be47e280498616858818a5%7C0%7C0%7C637272375844340509&sdata=PdIW4tJzmYbxH24BlWci00hk0WXzvZf6SoWFDKxEnks%3D&reserved=0>, or unsubscribe<https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAP4MNEZE2DLPTDWWMJINGMLRVUUM3ANCNFSM4NYSD4CA&data=02%7C01%7Ckyee%40umc.edu%7C3f6606e691e84856b92008d80bd9728c%7C78a0681ef0be47e280498616858818a5%7C0%7C0%7C637272375844350502&sdata=80Q8pB3Tqf9csexrlxWph406VYzvfheP775lDTJ9y6Q%3D&reserved=0>. Individuals who have received this information in error or are not authorized to receive it must promptly return or dispose of the information and notify the sender. Those individuals are hereby notified that they are strictly prohibited from reviewing, forwarding, printing, copying, distributing or using this information in any way.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/518#issuecomment-640799956:1511,authoriz,authorized,1511,https://qupath.github.io,https://github.com/qupath/qupath/issues/518#issuecomment-640799956,1,['authoriz'],['authorized']
Security,"There are many problems with groovy script processing, so I read the source code of the qupath software. And call the java interface to process the image. I want to save the analyzed image, but I failed, I don't know how to deal with this problem, so I hope to get your help.; -------------------------------; import java.awt.image.BufferedImage;; import java.io.IOException;; import java.util.Hashtable;; import java.util.SortedMap;. import javax.imageio.spi.ImageWriterSpi;. import org.controlsfx.control.SnapshotView;. import ij.plugin.JpegWriter;; import javafx.scene.SnapshotResult;; import qupath.lib.gui.ImageWriterTools;; import qupath.lib.gui.QuPathGUI;; import qupath.lib.gui.commands.SaveViewCommand;; import qupath.lib.gui.prefs.PathPrefs;; import qupath.lib.images.ImageData;; import qupath.lib.images.servers.ImageServer;; import qupath.lib.images.servers.ImageServerProvider;; import qupath.lib.io.ImageWriter;; import qupath.lib.regions.RegionRequest;; import qupath.lib.roi.interfaces.ROI;; import qupath.lib.scripting.QP;; import qupath.lib.scripting.QPEx;. public class test01 {; 	private static QuPathGUI qupath;; 	private static boolean wholeWindow;; 	; 	public void mydetection() throws InterruptedException {; 		// TODO Auto-generated method stub; 		String imagePath=""D:\\Overview\\9624CE91-1DA8-40AE-89AC-41412BE756DB.jpg"";; 		ImageServer<BufferedImage> server = ImageServerProvider.buildServer(imagePath, BufferedImage.class);; 		ImageData imageData = new ImageData<>(server);; 		String bind = ""{\""threshold\"": 162, \""requestedDownsample\"": 1.0, \""minAreaPixels\"": 100000.0, \""maxHoleAreaPixels\"": 500.0, \""darkBackground\"": false, \""smoothImage\"": true, \""medianCleanup\"": true, \""dilateBoundaries\"": false, \r\n"" + ; 				"" \""smoothCoordinates\"": true, \""excludeOnBoundary\"": false, \""singleAnnotation\"": true}');"";; 		boolean detection = false;; 		try {; 			detection = QP.runPlugin(""qupath.imagej.detect.tissue.SimpleTissueDetection2"",bind);; 		} catch (Exception e) {; 			",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/216#issuecomment-420269884:394,Hash,Hashtable,394,https://qupath.github.io,https://github.com/qupath/qupath/issues/216#issuecomment-420269884,1,['Hash'],['Hashtable']
Security,"There is a bug in how images are accessed from ImageJ from multiple threads; if two threads request part of the image simultaneously, then a different part of the image _may_ be returned for at least one of the threads than is expected. This bug should only matter if the 'Server type' is shown in the 'Image' tab is 'ImageJ server'; other servers are not affected by this. This means that the primary data used within QuPath, i.e. whole slide images (which are not supported by ImageJ servers), are unaffected. Additionally, most uses of an 'ImageJ server' are restricted to small images, where multithreading is not used for most commands requiring pixel access. Consequently, the only practical, reproducible occurrence of which I'm aware is whenever the *Analyze &rarr; Calculate features &rarr; Add intensity features...* command is run for an ImageJ server. In this case, it is possible (but not inevitable) that the wrong features are calculated for some regions. In the long term, this should be easily fixed by introducing synchronization to the access method. In the short term, if this bug is causing trouble then the workaround is to go to the *Preferences* and set the *Number of processors for parallel commands* value to 1.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/74:33,access,accessed,33,https://qupath.github.io,https://github.com/qupath/qupath/issues/74,3,['access'],"['access', 'accessed']"
Security,"There is really not enough information here to answer, and since it does not relate to a bug https://forum.image.sc/tags/qupath would be the right place to post this question. My guess is that your images may have moved / be on an external disk that is not accessible when you try to reopen the m2 project using QuPath v0.2.0-m2. But I would need to know what error messages are displayed, and if anything appears under *View &rarr; Show log*. It is not expected that a project created using m2 will open with m8 because of large changes between milestones; specifically I recall the project structure changed from m2 to m3 (I don't remember if there were subsequent changes). There is a script to migrate old projects from m2 to m3, but use with caution (i.e. with backups) and be sure to read the description at the top if you use it: https://gist.github.com/petebankhead/8dfbaf2de91f6432b79c7678e2997d6a",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/388#issuecomment-567854079:257,access,accessible,257,https://qupath.github.io,https://github.com/qupath/qupath/issues/388#issuecomment-567854079,1,['access'],['accessible']
Security,"These will likely cause some problems:; * Any JavaFX from 20.0.1 onwards breaks (javascript) search links within javadocs - at least when accessing javadocs from within a .jar; * Deep Java Library has probably broken the approach previously used to test if an `Engine` is available before attempting to download it. Nevertheless, we don't want to be stuck on old dependencies - so merging early in the path towards v0.6.0 will hopefully give us time to find fixes/workarounds. This commit also updates the pref name to have the correct QuPath version.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1496:138,access,accessing,138,https://qupath.github.io,https://github.com/qupath/qupath/pull/1496,1,['access'],['accessing']
Security,"This PR proposes a moderately significant change to the `ImageServer` interface, which I'd like to discuss (and sanity-check) with the people most affected. @iwbh15 @NicoKiaru @lacan @ap-- @sdvillal @finglis (sorry if I have missed anyone...). The background is that pixels are currently accessed in QuPath via something like; ```java; RegionRequest request = RegionRequest.createInstance(server.getPath(), downsample, x, y, width, height);; BufferedImage img = server.readBufferedImage(request);; ```. Creating a `RegionRequest` made sense in the early days, since it was used for caching. It remains useful for accessing corresponding regions in paired images, or for creating requests from ROIs, and for avoiding a plethora of parameters (particularly if `z` and `t` indices should be returned as well). However, often it just feels like unnecessary overhead, e.g. when writing simple scripts... or accessing from another language, like Python. It is pretty easy to retrofit support for; ```java; BufferedImage img = server.readBufferedImage(downsample, x, y, width, height, z, t);; BufferedImage img2 = server.readBufferedImage(downsample, x, y, width, height);; ```; by simply adding default methods to the interface. I don't think this should break anything. However this leads to another consideration... `readBufferedImage` isn't a great name, since the method really returns an instance of whatever the generic parameter `T` stands for in `ImageServer<T>`. It happens that this is pretty much always `BufferedImage` in QuPath, but the original idea was that an `ImageServer` could exists that returns something else that might be more convenient (e.g. something from ImgLib2, or an OpenCV `Mat`). So rather than doubling-down on `server.readBufferedImage` I would like to switch to `server.readRegion(RegionRequest)` instead. This feels to me more accurate and intuitive. The tricky bit is not breaking everything else... like parts of paquo or warpy, and all existing scripts that need pixel",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1072:288,access,accessed,288,https://qupath.github.io,https://github.com/qupath/qupath/pull/1072,3,['access'],"['accessed', 'accessing']"
Security,"This addresses https://github.com/qupath/qupath/issues/981. Main changes:; * Adjust gamma in Brightness/Contrast window (no longer in preferences); * Apply gamma to mini/channel viewers; * Make gamma accessible via public methods on the viewer; * Warn in the Brightness/Contrast window when the gamma is anything other than 1; * Support unbinding the gamma property for a viewer and setting it manually via scripting (although discouraged). One concern is that this means that the gamma slider in the brightness/contrast dialog controls a global preference, whereas the min/max sliders operate per-viewer. This may need to revised if it causes confusion. Bonus:; * Show RGB histograms in Brightness/Contrast window",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/987:200,access,accessible,200,https://qupath.github.io,https://github.com/qupath/qupath/pull/987,1,['access'],['accessible']
Security,"This commit aims to fix the use of non-default directories: https://github.com/petebankhead/qupath/commit/8d7693b22c79446b0d92b6dac1afab6ccb2b0745. Note that you can set the directory in the preferences, but search for 'user' rather than 'extensions'. Note that this is in a particular branch of my fork; I plan to sanitize the various branches/forks in the near future to make it a bit clearer where everything is/should be.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/298#issuecomment-476286936:315,sanitiz,sanitize,315,https://qupath.github.io,https://github.com/qupath/qupath/issues/298#issuecomment-476286936,1,['sanitiz'],['sanitize']
Security,"This is certainly possible in a script, since the coordinates are stored at that level. But the details depend on the kind of regions you are drawing, and how you need them to be exported. For example, you can get the bounding box of any shape like this:; ```groovy; def roi = getSelectedObject().getROI(); print([roi.getBoundsX(), roi.getBoundsY(), roi.getBoundsWidth(), roi.getBoundsHeight()]); ```. That is really all you need to represent a rectangle or an ellipse. For a line, you could get the end points:; ```groovy; def roi = getSelectedObject().getROI(); print([roi.getX1(), roi.getY1(), roi.getX2(), roi.getY2()]); ```. Or, if you have a polygon then this will print the points:; ```groovy; def roi = getSelectedObject().getROI(); print roi.getPolygonPoints(); ```. As far as I recall, you can also use the final option for other shapes. But beware of complex 'areas', which could be composed of multiple polygons and include holes etc. Extracting and interpreting the coordinates for these is somewhat more difficult. If you need more than this, I would recommend looking at the scripting documentation on the wiki, and then exploring in more detail the code for each of the ROI (region of interest) classes to see how their points are stored and accessible.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/95#issuecomment-324421783:1258,access,accessible,1258,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-324421783,1,['access'],['accessible']
Security,"This is certainly possible, although will involve writing some Python and/or Groovy code. The basic process is:. 1. Get your contours (somehow) into arrays of x and y coordinates accessible to QuPath. 2. Create ```PolygonROI``` objects from each pair of coordinate arrays. If polygons are not sufficient, and you rather need complex shapes with holes, it is also possible - but considerably more awkward. 3. Create some kind of ```PathObject``` for each ```PolygonROI```; probably a ```PathDetectionObject``` (if there will be a lot of them) or ```PathAnnotationObject``` (if there won't). There is some more information [here](https://github.com/qupath/qupath/wiki/Types-of-object). 4. Add each ```PathObject``` to the object hierarchy in QuPath so that it can be displayed. There is some information relevant to the last 3 steps at https://github.com/qupath/qupath/issues/61. For the first step, there are a few different options:. * If you are much more comfortable with Python rather than Groovy/Java, then you could try one of the methods of using Python with QuPath described [in the Wiki](https://github.com/qupath/qupath/wiki/Working-with-Python). Conceivably, you might even be able to run your whole code that way… or else just parse the results exported in a Python-friendly format. * You could try using OpenCV via its Java bindings via Groovy via QuPath. If you set things up as described [here](https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ) then the dependencies should be accessible. * You could write a simple Python script to export the coordinates for each contour, and then write a simple Groovy script to parse this and bring the coordinates into QuPath. Of these, I would choose the last option. There may be some merit in the others, but I expect they would be more complicated to set up. There are lots of tricks and shortcuts in Groovy that may help with the parsing, e.g. in order to extract floating point coordinates (such as those required to cons",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/81#issuecomment-307854757:179,access,accessible,179,https://qupath.github.io,https://github.com/qupath/qupath/issues/81#issuecomment-307854757,1,['access'],['accessible']
Security,"This provides more opportunities to customize QuPath at launch, rather than afterwards. It may be useful for setting paths or options for DJL or JNA, without relying on persistent preferences. Example:; ```; /path/to/QuPath -DPYTORCH_VERSION=1.13.1 -Doffline=false; ```. It's also possible to do; ```; /path/to/QuPath -Djava.library.path=/something/; ```; but I'm not sure if that works... it should however work to set JNA paths, see https://java-native-access.github.io/jna/4.2.1/com/sun/jna/NativeLibrary.html",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1430:455,access,access,455,https://qupath.github.io,https://github.com/qupath/qupath/pull/1430,1,['access'],['access']
Security,"This question is too broad to answer well... QuPath is primarily a desktop application, which you can use to analyze whole slide images - interactively and by scripting. Once you've established what you want to do, you can batch process it. To make QuPath accessible from IntelliJ, for Groovy scripting or potentially other reasons, see https://github.com/qupath/qupath/wiki/Advanced-scripting-with-IntelliJ. If this doesn't answer your question, please describe more fully what exactly you want to do.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/192#issuecomment-409096361:256,access,accessible,256,https://qupath.github.io,https://github.com/qupath/qupath/issues/192#issuecomment-409096361,1,['access'],['accessible']
Security,"This should create eg `build/dist/QuPath-0.5.0-SNAPSHOT.deb.sha512` with the checksum and the file name, for all platforms. Hopefully resolve #1027",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1368:77,checksum,checksum,77,https://qupath.github.io,https://github.com/qupath/qupath/pull/1368,1,['checksum'],['checksum']
Security,This works great! Should be a very helpful accessibility feature for colorblind folks :),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1669#issuecomment-2393449796:43,access,accessibility,43,https://qupath.github.io,https://github.com/qupath/qupath/pull/1669#issuecomment-2393449796,1,['access'],['accessibility']
Security,"True, lambdas are the only incompatibility that has particularly bothered me at times & required adjusting the code, although it's not too tricky: http://groovy-lang.org/differences.html#_lambdas; Other differences (e.g. with `equals` or numbers becoming `BigDecimal` if not explicitly made something else) can be a bit troublesome, but more so when using most Groovy-specific features. Fortunately, it looks like the lambda situation will change with Groovy 3.0: http://groovy-lang.org/releasenotes/groovy-3.0.html. With implementing `QuPathExtension`, the `META-INF/services/qupath.lib.gui.extensions.QuPathExtension` part is crucial (see [here](https://github.com/qupath/qupath/wiki/Creating-extensions), or [this](https://docs.oracle.com/javase/tutorial/ext/basics/spi.html#implement-the-service-provider) may also help - since the general idea isn't QuPath-specific). But if you just want to access the contents of the .jar from the script, then this shouldn't be necessary. It sounds like the problem you are seeing happens inside the imported code, because if I import something that doesn't exist then at least the errors are displayed (and sensible), e.g.:; ```groovy; print 'hello'. import something.that.does.not.exist; ```; gives me; ```; ERROR: Error: startup failed:; Script18.groovy: 4: unable to resolve class something.that.does.not.exist; @ line 4, column 1.; import something.that.does.not.exist; ^. 1 error; ```. When that happens, QuPath doesn't handle such exceptions very well and I've also seen the multiple-logging problem occasionally when things go badly wrong. A recent fix I made on my fork should help address this: https://github.com/petebankhead/qupath/commit/c3f8fd49f8c14dbf7956490d2fa4f79d8e11b057. Finally, there are different ways to integrate Groovy into a Java application: http://docs.groovy-lang.org/latest/html/documentation/guide-integrating.html; Currently, QuPath goes down the _JSR 223 javax.script API_ route to give (potentially at least) support for di",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/253#issuecomment-450918869:897,access,access,897,https://qupath.github.io,https://github.com/qupath/qupath/issues/253#issuecomment-450918869,1,['access'],['access']
Security,"Update gradle wrapper, checksums",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1369:23,checksum,checksums,23,https://qupath.github.io,https://github.com/qupath/qupath/pull/1369,1,['checksum'],['checksums']
Security,"Update logic related to reading/importing images, to try to have fewer errors and more informative messages logged when errors do occur. ## Improve checks for Bio-Formats image support. Throw an exception if unable to read a single pixel from a Bio-Formats image.; Accessing the pixel may introduce some overhead when importing images, but it avoids problems where metadata can be parsed yet the fact the image can't actually be read only becomes apparent later. This was causing trouble with .ndpi on Apple Silicon, because skipping the use of NDPIReader was causing a fallback to a regular TIFF reader... and this didn't recognize the image as pyramidal and couldn't read the pixels. So requesting Bio-Formats for .ndpi was both adding many (~12) images to a project (for the different pyramid levels), and not actually able to open them. Also fix the logic for determining which IFormatReader is used for a specified image. This was previously giving ImageReader rather than the specific reader, and therefore wasn't properly enabling the reader check to be skipped for readers generated in other threads. This also had an extra issue in Apple Silicon, because these checks could cause exceptions regarding unsupported libraries being logged, even if they weren't relevant to the image itself. ## Improve use of json with image servers. Make `JSONImageServerBuilder` genuinely useful by enabling it to read the server.json files stored within projects. This could potentially help in the future if attempting to recover data from a broken project. This involves estimating the ""builderType"" since that wasn't actually serialized within the server.json before. To simplify things in the future, the server.json now serializes the `ImageServer` and not the `ServerBuilder` - so that more information is present.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1402:265,Access,Accessing,265,https://qupath.github.io,https://github.com/qupath/qupath/pull/1402,1,['Access'],['Accessing']
Security,"Very good point, I hadn't ever really considered those two things together. In my mind, 'Import objects' was always associated with trying to read objects that are somehow associated with the source image (e.g. ROIs stored as an overlay for ImageJ TIFF, objects from an OMERO image). The ability to add images from another project, on the other hand, was developed separately and intended to always import all the data from that project. This means the entire image data, including stain vectors etc. The object hierarchy comes along with that. I imagined that, if anyone wanted to add the images without objects, they would just add the images in the 'normal way' and not via a project. But I suppose that assumes that projects don't contain very many images scattered across different disks, or accessed via OMERO or elsewhere. In any case, I agree that the current behavior is confusing in the case you describe, and should probably be changed. But I'm not sure if it should be a change of behavior, or a change of documentation + the addition of a new command?. Some ideas:. 1. Don't import *any specific `ImageData`* from a project when the ""Import objects"" checkbox is unselected. This would exclude objects *and everything else*. Potentially also including custom metadata, channel names, stain vectors etc.; * In this case, it would probably be best to rename the checkbox and document this behavior; 2. Keep the behavior as it is, but document it better. A user can always run a one-line script to delete all the objects later.; * I can imagine there might be use cases where someone wants to create a new project with the same images, but no associated data. Exporting the image list and reimporting it should support those cases.; * There is a related issue to this; * https://github.com/qupath/qupath/issues/1177; 4. Add an entirely separate command to import images from another project and/or prompt the users when importing from a project. This would give more control over what exactly",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1259#issuecomment-1498662837:797,access,accessed,797,https://qupath.github.io,https://github.com/qupath/qupath/issues/1259#issuecomment-1498662837,1,['access'],['accessed']
Security,"We are happy QuPath early adopters and have annotated many different images during the last year using QuPath v0.2.0m2 and v0.2.0m5. Now we are trying to convert the annotations to v0.2.0m9, wishing to get all the great benefits in later releases, specially everything related to the move to JTS. We can convert the projects to v0.2.0m5 without problems, but when trying to convert to later versions (we have tried with v0.2.0m6 and v0.2.0m9), there are many AreaROIs that seem to carry invalid geometries and so JTS chokes. The error (using v0.2.0m9) is always the same ```Invalid number of points in LinearRing (found 3 - must be 0 or >= 4)'```. ```java; ERROR: QuPath exception: Invalid number of points in LinearRing (found 3 - must be 0 or >= 4); at org.locationtech.jts.geom.LinearRing.validateConstruction(LinearRing.java:94); at org.locationtech.jts.geom.LinearRing.<init>(LinearRing.java:85); at org.locationtech.jts.geom.GeometryFactory.createLinearRing(GeometryFactory.java:356); at org.locationtech.jts.geom.GeometryFactory.createLinearRing(GeometryFactory.java:343); at org.locationtech.jts.geom.GeometryFactory.createPolygon(GeometryFactory.java:464); at qupath.lib.roi.GeometryTools$GeometryConverter.convertAreaToGeometry(GeometryTools.java:592); at qupath.lib.roi.GeometryTools$GeometryConverter.areaToGeometry(GeometryTools.java:492); at qupath.lib.roi.GeometryTools$GeometryConverter.areaToGeometry(GeometryTools.java:476); at qupath.lib.roi.GeometryTools$GeometryConverter.roiToGeometry(GeometryTools.java:440); at qupath.lib.roi.AbstractPathROI.getGeometry(AbstractPathROI.java:172); at qupath.lib.roi.AreaROI.getGeometry(AreaROI.java:355); at ...; ```. This makes it impossible to use anything depending on conversion to JTS geometry: from converting to GeoJSON (our main goal) to simply view the slide. For example, this fails:. ```python; GeometryTools.geometryToROI(roi.getGeometry(), roi.getImagePlane()); ```; I attach a serialized example of one such ROIs, and I would be h",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/429:792,validat,validateConstruction,792,https://qupath.github.io,https://github.com/qupath/qupath/issues/429,1,['validat'],['validateConstruction']
Security,"We have recently encountered issues installing QuPath on our computers at our academic hospital. According to our IT department, who investigated the matter, the problem is due to QuPath lacking an 'Extended Validation Code Signing Certificate'. Would it be possible to include this certificate in future builds so that we can continue using the software?",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1605:208,Validat,Validation,208,https://qupath.github.io,https://github.com/qupath/qupath/issues/1605,3,"['Certificate', 'Validat', 'certificate']","['Certificate', 'Validation', 'certificate']"
Security,"We've made some progress on improving OpenSlide support, but there are a few issues that will need sorting out before release. I'll try to summarise what I've been working on in a semi-lucid way... ## Java-C interface. We plan to switch from JNI to JNA to wrap OpenSlide. This seems to reduce the complexity of loading openslide, and has minimal overhead for us, as well as probably making it easier to access new OpenSlide features. ## Build process. I have forked and modified `openslide-winbuild` to try to make binaries with fewer dynamically-linked subdependencies for Mac and Linux. I've moved some of this code to a [non-forked repo](https://github.com/alanocallaghan/openslide-crossplatform-builds), as most of it is unlikely to be useful upstream (though I'm of course happy to contribute it if so). ## Windows. The self-contained builds provided by OpenSlide work well here, as do binaries from my forked repo, with the proviso that we need to load them from a path rather than a JAR, as the JNA library loading code will not find `winpthreads` or `ssp` if we try to load from a jar on the classpath. ## Mac. x86 and M1 builds using the same meson wrap system as Windows seem to work fairly well at first glance (see [x86](https://github.com/alanocallaghan/openslide-jna/actions/runs/6175143420/job/16761349958) and [m1](https://app.circleci.com/pipelines/github/alanocallaghan/openslide-jna/26/workflows/aafe7473-6e23-4897-91bd-b66d8456e2ce/jobs/26) build test runs). However, as Pete has pointed out, they have a number of weird dependencies, some of which are homebrew directories:. ```; otool -L /Users/petebankhead/Downloads/openslide-natives/openslide-natives-darwin-aarch64/darwin-aarch64/libopenslide.dylib; /Users/petebankhead/Downloads/openslide-natives/openslide-natives-darwin-aarch64/darwin-aarch64/libopenslide.dylib:; 	/lib/libopenslide.0.dylib (compatibility version 0.0.0, current version 0.0.0); 	/usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 131",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/629#issuecomment-1723504495:403,access,access,403,https://qupath.github.io,https://github.com/qupath/qupath/issues/629#issuecomment-1723504495,1,['access'],['access']
Security,"Well this turned into something rather a lot more complicated than I'd hoped... Attempted fix in https://github.com/petebankhead/qupath/commit/c331ba1a79223311f31e82d33482dc3102f99480. What *should* happen is that behavior remains the same, however unbeknown to most the Bio-Formats server now accepts arguments of the form `[""--bfOptions"" ""key=value""]` that will be passed to the reader. The 'easy' (sort of) way to access these is via the following script:; ```groovy; def bfOptions = qupath.lib.images.servers.bioformats.BioFormatsServerOptions.getInstance(); bfOptions.setReaderOptions([""zeissczi.autostitch"": ""false""]); ```; This will set the option for the current QuPath session; to reset it, either restart QuPath or call `options.clearReaderOptions()`. The necessary autostitching flag should then be retained if the image is added to a project. Because this happens regardless of whether the flag is relevant (e.g. it's for a totally different file type) it's best to clear the options when they aren't needed. If you can build QuPath from the same branch as the commit, please let me know if you find any problems. > Sidenote: Thanks to @melvingelbard you should also see a Bio-Formats series chooser when opening images even outside a project.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/396#issuecomment-582323621:417,access,access,417,https://qupath.github.io,https://github.com/qupath/qupath/issues/396#issuecomment-582323621,1,['access'],['access']
Security,"Well, there's a way you could do it.... If you try opening the image and running the following script, it should intercept the requests and change the photometric interpretation when needed. So you should then be able to work with the whole slide image directly. It does this with some very messy code, accessing private fields and such. Therefore I don't really recommend it... but it might help check whether it's on the right track. Note that I think you'll need to go to the QuPath preferences and turn off the Bio-Formats parallelization option for it to work. ```groovy; import javafx.application.Platform; import loci.common.RandomAccessInputStream; import loci.common.services.ServiceFactory; import loci.formats.ClassList; import loci.formats.FormatException; import loci.formats.IFormatReader; import loci.formats.ImageReader; import loci.formats.gui.BufferedImageReader; import loci.formats.in.LeicaSCNReader; import loci.formats.services.OMEXMLService; import loci.formats.tiff.IFD; import loci.formats.tiff.PhotoInterp; import loci.formats.tiff.TiffParser; import qupath.lib.gui.QuPathGUI; import qupath.lib.images.servers.BioFormatsImageServer; import qupath.lib.scripting.QPEx. // Access the current image; def server = QPEx.getCurrentImageData().getServer() as BioFormatsImageServer. if (server.willParallelize()); print 'For this to work, you will need to turn off parallelization in the QuPath preferences!'. // Create a new reader that intercepts the photometric interpretation, and 'trick' QuPath into using it; def classList = new ClassList<>(IFormatReader.class); classList.addClass(LeicaSCNReaderRGB); def reader2 = new ImageReader(classList); reader2.setFlattenedResolutions(false); def factory = new ServiceFactory(); def service = factory.getInstance(OMEXMLService.class); def meta = service.createOMEXMLMetadata(); reader2.setMetadataStore(meta); reader2.setId(server.filePath); server.manager.mapPrimary.put(server.filePath, BufferedImageReader.makeBufferedImageReader(read",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/141#issuecomment-358985847:303,access,accessing,303,https://qupath.github.io,https://github.com/qupath/qupath/issues/141#issuecomment-358985847,1,['access'],['accessing']
Security,"What happens if you try to open the `.scn` file with Fiji (www.fiji.sc)? If this is successful (even to open part of the image - probably not all), then it is likely an issue with the QuPath Bio-Formats extension. But if not, then it is unlikely to be something that can be solved on the QuPath side. QuPath does not handle proprietary file formats, and depends on Bio-Formats and OpenSlide; and OpenSlide is inherently limited to 8-bit RGB images, which really means that Bio-Formats is the only option here. I plan to make some updates to the QuPath Bio-Formats extension soon, and I'll investigate `.scn` specifically with the few sample images I have access to tomorrow. But I don't know if the changes I plan to make will be relevant to the issue you are seeing. If you are able to share an example image that isn't working, I can investigate further.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/191#issuecomment-409025091:655,access,access,655,https://qupath.github.io,https://github.com/qupath/qupath/issues/191#issuecomment-409025091,1,['access'],['access']
Security,"What is really interesting with the interaction with Cellprofiler is that we could use already developed and validated pipelines without starting from scratch. We have delopped a few extra CP python modules to handle specific analytical problems. The new version of CP is entirely python based. They do not support ImageJ anymore (no need to deal with javabridge which was a headache for us for while) and very attractive to deploy on a cluster environment. But what you suggest is a good idea, i.e. add it as a new feature request and see how it goes from there. But to my opinion the really interesting aspect with CP and the underlying python+addition libraries (so far) is the computational one, i.e. memory consumption and parallelisation. It would be very efficient to handle a very granular analysis (down to cell/organelle level) in python. We are running with up to 1*10^6 #objects per slide and you quickly go up to 12GB of RAM consumption for a single process in QuPath. The tiling of the slide before analysis is something I'm exploring with QuPath. The streamlining of QuPath and python is an excellent idea. It would allow interaction with CellProfiler modules and other python packages. . Great work. It's being very helpful to us. The interface is great and the other technical problems you can always find a solutions in one way or another even if it is not optimal.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/122#issuecomment-350242806:109,validat,validated,109,https://qupath.github.io,https://github.com/qupath/qupath/issues/122#issuecomment-350242806,1,['validat'],['validated']
Security,"When I run in QuPath 0.1.2,error appeared:. print(getQuPath().getBuildString()). ERROR: Error at line 15: No signature of method: org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.getQuPath() is applicable for argument types: () values: []; Possible solutions: getAt(java.lang.String), getClass(). ERROR: Script error; at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.callGlobal(GroovyScriptEngineImpl.java:415); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.access$000(GroovyScriptEngineImpl.java:97); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl$2.invokeMethod(GroovyScriptEngineImpl.java:329); at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:69); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:52); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:154); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:158); at Script7.run(Script7.groovy:15); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:7",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/282#issuecomment-473503394:470,access,access,470,https://qupath.github.io,https://github.com/qupath/qupath/issues/282#issuecomment-473503394,1,['access'],['access']
Security,"When running a script from the command line, extensions aren't loaded until much later, so we throw an error if you try to open an image with openslide. See https://forum.image.sc/t/running-qupath-through-command-line-unable-to-access-image-data/90746 for an example",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1447:228,access,access-image-data,228,https://qupath.github.io,https://github.com/qupath/qupath/pull/1447,1,['access'],['access-image-data']
Security,"When trying to run this I get; ```; qupath.fx.dialogs.Dialogs - QuPath exception: Exception in Application start method; java.lang.RuntimeException: Exception in Application start method; 	at com.sun.javafx.application.LauncherImpl.launchApplication1(LauncherImpl.java:893); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication$2(LauncherImpl.java:195); 	at java.base/java.lang.Thread.run(Thread.java:833); Caused by: java.lang.NullPointerException: Cannot invoke ""qupath.lib.gui.viewer.QuPathViewer.downsampleFactor()"" because ""this.viewer"" is null; ```. But even if this is fixed, would it have any visible impact? The label text should already be updated. I agree that downsample factor should be exposed as a property, but I think it will require a cautious approach; if it's not a `ReadOnlyDoubleProperty` then the user should be able to assume that they can also *set* the downsample via the property, but I expect that would require a bigger refactoring of `QuPathViewer`. It's old-fashioned and suboptimal, but for now adding a [`QuPathViewerListener`](https://github.com/qupath/qupath/blob/007b18108b9f43954279403cb1f796d7ada4b521/qupath-gui-fx/src/main/java/qupath/lib/gui/viewer/QuPathViewerListener.java) is the expected way to identify any kind of viewer change. Definitely a move towards a more property-based approach would be welcome, but then so would a viewer that uses JavaFX more natively (rather than lots of legacy Graphics2D stuff)... so I think the question is whether to invest time in refactoring the current viewer, or take on the task of writing an entirely new viewer?. I definitely think a new viewer would be nice at some point - would be good to discuss what to do along the way.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1279#issuecomment-1638638283:716,expose,exposed,716,https://qupath.github.io,https://github.com/qupath/qupath/pull/1279#issuecomment-1638638283,1,['expose'],['exposed']
Security,"When using multiple viewers, these are stored in an internal list, accessible with; ```groovy; QuPathGUI.getInstance().getViewers(); ```. However, whenever viewers are closed and removed, they remain within the list - when the expectation is that they would be removed. It can be hard to distinguish between viewers that are 'still there' and ones that are not, but the following code does so:; ```groovy; def viewers = qupath.getViewers().collect() // Original list is unmodifiable... so collect; println(""Number of viewers: "" + viewers.size()). // Remove viewers that are unattached to any scene; viewers.removeAll { it.getView().getScene() == null }; println(""Number of viewers attached to scene: "" + viewers.size()); ```. In any case, **for most users and most uses of QuPath, this does not matter**. Nevertheless, it can cause trouble when scripting with multiple viewers and is a bug that should be fixed. (Bug encountered and described [here](https://gitter.im/qupath-users/Lobby?at=587094505ffdeea723188845))",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/38:67,access,accessible,67,https://qupath.github.io,https://github.com/qupath/qupath/issues/38,1,['access'],['accessible']
Security,"With the latest commit I also added an option in the CLI interface to run the script for the whole project without accessing the image files.; ```bash; ./gradlew run --args=""script -p '/home/castoldi/426FC/project.qpproj' -n -c 'import qupath.imagej.tools.IJTools; println IJTools.convertToImagePlus(getCurrentServer(), RegionRequest.createInstance(getCurrentServer(), 16))'""; ````; output:; ```; > Task :qupath-app:run; 14:08:12.506 [main] [INFO ] qupath.lib.gui.prefs.PathPrefs - Setting default Locale to en_US; 14:08:12.507 [main] [INFO ] qupath.lib.gui.prefs.PathPrefs - Setting Locale for FORMAT to en_US; 14:08:12.507 [main] [INFO ] qupath.lib.gui.prefs.PathPrefs - Setting Locale for DISPLAY to en_US; 14:08:12.513 [main] [INFO ] qupath.lib.common.ThreadTools - Setting parallelism to 31; 14:08:12.513 [main] [INFO ] qupath.ScriptCommand - Setting tile cache size to 8000.00 MB (25.0% max memory); 14:08:12.525 [main] [INFO ] qupath.lib.scripting.QP - Initializing type adapters; Warning: Versions of org.bytedeco:javacpp:1.5.9 and org.bytedeco:opencv:4.6.0-1.5.8 do not match.; Warning: Versions of org.bytedeco:javacpp:1.5.9 and org.bytedeco:openblas:0.3.21-1.5.8 do not match.; 14:08:12.860 [main] [INFO ] qupath.ScriptCommand - Running script for SILVA_426.1 FC.czi - Scene #1 (0/48); 14:08:13.205 [main] [ERROR] qupath.ScriptCommand - The script tried to read pixels off an image while also requiring to run the script without accessing the image files.; [...]; 14:08:24.832 [main] [INFO ] qupath.ScriptCommand - Running script for SILVA_426.6 FC.czi - Scene #8 (48/48); 14:08:25.124 [main] [ERROR] qupath.ScriptCommand - The script tried to read pixels off an image while also requiring to run the script without accessing the image files. BUILD SUCCESSFUL in 18s; 34 actionable tasks: 10 executed, 24 up-to-date. ~/Projects/qupath light-script-runner* 19s; ❯ ; ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1488#issuecomment-2022842385:115,access,accessing,115,https://qupath.github.io,https://github.com/qupath/qupath/pull/1488#issuecomment-2022842385,3,['access'],['accessing']
Security,"Yes, under the View → Zoom... → Zoom in/out is where I encountered the reverse behavior.; I am working on a Mac. From: Pete <notifications@github.com>; Reply-To: qupath/qupath <reply@reply.github.com>; Date: Monday, June 8, 2020 at 12:56 PM; To: qupath/qupath <qupath@noreply.github.com>; Cc: ""Kathleen T. Yee"" <KYee@umc.edu>, Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [qupath/qupath] Zoom In and Zoom Out (#518). I understand the issue is with the specific commands under View → Zoom... → Zoom in/out (I've tested only on a Mac, but assume the unexpected behavior is common across platforms - it was also weird in m10, but not v0.1.2... I didn't check any others). —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fqupath%2Fqupath%2Fissues%2F518%23issuecomment-640781128&data=02%7C01%7Ckyee%40umc.edu%7C96af0114123c4ccd238f08d80bd54a7d%7C78a0681ef0be47e280498616858818a5%7C0%7C0%7C637272357990082394&sdata=2kWkyYCdApiRUWM942pRiwOnNoXy8SWGjV0e%2FyE0DuE%3D&reserved=0>, or unsubscribe<https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAP4MNE5SPRUYX7RMNYZKOFTRVUQ5LANCNFSM4NYSD4CA&data=02%7C01%7Ckyee%40umc.edu%7C96af0114123c4ccd238f08d80bd54a7d%7C78a0681ef0be47e280498616858818a5%7C0%7C0%7C637272357990082394&sdata=pU%2BYSYbllDKbPfdTG%2FD921yLOmUpYsg0rDDoywDA3bE%3D&reserved=0>. Individuals who have received this information in error or are not authorized to receive it must promptly return or dispose of the information and notify the sender. Those individuals are hereby notified that they are strictly prohibited from reviewing, forwarding, printing, copying, distributing or using this information in any way.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/518#issuecomment-640783525:1563,authoriz,authorized,1563,https://qupath.github.io,https://github.com/qupath/qupath/issues/518#issuecomment-640783525,1,['authoriz'],['authorized']
Security,"You can also open the `project.qpproj` file directly in a text editor, and then use 'Find & Replace' to change the paths. That is probably easier and faster than reimporting. You could even duplicate the project file and keep the duplicates in the same directory, each with the paths including a drive letter you might need. So you might have `projectD.qpproj`, `projectE.qppro`j, `projectF.qpproj`... each containing the different paths that you might need. Ultimately the data for each image is stored inside the 'data' subdirectory inside the project folder, with a filename based only on the name of the image (not its full path). Therefore just open the project file that contains the correct paths, and it should immediately have access to the same data. There is a little bit of information about how projects are structured at https://github.com/qupath/qupath/wiki/Project-structure; It's usually best to leave QuPath to take care of the files in the project directory... but it is intentionally quite simple so that, if you know more or less what it is doing, you can certainly hack it a bit to behave the way you need.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/114#issuecomment-342855367:736,access,access,736,https://qupath.github.io,https://github.com/qupath/qupath/issues/114#issuecomment-342855367,1,['access'],['access']
Security,"You can convert any existing QuPath ROI into a [`java.awt.Shape`](https://docs.oracle.com/javase/8/docs/api/index.html?java/awt/Shape.html) with [`PathROIToolsAwt`](https://github.com/qupath/qupath/blob/v0.1.2/qupath-core-awt/src/main/java/qupath/lib/roi/PathROIToolsAwt.java#L204). While it doesn't solve the shapefile problem, at least it gets the ROIs into a more QuPath-independent format, from with you can request vertices in a standard way (with a [PathIterator](https://docs.oracle.com/javase/8/docs/api/index.html?java/awt/Shape.html)) that is fairly well documented. Using [`java.awt.geom.Area`](https://docs.oracle.com/javase/8/docs/api/index.html?java/awt/Shape.html) is also an option for anything other than a `LineROI`. You _might_ then be able to find a library that converts a Java `Shape` into a more shapefile-friendly format (if you find a suitable library as a `.jar` file, you can just drag it onto QuPath to copy it to the extensions directory and then it should be accessible in your scripts - and potentially add it as a dependency in IntelliJ for easier scripting). Otherwise I guess I'd look for whatever way your shapefile-writing library represents complex shapes, and with the help of the `PathIterator` try to export from QuPath in the closest way I could. In general, I think QuPath needs better support for shapes and things that may be done with shapes, and every now and then I look towards [Java Topology Suite](https://github.com/locationtech/jts). I've written a couple of scripts with it, and am tentatively thinking of creating converters for all QuPath ROIs to a JTS representation... I just haven't had a big enough need for it yet. As far as I can see, JTS has support for reading shapefiles, but I don't see any for writing them. Although it may write GeoJSON - which is another candidate for a format. I've seen it used for pathology in [QuIP](https://sbu-bmi.github.io/quip_distro/), but I haven't noticed any other examples yet. I guess your main task is",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/95#issuecomment-396428574:989,access,accessible,989,https://qupath.github.io,https://github.com/qupath/qupath/issues/95#issuecomment-396428574,1,['access'],['accessible']
Security,"\os\.OS-3.vsi.bfmemo `. The file was ; `D:\QMDownload\5\os\OS-3.vsi.bfmemo ; `. After a successful running, all the output was:; ```; 16:23:06.071 [main] [INFO ] qupath.QuPath - Launching QuPath with args: -image, D:\\QMDownload\\5\\os\\OS-3.vsi, -script, C:\\Users\\rmd\\AppData\\Local\\Temp\\tpd56d11ce_e4ba_481c_a046_3d19297b763a.groovy ; 16:23:06.151 [main] [WARN ] q.lib.images.servers.FileFormatInfo - Strange 'bits per sample' of 0 ; 16:23:06.211 [main] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1 ; WARNING: An illegal reflective access operation has occurred ; WARNING: Illegal reflective access by com.esotericsoftware.kryo.util.UnsafeUtil (file:/C:/Program%20Files/QuPath-0.2.0-m1/app/kryo-2.24.0.jar) to constructor java.nio.DirectByteBuffer(long,int,java.lang.Object) ; WARNING: Please consider reporting this to the maintainers of com.esotericsoftware.kryo.util.UnsafeUtil ; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations ; WARNING: All illegal access operations will be denied in a future release ; 16:23:07.141 [main] [WARN ] loci.formats.Memoizer - deleting invalid memo file: D:\QMDownload\5\os\.OS-3.vsi.bfmemo ; com.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 429; Serialization trace:; service (loci.formats.in.OperettaReader); readers (loci.formats.ImageReader); reader (loci.formats.DimensionSwapper); reader (loci.formats.FileStitcher); helper (loci.formats.in.FilePatternReader); readers (loci.formats.ImageReader) ; 	at com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:119) ; 	at com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:641) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:375) ; 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:289) ; 	at com.esotericsoftware.kryo.Kry",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/287:1256,access,access,1256,https://qupath.github.io,https://github.com/qupath/qupath/issues/287,3,['access'],['access']
Security,"_b5603607aba8.groovy ; 15:23:36.512 [main] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1 ; 15:23:36.562 [main] [WARN ] q.l.i.s.o.OpenslideImageServer - Openslide: Property 'openslide.level[0].tile-width' not available, will return default value 256.0 ; 15:23:36.562 [main] [WARN ] q.l.i.s.o.OpenslideImageServer - Openslide: Property 'openslide.level[0].tile-height' not available, will return default value 256.0 ; 15:23:36.812 [main] [INFO ] q.l.i.s.o.OpenslideImageServer - Test reading thumbnail with openslide: passed (BufferedImage@2f953efd: type = 1 DirectColorModel: rmask=ff0000 gmask=ff00 bmask=ff amask=0 IntegerInterleavedRaster: width = 200 height = 87 #Bands = 3 xOff = 0 yOff = 0 dataOffset[0] 0) ; 15:23:36.812 [main] [INFO ] q.l.i.servers.ImageServerProvider - Returning server: OpenSlide for D:\\QMDownload\\5\\~!@#$%^&( )_+=-0987654321`{}[%23];',\\single_neur~!@#$%^&( )_+=-0987654321`{}[%23];',on_40X_3.mrxs ; WARNING: An illegal reflective access operation has occurred ; WARNING: Illegal reflective access by org.codehaus.groovy.vmplugin.v7.Java7$1 (file:/C:/Program%20Files/QuPath-0.2.0-m1/app/groovy-2.5.6.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class,int) ; WARNING: Please consider reporting this to the maintainers of org.codehaus.groovy.vmplugin.v7.Java7$1 ; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations ; WARNING: All illegal access operations will be denied in a future release ; 15:23:37.065 [main] [ERROR] qupath.QuPath - Error running script! ; javax.script.ScriptException: org.codehaus.groovy.control.MultipleCompilationErrorsException: startup failed: ; Script1.groovy: 102: expecting '}', found '' @ line 102, column 18. ; PixelWidthMic ; ^ ; ; 1 error ; ; 	at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:158) ; 	at qupath.QuPath.main(QuPath.java:161) ; Caused by: org.codehaus.groovy.control.MultipleCompilationErrors",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/286:2204,access,access,2204,https://qupath.github.io,https://github.com/qupath/qupath/issues/286,2,['access'],['access']
Security,"```; [jalal@goku bin]$ chmod 777 QuPath; [jalal@goku bin]$ ./QuPath; OpenJDK 64-Bit Server VM warning: Option --illegal-access is deprecated and will be removed in a future release.; Apr 11, 2022 4:51:53 PM com.sun.javafx.application.PlatformImpl startup; WARNING: Unsupported JavaFX configuration: classes were loaded from 'unnamed module @60975100'; 16:51:53.531 [JavaFX Application Thread] [INFO ] qupath.lib.common.ThreadTools - Setting parallelism to 11; 16:51:53.823 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - QuPath build: Version: 0.3.2; Build time: 2022-01-17, 08:49; Latest commit tag: '71884c6'; 16:51:53.824 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Setting tile cache size to 8024.00 MB (25.0% max memory). (QuPath:14092): Gdk-WARNING **: 16:51:54.374: XSetErrorHandler() called with a GDK error trap pushed. Don't do that.; 16:51:54.868 [JavaFX Application Thread] [INFO ] qupath.lib.scripting.QP - Initializing type adapters; *** Error in `./QuPath': free(): invalid pointer: 0x00007effa50f8c80 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x81329)[0x7f087c503329]; /lib64/libstdc++.so.6(_ZNSt6locale5_Impl16_M_install_facetEPKNS_2idEPKNS_5facetE+0x142)[0x7effa4e62192]; /lib64/libstdc++.so.6(_ZNSt6locale5_ImplC1Em+0x1e3)[0x7effa4e625e3]; /lib64/libstdc++.so.6(+0x71555)[0x7effa4e63555]; /lib64/libpthread.so.0(+0x620b)[0x7f087be4520b]; /lib64/libstdc++.so.6(+0x715a1)[0x7effa4e635a1]; /lib64/libstdc++.so.6(_ZNSt6localeC2Ev+0x13)[0x7effa4e635e3]; /lib64/libstdc++.so.6(_ZNSt8ios_base4InitC2Ev+0xbc)[0x7effa4e6043c]; /home/grad3/jalal/.javacpp/cache/opencv-4.5.3-1.5.6-linux-x86_64.jar/org/bytedeco/opencv/linux-x86_64/libopencv_core.so.4.5(+0x64ddd)[0x7efeb6536ddd]; /lib64/ld-linux-x86-64.so.2(+0xf9c3)[0x7f087cd659c3]; /lib64/ld-linux-x86-64.so.2(+0x1459e)[0x7f087cd6a59e]; /lib64/ld-linux-x86-64.so.2(+0xf7d4)[0x7f087cd657d4]; /lib64/ld-linux-x86-64.so.2(+0x13b8b)[0x7f087cd69b8b]; /lib64/libdl.so.2(+0xfab)[0x7f087cb52fab]; /lib64/",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/949:120,access,access,120,https://qupath.github.io,https://github.com/qupath/qupath/issues/949,1,['access'],['access']
Security,"a.base/sun.security.ssl.SSLSocketImpl.decode(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.readHandshakeRecord(Unknown Source); 	at java.base/sun.security.ssl.SSLSocketImpl.startHandshake(Unknown Source); 	at java.base/sun.net.www.protocol.https.HttpsClient.afterConnect(Unknown Source); 	at java.base/sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(Unknown Source); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream(Unknown Source); 	at java.base/sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(Unknown Source); 	at shaded.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.com.google.api.client.auth.oauth2.TokenRequest.executeUnparsed(TokenRequest.java:283); 	at shaded.com.google.api.client.auth.oauth2.TokenRequest.execute(TokenRequest.java:307); 	at shaded.com.google.api.client.auth.oauth2.Credential.executeRefreshToken(Credential.java:576); 	at shaded.com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:493); 	at com.quantumsoft.qupathcloud.oauth20.OAuth20.getCredential(OAuth20.java:84); 	at com.quantumsoft.qupathcloud.dao.CloudDaoImpl.createRequestForObjectList(CloudDaoImpl.java:352); 	at com.quantumsoft.qupathcloud.dao.CloudDaoImpl.getProjects(CloudDaoImpl.java:124); 	at com.quantumsoft.qupathcloud.gui.windows.CloudWindow.lambda$authorizationPage$4(CloudWindow.java:184); 	at java.base/java.lang.Thread.run(Unknown Source)}. ); javax.net.ssl|DEBUG|29|Thread-9|2020-04-13 21:28:52.417 NOVT|null:-1|close the underlying socket; javax.net.ssl|DEBUG|29|Thread-9|2020-04-13 21:28:52.417 NOVT|null:-1|close the SSL connection (initiative); ```. **Desktop**; - OS:Ubuntu - 18.04 LTS; - QuPath Version - v0.2.0-m5. Also, I tested it using v0.2.0-m9 and got the same issue.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/436:13453,authoriz,authorizationPage,13453,https://qupath.github.io,https://github.com/qupath/qupath/issues/436,1,['authoriz'],['authorizationPage']
Security,a:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$ClickGenerator.postProcess(Scene.java:3470); at javafx.scene.Scene$ClickGenerator.access$8100(Scene.java:3398); at javafx.scene.Scene$MouseHandler.process(Scene.java:3766); at javafx.scene.Scene$MouseHandler.access$1500(Scene.java:3485); at javafx.scene.Scene.impl_processMouseEvent(Scene.java:1762); at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2494); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:380); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:294); at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$354(GlassViewEventHandler.java:416); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:415); at com.sun.glass.ui.View.handleMouseEvent(View.java:555); at com.sun.glass.ui.View.notifyMouse(View.java:937); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$null$148(WinApplication.java:191); at java.lang.Thread.run(Thread.java:745); ERROR: QuPath exception; at qupath.lib.images.servers.OpenslideImageServer.<init>(OpenslideImageServer.java:91); at qupath.lib.images.servers.OpenslideServerBuilder.buildServer(OpenslideServerBuilder.java:47); at qupath.lib.images.servers.ImageServerProvider.buildServer(ImageServerProvider.java:115); at qupath.lib.gui.QuPathGUI.openImage(QuPathGU,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/35:10056,secur,security,10056,https://qupath.github.io,https://github.com/qupath/qupath/issues/35,1,['secur'],['security']
Security,a:151); at qupath.lib.gui.tools.PathObjectLabels$PathObjectListCell.updateItem(PathObjectLabels.java:138); at javafx.scene.control.ListCell.updateItem(ListCell.java:485); at javafx.scene.control.ListCell.lambda$new$2(ListCell.java:168); at javafx.collections.WeakListChangeListener.onChanged(WeakListChangeListener.java:88); at com.sun.javafx.collections.ListListenerHelper$Generic.fireValueChangedEvent(ListListenerHelper.java:329); at com.sun.javafx.collections.ListListenerHelper.fireValueChangedEvent(ListListenerHelper.java:73); at javafx.collections.ObservableListBase.fireChange(ObservableListBase.java:239); at javafx.collections.ListChangeBuilder.commit(ListChangeBuilder.java:482); at javafx.collections.ListChangeBuilder.endChange(ListChangeBuilder.java:541); at javafx.collections.ObservableListBase.endChange(ObservableListBase.java:211); at javafx.collections.ModifiableObservableListBase.setAll(ModifiableObservableListBase.java:98); at qupath.lib.gui.panes.AnnotationPane.hierarchyChanged(AnnotationPane.java:436); at qupath.lib.gui.panes.AnnotationPane.lambda$hierarchyChanged$9(AnnotationPane.java:404); at com.sun.javafx.application.PlatformImpl.lambda$runLater$10(PlatformImpl.java:457); at java.base/java.security.AccessController.doPrivileged(Unknown Source); at com.sun.javafx.application.PlatformImpl.lambda$runLater$11(PlatformImpl.java:456); at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:96); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:184); at java.base/java.lang.Thread.run(Unknown Source); ```. **To Reproduce**; See https://forum.image.sc/t/error-from-roitools-subtract-in-qupath-v0-4-0/74837. **Expected behavior**; Updating the list cell shouldn't throw any exception. **Desktop (please complete the following information):**; - OS: All (presumably); - QuPath Version: 0.4.0. **Additional context**; I haven't replicated the problem yet.,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1182:2056,secur,security,2056,https://qupath.github.io,https://github.com/qupath/qupath/issues/1182,2,"['Access', 'secur']","['AccessController', 'security']"
Security,"act that in [ImageDisplay](https://github.com/qupath/qupath/blob/main/qupath-gui-fx/src/main/java/qupath/lib/display/ImageDisplay.java), the function [setImageData()](https://github.com/qupath/qupath/blob/13bdeed047b4d05f35f47308b36b48c0f2bb3a24/qupath-gui-fx/src/main/java/qupath/lib/display/ImageDisplay.java#L202) is called when an image is open in QuPath. This function calls the `updateChannelOptions()` function and then the `updateHistogramMap()` function (see [here](https://github.com/qupath/qupath/blob/13bdeed047b4d05f35f47308b36b48c0f2bb3a24/qupath-gui-fx/src/main/java/qupath/lib/display/ImageDisplay.java#L228C4-L228C24)):; * `updateChannelOptions()` updates the [channelOptions](https://github.com/qupath/qupath/blob/13bdeed047b4d05f35f47308b36b48c0f2bb3a24/qupath-gui-fx/src/main/java/qupath/lib/display/ImageDisplay.java#L504) variable. It's an ObservableValue and, because of listeners, the [BrightnessContrastHistogramPane.updateHistogram()](https://github.com/qupath/qupath/blob/13bdeed047b4d05f35f47308b36b48c0f2bb3a24/qupath-gui-fx/src/main/java/qupath/lib/gui/commands/display/BrightnessContrastHistogramPane.java#L162C17-L162C32) function is called. This is the function responsible for displaying the histogram.; * `updateHistogramMap()` updates the `histogramManager` variable. This variable is responsible for providing the histogram values. So the problem is that the function displaying the histogram can be called before the function updating the histogram values. It is not possible to simply switch the calls of the `updateChannelOptions()` and `updateHistogramMap()` functions. **The solution** I found was to make `histogramManager` an ObservableValue. In this case, `BrightnessContrastHistogramPane.updateHistogram()` can be called each time the `histogramManager` value changes. I don't like this solution as it exposes the `histogramManager` variable (which is an implementation detail). But this was the solution requiring the less amount of refactoring I found.",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1462:2378,expose,exposes,2378,https://qupath.github.io,https://github.com/qupath/qupath/pull/1462,1,['expose'],['exposes']
Security,adata; INFO: No memoization file generated for /home/joelrv/Downloads/test_pyramid.tif; INFO: Returning server: Bio-Formats for /home/joelrv/Downloads/test_pyramid.tif; ERROR: QuPath exception; ERROR: java.lang.OutOfMemoryError: Java heap space; WARN: Fallback to requesting thumbnail directly...; ERROR: QuPath exception; WARN: Tile request exception; ERROR: QuPath exception; at qupath.lib.gui.viewer.QuPathViewer.updateSuggestedOverlayColorFromThumbnail(QuPathViewer.java:996); at qupath.lib.gui.viewer.QuPathViewer.getSuggestedOverlayColor(QuPathViewer.java:1005); at qupath.lib.gui.viewer.QuPathViewer.paintViewer(QuPathViewer.java:1665); at qupath.lib.gui.viewer.QuPathViewer.paintCanvas(QuPathViewer.java:413); at qupath.lib.gui.viewer.QuPathViewerPlus.paintCanvas(QuPathViewerPlus.java:249); at qupath.lib.gui.viewer.QuPathViewer.lambda$repaint$4(QuPathViewer.java:501); at com.sun.javafx.application.PlatformImpl.lambda$runLater$10(PlatformImpl.java:428); at java.base/java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.application.PlatformImpl.lambda$runLater$11(PlatformImpl.java:427); at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:96); at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); at com.sun.glass.ui.gtk.GtkApplication.lambda$runLoop$11(GtkApplication.java:277); at java.base/java.lang.Thread.run(Thread.java:834); INFO: TiffDelegateReader initializing /home/joelrv/Downloads/test_pyramid.tif; INFO: Reading IFDs; INFO: Populating metadata; INFO: Checking comment style; INFO: Populating OME metadata; INFO: No memoization file generated for /home/joelrv/Downloads/test_pyramid.tif; ERROR: QuPath exception; at qupath.lib.gui.viewer.QuPathViewer.updateSuggestedOverlayColorFromThumbnail(QuPathViewer.java:996); at qupath.lib.gui.viewer.QuPathViewer.getSuggestedOverlayColor(QuPathViewer.java:1005); at qupath.lib.gui.viewer.QuPathViewer.paintViewer(QuPathViewer.java:1665); at qupath.lib.gui.viewer.QuPathVie,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/279#issuecomment-472375699:10000,Access,AccessController,10000,https://qupath.github.io,https://github.com/qupath/qupath/issues/279#issuecomment-472375699,1,['Access'],['AccessController']
Security,add option to ProjectImageEntry.readImageData() to avoid accessing the file image,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1488:57,access,accessing,57,https://qupath.github.io,https://github.com/qupath/qupath/pull/1488,1,['access'],['accessing']
Security,"ail with this PR it fails, I believe because it is using a mixture of metadata (i.e. assuming that it has enough bytes for 32-bit data, and failing with an `ArrayIndexOutOfBoundsException`. > * One tile reader should support accessing only one `series`. Possibly - it is one option to overcome the issue. Currently, the implementation of `BioFormatsReaderWrapper` in this PR has two `getPixelValues()` methods. One of them sets the series and then resets it back to its original value, the other sets it but doesn't reset it. Without the reset, then the reader has changed into a different state - and the values returned by any call that requests metadata from the reader are subject to giving different results *(example at the end of this post)*. Additionally, both methods are potentially broken in a multithreading context because there is no synchronization done on the reader. . Excessive synchronization could harm performance. Forbidding the series and ID to be changed anywhere inside the class - *and* forbidding the reader from being accessed outside (i.e. not providing a `getReader()` option) - would reduce the need for synchronization, but probably not eliminate it because I am not sure that Bio-Formats guarantees that pixels can be accessed simultaneously from different threads even if the series and ID aren't changed. The alternative is to synchronize everything that uses the reader, and then taking care to design the class in such a way that it's not possible to get around the synchronization. To do that, the `getReader()` option should again be removed. A third option is to make the class *really* minimal and keep the `getReader()` option - but document that it is entirely up to the caller what they do with the reader, and they must take care of synchronization etc. The third option puts much more responsibility on the caller, but has the advantage of allowing the same reader to be reused for different images / series. This might have some small improvements in per",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1287#issuecomment-1714232547:1554,access,accessed,1554,https://qupath.github.io,https://github.com/qupath/qupath/pull/1287#issuecomment-1714232547,1,['access'],['accessed']
Security,anager.dispatchBubblingEvent(EventHandlerManager.java:238); at com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:191); at com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDispatcher.java:59); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:58); ERROR: QuPath exception; at qupath.lib.gui.viewer.QuPathViewer.updateSuggestedOverlayColorFromThumbnail(QuPathViewer.java:996); at qupath.lib.gui.viewer.QuPathViewer.getSuggestedOverlayColor(QuPathViewer.java:1005); at qupath.lib.gui.viewer.QuPathViewer.paintViewer(QuPathViewer.java:1665); at qupath.lib.gui.viewer.QuPathViewer.paintCanvas(QuPathViewer.java:413); at qupath.lib.gui.viewer.QuPathViewerPlus.paintCanvas(QuPathViewerPlus.java:249); at qupath.lib.gui.viewer.QuPathViewer.lambda$repaint$4(QuPathViewer.java:501); at com.sun.javafx.application.PlatformImpl.lambda$runLater$10(PlatformImpl.java:428); at java.base/java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.application.PlatformImpl.lambda$runLater$11(PlatformImpl.java:427); at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:96); at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); at com.sun.glass.ui.gtk.GtkApplication.lambda$runLoop$11(GtkApplication.java:277); at java.base/java.lang.Thread.run(Thread.java:834); ERROR: QuPath exception; at qupath.lib.gui.viewer.QuPathViewer.updateSuggestedOverlayColorFromThumbnail(QuPathViewer.java:996); at qupath.lib.gui.viewer.QuPathViewer.getSuggestedOverlayColor(QuPathViewer.java:1005); at qupath.lib.gui.viewer.QuPathViewer.paintViewer(QuPathViewer.java:1665); at qupath.lib.gui.viewer.QuPathViewer.paintCanvas(QuPathViewer.java:413); at qupath.lib.gui.viewer.QuPathViewerPlus.paintCanvas(QuPathViewerPlus.java:249); at qupath.lib.gui.viewer.QuPathViewer.lambda$repaint$4(QuPathViewer.java:501); at com.sun.javafx.application.PlatformImpl.lambda$runLater$10(Platf,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/279#issuecomment-472375699:7357,Access,AccessController,7357,https://qupath.github.io,https://github.com/qupath/qupath/issues/279#issuecomment-472375699,1,['Access'],['AccessController']
Security,asicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$DnDGesture.fireEvent(Scene.java:2933); at javafx.scene.Scene$DnDGesture.processTargetDrop(Scene.java:3159); at javafx.scene.Scene$DnDGesture.access$6400(Scene.java:2909); at javafx.scene.Scene$DropTargetListener.drop(Scene.java:2873); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.lambda$handleDragDrop$309(GlassSceneDnDEventHandler.java:95); at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassSceneDnDEventHandler.handleDragDrop(GlassSceneDnDEventHandler.java:92); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleDragDrop$363(GlassViewEventHandler.java:700); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleDragDrop(GlassViewEventHandler.java:699); at com.sun.glass.ui.View.handleDragDrop(View.java:712); at com.sun.glass.ui.View.notifyDragDrop(View.java:1037),MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/191#issuecomment-409021767:21675,access,access,21675,https://qupath.github.io,https://github.com/qupath/qupath/issues/191#issuecomment-409021767,6,"['Access', 'access', 'secur']","['AccessController', 'access', 'security']"
Security,"assify ; > <https://cloud.githubusercontent.com/assets/23145209/22407407/a1b3e02c-e61a-11e6-8ab8-8929d9b98c32.JPG>; >; > It may not be exactly what you wanted, but it is not too many steps ; > and should give similar results, I believe. Note that the Classify By ; > Specific Feature does not show up in the workflow at this time, but I ; > seem to remember it being scriptable manually.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub ; > <https://github.com/qupath/qupath/issues/46#issuecomment-275941788>, ; > or mute the thread ; > <https://github.com/notifications/unsubscribe-auth/APmGEcJu_dREsL0cqgibZHAb2Vy12MWjks5rXPDdgaJpZM4Lw1_o>.; >. -- ; Mit freundlichen Grüßen; Kind regards. Dipl. Biologe; David Haumann; CEO. Tel: +49 (0)7247 9342998-0; Mobil: +49 (0)171 9903171; E-Mail: david.haumann@hs-analysis.com; Webseite: www.hs-analysis.com. HS-Analysis GmbH; Steinbuch Centre for Computing (SCC), Geb. 441; Hermann-von-Helmholtz-Platz 1; 76344 Eggenstein-Leopoldshafen. Handelsregister: Amtsgericht Mannheim HRB 723920; UStIdNr: DE304551126; Geschäftsführer:; - David Haumann, Thomas Schenker, Sergey Biniaminov. _________________________________; Diese E-Mail und jeder übermittelte Anhang enthält gesetzlich geschützte; und vertrauliche Informationen. Wenn diese E-Mail nicht für Sie bestimmt ist,; bitten wir Sie, sie an uns zurückzusenden und anschließend von Ihrem Computersystem; zu löschen. Nicht für Sie bestimmte E-Mails und Anhänge dürfen Sie weder nutzen; noch verarbeiten oder Dritten zugänglich machen, gleich in welcher Form. This email including any attachments contains privileged and confidential; information. If you are not an intended recipient, please return the email; to us and then delete it from your computer system. You may neither use nor; edit any such emails including attachments received due to an error in; transmission, nor make them accessible to third parties in any manner whatsoever.",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/46#issuecomment-276000050:2397,confidential,confidential,2397,https://qupath.github.io,https://github.com/qupath/qupath/issues/46#issuecomment-276000050,2,"['access', 'confidential']","['accessible', 'confidential']"
Security,"at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1099); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:645); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:437); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$173(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$48(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:748); 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Light; 13:20:08.246 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 13:20:08.256 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 13:20:17.509 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Calling Platform.exit();; ```. In Centos 6, I found some information about the error message ""j java.lang.Object.<clinit>()V+0"" : this may be a stack problem. I tried to change the thread stack size wi",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/150#issuecomment-368857650:1969,Access,AccessController,1969,https://qupath.github.io,https://github.com/qupath/qupath/issues/150#issuecomment-368857650,1,['Access'],['AccessController']
Security,"at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857); 	at java.lang.Runtime.loadLibrary0(Runtime.java:870); 	at java.lang.System.loadLibrary(System.java:1122); 	at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:60); 	at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:73); 	at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:120); 	at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1092); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:633); 	at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:418); 	at qupath.lib.gui.QuPathApp.start(QuPathApp.java:59); 	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$106(LauncherImpl.java:863); 	at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$119(PlatformImpl.java:326); 	at com.sun.javafx.application.PlatformImpl.lambda$null$117(PlatformImpl.java:295); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.application.PlatformImpl.lambda$runLater$118(PlatformImpl.java:294); 	at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.java:139); 	at java.lang.Thread.run(Thread.java:745); 02:39:38.754 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: Modena Dark; 02:39:38.757 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 02:39:38.781 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 02:39:38.837 [JavaFX Application Thread] [INFO ] q.lib.gui.helpers.DisplayHelpers - QuPath Notice: This is a pre-release version of QuPath; Version: 0.0.6; Build time: 2016-11-16, 15:54; 02:40:13.093 [JavaFX Application Thread] [ERROR] q.l.i.servers.OpenslideServerBuilder - Co",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/27#issuecomment-262870405:2580,Access,AccessController,2580,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405,1,['Access'],['AccessController']
Security,atchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$ClickGenerator.postProcess(Scene.java:3470); at javafx.scene.Scene$ClickGenerator.access$8100(Scene.java:3398); at javafx.scene.Scene$MouseHandler.process(Scene.java:3766); at javafx.scene.Scene$MouseHandler.access$1500(Scene.java:3485); at javafx.scene.Scene.impl_processMouseEvent(Scene.java:1762); at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2494); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:380); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:294); at java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$354(GlassViewEventHandler.java:416); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:415); at com.sun.glass.ui.View.handleMouseEvent(View.java:555); at com.sun.glass.ui.View.notifyMouse(View.java:937); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$null$148(WinApplication.java:191); at,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/35:9664,access,access,9664,https://qupath.github.io,https://github.com/qupath/qupath/issues/35,2,['access'],['access']
Security,atchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$KeyHandler.process(Scene.java:4058); at javafx.scene.Scene$KeyHandler.access$1500(Scene.java:4004); at javafx.scene.Scene.processKeyEvent(Scene.java:2121); at javafx.scene.Scene$ScenePeerListener.keyEvent(Scene.java:2595); at com.sun.javafx.tk.quantum.GlassViewEventHandler$KeyEventNotification.run(GlassViewEventHandler.java:217); at com.sun.javafx.tk.quantum.GlassViewEventHandler$KeyEventNotification.run(GlassViewEventHandler.java:149); at java.base/java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleKeyEvent$1(GlassViewEventHandler.java:248); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:390); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleKeyEvent(GlassViewEventHandler.java:247); at com.sun.glass.ui.View.handleKeyEvent(View.java:547); at com.sun.glass.ui.View.notifyKey(View.java:971); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:174); at java.base/java.lang.Thread.run(Thread.java:834); ERROR: QuPath exception; at org.fxmisc.richtext.ParagraphText.checkWithinParagraph(ParagraphText.java:259); at org.fxmisc.richtext.ParagraphText.getCaretBounds(ParagraphText.java:198); at org.fxmisc.richtext.ParagraphBox.getCaretBounds(ParagraphBox.java:193); at org.fxmisc.richtext.GenericStyledArea.showCaretAtBottom(GenericStyledArea.java:1281); at org.fxmi,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/314:10354,Access,AccessController,10354,https://qupath.github.io,https://github.com/qupath/qupath/issues/314,1,['Access'],['AccessController']
Security,atchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$KeyHandler.process(Scene.java:4058); at javafx.scene.Scene$KeyHandler.access$1500(Scene.java:4004); at javafx.scene.Scene.processKeyEvent(Scene.java:2121); at javafx.scene.Scene$ScenePeerListener.keyEvent(Scene.java:2595); at com.sun.javafx.tk.quantum.GlassViewEventHandler$KeyEventNotification.run(GlassViewEventHandler.java:217); at com.sun.javafx.tk.quantum.GlassViewEventHandler$KeyEventNotification.run(GlassViewEventHandler.java:149); at java.base/java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleKeyEvent$1(GlassViewEventHandler.java:248); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:390); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleKeyEvent(GlassViewEventHandler.java:247); at com.sun.glass.ui.View.handleKeyEvent(View.java:547); at com.sun.glass.ui.View.notifyKey(View.java:971); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:174); at java.base/java.lang.Thread.run(Thread.java:834); ERROR: QuPath exception; at org.fxmisc.richtext.ParagraphText.checkWithinParagraph(ParagraphText.java:259); at org.fxmisc.richtext.ParagraphText.getCaretBounds(ParagraphText.java:198); at org.fxmisc.richtext.ParagraphBox.getCaretBounds(ParagraphBox.java:193); at org.fxmisc.richtext.GenericStyledArea.showCaretAtTop(GenericStyledArea.java:1289); at org.fxmisc.,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/314:5425,Access,AccessController,5425,https://qupath.github.io,https://github.com/qupath/qupath/issues/314,1,['Access'],['AccessController']
Security,atcher.dispatchEvent(BasicEventDispatcher.java:58); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); 	at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); 	at javafx.event.Event.fireEvent(Event.java:198); 	at javafx.scene.Scene$MouseHandler.process(Scene.java:3757); 	at javafx.scene.Scene$MouseHandler.access$1500(Scene.java:3485); 	at javafx.scene.Scene.impl_processMouseEvent(Scene.java:1762); 	at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2494); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:352); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:275); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$300(GlassViewEventHandler.java:388); 	at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:387); 	at com.sun.glass.ui.View.handleMouseEvent(View.java:555); 	at com.sun.glass.ui.View.notifyMouse(View.java:937); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.j,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/65:5906,access,access,5906,https://qupath.github.io,https://github.com/qupath/qupath/issues/65,1,['access'],['access']
Security,atcher.dispatchEvent(BasicEventDispatcher.java:58); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); 	at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); 	at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); 	at javafx.event.Event.fireEvent(Event.java:198); 	at javafx.scene.Scene$MouseHandler.process(Scene.java:3757); 	at javafx.scene.Scene$MouseHandler.access$1500(Scene.java:3485); 	at javafx.scene.Scene.impl_processMouseEvent(Scene.java:1762); 	at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2494); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:352); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:275); 	at java.security.AccessController.doPrivileged(Native Method); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$300(GlassViewEventHandler.java:388); 	at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:389); 	at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:387); 	at com.sun.glass.ui.View.handleMouseEvent(View.java:555); 	at com.sun.glass.ui.View.notifyMouse(View.java:937); 	at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); 	at com.sun.glass.ui.gtk.GtkApplication.lambda$null$450(GtkApplication.j,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/27#issuecomment-262870405:7387,access,access,7387,https://qupath.github.io,https://github.com/qupath/qupath/issues/27#issuecomment-262870405,1,['access'],['access']
Security,ating OME metadata; INFO: No memoization file generated for /home/joelrv/Downloads/test_pyramid.tif; INFO: Returning server: Bio-Formats for /home/joelrv/Downloads/test_pyramid.tif; ERROR: QuPath exception; ERROR: java.lang.OutOfMemoryError: Java heap space; WARN: Fallback to requesting thumbnail directly...; ERROR: QuPath exception; WARN: Tile request exception; ERROR: QuPath exception; at qupath.lib.gui.viewer.QuPathViewer.updateSuggestedOverlayColorFromThumbnail(QuPathViewer.java:996); at qupath.lib.gui.viewer.QuPathViewer.getSuggestedOverlayColor(QuPathViewer.java:1005); at qupath.lib.gui.viewer.QuPathViewer.paintViewer(QuPathViewer.java:1665); at qupath.lib.gui.viewer.QuPathViewer.paintCanvas(QuPathViewer.java:413); at qupath.lib.gui.viewer.QuPathViewerPlus.paintCanvas(QuPathViewerPlus.java:249); at qupath.lib.gui.viewer.QuPathViewer.lambda$repaint$4(QuPathViewer.java:501); at com.sun.javafx.application.PlatformImpl.lambda$runLater$10(PlatformImpl.java:428); at java.base/java.security.AccessController.doPrivileged(Native Method); at com.sun.javafx.application.PlatformImpl.lambda$runLater$11(PlatformImpl.java:427); at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:96); at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); at com.sun.glass.ui.gtk.GtkApplication.lambda$runLoop$11(GtkApplication.java:277); at java.base/java.lang.Thread.run(Thread.java:834); INFO: TiffDelegateReader initializing /home/joelrv/Downloads/test_pyramid.tif; INFO: Reading IFDs; INFO: Populating metadata; INFO: Checking comment style; INFO: Populating OME metadata; INFO: No memoization file generated for /home/joelrv/Downloads/test_pyramid.tif; ERROR: QuPath exception; at qupath.lib.gui.viewer.QuPathViewer.updateSuggestedOverlayColorFromThumbnail(QuPathViewer.java:996); at qupath.lib.gui.viewer.QuPathViewer.getSuggestedOverlayColor(QuPathViewer.java:1005); at qupath.lib.gui.viewer.QuPathViewer.paintViewer(QuPathViewer.java:1665); at qupath.lib.gui.vie,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/279#issuecomment-472375699:9991,secur,security,9991,https://qupath.github.io,https://github.com/qupath/qupath/issues/279#issuecomment-472375699,1,['secur'],['security']
Security,"ation Thread]	ERROR	qupath.lib.gui.QuPathUncaughtExceptionHandler	Cannot invoke ""javafx.stage.Stage.close()"" because ""this.dialog"" is null	java.lang.NullPointerException: Cannot invoke ""javafx.stage.Stage.close()"" because ""this.dialog"" is null; 	at qupath.lib.gui.scripting.DefaultScriptEditor.promptToClose(DefaultScriptEditor.java:518); 	at qupath.lib.gui.QuPathGUI.handleCloseMainStageRequest(QuPathGUI.java:1018); 	at javafx.base@22.0.1/com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86); 	at javafx.base@22.0.1/com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:232); 	at javafx.base@22.0.1/com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:189); 	at javafx.base@22.0.1/com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDispatcher.java:59); 	at javafx.base@22.0.1/com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:58); 	at javafx.base@22.0.1/com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); 	at javafx.base@22.0.1/com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); 	at javafx.base@22.0.1/com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); 	at javafx.base@22.0.1/javafx.event.Event.fireEvent(Event.java:198); 	at javafx.graphics@22.0.1/com.sun.javafx.stage.WindowPeerListener.closing(WindowPeerListener.java:100); 	at javafx.graphics@22.0.1/com.sun.javafx.tk.quantum.GlassStage.lambda$requestClosingAllWindows$3(GlassStage.java:204); 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:400); 	at javafx.graphics@22.0.1/com.sun.javafx.tk.quantum.GlassStage.requestClosingAllWindows(GlassStage.java:203); 	at javafx.graphics@22.0.1/com.sun.javafx.tk.quantum.QuantumToolkit$2.handleQuitAction(QuantumToolkit.java:370); 	at javafx.graphics@22.0.1/com.sun.glass.ui.mac.MacApplication$4.action(MacApplication.java:226); ```",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/pull/1524#issuecomment-2133581152:1740,secur,security,1740,https://qupath.github.io,https://github.com/qupath/qupath/pull/1524#issuecomment-2133581152,3,"['Access', 'secur']","['AccessController', 'security']"
Security,"ation Thread] [WARN ] qupath.lib.gui.QuPathGUI - No directory set for log files! None will be written.; 12:07:41.225 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - QuPath build: Version: 0.2.0-m1; Build time: 2019-03-08, 17:51; Latest commit tag: v0.0.1-beta-561-gfb062c1. (QuPath-0.2.0-m1:8210): Gdk-WARNING **: XSetErrorHandler() called with a GDK error trap pushed. Don't do that.; 12:07:42.748 [JavaFX Application Thread] [INFO ] q.l.i.s.b.BioFormatsOptionsExtension - Bio-Formats version 6.0.0; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.codehaus.groovy.vmplugin.v7.Java7$1 (file:/home/joelrv/software/opt/QuPath/qupath_0.2.0-m1/app/groovy-2.5.6.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class,int); WARNING: Please consider reporting this to the maintainers of org.codehaus.groovy.vmplugin.v7.Java7$1; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 12:07:43.276 [JavaFX Application Thread] [INFO ] q.l.i.s.o.OpenslideServerBuilder - OpenSlide version 3.4.1; 12:07:43.360 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Selected style: null; 12:07:43.360 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathGUI - Performing update check...; 12:07:43.365 [JavaFX Application Thread] [INFO ] qupath.lib.gui.QuPathApp - Starting QuPath with parameters: []; 12:08:18.669 [JavaFX Application Thread] [WARN ] q.l.i.s.o.OpenslideImageServer - Openslide: Property 'openslide.mpp-x' not available, will return default value NaN; 12:08:18.670 [JavaFX Application Thread] [WARN ] q.l.i.s.o.OpenslideImageServer - Openslide: Property 'openslide.mpp-y' not available, will return default value NaN; 12:08:18.670 [JavaFX Application Thread] [WARN ] q.l.i.s.o.OpenslideImageServer - Openslide: Property 'openslide.objective-power' not available, will retur",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/279:1792,access,access,1792,https://qupath.github.io,https://github.com/qupath/qupath/issues/279,3,['access'],['access']
Security,b.scripting.QPEx.runPlugin(QPEx.java:266); at qupath.lib.scripting.QPEx.runPlugin(QPEx.java:286); at qupath.lib.scripting.QPEx$runPlugin.callStatic(Unknown Source); at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:214); at Script30.run(Script30.groovy:12); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:343); at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:152); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:765); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:695); at qupath.lib.scripting.DefaultScriptEditor.executeScript(DefaultScriptEditor.java:677); at qupath.lib.scripting.DefaultScriptEditor.access$400(DefaultScriptEditor.java:136); at qupath.lib.scripting.DefaultScriptEditor$2.run(DefaultScriptEditor.java:1029); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by null at qupath.lib.images.servers.BioFormatsImageServer.getTimePoint(BioFormatsImageServer.java:930); at qupath.imagej.images.servers.BufferedImagePlusServer.getTimePoint(BufferedImagePlusServer.java:173); at qupath.imagej.helpers.IJTools.calibrateImagePlus(IJTools.java:220); at qupath.imagej.images.servers.BufferedImagePlusServer.readImagePlusRegion(BufferedImagePlusServer.java:241); at qupath.imagej.detect.tissue.SimpleTissueDetection2$GlobalThresholder.runDetection(SimpleTissueDetection2.java:158); at qupath.lib.plugins.Detect,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/223#issuecomment-424986075:10426,access,access,10426,https://qupath.github.io,https://github.com/qupath/qupath/issues/223#issuecomment-424986075,1,['access'],['access']
Security,"blematic frame:; # C [libc.so.6+0x9a23b] __libc_malloc+0x12b. [...more stuff...]. Current thread (0x00007f594d8d5540): JavaThread ""tile-exporter10"" daemon [_thread_in_vm, id=314754, stack(0x00007f4ec1aaf000,0x00007f4ec1bb0000)]. Stack: [0x00007f4ec1aaf000,0x00007f4ec1bb0000], sp=0x00007f4ec1bac3d0, free space=1012k; Native frames: (J=compiled Java code, A=aot compiled Java code, j=interpreted, Vv=VM code, C=native code); C [libc.so.6+0x9a23b] __libc_malloc+0x12b. Java frames: (J=compiled Java code, j=interpreted, Vv=VM code); J 758 java.lang.ClassLoader.defineClass1(Ljava/lang/ClassLoader;Ljava/lang/String;[BIILjava/security/ProtectionDomain;Ljava/lang/String;)Ljava/lang/Class; java.base@16.0.2 (0 bytes) @ 0x00007f594243a6f0 [0x00007f594243a640+0x00000000000000b0]; J 754 c1 java.lang.ClassLoader.defineClass(Ljava/lang/String;[BIILjava/security/ProtectionDomain;)Ljava/lang/Class; java.base@16.0.2 (43 bytes) @ 0x00007f593b0f1dc4 [0x00007f593b0f1a80+0x0000000000000344]; J 939 c1 java.security.SecureClassLoader.defineClass(Ljava/lang/String;[BIILjava/security/CodeSource;)Ljava/lang/Class; java.base@16.0.2 (16 bytes) @ 0x00007f593b150c8c [0x00007f593b150bc0+0x00000000000000cc]; J 739 c1 jdk.internal.loader.BuiltinClassLoader.defineClass(Ljava/lang/String;Ljdk/internal/loader/Resource;)Ljava/lang/Class; java.base@16.0.2 (121 bytes) @ 0x00007f593b0e9acc [0x00007f593b0e8c20+0x0000000000000eac]; J 653 c1 jdk.internal.loader.BuiltinClassLoader.findClassOnClassPathOrNull(Ljava/lang/String;)Ljava/lang/Class; java.base@16.0.2 (64 bytes) @ 0x00007f593b0be434 [0x00007f593b0bd460+0x0000000000000fd4]; J 3884 c1 jdk.internal.loader.BuiltinClassLoader.loadClassOrNull(Ljava/lang/String;Z)Ljava/lang/Class; java.base@16.0.2 (143 bytes) @ 0x00007f593b6e8024 [0x00007f593b6e71c0+0x0000000000000e64]; J 632 c1 jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(Ljava/lang/String;Z)Ljava/lang/Class; java.base@16.0.2 (40 bytes) @ 0x00007f593b0b206c [0x00007f593b0b1a60+0x000000000000060c]; ",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/932#issuecomment-1057931302:1433,secur,security,1433,https://qupath.github.io,https://github.com/qupath/qupath/issues/932#issuecomment-1057931302,1,['secur'],['security']
Security,"brary.load(Native Method). at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941). at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857). at java.lang.Runtime.loadLibrary0(Runtime.java:870). at java.lang.System.loadLibrary(System.java:1122). at qupath.opencv.OpenCVExtension.loadNativeLibrary(OpenCVExtension.java:59). at qupath.opencv.OpenCVExtension.addQuPathCommands(OpenCVExtension.java:72). at qupath.opencv.OpenCVExtension.installExtension(OpenCVExtension.java:116). at qupath.lib.gui.QuPathGUI.refreshExtensions(QuPathGUI.java:1093). at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:637). at qupath.lib.gui.QuPathGUI.<init>(QuPathGUI.java:429). at qupath.lib.gui.QuPathApp.start(QuPathApp.java:63). at com.sun.javafx.application.LauncherImpl.lambda$launchApplication1$161(LauncherImpl.java:863). at com.sun.javafx.application.PlatformImpl.lambda$runAndWait$174(PlatformImpl.java:326). at com.sun.javafx.application.PlatformImpl.lambda$null$172(PlatformImpl.java:295). at java.security.AccessController.doPrivileged(Native Method). at com.sun.javafx.application.PlatformImpl.lambda$runLater$173(PlatformImpl.java:294). at com.sun.glass.ui.InvokeLaterDispatcher$Future.run(InvokeLaterDispatcher.java:95). at com.sun.glass.ui.win.WinApplication._runLoop(Native Method). at com.sun.glass.ui.win.WinApplication.lambda$null$147(WinApplication.java:177). at java.lang.Thread.run(Thread.java:748). INFO: Selected style: Modena Light. INFO: Performing update check... INFO: Starting QuPath with parameters: []. . I deinstalled the other version but there it did work without any problems. Is there any way to deinstall qupath so that I can try to install it again?. . Best,. Marcel. . . Von: Pete [mailto:notifications@github.com] ; Gesendet: Dienstag, 7. August 2018 03:02; An: qupath/qupath; Cc: 2010mars2010; Author; Betreff: Re: [qupath/qupath] touch gestures: zooms when moving up/down (#188). . I only got one problem: QuPath cannot open any *.svs (scanscope virtual slide) images any",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/188#issuecomment-411621646:1136,secur,security,1136,https://qupath.github.io,https://github.com/qupath/qupath/issues/188#issuecomment-411621646,1,['secur'],['security']
Security,cEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$ClickGenerator.postProcess(Scene.java:3597); at javafx.scene.Scene$MouseHandler.process(Scene.java:3899); at javafx.scene.Scene.processMouseEvent(Scene.java:1885); at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2618); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:409); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:299); at java.base/java.security.AccessController.doPrivileged(Unknown Source); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$2(GlassViewEventHandler.java:447); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:412); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:446); at com.sun.glass.ui.View.handleMouseEvent(View.java:556); at com.sun.glass.ui.View.notifyMouse(View.java:942); at com.sun.glass.ui.win.WinApplication._runLoop(Native Method); at com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:174); at java.base/java.lang.Thread.run(Unknown Source). 2. how precisely did the abnormal shutdown occur?. I had a VPN connection with my pc in the office and then somebody else logged in to the machine and I got logged out. The VPN connection is via a .rdp file where I can just use my home screen/pc as a window to my office pc (is this clear?). 3. can you give precise steps to replicate the issue? -> Yes,MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/512#issuecomment-640534382:4450,Access,AccessController,4450,https://qupath.github.io,https://github.com/qupath/qupath/issues/512#issuecomment-640534382,1,['Access'],['AccessController']
Security,cEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$ClickGenerator.postProcess(Scene.java:3599); at javafx.scene.Scene$MouseHandler.process(Scene.java:3903); at javafx.scene.Scene.processMouseEvent(Scene.java:1887); at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2620); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:411); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:301); at java.base/java.security.AccessController.doPrivileged(Unknown Source); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$2(GlassViewEventHandler.java:450); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:424); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:449); at com.sun.glass.ui.View.handleMouseEvent(View.java:551); at com.sun.glass.ui.View.notifyMouse(View.java:937); at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); at com.sun.glass.ui.gtk.GtkApplication.lambda$runLoop$11(GtkApplication.java:316); at java.base/java.lang.Thread.run(Unknown Source); Caused by DuplicatableGlyph.textFill : A bound value cannot be set. at javafx.beans.property.ObjectPropertyBase.set(ObjectPropertyBase.java:143); at javafx.css.StyleableObjectProperty.set(StyleableObjectProperty.java:82); at javafx.beans.property.ObjectProperty.setValue(ObjectProperty.java:78); at com.sun.javafx.binding.BidirectionalBinding$TypedGen,MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1202:8291,Access,AccessController,8291,https://qupath.github.io,https://github.com/qupath/qupath/issues/1202,1,['Access'],['AccessController']
Security,"cEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56); at com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114); at com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74); at com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54); at javafx.event.Event.fireEvent(Event.java:198); at javafx.scene.Scene$ClickGenerator.postProcess(Scene.java:3599); at javafx.scene.Scene$MouseHandler.process(Scene.java:3903); at javafx.scene.Scene.processMouseEvent(Scene.java:1887); at javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2620); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:411); at com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:301); at java.base/java.security.AccessController.doPrivileged(Unknown Source); at com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$2(GlassViewEventHandler.java:450); at com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:424); at com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:449); at com.sun.glass.ui.View.handleMouseEvent(View.java:551); at com.sun.glass.ui.View.notifyMouse(View.java:937); at com.sun.glass.ui.gtk.GtkApplication._runLoop(Native Method); at com.sun.glass.ui.gtk.GtkApplication.lambda$runLoop$11(GtkApplication.java:316); at java.base/java.lang.Thread.run(Unknown Source); INFO: Image data set to ImageData: Brightfield (other), Training Img (Classifier); ERROR: Bidirectional binding failed, setting to the previous value (see full stack trace above, or use 'debug' log level); ERROR: Bidirectional binding failed, setting to the previous value (see full stack trace above, or use 'debug' log level)`. When I run it on QuPa",MatchSource.ISSUE,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/1202:15160,Access,AccessController,15160,https://qupath.github.io,https://github.com/qupath/qupath/issues/1202,1,['Access'],['AccessController']
Security,"cend from the 'base' POM, which specifies that the compiler should be compatible with [Java 8 here](https://github.com/qupath/qupath/blob/v0.1.2/pom.xml#L176). I believe this should then be inherited across the project.; * slf4j-api is a dependency of logback-classic. This is specified in the base POM, and so Maven should still take care of slf4j even if it isn't mentioned directly. I don't know why anything involving javax.script would be troublesome.; * The jar files alone required for QuPath are reasonably small, but the JRE is required for running it. The JavaFX packager can be used to put them all together in one (larger) installer, but if you already have a compatible JRE installed then you shouldn't need this.; * OpenSlide and OpenCV require native libraries... which opens a new area of effort for configuring everything properly. I suspect this final point is critical for the 'opening only thumbnails' issue. When opening a new image from a given path, QuPath will test all potential file readers it has access to and check if they can handle the path. If you are only getting the thumbnails, then this implies that the OpenSlide check doesn't pass - which, because OpenSlide *can* certainly handle .svs, suggests that the OpenSlide native libraries are not properly accessible to QuPath, even if the jar is there. When QuPath shows 'ImageJ' as the reader, it does mean just this; ImageJ1 is being used, which can handle a range of small (non-whole-slide) images only, with a combination of its own TIFF reader and Java's ImageIO. It can also sometimes extract the thumbnail from a whole slide image, but only that. If you want to use Bio-Formats you can, but need to download and add it separately - see https://github.com/qupath/qupath-bioformats-extension. If you do install the Bio-Formats extension, then that postpones the immediate need to solve the problem of accessing native libraries; at least, you should be able to open the formats supported by Bio-Formats so long as",MatchSource.ISSUE_COMMENT,qupath,qupath,v0.5.1,https://github.com/qupath/qupath/issues/84#issuecomment-317351735:1536,access,access,1536,https://qupath.github.io,https://github.com/qupath/qupath/issues/84#issuecomment-317351735,1,['access'],['access']
