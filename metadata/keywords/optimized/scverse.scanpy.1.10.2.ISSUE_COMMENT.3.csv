quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Safety,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:1383,detect,detection,1383,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088,1,['detect'],['detection']
Safety,@falexwolf Is there anyplace where we can read into `diffxpy`? I've been benchmarking available marker gene detection algorithms and am interested to see what is included in this new package.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/159#issuecomment-420362783:108,detect,detection,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159#issuecomment-420362783,1,['detect'],['detection']
Safety,"@falexwolf Thanks for the explanation.; I see now that it's an issue of how the package should be used, i.e. the philosophy behind your api, and I seem to have tried to use it in a different perhaps more low level way. I will look in to using more low level functions/modules if I need it and work with your original intended workflow which i think make sense. I have missed the whole settings functionality which seems really useful to avoid some of the issues I have had.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/419#issuecomment-453876840:437,avoid,avoid,437,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419#issuecomment-453876840,1,['avoid'],['avoid']
Safety,"@falexwolf Thanks for the support. . I agree that this is not an urgent changes that can quietly be tested. Have you consider having a 'develop' branch were we can put all code like this? . As you point out some differences are seen with respect to the shape of the plot when multiple panels are plot. This is mostly due to some code to add space for the colorbar and legends that can overlap nearby figures. Nevertheless, I can further adjust this to get plots that are more similar to the actual ones. I think that the tests are failing because there is a clash between the module and a method called `scatter`. Once the code is cleaned this should go away. . If you don't mind I would slowly start removing redundant code and adding further tests. So, lets keep this PR open.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-416855357:710,redund,redundant,710,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-416855357,1,['redund'],['redundant']
Safety,"@falexwolf, I think it would be worth going over what kind of interactivity would be most useful. I find linked selection and summary statistics on selected groups is pretty powerful. For QC plots, it's nice to know other properties of cells which look like outliers. It can also be useful for figuring out what's up with the classification that's not agreeing with your reduced dimension plot. Being able to interactively search and select genes to view would also be nice. It would also be good if it were easy to share this kind of visualization with non-technical collaborators easily. I think there's also a question of scale, and whether it would be nice to use libraries like [datashader](http://datashader.org) to avoid the over plotting problems that are so common in this field. I'm working on a few prototypes at the moment, but I'm not sure how well they fit into the api of adding an `interact` flag. Once I have things a little more formalized I'll set up a repo, but am open to suggestions for other plot types. I'd be interested in getting opinions on the usefulness of `datashader`'s edge bundling for graph plots ([examples here](http://holoviews.org/user_guide/Network_Graphs.html#) under the header ""Bundling graphs""). There's also the issue of libraries. Currently, I'm frustrated with every python plotting library, but am leaning towards the `holoviews`, `bokeh`, `datashader` stack for this. @gokceneraslan If you're asking about what usage of bokeh looks like, [they have a bunch of notebooks](https://github.com/bokeh/bokeh-notebooks) in a repo that'll run on [Binder](https://mybinder.org).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/253#issuecomment-418597651:722,avoid,avoid,722,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/253#issuecomment-418597651,1,['avoid'],['avoid']
Safety,"@fidelram Since we are not using tight layout when we save figures for the plotting tests, axis labels are cut off. I enabled it to avoid that with the following modification:. <img width=""759"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/110717685-87ba0900-81d7-11eb-8cfd-a1c71155d276.png"">. Here is the new plot testing this PR without the tight layout:. ![master_dotplot_groupby_list_catorder](https://user-images.githubusercontent.com/1140359/110726467-6cef9080-81e7-11eb-971d-e6b87dd92f6e.png). which is pretty bad because what really matters in this plot for this PR is the labels of the x axis. Here is the same plot with the tight layout:. ![master_dotplot_groupby_list_catorder-tightlayout](https://user-images.githubusercontent.com/1140359/110726408-534e4900-81e7-11eb-9931-adae793d099e.png). However, many plotting tests fail now due to this change :/ Do you mind helping me with the failing tests?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1735#issuecomment-796324421:132,avoid,avoid,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1735#issuecomment-796324421,1,['avoid'],['avoid']
Safety,@flying-sheep I completely agree that it may not be the best naming convention. That was what it was used for at the time though. @grst The idea of using gene symbols as `.var_names` in scanpy was to make the software as user friendly as possible as far as I'm aware. Typically people care about the gene-level as the highest resolution. This is probably also due to the dominance of 3` enrichment protocols making it hard to detect signals at a higher resolution.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/376#issuecomment-441077219:426,detect,detect,426,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/376#issuecomment-441077219,1,['detect'],['detect']
Safety,"@flying-sheep I think the output is clear once you know what is about. Since this error may happen to future contributions that are not aware of the efforts to reduce import times, I think is better to be explicit. Something like: ""Slow import detected (scipy.stats). Please check that slow-to-import packages are not in top level calls but inside the functions that require them"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/797#issuecomment-537510120:244,detect,detected,244,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797#issuecomment-537510120,1,['detect'],['detected']
Safety,"@flying-sheep I thought that by doing `adata[:, 'gene_name'].X` the AnnData object does all sorts of checks which are redundant if I only want to access a single column on the data matrix. But if you say this is fine I will not change it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-422361197:118,redund,redundant,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-422361197,1,['redund'],['redundant']
Safety,"@giovp Looking more into the crashing I was getting with my strange use case, it turns out that I had both (a) a pair of completely correlated features, and (b) very strange count distributions. Once I used a proper variance stabilizing transform (arcsinh in this case) and remove redundant features, I can't reliably reproduce this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-802328453:281,redund,redundant,281,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-802328453,1,['redund'],['redundant']
Safety,"@gokceneraslan I like the idea, that would save quite some space. However, as a partial color blind person, I tend to avoid legends based on color because I can not map them reliably back to the figure. But otherwise, I think it is easy to adapt the current code to add such feature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/228#issuecomment-411039951:118,avoid,avoid,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/228#issuecomment-411039951,1,['avoid'],['avoid']
Safety,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-761117523:454,avoid,avoid,454,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-761117523,1,['avoid'],['avoid']
Safety,"@gokceneraslan. > I want the h5ad file to include absolutely everything, so that it can be simply used as a single file distribute the ""full dataset"". As a point about this, I don't think `raw` completley solves this problem. There's two reasons for this:. ### Only a different set of variables. Raw only differs from the main object by variables. But we just as often want to remove observations (doublet detection for example). To account for this, I think it makes sense to just have two different anndata objects. ### absolutely everything. I don't think we really can expect to have everything. There are always going to be analyses that require going back to the BAM. If ""single file"" is the issue, we could definitely allow something like:. ```python; with h5py.File(""analysis.h5"") as f:; processed = ad.read_h5ad(f[""processed""]); raw = ad.read_h5ad(f[""raw""]); ```. -----------------------------. @LuckyMD . > Integration works better with HVGs typically. I'm thinking of the case where I have a few datasets saved as `h5ad` that I want to integrate. What if a highly variable gene in one dataset just isn't present in another? Is it because it wasn't found in that dataset at all, or because it was only present in a few cells? If it was only present in a few cells, how can I be sure a particular cell type wasn't just poorly represented in that dataset?. I feel like it's helpful to have the all the measured genes present, so that when you do gather your datasets together you can select features from the full set. > > This does run into memory usage problems if want do a densifying transform on the data; > Don't understand this entirely... I was thinking about what happens if you do something like `sc.pp.scale`, where you don't have any 0s in your expression matrix anymore, so it has to be stored as a dense matrix. I believe this is why `raw` was even introduced originally, since the normalization workflow then was feature selection -> scale. It was wasteful to store the entire s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-820902472:406,detect,detection,406,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-820902472,1,['detect'],['detection']
Safety,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`; In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-734460539:451,avoid,avoid,451,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-734460539,1,['avoid'],['avoid']
Safety,"@ivirshup @flying-sheep I would remove the `, optional` statement from the docstrings, as, what we mean with this is ""a parameter has a default value"". Hence, it's redundant. However, it's consistently used in all of numpy, scipy, sklearn, pandas, etc.; ![image](https://user-images.githubusercontent.com/16916678/56281364-b3780580-610c-11e9-8e40-2f44d3007a19.png). In the auto-generated type annotations, the default values miss completely, and I don't think we'll ever restore the `, optional` descriptor, there. ![image](https://user-images.githubusercontent.com/16916678/56281431-e15d4a00-610c-11e9-990c-6a2477540535.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/610#issuecomment-484029598:164,redund,redundant,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484029598,1,['redund'],['redundant']
Safety,"@ivirshup I think doublet detection is a little too narrow in that we can also associate cells to the original sample they came from. Although many folks use cell hashing solely for the purpose of doublet detection. I'd prefer ""Sample demultiplexing"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1483#issuecomment-724181103:26,detect,detection,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483#issuecomment-724181103,2,['detect'],['detection']
Safety,"@ivirshup Indeed the problem is `use_raw=True` by default. In the test, I think what happens is that the raw data is being plotted and thus no error appears. The tolerance for the image difference may hide the problem if indeed the test image is correct. To avoid this confusion when plotting a layer I think it is better to override `use_raw`. This is how it was supposed to be working before the changes according to the documentation:. ```; layer : typing.Union[str, NoneType], optional (default: None); Name of the AnnData object layer that wants to be plotted. By default; adata.raw.X is plotted. If `use_raw=False` is set, then `adata.X` is plotted.; If `layer` is set to a valid layer name, then the layer is plotted. `layer`; takes precedence over `use_raw`.; ``` ; The current logic is around this lines https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L744. PS: the `use_raw` has been a source of many confusions for me. Now I know when raw is used by default but for new users this may not be obvious. One solution is to add a warning message everytime that `use_raw` is set to `True` by the code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/730#issuecomment-510785080:258,avoid,avoid,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730#issuecomment-510785080,1,['avoid'],['avoid']
Safety,"@ivirshup The idea is that if downloading with a browser or wget works but python requests fail, then the problem should be somewhere in the header. Changing user agent (to avoid blacklist \ whitelist on the server) is the most obvious thing to try.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1334#issuecomment-664924095:173,avoid,avoid,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334#issuecomment-664924095,1,['avoid'],['avoid']
Safety,"@ivirshup thanks for catching these things, i'll fix them. ; In addition to some splitting and cleaning i also want to improve wilcoxon implementation (avoid densification at least, i have some code for it). But this should be another step, i think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1081#issuecomment-596456525:152,avoid,avoid,152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1081#issuecomment-596456525,1,['avoid'],['avoid']
Safety,"@jlause Interesting work! It would indeed be nice to avoid having to learn bandwidths altogether. What would be the procedure for learning global theta from the data? Would you just flatten the expression matrix into one vector?. With regards to the clipping, I turned my brain off and copied the Seurat implementation as much as possible. `sqrt(n/30)` was the default parameter used by the SCTransform wrapper in Seurat. I also removed negative values to preserve sparsity structure of the data. Sorry I couldn't provide any insight about this!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1643#issuecomment-791871293:53,avoid,avoid,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1643#issuecomment-791871293,1,['avoid'],['avoid']
Safety,@liiskolb The problem is that the `python-gprofiler` and `gprofiler-official` packages are both imported as `import gprofiler`. That means that someone who has installed one of them and then gets the other with scanpy won't know what they are importing if they just run `import gprofiler`. This is not ideal. I just experienced the same thing and decided to remove `python-gprofiler`. But we can't really mandate that everyone does this. @ivirshup maybe the solution is to detect which version people have and then parse according to their version? The format is quite similar. I've used both now and could probably convert inputs and outputs easily. And then I'd throw a warning if `python-gprofiler` is installed.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467#issuecomment-504960614:473,detect,detect,473,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-504960614,1,['detect'],['detect']
Safety,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```; python3 download_expression_atlas.py {accession}; ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271:676,redund,redundant,676,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271,1,['redund'],['redundant']
Safety,"@shendong124 @ivirshup I assume `normalize_geometric` was intended to be similar to Seurat's centered log ratio transformation, which is implemented as follows in R: `log1p(x = x / (exp(x = sum(log1p(x = x[x > 0]), na.rm = TRUE) / length(x = x))))`. This is CLR with some safeguards for 0 counts. Here's a reimplementation of the Seurat CLR transformation for scanpy. Call this with `clr_normalize_each_cell(adata)`:. ```; def clr_normalize_each_cell(adata, inplace=True):; """"""Normalize count vector for each cell, i.e. for each row of .X"""""". import numpy as np; import scipy. def seurat_clr(x):; # TODO: support sparseness; s = np.sum(np.log1p(x[x > 0])); exp = np.exp(s / len(x)); return np.log1p(x / exp). if not inplace:; adata = adata.copy(). # apply to dense or sparse matrix, along axis. returns dense matrix; adata.X = np.apply_along_axis(; seurat_clr, 1, (adata.X.A if scipy.sparse.issparse(adata.X) else adata.X); ); return adata; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1208#issuecomment-638496235:272,safe,safeguards,272,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208#issuecomment-638496235,1,['safe'],['safeguards']
Safety,"About adding all powers of adjacency matrix - i implemented it at first as you did, but then i thought that it was redundant and changed to the present variant. My thought was that the hexagonal connectivity structure would allow to get all paths of less than n_rings with only n_rings power. And this works in practice, but i agree that there can be some edge cases with isolated node blocks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-701247872:115,redund,redundant,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-701247872,1,['redund'],['redundant']
Safety,"Actually, I just realised that ; ```python; adata.var_names = adata.var_names + ""-"" + adata.var[""ensembl_id""]; ```; is not optimal because it adds ENSEMBL to every single var name, making the names very long (which is what most people are likely trying to avoid)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1719#issuecomment-793713405:256,avoid,avoid,256,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719#issuecomment-793713405,1,['avoid'],['avoid']
Safety,"Advantage of networkx is that it's easily installed... But yes, we should remove it in the future. I think with anaconda, one gets all the igraph and louvain stuff to work very easily without compiling. Without using Grohlke's binaries... One just needs to document this probably. At the latest when igraph and louvain are easily installed, networkx can be removed... PS: I'm currently preparing scanpy 1.0; there will be some slight changes to make the API less redundant... So for now, please no big changes...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97#issuecomment-370144822:463,redund,redundant,463,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/97#issuecomment-370144822,1,['redund'],['redundant']
Safety,"All of this is really nice! :smile:. Regarding your comment on plotly: returning a fig instead of an ax would follow a different convention as in seaborn; which I'd try to mimic as closely as possible. But for the scatter plots, which are the only ones that would profit a lot from interactive exploration, one could think about breaking this convention. Regarding bugs for now: One bug I could quickly fix myself, two further bugs that I've stumbled across in the past few hours and couldn't fix right away: If I'm calling; ```; sc.pl.umap(adata, color=['celltypes', 'prediction'], palette=[sc.pl.palettes.vega_20, sc.pl.palettes.default_64]); ```; the color maps are ignored. And if I'm calling; ```; sc.pl.umap(adata, color=['louvain', 'Gata1'], legend_loc='on data'; ); ```; the first plot has a different shape than the second.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-424863360:569,predict,prediction,569,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-424863360,1,['predict'],['prediction']
Safety,"Alright! I've got a little example case I'd probably be using for a test case [here](https://gist.github.com/ivirshup/2a0d9a785339b719e7d372027ae2df31) (doublet prediction by simulation and projection). My current thoughts:. * Since we need to be working in the same feature space, we'll at least need PCA projection, but this is pretty easy:. <details>; <summary> Basic PCA projection </summary>. ```python; def pca_update(tgt, src, inplace=True):; # TODO: Make sure we know the settings (just whether to center?) from src; if not inplace:; tgt = tgt.copy(); if sparse.issparse(tgt.X):; X = tgt.X.toarray(); else:; X = tgt.X.copy(); X -= np.asarray(tgt.X.mean(axis=0)); tgt_pca = np.dot(X, src.varm[""PCs""]); tgt.obsm[""X_pca""] = tgt_pca; return tgt; ```. </details>. * Are you planning on storing the UMAP object in the AnnData? That would make transformation easier, but I see how on-disk representation could get complicated.; * What order should we do this in? Would you like everything to be accomplished by this PR or should we break it up?; * Are we introducing a general transfer learning api? Probably worth considering that a bit. Some relevant questions:; * Does the syntax still work for cases other than 1-to-1 transfer? ; * How do we deal with concatenation/ joins? The current `concatenate` doesn't join things like `obsm`.; * Alternatively, does everything have to be in the same AnnData? It would solve issues with having `var` be the same, but could complicate a lot of other code (many functions would need some kind of masking argument).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-481525842:161,predict,prediction,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-481525842,1,['predict'],['prediction']
Safety,"Also, I just found time to read the links you posted @davidsebfischer. Shouldn't we always use a welch t-test instead of a t-test in marker gene detection according to your second stackexchange link? They state that If you don't have a good reason to assume equal variances in the groups, then use the Welch correction... if we have a `group` vs `rest` type of setup as we do in `rank_genes_groups()` at the moment, then we would definitely not expect a single cluster to have an equal variance to the combination of all other cells in other clusters. I think the default is currently `t-test-overestimate-var`... being oblivious to exactly how that works, might it not be better to adapt that to a `welch-t-test-overestimate-var` or something like that @falexwolf?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-449358857:145,detect,detection,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-449358857,1,['detect'],['detection']
Safety,"And in terms of the `sc.pp.highly_variable_genes` function. We typically don't use the `max_mean` and `disperson` based parametrization anymore, but instead just select `n_top_genes`, which avoids this problem altogether. That being said, there is a PR with the VST-based highly-variable genes implementation from Seurat that will be added into scanpy soon. If you would like to reproduce an updated pbmc3k tutorial from Seurat using scanpy functions, that would be very welcome of course!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1338#issuecomment-665746348:190,avoid,avoids,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338#issuecomment-665746348,1,['avoid'],['avoids']
Safety,"Apologies for again, the late response @fidel! I married and moved to the US with twin babies last week. And in between, I spilled something over my laptop... Yes, please go ahead and remove redundant code and add further tests. We'll merge this PR eventually. And yes, we can think about a `develop` branch starting from 1.3. What do you say, @flying-sheep?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-418062501:191,redund,redundant,191,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-418062501,1,['redund'],['redundant']
Safety,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/510#issuecomment-488011785:456,avoid,avoiding,456,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-488011785,1,['avoid'],['avoiding']
Safety,"As an alternative, I'd be up for just deprecating raw all together, as I think it causes more problems than it solves. I was talking about this recently with @falexwolf, who has come to a similar conclusion. This could be done on the `anndata` side, and just warn whenever `raw` is set. If no `raw` is present, then none of the weird behavior should come up. > I wonder how important it is to keep genes that are filtered out due to being expressed in too few cells anyway. Might be important for integration? But hopefully this could be solvable by just knowing what annotation was used so you can safely assume the missing values are 0. Also, what level of filtering are you doing here? I've tend to go `min_cells=1`. I think we do need to have a more general solution for having a ""feature-select-ed"" subset of the data, but think this can be done with `mask` argument. E.g. `sc.pp.pca(adata, mask=""highly_variable"")` (I believe we've talked about this before). This does run into memory usage problems if want do a densifying transform on the data, though I have doubts about whether this can be a good representation of the data. This can be technically solved by using a block sparse matrix type, but I'm not sure if any practically usable implementations of this are currently available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988:599,safe,safely,599,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988,1,['safe'],['safely']
Safety,"Can confirm that `tissue_positions.csv` is not properly detected in 1.9.3 installed off pip, but everything works fine in 1.10.0.dev87+gd08518f5 installed off GitHub.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2565#issuecomment-1651665498:56,detect,detected,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2565#issuecomment-1651665498,1,['detect'],['detected']
Safety,"Caught it. I had forgotten that arguments only get evaluated once, so if you mutate them, there is state which is maintained to other calls. I think the unhelpful `abort` message is from `louvain-igraph` expecting a weight vector of the right shape, which ended up with the error:. ```; libc++abi.dylib: terminating with uncaught exception of type char const*; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248#issuecomment-419698370:164,abort,abort,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248#issuecomment-419698370,1,['abort'],['abort']
Safety,"Cool! :smile:. But is it possible to stay within the naming scheme? Or maybe even better, to avoid cluttering the namespace with many similar functions, add a parameter to `calculate_qc_metrics` that allows to restrict to `obs` and `var` if wanted?. Updating `docs/release_notes.rst` would also be great!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/615#issuecomment-487026013:93,avoid,avoid,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/615#issuecomment-487026013,1,['avoid'],['avoid']
Safety,"Could you please do `Dict[KeyType, ValueType]` instead of `dict` in the type annotations?. @falexwolf you forgot that the types will be added to the shift-tab info too: https://github.com/theislab/scanpy/blob/10f8a3c8aa5cfa4431db2a10f1f3cc088072e788/scanpy/__init__.py#L42. So yes, @LuckyMD please remove all *redundant* type info in the docs. The info for `method` and `normalize` should stay, the rest can go with absolutely no loss of information anywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/549#issuecomment-476111286:310,redund,redundant,310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-476111286,1,['redund'],['redundant']
Safety,Do you reckon it makes sense to make `sc.tl.marker_genes_overlap()` use this code internally to reduce code redundancy?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-560100529:108,redund,redundancy,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-560100529,1,['redund'],['redundancy']
Safety,"Good to hear! Looking forward to learning more about it.; PS: Having a doublet detection tool in `tl` would be fine, I'd say... `pp` and `tl` are just meant to give a rough orientation for users... in some cases, it's not completely clear what *preprocessing* and what *downstream* analysis is...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-400277845:79,detect,detection,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-400277845,1,['detect'],['detection']
Safety,Google can't find 4000 and UMI on their website:. https://www.google.com/search?safe=off&ei=PC4aXYaLBcWAad_4vdAG&q=%224000%22++inurl%3A10xgenomics+umi&oq=%224000%22++inurl%3A10xgenomics+umi&gs_l=psy-ab.3...3637.3826..3984...0.0..0.76.218.3......0....1..gws-wiz.......0i71.oYAb2OqUy7I. >,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/718#issuecomment-507326463:80,safe,safe,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/718#issuecomment-507326463,1,['safe'],['safe']
Safety,"Great that you fixed it! :). I'm in principle happy to merge the pull request! However, it contains a lot of the previous commits to master by other people; maybe you haven't properly rebased your branch to master at some point? Looking at the diff across the whole request, I see mostly old things from the 25 commits before. So, (1) could you point me to the diff across all your commits that you actually did? (2) Are we going to have a messed up history with redundant commits on the master branch if I merge this, I don't think so, but I'm not 100% sure. Sorry for the additional work, but blindly merging something into master is of course too dangerous, and going through each single commit is too tedious. ;). Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248#issuecomment-420660906:463,redund,redundant,463,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248#issuecomment-420660906,1,['redund'],['redundant']
Safety,"Great! @ivirshup set up this https://scanpy.discourse.group. We'll properly announce it and, I hope this becomes the persistent place for discussing issues around using Scanpy. Thank you for the initiative, Brandon! I'll close this for now; if we're unhappy with this solution, we can get back at some point. I'll also follow up on this with an email to you guys. PS: Brandon, could you delete scanpyhelp at gitter so that we avoid potentially confusing people? Thank you. ; PPS: For reference: https://github.com/theislab/scanpy/commit/df80290a2c24403d4af4c8eb4091acaa49e39496",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/542#issuecomment-509111551:426,avoid,avoid,426,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542#issuecomment-509111551,1,['avoid'],['avoid']
Safety,"Have the same issue. Windows, Ubuntu for WSL, miniconda:. > conda install -c bioconda/label/cf201901 scanpy; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: |; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. > UnsatisfiableError: The following specifications were found; to be incompatible with the existing python installation in your environment:. > Specifications:. > - scanpy -> python[version='>=3.6,<3.7.0a0']. > Your python: python=3.7",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-582183368:624,abort,abort,624,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-582183368,1,['abort'],['abort']
Safety,"Having the exact same problem. Windows machine, win10, 64 bit. Trying to install from miniconda. FWIW, I have installed scanpy successfully on two other windows machines (my home computer and my work computer) in the last three weeks. Now following identical steps on my laptop and having this tissue. . ```; conda install -c bioconda scanpy; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: /; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package pytables conflicts for:; scanpy -> pytables; Package pandas conflicts for:; scanpy -> pandas[version='>=0.21']; Package umap-learn conflicts for:; scanpy -> umap-learn[version='>=0.3.0']; Package h5py conflicts for:; scanpy -> h5py!=2.10.0; Package patsy conflicts for:; scanpy -> patsy; Package numba conflicts for:; scanpy -> numba[version='>=0.41.0']; Package anndata conflicts for:; scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']; Package seaborn conflicts for:; scanpy -> seaborn; Package setuptools conflicts for:; scanpy -> setuptools; Package python conflicts for:; scanpy -> python[version='>=3.6']; Package importlib-metadata conflicts for:; scanpy -> importlib-metadata; Package importlib_metadata conflicts for:; scanpy -> importlib_metadata[version='>=0.7']; Package scikit-learn conflicts for:; scanpy -> scikit-learn[version='>=0.21.2']; Package networkx conflicts for:; scanpy -> networkx; Package python-igraph conflicts for:; scanpy -> python-igraph; Package louvain conflicts for:; scanpy -> louvain;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-575769824:858,abort,abort,858,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-575769824,1,['abort'],['abort']
Safety,"Hello,; For information: if I understood correctly, there could be a risk on the current version of `score_genes_cell_cycle` method when the `adata.raw` is present:; - `score_genes_cell_cycle` is based on `score_genes` method which seems to use `adata.raw` to estimate gene score when it is present by default. As far as I know, people often store log-transformed counts to `adata.raw` (an example could be found [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html)).; - However, according to [here](https://nbviewer.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb), ""Log-transformation of data and scaling should always be performed before scoring."". In this situation, when people use `adata.raw` to store logged values, and apply `score_genes_cell_cycle` method to the object without explicitly setting `use_raw = False`, the results could be problematic, unless there is some specific processing overwritting `score_genes`' initial behaviour that I was not aware of.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1599#issuecomment-1465898381:69,risk,risk,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1599#issuecomment-1465898381,1,['risk'],['risk']
Safety,"Hey Isaac - thanks for the tip, I did not know about `add_totals`! Violin plots are, in principle, exactly what I would like to have, but they are very hard to read for genes with lots of zeros or for clusters with a lot of cells. I am still worried that this doesn't make the relative numbers clear. For instance, something like 40% of CD14+ monocytes express LDHB, while maybe 80% of dendritic cells do. This looks like it might be more ""relevant"", but in reality, the number of monocytes that express the gene is three times the number of total dendritic cells. Does this make sense?. I guess that in the end the onus is on me to avoid or highlight such ambiguities in the analysis, and remain cognisant of them while looking at the data. I will keep thinking about this and post here if I have an epiphany.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2107#issuecomment-1016453592:633,avoid,avoid,633,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2107#issuecomment-1016453592,1,['avoid'],['avoid']
Safety,"Hey! I think it's a great idea to put HVG calculation within batches as a pull request. This is also an important pre-processing step for `sce.mnn_correct`, which I usually run on the intersection of HVGs from each batch. Do you think you could output the intersection as well? Or would it just be a matter of subsetting HVGs that are detected in all batches from the resulting dataframe?. I'm a bit more skeptical for advertising this as a batch-correction approach though. Maybe for time-series data where you can't use other batch correction methods?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/614#issuecomment-485751500:335,detect,detected,335,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/614#issuecomment-485751500,1,['detect'],['detected']
Safety,"Hey! Thank you for using Scanpy!. ```; # First solution: assign subset to cluster 1 -- does not work; adata[gene1_obs,:].obs[""my_cluster""] = 1; ```; If you print `adata[gene1_obs,:]`, you'll see that it generates a view on `adata`. If you try the annotations of the view, however, this view becomes a copy. This is a safety measure as most people treat subsets of the data matrix as if it was a copy. Views are necessary, however, to be able to index in a data matrix (also for efficiency reasons). But I realize that we should print warnings when someone tries to do this, similar to pandas, which also prints a warning if you do `df['col'].loc['a':'b'] = value`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/612#issuecomment-484037086:317,safe,safety,317,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/612#issuecomment-484037086,1,['safe'],['safety']
Safety,"Hey!. Logistic regression currently doesn’t output p-values i believe. Either way, it also treats genes as independent variables, so no need for subsetting here either. As for your second question, you may have misunderstood my answer. `sc.tl.rank_genes_groups()` gives you marker genes just as MAST or diffxpy do (but with more complex models that can incorporate covariates). I was just commenting on the interpretation of marker genes. They tell you which genes characterize a cluster, but don’t necessary tell you which genes contributed most to the global split of clusters that was generated (which i thought you were asking about). That type of question would require a feature importance metric on a multiclass classification problem. For example training a random forest to predict the clusters and then using gini importance to rank the features. That is not a common question asked of single-cell data though, so there’s no tool i’m familiar with that does this. I hope that is clearer.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/748#issuecomment-515168347:783,predict,predict,783,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748#issuecomment-515168347,1,['predict'],['predict']
Safety,"Hey, sorry for being slow here. upon looking into this again, it is the case that `read_10x_mtx` has to make strong assumptions on the files being generated by Cell Ranger. This is also reflected in the filenames this software outputs. Is there a widely used processing pipeline which does not adhere to this file naming?; If yes, scanpy should indeed be able to deal with this;; If no, custom workflows would actually be more reliably dealt with by using a small custom reading script as suggested by @flying-sheep above:. > Hi! That function is for reading the files output by [cellranger’s mex option](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/output/matrices). Your files have been renamed by someone in a way we can’t predict, and you should just adapt the little code needed to read them yourself:; > ; > https://github.com/theislab/scanpy/blob/e6e08e51d63c78581bb9c86fe6e302b80baef623/scanpy/readwrite.py#L324-L341; > ; > Took me 3 minutes:; > ; > ```python; > samples = []; > for sample in range(1, 10):; > s = read(; > path / f'{sample}.matrix.mtx',; > cache=cache,; > cache_compression=cache_compression,; > ).T; > genes = pd.read_csv(path / f'{sample}.genes.tsv', header=None, sep='\t'); > s.var_names = genes[0]; > s.var['gene_symbols'] = genes[1].values; > s.obs_names = pd.read_csv(path / f'{sample}.barcodes.tsv', header=None)[0]; > samples.append(s); > adata = AnnData.concatenate(samples); > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/882#issuecomment-1759283694:767,predict,predict,767,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/882#issuecomment-1759283694,1,['predict'],['predict']
Safety,"Hey. I also thought about the intersection but didn't implement it as the default output for two reasons. . 1) it can be too harsh, especially if there is some biological variation between batches. When we sort the genes based on in how many batches they're detected as HVG and on mean normalized dispersion, there is still a chance for the user to catch such ""biological"" genes with a high n_top_genes value. . 2) Output of highly_variable_genes should be consistent regardless of batch_key option. So n_top_genes and mean/dispersion cutoff flavors should still work the same way. I feel like using the intersection directly as the output violates that. However, making `'highly_variable': np.nansum` part available in adata.var is a good idea. Then users can manually make the selection more stringent by selecting genes where this value == nbatches.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/614#issuecomment-485822437:258,detect,detected,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/614#issuecomment-485822437,1,['detect'],['detected']
Safety,"Hi !; To answer about how it is useful, we are using ICA in our lab to a dataset of more than 100k cells, with a lot of complexity, and the main advantage of ICA against PCA is that it helps us detecting small populations of cells. As these small populations are not accounting for a lot of variance within the dataset, using a treshold on PCs, we discarded the PCs that would allow the separate them.; Another advantage is that we do not make use of a selection of ""highly variable genes"" anymore, and use all genes expressed in more than 100 cells for the whole analysis... Doing the same and applying PCA gave us quite poor results.. . We made use of Seurat implementation.. and I tried fastICA from sklearn once but I couldn't obtain similar results... I have not looked thoroughly into seurat's code tough... . Hope it helps ! ; Best",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/767#issuecomment-519089834:194,detect,detecting,194,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767#issuecomment-519089834,1,['detect'],['detecting']
Safety,"Hi @JonathanShor,. you don't need to create a custom API. One point of Scanpy is to provide convenient access via `anndata` to many single-cell packages around. The only thing needed for that is to provide a very simple interface like [this](https://github.com/theislab/scanpy/blob/master/scanpy/tools/phate.py#L8-L145) or [this](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/mnn_correct.py#L4-L104) or several of the other tools... Simply click on the GitHub links in the Scanpy docs... If your package works reliably, both the restrictions you mention should in principle not prevent adding your package. Of course, in the future, we want all elements of Scanpy to scale to millions of cells, not just the core tools. But for a lot of people, it's right now helpful to have a large number of tools available also for relatively small datasets. The only problem is to avoid cluttering the Scanpy API with virtually any tool there is. Tools in the API should have passed a certain quality check. Doublet detection is a difficult problem. Already last autumn, we played around with @swolock 's tool but didn't end up using it - it was good, but in our situation, it didn't seem to apply (are you eventually going to distribute a package for it @swolock ?). I myself quickly wrote a tool, too, but it didn't work well. Just yesterday, [this](https://www.biorxiv.org/content/early/2018/06/20/352484) appeared. Then there is also [this](https://www.biorxiv.org/content/early/2018/04/04/234872) on ""empty cell detection"". There are more tools out there, I think... What I mean is: computationally detecting doublets is still something where the field has not agreed on a consensus. Just like batch correction. Therefore, I would not add a tool `tl.doublet_detection` or `tl.detect_doublets` to the API at this stage. There are two options. Either we create a `.beta` module of the API for tools that don't even have a preprint and add your tool and similar cases in the future there. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-399367409:891,avoid,avoid,891,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-399367409,1,['avoid'],['avoid']
Safety,"Hi @ThomasThaewel,; In the current best-practices paper the recommendation is to use ""measured data"" as input for marker gene detection. This includes both raw, normalized, and log-normalized data formats. If you are using a count modelling approach for differential expression analysis (e.g., negative binomial, poisson), then you should use raw data (not-normalized) and include size factors in the model. For non-parametric approaches like the ones implemented in `sc.tl.rank_genes_groups()` log-normalized data is better. Hope that clarifies things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2180#issuecomment-1073786068:126,detect,detection,126,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180#issuecomment-1073786068,1,['detect'],['detection']
Safety,"Hi @cartal,. Could it be that you are using a subsetted anndata object on which you are running clustering? If you run an `adata_subset = adata_subset.copy()` You turn that from a view into an anndata object, which might avoid this. I'm however not sure why using a view would make the clustering results end up in `adata.uns`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1410#issuecomment-689475876:221,avoid,avoid,221,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1410#issuecomment-689475876,1,['avoid'],['avoid']
Safety,"Hi @dwnorton, . Sorry for the delay. I can see now that there are a few changes about this on the [UMAP side](https://github.com/lmcinnes/umap/blob/master/umap/spectral.py#L98):. <img width=""617"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/115237075-1f214e80-a0ea-11eb-8257-8352f16ac2ad.png"">. Few questions:. - Can we improve the sparse array handling (e.g. mimicking UMAP e.g. using `SPARSE_SPECIAL_METRICS`) ; - Can we also use the `SKLEARN_PAIRWISE_VALID_METRICS` instead of catching the ValueError? Would that be safer?; - If we start using these keywords, do we need to change any of the requirements of scanpy?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1413#issuecomment-822439809:541,safe,safer,541,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1413#issuecomment-822439809,1,['safe'],['safer']
Safety,"Hi @genecell,. We have a review paper on current best-practices in scRNA-seq analysis which is coming out soon in Molecular Systems Biology that discusses this a bit. The issue with batch correction in scRNA-seq data isn't that batch affects different cell types differently, but rather that if cell type compositions change between batches, then transcriptional differences between the cell types that differ between the batches confound the technical batch effect estimation. So you end up correcting for more than just the technical effect. This means that you can use Combat if the cell type compositions are expected to be similar between batches. Indeed, ComBat is shown to outperform MNN for simple batch correction scenarios ([kBet paper](http://www.nature.com/articles/s41592-018-0254-1)). Inspite of the above argument, the better way to do things is definitely to include batch as a covariate. That way you don't underestimate your background variance. In the case of marker gene detection, this is not quite so problematic as:; 1. It is an easy problem, as cell-type differences tend to be very pronounced so you should always detect a signal even with non-optimal methods.; 2. The p-values you calculate from marker gene detection are inflated anyway and therefore not meaningful. We discuss the above points in our manuscript. I'm not aware whether using corrected data for differential expression testing is discussed anywhere else though. If you email me, I could forward you a copy of the manuscript, but it should be available in MSB in the next weeks. The issue with inflated p-values is also discussed is a few other places like [here](https://www.biorxiv.org/content/early/2018/11/05/463265).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/691#issuecomment-502582404:991,detect,detection,991,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691#issuecomment-502582404,3,['detect'],"['detect', 'detection']"
Safety,"Hi @grst, I had a superficial look at the functionalities and setup and it does look very nice!. - BCR makes sense to add, there seems to be generally less happening in this space in single-cell though right now, compared to TCR. Would be good to have somebody on board who actually works on this data.; - [tcellmatch](https://github.com/theislab/tcellmatch)'s primary purpose is specificity prediction, this could be easily added ontop of this, I will look into your data structure and will think about the necessary changes. I am in the process of making this code public anyway, hopefully next week or so.; - You mentioned distance metrics, this is definitely an interesting and relevant area, in [tcellmatch](https://github.com/theislab/tcellmatch), we implicitly use 1. manhatten distances, 2. euclidian distances in BLOSUM embedding and 3. learned embedding distances, 2. and maybe 3. could be potentially integrated, would be worth discussing in any case.; - Integration with epitope data bases: I have data loaders for IEDB and VDJdb downloads, can you be a bit more specific how you would integrate that with exploratorive single-cell studies? I can only imagine searching for similar TCRs? These anticipated use cases would determine how and whether this makes sense i think.; - Potentially additionally relevant: An integration with dextramer counts to ""stain"" TCR specificity? There is the purely numeric, standard multi-modal single-cell, nature to this data that can be covered by standard scanpy work flows. This data is especially useful in the context of clonotypes etc which then would require additional functionalities, which could be built on what you have here. I have been looking into this type of analysis a lot in context of tcellmatch. Would be to contribute but also happy to see what other people do here, too!. Could you add a brief summary of how you use anndata to store the TCR data in the docs? That would be very helpful to design extension or custom workflows. Grea",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1163#issuecomment-613297254:392,predict,prediction,392,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163#issuecomment-613297254,1,['predict'],['prediction']
Safety,"Hi @hejing3283,. The wrong shape is probably because you have subsetted `adata.X` to highly variable genes, or did some additional filtering after storing data in `adata.raw`. For a while now scanpy avoids filtering highly variable genes, but instead annotates them in `adata.var['highly_variable']` which is then used in `sc.pp.pca()`. I would suggest you use `subset=False` next time you use `sc.pp.highly_variable()` to avoid different dimensions in `adata.X` and `adata.raw.X`. You can easily proceed by just making a new anndata object from `adata.raw.X`, `adata.raw.var` and `adata.raw.obs` and storing this to be loaded into cellxgene. Just do the following:; ```; adata_raw = sc.AnnData(X=adata.raw.X, obs=adata.raw.obs, var=adata.raw.var); adata_raw.write(my_file); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/262#issuecomment-499111938:199,avoid,avoids,199,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/262#issuecomment-499111938,2,['avoid'],"['avoid', 'avoids']"
Safety,"Hi @honghh2018,. Whatever is output depends on what you store in `adata.X`. If you don't want to output scaled data, then you can avoid calling `sc.pp.scale()` on your data. An alternative would be to save a version of your data before scaling in a different adata layer. For example, before scaling, you can just store a copy of your data by e.g., calling `adata.layers['normalized_unscaled] = adata.X`. You can export this data matrix by calling `adata.layers['normalized_unscaled'].to_csv(FILENAME)`. Hope this helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1650#issuecomment-779132748:130,avoid,avoid,130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1650#issuecomment-779132748,1,['avoid'],['avoid']
Safety,"Hi Alex, ; The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`; , I get the following error. The igraph I am using is V 0.1.11.; Many thanks; Hashem; `DeprecationWarning Traceback (most recent call last); <ipython-input-20-fb44185f2d28> in <module>(); 1 ; ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True); 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy); 78 directed = False; 79 if not directed: logg.m(' using the undirected graph', v=4); ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed); 81 if flavor == 'vtraag':; 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed); 41 def get_igraph_from_adjacency(adjacency, directed=None):; 42 """"""Get igraph graph from adjacency matrix.""""""; ---> 43 import igraph as ig; 44 sources, targets = adjacency.nonzero(); 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(); 6 __license__ = ""MIT""; 7 ; ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, ""; 9 ""this visualization library has been renamed to ""; 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324587457:1427,avoid,avoid,1427,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324587457,2,['avoid'],['avoid']
Safety,"Hi David, . thanks for your reply and your interest!. > I had a superficial look at the functionalities and setup and it does look very nice. Well, I learned a lot from `scanpy` here ;) . > tcellmatch's primary purpose is specificity prediction, this could be easily added ontop of this,. Scirpy currently supports the construction of clonotype similarity networks based on Levenshtein distance and BLOSUM62 pairwise sequence alignments. With these networks, we, indeed, had in mind, that clonotypes forming a connected subgraph should recognize the same antigen. Supporting `tcellmatchs`'s learned embedding distances would be a great addition. Dou you think this could be implemented as a subclass of the `_DistanceCalculator` [here](https://github.com/icbi-lab/scirpy/blob/master/scirpy/_preprocessing/_tcr_dist.py#L20)? Feel free to open an issue in `scirpy` for that! . I'd also be curious how the BLOSUM embedding relates to our alignment distance. (How) does the embedding handle gaps?. > Integration with epitope data bases: I have data loaders for IEDB and VDJdb downloads, can you be a bit more specific how you would integrate that with exploratorive single-cell studies? I can only imagine searching for similar TCRs?. Exactly! I think it would be helpful if we could find a way to automatically annotate clonotypes with known epitopes (e.g. to identify clonotypes that are specific to common viral antigens which could represent ""bystander T-cells"" in cancer). I believe using our alignment-based approach or `tcellmatch` could improve over the existing database-queries that rely on Levenshtein distance. We can continue a more in-depth discussion in https://github.com/icbi-lab/scirpy/issues/54. > An integration with dextramer counts to ""stain"" TCR specificity? . Interesting! Do you have an example where this was used with single cells? . > Could you add a brief summary of how you use anndata to store the TCR data in the docs? That would be very helpful to design extension or cust",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1163#issuecomment-613394910:234,predict,prediction,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163#issuecomment-613394910,1,['predict'],['prediction']
Safety,"Hi Jiping!. I know that sometimes DPT detects groups with no cells in it; you can try setting the obscure option `allow_kendall_tau_shift` to `False`; sometimes this helps. But the problem goes deeper [see at the very end [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) and [there](https://github.com/theislab/scanpy_usage/blob/master/170430_krumsiek11/krumsiek11.ipynb) how branching groups are sometimes not meaningfully chosen). We're almost done with a method that combines the merits of DPT with conventional clustering that resolves this problem. No, it doesn't mean that there is no branching signature in your data; but it is certainly not a strong one; in many ""easy"" cases, DPT works perfectly. You could also try to make the branching more proncounced by changing the preprocessing. Hope that helps,; Alex. Btw: We started to set up a documentation at https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/33#issuecomment-324471700:38,detect,detects,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33#issuecomment-324471700,1,['detect'],['detects']
Safety,"Hi Michael. For my own data, ; I compared `scanpy` `umap` with the original `umap`; The original `umap` output is:; ```; import umap; import umap.plot; mapper = umap.UMAP().fit(adata.X); umap.plot.points(mapper, labels=adata.obs['batch']); ```; ![image](https://user-images.githubusercontent.com/33963919/209409453-578ce08c-3eed-4b42-a0c9-e3165d5859cc.png). ```; mapper2 = umap.UMAP().fit(adata.obsm['X_pca']); umap.plot.points(mapper2, labels=adata.obs['batch']); ```; ![image](https://user-images.githubusercontent.com/33963919/209409492-9559fc2e-817e-4003-b8e2-560a5687b241.png). The `scanpy` output is:; ```; sc.pp.filter_cells(adata, min_counts = 100); adata = adata[adata.obs['mt_frac'] < 0.2]; sc.pp.filter_cells(adata, min_genes = 1); sc.pp.filter_genes(adata, min_cells=1). import doubletdetection; clf = doubletdetection.BoostClassifier(; n_iters=10, ; use_phenograph=False, ; standard_scaling=True; ); doublets = clf.fit(adata.X).predict(p_thresh=1e-16, voter_thresh=0.5); doublet_score = clf.doublet_score(); adata.obs[""doublet""] = doublets; adata = adata[adata.obs[""doublet""] == 0.0] # filter out doublets . sc.pp.normalize_total(adata, target_sum=1e6); sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, ; flavor='cell_ranger'); sc.pp.scale(adata, max_value=10); sc.pp.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=15); sc.tl.umap(adata, min_dist=0.5, spread = 1.0); sc.pl.umap(adata, color='batch', use_raw=False, save='batch_umap.pdf'). ```. ![image](https://user-images.githubusercontent.com/33963919/209409864-0c0c0207-c3af-40f3-8af4-c3448f9ca0f1.png). If I do not run pca, then run `sc.tl.umap` I will get:. ![image](https://user-images.githubusercontent.com/33963919/209410266-efca8967-c8d0-4253-b273-3a048ae27653.png). 1. What should I do to get more compact clusters?; 2. Why the output so different between `scanpy.tl.umap` and the orignal `umap`?; 3. Should I use PCA for umap or not?; 4. Should I us",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364366326:941,predict,predict,941,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364366326,1,['predict'],['predict']
Safety,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:1237,avoid,avoid,1237,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617,1,['avoid'],['avoid']
Safety,"Hi all,. thanks for the nice discussion!. Phenograph is cited not for the specific implementation but for suggesting to use community detection for clustering in single-cell data. This is what the docs state ""The Louvain algorithm has been proposed for single-cell analysis by [Levine15]."". My opinion on clustering algorithms: use something that respects the topology of the data (points belonging to one clusters should be connected). Any graph clustering algorithm respects that, even spectral clustering. So, I'm not a big fan of trying 5 clustering algorithms to produce sensible results. Either a given representation of the data clusters clearly or it doesn't. If it doesn't, Louvain clustering just gives you one possible, representative partitioning of the data. But there are many others that are equally meaningful. Similar for other graph clustering algorithms. Now, running Louvain clustering on a fully connected graph is prohibitive computationally (memory and CPU time wise).; > Intuitively, I'd think having a more complete graph with weighted edges is more representative of the data than an arbitrary k neighbors. Even if you do use a hard cutoff on number of neighbors, I don't see how discounting all distance information would give a more accurate result. I would suspect using a weighted graph could perform better at identifying small subpopulations (where nearest neighbors from other cell types could be common), but that's just conjecture. That's just speculation to me. I never saw convincing benchmarks. No one claims that ""discounting all distance information gives a more accurate result"". It's just that it's computationally cheaper. I acknowledge that a ""non-fixed-degree knn graph"" varying say, between 5 and 100, would be computationally tractable and would carry information about the sampling density of the data in the given representation. This information is only indirectly available in the fixed-degree knn graph (more loops etc. in high-density regions). I n",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-416725777:134,detect,detection,134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/240#issuecomment-416725777,1,['detect'],['detection']
Safety,"Hi there!. I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done; > Solving environment: failed with initial frozen solve. Retrying with flexible solve.; > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; > Collecting package metadata (repodata.json): done; > Solving environment: failed with initial frozen solve. Retrying with flexible solve.; > Solving environment: - ; > Found conflicts! Looking for incompatible packages.; > This can take several minutes. Press CTRL-C to abort.; > failed ; > ; > UnsatisfiableError: The following specifications were found to be incompatible with each other:; > ; > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:; > ; > - feature:/linux-64::__glibc==2.31=0; > - feature:|@/linux-64::__glibc==2.31=0; > ; > Your installed version is: 2.31",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1298#issuecomment-1008789859:923,abort,abort,923,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298#issuecomment-1008789859,1,['abort'],['abort']
Safety,"Hi! That function is for reading the files output by [cellranger’s mex option](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/output/matrices). Your files have been renamed by someone in a way we can’t predict, and you should just adapt the little code needed to read them yourself:. https://github.com/theislab/scanpy/blob/e6e08e51d63c78581bb9c86fe6e302b80baef623/scanpy/readwrite.py#L324-L341. Took me 3 minutes:. ```py; samples = []; for sample in range(1, 10):; s = read(; path / f'{sample}.matrix.mtx',; cache=cache,; cache_compression=cache_compression,; ).T; genes = pd.read_csv(path / f'{sample}.genes.tsv', header=None, sep='\t'); s.var_names = genes[0]; s.var['gene_symbols'] = genes[1].values; s.obs_names = pd.read_csv(path / f'{sample}.barcodes.tsv', header=None)[0]; samples.append(s); adata = AnnData.concatenate(samples); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/882#issuecomment-545433846:241,predict,predict,241,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/882#issuecomment-545433846,1,['predict'],['predict']
Safety,"Hi, . Thanks so much for the explanations! Doing it now and it works. . Best,; Jing. > On Jun 5, 2019, at 10:39, MalteDLuecken <notifications@github.com> wrote:; > ; > Hi @hejing3283,; > ; > The wrong shape is probably because you have subsetted adata.X to highly variable genes, or did some additional filtering after storing data in adata.raw. For a while now scanpy avoids filtering highly variable genes, but instead annotates them in adata.var['highly_variable'] which is then used in sc.pp.pca(). I would suggest you use subset=False next time you use sc.pp.highly_variable() to avoid different dimensions in adata.X and adata.raw.X.; > ; > You can easily proceed by just making a new anndata object from adata.raw.X, adata.raw.var and adata.raw.obs and storing this to be loaded into cellxgene. Just do the following:; > ; > adata_raw.write(my_file); > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/262#issuecomment-499126695:369,avoid,avoids,369,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/262#issuecomment-499126695,2,['avoid'],"['avoid', 'avoids']"
Safety,"Hi, ; Thank you very much for such a detailed explanation. It really helps. I've two more questions: . 1). Can we do this gene subsetting with Logistic regression (where no multiple testing correction is involved)? . 2). Since you nicely pointed out sc.tl_rank_genes_groups doesn't tell about the contribution of genes in the clustering- are there tools that can be integrated with ScanPy to do this job? (for example, diffxpy or MAST). I'm really interested in the differential gene testing to predict the markers (from a gene subset used for clustering). . I shall be grateful if you can suggest a method.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/748#issuecomment-515114575:495,predict,predict,495,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748#issuecomment-515114575,1,['predict'],['predict']
Safety,"Hi, @ivirshup . Thanks for the review. I'll address the comments soon.; No, this currently doesn't deal with correctness, tie correction and the other things in the issues, just general structure. But i'll definitely turn to them after this. About the reference thing. Yes, you are right, i can use this approach of course. However, i didn't want to store the same value multiple times, it doesn't make much difference in performance, but still gives uneasy feelings, i would say. upd: oh, i see that `numpy.broadcast_to` creates a view, so it should avoid the problem of storing the same value multiple times.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1156#issuecomment-614656197:551,avoid,avoid,551,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1156#issuecomment-614656197,1,['avoid'],['avoid']
Safety,"Hi, this is fixed on master. You can temporarily downgrade scipy to avoid this error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1313#issuecomment-656318884:68,avoid,avoid,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313#issuecomment-656318884,1,['avoid'],['avoid']
Safety,"Hi,. great options with the styles... just one comment/question... to me, it seems that the automatic detection of the background for the color of the dot is not working:. dot_edge_color : str, Tuple[float, …], None (default: 'black'); Dot edge color. When color_on='dot' the default is no edge. When color_on='square', edge color is white for darker colors and black for lighter background square colors. in my case, all dots are black independent of the background color:. ![image](https://user-images.githubusercontent.com/59560120/100715263-3c61b480-33b7-11eb-8874-2a85364acea4.png). Stefan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1371#issuecomment-736307368:102,detect,detection,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1371#issuecomment-736307368,1,['detect'],['detection']
Safety,"Hm. Are all functions that you edit in 1.9.6? Then we could set the milestone to 1.9.7. If you’re not sure, it’s safer to set it to 1.10.0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2742#issuecomment-1814325890:113,safe,safer,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2742#issuecomment-1814325890,1,['safe'],['safer']
Safety,"How did you installed scanpy?. Try:. conda install --file requirements.txt. this may install all the right versions of the packages that you need. On Thu, Oct 4, 2018 at 2:26 AM ar-baya <notifications@github.com> wrote:. > Hi, I am reproducing this tutorial; > https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb; >; > the line sc.pp.neighbors(adata) produces the following error:; >; > Inconsistency detected by ld.so: dl-version.c: 205:; > _dl_check_map_versions: Assertion `needed != NULL' failed!; >; > Ubuntu 18.04; > Python 3.6.6; >; > scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4; > scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; >; > Can you help me? Thank You; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/280>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1Sgm2UxCRL2y2-EGlah7YmtIrmmeks5uhVXGgaJpZM4XHKo6>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-426896350:448,detect,detected,448,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-426896350,1,['detect'],['detected']
Safety,How to avoid the 'HTTP Error 403: Forbidden' exactly? I reinstalled scanpy and still have this issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1334#issuecomment-705184936:7,avoid,avoid,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334#issuecomment-705184936,1,['avoid'],['avoid']
Safety,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console; $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no; Numba function called from a non-threadsafe context. Try installing `tbb`.; Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads.; - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):; File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper; File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _; File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper; File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get; File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task; File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task; File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks; File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", li",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3335#issuecomment-2457625478:19,detect,detected,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335#issuecomment-2457625478,2,['detect'],['detected']
Safety,"I agree with malte that there's so much more ML out there that just adding a function cause it can be quickly implemented can be risky.; however if we're not the ones to try then who else should. so what if we test the leiden_multiplex in comparison to seurat's WNN on the tutorial data, and decide then? I would be surprised if we didn't find a set of params for leiden_multiplex that allows to replicate the seurat clustering results. also comes to mind similarity network fusion (implemented for citeseq in the citefuse package). prob a project of its own sake tbh. ; happy to help with this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1818#issuecomment-857832028:129,risk,risky,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818#issuecomment-857832028,1,['risk'],['risky']
Safety,"I also like the `normalization` and `normalization_axis` suggestion, I use z-score also all the time but it's very painful right now. I also agree with Stephen's concerns, minmax is not perfect and can be misleading, and it's safer to be more flexible, provide more normalization options and let the user be responsible for how the plots look like IMO. As I mentioned in #1913, we have to write in the legend that it's min-max scaled expression. We can even remove the color legend labels (0.0, 0.5, 1.0) if minmax is applied.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1757#issuecomment-873078527:226,safe,safer,226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757#issuecomment-873078527,1,['safe'],['safer']
Safety,"I am also unable to install scanpy on mac OS. I tried using python 3.8.x . 3.7.x and 3.6.x. ```; (base) $ conda activate SCA. (SCA) $ conda --version; conda 4.8.2. (SCA) $ python --version; Python 3.6.10 :: Anaconda, Inc. (SCA) $ conda install -c bioconda scanpy; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \ ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1142#issuecomment-609514112:526,abort,abort,526,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142#issuecomment-609514112,1,['abort'],['abort']
Safety,"I am checking, it seems that the format for `rp_forest `changed significantly. No, failing forest conversion won't cause any problems because it was deliberately coded to avoid problems. The code is in neighbors, and neighbors is critical functuionality and can work without `rp_forest`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1601#issuecomment-763734853:171,avoid,avoid,171,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1601#issuecomment-763734853,1,['avoid'],['avoid']
Safety,"I am getting this same error, namely when I run `sc.pl.umap(adata, color='pid')` I see `UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored` and then `adata.uns['pid_colors']` all gets set to gray, and my whole UMAP plot looks gray instead of being color by 'pid.'. I am using scanpy 1.9.1 and matplotlib 3.6.3. Can someone advise me what I need to upgrade to avoid this error, or how I can work around it with my current package versions? I see that #2212 upped the required matplotlib to 3.4, but since I'm at 3.6.3 I thought I should be okay. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2208#issuecomment-1477955919:398,avoid,avoid,398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1477955919,1,['avoid'],['avoid']
Safety,"I came across this when I wanted to plot the predicted doublets from scrublet. `predicted_doublet` is stored as boolean. So, I would like to have this plotted like a categorical. I realized that plotting actually works when using `pl.scatter`:. ```python; import scanpy as sc; adata = sc.datasets.blobs(); sc.pp.pca(adata). adata.obs['boolean'] = True. sc.pl.scatter(adata, color='boolean', basis='pca'); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1646#issuecomment-778079358:45,predict,predicted,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1646#issuecomment-778079358,1,['predict'],['predicted']
Safety,"I can recover the previous behavior, i.e., different runs of the notebook give identical UMAP and leiden clusters, by downgrading to scanpy version 1.9.2 (and also pandas to version 1.5.3). I do this in conda and in this environment other relevant installed package versions are numpy 1.23.5, scipy 1.10.1 and scikit-learn 1.2.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555:6,recover,recover,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555,1,['recover'],['recover']
Safety,"I don't feel well adding a large dataset to the repository. Adding something subsampled and rather low-dimensional would be fine. Alternatively, you could also just add a dataset that is automatically downloaded: as [here](https://github.com/theislab/scanpy/blob/7646c947f632ea7b09fea783e32a017136cfed24/scanpy/datasets/__init__.py#L104-L106) or [here](https://github.com/theislab/scanpy/blob/7646c947f632ea7b09fea783e32a017136cfed24/scanpy/datasets/__init__.py#L142-L144). As both travis and readthedocs will cache this, it should be a viable solution that avoids bloating the repository with several MB of data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/207#issuecomment-405508287:558,avoid,avoids,558,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/207#issuecomment-405508287,1,['avoid'],['avoids']
Safety,"I don't know how ""easy"" the density estimation problem here is, but I would avoid scott's whenever I can (e.g. https://aakinshin.net/posts/kde-bw/).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1643#issuecomment-786378869:76,avoid,avoid,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1643#issuecomment-786378869,1,['avoid'],['avoid']
Safety,"I don't want to do too much with string mangling. Now that mention trying to detect it though, I don't think I'd have anything against passing a `Path` to override this behaviour. We could also add a different argument with this behaviour – like `path` – then deprecate `save`, or at least passing a string to `save`. On the other hand, I wonder how much we gain by controlling the saving of a figure. Maybe the only way to save a figure should be from the user calling matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1508#issuecomment-735050380:77,detect,detect,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508#issuecomment-735050380,1,['detect'],['detect']
Safety,"I first understood the warning that the default will be switched so that we have to be explicit (`flavor=""leidenalg""`) if the old default works for us. But the warning persists, maybe suggesting that we should switch to `flavor=""igraph""`. When switching to `igraph`, we get a deprecation warning `resolution_parameter keyword argument is deprecated, use resolution=... instead` which has been deprecated in igraph some years ago ([7848bcb](https://github.com/igraph/python-igraph/commit/7848bcbc8b81fa248362f56d5593d366836deb1f#diff-cba05fe79beed98bcc3a46ca51cc58e92142b971ce1caebb8c23895101fde8dcR467-R469)). Scanpy has not yet updated the parameter since the [initial](https://github.com/scverse/scanpy/commit/9fa4c0f9abf4b050f6e347565dff24f9b317cb32) leiden implementation, or the deprecation was not noticed. Can users ignore the warning, or should users put an upper cap on the igraph version to be safe?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2865#issuecomment-2112993599:904,safe,safe,904,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2865#issuecomment-2112993599,1,['safe'],['safe']
Safety,"I follow your argumentation on ""good clusters"". However, I also like the concept that putting k=35 means you make it harder to detect clusters of size < 35, as you 'over-connect' those clusters in a way. The weighted case is less interpretable in that way. However, here it clearly outperforms the unweighted case. I am still a little on the fence (due to interpretability), but I'd be okay with weighting I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-488610378:127,detect,detect,127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-488610378,1,['detect'],['detect']
Safety,"I have the same problem. I am using macOS catalina 10.15.2. $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: | ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package natsort conflicts for:; scanpy -> natsort; Package louvain conflicts for:; scanpy -> louvain; Package patsy conflicts for:; scanpy -> patsy; Package importlib_metadata conflicts for:; scanpy -> importlib_metadata[version='>=0.7']; Package zlib conflicts for:; python=3.7 -> zlib[version='>=1.2.11,<1.3.0a0']; Package libcxx conflicts for:; python=3.7 -> libcxx[version='>=4.0.1']; Package scikit-learn conflicts for:; scanpy -> scikit-learn[version='>=0.21.2']; Package matplotlib conflicts for:; scanpy -> matplotlib[version='3.0.*|>=2.2']; Package statsmodels conflicts for:; scanpy -> statsmodels[version='>=0.10.0rc2']; Package numba conflicts for:; scanpy -> numba[version='>=0.41.0']; Package readline conflicts for:; python=3.7 -> readline[version='>=7.0,<8.0a0']; Package importlib-metadata conflicts for:; scanpy -> importlib-metadata; Package setuptools conflicts for:; scanpy -> setuptools; Package tqdm conflicts for:; scanpy -> tqdm; Package libffi conflicts for:; python=3.7 -> libffi[version='>=3.2.1,<4.0a0']; Package scipy conflicts for:; scanpy -> scipy[version='<1.3|>=1.3']; Package anndata conflicts for:; scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']; Package pip conflicts for:; python=3.7 -> pip; Package seaborn conflicts for:; scanpy -> ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-580295241:612,abort,abort,612,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-580295241,1,['abort'],['abort']
Safety,"I haven't performed an in-depth benchmark comparison. But results from a single run of modularity detection on an example (a [Facebook graph](http://konect.uni-koblenz.de/networks/facebook-wosn-links)) is sufficiently revealing I think:; ```; Running Leiden 0.7.0.post1+71.g14ba1e4.dirty; Running igraph 0.8.0; Read graph (n=63731,m=817035), starting community detection.; leidenalg: t=8.048258741036989, m=0.6175825273363675; igraph community_leiden: t=1.159165252931416, m=0.6298702028415605; ```; This is only a relatively small graph, and the difference is likely to be even bigger for larger graphs. Perhaps the `igraph` Leiden algorithm can indeed be the default, with `leidenalg` being an optional choice or something?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-586969791:98,detect,detection,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053#issuecomment-586969791,2,['detect'],['detection']
Safety,"I just checked again... and it's not exactly the same... if you select `n_top_genes` then, you will get the top genes shared by the most batches. If you select thresholds for mean and dispersion, you will use these thresholds against the mean dispersion and mean mean across all batches. And those can be lower than the thresholds if HVGs are not shared between many batches. So to be safe, you can go with selecting `n_top_genes`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/935#issuecomment-559568443:385,safe,safe,385,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/935#issuecomment-559568443,1,['safe'],['safe']
Safety,"I like @flying-sheep's very last solution. To enable this for truly large-scale data and AnnData's that are backed on disk we need a much more efficient transposition implementation, which will probably need to return a view. That's problematic as it will break backwards compat (`.T` returns a copy these days). But it's good as it will allow adding fields to `.var`. @LuckyMD: At the time, when you mentioned that you wanted to plot over genes in scatter, I was fine with with having the scatter wrapper and assuming no ambiguity in obs and var keys. Now, I'd advocate for @flying-sheep's solution. Of course, we'll maintain the feature in `pl.scatter` when refactoring its code (a lot of it became redundant after fidel introduced the completely rewritten scatter plots).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/375#issuecomment-441473742:701,redund,redundant,701,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375#issuecomment-441473742,1,['redund'],['redundant']
Safety,I like the idea.; You could probably avoid the context manager but it's ok I think.-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/50#issuecomment-346761583:37,avoid,avoid,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50#issuecomment-346761583,1,['avoid'],['avoid']
Safety,"I see. . The output for `adata` is:; ```; AnnData object with n_obs × n_vars = 106774 × 33538; obs: 'Cell', 'sampleID', 'sample_name', 'UMI_count', 'detectedGenesPerCell', 'percent_mito', 'data_set', 'IsPassed', 'batch', 'status', 'n_genes', 'n_counts', 'leiden', 'leiden_scVI'; var: 'name'; uns: 'log1p'; ```. I can see that my attempts to `leiden`ing have ended up here in `adata.obs` ...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1410#issuecomment-689498294:149,detect,detectedGenesPerCell,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1410#issuecomment-689498294,1,['detect'],['detectedGenesPerCell']
Safety,I started work to move `scrublet` into scanpy (since the last commit was 3 years ago and it’s safe to assume it’s not maintained anymore). https://github.com/scverse/scanpy/pull/2703,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-1780971567:94,safe,safe,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-1780971567,1,['safe'],['safe']
Safety,"I sympathize with the problem which I tend to solve by plotting individual scatterplots, each one with its specific vmax. But I will be happy to have a better output. I like the idea of using quantile but I would avoid an increasing list of parameters. Thus @ivirshup suggestion to use `functools.partial` seems better. I like the flexibility it provides and I think we should implement it, but I don't know if this would be difficult to document and explain to the user that just would like to compute the quantile. An idea would be to allow some encoding for vmax as for example `vmax='q99'` which would be interpreted as np.quantile. My suggestion is to . - add vectorized vmax and vmin; - each entry of vmax or vmin would be interpreted depending on the data type. Besides a number, if it is a string then it is interpreted as for example quantile if it starts with 'q' or as a function if the type is `partial`. The following options would then be valid:. ```PYTHON; sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[4., 3.]); sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=['q80', 'q90']). from functools import partial; sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[partial(np.mean), partial(np.median)]). # combination; sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2"", ""gene3""], ; vmax=[4., 'q85', partial(np.percentile, q=90]); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/775#issuecomment-521550044:213,avoid,avoid,213,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775#issuecomment-521550044,1,['avoid'],['avoid']
Safety,"I think I've got an example for you, which should be pretty easy for you to play around with in datashader. The example is doublet detection. I'm following the basic outline of the methods which simulate doublets, then project those onto the real data to find which barcode (/cell) the simulated doublets sit next to. Those barcodes are presumed to be doublets. So we'd expect that areas of mostly singlets in the real data would have a lower relative (to the real data) density of points in the simulated. I'm still exploring what the best way to summarize that difference in density is through. Here's an example with some pbmcs from 10x:. <details>; <summary> Setup (loading, simulating, and projecting) </summary>. ```python; import scanpy as sc; import numpy as np; import pandas as pd; from scipy import sparse; from umap import UMAP. from itertools import repeat, chain. # Define functions. def preprocess(adata):; adata.var[""mito""] = adata.var[""gene_symbols""].str.startswith(""MT-""); sc.pp.calculate_qc_metrics(adata, qc_vars=[""mito""], inplace=True); sc.pp.normalize_per_cell(adata, counts_per_cell_after=10000); sc.pp.log1p(adata); return adata. def pca_update(tgt, src, inplace=True):; # TODO: Make sure we know the settings from src; if not inplace:; tgt = tgt.copy(); if sparse.issparse(tgt.X):; X = tgt.X.toarray(); else:; X = tgt.X.copy(); X -= np.asarray(tgt.X.mean(axis=0)); tgt_pca = np.dot(X, src.varm[""PCs""]); tgt.obsm[""X_pca""] = tgt_pca; return tgt. def simulate_doublets(adata, frac=.5):; """"""Simulate doublets from count data.; ; Params; ------; adata; The anndata object to sample from. Must have count data.; frac; Fraction of total cells to simulate.; """"""; m, n = adata.X.shape; n_doublets = int(np.round(m * frac)); pos_idx = np.array(list(chain.from_iterable(map(lambda x: repeat(x, 2), range(n_doublets))))); combos = np.random.randint(0, m, (n_doublets * 2)); pos = sparse.csr_matrix(; (np.ones_like(combos, dtype=adata.X.dtype), (pos_idx, combos)), ; shape=(n_doublets, m);",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/575#issuecomment-481184384:131,detect,detection,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-481184384,1,['detect'],['detection']
Safety,"I think Seaborn would typically use `.dropna()` to just omit values that are `NA`, no? That would be safer than assigning a colour.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1355#issuecomment-668430991:101,safe,safer,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355#issuecomment-668430991,1,['safe'],['safer']
Safety,"I think a new section would good here, maybe ""Doublet detection""?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1483#issuecomment-723850755:54,detect,detection,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483#issuecomment-723850755,1,['detect'],['detection']
Safety,"I think saying discrete was redundant with independent, in that each component should correspond to a signal in the data. > And so you're saying 1, 5, and 7 being given as solutions to ICA is non-optimal. I'm not sure how to interpret it. I know that if I run an analysis on the same dataset with 20 components I get more independent ones. My impression is the ""failure modes"" of linear decompositions like this are not well characterized. > It feels strange to generally say that ICA is better as higher dimensions. I probably wouldn't say this. I think there are different use cases, and ICA components may be easier to interpret than PCA components. I was also just at a talk by Elana Fertig (who knows much more about this kind of thing than I do) where one of the take aways was ""different decompositions for different use-cases"". I think I'll still use PCA for clustering and generating UMAPs. > while at lower dimensions there is redundant information compared to PCA. I'd note that there is no order to ICA components.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/941#issuecomment-560219393:28,redund,redundant,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941#issuecomment-560219393,2,['redund'],['redundant']
Safety,"I think that if you store a categorical value in a pandas dataframe (like; .obs) the storage of this redundant information is quite efficient. In a; quick search I found this:; https://towardsdatascience.com/make-working-with-large-dataframes-easier-at-least-for-your-memory-6f52b5f4b5c4. On Wed, May 22, 2019 at 3:59 PM MalteDLuecken <notifications@github.com>; wrote:. > To clarify a bit... I think it would be good to enable something like:; > sc.pl.umap(adata, color=(uns_dict_key, obs_column)); >; > Where the sc.pl.umap() function then does:; >; > if isinstance(color, tuple):; > color_vector = [adata.uns[color[1]+""_linked_data""][color[0]]][adata.obs[color[1]]]; > sc.pl.plot_scatter(adata, color=color_vector, ...); >; > It might need to be a pandas dataframe rather than a dictionary with the; > above setup.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/658?email_source=notifications&email_token=ABF37VINUTKOPIDJADJOMMTPWVGT3A5CNFSM4HOUNBK2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODV7ENLQ#issuecomment-494814894>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VL26UDSJCBGW67HNNLPWVGT3ANCNFSM4HOUNBKQ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/658#issuecomment-495177880:101,redund,redundant,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/658#issuecomment-495177880,1,['redund'],['redundant']
Safety,"I think that the `all_data.uns['leiden_colors']` list is only updated if the new number of clusters is bigger than the previous cluster number as the goal is to avoid missing colors. . In you use the the `palette` argument, the color list will always be updated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/420#issuecomment-453067108:161,avoid,avoid,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420#issuecomment-453067108,1,['avoid'],['avoid']
Safety,"I think the alternative version is safer, as it’ll work even if they change the format of that autogenerated label. Unless they document it somewhere that it’s that, I assume it’s an implementation detauil.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2682#issuecomment-1761498585:35,safe,safer,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682#issuecomment-1761498585,1,['safe'],['safer']
Safety,"I think the spring export function currently fails because it only checks whether each column in `adata.obs` is a pandas categorical variable (`not is_categorical(adata.obs[obs_name])`) and, if not, assumes it's a continuous variable and then tries to join a str with an integer. . If you look at your file `data.obs` contains a number of categorical variables that are currently numpy objects; ```pytb; data.obs.dtypes; ClusterID int32; ClusterName object; RNA_snn_res_0_5 object; nCount_RNA float32; nFeature_RNA int32; orig_ident object; percent_mt float32; seurat_clusters object; louvain category; dtype: object; ```. As a quick fix, I think you can do something like this:; ```python; adata = data.copy(); obj_cols = adata.obs.columns[adata.obs.dtypes == np.object]; adata.obs[obj_cols] = adata.obs[obj_cols].astype('category') ; sce.exporting.spring_project(adata, './pbmc3k', 'draw_graph', subplot_name='force1', overwrite=True); ```; Not sure what's the best way to fix it for the future: check for other dtypes or uses f-strings to avoid the str concatenation errors?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/889#issuecomment-590643431:1042,avoid,avoid,1042,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/889#issuecomment-590643431,1,['avoid'],['avoid']
Safety,"I took about 20 minutes on it, but couldn't figure out how to add more annotations. I've got interactive versions with hover over, but log scale is bugged in those libraries... I believe the bins that are the darkest shade in the minimum cluster size for the unweighted graph actually correspond to a minimum cluster size of 1 cell. Megakaryocytes were detected as a distinct cluster every time that k was 10 in the unweighted case, but no other times. I think that when we make a call on ""this is a kind of cell"" from unsupervised clustering, those results should be robust. That is, if there's strong signal in the data and your clustering algorithm can pick up that signal, good clusters shouldn't change much if you vary the parameters a little. If you can pick any parameters from a wide range and get results that are pretty consistent, that seems like good data and a good method to me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-488191694:353,detect,detected,353,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-488191694,1,['detect'],['detected']
Safety,"I was just about to ask about the chunking along genes - you read my mind @falexwolf. I think it might be possible to do a multi-dimensional adaptation of the scipy.stats code you linked to, and still do the math with sparse matrices, similar to how we implemented the t-tests. This way we could possibly avoid the chunking (it might help with readability of the code). Would this be worth pursuing?. I'll give this a quick try, but I am a little limited in bandwidth. I'll let you know soon if it would be best to get some help from @Koncopd (if they have time!)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-427489214:305,avoid,avoid,305,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-427489214,1,['avoid'],['avoid']
Safety,"I will check. Meanwhile, I realized that some errors were introduced in the latest plotting functions, thus I started working in a list of tests to avoid those problems in the future.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/204#issuecomment-405303780:148,avoid,avoid,148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/204#issuecomment-405303780,1,['avoid'],['avoid']
Safety,"I will get that fixed soon. I don't know why the palette assignment is not; working as I am using the previous code for that. On Wed, Sep 26, 2018 at 10:44 PM Alex Wolf <notifications@github.com> wrote:. > All of this is really nice! 😄; >; > Regarding your comment on plotly: returning a fig instead of an ax would; > follow a different convention as in seaborn; which I'd try to mimic as; > closely as possible. But for the scatter plots, which are the only ones; > that would profit a lot from interactive exploration, one could think about; > breaking this convention.; >; > Regarding bugs for now: One bug I could quickly fix myself, two further; > bugs that I've stumbled across in the past few hours and couldn't fix right; > away: If I'm calling; >; > sc.pl.umap(adata, color=['celltypes', 'prediction'], palette=[sc.pl.palettes.vega_20, sc.pl.palettes.default_64]); >; > the color maps are ignored. And if I'm calling; >; > sc.pl.umap(adata, color=['louvain', 'Gata1'], legend_loc='on data'; > ); >; > the first plot has a different shape than the second.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/244#issuecomment-424863360>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1Z-BMqIuY9jlSyFcI4TEHi4ULBoZks5ue-cdgaJpZM4WNj5_>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-424986420:798,predict,prediction,798,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-424986420,1,['predict'],['prediction']
Safety,I would tend to agree with @gokceneraslan on this. Concatenating obsm seems like a risky thing to do.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1021#issuecomment-582636654:83,risk,risky,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021#issuecomment-582636654,1,['risk'],['risky']
Safety,"I'd be happy with whatever, but it needs to go somewhere!. How about ""Demultiplexing/ Doublet detection"", so it can go with scrublet (#1476) in the next release, and potentially get split out later if more demultiplexing methods are added?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1483#issuecomment-726001024:94,detect,detection,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483#issuecomment-726001024,1,['detect'],['detection']
Safety,"I'll take a look at this to make sure I've not messed up in writing this wrapper (I'm actually doing some more testing myself for production use right now). . But you should know that what we've done here is mirror some of the internals of scrublet, but using Scanpy functions. Scrublet should be supplied with raw counts, but does do its own normalisations internally before doing the actual doublet prediction, which is what we're doing here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1957#issuecomment-889126422:401,predict,prediction,401,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957#issuecomment-889126422,1,['predict'],['prediction']
Safety,"I'm having some trouble debugging whatever is going wrong with the notebook tests here. I get the same results if I run `pytest` on my machine, but don't get a failure if I run the code manually. Additionally, I don't get an error (the `abort`) if I *only* run the notebook tests (`pytest -k ""test_pbmc3k""`). Pretty sure the error is happening on the call to louvain in the notebook tests – an `assert False` fails the tests, one after gives current result – but I can't reproduce the abort interactively. Any idea what's going on/ how I can get a more helpful error message here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248#issuecomment-419695136:237,abort,abort,237,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248#issuecomment-419695136,2,['abort'],['abort']
Safety,"I'm not sure I can help a lot, but I strongly suspect this is weird interactions between matplotlib and rstudio. . First thing I would suggest is increasing your figure size a bit. Either through scanpy's [`set_figure_params(figsize=...)`](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.set_figure_params.html#scanpy._settings.ScanpyConfig.set_figure_params) or via matplotlib directly with `rcParams` (here's a [temporary link](https://icb-scanpy--2901.com.readthedocs.build/en/2901/tutorials/plotting/advanced.html#plot-size) to a demonstration of this, but it will be on the main docs shortly). I've seen things like this before when `matplotlib` was using one of its less supported [backends](https://matplotlib.org/stable/users/explain/figure/backends.html#). You can check which backend is being used with:. ```python; import matplotlib as mpl; mpl.get_backend(); ```. I think `agg` is the safest choice for backend, you can choose it with:. ```; mpl.use(""agg""); ```. @lazappi any thoughts/ experience on your end?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2955#issuecomment-2018738629:929,safe,safest,929,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2955#issuecomment-2018738629,1,['safe'],['safest']
Safety,"I'm not sure spike-ins are so helpful if they only account for part of the technical effects that have to be normalized out. In the end you will have the same problem with the remaining effects you are not capturing on which you don't have a good experimental handle. Unless you can spike into a tissue directly somehow? I quite like the idea of spike-in cells though for batch effects, but those have similar limitations as well. . In general, I'm yet to see a spike-in approach that if modeled and used to normalize your data would compare well against a good normalization method. That doesn't mean it doesn't exist... but it seems that since droplet-based techniques took off spike-ins are being avoided as they just increase sequencing costs and the larger droplet-based datasets allow us to use model-based normalization techniques.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1364#issuecomment-679164180:700,avoid,avoided,700,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364#issuecomment-679164180,1,['avoid'],['avoided']
Safety,"I'm wondering if we can come to some agreement on a slight modification to this proposal. > > How does this impact users vs. developers?; >; > user none, as the analysis package would ofc have the IO as dep. developer would be impacted by a leaner dep tree. This seems good. > > Who manages the sub-packages?; >; > the IO subpackage? everyone 😅. 😅 indeed. > For instance, for modality-specific formats we'd have to rely on specific external libraries which would then have to be lazily imported (as pointed out before). Would this create the premise of exponential growing of modality-specific lazy import libraries? probably yes. Is this best practice? I don't know. I feel like complicated dependency management was what we were trying to avoid here. Also it's nice when you install a package call a function and it works, less nice to have to start mucking around with dependencies. --------------. ## An alternative: project specific IO. `squidpy_io`, `muon_io`. Packages which read in package specific formats with a minimal set of dependencies. We can keep `muon.read_10x_atac`, so nothing changes for users. We skip out on complicated ownership and complicated dependencies. This should be very low overhead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1387#issuecomment-1059537650:741,avoid,avoid,741,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1387#issuecomment-1059537650,1,['avoid'],['avoid']
Safety,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:; ```; import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'); adata.raw=adata.copy() #data to save; sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should; adata=adata.raw.to_adata(); sc.pp.log1p(adata); ##>>> no warning; ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:; ```; import scanpy as sc. ## same as above; adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'); adata.raw=adata.copy() #data to save; sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw; ### saving object, reading, testing again; ### Doesnt work; adata.write_h5ad(tmp+'scanpy_test.h5ad'); adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'); adata=adata.raw.to_adata(); sc.pp.log1p(adata); ###>>>WARNING: adata.X seems to be already log-transformed.; ```. I'm on scanpy 1.9.1 if it matters",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1333#issuecomment-1209486748:464,avoid,avoid,464,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333#issuecomment-1209486748,1,['avoid'],['avoid']
Safety,"I've got one minor comment left (one last redundant print statement), but otherwise I'm good.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-480637170:42,redund,redundant,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-480637170,1,['redund'],['redundant']
Safety,"In supplementary figure 9 of our paper, I did a light comparison of tools using the demuxlet data as ground truth: https://www.cell.com/cms/10.1016/j.cels.2020.05.010/attachment/040c239d-1e70-42a4-8974-9fbd75c65551/mmc1.pdf; Which I think is a fine first stab at getting at this comparison, but it could be better. Hashsolo performance was comparable with other methods but is able to recover cell types with lower CMO counts. . I think that sounds great. That's an issue we had as well, but I noticed it occurring for NK cells in kidney; ![Screen Shot 2021-01-13 at 9 18 30 AM](https://user-images.githubusercontent.com/6864886/104486266-5d095680-5580-11eb-971e-c882063f2a45.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-759597008:385,recover,recover,385,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-759597008,1,['recover'],['recover']
Safety,"In the ""requirement already satisfied"" it looks like ""scikit-misc"" is installed in a different location and not within the `site-packages` folder of the anaconda env listed on the line below for `numpy`. From within the `py38` env you could try to reinstall it with `pip install --user scikit-misc --force` and also delete the other one or remove it from your `$PYTHONPATH`? Installing things in the jupyter notebook might be using a different version of pip than the one in the environment (depending on how your kernels are set up) so I think it's sometimes safer to do these things from the command line.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-989974912:560,safe,safer,560,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-989974912,1,['safe'],['safer']
Safety,"In the dotplots, when the color_on == 'square', fixed dot edge color might lead to some trouble in visibility when the square color and dot edge color happen to be similar. There is a nice feature of seaborn heatmap to avoid exactly that, where the annotation text color is determined conditionally on the square color, see [here](https://seaborn.pydata.org/generated/seaborn.heatmap.html) for the documentation and [here](https://github.com/mwaskom/seaborn/blob/master/seaborn/matrix.py#L261) for the relevant code:. ![image](https://user-images.githubusercontent.com/1140359/84678062-8f28dc00-aefd-11ea-84f5-d1b4f1496814.png). It can be too much work, feel free to ignore but just wanted to highlight.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1210#issuecomment-644215713:219,avoid,avoid,219,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210#issuecomment-644215713,1,['avoid'],['avoid']
Safety,"Initial justification was that it makes a number of computations much faster and doesn't seem to cause problems. If you have examples of problems being caused, that would be great to know. I get this is sort of like `stringsAsFactors`, but I think a lot the problems with that is avoided by categorical having a more sane api than factors. For instance, you can just interact with categorical arrays of strings as though it was an array of strings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1747#issuecomment-800776373:280,avoid,avoided,280,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1747#issuecomment-800776373,1,['avoid'],['avoided']
Safety,"Is there a way to blacklist igraph and umap packages in setup.py to avoid; further confusion?. On Tue, Sep 24, 2019, 12:13 PM Yiwei Niu <notifications@github.com> wrote:. > @LuckyMD <https://github.com/LuckyMD> Thank you very much! It woks now.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/807?email_source=notifications&email_token=AAIWNB5YP7V74NDJXNEZJ6DQLHR4HA5CNFSM4ISZVL6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD7N3DPA#issuecomment-534491580>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AAIWNBZCSV4KT2AYXIS43BTQLHR4HANCNFSM4ISZVL6A>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/807#issuecomment-534505271:68,avoid,avoid,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807#issuecomment-534505271,1,['avoid'],['avoid']
Safety,"Is there any interest in regular solo doublet detection to scanpy external? I have used scrublet for some time, but solo claims to outperform it and I am not sure that scrublet is actively maintained",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1432#issuecomment-788389902:46,detect,detection,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432#issuecomment-788389902,1,['detect'],['detection']
Safety,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1538#issuecomment-743241392:471,avoid,avoid,471,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538#issuecomment-743241392,1,['avoid'],['avoid']
Safety,It looks like this may have stalled a bit. Is anyone currently working on making some form of doublet detection available from scanpy?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-481057117:102,detect,detection,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-481057117,1,['detect'],['detection']
Safety,"It should work. Since what fails is some clean up of annData categories,; you may want to check that `tiss.obs['cell_ontology_class']` is set as; categorical. Also check `'B cell' in; tiss.obs['cell_ontology_class'].cat.categories` to avoid a typo. Finally, I think that I had a similar issue which I resolved by removing a adata.uns elements that end in `_colors`. In your case I think you would need to do `del tiss.uns['cell_ontology_class_colors]`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/226#issuecomment-438963856:235,avoid,avoid,235,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/226#issuecomment-438963856,1,['avoid'],['avoid']
Safety,"Its an issue with numba. See here https://github.com/jmschrei/apricot/blob/98693788ca315ceceeb2eb0f4ce8526f40e0049b/README.md. *Update* Quoting from the REAME above. > If you get an error that looks like; > ; > Inconsistency detected by ld.so: dl-version.c: 224: _dl_check_map_versions: Assertion `needed != NULL' failed!; > ; > or a segmentation fault when importing apricot for the first time then you should try reinstalling numba through conda using; > ; > conda install numba.; > ; > or; > ; > pip install numba==0.39.0; > ; > The issue appears to be with the most recent verson of numba, v0.40.0. Downgrading to numba v0.39.0 should solve the issue. ; > . That means numba should be frozen to v0.39.0 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-427364460:225,detect,detected,225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-427364460,1,['detect'],['detected']
Safety,"Just came across this - is this still relevant?; Scanpy as is does not feature a neat solution integrating with interactive interfaces which would allow to manually tag/select individual points from a plot - for such tasks, [holoviz](https://holoviz.org/) tools might be considered.; As sidenote, a heads-up about considering 2D representations with caution e.g. [here](https://www.sciencedirect.com/science/article/pii/S2405471223002090?via%3Dihub) - considering metrics instead of visual low-dimensional representations to detect or remove outliers might be considered as a viable alternative here in many cases :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1992#issuecomment-1798949475:525,detect,detect,525,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1992#issuecomment-1798949475,1,['detect'],['detect']
Safety,"Mm I think I you're supposed to use a context (`with ... :`) to avoid changing things globally. Anyway my current workaround of doing `from scanpy.api import preprocessing as scpp` is not too cumbersome, so should be okay until 1.0 hits :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/108#issuecomment-375036470:64,avoid,avoid,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/108#issuecomment-375036470,1,['avoid'],['avoid']
Safety,"My code also has the same bug problem, may I ask, how to solve it?. `adata.raw = adata # keep full dimension safe; sc.pp.highly_variable_genes(; adata,; flavor=""seurat_v3"",#; n_top_genes=2000,; layer=""counts"",; batch_key=""orig.ident"",; subset=True,; span=1; ); `. Error output. `ValueError Traceback (most recent call last); Cell In[13], line 3; 1 #高变基因选取; 2 adata.raw = adata # keep full dimension safe; ----> 3 sc.pp.highly_variable_genes(; 4 adata,; 5 flavor=""seurat_v3"",#; 6 n_top_genes=2000,; 7 layer=""counts"",; 8 batch_key=""orig.ident"",; 9 subset=True,; 10 span=1; 11 ); 13 filename = 'melanoma_sw_high_var.h5ad'; 14 adata.write(filename). File ~/miniconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:441, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 439 sig = signature(_highly_variable_genes_seurat_v3); 440 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default); --> 441 return _highly_variable_genes_seurat_v3(; 442 adata,; 443 layer=layer,; 444 n_top_genes=n_top_genes,; 445 batch_key=batch_key,; 446 check_values=check_values,; 447 span=span,; 448 subset=subset,; 449 inplace=inplace,; 450 ); 452 if batch_key is None:; 453 df = _highly_variable_genes_single_batch(; 454 adata,; 455 layer=layer,; (...); 462 flavor=flavor,; 463 ). File ~/miniconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:87, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 85 x = np.log10(mean[not_const]); 86 model = loess(x, y, span=span, degree=2); ---> 87 model.fit(); 88 estimat_var[not_const] = model.outputs.fitted_values; 89 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:927, in _loess.loess.fit(). ValueError: b'Extrapolation not allowed with blending'`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2853#issuecomment-2019348837:109,safe,safe,109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2853#issuecomment-2019348837,2,['safe'],['safe']
Safety,"My hunch would be that both runs just find different local minima: one being further away from the global minimum than the other. As Louvain is just a heuristic solution to an NP-hard problem, this is not surprising. Just use a random number generator for the random seed and run it 100 times for each resolution, it would probably show the expected picture again for the average number of clusters detected. . I'm not sure if the tie breaking rule is deterministic or not. But you'd get different ties in both cases anyway I assume.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/279#issuecomment-426834933:399,detect,detected,399,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/279#issuecomment-426834933,1,['detect'],['detected']
Safety,"Nevertheless, some of the plotting functions are returning ax by default. I; will need to change that. On Mon, Jan 14, 2019 at 12:44 AM Andreas <notifications@github.com> wrote:. > @falexwolf <https://github.com/falexwolf> Thanks for the explanation.; > I see now that it's an issue of how the package should be used, i.e. the; > philosophy behind your api, and I seem to have tried to use it in a; > different perhaps more low level way. I will look in to using more low; > level functions/modules if I need it and work with your original intended; > workflow which i think make sense. I have missed the whole settings; > functionality which seems really useful to avoid some of the issues I have; > had.; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/419#issuecomment-453876840>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1YINwJpe8e_BJavkUulUdzp6IMItks5vC8TLgaJpZM4Z4pAD>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/419#issuecomment-453980627:666,avoid,avoid,666,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419#issuecomment-453980627,1,['avoid'],['avoid']
Safety,"No, there is no such way in DPT. We had good experience with manually choosing it. In our opinion, no one really came up with a sound and reliable statistical way of detecting the number of branching points, independent of the underlying algorithm. The best attempts to solve the problem though might be found within [Monocle 2](http://biorxiv.org/content/early/2017/02/21/110668) or [K-Branches](http://biorxiv.org/content/early/2016/12/15/094532).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/11#issuecomment-285361766:166,detect,detecting,166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/11#issuecomment-285361766,1,['detect'],['detecting']
Safety,"No, you're right. It's fine to continue having this. Initially, I wanted to get rid of it at some point... but also numpy has this redundancy between many array attributes which pop up as numpy level functions everywhere. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/423#issuecomment-453688357:131,redund,redundancy,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/423#issuecomment-453688357,1,['redund'],['redundancy']
Safety,"OK, thank you for the explanation! Let us think about it. There are a couple of sanity checks running in the background, which are easy to call at the beginning of the plotting functions, for instance, if they don't cost performance. E.g., there was a standard `adata._sanitize()` call in all the plotting functions. Is it still there, @fidelram? If not, no problem... We should have a solution that essentially doesn't require writing new code. Also, what are your thoughts, @flying-sheep?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/422#issuecomment-456034330:80,sanity check,sanity checks,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422#issuecomment-456034330,1,['sanity check'],['sanity checks']
Safety,"Oh, and one more thing. It would be great if the test for the batched version could check it was equivalent to computing the doublets separately. E.g. <details>; <summary> modified `test_scrublet_batched` </summary>. ```python; def test_scrublet_batched():; """"""; Test that Scrublet run works with batched data. Check that scrublet runs and detects some doublets.; """"""; pytest.importorskip(""scrublet""). adata = sc.datasets.pbmc3k(); adata.obs['batch'] = 1350 * ['a'] + 1350 * ['b']; split = [adata[adata.obs[""batch""] == x].copy() for x in (""a"", ""b"")]. sce.pp.scrublet(adata, use_approx_neighbors=False, batch_key='batch'). # replace assertions by conditions; assert ""predicted_doublet"" in adata.obs.columns; assert ""doublet_score"" in adata.obs.columns. assert adata.obs[""predicted_doublet""].any(), ""Expect some doublets to be identified""; assert (; 'batches' in adata.uns['scrublet'].keys(); ), ""Expect .uns to contain batch info"". # Check that results are independent; for s in split:; sce.pp.scrublet(s, use_approx_neighbors=False); merged = sc.concat(split). pd.testing.assert_frame_equal(adata.obs[merged.obs.columns], merged.obs); ```. </details>. --------. For the docs, I think you might need to merge from master to get them to build. Sphinx has been acting up a lot recently.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1965#issuecomment-1075220656:340,detect,detects,340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965#issuecomment-1075220656,1,['detect'],['detects']
Safety,"One of the aims of scanpy is to be self-contained and easy-to-install for users and also to be easy to maintain by the developers. Heavy dependencies like louvain and python-igraph are already troublesome, expecting users to have rpy2 + proper R installation + Bioconductor + scran would risk smooth user experience and easy maintainability. I was wondering whether it makes sense to have a community-maintained `scanpy-contrib` or `scanpy-extensions` repository (and python package) similar to https://github.com/keras-team/keras-contrib ? There are also couple of things I have in mind like `sc.pl.netsne(adata, anotheradata)` for embedding unseen samples via parametric tSNE, or `sc.tl.simlr` and `sc.pl.simlr` for [SIMLR](https://github.com/BatzoglouLabSU/SIMLR) via RPy2 bridge... . These are popular requests for Scanpy and people expect the same convenient API and an easy integration with AnnData objects. However, they will probably not be included in the mainstream Scanpy because of the reasons I mentioned above. What do you think @falexwolf and @flying-sheep ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-381980880:288,risk,risk,288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-381980880,1,['risk'],['risk']
Safety,Perhaps the name should be more specific to avoid confusion with [harmony package for batch correction](https://github.com/immunogenomics/harmony)? That code has a C++ backend for which a Python front end might be written.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/503#issuecomment-467181263:44,avoid,avoid,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503#issuecomment-467181263,1,['avoid'],['avoid']
Safety,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]; > ; > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all.; > ; > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3095#issuecomment-2154540758:327,detect,detection,327,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095#issuecomment-2154540758,2,['detect'],"['detected', 'detection']"
Safety,"Project specific IO is interesting but IMO makes it even more complicated in some ways. The current biggest problem we face is that no one knows where to go to read certain formats.... scanpy? muon? squidpy? Scanpy has read visium but squidpy is the spatial package? I can analyze atac data in scanpy but need to use muon to read the file?. Seurat has basically every reader one would need. This kind of fractured environment is not going to help us gain ground. > Who manages the sub-packages?. Scverse (also it's one package not many). We are talking about 5-15 readers that have been touched a handful of times in 4-5 years. I don't think this is a complicated package to maintain. Agree that one person needs to take the lead on releases (probably very infrequent). > I feel like complicated dependency management was what we were trying to avoid here. Where is the complicated dependency management? We have a core set of readers (h5, pandas, scipy) and more complex readers (lazy import). We can have a conda env file too for everything if we want. Even anndata lazy imports loom for example. It's a small price to pay for ecosystem synchronization and enhanced user experience. > Packages which read in package specific formats with a minimal set of dependencies. It's also unclear to me what package specific stuff muon has in particular. The way I see it there's one `read_10x_h5(return_anndata=True, return_mudata=False, gex_only=None)` I don't think muon is loading any extra information or putting it in any package specific places?. > How does this impact users vs. developers?. Developers: (1) export `scio` readers into their packages, can contribute improvements to readers, (2), access to many more practical readers for their packages (scvi-tools has no 10x h5 reader because we don't feel the need to depend on scanpy for one function). Users: (1) no impact if they continue using the packages they like (e.g., scanpy reader will be completely unchanged). (2) Can go ahead and just ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1387#issuecomment-1059551352:845,avoid,avoid,845,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1387#issuecomment-1059551352,1,['avoid'],['avoid']
Safety,"Regarding your other bug: `scanpy.plotting` used to have the attribute and `scanpy.api.plotting` would simply import the module. To make the [overview of the API](https://scanpy.readthedocs.io/en/latest/api.html) work, I had to introduce a [dummy module](https://github.com/theislab/scanpy/blob/master/scanpy/api/pl.py). In order to avoid duplication, I removed all exports from `scanpy.plotting.__init__`. I readded it to fix the bug on the development branch, but I need to think of a better solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/34#issuecomment-324378094:333,avoid,avoid,333,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34#issuecomment-324378094,1,['avoid'],['avoid']
Safety,Same here. I would like to run Scanpy on the latest Python version. Does anyone have an ETA or a way to force installation (at our own risk of course)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1327933295:135,risk,risk,135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1327933295,1,['risk'],['risk']
Safety,Same issue here. Using `pip` +pyhton3.7 and not conda to install from pypi. Is there a way to resolve it without installing using conda?. Logs:. ```; [dilawars@chamcham scanpy_exp]$ python planaria.py ; /home1/dilawars/.local/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses; import imp; scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1 ; ... storing 'clusters' as categorical; computing tSNE; using data matrix X directly; using the 'MulticoreTSNE' package by Ulyanov (2017); finished (0:02:53.98); saving figure to file ./figures/tsne_full.pdf; computing neighbors; using data matrix X directly; Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed!; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-427357518:866,detect,detected,866,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-427357518,1,['detect'],['detected']
Safety,"Should be possible to turn the y ticks legends on. But I just tested it and didn't work. I will try to fix it. The syntax is:; ```PYTHON; sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True).style(yticklabels=True,row_palette='muted').show(); ```. `style` needs to be used to tune the graphical parameters to avoid overcrowding the parameters list. But I am open to have a discussion on what the users think is best. Documentation is here: https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.DotPlot.style.html#scanpy.pl.DotPlot.style",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1321#issuecomment-666170536:332,avoid,avoid,332,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321#issuecomment-666170536,1,['avoid'],['avoid']
Safety,"So for our workflows, where we pass the clustering step directly to the marker detection, it would be good to be able to get markers for non-singlet groups when we specify 'all', even where there are singlet groups. We can add a workaround to our CLI layer and in fact I'm doing that anyway since we need a fix quickly https://github.com/ebi-gene-expression-group/scanpy-scripts/pull/88, but there I'm having to transiently edit .obs to remove the singlet clusters which seems messier (and we're not sure if that will have unintended consequences).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490#issuecomment-725930096:79,detect,detection,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490#issuecomment-725930096,1,['detect'],['detection']
Safety,"Some notes/observations from my side towards choosing the proper resolution: . - the Leiden algorithm depends on a random seed. With a different random seed, you might get a different number of clusters with the same resolution; - a sensible resolution depends on the input data: when clustering on data processed with `sc.tl.diffmap` a much lower resolution will give the same number of clusters than without. ; - I performed a hyperparameter search for the resolution (steps of 0.005) on a large dataset of CD8+ T cells. I observed that at certain resolution ranges, the number of clusters is stable. In my case, I was looking for subtypes of CD8+ T cells and hypothesized that at ~0.1 and ~0.3 I would find something biologically meaningful. Would be interesting to re-do that on the PBMC dataset. I would expect a plateau at a resolution that recovers the well-known cell types CD8+, CD4+, etc. . ![2019-06-03_09:53:34_911x604](https://user-images.githubusercontent.com/7051479/58785259-7ea10e80-85e5-11e9-8e0b-789e2e74754a.png); **Fig:** hyperparameter search for resolution in steps of 0.005. The graph shows the resolution vs. detected number of Leiden-clusters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-498153336:847,recover,recovers,847,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498153336,2,"['detect', 'recover']","['detected', 'recovers']"
Safety,"Sorry about the delay, I've been working on some writing about this stuff (though from a different perspective). I'm not sure `k` is ""meant"" to have any particular effect, since these methods weren't designed for KNN graphs. I'd also argue if the parameters are analogous, there's an advantage of simplicity to just choosing one of them. I've got some plots for the effect of resolution and number of neighbors on the size of clusters which are found. This is for the 10x example dataset with 10k pbmcs using the v3 chemistry. What I've done is build the networks at 5 different values of k, four times each (different random seeds). For each of those networks, I ran clustering at 50 different resolutions (`np.geomspace(0.05, 20, 50)`). Here are the maximum cluster sizes found for each combination of k and resolution for the unweighted and weighted graph (color bar is logscale, from 1 to 6000, but I couldn't get useful ticks to work):. ![image](https://user-images.githubusercontent.com/8238804/56872793-2c158500-6a70-11e9-91fd-ee7aac91b811.png); ![image](https://user-images.githubusercontent.com/8238804/56872794-2d46b200-6a70-11e9-9607-67147d7493f9.png). Overall, pretty similar. Now, the minimum cluster sizes (color scales are different, but you'll see why):. ![image](https://user-images.githubusercontent.com/8238804/56872836-a34b1900-6a70-11e9-9a60-7b2a51b53da2.png); ![image](https://user-images.githubusercontent.com/8238804/56872837-a6460980-6a70-11e9-8722-be6576f605e7.png). This looks to me like using the weighted graph allows identifying small clusters even at low resolutions. The cluster of 25 cells looks like megakaryocytes, and are being detected at pretty much every clustering (996 out of 1000) using the weighted graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-487432411:1664,detect,detected,1664,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-487432411,1,['detect'],['detected']
Safety,"Sorry for the late reply, I was afk for a week. . This is really cool... What I had in mind is most similar to the 2D histogram you show. For the second part you fit the umap to one dataset and use that transformation to project the doublets in, right? What I do is join the two datasets and make a combined umap embedding. I can see how your approach makes more sense for doublet detection, but in a general case it's probably not as valid (i.e., when one dataset isn't ""fake"" data). . I will use this to play around a bit with the package when time permits though... thanks a lot for the extensive code!. And we discussed similar things for the normalization of the data for the subtraction above...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/575#issuecomment-483712379:381,detect,detection,381,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-483712379,1,['detect'],['detection']
Safety,"Sorry, I didn't use multiplex community detection. I focused more on preprocessing and briefly on graph construction. I stored the CITE-Seq data in `adata.obsm` and the gene-protein mapping as a column in `adata.var` - if this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1818#issuecomment-828326883:40,detect,detection,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818#issuecomment-828326883,1,['detect'],['detection']
Safety,"Sounds good, we are currently hosting the whole scanpy-scripts as a bioconda package, but we could look into having it as pip installable as well. Does this means that scanpy administrators are happy to have the scanpy-scripts code poured here to make them pip installable, or that you want to contribute the pip packaging to the repo where we currently have scanpy-scripts? We have travis testing for our scripts layer, that would make maintenance easier on your side, as it would detect any changes on scanpy that break the scripts layers (taking you to only break API if extremely necessary - in turn making your tool more stable for external users).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/281#issuecomment-437031478:482,detect,detect,482,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281#issuecomment-437031478,1,['detect'],['detect']
Safety,"Sounds like a great idea! Currently, `pip install scanpy` avoids installing the C++ dependencies, which give some users trouble: `louvain` and `python-igraph`. I think that these should still remain optional dependencies: users should be able to do some basic analysis with plotting without having to install C++ dependencies. They can then continue to install optional dependencies, if they like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/59#issuecomment-354904560:58,avoid,avoids,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59#issuecomment-354904560,1,['avoid'],['avoids']
Safety,"Sure! @michalk8 , could you please add the below sentence:. ""CellRank is a toolkit to uncover cellular dynamics based on scRNA-seq data with RNA velocity annotation by detecting initial and terminal populations, inferring fate potentials and uncovering gene expression trends towards specific terminal populations. """,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1304#issuecomment-658032666:168,detect,detecting,168,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1304#issuecomment-658032666,1,['detect'],['detecting']
Safety,"Sure, and I'm not against supporting special cases! Could you please explain the setup?. Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory?. Some systems are strange. We should be nice and support those systems while still doing the correct thing by default. We shouldn't do the wrong thing by default to accommodate strange cases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476680606:195,detect,detect,195,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476680606,1,['detect'],['detect']
Safety,"Thank you for all your thoughts! That's very interesting and helpful!. > although it would also make sense for log1p to be a class method, given that it only needs to exist for AnnData objects. Yes! I also think so. But then the question is which function makes into AnnData and which doesn't. Right now we only put functionality that is related to bookkeeping of the data into AnnData. Everything else remains out of it, even it's something as simple as `log1p`... but that's just a safeguard towards cluttering the object... I agree that it would be more convenient to have some of this in `AnnData`. I guess numpy went a similar way: not all of numpy's functions are available as `np.ndarray`'s class methods. > In such a library it's easy to switch between an in-place or copying workflow, to inspect intermediate output if desired. Interesting! I never thought of this. > This behavior is what numpy.log1p itself is doing here, for that matter–with an out argument it still returns the array. Yes! I think that's a good solution. The `out` argument is very verbose and allows setting a second name for the reference to the modified object, which is returned in addition. I thought about making `inplace` the default for Scanpy's function or not for a long time and finally decided for the unorthodox choice of making it the default - having in mind that AnnData's will become pretty large and at some point backed on disk (which hugely limits the possibilities of how you can write pipelines). Then the `out` rationale doesn't work anymore, as, by default, there simply is no second reference around... Again, thank you for your perspective. And, I'll merge this as soon as having figured out the `chunked` issue. Should be tomorrow or so...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/191#issuecomment-403313076:484,safe,safeguard,484,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191#issuecomment-403313076,1,['safe'],['safeguard']
Safety,"Thank you for developing the method, I'm looking forward to being able to use it. One thing that the deviances did was perform a chi-square test on the obtained values, with degrees of freedom based on the number of cells. I was fond of that as it translated into a data-driven cutoff for feature selection rather than requiring some number of top genes. Is there a chance of something similar showing up here? Apologies if this is not the place to ask this, but I'd be even more likely to switch over if I could have the option to avoid the parameterisation that tends to come with HVG identification.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-872954063:532,avoid,avoid,532,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-872954063,1,['avoid'],['avoid']
Safety,"Thank you for this. I took a dive into the data set to figure out what filtering step is causing this problem, and it seems to be the conditions set for `sc.pp.highly_variable_genes`. To carry on with `LYZ`, it does not show up because its `mean_counts` is too high, above the *maximum* of 3 set in the analysis:. ```; >>> adata.raw.to_adata().var.loc['LYZ']; gene_ids ENSG00000090382; n_cells 1631; mt False; n_cells_by_counts 1631; mean_counts 10.2467; pct_dropout_by_counts 39.5926; total_counts 27666; highly_variable False; means 3.68714; dispersions 5.12101; dispersions_norm 3.65908; Name: LYZ, dtype: object; ```. Is this filtering on `max_mean` as described in the tutorial a reasonable thing to do? That said, even if I were to not filter the matrix to restrict it to genes detected as highly variable, by default `scanpy.tl.pca` would not even use `LYZ` as a potential contributor to a principal component, because it is not highly variable. Again, the equivalent Seurat tutorial does have LYZ in it, but I assume that is because they are now using a different way to classify which genes are variable. Would you say my interpretation is correct? If so, would a better implementation of `sc.pp.highly_variable_genes` solve the problem? Would be happy to contribute if that is something that would be needed and there's no good Python-based alternative around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1338#issuecomment-665648276:784,detect,detected,784,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338#issuecomment-665648276,1,['detect'],['detected']
Safety,"Thank you so much for fielding so many of the issues, @LuckyMD! :smile:. Can we elaborate a bit further on this one, though? For simple two-group comparisons, `rank_genes_groups` with `method='wilcoxon'` (Wilcoxon-Rank-Sum/Mann-Whitney U test) should be a legit choice, shouldn't it? It's used in many of this year's Nature, Cell and Science single-cell papers, it's the default test of Seurat (https://satijalab.org/seurat/de_vignette.html) and several people reported that it performs well in [Sonison & Robinson, Nat Meth (2018)](https://doi.org/10.1038/nmeth.4612). So, I don't think one needs to encourage people to immediately go to the great and powerful MAST, limma and DESeq2. Can you point me to a reference that shows that a Wilcoxon-Rank-Sum test is less _sensitive_? How is this even a useful statement if you don't talk about the false positives you buy in? We should look at an AUC that scans different p-values, right? A bit more than a year ago, @tcallies and I had a full paper draft discussing AUCs for marker gene detection formulated as a classification problem, but we never finished it. In the general setting, it's not at all straightforward to make the evaluation a well-defined problem and other people will for sure have done a better job. Unfortunately, I have never fully caught up with the literature, I fear...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447598981:1034,detect,detection,1034,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447598981,1,['detect'],['detection']
Safety,"Thanks for all the great bug reports! This is really useful!. The way that we assign colors to each obs is basically:. ```; values = adata.obs[categorical_column]; color_vector = np.asarray(adata.uns[color_key])[values.codes]; ```. When there is a missing value in a categorical array, the code for that value is `-1` (which is why the color of the last category is being assigned). [Pandas does not allow you to make `NA` a category](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html#missing-data), so `NA` will always have a code of `-1`. I think handling of this could take some consideration. I'm not sure we can safely set a default color for missing categorical values since that color (or one that looks very similar) could already be used. That said, it could be much more complex to allow passing a color for missing values. It might be worth looking into how other plotting libraries deal with missing categorical values and color. . Right now we have a related concept with the `groups` argument. Any samples not in the passed groups will just be colored light gray. This could probably also handle missing values if we want to go with that. I've started an implementation of this in #1356.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1355#issuecomment-668396560:640,safe,safely,640,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355#issuecomment-668396560,1,['safe'],['safely']
Safety,"Thanks for looking at this... it is surprising that this bug was not detected earlier. . I looked at the code and looks fine but, I would like to add a test. @LisaSikkema can you check this? If this is too much trouble I can do it or I can help you because the plot test are difficult as they require similar setup as in the CI tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1511#issuecomment-739858710:69,detect,detected,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511#issuecomment-739858710,1,['detect'],['detected']
Safety,"Thanks for the explanation. But what do you mean by ""discrete"" here?. And so you're saying 1, 5, and 7 being given as solutions to ICA is non-optimal. I guess that's just local optima that are found. It feels strange to generally say that ICA is better as higher dimensions still separate out clusters, while at lower dimensions there is redundant information compared to PCA.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/941#issuecomment-560100063:338,redund,redundant,338,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941#issuecomment-560100063,1,['redund'],['redundant']
Safety,"Thanks for the feedback. I have now merged master into the fix branch and the CI tests are happy. To address the shrewd questions asked by @gokceneraslan:; 1) I pondered over this myself. As I mentioned (above), I based my approach on a pull request in umap's own codebase which also resorts to densification of the matrix. As far as I can see, `pairwise_special_metric` doesn't directly support a sparse matrix and I don't see an alternative approach that wouldn't involve duplicating some of its implementation and (probably) sacrificing some of the benefits (i.e. parallel processing). A deeper analysis by another brain might draw different conclusions.; 2) Another good question. Based on my ""git blame"" detective work, `pairwise_special_metric` was introduced in [a change on 20 Nov 2018](https://github.com/lmcinnes/umap/commit/edade6841bd9b3c80454bf7f4386177c9aa35ab5) which should have seen it incorporated into version [0.3.7](https://github.com/lmcinnes/umap/tree/0.3.7). Since then its signature has remained compatible (with the only change being the addition of the `kwds` argument). scanpy's `requirements.txt` already has `umap-learn` set to a minimum version of 0.3.10 so I believe we're good on that front.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1413#issuecomment-698903808:709,detect,detective,709,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1413#issuecomment-698903808,1,['detect'],['detective']
Safety,"Thanks for the response! The core `reduce` function of SCA is not scanpy-based, but I wrote a very simple wrapper called `reduce_scanpy` to make it easier for scanpy users while this pull request is being considered. It would be even easier for scanpy users to access this code natively in `sc.tl.external`, and it seems odd that the existence of the wrapper (which just runs `reduce` and adds the result to the input AnnData) should disqualify it. Although the current pull request implements `sc.tl.external.sca`as an additional wrapper to `reduce_scanpy`, I could easily write it as a wrapper to `reduce`, which would remove the redundancy of having separate scanpy interfaces in the base package and in sc.tl.external. I would then mark `reduce_scanpy` as deprecated in further releases of SCA, and direct the user instead to `sc.tl.external.sca`. Does this seem reasonable? Of course, I'd be happy to be part of `ecosystem` if that's still where you think it belongs!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1780#issuecomment-825877662:632,redund,redundancy,632,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780#issuecomment-825877662,1,['redund'],['redundancy']
Safety,"That error is not specific to scanpy. It would be good to know which; library is causing the problem such that it can be updated but most likely; is either numpy, scipy, matplotlib or sklearn. Maybe try to update those; packages and see if the error goes away or try to google the error to find; some solution. On Fri, Oct 5, 2018 at 2:59 PM Dilawar Singh <notifications@github.com>; wrote:. > Same issue here. Using pip +pyhton3.7 and not conda to install from pypi.; > Is there a way to resolve it without installing using conda?; >; > Logs:; >; > [dilawars@chamcham scanpy_exp]$ python planaria.py; > /home1/dilawars/.local/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses; > import imp; > scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1; > ... storing 'clusters' as categorical; > computing tSNE; > using data matrix X directly; > using the 'MulticoreTSNE' package by Ulyanov (2017); > finished (0:02:53.98); > saving figure to file ./figures/tsne_full.pdf; > computing neighbors; > using data matrix X directly; > Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed!; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/280#issuecomment-427357518>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1WzuXR5Mhpb3jNte9UkVDqzQjb1pks5uh1eZgaJpZM4XHKo6>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-427359171:1288,detect,detected,1288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-427359171,1,['detect'],['detected']
Safety,That’s super redundant now. Please extract all that text from `doc_scatter_bulk` into another variable and import and use that one instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/557#issuecomment-476508242:13,redund,redundant,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557#issuecomment-476508242,1,['redund'],['redundant']
Safety,"The bio conda builds look like their broken at the moment, and we haven't had the bandwidth to fix them yet (we are not the direct maintainers of the bio-conda builds). You can find up to date installation instructions which avoid this on the [latest docs](https://scanpy.readthedocs.io/en/latest/installation.html)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1190#issuecomment-623272806:225,avoid,avoid,225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190#issuecomment-623272806,1,['avoid'],['avoid']
Safety,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py; import scanpy as as; adata = sc.datasets.pbmc3k(); # sc.pp.normalize_total(adata, target_sum=10000); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000); adata.var[""highly_variable""].sum(); ```; ```; 10367; ```; Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)); Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R; library(dplyr); library(Seurat); library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)); ```; ```; 2292; ```; However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3157#issuecomment-2255759888:24,detect,detect,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157#issuecomment-2255759888,1,['detect'],['detect']
Safety,"The fact that `normalize_per_cell` filters cells caused me some trouble recently, especially because there is nothing in documentation that says this will happen and there the subset indices are not returned. My use case is a little different: I am running a K-fold cross validation and `normalize_per_cell` is a step in the process. Since this function filters out some cells, the array of predicted labels has fewer entries than I would expect for the fold. Ideally, this behavior could be switched off. For example, you could pass a `min_counts` argument to `normalize_per_cell`. I've made this change if this is an approach you would like to take: https://github.com/umangv/scanpy/tree/umangv-normalize",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/210#issuecomment-428983959:391,predict,predicted,391,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/210#issuecomment-428983959,1,['predict'],['predicted']
Safety,"The problem is that it does not install at all. ; When I run; ```; conda create -n test; conda activate test; conda install python=3.11; conda install -c conda-forge scanpy; ```; I get an error output for the last line, which is:; ```; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:336,abort,abort,336,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['abort'],['abort']
Safety,"There’s a few uses:. 1. Humans. Once you understand the syntax ([very easy](https://docs.python.org/3/library/typing.html), i just get `Generator` wrong all the time) it improves your understanding what a function really accepts and returns; 2. IDEs. They’ll get better when inferring the types of variables and will show you more actual problems in the code and less false positives; 3. Testing. Some projects use mypy to check if all code in your repo typechecks properly, which can be integrated into a test suite; 4. Runtime type checking. Has a performance hit (as said) but given proper type hints, it makes your code safer and the error messages better (“Function blah excepted a parameter foo of type Bar, but you passed a foo of type Baz”). i’m not planning to do 3 and 4 (yet, and probably never)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441256142:624,safe,safer,624,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441256142,1,['safe'],['safer']
Safety,"They'll both be affected by the [resolution limit](https://www.pnas.org/content/104/1/36), which might be what you're referring to. This is a well-described problem for Modularity with the configuration null model that it only optimally detects communities within a certain size range relative to the size of the network. For me heavy-tailed networks are PPIs.. KNNs are a lot more regular than that. I'm not sure what a weighted KNN graph would be... are you talking about the PhenoGraph approach?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-483313915:237,detect,detects,237,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-483313915,1,['detect'],['detects']
Safety,This is a consequence of our rec-arrays where we have to specify the length of strings. I think it would be safe to calculate the maximum length of a gene name instead of using a hard coded value.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/753#issuecomment-517530320:108,safe,safe,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/753#issuecomment-517530320,1,['safe'],['safe']
Safety,"This looks a lot more convincing... It's a bit hard to read the second last plot though... The black parts are also clusters around size 2-10, no? Or am I misreading the scale? Do you have a version with a few more annotations on the colour bar? How often are megakaryocytes detected as a separate cluster in the unweighted case? It looks like unweighted case is definitely worse for higher resolutions with >10 neighbours though. And coming back to the `k` discussion.. From my perspective, If you treat the clustering and knn graph generation as two separate steps, you may want `k` to have an effect. If you treat it as the same process, then I follow your argumentation that having a single parameter to affects the scale of the clustering suffices.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-487559376:275,detect,detected,275,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-487559376,1,['detect'],['detected']
Safety,Timeout and Scrublet failing in Python3.12?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3042#issuecomment-2195057576:0,Timeout,Timeout,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042#issuecomment-2195057576,1,['Timeout'],['Timeout']
Safety,"To answer the following question:. > 2. what you said: The original approach samples from the full list of genes in each bin, then restricts the sample to valid ones. Your approach samples from the valid genes in each bin.; >; > So if a bin e.g. contains mostly invalid genes, the original code adds only a few genes for that bin, while yours adds the maximum possible number.; >; > So the questions is: is the sampling bias introduced in the original code wanted? If not, you not only made the code more resilient, but also more objective. After going through the original [code from Seurat](https://github.com/satijalab/seurat/blob/c54e57d3423b3f711ccd463e14965cc8de86c31b/R/utilities.R#L280C3-L303), it seems to me that there's not equivalent to removing genes to be scored from the control gene set.; From what I can tell, if one of the genes to be scored happens to be chosen as the background, it will be included in the calculation.; But please correct me if that's not the case. So if the original implementation does not remove score genes from the control gene set, we would simply need to remove the following line: https://github.com/scverse/scanpy/blob/ec4457470618efd85da3c7b29f951cab01a49e3a/scanpy/tools/_score_genes.py#L169. (Note: if we want to keep the current behaviour, we should still remove the line above, since it would be redundant)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2875#issuecomment-2015316358:1348,redund,redundant,1348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2875#issuecomment-2015316358,1,['redund'],['redundant']
Safety,Unfortunately I am still facing this problem! ; Is there a way to avoid it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/952#issuecomment-611280656:66,avoid,avoid,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/952#issuecomment-611280656,1,['avoid'],['avoid']
Safety,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2992#issuecomment-2230448251:96,redund,redundancy,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992#issuecomment-2230448251,1,['redund'],['redundancy']
Safety,"We should make dynamic 3D plots ;-) . If I remember correctly, in the past we have the issue that the categorical colors were given by the adata.obs order and we change them such that they follow the order of the categories. Yet, I agree that a good mix of categorical colors is good sometimes. To address this issue I think that we can simply randomize the order if `sort_order=False` to avoid adding any new parameters. . Isaac's solution looks great for dealing with of lots of cells, something that I imagine will become more frequent. I think we should have a 'cookbook' where we can keep this and other information. I find this better than adding more and more functionality to the scatter plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1263#issuecomment-761095279:389,avoid,avoid,389,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263#issuecomment-761095279,1,['avoid'],['avoid']
Safety,"We use whatever cellranger outputs. For cellranger 3.0.0+ those files are gzip compressed. I would be fine with either of those changes. Could you make a PR?. More general note, I wouldn't want the function to look for either compressed or uncompressed. It should just be outputs from cellranger. This is to avoid scope creap – e.g. we aren't looking to support arbitrary ""cellranger-like delimited files"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2128#issuecomment-1027837933:308,avoid,avoid,308,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2128#issuecomment-1027837933,1,['avoid'],['avoid']
Safety,"We will always try to make `.X` a reference to the passed array. There may be cases where we need to make a copy, but we'll try to avoid that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1415#issuecomment-697187069:131,avoid,avoid,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1415#issuecomment-697187069,1,['avoid'],['avoid']
Safety,"What worries me is that the behaviour you describe might not so for `method='logreg'`. Let's have a look at the following example:. ```python; import scanpy.api as sc; adata = sc.datasets.blobs(); sc.pp.scale(adata). sc.pp.neighbors(adata); sc.tl.louvain(adata). for method in ['t-test', 'logreg']:; # first call, without groups; sc.tl.rank_genes_groups(adata, 'louvain', method=method); sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1). # first call, with groups ; sc.tl.rank_genes_groups(adata, 'louvain', method=method, groups=['0', '1', '2']); sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1); ```; As setting `groups` to `['0', '1', '2']` should not change the reference dataset, exactly the same marker genes should be detected for the first and the second call of `sc.tl.rank_genes_groups`. This is indeed true if I set the method to `t-test`. However, when setting method to `logreg`, I get other marker genes. Visually it appears to me that only the groups `['0', '1', '2']` are used a the reference set when using the method `logreg`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/278#issuecomment-427063030:733,detect,detected,733,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/278#issuecomment-427063030,1,['detect'],['detected']
Safety,"With https://github.com/scverse/spatialdata-io/pull/102 we could consider replacing `scanpy.read_visium` with. ```python; def read_visium(*args, **kwargs): ; import spatialdata_io; return spatialdata_io.visium(*args, **kwargs).to_legacy_anndata(); ```. and avoid maintaing the annoying spaceranger output parsing in multiple locations.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2424#issuecomment-1910300363:257,avoid,avoid,257,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2424#issuecomment-1910300363,1,['avoid'],['avoid']
Safety,"Yeah, so it appears that the function expects log-transformed data. Otherwise the use of `np.expm1()` doesn't make sense. If you don't log transform your data, you would get the wrong values. It might be worth either auto-detecting whether data was log-transformed or not, or adding it as a parameter.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/673#issuecomment-502551963:222,detect,detecting,222,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/673#issuecomment-502551963,1,['detect'],['detecting']
Safety,"Yes, I'll send an example in a bit, recovered variable genes seem wildly discrepant. I can get to this tomorrow! Thanks for your quick response",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2780#issuecomment-1865046956:36,recover,recovered,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1865046956,1,['recover'],['recovered']
Safety,"Yes. I'm interested in many of the things here. Thank you for pinging me. I'm happy to engage going forward in a variety of ways. Let's start with a few responses. > I tried looking at pydata sparse with Dask, but it ran a lot slower than regular scipy.sparse (which is what Scanpy uses). It would be great to get a slimmed down version of the operations that you're running with pydata/sparse and submit those to the issue tracker there. @hameerabbasi is usually pretty responsive, and I know that he appreciates learning about new use cases of pydata/sparse. > So I wrote a wrapper around scipy.sparse to implement NumPy's __array_function__ protocol. This allows sparse arrays to be chunks in a Dask array. This approach seemed promising, with basic operations able to take take advantage of multiple cores and run faster than regular scipy.sparse. Thoughts on adding this to scipy.sparse itself so that we can avoid the wrapper? cc @rgommers. > It turned out that by using Anndata arrays, Dask has to materialize intermediate data more than is necessary in order to populate the Anndata metadata. This is because the way Anndata works means that its metadata must be computed eagerly after each operation in the Zheng17 recipe, rather than lazily for the whole computation (which is the way Dask works). Another option would be to see if you can swap out Anndata for Xarray. This is a big change obviously, and probably pretty disruptive to the existing codebase, but it would align you with many other software projects and scientific communities that are currently thinking about these exact same problems. My guess is that in the long run it would save you time, assuming that Xarray DataArrays meet your needs semantically. > Many operations work, however cupyx.scipy.sparse has a number of missing features that mean it can’t be used for Zheng17 yet. It would require significant work in CuPy to get it working:. I could imagine that these might be in scope for NVidia folks to work on in a f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-557191880:914,avoid,avoid,914,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921#issuecomment-557191880,1,['avoid'],['avoid']
Safety,"Your way sounds sure better, many things into the scrublet algorithm are in; redundancy with components of scanpy. It will sure look great :); Just one thing: in the scrublet paper they suggest always to just run the; simulation of doublets and look at the expected vs estimated fraction of; doublets before removing doublets. If those two values do not match, they; say one should rerun scrublet and tune the expected fraction.; Does your script only run simulation of doublets and output the doublets; score, or does it also remove doublets at once? If you do the latter, then; one is not able to simulate doublets more than once to adjust the expected; doublet fraction.; Cheers. Den tor. 16. maj 2019 kl. 05.15 skrev Sam Wolock <notifications@github.com>:. > @cartal <https://github.com/cartal> @SamueleSoraggi; > <https://github.com/SamueleSoraggi>; > For some reason I decided to integrate Scrublet using Scanpy's functions; > where possible, rather than making a simple wrapper. The core functionality; > is up and running in this fork <https://github.com/swolock/scanpy>, and; > now I just need to add documentation, make some of the code more; > Scanpythonic(?), and add an example.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/173?email_source=notifications&email_token=ACC66UNQC744WOUTLRZ2CN3PVTGWTA5CNFSM4FE4LIF2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVQRA2I#issuecomment-492900457>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACC66UI4FF4LES7GRVKHZZDPVTGWTANCNFSM4FE4LIFQ>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-492936700:77,redund,redundancy,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-492936700,1,['redund'],['redundancy']
Safety,"[The documentation for `AnnData.write_csvs`](https://anndata.readthedocs.io/en/latest/anndata.AnnData.write_csvs.html) tells you. > It is not possible to recover the full AnnData from the output of this function. Use write() for this. Sorry for that! We thought that not having a function to read back those CSVs, we won’t lull people into the false security that the AnnData object can be safely restored from CSVs. But if you have nothing else but those files, you can of course try to use [`pandas.read_csv`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) to read the `.obs` and `.var` dataframes and do something like. ```py; adata = AnnData(; pd.read_csv('output/X.csv').asarray(),; pd.read_csv('output/obs.csv'),; pd.read_csv('output/var.csv'),; { # adata.uns; 'some_thing': pd.read_csv('output/some_thing.csv'),; },; pd.read_csv('output/obsm.csv'),; pd.read_csv('output/varm.csv'),; ); ```. You might have to fiddle with parameters to `pandas.read_csv`, like `index_col`, and obsm/varm might not be able to be specified as data frames.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/399#issuecomment-447793340:154,recover,recover,154,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/399#issuecomment-447793340,2,"['recover', 'safe']","['recover', 'safely']"
Safety,[here’s code](https://github.com/flying-sheep/smart-progress/blob/1091a0a9cc2d7a6304f992d13cb718d5150a64c6/smart_progress.py#L12-L21) to detect if we’re in a notebook or not. we could use that to decide if we want to use `tqdm_notebook` or `tqdm`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/16#issuecomment-298757002:137,detect,detect,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16#issuecomment-298757002,1,['detect'],['detect']
Safety,"_raw2, sigma):; <source elided>; vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32); for index, ve in zip(mnn2, vect):; ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)); /data/yosef2/users/adamgayoso/.pyenv/versions/3.7.3/envs/anndata_test/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File "".pyenv/versions/3.7.3/envs/anndata_test/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:; def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):; <source elided>; vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32); for index, ve in zip(mnn2, vect):; ^. state.func_ir.loc)); /data/yosef2/users/adamgayoso/.pyenv/versions/3.7.3/envs/anndata_test/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File "".pyenv/versions/3.7.3/envs/anndata_test/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:; def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):; <source elided>; vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32); for index, ve in zip(mnn2, vect):; ^. state.func_ir.loc)); ```. ```pytb; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-16-0bc362244a72> in <module>; ----> 1 sc.external.pp.mnn_correct(a, b). /data/yosef2/users/adamgayoso/.pyenv/versions/3.7.3/envs/anndata_test/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_catego",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/974#issuecomment-572849200:2157,detect,detected,2157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/974#issuecomment-572849200,1,['detect'],['detected']
Safety,"`adata.obsm['X_pca']` seems to have predicted better clustering. Thank you. I'm going to try that with the rest of my data and see what clustering it suggests. . As for `adata.uns['neighbors']['distances']`, shortly after my post I read that the `silhouette_score` function wasn't designed to handle spares matrices, so you're right with that. ; (source: https://books.google.com/books?id=skvZDQAAQBAJ&pg=PA786&lpg=PA786&dq=silhouette_score+precomputed+python3&source=bl&ots=YRC9VPTPPW&sig=7KPSQDWtZG6537-f_vZGwMpMvCc&hl=en&sa=X&ved=2ahUKEwjO3ruPqsXcAhWEg-AKHXD5BUAQ6AEwCXoECAMQAQ#v=onepage&q=silhouette_score%20precomputed%20python3&f=false). ; It suggested using todense() if the matrix is small, but to avoid this function all together if the matrix is large. When I trade toarray() for todense() it seems to produce similar results. Since single-cell datasets are likely always to be too big, it suggested using V-Measure or Adjusted Mutual Information as a way to evaluate sparse matrices instead. Just thought I'd update with my findings. Again, the `adata.obsm['X_pca']` suggestion seems to predict better clustering arrangements. Big ups for that! . Best",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/222#issuecomment-408842788:36,predict,predicted,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/222#issuecomment-408842788,3,"['avoid', 'predict']","['avoid', 'predict', 'predicted']"
Safety,"adata.var[""highly_variable""] and adata.var[""highly_variable_intersection""] have very different meanings and it's good to have them separate, I think. Considering that PCA looks for the genes marked True in adata.var[""highly_variable""] (regardless of the value of the batch_key option), using adata.var[""highly_variable_intersection""] for filtering is not a good idea. If there is confusion between adata.var[""highly_variable""] and adata.var[""highly_variable_intersection""]:. If the user specifies n_top_genes, adata.var[""highly_variable""] contains top variable genes in the list of genes sorted by number of batches they are detected as variable (ties broken using dispersion). If mean/dispersion filters are provided, we apply these cutoffs to mean mean/dispersion across batches to construct a unified adata.var[""highly_variable""]. adata.var[""highly_variable_intersection""] is a very strict definition that I personally avoid using at all, but it also depends on the experimental setting and batch_key itself. Therefore, there is a mistake in the following code:. ```python; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""); adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(); sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below; ```. This possibly removes many genes that are identified as highly variable in adata.var.highly_variable because adata_hvg = adata[:, adata.var.highly_variable_intersection] keeps only a subset of highly variable genes (see the definitions above). If one wants to use the strict definition, correct usage would be:. ```python; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""); adata.var.highly_variable = adata.var.highly_variable_intersection; sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032#issuecomment-616740607:625,detect,detected,625,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032#issuecomment-616740607,2,"['avoid', 'detect']","['avoid', 'detected']"
Safety,"anchings and partition the data into segments; 129 if n_branchings > 0:; --> 130 dpt.branchings_segments(); 131 adata.obs['dpt_groups'] = pd.Categorical(; 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self); 187 for each segment.; 188 """"""; --> 189 self.detect_branchings(); 190 self.postprocess_segments(); 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self); 262 segs_connects,; 263 segs_undecided,; --> 264 segs_adjacency, iseg, tips3); 265 # store as class members; 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3); 476 # branching on the segment, return the list ssegs of segments that; 477 # are defined by splitting this segment; --> 478 result = self._detect_branching(Dseg, tips3, seg); 479 ssegs, ssegs_tips, ssegs_adjacency, ssegs_connects, trunk = result; 480 # map back to global indices. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in _detect_branching(self, Dseg, tips, seg_reference); 646 if len(np.flatnonzero(newseg)) <= 1:; 647 logg.warning(f'detected group with only {np.flatnonzero(newseg)} cells'); --> 648 secondtip = newseg[np.argmax(Dseg[tips[inewseg]][newseg])]; 649 ssegs_tips.append([tips[inewseg], secondtip]); 650 undecided_cells = np.arange(Dseg.shape[0], dtype=int)[nonunique]. ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in argmax(a, axis, out); 1101 ; 1102 """"""; -> 1103 return _wrapfunc(a, 'argmax', axis=axis, out=out); 1104 ; 1105 . ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds); 54 def _wrapfunc(obj, method, *args, **kwds):; 55 try:; ---> 56 return getattr(obj, method)(*args, **kwds); 57 ; 58 # An AttributeError occurs if the object does not have. ValueError: attempt to get argmax of an empty sequence; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442:8233,detect,detected,8233,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442,1,['detect'],['detected']
Safety,"arse matrix of type '<class 'numpy.float64'>'; 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]); WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters.; WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`); WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`); WARNING: detected group with only [] cells; ```. </details>; <details><summary>Traceback</summary>. ```pytb; ValueError Traceback (most recent call last); ~/diffusion_map.py in <module>; 57 adata.uns['iroot'] = 0; 58 print(adata.uns); ---> 59 sc.tl.dpt(adata, n_branchings=2); 60 sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in dpt(adata, n_dcs, n_branchings, min_group_size, allow_kendall_tau_shift, copy); 128 # detect branchings and partition the data into segments; 129 if n_branchings > 0:; --> 130 dpt.branchings_segments(); 131 adata.obs['dpt_groups'] = pd.Categorical(; 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self); 187 for each segment.; 188 """"""; --> 189 self.detect_branchings(); 190 self.postprocess_segments(); 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self); 262 segs_connects,; 263 segs_undecided,; --> 264 segs_adjacency, iseg, tips3); 265 # store as class members; 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3); 476 # branching on the segment, return the list ssegs of segments that; 477 # are defined by splitting this segment; --> 478 result = self._detect_branching(Dseg, tips3, seg); 479 ssegs, ssegs_tips, ssegs_adjacenc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442:6992,detect,detect,6992,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442,1,['detect'],['detect']
Safety,"ation visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:; @numba.jit(); def fuzzy_simplicial_set(; ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)); OrderedDict([('neighbors', {'params': {'n_neighbors': 100, 'method': 'umap', 'metric': 'euclidean'}, 'distances': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'; 	with 1803087 stored elements in Compressed Sparse Row format>, 'connectivities': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'; 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]); WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters.; WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`); WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`); WARNING: detected group with only [] cells; ```. </details>; <details><summary>Traceback</summary>. ```pytb; ValueError Traceback (most recent call last); ~/diffusion_map.py in <module>; 57 adata.uns['iroot'] = 0; 58 print(adata.uns); ---> 59 sc.tl.dpt(adata, n_branchings=2); 60 sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in dpt(adata, n_dcs, n_branchings, min_group_size, allow_kendall_tau_shift, copy); 128 # detect branchings and partition the data into segments; 129 if n_branchings > 0:; --> 130 dpt.branchings_segments(); 131 adata.obs['dpt_groups'] = pd.Categorical(; 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self); 187 for each segment.; 188 """"""; --> 189 self.detect_branchings(); 190 self.postprocess_segments(); 191 self.set_segs_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442:6514,detect,detected,6514,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442,1,['detect'],['detected']
Safety,"ay, you need to retrieve the keys access individual values and then use the ‘ylim’ property. Get Outlook for iOS<https://aka.ms/o0ukef>; ________________________________; From: ZxyChopcat ***@***.***>; Sent: Thursday, September 16, 2021 1:24:05 PM; To: theislab/scanpy ***@***.***>; Cc: Vekeria, Jai Patel ***@***.***>; Comment ***@***.***>; Subject: Re: [theislab/scanpy] How to use stacked_violin with variable y-axis limits between rows? (#386). Hi,; I tried to set the y-axis limit, but failed with the error:; `>>> axes = sc.pl.stacked_violin(adata, marker_genes, groupby='cell_types', rotation=90,swap_axes=True,row_palette='muted',yticklabels=True,show=False). for ax in axes:; ... ax.set_ylim(0, 5); ...; Traceback (most recent call last):; File """", line 2, in; AttributeError: 'str' object has no attribute 'set_ylim'; `; I use scanpy 1.8.1.; Do you have any idea? Thanks!. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ftheislab%2Fscanpy%2Fissues%2F386%23issuecomment-921089934&data=04%7C01%7Cjai.vekeria%40pitt.edu%7C4da79e06909d45b4b4e508d97936c8d4%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1%7C0%7C637674098542578553%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=t3jhsNr2Q3IlftHnubs6%2FWZyy%2FAijC2BWJ18Ih41Py0%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAL6KD25HVPRX7SK4DD5UPE3UCIR3LANCNFSM4GH7A7BA&data=04%7C01%7Cjai.vekeria%40pitt.edu%7C4da79e06909d45b4b4e508d97936c8d4%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1%7C0%7C637674098542578553%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=NONHFLCjdRyCv1jUBuSyGgy4%2FX8do5WWWrrPPyLk5tw%3D&reserved=0>.; Triage notifications on the go with GitHub Mobile for iOS<https://nam12.safelinks.protection.outloo",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/386#issuecomment-921104209:1247,safe,safelinks,1247,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/386#issuecomment-921104209,1,['safe'],['safelinks']
Safety,"ception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper; return f(*args, **kwargs); File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed; backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',; File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read; **kwargs,; File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read; is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,); File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download; _download(backup_url, path); File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download; urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:; File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen; return opener.open(url, data, timeout); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open; response = self._open(req, data); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open; '_open', req); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain; result = func(*args); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open; context=self._context, check_hostname=self._check_hostname); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open; raise URLError(err); urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1472#issuecomment-721326665:2896,timeout,timeout,2896,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472#issuecomment-721326665,1,['timeout'],['timeout']
Safety,"coverage decreased, I think not detected because some pytest.parametrize were removed?; I can also add the new specific test separately do avoid this, else it looks good to me",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3042#issuecomment-2195081621:32,detect,detected,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042#issuecomment-2195081621,2,"['avoid', 'detect']","['avoid', 'detected']"
Safety,"cs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```; modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership); q = modularity_part.quality(); ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :); > ; > A couple follow up points on this and @LuckyMD's points; > ; > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores.; > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-529494088:2904,safe,safe,2904,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819#issuecomment-529494088,1,['safe'],['safe']
Safety,"def nn_descent(; ^. self.func_ir.loc)); /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 467:; def fuzzy_simplicial_set(; <source elided>; if knn_indices is None or knn_dists is None:; knn_indices, knn_dists, _ = nearest_neighbors(; ^. @numba.jit(); /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:; @numba.jit(); def fuzzy_simplicial_set(; ^. self.func_ir.loc)); /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:; @numba.jit(); def fuzzy_simplicial_set(; ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)); OrderedDict([('neighbors', {'params': {'n_neighbors': 100, 'method': 'umap', 'metric': 'euclidean'}, 'distances': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'; 	with 1803087 stored elements in Compressed Sparse Row format>, 'connectivities': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'; 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]); WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters.; WARNING: shifting branching point away from maximal ken",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442:5343,detect,detected,5343,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442,1,['detect'],['detected']
Safety,"e the way Anndata works means that its metadata must be computed eagerly after each operation in the Zheng17 recipe, rather than lazily for the whole computation (which is the way Dask works). Another option would be to see if you can swap out Anndata for Xarray. This is a big change obviously, and probably pretty disruptive to the existing codebase, but it would align you with many other software projects and scientific communities that are currently thinking about these exact same problems. My guess is that in the long run it would save you time, assuming that Xarray DataArrays meet your needs semantically. > Many operations work, however cupyx.scipy.sparse has a number of missing features that mean it can’t be used for Zheng17 yet. It would require significant work in CuPy to get it working:. I could imagine that these might be in scope for NVidia folks to work on in a few months (no promises though). If you wanted to raise these as issues there to track things that would be helpful. cc @jakirkham @pentschev. > However, when I tried NumPy 1.17 the Dask implementation slowed down significantly. I haven't been able to pinpoint the issue. I would be curious to know what's going on here if you find out. >> Any chance you did any profiling of these runs? I'd be interested in seeing the performance impact across the pipeline. > The closest I got to this was using the Dask web UI to watch tasks being run (see this part of the benchmark script: https://github.com/tomwhite/scanpy/blob/sparse-dask/benchmark.py#L54-L55). This is useful to see what operations are bottlenecks. The only timings I did were to run the complete recipe. +1 on profiling. I suggest that you first start with `compute(scheduler=""single-threaded"")` and the cProfile module. This will avoid any parallelism, and hopefully let you use profiling techniques that are more familiar to you. I personally like snakeviz. . If you want to get on a screenshare some time I'm happy to look at dashboard plots with you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-557191880:2892,avoid,avoid,2892,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921#issuecomment-557191880,1,['avoid'],['avoid']
Safety,"for very large data (`pp.log1p` and `pp.pca`), where it already gives remarkable memory use reduction in `memory` mode. Of course, this is considerably slower than feeding in the full data matrix. We'll use AnnData's chunked functionality in other tools, soon. We're also using it when working with tensorflow. At some point, when you open an AnnData in `backed` mode, the whole pipeline will run through by processing chunks and the user won't have to do a single change to his or her code. By that, code that has been written for data that fits into memory will automatically scale to many millions of observations. Also, there will be global settings that allow to manually determine whether the whole pipeline should run on chunks but still load the basic data matrix into memory, something we've found useful in several occasions.; - not returning `None` when modifying a reference inplace: the very first draft of Scanpy was written this way. then @flying-sheep remarked, that it shouldn't and I agreed with him right away: if you return the changed object, you'll allow two different variable names for the same reference. This is a dangerous source for bugs - this was one of the few instances where I produced more bugs than in C++, where one would always write inplace functions (taking pointers or references) that return `void`. In addition, returning `None` directly tells the user that the typical code for writing pipelines does not have to be redundant: `function(adata)` instead of `adata = function(adata)`. Finally: all of Scanpy is consistently written using these principles and it would cause a lot of trouble both changing it in a simple function and changing it everywhere. Why do you think that _it allows for a more functional style of writing a processing pipeline_?. Hence, I'm sorry that I tend to not merge your pull request as is. Either you restore everything else that was there and solely add the inplace `np.log1p` or I'd do that. :smile:. Have a good Sunday!; Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/191#issuecomment-403240196:2327,redund,redundant,2327,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191#issuecomment-403240196,1,['redund'],['redundant']
Safety,"ge interaction. I will leave here the description of the packages installed in both cases for reference, and then close the issue:. 1. The behavior shown in this issue does not happen if I create an environment in conda with python installed, and then install all packages using pip like this:. ```; conda create -n scanpy_test1 python; pip install scanpy leidenalg scvi-tools; pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118; ```. This allows me to have GPU support with scvi-tools and different runs are reproducible. The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; absl-py 1.4.0 pypi_0 pypi; adjusttext 0.8 pypi_0 pypi; aiohttp 3.8.5 pypi_0 pypi; aiosignal 1.3.1 pypi_0 pypi; airr 1.4.1 pypi_0 pypi; anndata 0.9.1 pypi_0 pypi; anyio 3.7.1 pypi_0 pypi; arrow 1.2.3 pypi_0 pypi; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; async-timeout 4.0.2 pypi_0 pypi; attrs 23.1.0 pypi_0 pypi; awkward 2.3.1 pypi_0 pypi; awkward-cpp 21 pypi_0 pypi; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backoff 2.2.1 pypi_0 pypi; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pypi_0 pypi; blessed 1.20.0 pypi_0 pypi; brotli-python 1.0.9 py311ha362b79_9 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; certifi 2022.12.7 pypi_0 pypi; charset-normalizer 2.1.1 pypi_0 pypi; chex 0.1.7 pypi_0 pypi; click 8.1.6 pypi_0 pypi; cmake 3.25.0 pypi_0 pypi; colorama 0.4.6 pyhd8ed1ab_0 conda-forge; comm 0.1.3 pyhd8ed1ab_0 conda-forge; contextlib2 21.6.0 pypi_0 pypi; contourpy 1.1.0 pypi_0 pypi; croniter 1.4.1 pypi_0 pypi; cycler 0.11.0 pypi_0 pypi; dateutils 0.6.12 pypi_0 pypi; debugpy 1.6.7 py311hcafe171_0 conda-forge; decorator 5.1.1 pyhd8ed1ab_0 conda-forge; deepdiff 6.3.1 pypi_0 pypi; dm-tree 0.1.8 pypi_0 pypi; docr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:1447,timeout,timeout,1447,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205,1,['timeout'],['timeout']
Safety,h96ca727_0; - r/linux-64::r-recommended==3.6.0=r36_0; - r/linux-64::r-rpart==4.1_15=r36h96ca727_0; - r/linux-64::r-spatial==7.3_11=r36h96ca727_4; - r/linux-64::r-survival==2.44_1.1=r36h96ca727_0; ```. </Details>. <Details>; <Summary>Package versions in old environment</Summary>. ```# packages in environment at /home/karl/anaconda3/envs/scanpy1_7:; #; # Name Version Build Channel; _anaconda_depends 2020.07 py38_0 ; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 1_gnu conda-forge; _r-mutex 1.0.0 anacondar_1 ; adjusttext 0.7.3.1 py_1 conda-forge; aiohttp 3.7.4.post0 pypi_0 pypi; aiohttp-cors 0.7.0 pypi_0 pypi; aioredis 1.3.1 pypi_0 pypi; alabaster 0.7.12 pyhd3eb1b0_0 ; anaconda custom py38_1 ; anaconda-client 1.7.2 py38_0 ; anaconda-project 0.10.0 pyhd3eb1b0_0 ; anndata 0.7.6 pypi_0 pypi; anyio 2.2.0 py38h06a4308_1 ; appdirs 1.4.4 py_0 ; argh 0.26.2 py38_0 ; argon2-cffi 20.1.0 py38h27cfd23_1 ; asn1crypto 1.4.0 py_0 ; astroid 2.5 py38h06a4308_1 ; astropy 4.2.1 py38h27cfd23_1 ; async-timeout 3.0.1 pypi_0 pypi; async_generator 1.10 pyhd3eb1b0_0 ; atomicwrites 1.4.0 py_0 ; attrs 21.2.0 pyhd3eb1b0_0 ; autopep8 1.5.6 pyhd3eb1b0_0 ; babel 2.9.1 pyhd3eb1b0_0 ; backcall 0.2.0 pyhd3eb1b0_0 ; backports 1.0 pyhd3eb1b0_2 ; backports.shutil_get_terminal_size 1.0.0 pyhd3eb1b0_3 ; bbknn 1.4.0 py38h0213d0e_0 bioconda; beautifulsoup4 4.9.3 pyha847dfd_0 ; binutils_impl_linux-64 2.33.1 he6710b0_7 ; binutils_linux-64 2.33.1 h9595d00_15 ; bitarray 2.1.0 py38h27cfd23_1 ; bkcharts 0.2 py38_0 ; black 19.10b0 py_0 ; blas 1.0 mkl ; bleach 3.3.0 pyhd3eb1b0_0 ; blessings 1.7 pypi_0 pypi; blosc 1.21.0 h8c45485_0 ; bokeh 2.3.2 py38h06a4308_0 ; boto 2.49.0 py38_0 ; bottleneck 1.3.2 py38heb32a55_1 ; brotlipy 0.7.0 py38h27cfd23_1003 ; bwidget 1.9.11 1 ; bzip2 1.0.8 h7b6447c_0 ; c-ares 1.17.1 h27cfd23_0 ; ca-certificates 2021.4.13 h06a4308_1 ; cached-property 1.5.2 py_0 ; cachetools 4.2.2 pypi_0 pypi; cairo 1.14.12 h8948797_3 ; capital 1.0.0 pypi_0 pypi; cellrank 1.2.0 pypi_0 pypi; certifi ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310:4951,timeout,timeout,4951,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310,1,['timeout'],['timeout']
Safety,hi @Hrovatin ; so was it useful for your task? Curious to hear. Couple of questions:; - why having a tool redundant between two packages? ; - what is SEMITONES?; thank you!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-787484724:106,redund,redundant,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698#issuecomment-787484724,1,['redund'],['redundant']
Safety,"hi Alex, I'm not sure how to test this either. I tried to run in a new clean conda environment but cant use more than 50% of the cells in pre-processing (otherwise the process is killed at even the normalization stage, ""pp.normalize_ per_cell"" and uses over 120GB RAM); The file from 10X i'm using is the link to ""1M_neurons aggr - Gene / cell matrix HDF5 (filtered)"" from https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/ ; This is what i type into the terminal; $ python cluster_mouse_brain.py 1M_neurons_filtered_gene_bc_matrices_h5.h5; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; reading 1M_neurons_filtered_gene_bc_matrices_h5.h5 (0:01:19.78); running recipe zheng17; filtered out 3983 genes that are detected in less than 1 counts; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Killed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/511#issuecomment-469664995:772,detect,detected,772,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-469664995,1,['detect'],['detected']
Safety,how would you avoid the context manager?. it’s either that or wrapping try/catch around every single use of the `writedir`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/50#issuecomment-346763343:14,avoid,avoid,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50#issuecomment-346763343,1,['avoid'],['avoid']
Safety,"louvain is deprecated. leiden is its successor. So unless you want compare different community detection methods, you should use leiden instead of louvain. Just leave out the `flavor`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1283#issuecomment-1638297190:95,detect,detection,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283#issuecomment-1638297190,1,['detect'],['detection']
Safety,"n GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ftheislab%2Fscanpy%2Fissues%2F386%23issuecomment-921089934&data=04%7C01%7Cjai.vekeria%40pitt.edu%7C4da79e06909d45b4b4e508d97936c8d4%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1%7C0%7C637674098542578553%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=t3jhsNr2Q3IlftHnubs6%2FWZyy%2FAijC2BWJ18Ih41Py0%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAL6KD25HVPRX7SK4DD5UPE3UCIR3LANCNFSM4GH7A7BA&data=04%7C01%7Cjai.vekeria%40pitt.edu%7C4da79e06909d45b4b4e508d97936c8d4%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1%7C0%7C637674098542578553%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=NONHFLCjdRyCv1jUBuSyGgy4%2FX8do5WWWrrPPyLk5tw%3D&reserved=0>.; Triage notifications on the go with GitHub Mobile for iOS<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapps.apple.com%2Fapp%2Fapple-store%2Fid1477376905%3Fct%3Dnotification-email%26mt%3D8%26pt%3D524675&data=04%7C01%7Cjai.vekeria%40pitt.edu%7C4da79e06909d45b4b4e508d97936c8d4%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1%7C0%7C637674098542588546%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=%2FXLG4aYkL8kN8XOgwQdaIBq3OoN%2FjjSAE984xAYIRDM%3D&reserved=0> or Android<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fplay.google.com%2Fstore%2Fapps%2Fdetails%3Fid%3Dcom.github.android%26referrer%3Dutm_campaign%253Dnotification-email%2526utm_medium%253Demail%2526utm_source%253Dgithub&data=04%7C01%7Cjai.vekeria%40pitt.edu%7C4da79e06909d45b4b4e508d97936c8d4%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1%7C0%7C637674098542588546%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=jfOeBNWAPuUo7LZ0gx6ArEZqlajNpIB1XHvuXjBYblo%3D&reserved=0>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/386#issuecomment-921104209:2225,safe,safelinks,2225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/386#issuecomment-921104209,2,['safe'],['safelinks']
Safety,"node = make_euclidean_tree(data, left_indices, rng_state, leaf_size); ^. [1] During: resolving callee type: recursive(type(CPUDispatcher(<function make_euclidean_tree at 0x7f822dd05d08>))); [2] During: typing of call at /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py (457). File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 457:; def make_euclidean_tree(data, indices, rng_state, leaf_size=30):; <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size); ^. @numba.jit(); /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""make_euclidean_tree"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:; @numba.jit(); def make_euclidean_tree(data, indices, rng_state, leaf_size=30):; ^. self.func_ir.loc)); /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:; @numba.jit(); def make_euclidean_tree(data, indices, rng_state, leaf_size=30):; ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)); /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: ; The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:; @numba.njit(parallel=True); def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):; ^. current_gra",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442:2848,detect,detected,2848,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442,1,['detect'],['detected']
Safety,"ork"".; > > 1. Return cluster labels as ints. I'm not sure using strings breaks any compatability. Doesn't scikit-learn work fine with strings representing categories?. <details>; <summary> Example of sklearn working with string categories </summary>. ```python; from sklearn import metrics; import numpy as np; from string import ascii_letters. x = np.random.randint(0, 10, 50); y = np.array(list(ascii_letters))[np.random.randint(0, 10, 50)]. metrics.adjusted_rand_score(x, y); ```. </details>. > but I think it's a mistake to change the convention for how one indexes positionally vs using labels; > 2. Support non-string indexes (and adopt loc vs iloc). I don't think the conventions are so set in stone. Numpy behaves differently than pandas, which behaves differently than xarray. I personally like the conventions of [DimensionalData.jl](https://github.com/rafaqz/DimensionalData.jl), but think xarray is a likely the direction we'll head. > 3. Support ufuncs with AnnData. What does `np.log1p(adata)` return? Is it the whole object? Do we want to copy the whole object just to update values in X?. I think probably not. I also think AnnData <-> pd.DataFrame is the wrong analogy. In my view, an AnnData object is a collection of arrays, more akin to an xarray.Dataset, Bioconductor SummarizedExperiment, or an OLAP cube. I think a syntax that could work better would be something like:. ```python; adata.apply_ufunc(np.log1p, in=""X"", out=""X""); adata.apply_ufunc(np.log1p, in=(""layers"", ""counts""), out=(""layers"", ""log_counts"")); ```. As an aside, I think we could do something similar with sklearn style transformers, i.e. ```python; clf = SVC.fit(labelled, X=(""obsm"", ""X_pca""), y=""leiden""); clf.predict(unlabelled, X=(""obsm"", ""X_pca""), key_added=""transferred_labels""); ```. > 4. (maybe) Return copies of input for most scanpy functions. I think a core advantage of scanpy over the bioconductor ecosystem is the performance. If we always returned copies by default, a lot of that would go away.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-584460629:2333,predict,predict,2333,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-584460629,1,['predict'],['predict']
Safety,"raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 161 parent = _get_parent(elem); 162 raise AnnDataReadError(; --> 163 f""Above error raised while reading key {elem.name!r} of ""; 164 f""type {type(elem)} from {parent}.""; 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'); ```. <details>; <summary>Versions</summary>. Package Version; ----------------------- ------------; absl-py 1.1.0; aiohttp 3.8.1; aiosignal 1.2.0; anndata 0.7.5; anndata2ri 1.0.6; annoy 1.17.0; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; asn1crypto 1.4.0; async-timeout 4.0.2; asynctest 0.13.0; attrs 20.3.0; backcall 0.2.0; beautifulsoup4 4.11.1; bleach 5.0.0; boto3 1.17.66; botocore 1.20.66; brotlipy 0.7.0; cached-property 1.5.2; cachetools 5.2.0; certifi 2020.12.5; cffi 1.14.5; chardet 4.0.0; charset-normalizer 2.0.12; chex 0.1.3; click 8.1.3; colormath 3.0.0; commonmark 0.9.1; conda 4.6.14; conda-package-handling 1.7.3; cryptography 3.4.7; cycler 0.10.0; Cython 0.29.30; decorator 5.0.7; defusedxml 0.7.1; dill 0.3.3; dm-tree 0.1.7; docrep 0.3.2; entrypoints 0.4; et-xmlfile 1.1.0; fa2 0.3.5; fastjsonschema 2.15.3; flatbuffers 2.0; flax 0.5.0; frozenlist 1.3.0; fsspec 2022.5.0; future 0.18.2; get-version 2.2; google-auth 2.6.6; google-auth-oauthlib 0.4.6; google-pasta 0.2.0; grpcio 1.46.3; h5py 3.2.1; idna 2.10; imageio 2.19.3; importlib-metadata 4.11.4; importlib-resources 5.7.1; ipykernel 5.5.4; ipython 7.23.1; ipython-genutils 0.2.0; ipywidgets 7.7.0; jax 0.3.13; jaxlib 0.3.10; jedi 0.18.0; Jinja2 3.1.2; jmespath 0.10.0; joblib 1.0.1; jsonsc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336:2286,timeout,timeout,2286,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336,1,['timeout'],['timeout']
Safety,"reate a custom API. One point of Scanpy is to provide convenient access via `anndata` to many single-cell packages around. The only thing needed for that is to provide a very simple interface like [this](https://github.com/theislab/scanpy/blob/master/scanpy/tools/phate.py#L8-L145) or [this](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/mnn_correct.py#L4-L104) or several of the other tools... Simply click on the GitHub links in the Scanpy docs... If your package works reliably, both the restrictions you mention should in principle not prevent adding your package. Of course, in the future, we want all elements of Scanpy to scale to millions of cells, not just the core tools. But for a lot of people, it's right now helpful to have a large number of tools available also for relatively small datasets. The only problem is to avoid cluttering the Scanpy API with virtually any tool there is. Tools in the API should have passed a certain quality check. Doublet detection is a difficult problem. Already last autumn, we played around with @swolock 's tool but didn't end up using it - it was good, but in our situation, it didn't seem to apply (are you eventually going to distribute a package for it @swolock ?). I myself quickly wrote a tool, too, but it didn't work well. Just yesterday, [this](https://www.biorxiv.org/content/early/2018/06/20/352484) appeared. Then there is also [this](https://www.biorxiv.org/content/early/2018/04/04/234872) on ""empty cell detection"". There are more tools out there, I think... What I mean is: computationally detecting doublets is still something where the field has not agreed on a consensus. Just like batch correction. Therefore, I would not add a tool `tl.doublet_detection` or `tl.detect_doublets` to the API at this stage. There are two options. Either we create a `.beta` module of the API for tools that don't even have a preprint and add your tool and similar cases in the future there. We could make a separate page for tha",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-399367409:1026,detect,detection,1026,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-399367409,1,['detect'],['detection']
Safety,"ried to set the y-axis limit, but failed with the error:; `>>> axes = sc.pl.stacked_violin(adata, marker_genes, groupby='cell_types', rotation=90,swap_axes=True,row_palette='muted',yticklabels=True,show=False). for ax in axes:; ... ax.set_ylim(0, 5); ...; Traceback (most recent call last):; File """", line 2, in; AttributeError: 'str' object has no attribute 'set_ylim'; `; I use scanpy 1.8.1.; Do you have any idea? Thanks!. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ftheislab%2Fscanpy%2Fissues%2F386%23issuecomment-921089934&data=04%7C01%7Cjai.vekeria%40pitt.edu%7C4da79e06909d45b4b4e508d97936c8d4%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1%7C0%7C637674098542578553%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=t3jhsNr2Q3IlftHnubs6%2FWZyy%2FAijC2BWJ18Ih41Py0%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAL6KD25HVPRX7SK4DD5UPE3UCIR3LANCNFSM4GH7A7BA&data=04%7C01%7Cjai.vekeria%40pitt.edu%7C4da79e06909d45b4b4e508d97936c8d4%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1%7C0%7C637674098542578553%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=NONHFLCjdRyCv1jUBuSyGgy4%2FX8do5WWWrrPPyLk5tw%3D&reserved=0>.; Triage notifications on the go with GitHub Mobile for iOS<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapps.apple.com%2Fapp%2Fapple-store%2Fid1477376905%3Fct%3Dnotification-email%26mt%3D8%26pt%3D524675&data=04%7C01%7Cjai.vekeria%40pitt.edu%7C4da79e06909d45b4b4e508d97936c8d4%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1%7C0%7C637674098542588546%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=%2FXLG4aYkL8kN8XOgwQdaIBq3OoN%2FjjSAE984xAYIRDM%3D&reserved=0> or Android<https://nam12.safe",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/386#issuecomment-921104209:1704,safe,safelinks,1704,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/386#issuecomment-921104209,1,['safe'],['safelinks']
Safety,"slab/scanpy.git to /tmp/pip-_z2v8och-build; fatal: Unable to find remote helper for 'https'; Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None; ```. second, I tried; ```; pip install git+git://github.com/theislab/scanpy.git ; ```; I got ouput as:; ```; Collecting git+git://github.com/theislab/scanpy.git; Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build; ```; and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```; python setup.py build; ```. I got ouput as:. ```; importlib_metadata.PackageNotFoundError: scanpy; ```. after this, I tried . ```; pip install -e .; ```. I got ouput as:. ```; Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/; ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` ; pip install https://github.com/theislab/scanpy.git; ```. output:. ```; Collecting https://github.com/theislab/scanpy.git; Downloading https://github.com/theislab/scanpy.git; \ 143kB 442kB/s; Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format; Cannot determine archive format of /tmp/pip-xolhyav7-build; ```. and i also tried. ```; git clone --recursive git://github.com/theislab/scanpy.git; ```. output:. ```; Cloning into 'scanpy'...; remote: Enumerating objects: 122, done.; remote: Counting objects: 100% (122/122), done.; remote: Compressing objects: 100% (109/109), done.; Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s; fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s; fatal: early EOF; fatal: index-pack failed; ```. however, i can successfully install scanpy 1.4.4 with. ```; pip install scanpy; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-532985027:1678,detect,detect,1678,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-532985027,1,['detect'],['detect']
Safety,"st debating the API, which wouldn't be that hard to change before a release anyways. It becomes much harder after a release because they you have to worry about backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-801745797:1024,avoid,avoid,1024,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-801745797,1,['avoid'],['avoid']
Safety,"sure, we’ll talk in 10 days or so, after my holidays 😄. except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents don’t survive a reboot). ```py; # python gives you a context manager that deletes the file after its block; with tempfile.TemporaryFile() as fp:; use(fp); # fp and the file are gone now; ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/50#issuecomment-346781457:1591,safe,safely,1591,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50#issuecomment-346781457,1,['safe'],['safely']
Safety,"tools in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from legacy-api-wrap->scanpy) (42.0.2.post20191203); Requirement already satisfied: numexpr>=2.6.2 in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from tables->scanpy) (2.7.0); Requirement already satisfied: more-itertools in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata>=0.7; python_version < ""3.8""->scanpy) (7.2.0); ```. ```; conda install -c bioconda scanpy; ```. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: |; /; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package pandas conflicts for:; scanpy -> pandas[version='>=0.21']; Package tqdm conflicts for:; scanpy -> tqdm; Package setuptools conflicts for:; scanpy -> setuptools; Package patsy conflicts for:; scanpy -> patsy; Package seaborn conflicts for:; scanpy -> seaborn; Package pytables conflicts for:; scanpy -> pytables; Package umap-learn conflicts for:; scanpy -> umap-learn[version='>=0.3.0']; Package networkx conflicts for:; scanpy -> networkx; Package readline conflicts for:; python=3.7 -> readline[version='>=7.0,<8.0a0']; Package joblib conflicts for:; scanpy -> joblib; Package importlib-metadata conflicts for:; scanpy -> importlib-metadata; Package tk conflicts for:; python=3.7 -> tk[version='>=8.6.7,<8.7.0a0|>=8.6.8,<8.7.0a0']; Package numba conflicts for:; scanpy -> numba[version='>=0.41.0']; Package python-igraph conflicts for:; scanpy -> python-igraph; Package li",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-575281452:11343,abort,abort,11343,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-575281452,1,['abort'],['abort']
Safety,"umap expects a list as group, so it will work if you do:. ```python; sc.pl.umap(adata, color='blobs', groups=['Zero']); ````. the improvement that I would consider is to automatically convert a string into a list to avoid the error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/231#issuecomment-414236960:216,avoid,avoid,216,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/231#issuecomment-414236960,1,['avoid'],['avoid']
Safety,"version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console; $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no; Numba function called from a non-threadsafe context. Try installing `tbb`.; Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads.; - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):; File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper; File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _; File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper; File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get; File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task; File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task; File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks; File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run; File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3335#issuecomment-2457625478:1089,Abort,Aborted,1089,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335#issuecomment-2457625478,1,['Abort'],['Aborted']
Safety,"when I detect the with adata.obs[""seurat_clusters""].dtype.name != 'category'. the resault shows Ture",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1414#issuecomment-692446575:7,detect,detect,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1414#issuecomment-692446575,1,['detect'],['detect']
Safety,"yes, this sanity check for `n_components` in diffmap definitely makes sense. makes sense for any parameter in any function. but is so much work! :wink: I'll add it for this case, soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/170#issuecomment-398776008:10,sanity check,sanity check,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/170#issuecomment-398776008,1,['sanity check'],['sanity check']
Safety,you can make a new column to avoid overwriting the boolean. ```python; adata.obs['boolean_cat'] = adata.obs['boolean'].astype(str).astype('category'); ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1646#issuecomment-778338666:29,avoid,avoid,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1646#issuecomment-778338666,1,['avoid'],['avoid']
Safety,"ype=""dataframe""); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:291: in dmatrix; NA_action, return_type); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:165: in _do_highlevel_design; NA_action); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:62: in _try_incr_builders; formula_like = ModelDesc.from_formula(formula_like); ../../../miniconda3/lib/python3.6/site-packages/patsy/desc.py:164: in from_formula; tree = parse_formula(tree_or_string); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:148: in parse_formula; _atomic_token_types); ../../../miniconda3/lib/python3.6/site-packages/patsy/infix_parser.py:210: in infix_parse; for token in token_source:; ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:94: in _tokenize_formula; yield _read_python_expr(it, end_tokens); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:44: in _read_python_expr; for pytype, token_string, origin in it:; ../../../miniconda3/lib/python3.6/site-packages/patsy/util.py:332: in next; return six.advance_iterator(self._it); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . code = ''. def python_tokenize(code):; # Since formulas can only contain Python expressions, and Python; # expressions cannot meaningfully contain newlines, we'll just remove all; # the newlines up front to avoid any complications:; code = code.replace(""\n"", "" "").strip(); it = tokenize.generate_tokens(StringIO(code).readline); try:; for (pytype, string, (_, start), (_, end), code) in it:; if pytype == tokenize.ENDMARKER:; break; origin = Origin(code, start, end); > assert pytype not in (tokenize.NL, tokenize.NEWLINE); E AssertionError. ../../../miniconda3/lib/python3.6/site-packages/patsy/tokens.py:35: AssertionError; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/398#issuecomment-451762530:2068,avoid,avoid,2068,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-451762530,1,['avoid'],['avoid']
Security, 2.2.0 py38h06a4308_1 ; appdirs 1.4.4 py_0 ; argh 0.26.2 py38_0 ; argon2-cffi 20.1.0 py38h27cfd23_1 ; asn1crypto 1.4.0 py_0 ; astroid 2.5 py38h06a4308_1 ; astropy 4.2.1 py38h27cfd23_1 ; async-timeout 3.0.1 pypi_0 pypi; async_generator 1.10 pyhd3eb1b0_0 ; atomicwrites 1.4.0 py_0 ; attrs 21.2.0 pyhd3eb1b0_0 ; autopep8 1.5.6 pyhd3eb1b0_0 ; babel 2.9.1 pyhd3eb1b0_0 ; backcall 0.2.0 pyhd3eb1b0_0 ; backports 1.0 pyhd3eb1b0_2 ; backports.shutil_get_terminal_size 1.0.0 pyhd3eb1b0_3 ; bbknn 1.4.0 py38h0213d0e_0 bioconda; beautifulsoup4 4.9.3 pyha847dfd_0 ; binutils_impl_linux-64 2.33.1 he6710b0_7 ; binutils_linux-64 2.33.1 h9595d00_15 ; bitarray 2.1.0 py38h27cfd23_1 ; bkcharts 0.2 py38_0 ; black 19.10b0 py_0 ; blas 1.0 mkl ; bleach 3.3.0 pyhd3eb1b0_0 ; blessings 1.7 pypi_0 pypi; blosc 1.21.0 h8c45485_0 ; bokeh 2.3.2 py38h06a4308_0 ; boto 2.49.0 py38_0 ; bottleneck 1.3.2 py38heb32a55_1 ; brotlipy 0.7.0 py38h27cfd23_1003 ; bwidget 1.9.11 1 ; bzip2 1.0.8 h7b6447c_0 ; c-ares 1.17.1 h27cfd23_0 ; ca-certificates 2021.4.13 h06a4308_1 ; cached-property 1.5.2 py_0 ; cachetools 4.2.2 pypi_0 pypi; cairo 1.14.12 h8948797_3 ; capital 1.0.0 pypi_0 pypi; cellrank 1.2.0 pypi_0 pypi; certifi 2020.12.5 py38h06a4308_0 ; cffi 1.14.0 py38h2e261b9_0 ; chardet 4.0.0 py38h06a4308_1003 ; click 8.0.0 pypi_0 pypi; cloudpickle 1.6.0 py_0 ; clyent 1.2.2 py38_1 ; cmake 3.18.4.post1 pypi_0 pypi; colorama 0.4.4 pyhd3eb1b0_0 ; conda-pack 0.6.0 pyhd3eb1b0_0 ; contextlib2 0.6.0.post1 py_0 ; cryptography 3.4.7 py38hd23ed53_0 ; curl 7.69.1 hbc83047_0 ; cycler 0.10.0 py38_0 ; cython 0.29.22 pypi_0 pypi; cytoolz 0.11.0 py38h7b6447c_0 ; dask 2021.4.0 pyhd3eb1b0_0 ; dask-core 2021.4.0 pyhd3eb1b0_0 ; dbus 1.13.18 hb2f20db_0 ; decorator 5.0.9 pyhd3eb1b0_0 ; defusedxml 0.7.1 pyhd3eb1b0_0 ; deprecated 1.2.11 pypi_0 pypi; diff-match-patch 20200713 py_0 ; distributed 2021.5.0 py38h06a4308_0 ; docrep 0.3.2 pyh44b312d_0 conda-forge; docutils 0.17.1 py38h06a4308_1 ; dorothea-py 1.0.3 pypi_0 pypi; entrypoints 0.3 py38_0 ; et,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310:5759,certificate,certificates,5759,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310,1,['certificate'],['certificates']
Security," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:2152,validat,validating,2152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823,1,['validat'],['validating']
Security," this can quickly get out of bounds, I'd thus suggest to; ; - constrain this discussion to `matplotlib`/`seaborn` (as this is what scanpy and afaik most of the ecosystem projects are using); - only focus on the low-level use-cases. . In brief all that is required to implement a plotting API that behaves like scanpy's. . ---. > I'd be interested in hearing specific thoughts on this. I've personally been thinking it would be nice to lean on seaborn plotting classes more heavily here, potentially contributing features upstream. Here's one example mwaskom/seaborn#2487 of a feature which could fit the AnnData data model nicely. I was mostly referring to @fidelram's idea how to make plot styling more ""modular"" instead of having a vast amount of arguments for a single plotting function (#956). If this idea was to be implemented for all scanpy plotting functions, I thought that maybe an abstract base-class could provide the method signatures to ensure consistency within scanpy and ecosystem packages. Even with the current ""keyword approach"" it would be great if there was some way to ensure that common keywords are always named consistently. . What would be an example of a plot object you would like to ""move"" to seaborn? Something like a multi-panel UMAP plot? . ---. > I'd like to move towards stabilizing this. I'm not sure how much we'd want to provide plotting library specific code, vs. more generic helpers. Right now the most obvious addition is _set_color_for_categorical_obs, which I'd also like to make accessible through sc.get. Adding groupby support to anndata would help a lot here too (theislab/anndata#556). that sounds great! . ---. Finally, in terms of ""reusable building blocks"" I was thinking of, for instance, . - the ""dot size legend"" ; ![image](https://user-images.githubusercontent.com/7051479/118252952-a378ae80-b4a9-11eb-8a11-72bf46cdae20.png). - Setting up axes for a scatter plot together with the appropriate legend (continuous color bar or categorical legend)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1832#issuecomment-841139143:1578,access,accessible,1578,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832#issuecomment-841139143,1,['access'],['accessible']
Security," to start a flame war. Scanpy is an excellent piece of software, and I greatly appreciate at the work that goes into it. Responding to @LuckyMD, I again would just point out that returning cluster labels as ints is the standard for sklearn, and I would urge that scanpy serve as an access point to single cell analysis both for biologists and also for data science / machine learning researchers. Biologists will likely stick to using scanpy's plotting functions where you can handle default color maps for things that appear to be labels. We do this kind of checking in scprep: https://github.com/KrishnaswamyLab/scprep/blob/09de1bf41c4b42d331b29a4493c436110b641e07/scprep/plot/scatter.py#L206-L253. However, for machine learning researchers who likely have their own preferred plotting tools in matplotib or seaborn, might be trying to use the results from clustering in scanpy to compare to results from `sklearn.cluster`, or otherwise want to fit scanpy into their analysis pipelines, turning arrays of numerics into arrays of strings causes headaches that make the tools less accessible. The argument about the default colormap in matplotlib is continuous seems less important than making scanpy compatible with the larger ecosystem of data science tools in Python. Finally, I will note that in Python, strings are also defined ordinally, even if you might not think of them that way. Although in some respects the question, ""Is `'1'` less than `'a'`?"" is nonsensical, this is a well defined test in Python. ```python; In [1]: '1' < 'a'; Out[1]: True; ```. Again, I want to emphasize that I really love what has been done with scanpy / anndata so far. We use it in various places in our single cell workshop (https://krishnaswamylab.org/workshop), and I rely on the implementations of louvain / paga / dpt for my research. I bring up these issues here because I think changing some of these conventions could result in greater widespread adoption that I would love to see for scanpy and anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-582988545:2211,access,accessible,2211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-582988545,1,['access'],['accessible']
Security,"# simple log(n+1) (as used in RNAseq); ![image](https://user-images.githubusercontent.com/20694664/83345487-a05cd080-a2e1-11ea-858e-4d98621d12e6.png). can suffer from discretization at low values... note: even though Seurat/Scanpy/Loupe all use different bases, the log base doesn't really matter; it just changes the scale, not the shape/distinguishing power. ### hyperbolic arcsin (as used in CyTOF); ![image](https://user-images.githubusercontent.com/20694664/83345476-81f6d500-a2e1-11ea-8f68-ddff22ffe853.png). not as noisy as log at low values, and doesn't assert that zeros have to be Laplace smoothed with a pseudocount of +1. ### biexponential family (as used in flow cytometry); ![image](https://user-images.githubusercontent.com/20694664/83345554-6fc96680-a2e2-11ea-8112-3bdc09260e63.png). best smoothing so far in the low counts, because that's what it was designed to do. in this case, it is the newest of this family: `vlog(alpha=0, beta=12, xmax=70000, zmax=1)`; - https://doi.org/10.1002/cyto.a.23017; - https://doi.org/10.1002/cyto.a.22030; - https://doi.org/10.1002/cyto.a.20258. ### centered log ratio (as used in CITEseq paper); ![image](https://user-images.githubusercontent.com/20694664/83345643-a9e73800-a2e3-11ea-8303-365fccca16cc.png). not only does this have good smoothing, but it differs in that it is injecting an additional aspect beyond just bringing high values into a linear range; specifically, the centering feature seems to impart an assumption about compositional data, giving higher preference to relative ratios, even if the absolute magnitude might be different -- this has the effect of counteracting cell size, but I've observed that it may introduce unexpected changes (not shown here) in the shape of the distribution that is different from all of the other transforms mentioned, so these need to be validated biologically against some ""ground truth"". for the time being though, the last few mentioned are all good candidates to include as transform options",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-636429530:2178,inject,injecting,2178,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117#issuecomment-636429530,2,"['inject', 'validat']","['injecting', 'validated']"
Security,",0], dtype='category'); sizes = pd.Series(data[:,1], dtype='category'). plt.scatter(data[:,0], data[:,1], c=colors, s=sizes); ```; I made a note of this https://github.com/matplotlib/matplotlib/issues/6214 . Thanks @ivirshup for pointing me to https://github.com/theislab/anndata/issues/35 and https://github.com/theislab/anndata/issues/31. I'm not convinced that positional vs label indexing is so complicated to understand that people will find scanpy difficult to use if you start adopting an `iloc` vs `loc` syntax. I agree that it makes the learning curve a little steeper, but it enables greater comparability with the ecosystem of data science tools in python. It looks like there are some strong opinions here though, and I don't want to start a flame war. Scanpy is an excellent piece of software, and I greatly appreciate at the work that goes into it. Responding to @LuckyMD, I again would just point out that returning cluster labels as ints is the standard for sklearn, and I would urge that scanpy serve as an access point to single cell analysis both for biologists and also for data science / machine learning researchers. Biologists will likely stick to using scanpy's plotting functions where you can handle default color maps for things that appear to be labels. We do this kind of checking in scprep: https://github.com/KrishnaswamyLab/scprep/blob/09de1bf41c4b42d331b29a4493c436110b641e07/scprep/plot/scatter.py#L206-L253. However, for machine learning researchers who likely have their own preferred plotting tools in matplotib or seaborn, might be trying to use the results from clustering in scanpy to compare to results from `sklearn.cluster`, or otherwise want to fit scanpy into their analysis pipelines, turning arrays of numerics into arrays of strings causes headaches that make the tools less accessible. The argument about the default colormap in matplotlib is continuous seems less important than making scanpy compatible with the larger ecosystem of data science tool",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-582988545:1412,access,access,1412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-582988545,1,['access'],['access']
Security,". The Debian build file is (here)[https://salsa.debian.org/med-team/python-scanpy/-/blob/master/debian/rules] though mostly it lets you see what tests I was skipping because of missing dependencies. Also if I set a color like in_tissue, or array_row the data shows up. I can paste the full build log if you'd like but this is the dependencies installed and the environment variables. . ```; Build-Origin: Debian; Build-Architecture: amd64; Build-Date: Sun, 14 Nov 2021 20:11:26 +0000; Build-Path: /<<PKGBUILDDIR>>; Installed-Build-Depends:; adduser (= 3.118),; adwaita-icon-theme (= 41.0-1),; autoconf (= 2.71-2),; automake (= 1:1.16.5-1),; autopoint (= 0.21-4),; autotools-dev (= 20180224.1+nmu1),; base-files (= 12),; base-passwd (= 3.5.52),; bash (= 5.1-3.1),; binutils (= 2.37-8),; binutils-common (= 2.37-8),; binutils-x86-64-linux-gnu (= 2.37-8),; blt (= 2.5.3+dfsg-4.1),; bsdextrautils (= 2.37.2-4),; bsdutils (= 1:2.37.2-4),; build-essential (= 12.9),; bzip2 (= 1.0.8-4),; ca-certificates (= 20211016),; coreutils (= 8.32-4.1),; cpp (= 4:11.2.0-2),; cpp-11 (= 11.2.0-10),; dash (= 0.5.11+git20210903+057cd650a4ed-3),; dbus (= 1.12.20-3),; dbus-bin (= 1.12.20-3),; dbus-daemon (= 1.12.20-3),; dbus-session-bus-common (= 1.12.20-3),; dbus-system-bus-common (= 1.12.20-3),; dbus-user-session (= 1.12.20-3),; dconf-gsettings-backend (= 0.40.0-2),; dconf-service (= 0.40.0-2),; debconf (= 1.5.79),; debhelper (= 13.5.2),; debianutils (= 5.5-1),; dh-autoreconf (= 20),; dh-python (= 5.20211105),; dh-strip-nondeterminism (= 1.12.0-2),; diffutils (= 1:3.7-5),; dmsetup (= 2:1.02.175-2.1),; docutils-common (= 0.17.1+dfsg-2),; dpkg (= 1.20.9),; dpkg-dev (= 1.20.9),; dwz (= 0.14-1),; file (= 1:5.39-3),; findutils (= 4.8.0-1),; flit (= 3.0.0-1),; fontconfig (= 2.13.1-4.2),; fontconfig-config (= 2.13.1-4.2),; fonts-font-awesome (= 5.0.10+really4.7.0~dfsg-4.1),; fonts-lato (= 2.0-2.1),; fonts-lyx (= 2.3.6-1),; g++ (= 4:11.2.0-2),; g++-11 (= 11.2.0-10),; gcc (= 4:11.2.0-2),; gcc-11 (= 11.2.0-10),; g",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616:1475,certificate,certificates,1475,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616,1,['certificate'],['certificates']
Security,"1. I've been playing around with `xarray` and finding the `Dataset` objects fairly intuitive for storing multidimensional arrays. I think it makes sense to store calculated values like this, but give easy access to a long (/tidy) dataframe (similar to that binder notebook). I think representing it internally as a tidy dataframe could be inefficient, since that's pretty close to 100% dense COO matrix. My impression is this is broadly similar to how diffxpy is representing it's results. I think there are also two separate problems here, which are ""what's a better way to store differential expression results"" and ""what's a good api for differential expression"". I'm interested in the `sc.ex` module you're suggesting. Would you mind elaborating a bit more on that, particularly on some functions that would be there?. 2. I'd really like to get a generalized version of this implemented. Right now, I think the biggest thing holding it back is being smart about how sparse matrices are handled, but otherwise xarray has a good model for the semantics.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/562#issuecomment-487343093:205,access,access,205,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487343093,1,['access'],['access']
Security,> @brianpenghe hashsolo is implementer in scanpy now. That would be awesome. Which version of Scanpy includes hashsolo? Any Scanpy tutorials?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-788842420:15,hash,hashsolo,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-788842420,2,['hash'],['hashsolo']
Security,"> Are you suggesting that the table would be added to at runtime (when a function is called)? I think this may be better addressed by a broader solution to ""what has been done to this dataset?"". I'm not sure how this could be done without buy in from third party libraries. Also has been discussed a bit previously: #472. Yeah I suppose, though I could see how this gets complicated by the fact that I imagine more people than myself use multiple h5ads throughout their analysis of the same dataset. Though maybe something simpler is to be able to access a global table of functions and citations, and it gives you the bibtex. But if there's any interest in it (a bit of a weird idea I understand) I can make an issue for it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-764945553:548,access,access,548,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-764945553,1,['access'],['access']
Security,"> Awesome, Gokcen, thank you! 😁; >. Thank you!; ; > Also, adding an export utility for Gephi was on the list already before. Cool that you found a simple solution for this.; > . Ah ok, didn't know that. Here is what I used so far for gephi:. ```python; # python-igraph from master branch is required; # see https://github.com/igraph/python-igraph/issues/115; from igraph.remote.gephi import GephiConnection, GephiGraphStreamer. sc.tl.draw_graph(adata); # would be also nice have access to igraph object right after sc.tl.draw_graph; g = sc.utils.get_igraph_from_adjacency(adata.uns['data_graph_norm_weights']). # then install latest Gephi and the streaming plugin:; # https://gephi.org/plugins/#/plugin/graphstreaming; # and start the Gephi master server; streamer = GephiGraphStreamer(); conn = GephiConnection(workspace=1). # igraph cannot serialize numpy float32 to json, so it must be converted to float64; g.es['weight'] = [float(x) for x in g.es['weight']]; g.vs['groups'] = adata.obs['louvain_groups'].tolist(); streamer.post(g, conn); ```. Here is the Yifan Hu layout for 3K PBMC:. ![image](https://user-images.githubusercontent.com/1140359/34961174-384c5658-fa0c-11e7-8597-db4e77cbf4e3.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/68#issuecomment-357787075:479,access,access,479,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/68#issuecomment-357787075,1,['access'],['access']
Security,"> Has the format changed for all assays, or is this specific to visium HD?. Do you refer to the support for multiple annotation tables or also to other parts of the specs? Visium HD and MCMICRO are currently the only technologies making use of multiple tables. > just accessing the AnnData from spatialdata_io.visium_hd. I would favor this approach. I would call `to_legacy_anndata()` only if it is essential to have the spatial information is obsm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2973#issuecomment-2035363386:268,access,accessing,268,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973#issuecomment-2035363386,1,['access'],['accessing']
Security,> How are the download speeds/ hosting for figshare? Do they mirror to different regions? I recall some painful download times from Australia. It's also probably pretty stable. the datasets we have in figshar for squidpy are fast to access (europe at least) but also traffic is probably much less than pbmc3k() 😅,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2124#issuecomment-1026092545:233,access,access,233,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124#issuecomment-1026092545,1,['access'],['access']
Security,"> I am checking, it seems that the format for rp_forest changed significantly. Can we validate the format? If so, can we just recalculate the forest if the format isn't what we expect?. Also, can you point me to the code where this is handled in `ingest`? I feel like something user visible should happen if there's malformed data in the object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1601#issuecomment-764398251:86,validat,validate,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1601#issuecomment-764398251,1,['validat'],['validate']
Security,"> I know exactly that in PCA I can interpret a component based on its rank (and/or variance contribution). Ah, I meant more specifically that it may be easier to biologically interpret an ICA. > That would say I should try as many decompositions as possible to see when I get a good result. I'm a little unsure of your meaning here. Do you mean decompositions like decomposition techniques? If so, I don't think this is the right conclusion. I think it means: probably PCA for clustering, probably NMF for finding gene modules. I would also suspect something which finds sparser variable loadings like ICA or NMF could be more robust for cross dataset classification. If you mean, if the results are unstable how do we know which to trust – I did ask that question. I think it's the usual: have a validation dataset, maybe some ensemble/ robustness method, or do some sort of enrichment. It's an open question, but a lot of our analysis pipeline is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/941#issuecomment-560313033:797,validat,validation,797,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941#issuecomment-560313033,1,['validat'],['validation']
Security,"> I'll definitely talk to the admin, but I am not sure he would update. An admin that doesn’t take security risks seriously isn’t doing their job properly. ---. > Jupyter Notebook requires JavaScript. that probably means that Jupyter notebook tries to run lynx or www or sone other text-only browser. `jupyter notebook --no-browser` is correct and the tokens aren’t machine-specific. [I set up stuff differently](https://jupyter-notebook.readthedocs.io/en/stable/public_server.html#automatic-password-setup), but @ivirshup’s setup should work perfectly as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/561#issuecomment-477525477:99,secur,security,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477525477,2,"['password', 'secur']","['password-setup', 'security']"
Security,"> I've figured out what was causing my error. The scanpy function to read in `features.tsv.gz` expects three columns: `['gene_symbols, 'gene_ids', 'feature_types']` Where 'feature types' is a text string like 'Gene Expression' and usually repeated along the whole length of the file. The file I was reading in was from HTO data and only had one column:; > ; > > Hashtag1-GTCAACTCTTTAGCG; > > Hashtag2-TTCCGCCTCTCTTTG; > > Hashtag3-AAGTATCGTTTCGCA; > > unmapped; > ; > So if others run into this same error, just add in some extra columns to the `features.tsv` file so it doesn't error out when looking for the extra columns. Something like this (different features file):; > ; > > RP11-34P13.7	RP11-34P13.7	Gene Expression; > > FO538757.3	FO538757.3	Gene Expression; > > FO538757.2	FO538757.2	Gene Expression; > > AP006222.2	AP006222.2	Gene Expression; > > RP4-669L17.10	RP4-669L17.10	Gene Expression; > ; > It would also be helpful if scanpy would validate the number of columns at the start. At the moment it looks like it reads in the whole `.mtx` file before trying to map the feature names and producing this error, so it takes a while to fail. when you do add those columns it makes the number of genes to 0 while reading it!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-1433364355:949,validat,validate,949,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-1433364355,1,['validat'],['validate']
Security,"> I've observed that it may introduce unexpected changes (not shown here) in the shape of the distribution that is different from all of the other transforms mentioned, so these need to be validated biologically against some ""ground truth"". Here's some selected examples (skipping the raw and geometric mean for reasons stated earlier) of the additional aspect introduced by CLR, beyond linearization of the signal, which illustrate how one might want to decide on a case by case basis which is biologically true:. Some *potential* artifacts:; - discreteness at low values (reflected in the histograms earlier), and a ""kink"" near there in the contour that doesn't match with a 2D-gaussian; - skewing of the ""absence"" of a marker depending on presence of another marker; - a weird double-positive tail that extends along the diagonal. These types of effects are reminiscent of [flow cytometry artifacts](https://docs.flowjo.com/flowjo/graphs-and-gating/gw-transform-overview/gw-transform-digital/). However, without proving which one is ground truth, we don't know for sure which one is true. At least initially, I would think that the CLR plots look more plausible. ![image](https://user-images.githubusercontent.com/20694664/83360046-51985080-a34c-11ea-9ec0-2057301ae4fc.png). ![image](https://user-images.githubusercontent.com/20694664/83360065-74c30000-a34c-11ea-9e0b-d28cea53993e.png). ![image](https://user-images.githubusercontent.com/20694664/83360079-84dadf80-a34c-11ea-9026-4256d8a3199b.png). I used a neutral word earlier: that CLR ""injects"" additional changes, but now it seems that may be a positive thing because many of these empirical cases seem believable from a biological standpoint -- a more systematic validation/comparison might conclude that it ""corrects"" some aspect of the signal acquisition (e.g. combats protein differences simply due to cell size). Again, this is because by design, CLR isn't just a rescaling: it performs cell-specific centering relative to all markers in ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-636513215:189,validat,validated,189,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117#issuecomment-636513215,1,['validat'],['validated']
Security,"> I’m unsure if we can help you with this, as it’s your system creating his error and we don’t have access to the data. There’s multiple possible causes and solutions:; > ; > * a misunderstanding: The arrays should require `310385 * 8563 * 8B = 21.3 GB`, no idea why it says 10. But of course that’s still not close to 100GB unless other people/processes are using the machine, or other arrays are allocated. Can you track the memory usage and see if it spikes close to the maximum before the code crashes?; > * our implementation allocates memory it shouldn’t: this is the only one we can fix, but we’d have to figure out under which circumstances that happens, and where in our code.; > * some machine problem, [like many people on stackoverflow](https://www.google.com/search?q=site%3Astackoverflow.com+%22Unable+to+allocate%22+%22GiB+for+an+array+with+shape%22+%22and+data+type%22): maybe your sysadmin can help?. Thank you so much for all your assistance and detailed suggestion, I really appreciate it. I tracked the memory usage and found out that the free system memory is only about 5 GB, so apparently I have misunderstood the concept of ""memory usage"" before......Now I am going to turn to people who have encountered the same machine problem on stackoverflow and see if there is some advice. Thank you again for your time and attention!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2551#issuecomment-1640426447:100,access,access,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551#issuecomment-1640426447,1,['access'],['access']
Security,"> My idea was to have print_header output very little, plus an expandable region (as it’s the one called in notebooks), and to revert print_versions to just copyable text output. Could we deprecate `print_header` and instead suggest a way to call `session_info` for the equivalent?. If all we're doing is calling `session_info.show` with a couple default arguments, I'm not sure it's worth keeping here. I'd like users to call it directly because:. * Users get access to all of the session_info options without us having to mediate that; * If something doesn't work, it's not our problem. > session_info has no file argument. It has `write_req_file`, which is the same intent – right?. I assume `file` was there from a time when this wrote something that you could `pip install` from?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2089#issuecomment-998837030:461,access,access,461,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2089#issuecomment-998837030,1,['access'],['access']
Security,"> The `scipy.sparse` wrapper is actually interesting. I think it's tricky to add directly to SciPy, but it could be split out as a separate package that users could use and we could link to in the `scipy.sparse` docs. Any thoughts on where the `scipy.sparse` wrapper might live? It currently exposes just enough of the NumPy API for the purposes of ScanPy - i.e. it would need quite a bit more work to be more generally useful. Ditto for the `cupyx.scipy.sparse` wrapper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-557464075:292,expose,exposes,292,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921#issuecomment-557464075,1,['expose'],['exposes']
Security,"> The just added changes should mimic the response from 1.6 except for duplicate names in var_names which I think should respond similarly like when doing a slicing on the AnnData object. Thinking about this more. Considering that no one has complained about this so far. I think I'm actually fine with this being an error. If there are complaints, I think we should change it back. I do think it's important that `gene_symbols` can have duplicates as long as those values aren't being accessed (as non-unique identifiers is the whole point of `gene_symbols`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770641710:486,access,accessed,486,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770641710,1,['access'],['accessed']
Security,"> This sounds familiar, but I don't remember where it happens. Could you point me towards that?; > ; > Never mind, I think I found it in [`fuzzy_simplical_set`](https://github.com/lmcinnes/umap/blob/439db748b9959b53d6678b6fdc6cb18e8f49c6c6/umap/umap_.py#L566-L574), . Yes, exactly. > but made me think of another question:; > ; > Do we want to save the indices and distances as a pair of arrays, . What do you mean? If we merge this, we will have `adata.uns['neighbors']['knn_indices']` and `adata.uns['neighbors']['distances']` (only if it's requested by the user). Is this what you mean? . > or just save a sparse matrix of the original distances? I think the latter would be easier to work with. I'm not following. `adata.uns['neighbors']['distances']` encodes a different type of information since it represents the graph structure and it's symmetrized. `knn_indices` on the other hand represents the ""raw"" output of kNN method. Just like `adata.uns['neighbors']['rp_forest']`, it's additional information about the kNN. It can be used for other things like kNN classifiers or building other types of graphs like mutual kNN as I mentioned. Just to clarify, I don't propose using knn_indices as a replacement of distance or connectivitiy matrix. It's just to be able to access more details of the kNN construction. Furthermore, it's optional and it's False by default.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/820#issuecomment-529927212:1273,access,access,1273,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/820#issuecomment-529927212,1,['access'],['access']
Security,"> Though maybe something simpler is to be able to access a global table of functions and citations, and it gives you the bibtex. @adamgayoso From my point of view, references are already available ([source](https://github.com/theislab/scanpy/blob/master/docs/references.rst), [rendered](https://scanpy.readthedocs.io/en/latest/references.html)) and linked to in the documentation. I'm not against the idea, I'm just not seeing how it makes this information more accessible/ prominent. A separate issue for the topic would be good for more discussion. ---------------------. > Would really welcome that. I can help where I can, although not so familiar with numba. @LuckyMD, meant to say, `numba` is super easy, it's really just python. Next best thing to Julia. Definitely worth some time to learn, but also it won't take that much time to learn.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-765107026:50,access,access,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-765107026,2,['access'],"['access', 'accessible']"
Security,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen?. > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install?. > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-782812159:1010,validat,validating,1010,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-782812159,1,['validat'],['validating']
Security,"> Where shall I call this code?. I would call it on the same exact same `X` on different machines. E.g. something like:. ```python; from hashlib import sha256; import anndata as ad; from sklearn.decomposition import PCA. adata = ad.read_h5ad(""PC1.h5ad""); print(sha256(adata.X).hexdigest()). pca = PCA(n_components=50, solver=""arpack"", random_state=0). print(sha256(pca.fit_transform(adata.X)).hexdigest()); ```. The first hash should be the same on all systems, while I would expect the second to vary if the PCA isn't reproducing. > To switch out the solver, did you mean that I should delete svd_solver='arpack' in sc.tl.pca(adata, svd_solver='arpack')?. I think you should specify a different one, like ""lob_pcg"" or ""randomized"", but you can pass this directly to `PCA(..., solver=...)` too. > To use 64bit value, shall I call this adata.X = adata.X.astype('float64') . Yes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021416791:137,hash,hashlib,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021416791,2,['hash'],"['hash', 'hashlib']"
Security,"> Why is this PR getting a build if there is no `pr` trigger entry in the yaml?. See 3 paragraphs down:. > If no pr triggers appear in your YAML file, pull request validations are automatically enabled for all branches, as if you wrote the following pr trigger. This configuration triggers a build when any pull request is created, and when commits come into the source branch of any active pull request.; > ; > ```; > pr:; > branches:; > include:; > - '*' # must quote since ""*"" is a YAML reserved character; we want a string; > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1516#issuecomment-737862275:164,validat,validations,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516#issuecomment-737862275,1,['validat'],['validations']
Security,"> You mean the fact that the index makes the dataframe now actually useful? I can’t think of a way in which this breaks things in a way that isn’t immediately obvious and welcome. Of course, code can be infinitely weird, but can you think of a scenario?. I get that it is more useful, but any code that was accessing it with `.loc` especially if it was relying on unique indices could run into a problem. It's minor, I'd be fine to leave it. Just we may need to revert.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1945680366:307,access,accessing,307,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1945680366,1,['access'],['accessing']
Security,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review?. Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”?. Also: can we reenable squash/rebase merges soon?. > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-777397179:519,validat,validates,519,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-777397179,1,['validat'],['validates']
Security,"> obs-like structure with clusters in rows. Completely agreed!; 1. agreed with @ivirshup that there should be a more comprehensive object (which can possibly simply be stored as a dataframe and params in `.uns['rank_genes_groups']`, that clarify what the reference for the test was, but that might be not powerful enough)... your latest suggestion, @ivirshup, representing things as in 3d array sounds very promising, too... how to make an intuitive object? represent the 3d array in a long-form dataframe where two axes are accessible from one multi-index? or store an actual 3d array in AnnData, which can be cast into a convenient object, through a casting namespace... the logic being `sc.tl....` computes some complicated annotation, `sc.pl...` visualizes this annotation and `sc.ex....` extracts and casts annotation into more easily manageable objects. One example is `sc.Neigbors` (which should go into `sc.ex...`) which takes the weird annotation that `sc.pp.neighbors` writes and casts them into an object that allows accessing things... ; 2. Related, but really independent of `rank_genes_groups`: I had implemented a [draft of a `.collapse()` function](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/zebrafish/zebrafish.ipynb#Collapsing-the-AnnData-object), which is very similar to the [`.groupby()` function](https://github.com/ivirshup/mantis#group-by) that @ivirshup suggests, but much less elegant (I would also never have put it into the main repo...). You take a summary metric like `.mean()` or `.std()` and collapse the object by that (in pandas, would be `df.groupby('louvain').mean()`. > Why is it that .obs, .var, and .uns don't have data frames in them? np.recarray don't seem like a very popular data structure elsewhere. We just did only allow rec arrays in `.uns` as they are natively supported by hdf5 and dataframes aren't. It was really just that reason, nothing else. As mentioned in anndata, I'd love to completely move away from rec arrays as a means o",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/562#issuecomment-487279241:525,access,accessible,525,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487279241,1,['access'],['accessible']
Security,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata.; 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized.; 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-730939013:34,expose,exposed,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-730939013,1,['expose'],['exposed']
Security,"@Khalid-Usman Of course you can use silhouette coefficient for any kind of clustering in principal. you just need to choose the ""best option"" depending on your dataset which is again depending on what you are interested in and then you can validate it by looking into your clusters markers. I am actually very curious to see the T-cells case that was mentioned here....you can also have a look here: https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set; Again I would like to mention using such control parameters are mathematical methods to assess your clustering quality it might has nothing to do with the biological side and they can be actually helpful when you have no clue over the number of clusters you would look for so you would reply only on mathematics ! your question is really topic specific that what you look for and in which case you want to assess your data...if you already have an estimation or no.......there are also other ways to look for the quality of the data as grst mentioned but again it really depends on what you look into.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-498181103:240,validat,validate,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498181103,1,['validat'],['validate']
Security,"@Lucas-Maciel ; Can you try setting the `number_of_noise_barcodes = 1`? . e.g. `scanpy.external.pp.hashsolo(adata, cell_hashing_columns, *, priors=(0.01, 0.8, 0.19), pre_existing_clusters=None, number_of_noise_barcodes=1)`; https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.pp.hashsolo.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-2305593426:99,hash,hashsolo,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-2305593426,2,['hash'],['hashsolo']
Security,@Zethson hashsolo is in scanpy already in the external api. Let me know if you have any questions about it !,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-1975387276:9,hash,hashsolo,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-1975387276,1,['hash'],['hashsolo']
Security,@adamgayoso I don't think it fits under the other preprocessing tool headings of Data integration or Imputation. Maybe add a new one called Call hashing or Sample demultiplexing. @fidelram thoughts? Not sure who else to tag,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1483#issuecomment-722042260:145,hash,hashing,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483#issuecomment-722042260,1,['hash'],['hashing']
Security,@aditisk I'm the author of this method https://github.com/calico/solo. it should install relatively easily if you have any issues I'm happy to help. The main functionality it doesn't have is `tag_groups` so you'd have t manually create that if you have used multiple hashes per group.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-601407528:267,hash,hashes,267,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-601407528,1,['hash'],['hashes']
Security,"@ashish615 after doing some benchmarking myself I found out that your solution for `axis=1` is under performing compared to `axis=0` for larger arrays. I think that is because of the memory access pattern you choose. I rewrote the function with that in mind. I'll again make a PR to you, because for some reason you disallow us from making changes to your PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3099#issuecomment-2191349887:190,access,access,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099#issuecomment-2191349887,1,['access'],['access']
Security,@brianpenghe hashsolo is implementer in scanpy now,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-788095696:13,hash,hashsolo,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-788095696,1,['hash'],['hashsolo']
Security,@brianpenghe solo is here at least: https://docs.scvi-tools.org/en/stable/api/reference/scvi.external.SOLO.html Don't think hashsolo is anywhere yet though,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-1975375458:124,hash,hashsolo,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-1975375458,1,['hash'],['hashsolo']
Security,"@dburkhardt Sorry for the late response to this. I agree that the space of single cell 'omics analysis tools is essentially the wild west, where every tool should be viewed critically. However, I'm wary of abandoning a critical discussion of imputation methods in this space because other portions of the typical workflow have issues as well. Further, I think there are important distinctions to be made between different classes of methodology that are (mis)used in this problem space. I. Methods that are fundamentally flawed by their assumptions or algorithm. These should obviously be avoided.; II. Methods that are fundamentally sound but are not sufficiently validated, e.g. the validation doesn't exist in this problem space, isn't sufficiently comprehensive/relevant, performs poorly against other fundamentally sound methodologies, or has such restrictive assumptions it isn't broadly useful/applicable.; III. Methods that are fundamentally sound in assumption/algorithm and can be used by a competent practitioner but still have the potential to be abused through applying it to data that violate those assumptions. I'd consider t-SNE and a great deal of the clustering algorithms to be in class III for the reasons you said; they're valid, functional tools but can be applied in assumption-violating or quasi-valid ways. I'm pretty sure that scImpute, for example, belongs in class I because its description of dropout and simulated test cases are inappropriate. I'd put MAGIC and several other currently available imputation methods in class II as they've got strong foundations but currently insufficient validation IMO. I'm not trying to pick on MAGIC or any specific imputation method. Instead I'd like to have an open discussion about the benefits, limitations, and relative performance of the various imputation methods available with the goal leading to something like @gokceneraslan suggested. Well, and since you brought it up, batch correction and multimodal integration methods a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189#issuecomment-417692893:665,validat,validated,665,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189#issuecomment-417692893,2,['validat'],"['validated', 'validation']"
Security,"@falexwolf Mostly just following along with the Seurat vignettes here using scanpy:. * [Demultiplexing with cell hashing](https://satijalab.org/seurat/hashing_vignette.html); * [Multimodal analysis with CITE-seq ADTs](https://satijalab.org/seurat/multimodal_vignette.html). Mostly I'm using [CITE-seq-count](https://github.com/Hoohm/CITE-seq-Count) to generate counts matrices then storing the ADT counts in `adata.obsm[""X_adt""]` and HTO counts in `adata.obsm[""X_hto""]`. From there, I generate additional metadata about the cells which I store in either `adata.obs` (e.g, for HTOs, `adata.obs.global_classification` stores `[""singlet"", ""doublet"", ""negative""]` and `adata.obs.tag_class` stores `[""hashtag_1"", ""hashtag_2"", ...]`). I'd be happy to contribute a PR in the next couple weeks. A quick question though: the workflow involves some IO, normalization, classification, and plotting, so where would be the best entry point for this? I was thinking about stashing all related functionality in a `multimodal.py` module, but then should they be part of the `tools` api or a separate api like `sc.mm`? Or should I spread out the functionality across the existing `pp`, `tl`, `pl` apis?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-437946116:113,hash,hashing,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-437946116,1,['hash'],['hashing']
Security,"@falexwolf thanks for the feedback. :). I agree with your comments on the `sc.tl.dendrogram`. Similar reasoning originally motivated me to separate and expose the implementation of the function. I expect that now, is easier to extend the creation of a correlation matrix to other methods and groupings as you suggest. Currently, by default `sc.tl.dendrogram` uses PCA by recycling the function used by `sc.tl.neighbors` (`tools._utils.choose_representation()`). Any other embedding in `.obsm` can be used (as is the case by `sc.tl.neighbors`. Also, any group of genes can be given as parameter . What tl.dendrogram does not do is to use the underlying network to compute a distance matrix as I think seurat does and apparently you also do in PAGA. . For me, what is important is that the plotting functions get the dendrogram data from `.uns` and thus the generation of the hierarchical clustering is separated and can be computed by any other method.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/425#issuecomment-456065730:152,expose,expose,152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-456065730,1,['expose'],['expose']
Security,@fidelram are you calling an implicit function `summarize_categorical` or something that could be exposed to the user as a tool? . @wangjiawen2013 `sc.set_figure_params(vector_friendly=False)` does what you want: https://scanpy.readthedocs.io/en/latest/api/index.html#settings,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/336#issuecomment-435730736:98,expose,exposed,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/336#issuecomment-435730736,1,['expose'],['exposed']
Security,"@fidelram; I gave you write access to the repo so that you can quickly merge PRs like this to your plotting API. It would still be great if bigger chunks of new functionality continued to come in PRs, which you could then merge yourself upon a brief check by any of us. Does that sound right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/538#issuecomment-474281330:28,access,access,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538#issuecomment-474281330,1,['access'],['access']
Security,"@flying-sheep I thought that by doing `adata[:, 'gene_name'].X` the AnnData object does all sorts of checks which are redundant if I only want to access a single column on the data matrix. But if you say this is fine I will not change it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-422361197:146,access,access,146,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-422361197,1,['access'],['access']
Security,"@flying-sheep that user experience seems pretty reasonable. I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for `expression_atlas` would have a reference to `dataset_dir`?. Also on point 4, I've definitely had conda exit with helpful errors when I ran out of space.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478225437:200,access,access,200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478225437,1,['access'],['access']
Security,"@gokceneraslan Thanks for the PR. I hesitated in the past to add such functionality as this makes the definition of expression very *ad hoc*. However, I also noticed the pitfalls when you have only normalized data and the dotplot does not makes sense. Are you planning any further changes?. @falexwolf Thanks for giving me write access. I will use the new status responsible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/538#issuecomment-474721527:329,access,access,329,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538#issuecomment-474721527,1,['access'],['access']
Security,"@ivirshup @flying-sheep @falexwolf . I would like to merge this branch soon and I would like your opinion on the following:; * Extended functionality and fine tuning of the plots is achieved by using the new plot objects. However, I don't know how they can be documented in readthedocs (or if we want that). Note: the object methods are well documented and can be accessed, for example in Jupyter notebooks. * I am using `return_fig` as an argument to return the plot object in `sc.pl.dotplot` etc. Is this a good name choice?. As mentioned previously, the current PR tries to keep the current functionality with minimal changes to the way functions like `sc.pl.dotplot` are called. On the background, the code was refactored to remove much repetition as possible and allow new functionally. . The current progress on the visualization tutorial is here: https://nbviewer.jupyter.org/github/fidelram/scanpy-tutorials/blob/marker_genes_vis_tutorial/visualizing-marker-genes.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1210#issuecomment-636014104:364,access,accessed,364,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210#issuecomment-636014104,1,['access'],['accessed']
Security,@ivirshup @gokceneraslan Do you have access to the error details for readthedocs? I get 'page does not exists' error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1204#issuecomment-654765480:37,access,access,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204#issuecomment-654765480,1,['access'],['access']
Security,"@ivirshup I think doublet detection is a little too narrow in that we can also associate cells to the original sample they came from. Although many folks use cell hashing solely for the purpose of doublet detection. I'd prefer ""Sample demultiplexing"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1483#issuecomment-724181103:163,hash,hashing,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483#issuecomment-724181103,1,['hash'],['hashing']
Security,"@ivirshup In the last few commits, I added some things to skip some unnecessary computation steps (which were only used for logging/warning). Here's a quick example:. ```python; import fsspec; import zarr; from anndata.experimental import sparse_dataset; from anndata import AnnData; import dask.array as da; from dask import delayed; from scipy import sparse. class AccessTrackingStore(zarr.LRUStoreCache):; def __init__(self, *args, **kwargs):; super().__init__(*args, **kwargs). def __getitem__(self, key):; if key not in self._values_cache:; print(key); return super().__getitem__(key). def csr_callable(shape: tuple[int, int], dtype) -> sparse.csr_matrix:; if len(shape) == 0:; shape = (0, 0); if len(shape) == 1:; shape = (shape[0], 0); elif len(shape) == 2:; pass; else:; raise ValueError(shape). return sparse.csr_matrix(shape, dtype=dtype). class CSRCallable:; """"""Dummy class to bypass dask checks""""""; def __new__(cls, shape, dtype):; return csr_callable(shape, dtype). def make_dask_chunk(x, start: int, end: int) -> da.Array:; def take_slice(x, idx):; return x[idx]. return da.from_delayed(; delayed(take_slice)(x, slice(start, end)),; dtype=x.dtype,; shape=(end - start, x.shape[1]),; meta=CSRCallable,; ). def sparse_dataset_as_dask(x, stride: int):; n_chunks, rem = divmod(x.shape[0], stride). chunks = []; cur_pos = 0; for i in range(n_chunks):; chunks.append(make_dask_chunk(x, cur_pos, cur_pos + stride)); cur_pos += stride; if rem:; chunks.append(make_dask_chunk(x, cur_pos, x.shape[0])). return da.concatenate(chunks, axis=0). def read_w_sparse_dask(group, obs_chunk: int = 1000) -> AnnData:; return AnnData(; X=sparse_dataset_as_dask(sparse_dataset(group[""X""]), obs_chunk),; ); ```; After this setup:; ```python; mapper = fsspec.get_mapper(; ""https://vitessce-demo-data.storage.googleapis.com/anndata-demos/BALF_VIB-UGent_processed_cleaned.zarr/""; ); store = AccessTrackingStore(mapper, max_size=2**28); adata = read_w_sparse_dask(zarr.convenience.open_consolidated(store)); ```; T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2856#issuecomment-1983048375:367,Access,AccessTrackingStore,367,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2856#issuecomment-1983048375,1,['Access'],['AccessTrackingStore']
Security,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308:38,expose,exposed,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308,1,['expose'],['exposed']
Security,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```; python3 download_expression_atlas.py {accession}; ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271:299,access,accession,299,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271,2,['access'],['accession']
Security,"@njbernstein I had also noticed hashsolo wasn't added to the documentation, which you can do by adding `pp.hashsolo` [here](https://github.com/theislab/scanpy/blob/master/scanpy/external/__init__.py). Though I'm unsure which heading it belongs under.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1483#issuecomment-722025417:32,hash,hashsolo,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483#issuecomment-722025417,2,['hash'],['hashsolo']
Security,"@njbernstein Probably not the right place for this discussion, but a couple of follow-up questions for you:; - Do you happen to have a benchmark of `hashsolo` vs the other demuxing algos? It's been on my todo list for ..a while.. but still haven't gotten around to doing it. I've seen the benchmarks of the doublet finding capabilities of `solo` and they look good. As a user of scrublet, it'd be nice to have one tool/codebase that handles both transcriptomic and tag multiplets.; - Are you open to PRs? I'd at least like to have functionality to generate the initial h5ad object containing the tag counts from the output of `CITE-seq-Count`.; - Regarding non-antibody tags, have you noticed celltype-specific preferential binding? I've had problems with LMO/CMOs where not tagging particular celltypes (like some epithelial subtypes where we had 2-3 orders of magnitude lower tag counts).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-759587209:149,hash,hashsolo,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-759587209,1,['hash'],['hashsolo']
Security,"@phamidko I've modified your comment, and placed the output in the collapsed section below so I don't have to scroll so much on this issue. Unfortunately replies sent from email don't support markdown :(. <details>; <summary> phamidko's environment </summary>. ```; # This file may be used to create an environment using:; # $ conda create --name <env> --file <this file>; # platform: linux-64; _libgcc_mutex=0.1=main; anndata=0.7.1=pypi_0; attrs=19.3.0=py_0; backcall=0.1.0=py_0; bleach=3.1.4=pyh9f0ad1d_0; brotlipy=0.7.0=py37h8f50634_1000; ca-certificates=2020.4.5.1=hecc5488_0; cairo=1.16.0=hcf35c78_1003; certifi=2020.4.5.1=py37hc8dfbb8_0; cffi=1.14.0=py37hd463f26_0; chardet=3.0.4=py37hc8dfbb8_1006; cryptography=2.9.2=py37hb09aad4_0; cycler=0.10.0=pypi_0; decorator=4.4.2=py_0; defusedxml=0.6.0=py_0; entrypoints=0.3=py37hc8dfbb8_1001; fontconfig=2.13.1=h86ecdb6_1001; freetype=2.10.1=he06d7ca_0; get-version=2.1=pypi_0; gettext=0.19.8.1=hc5be6a0_1002; glib=2.64.2=h6f030ca_0; gmp=6.2.0=he1b5a44_2; h5py=2.10.0=pypi_0; icu=64.2=he1b5a44_1; idna=2.9=py_1; importlib-metadata=1.6.0=py37hc8dfbb8_0; importlib_metadata=1.6.0=0; ipykernel=5.2.1=py37h43977f1_0; ipython=7.13.0=py37hc8dfbb8_2; ipython_genutils=0.2.0=py_1; jedi=0.17.0=py37hc8dfbb8_0; jinja2=2.11.2=pyh9f0ad1d_0; joblib=0.14.1=pypi_0; json5=0.9.0=py_0; jsonschema=3.2.0=py37hc8dfbb8_1; jupyter_client=6.1.3=py_0; jupyter_contrib_core=0.3.3=py_2; jupyter_contrib_nbextensions=0.5.1=py37_0; jupyter_core=4.6.3=py37hc8dfbb8_1; jupyter_highlight_selected_word=0.2.0=py37_1000; jupyter_latex_envs=1.4.6=py37_1000; jupyter_nbextensions_configurator=0.4.1=py37_0; jupyterlab=2.1.1=py_0; jupyterlab_server=1.1.1=py_0; kiwisolver=1.2.0=pypi_0; ld_impl_linux-64=2.33.1=h53a641e_7; legacy-api-wrap=1.2=pypi_0; leidenalg=0.8.0=py37h43df1e8_0; libedit=3.1.20181209=hc058e9b_0; libffi=3.2.1=hd88cf55_4; libgcc-ng=9.1.0=hdf63c60_0; libgfortran-ng=7.3.0=hdf63c60_5; libiconv=1.15=h516909a_1006; libpng=1.6.37=hed695b0_1; libsodium=1.0.17=h516909a_0; li",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1183#issuecomment-620988575:545,certificate,certificates,545,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183#issuecomment-620988575,1,['certificate'],['certificates']
Security,"@wflynny `hashsolo` allows you to set a prior for your expected rate negatives, singlets, and doublets, which helps quite a bit with the issue you described despite modeling the log CMO counts as a normal distribution. Additionally, you can also add cell types if you've done cell-type annotation or even leiden clustering labels to help with cell type variability with CMO counts. This helped me quite a bit in kidney where NK cells had far fewer CMO counts than other cells despite being apparently live cells, e.g. good gene diversity and low mitochondrial gene percentage. @fidelram I'd be happy to add a visualization tool like you suggested if you have the code laying around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-759575072:10,hash,hashsolo,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-759575072,1,['hash'],['hashsolo']
Security,"Ahh, I think this is just because of the way I've tried to translate into to the Scanpy workflow. There's a sparsing step [at the start of the basic Scrublet workflow](https://github.com/swolock/scrublet/blob/67f8ecbad14e8e1aa9c89b43dac6638cebe38640/src/scrublet/scrublet.py#L100), but I'm [injecting](https://github.com/theislab/scanpy/blob/76814588696d00183e5f6f02e64f145dbcf944a0/scanpy/external/pp/_scrublet.py#L360) the normalised matrix and effectively skipping that step. I'll PR a sparsing check and conversion (and yes @ivirshup , I'll add a test :-) ), but the workaround is perfectly valid for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1645#issuecomment-788832663:291,inject,injecting,291,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1645#issuecomment-788832663,1,['inject'],['injecting']
Security,"Also two api thoughts:. For `sc.metrics.gearys_c(a: ""array"", b: ""array"")`, where `b` is 2d is expected to have a shape like: `(variable, number_of_cells)` – the ufunc shape signature would be: `(m,m)(n,m)->(n,)`. This is because it needs fast access to each variable, so they correspond to rows. Also the length of the returned array depends on the first axis of the passed input. Is this intuitive, or should the input be transposed?. Second, for `confusion_matrix`, I'm thinking I should make it singly dispatched on the first argument. This way if a dataframe is passed, the next two arguments could correspond to keys in that dataframe. Otherwise, vectors can be passed directly. Under that, these calls would be equivalent:. ```python; sc.metrics.confusion_matrix(adata.obs, ""sample_labels"", ""leiden""); sc.metrics.confusion_matrix(adata.obs[""sample_labels""], adata.obs[""leiden""]); ```. Right now it has the seaborn style argument handling shown at the top of this PR. I'm not sure that's really caught on in other packages or fits with scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-559928610:243,access,access,243,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-559928610,1,['access'],['access']
Security,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts; `; and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates; ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0); ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1273#issuecomment-653294084:195,hash,hashes,195,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273#issuecomment-653294084,1,['hash'],['hashes']
Security,"Awesome, just gave you write access to my fork.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027#issuecomment-968960149:29,access,access,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027#issuecomment-968960149,1,['access'],['access']
Security,"Can you try using the `palette` argument? After 1.3.1, Scanpy's plotting underwent quite some fundamental changes due to @fidelram. The code base improved a lot, there might be a few small issues, though. I had both `cmap` and `palette` as argument as I wanted users to choose a default for both continuous and categorical annotation. So if someone passes a `cmap` this only affects the continuous annotation, but for categoricals the `rcParams` default is used. Does this make sense? It might stop making sense when you provide lists to `cmap` and/or `palette`; in order to plot two different categoricals with two different palettes (which should be the default behavior at some point). Happy to discuss, whether we should depricate the `palette` argument and have the default access via `cmap`, that can be provided as a list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/286#issuecomment-430389498:779,access,access,779,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286#issuecomment-430389498,1,['access'],['access']
Security,"Cool! Great to have you with write access, @fidelram! :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/538#issuecomment-475421495:35,access,access,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538#issuecomment-475421495,1,['access'],['access']
Security,"Dear @wflynny. You're completely right, I added to the documentation a note that the whole topic is under debate ([here](http://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp)). Generally, Scanpy aims to enable access to different tools via the same data object and consistent interfaces so that users can conveniently try out different tools. The threshold for including an interface in Scanpy is low and only requires that a preprint/paper together with a solid GitHub repository exist.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189#issuecomment-405181668:228,access,access,228,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189#issuecomment-405181668,1,['access'],['access']
Security,"Dear Olivia,; as I understand, you get a; ```; KeyError: 'Wfdc18'; ```; when calling; ```; adata1 = adata[:, filter_result.gene_subset]; adata1.var.ix['Wfdc18']; ```; Right? So, 'Wfdc18' is no longer `adata1.var_names`. You can also check by typing; ```; print('Wfdc18' in adata1.var_names); ```; which should print `False`. Regarding plotting: as stated in the [basic tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) in box [22], you have to pass `use_raw=False` if you want to access `adata.X` in plotting if `adata.raw` has been set, otherwise it assumes that you want to plot the raw data.; ```; sc.pl.pca(adata1, color='Wfdc18', use_raw=False); ```; which will throw an error after filtering if 'Wfdc18' is no longer there. Does this help and explain what you observe?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/109#issuecomment-375856560:538,access,access,538,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109#issuecomment-375856560,1,['access'],['access']
Security,"Details: https://github.com/conda/conda/issues/9074#issuecomment-675552817. It won’t fix anything, but you should be able to give yourself symlink creation permissions on windows and just use `-s`: https://docs.microsoft.com/en-us/windows/security/threat-protection/security-policy-settings/create-symbolic-links",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1378#issuecomment-675523238:239,secur,security,239,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1378#issuecomment-675523238,3,"['secur', 'threat']","['security', 'security-policy-settings', 'threat-protection']"
Security,"Do you guys think this PR makes sense or is it too much to add R packages to the travis setup? @ivirshup @flying-sheep . There are bunch of useful R packages out there that will most likely not be reimplemented in Python (limma-voom pseudobulk DE, Liger, MAST etc.). I think it'd be cool to revive rtools and add access to such packages. I'm not sure if this is the right way but, any guidance is appreciated :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1271#issuecomment-666481854:313,access,access,313,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271#issuecomment-666481854,1,['access'],['access']
Security,"Duplicate of #2969, please subscribe to that one. I don’t have access to Windows, so unless someone else fixes this, it’s probably not going to get fixed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3228#issuecomment-2356349358:63,access,access,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228#issuecomment-2356349358,1,['access'],['access']
Security,"Found the `Dict[str, set]` option in the `typing` module. I've left the `dict` typing for the hidden functions though... I guess they're not user exposed anyway. I left the code in there for `inplace=True`... so when the pandas writing option is implemented, the `if inplace: raise NotImplementedError('...')` lines just need to be removed. Ready to be merged from my side now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/549#issuecomment-478158473:146,expose,exposed,146,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478158473,1,['expose'],['exposed']
Security,"Given the old function now raises an error, could you at least add a; FutureWarning (or np.exceptions.VisibleDeprecationWarning) indicating the; new function to be used? Thanks!. On Wed, 7 June 2023, 05:35 Philipp A., ***@***.***> wrote:. > Closed #2500; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500&g=ZWVjM2FjODk0ZjdmMTI1Nw==&h=N2Y4NmFmODU2ZTBlYjI1NzEzZDVlY2M3ZDQxMmVkMGVkZjY2OGMxZjEzMjZiMjNlODhmMGFhMTkwYjFmNGVjOQ==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > as not planned.; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23event-9456493371&g=ZGJmZGZhMzNmOTM5ZTgzYQ==&h=Y2JmZjM5MDc2MjMzNjM3MGQwMzk1MDYxZmE3MDZlYzBiNWEzYzdjMTMwNWY5MjgxNTU5YmQ3NDI0ZDBjNWRhZg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAWZ7ISUHUBPHQDLLCDXKBDOHANCNFSM6AAAAAAY3HAO3E&g=NDU3YTZlZTA4ZDE0MzNhZQ==&h=OWQzOWMxNDgxMjZkZGM3ZWUxMmQ1ZTFlN2UwNjI5ZDI4YjFmMDA3OGVmYjc5MTljZDVkMDlhMTE1YjRiODBmNg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895:1491,confidential,confidential,1491,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895,2,"['authoriz', 'confidential']","['authorized', 'confidential']"
Security,"Good! So, I'd really like to jump in and work on ann_matrix as well, if you think this is efficient. Of course, I don't want to mess up what you had in mind.; 1. yes, that's important - can i help?; 2. that's easy, simply put it in smp as a multicolumn object; 3. should be very easy as well, maybe recarray can directly be written with a single key, if not, one has to make the separation between str and float columns -> shall I attack that? see [this](https://github.com/theislab/scanpy/commit/ac79f8991953bf7f4ae33f243b384560c131a8f9#L650-L669) for how it was done with the ddata using its 'rowcat' attribute. should be straightforwardly adapted, right?*; ---; *sorry, I simply forgot to add readwrite.py on thursday night, which caused master to be non-working since then, of course. with readwrite.py added, master now works just fine. I guess the only change you made to utils.py was adding the AnnData.from_dict(...) in the function read()? so one could use readwrite.py from master within ann_matrix. or just create readwrite.py again by cutting out everything related to reading/writing from utils and pasting it into the new module readwrite.py.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1#issuecomment-277506990:431,attack,attack,431,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1#issuecomment-277506990,1,['attack'],['attack']
Security,"Great info about the figdir, thank you. I think it would be good to be able to access/save both plots, yes. I want this sort of pipeline script to be able to generate the same output for inspection as if the user were running the commands within Jupyter, and both display there. I don't think it's a critical thing though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/73#issuecomment-361946553:79,access,access,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73#issuecomment-361946553,1,['access'],['access']
Security,"Great to hear! Usually when there’s weird, site-specific errors, I say I can’t help because I don’t have SSH access and “my crystal ball is currently out of order”. Seems like my crystal ball worked just fine these days!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-668185146:109,access,access,109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-668185146,1,['access'],['access']
Security,"Great! Glad to have the discussion. I think there's a lot to talk about here, and it seems like a lot of it circles around how scanpy / anndata should interact with the greater ecosystem of tools for data analysis in Python. . I think there are conventions in `numpy` / `pandas` / `sklearn` / `matplotlib` ecosystems that result in a steep learning curve. I am very supportive of making that learning curve more accessible. I think it's great to provide helper functions that ""just work."" I think of the the filtering, normalization, and plotting functions especially. I also am very in favor of accessible tutorials and documentation and workshops that make using these tools approachable for a lay audience that may not understand the distinctions between various APIs. I've relied heavily of these kinds of resources as I've learned how to program within this ecosystem, and I've seen how helpful they can be for new users. What I find less desirable here is introducing incompatibilities or breaking conventions used in the broader `numpy` / `pandas` / `sklearn` / `matplotlib` ecosystems to lower the barrier to entry for scanpy. I agree with you that using numerics to represent clusters is counter-intuitive when these integers actually represent discrete labels. However, I don't find this to be a compelling reason to break the convention used in the broader data analysis ecosystem. If I want to compare louvain to spectral clustering in Python, I need to use `scanpy` and `sklearn` and I want this to ""just work"". I agree with you that `iloc` vs `loc` indexing is not straightforward to lay users, but I think it's a mistake to change the convention for how one indexes positionally vs using labels. _Especially when the underlying data structures is often a dataframe._ Instead of breaking these conventions, I would love to see the tool ""just work"" and make sure the tutorials and documentation make the conventions exceedingly clear for new users. I'm not sure what's the best way to res",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-583875715:412,access,accessible,412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-583875715,2,['access'],['accessible']
Security,"Has the format changed for all assays, or is this specific to visium HD?. And is there significant analysis that can be done on these without taking into account extra spatial information?. I would be inclined to say that the visium IO functions in scanpy should be deprecated/ replaced with a light wrapper around: `spatialdata_io.experimental.to_legacy_anndata(spatialdata_io.visium(*args, **kwargs))` or just accessing the AnnData from `spatialdata_io.visium_hd`. But if there is significant burden involved in the dependencies of `spatialdata`, then maybe we could implement something lighter here for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2973#issuecomment-2033981290:412,access,accessing,412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973#issuecomment-2033981290,1,['access'],['accessing']
Security,"Hello @ivirshup , I met the errors. ; ```python; from hashlib import sha256; import anndata as ad; from sklearn.decomposition import PCA. adata = ad.read_h5ad(""C:/Users/Park_Lab/Documents/PC1.h5ad""); print(sha256(adata.X).hexdigest()). pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0). print(sha256(pca.fit_transform(adata.X)).hexdigest()). ValueError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_3908/912381655.py in <module>; 8 pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); 9 ; ---> 10 print(sha256(pca.fit_transform(adata.X)).hexdigest()). ValueError: ndarray is not C-contiguous; ```; change to this, same error.; ```python; from hashlib import sha256; import anndata as ad; from sklearn.decomposition import PCA. adata = ad.read_h5ad(""C:/Users/Park_Lab/Documents/PC1.h5ad""); print(sha256(adata.X).hexdigest()). pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); a=adata.X.copy(order='C'). print(sha256(pca.fit_transform(a)).hexdigest()). ValueError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_3908/1058352035.py in <module>; 8 pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); 9 a=adata.X.copy(order='C'); ---> 10 print(sha256(pca.fit_transform(a)).hexdigest()). ValueError: ndarray is not C-contiguous",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021455251:54,hash,hashlib,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021455251,2,['hash'],['hashlib']
Security,"Hello! I'm running scanpy version 1.9.3 now and it seems that bug is still not fixed since it was found in scanpy 1.6.0. ; The situation is the same as in previous comments.; I created the new column in the adata.var with some names changed to the GenBank ID (I'm working with non-model species and the majority of gene names are non-informative like ""nbis-gene-11111"", but I am interested in some genes of actin that I deposited in GenBank. I would like to put GB accessions into the plot.) I created the column with following code: [""bob"" is the dataset name]. bob.var['GB_IDs'] = bob.var_names.copy(); ID_dict = {; ""nbis-gene-777"":""MT451954"",; ""nbis-gene-775"":""MT451955"",; ""nbis-gene-3785"":""MT451956"",; ""nbis-gene-3784"":""MT451957"",; ""nbis-gene-23114"":""MT451958"",; ""nbis-gene-25113"":""MT451959"",; ""nbis-gene-3783"":""MT518195""; }; bob.var['GB_IDs'].replace(ID_dict, inplace=True). After that GB_IDs column was present in the dataframe.; And then I tried to plot the dotplot:. dict = {; ""Actin 1"": [""nbis-gene-777""],; ""Actin 2"": [""nbis-gene-775""],; ""Actin 3"": [""nbis-gene-3785""],; ""Actin 4"": [""nbis-gene-3784""],; ""Actin 5"": [""nbis-gene-23114""],; ""Actin 6"": [""nbis-gene-25113""],; ""Actin 7"": [""nbis-gene-3783""]; }; dp=sc.pl.dotplot(bob, dict, ""scGate_multi"", dendrogram=False, return_fig=True, cmap='YlGnBu', gene_symbols='GB_IDs'). This results in an error: . ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); File ~/software/SAMap/lib/python3.9/site-packages/pandas/core/indexes/base.py:3791, in Index.get_loc(self, key); 3790 try:; -> 3791 return self._engine.get_loc(casted_key); 3792 except KeyError as err:. File index.pyx:152, in pandas._libs.index.IndexEngine.get_loc(). File index.pyx:181, in pandas._libs.index.IndexEngine.get_loc(). File pandas/_libs/hashtable_class_helper.pxi:7080, in pandas._libs.hashtable.PyObjectHashTable.get_item(). File pandas/_libs/hashtable_class_helper.pxi:7088, in pandas._libs.hashtable.PyObje",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1636#issuecomment-2048223788:465,access,accessions,465,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636#issuecomment-2048223788,1,['access'],['accessions']
Security,"Hello,. I am having a similar issue with `read_10x_mtx`, except my error is showing `Key Error: 1` and it is from 10X data we produced ourselves, do doesn't involve a GEO incompabitibility. Error below:. ```. >>> juno = sc.read_10x_mtx(path = ""../../Data/juno_influenza_pilot/hash_t_cells/umi_count""); Traceback (most recent call last):; File ""/home/daniel/miniconda/envs/scvi/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 3361, in get_loc; return self._engine.get_loc(casted_key); File ""pandas/_libs/index.pyx"", line 76, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 108, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 2131, in pandas._libs.hashtable.Int64HashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 2140, in pandas._libs.hashtable.Int64HashTable.get_item; KeyError: 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/daniel/miniconda/envs/scvi/lib/python3.8/site-packages/scanpy/readwrite.py"", line 481, in read_10x_mtx; adata = read(; File ""/home/daniel/miniconda/envs/scvi/lib/python3.8/site-packages/scanpy/readwrite.py"", line 552, in _read_v3_10x_mtx; var_names = genes[1].values; File ""/home/daniel/miniconda/envs/scvi/lib/python3.8/site-packages/pandas/core/frame.py"", line 3455, in __getitem__; indexer = self.columns.get_loc(key); File ""/home/daniel/miniconda/envs/scvi/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 3363, in get_loc; raise KeyError(key) from err; KeyError: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-927497782:741,hash,hashtable,741,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-927497782,2,['hash'],['hashtable']
Security,"Here are some updates:; - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors!; - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1138619110:77,expose,exposed,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-1138619110,1,['expose'],['exposed']
Security,"Here it is:. ```; [I 2024-02-06 12:45:46.915 ServerApp] Kernel started: 9fd93000-73b0-4abb-8cf1-505bec376572; 0.00s - Debugger warning: It seems that frozen modules are being used, which may; 0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off; 0.00s - to python to disable frozen modules.; 0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.; [I 2024-02-06 12:45:47.931 ServerApp] Connecting to kernel 9fd93000-73b0-4abb-8cf1-505bec376572.; [I 2024-02-06 12:45:47.936 ServerApp] Connecting to kernel 9fd93000-73b0-4abb-8cf1-505bec376572.; [I 2024-02-06 12:45:47.946 ServerApp] Connecting to kernel 9fd93000-73b0-4abb-8cf1-505bec376572.; [I 2024-02-06 12:45:52.822 ServerApp] Creating new directory in; [W 2024-02-06 12:46:00.673 ServerApp] delete /Untitled Folder; [I 2024-02-06 12:46:08.209 ServerApp] Kernel shutdown: 9fd93000-73b0-4abb-8cf1-505bec376572; [W 2024-02-06 12:46:08.330 ServerApp] delete /Untitled.ipynb; [I 2024-02-06 12:46:15.481 ServerApp] Kernel started: 54f6e9a0-500c-48ed-8d4d-49943b2f107c; 0.00s - Debugger warning: It seems that frozen modules are being used, which may; 0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off; 0.00s - to python to disable frozen modules.; 0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.; [I 2024-02-06 12:46:16.520 ServerApp] Connecting to kernel 54f6e9a0-500c-48ed-8d4d-49943b2f107c.; [I 2024-02-06 12:48:15.364 ServerApp] Saving file at /Tests/scanpytutorial/Untitled.ipynb; [I 2024-02-06 12:49:18.462 ServerApp] AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports; [W 2024-02-06 12:49:18.462 ServerApp] kernel 54f6e9a0-500c-48ed-8d4d-49943b2f107c restarted; [I 2024-02-06 12:49:18.468 ServerApp] Starting buffering for 54f6e9a0-500c-48ed-8d4d-49943b2f107c:df20bfae-3e78-44d6-b98f-42f032c621cb; [I 2024-02-06 12:49:18.476 ServerApp] Connecting to kernel 54f6e9a0-500c-4",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2840#issuecomment-1929361492:407,validat,validation,407,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2840#issuecomment-1929361492,1,['validat'],['validation']
Security,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476588843:673,access,accessible,673,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476588843,1,['access'],['accessible']
Security,"Hey!; I'm a member of g:Profiler (biit.cs.ut.ee/gprofiler) development team and was scanning through web to find services that might depend on us. . We recently went live with an extensive update which might break some of the previous pipelines and wrappers. . All the existing Python and R packages should work, however they are linking to an archived data version and they don't access the most up-to-date data from g:Profiler due to the new API etc. . We have already created a new R package that corresponds to the new API, Python package is still in the progress. . I just wanted to let you know and please feel free to contact me if I can be of any help. All the best,; Liis",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467#issuecomment-466359205:381,access,access,381,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-466359205,1,['access'],['access']
Security,"Hi @JonathanShor,. you don't need to create a custom API. One point of Scanpy is to provide convenient access via `anndata` to many single-cell packages around. The only thing needed for that is to provide a very simple interface like [this](https://github.com/theislab/scanpy/blob/master/scanpy/tools/phate.py#L8-L145) or [this](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/mnn_correct.py#L4-L104) or several of the other tools... Simply click on the GitHub links in the Scanpy docs... If your package works reliably, both the restrictions you mention should in principle not prevent adding your package. Of course, in the future, we want all elements of Scanpy to scale to millions of cells, not just the core tools. But for a lot of people, it's right now helpful to have a large number of tools available also for relatively small datasets. The only problem is to avoid cluttering the Scanpy API with virtually any tool there is. Tools in the API should have passed a certain quality check. Doublet detection is a difficult problem. Already last autumn, we played around with @swolock 's tool but didn't end up using it - it was good, but in our situation, it didn't seem to apply (are you eventually going to distribute a package for it @swolock ?). I myself quickly wrote a tool, too, but it didn't work well. Just yesterday, [this](https://www.biorxiv.org/content/early/2018/06/20/352484) appeared. Then there is also [this](https://www.biorxiv.org/content/early/2018/04/04/234872) on ""empty cell detection"". There are more tools out there, I think... What I mean is: computationally detecting doublets is still something where the field has not agreed on a consensus. Just like batch correction. Therefore, I would not add a tool `tl.doublet_detection` or `tl.detect_doublets` to the API at this stage. There are two options. Either we create a `.beta` module of the API for tools that don't even have a preprint and add your tool and similar cases in the future there. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-399367409:103,access,access,103,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-399367409,1,['access'],['access']
Security,"Hi @a-munoz-rojas, diffxpy will be public very soon, once we finished running all benchmarks that we need for validation. I would be happy to help you set it up if you still want to give it a go then!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/159#issuecomment-421157493:110,validat,validation,110,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159#issuecomment-421157493,1,['validat'],['validation']
Security,"Hi @alexlenail . Re ; > I think it might be enough to leave it to random chance. As it is now, `sc.pl.umap` works with 70 colors, which aren't easily distinguishable -- but neighboring clusters seem to always be distinguishable. . How can I access the 70 colors? I have a plot with 54 clusters but they're all colored gray.; ![umap_10x_gse_leiden_bc_0001](https://github.com/scverse/scanpy/assets/32474661/dbc9781e-30a0-4262-b850-5af977a3dd24)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2313#issuecomment-1837720757:241,access,access,241,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313#issuecomment-1837720757,1,['access'],['access']
Security,"Hi @brianpenghe ; I've been fiddling with this a little bit and this may be helpful for your request if you haven't come across it already, there is a 'categories_ordered' field in the dendrogram information that you can access as ; adata.uns[DENDROGRAM_NAME]['categories_ordered']; which I think gives what you would want",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2016#issuecomment-980480553:221,access,access,221,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2016#issuecomment-980480553,1,['access'],['access']
Security,"Hi @fidelram, good to see you :smile:. I was working on the Galaxy integration. I tested that with the `1.3.2` version from Bioconda. I tested with adata from krumsiek11. - For colors, I tried with `sc.pl.scatter(adata=adata, x='EKLF', y='Cebpa', color=['EgrNab', 'cJun']) and I got the error:. ```; ...; and (color is None or color in adata.obs.keys() or color in adata.var.index)):; File ""path/to/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 2035, in __contains__; hash(key); TypeError: unhashable type: 'list'; ```. - For components: the command was . ```; sc.pl.scatter(; adata=adata,; x='EKLF',; y='Cebpa',; color='EgrNab',; layers=('X', 'X', 'X'),; use_raw=False,; sort_order=True,; components='all',; projection='2d',; legend_loc='right margin',; legend_fontsize=1,; legend_fontweight='normal',; palette='viridis',; frameon=True,; right_margin=1.0,; size=1.0,; show=False,; save='.png'); ```; and the error:. ```; components = np.array(components).astype(int) - 1; ValueError: invalid literal for int() with base 10: 'all'; ```. Did I put the parameters in a wrong way?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/311#issuecomment-431284136:485,hash,hash,485,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311#issuecomment-431284136,1,['hash'],['hash']
Security,Hi @njbernstein . I'm using scanpy version 1.10.2 and when I tried to run hashsholo but it's not working and I'm not sure why. ![image](https://github.com/user-attachments/assets/3a542123-f7b1-432d-9898-cb25ed52bd51). Any suggestions? Thank you. Edit: htos is just the list with he two hashtag names shown in the obs,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-2304281523:74,hash,hashsholo,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-2304281523,2,['hash'],"['hashsholo', 'hashtag']"
Security,"Hi @pinin4fjords! I understand by integration, you mean access under the scanpy api. We try to advance the scanpy environment by modular extensions, which are packages with their own API, that also work on adata instances. This is currently what diffxpy is and there are no plans to collect all scanpy-related packages under `sc.*` as far as I am aware.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1955#issuecomment-884979935:56,access,access,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955#issuecomment-884979935,1,['access'],['access']
Security,"Hi Alex, ; The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`; , I get the following error. The igraph I am using is V 0.1.11.; Many thanks; Hashem; `DeprecationWarning Traceback (most recent call last); <ipython-input-20-fb44185f2d28> in <module>(); 1 ; ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True); 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy); 78 directed = False; 79 if not directed: logg.m(' using the undirected graph', v=4); ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed); 81 if flavor == 'vtraag':; 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed); 41 def get_igraph_from_adjacency(adjacency, directed=None):; 42 """"""Get igraph graph from adjacency matrix.""""""; ---> 43 import igraph as ig; 44 sources, targets = adjacency.nonzero(); 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(); 6 __license__ = ""MIT""; 7 ; ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, ""; 9 ""this visualization library has been renamed to ""; 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324587457:264,Hash,Hashem,264,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324587457,4,"['Hash', 'hash']","['Hashem', 'hashem']"
Security,"Hi Alex,; Thanks for your very prompt reply. The problem is solved.; Looking forward using it.; Hashem",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/29#issuecomment-321769746:96,Hash,Hashem,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/29#issuecomment-321769746,1,['Hash'],['Hashem']
Security,"Hi I am having a similar issue where I would like to set the tick locations on the colorbar. Using similar code as above. ```; ax = sc.pl.tsne(adata, color = 'gene', show=False); fig = plt.gcf(); cbar_ax = fig.axes[-1]; cbar_ax.set_yticks([0,1]); ```; I get the following error 'UserWarning: Use the colorbar set_ticks() method instead'. How can I access the colorbar specifically?. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/337#issuecomment-726207918:348,access,access,348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/337#issuecomment-726207918,1,['access'],['access']
Security,"Hi Ilan, thanks for your interest. One of the main advantages of Marsilea is the flexibility for layout plots and adding/removing components compared to the pre-defined visualization APIs in Scanpy. From my perspective, there could be two ways of integration: . 1) Reimplement some of the visualization APIs in scanpy using Marsilea, but we don't expose Marsilea to the user. You will always have a plot with known rendered size and fixed layout compared to directly using matplotlib. This could significantly reduce the code base complexities on the scanpy side, so less maintenance work. 2) Exposing the Marsilea API, we can create a visualization object that simulates the Marsilea API but is tailored specifically for `AnnData`. Maybe include some data transformation and aggregation functions that the user could directly apply during visualization. But this design doesn't make much difference compared to directly using Masilea as shown in the [notebook](https://scanpy.readthedocs.io/en/stable/how-to/plotting-with-marsilea.html).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693:347,expose,expose,347,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693,1,['expose'],['expose']
Security,"Hi Joshua, can you upload an example dataset somewhere? So that I can reproduce the figure above? I'm confident that I can speed this up...; PS: Still consolidating all the gene correlation stuff... Everything works, but we do not want to expose things to the user that have not been checked 3 times... in particular the conventions need to be intuitive etc.; PPS: The new cell cycle example could interest you:; https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html; https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes_cell_cycle.html; Both link to the notebook in the ""Examples"" section; https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/85#issuecomment-365873899:239,expose,expose,239,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85#issuecomment-365873899,1,['expose'],['expose']
Security,"Hi, . Thank you for your interest in scanpy and for raising your question here!. It looks like you are interested in getting the results of `sc.tl.rank_genes_groups`.; For this, we recommend using `sc.get.rank_genes_groups` - you can find more about scanpy’s getters [here](https://scanpy.readthedocs.io/en/stable/api.html#module-scanpy.get). This might look for example like this:. ```py; import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(pbmc, groupby=""louvain"", pts=True, use_raw=True). dedf = sc.get.rank_genes_groups_df(pbmc, group=""0""); ```. By accessing the `.uns` as you outlined, just using the ordering of the pts column might not match the ordering of the sorted genes.; This behaviour is subject to updates in the future - in any case `sc.get.rank_genes_groups` is the way to go here :). I hope this helps?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2628#issuecomment-1742964494:584,access,accessing,584,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628#issuecomment-1742964494,1,['access'],['accessing']
Security,"Hi, after release 1.6 this is now partially possible. If you set the parameter `return_fig=True` then you have access to the `style()` method (see: https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.DotPlot.style.html#scanpy.pl.DotPlot.style). ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; ax_dict = sc.pl.dotplot(adata,marker_genes,groupby='bulk_labels', return_fig=True).style(grid=True).show(); ```; ![image](https://user-images.githubusercontent.com/4964309/90759033-2a647600-e2e0-11ea-86e4-2a0e060955ad.png). What is not possible is to change the linewidth.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1371#issuecomment-677516048:111,access,access,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1371#issuecomment-677516048,1,['access'],['access']
Security,"Hm, I researched a bit more. psutil doesn't seem to cause problems and also, this has not been a problem within Scanpy for any user up to now. If you start a terminal with `python` and type; ```; import psutil; psutil.process_iter(); ```; does this throw an error? I'd really like to know what's going on. If you want a quick fix; you can simply comment out line 773 in your file `/ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py`; this should cause no problem for your applications.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324476821:392,hash,hashem,392,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324476821,1,['hash'],['hashem']
Security,"Hm, `n_counts` and `total_counts` is of course non-sense. Scanpy tries to adapt the `n_...` convention in scikit-learn and statsmodels for anything that is a number. We'll soon expose the quantile normalization preprocessing function to the users in a proper way. Then we'll have 95%-quantile counts vs. total counts. Then it starts making sense to use the notion `total_`. So, in the light of that, we could think about moving there. Yes, we'd deprecate old names and output a warning, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/316#issuecomment-435731327:177,expose,expose,177,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316#issuecomment-435731327,1,['expose'],['expose']
Security,"Hmm, that's strange. I use the generated token to connect to remote notebook servers pretty frequently. Any ideas why it isn't working for you?. Here's the workflow I follow. First, on the machine you'd like to work on, in the conda environment you want to use:. ```; jupyter notebook --no-browser --port=8889; ```. This will start the notebook server and report the security token. On my machine I create an ssh tunnel to the server with the following command (replacing `<remote_user>` and `<remote_host>` with your info):. ```; ssh -N -L 8889:localhost:8889 <remote_user>@<remote_host>; ```. Now I point my browser to `localhost:8889` and will be connected to the remote server, where it'll ask for the token. After pasting that in I'm connected.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/561#issuecomment-477403279:367,secur,security,367,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477403279,1,['secur'],['security']
Security,"How pandas does this: there's branch for a minor version, e.g. `1.1.x`. Bugfixes get back ported to this branch, and releases are tagged here. There is automation of back porting through [meeseeksbox](https://meeseeksbox.github.io). We might have to request access for this?. Julia does something pretty similar, except it looks like all back ports are done at once in a PR, instead of continuously. This is a bit more manual, but requires less setup. Both of these systems use tags to mark which PRs need back porting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1399#issuecomment-685401364:258,access,access,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1399#issuecomment-685401364,1,['access'],['access']
Security,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console; $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no; Numba function called from a non-threadsafe context. Try installing `tbb`.; Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads.; - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):; File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper; File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _; File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper; File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get; File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task; File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task; File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks; File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", li",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3335#issuecomment-2457625478:628,access,access,628,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335#issuecomment-2457625478,3,['access'],"['access', 'accessed']"
Security,"I can validate this problem. Actually, any value from C0 to C9 causes the problem but each case gets a different color. ![image](https://user-images.githubusercontent.com/4964309/44329411-a82ce700-a464-11e8-940c-c85a67bf579a.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/232#issuecomment-414240268:6,validat,validate,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/232#issuecomment-414240268,1,['validat'],['validate']
Security,"I completely understand but I’m travailing and have no access to my data. but it’s the basic function and you can use any anndata object and the groupby argument on any observation. Sent from my iPad. On 5. Jan 2023, at 15:11, Lukas Heumos ***@***.***> wrote:. ﻿. By a minimal working example I mean something that we can copy and paste and reproduce your result directly. The easier you make it for us the more likely we can dedicate some time to look at your issue. Thanks. —; Reply to this email directly, view it on GitHub<https://github.com/scverse/scanpy/issues/1988#issuecomment-1372263677>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AOGNBODKUC3S3SZC32VD3TLWQ3JBVANCNFSM5DB5VLAQ>.; You are receiving this because you authored the thread.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1988#issuecomment-1372293439:55,access,access,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988#issuecomment-1372293439,1,['access'],['access']
Security,"I don't know about Isaac, but our HPC nodes don't like long-running; jypyters on them. On Tue, Sep 18, 2018 at 9:32 AM, Alex Wolf <notifications@github.com> wrote:. > OK, got it! So you're actually moving the data between your HPC and your; > laptop? Why does the typical forwarding via ssh -L ... that I think most; > people use for accessing the server running jupyter lab, notebooks,; > tensorboard etc. locally doesn't work for you (e.g. here; > <http://benjlindsay.com/blog/running-jupyter-lab-remotely/>)? I can do; > all the visualizations on the remote infrastructure and never have to move; > around data, which is nice. ;); >; > Of course, though, the backed functionality of Scanpy should become fully; > stable.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/263#issuecomment-422394446>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AAS-TQtLnSFiZOCsL0oqDgJcrzo1VJXJks5ucPXugaJpZM4WokmY>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/263#issuecomment-422402199:334,access,accessing,334,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/263#issuecomment-422402199,1,['access'],['accessing']
Security,I don't know why the tests related to violin plots fail. I assume that it has to do with different libraries that produce slightly different shapes. But without access to the images generated during the testing would be difficult to say.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/228#issuecomment-411070568:161,access,access,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/228#issuecomment-411070568,1,['access'],['access']
Security,"I downloaded the github source archive at the 1.8.2 tag. The build process applies a few patches viewable [here](https://salsa.debian.org/med-team/python-scanpy/-/tree/master/debian/patches). One is a small change to some R code, and the other is I marked several more tests as needs internet because the Debian builds in an environment without network access and those ultimately tried to download something. (And it's really unclear if we can legally redistributed the 10x pbmc3k dataset.). The Debian build file is (here)[https://salsa.debian.org/med-team/python-scanpy/-/blob/master/debian/rules] though mostly it lets you see what tests I was skipping because of missing dependencies. Also if I set a color like in_tissue, or array_row the data shows up. I can paste the full build log if you'd like but this is the dependencies installed and the environment variables. . ```; Build-Origin: Debian; Build-Architecture: amd64; Build-Date: Sun, 14 Nov 2021 20:11:26 +0000; Build-Path: /<<PKGBUILDDIR>>; Installed-Build-Depends:; adduser (= 3.118),; adwaita-icon-theme (= 41.0-1),; autoconf (= 2.71-2),; automake (= 1:1.16.5-1),; autopoint (= 0.21-4),; autotools-dev (= 20180224.1+nmu1),; base-files (= 12),; base-passwd (= 3.5.52),; bash (= 5.1-3.1),; binutils (= 2.37-8),; binutils-common (= 2.37-8),; binutils-x86-64-linux-gnu (= 2.37-8),; blt (= 2.5.3+dfsg-4.1),; bsdextrautils (= 2.37.2-4),; bsdutils (= 1:2.37.2-4),; build-essential (= 12.9),; bzip2 (= 1.0.8-4),; ca-certificates (= 20211016),; coreutils (= 8.32-4.1),; cpp (= 4:11.2.0-2),; cpp-11 (= 11.2.0-10),; dash (= 0.5.11+git20210903+057cd650a4ed-3),; dbus (= 1.12.20-3),; dbus-bin (= 1.12.20-3),; dbus-daemon (= 1.12.20-3),; dbus-session-bus-common (= 1.12.20-3),; dbus-system-bus-common (= 1.12.20-3),; dbus-user-session (= 1.12.20-3),; dconf-gsettings-backend (= 0.40.0-2),; dconf-service (= 0.40.0-2),; debconf (= 1.5.79),; debhelper (= 13.5.2),; debianutils (= 5.5-1),; dh-autoreconf (= 20),; dh-python (= 5.20211105),; dh-strip-no",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616:353,access,access,353,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616,1,['access'],['access']
Security,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```; gene1 = 'XXX'; gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &; (adata.raw[:,'{}'.format(gene2)].X.todense() > 0); ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/490#issuecomment-587473372:183,access,access,183,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-587473372,1,['access'],['access']
Security,"I like the idea for the ""nice data accessors module""! Maybe `sc.get`? `sc.get.obs_values(adata, ...)`, `sc.get.neighbors(adata, ...)`. We'd definitely have to be sure we're returning a nice object. | If you say that diffxpy has a good solution, why should we build a new one? Can't we just use their solution?. I think this would involve throwing away recarrays, unless someone wants to write a converter (not me). I'm also not so sure how mature/ stable `diffxpy` is, but Theis lab people might have a better sense of that?. | That being said: it's likely that we'll continue to choose representations for on-disk. I like that the current representations are pretty easy to read in other languages as they're mostly standard hdf5 types. I think there are definitely cases where it make sense to break cross-compat, like complicated datastructures for a specific package (an index, for example). | If one uses xarray or dataframes, one has to think about how this gets written to disk. My impression is `xarray` were designed to be similar to `netCDF` files, which [are a subset of hdf5](https://www.unidata.ucar.edu/software/netcdf/docs/faq.html#How-can-I-convert-netCDF-4-files-into-HDF5-files). `pandas`, on the other hand, has a pretty opaque `hdf5` representation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/562#issuecomment-487830709:35,access,accessors,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487830709,1,['access'],['accessors']
Security,"I think it shows us some strategy, yes. I can't claim to understand what each line you did there does but I have a notebook open now and am trying to step through it. I think part of the issue here is we're wanting to store aggregate values like means within adata so that they don't have to be recomputed every time they are needed. Web interfaces are being driven off these files, so rapid access is preferred over storage concerns. . If, in the example of datasets with technical replicates, we almost always are only interested in the mean values across replicates. So if our input is like this:. ![screenshot from 2018-04-11 15-11-07](https://user-images.githubusercontent.com/330899/38640690-9b7c41a8-3d9a-11e8-9b40-b9763a3df422.png). Simple demo with 4 genes, 2 conditions, and 3 replicates of each condition. Does one make this exact matrix adata.X? . ![screenshot from 2018-04-11 15-16-11](https://user-images.githubusercontent.com/330899/38640934-4a25562c-3d9b-11e8-82eb-eb7811463fa4.png). Or should the means be calculated and stored as adata.X with individual replicates stored as separate matrices of the same size, like adata.uns['rep1'], adata.uns['rep2'], ... etc. This is specifically the part I was asking about regarding conventions, as it seems there must already be a convention for storing technical replicates and their aggregate values (mean, stddev, etc.). I think the examples given with values like 0 and 1 are a bit confusing because I can't tell if you're using that as a proxy for column names or are they index positions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/106#issuecomment-380582298:392,access,access,392,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106#issuecomment-380582298,1,['access'],['access']
Security,"I think making access to entires in `obsm` for plotting functions is a good idea. This is definitely on our roadmap, and has started to be implemented (https://github.com/theislab/anndata/pull/342), but is a bit stalled at the moment. Am I correct in understanding that being able to things like:. ```python; adata.obsm[""pathways""] = pathway_dataframe_func(adata); sc.pl.heatmap(adata, groupby=""leiden"", obsm=""pathway""); sc.pl.umap(adata, color=[""pathways/pathway-1"", ""leiden""]); ```. would solve most of the barriers you're facing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1724#issuecomment-794802960:15,access,access,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724#issuecomment-794802960,1,['access'],['access']
Security,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks.; code. ```; x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'; Train_name = 'Baron'; Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'; Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata); all_adata = all_adata.concatenate(test_adata); ```. error; ```; AnnData object with n_obs × n_vars = 2133 × 22757; AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>; File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate; out.var.columns.str.extract(pat, expand=False); File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__; accessor_obj = self._accessor(obj); File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__; self._inferred_dtype = self._validate(data); File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate; raise AttributeError(""Can only use .str accessor with string values!""); AttributeError: Can only use .str accessor with string values!; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3261#issuecomment-2399331404:1070,access,accessor,1070,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261#issuecomment-2399331404,5,['access'],['accessor']
Security,"I think there's definitely room for more plotting libraries in the ecosystem, but have some doubts about whether all needs can be met by one library. I personally use `seaborn`/ `matplotlib`, `bokeh`, `datashader`, and `altair` for different cases. I also think making a good plotting API is exceedingly difficult, especially if you target both high and low level use cases. I would note that the plotting code in scanpy feels like some of the most maintenance intensive code in the library. > provides helper functions for handling colors, saving figures, etc. We can do a bit more of this here. But of course, much of it would end up being `matplotlib` specific. > encourages a consistent plotting API (e.g. by defining abstract base classes). I'd be interested in hearing specific thoughts on this. I've personally been thinking it would be nice to lean on `seaborn` plotting classes more heavily here, potentially contributing features upstream. Here's one example https://github.com/mwaskom/seaborn/issues/2487 of a feature which could fit the `AnnData` data model nicely. > there is quite some duplicated code in the plotting section. We'd definitely like to reduce the amount of duplicated code, which is what drove the addition of `sc.get`. This seems to be working out internally, if slowly. > All the scanpy helper functions for plotting (e.g. savefig_or_show, _set_color_for_categorical_obs etc.) are private scanpy functions. I'd like to move towards stabilizing this. I'm not sure how much we'd want to provide plotting library specific code, vs. more generic helpers. Right now the most obvious addition is `_set_color_for_categorical_obs`, which I'd also like to make accessible through `sc.get`. Adding `groupby` support to `anndata` would help a lot here too (https://github.com/theislab/anndata/issues/556). `save_fig_or_show` is something that I don't think we should export, and may need a rework (#1508).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1832#issuecomment-838305749:1683,access,accessible,1683,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832#issuecomment-838305749,1,['access'],['accessible']
Security,"I wanted to report success here. I had to change your references to var_names above to obs_names but got it working after that. Now I just need to figure out how to access the plot customization methods so I can clean it up. The labels are all blurred together, for example.; ![screenshot from 2018-03-06 11-16-16](https://user-images.githubusercontent.com/330899/37047580-01c7b8e2-2131-11e8-9bb7-d060bfc6d0d6.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/85#issuecomment-370859955:165,access,access,165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85#issuecomment-370859955,1,['access'],['access']
Security,"I was referring to both the instability and what i understood to mean non-robustness to different datasets. But it seems a ""use case"" is an analytical step here, rather than a particular dataset to be analysed. That makes it a lot better, and it means there is work to be done but a general best practice conclusion would be reachable. . In that case it's only the instability of the algorithm that is the issue per dataset. And in the case where you're doing exploratory analysis for a new dataset, you don't typically have a validation dataset, which makes this pretty challenging for end users of the method. Enrichment could be a way forward I guess... I'm not the biggest fan of using enrichment results as a measure for success though. Enrichment results still require quite a bit of interpretation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/941#issuecomment-560323107:527,validat,validation,527,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941#issuecomment-560323107,1,['validat'],['validation']
Security,I'd like to tackle this. Can someone tell me how we want to store hashing data in an `anndata` object?; @flying-sheep @fidelram . I'll take back up porting hashsolo to scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-698009524:66,hash,hashing,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-698009524,2,['hash'],"['hashing', 'hashsolo']"
Security,"I'm happy to implement my method, when we have a consensus. https://github.com/calico/solo/blob/master/solo/hashsolo.py. https://www.biorxiv.org/content/10.1101/841981v1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-561856270:108,hash,hashsolo,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-561856270,1,['hash'],['hashsolo']
Security,"I'm not super into the idea of supporting much beyond exactly what `cellranger` outputs for these functions. We expect very specific things from these files, and I think it's difficult to say what's a reasonable amount of modification once we start supporting any. I'd be open to exposing some of the internally used functions so it's easier to write a custom reading function here, if that's a reasonable alternative to you? I think all that we'd really expose here is a faster [`scipy.io.mmread`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.mmread.html#scipy.io.mmread), since the other files are read with `pd.read_csv`. --------------------. @LuckyMD . > At some point scanpy switched to non-gzipped files by default as file I/O is faster that way. Reading files quickly was regarded as a more important that storage minimization. I believe this only applies to writing `h5ad`. But really, `lzf` is probably ideal here. It's much faster than `gzip`, has similar compression, and is barely slower than no compression. But `lzf` is vendored with `h5py` not `hdf5` (last I checked), so you might not be able to read a file compressed that way from `R` or something else.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1731#issuecomment-803518963:455,expose,expose,455,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731#issuecomment-803518963,1,['expose'],['expose']
Security,"I've figured out what was causing my error. The scanpy function to read in `features.tsv.gz` expects three columns: `['gene_symbols, 'gene_ids', 'feature_types']`; Where 'feature types' is a text string like 'Gene Expression' and usually repeated along the whole length of the file.; The file I was reading in was from HTO data and only had one column:. > Hashtag1-GTCAACTCTTTAGCG; > Hashtag2-TTCCGCCTCTCTTTG; > Hashtag3-AAGTATCGTTTCGCA; > unmapped. So if others run into this same error, just add in some extra columns to the `features.tsv` file so it doesn't error out when looking for the extra columns. Something like this (different features file):. >RP11-34P13.7	RP11-34P13.7	Gene Expression; >FO538757.3	FO538757.3	Gene Expression; >FO538757.2	FO538757.2	Gene Expression; >AP006222.2	AP006222.2	Gene Expression; >RP4-669L17.10	RP4-669L17.10	Gene Expression. It would also be helpful if scanpy would validate the number of columns at the start. At the moment it looks like it reads in the whole `.mtx` file before trying to map the feature names and producing this error, so it takes a while to fail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-1286404697:906,validat,validate,906,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-1286404697,1,['validat'],['validate']
Security,"I've found a workaround, when I downgrade to `anndata=0.6.22.post1` (still with `scanpy==1.4.5.post2`), it generates an output with `paga_path` but also this warning:. ```; FutureWarning: In anndata v0.7+, arrays contained within an AnnData object will maintain their dimensionality. For example, prior to v0.7 `adata[0, 0].X` returned a scalar and `adata[0, :]` returned a 1d array, post v0.7 they will return two dimensional arrays. If you would like to get a one dimensional array from your AnnData object, consider using the `adata.obs_vector`, `adata.var_vector` methods or accessing the array directly.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-583346609:579,access,accessing,579,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-583346609,1,['access'],['accessing']
Security,"I've just merged initial pre-commit stuff via #1684 (just black). Once the doc builds propagate, there will be a section under: ""Getting set up"" in the dev docs on how to install. I would like to see a `flake8` PR, though it might take a bit of time to hash out configuration. Maybe @giovp or @Zethson would be interested in looking into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-784875825:253,hash,hash,253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-784875825,1,['hash'],['hash']
Security,"I've ran into this before (`sc.read_10x_mtx()` has the same default of course). One possible issue with defaulting to `gex_only=False` is that someone might accidentally run a 'regular pipeline' with multi-modal data, e.g. log-normalizing RNA+protein+cell hashing counts together without first subsetting the adata based on `.var[""feature_types""]`. By contrast, anyone who know they have multi-modal data would hopefully notice the missing the data with `gex_only=True`. Either way, logging warnings sounds good.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1949#issuecomment-879247652:256,hash,hashing,256,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949#issuecomment-879247652,1,['hash'],['hashing']
Security,"If someone figures out a simple workaround and submits a PR, we'll merge it, but we only support the newest bugfix releases ourselves. You should definitely tell your sysadmin to update to Python 3.5.4, there are security holes in your version as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/561#issuecomment-477128825:213,secur,security,213,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477128825,1,['secur'],['security']
Security,"If you update to more recent releases, you won't be able to access elements of `obsm` or `varm` like an attribute. It should all be through `.__getitem__` (e.g. `adata.obsm[""X_tsne""]`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/778#issuecomment-522895754:60,access,access,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778#issuecomment-522895754,1,['access'],['access']
Security,"In https://github.com/scverse/scanpy/pull/2220, DocSearch was removed from the `latest` docs. Our current theme would probably support it, so we could re-introduce it (https://github.com/pydata/pydata-sphinx-theme/issues/795). @ivirshup how do I get access to our DocSearch account?. PS: There’s more discussion about search plugins supported by our theme here: https://github.com/pydata/pydata-sphinx-theme/issues/202",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2763#issuecomment-1825412324:250,access,access,250,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2763#issuecomment-1825412324,1,['access'],['access']
Security,"In supplementary figure 9 of our paper, I did a light comparison of tools using the demuxlet data as ground truth: https://www.cell.com/cms/10.1016/j.cels.2020.05.010/attachment/040c239d-1e70-42a4-8974-9fbd75c65551/mmc1.pdf; Which I think is a fine first stab at getting at this comparison, but it could be better. Hashsolo performance was comparable with other methods but is able to recover cell types with lower CMO counts. . I think that sounds great. That's an issue we had as well, but I noticed it occurring for NK cells in kidney; ![Screen Shot 2021-01-13 at 9 18 30 AM](https://user-images.githubusercontent.com/6864886/104486266-5d095680-5580-11eb-971e-c882063f2a45.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-759597008:315,Hash,Hashsolo,315,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-759597008,1,['Hash'],['Hashsolo']
Security,"It looks great!; ![image](https://user-images.githubusercontent.com/25887487/90914608-7990d080-e3de-11ea-81ed-15fdf5c3be80.png). One first improvement could be to expose a parameters that explicitly ask for the number of rings in the neighbors (first 6 ring etc.). Btw, how do I push to this specific PR from my local repo? I managed to pull it but can't figure out a way to push here and not on my fork.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-678387240:163,expose,expose,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-678387240,1,['expose'],['expose']
Security,It seems that something wrong happened for the Seurat meta slot. The code told that this error happened when AnnData tried to construct obs attribute. ; I am afraid this beyond my scope since I cannot access your data for further debugging,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-487647761:201,access,access,201,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487647761,1,['access'],['access']
Security,"It's definitely been discussed and is something I would like to do, but it has not been implemented. I think the main blocker here is that it would be a lot of effort to go through every plotting function and make it work with that structure. A good step towards this would be normalizing access to colors through a single function. In general, I think the colors could be stored as something like:. ```; .uns[""colors""][dim][key] = {cat1: color1, ...}; ``` . though I'm open to other solutions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1340#issuecomment-666128751:289,access,access,289,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340#issuecomment-666128751,1,['access'],['access']
Security,"It's more along the line of selecting number of PCs for denoising but MCV (https://github.com/czbiohub/molecular-cross-validation) is also interesting here. It helps with hyperparameter selection based on reconstruction loss on the hold out ""molecules"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/872#issuecomment-559179146:119,validat,validation,119,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/872#issuecomment-559179146,1,['validat'],['validation']
Security,"I’m unsure if we can help you with this, as it’s your system creating his error and we don’t have access to the data. There’s multiple possible causes and solutions:. - a misunderstanding: The arrays should require `310385 * 8563 * 8B = 21.3 GB`, no idea why it says 10. But of course that’s still not close to 100GB unless other people/processes are using the machine, or other arrays are allocated. Can you track the memory usage and see if it spikes close to the maximum before the code crashes?; - our implementation allocates memory it shouldn’t: this is the only one we can fix, but we’d have to figure out under which circumstances that happens, and where in our code.; - some machine problem, [like many people on stackoverflow](https://www.google.com/search?q=site%3Astackoverflow.com+%22Unable+to+allocate%22+%22GiB+for+an+array+with+shape%22+%22and+data+type%22): maybe your sysadmin can help?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2551#issuecomment-1630946384:98,access,access,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551#issuecomment-1630946384,1,['access'],['access']
Security,"Just a little about my use case for backed mode:. I run all of my computations in memory. However, the HPCs I have access to limit the ways I can use them interactively, so I like to do my visualization locally on a backed object. Personally, I really like this feature of Scanpy. Since I've been playing with more complicated visualization code, I'm starting to run into these issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/263#issuecomment-422243349:115,access,access,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/263#issuecomment-422243349,1,['access'],['access']
Security,"Look at the documentation before you ask questions. The object returned from the function you called doesn’t return a matplotlib object, it returns a dictionary, assuming that the ‘show’ parameter is off. You can’t loop through a dictionary like an array, you need to retrieve the keys access individual values and then use the ‘ylim’ property. Get Outlook for iOS<https://aka.ms/o0ukef>; ________________________________; From: ZxyChopcat ***@***.***>; Sent: Thursday, September 16, 2021 1:24:05 PM; To: theislab/scanpy ***@***.***>; Cc: Vekeria, Jai Patel ***@***.***>; Comment ***@***.***>; Subject: Re: [theislab/scanpy] How to use stacked_violin with variable y-axis limits between rows? (#386). Hi,; I tried to set the y-axis limit, but failed with the error:; `>>> axes = sc.pl.stacked_violin(adata, marker_genes, groupby='cell_types', rotation=90,swap_axes=True,row_palette='muted',yticklabels=True,show=False). for ax in axes:; ... ax.set_ylim(0, 5); ...; Traceback (most recent call last):; File """", line 2, in; AttributeError: 'str' object has no attribute 'set_ylim'; `; I use scanpy 1.8.1.; Do you have any idea? Thanks!. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ftheislab%2Fscanpy%2Fissues%2F386%23issuecomment-921089934&data=04%7C01%7Cjai.vekeria%40pitt.edu%7C4da79e06909d45b4b4e508d97936c8d4%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1%7C0%7C637674098542578553%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=t3jhsNr2Q3IlftHnubs6%2FWZyy%2FAijC2BWJ18Ih41Py0%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAL6KD25HVPRX7SK4DD5UPE3UCIR3LANCNFSM4GH7A7BA&data=04%7C01%7Cjai.vekeria%40pitt.edu%7C4da79e06909d45b4b4e508d97936c8d4%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1%7C0%7C637674098542578553%7CUnknown%7CTWF",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/386#issuecomment-921104209:286,access,access,286,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/386#issuecomment-921104209,1,['access'],['access']
Security,No worries and thank you for usually very prompt suggestions.; The idea that scanpy can handle many cells efficiently is great and therefore I have been trying it in a computing cluster (and not my local machine) for the future usage. This in turn makes configuration just a bit more difficult. ; Looking forward to a more stable version with more added function.; Thank you; Hashem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324641466:376,Hash,Hashem,376,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324641466,1,['Hash'],['Hashem']
Security,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1306#issuecomment-662072716:194,access,access,194,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306#issuecomment-662072716,1,['access'],['access']
Security,"Not exactly sure how to test this - it's not that the axis is misordered, it's that we were not informing the violin plot of this ordering. I am not sure if there is a way to access the underlying data of a plot...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3196#issuecomment-2269833379:175,access,access,175,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196#issuecomment-2269833379,1,['access'],['access']
Security,"OK, got it! So you're actually moving the data between your HPC and your laptop? Why does the typical forwarding via `ssh -L ...` that I think most people use for accessing the server running jupyter lab, notebooks, tensorboard etc. locally doesn't work for you (e.g. [here](http://benjlindsay.com/blog/running-jupyter-lab-remotely/))? I can do all the visualizations on the remote infrastructure and never have to move around data, which is nice. ;). Of course, though, the backed functionality of Scanpy should become fully stable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/263#issuecomment-422394446:163,access,accessing,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/263#issuecomment-422394446,1,['access'],['accessing']
Security,"OK, we have those alternatives:. Alternative | Pro | Con; ---|---|---; Keep everything as it is | People will have the best unterstanding of its structure and not treat it as a black box | Unwieldy; Subclass AnnData in scanpy and add accessor methods/attrs | Nice API | <ul><li>Everyone would start using Scanpy’s AnnData subclass instead of the generic container that I think is a great design choice for extensibility<li>Hides AnnData structure</ul>; `sc.get` | <ul><li>Nice API<li>Separates Scanpy-specific API from AnnData API</ul> | Hides AnnData structure. I think `sc.get` is the best option here!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/562#issuecomment-503949436:234,access,accessor,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-503949436,1,['access'],['accessor']
Security,"Of course! would be wild if the plotting would internally transpose the anndata object in case one of the provided `keys` exists in `.var`. `sc.pl.violin(adata.T, 'key')` is 100% the right thing to do. I think the docs are a bit improvable though:. > *keys* : str or list of str; > &emsp;Keys for accessing variables of .var_names or fields of .obs. The mention of `var_names` here means that you can select one or more genes to plot. How can we phrase that better? Maybe we should also add an example that uses transposing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/375#issuecomment-441056129:297,access,accessing,297,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375#issuecomment-441056129,1,['access'],['accessing']
Security,"Oh, I also added tests for example dataset loading since checking they worked manually was a pain. These won't run by default (they take a while, and can fail for network access reasons), but will run with `pytest --internet-tests`. Note that `test_burczynski06` will fail until this get's rebased on master. Thoughts?. Also travis failed this for `scanpy/tests/test_marker_gene_overlap.py` failing an assertion on the first time around, but passed when I triggered a new build. Not sure what's up with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/573#issuecomment-478414881:171,access,access,171,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478414881,1,['access'],['access']
Security,"Oh, sorry, I had completely missed your comment here!. > It looks great!. Thanks! Can I ask why you used leiden clustering on this?. > One first improvement could be to expose a parameters that explicitly ask for the number of rings in the neighbors. This should be easy enough. I'm curious as to whether this it's better to leave this up to whatever algorithm is being used however, since the one step graph has some nice properties. It'd probably be important to include distance in the multistep graph. > Btw, how do I push to this specific PR from my local repo?. This should be fairly straight forward. If you're using the github cli, I think it should just be:. ```sh; gh pr checkout 1383; # whatever changes; git push; ```. Let me know if that gives you errors, since it might be a repository permissions issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-691844681:169,expose,expose,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-691844681,1,['expose'],['expose']
Security,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users.; - plot function moved to scanpy/external/pl.py as scrublet_score_distribution().; - functions linked via 'See also' sections.; - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-727953553:88,expose,exposed,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-727953553,2,['expose'],['exposed']
Security,Phenograph accepts all additional `**kwargs` and doesn’t validate them. We can’t do it for them.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2653#issuecomment-1706324208:57,validat,validate,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653#issuecomment-1706324208,1,['validat'],['validate']
Security,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2337#issuecomment-1371840544:102,access,access,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337#issuecomment-1371840544,1,['access'],['access']
Security,"Seems like an ""old"" X_diffmap has only length 2056. But that should not be the case, of course, as that would be invalid. I just learned about a bug in the storage of the graph `.uns['neighbors']['connectivities']` that appears when you do subsetting on an AnnData and want to access the original object. That could explain what is happening... I'll submit a bug for that in the next couple of hours.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/123#issuecomment-381650708:277,access,access,277,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123#issuecomment-381650708,1,['access'],['access']
Security,"So basically this would be a transaction layer, right? Like subsequent lines in a Dockerfile:. 1. AnnDatas with certain initial data start with a hash computed from it; 2. Each interaction creates a new state with an associated hash. The difference (and only thing that has to be stored) between two states is all properties that changed.; 3. If you rerun a script with modifications, all steps that didn’t change just forward to the next state, all states after a change are deleted and the steps executed. Did I get this right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/947#issuecomment-562563637:146,hash,hash,146,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/947#issuecomment-562563637,2,['hash'],['hash']
Security,"So, I'll go ahead and start a pull request?. Something I think could be useful to include in implementing this is allowing multiple network representations with keyed access (similar to `use_rep`). This would be useful for the cases where you want to cluster on a network that would be inappropriate to use for UMAP.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-416437517:167,access,access,167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/240#issuecomment-416437517,1,['access'],['access']
Security,"Sorry for the late response, I was on holidays. I'm happy to merge a pull request for this, if the package appears solid. Would you want to add a file `scanpy/preprocessing/doubletdetection`? We should probably just ask @JonathanShor whether he's interested in an interface for easily accessing his package. If he is, he should also make the pull request, I'd say. :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-398678802:285,access,accessing,285,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-398678802,1,['access'],['accessing']
Security,"Sorta!. ![image](https://user-images.githubusercontent.com/8238804/108616034-ce7cd480-745d-11eb-93e4-996a912c5041.png). Not sure if it's not working because something is wrong with the configuration, because it doesn't work with PRs, or that it takes a bit for search results to be available. One downside of using this over algolia's search is that we get search analytics through algolia, while we'd have to upgrade our readthedocs subscription to have access to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1672#issuecomment-782797773:455,access,access,455,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1672#issuecomment-782797773,1,['access'],['access']
Security,"Sure:. ```; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-161-7b672fc51046> in <module>; ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs); 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 725 """"""; --> 726 return embedding(adata, 'pca', **kwargs); 727 ; 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 226 itertools.product(color, idx_components); 227 ):; --> 228 color_vector, categorical = _get_color_values(; 229 adata,; 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer); 1031 ):; 1032 # We should probably just make an index for this, and share it over runs; -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][; 1034 0; 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key); 4095 if is_scalar(key):; 4096 key = com.cast_scalar_indexer(key, warn_float=True); -> 4097 return getitem(key); 4098 ; 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-703164973:244,Access,Accession,244,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-703164973,1,['Access'],['Accession']
Security,"Thank you! So you say it doesn’t work, but I see a green checkmark. Would you mind adding a test that exposes the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364153382:102,expose,exposes,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364153382,1,['expose'],['exposes']
Security,Thank you!. Would it be possible to catch and validate this behavior with a test here https://github.com/theislab/scanpy/blob/master/scanpy/tests/external/test_hashsolo.py ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2190#issuecomment-1079689047:46,validat,validate,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190#issuecomment-1079689047,1,['validat'],['validate']
Security,Thanks for the contribution. This is great. I tried hash solo. This tool should be external as the maintenance and code falls outside the core development. The documentation should also point to the main developer of the functionality and give the due credits.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1432#issuecomment-699862845:52,hash,hash,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432#issuecomment-699862845,1,['hash'],['hash']
Security,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3054#issuecomment-2117801388:85,access,access,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054#issuecomment-2117801388,2,['access'],['access']
Security,"Thanks for the flowers (on behalf of the people who did a lot of the work, not me ^^), but it's also the developers of some of these packages, who are ensuring that their packages are directly accessible via this ecosystem. The scanpy ecosystem can only work if everyone is involved. Please feel free to contribute future tools you are working on as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2117#issuecomment-1018747515:193,access,accessible,193,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2117#issuecomment-1018747515,1,['access'],['accessible']
Security,"Thanks for the long response @ivirshup!. For 1. I think a ufunc should always act on adata.X and I want it to return the adata object with the sqrt applied to adata.X. Adding support for the sklearn operators would be great. For the second part, my intention is for the result to be `adata[:, adata.var_names[0:3]].X - adata[:, adata.var_names[3:6]].X`, and it's fine with me in the varnames are lost so long as the obsnames are kept. If they're not the same shape, then I would expect the same error as pandas throws. For 2. I think its okay if you return a dense 1-d array when I access a single column vector. I don't understand where the confusion is coming in with adata.X changing when you access a single column, but that's not been an issue for me. For the rest, I hope you can survey the community to figure out how rare my use-cases are. I would like scanpy / anndata to fit into my existing workflow that I picked up while learning matplotlib / pandas / numpy. I want slicing an AnnData to behave like slicing a DataFrame; I want clusters to be ints; I want to apply a transformation to a data-container and get the whole container returned with the transformation applied to the values. . I can come up with workarounds for all of the choices you've made here. That's not the issue. I raised this comment because these workarounds add overhead to getting my work done. I'm not going to change my work flow to match your design choices where they diverge from the apis for sklearn / numpy / pandas etc. I know I'm not the only one with these wants (e.g. @scottgigante has similar frustrations), but I don't know how prevalent these frustrations are. I think at the end of the day, my concern here boils down to what infrastructure you put in place to make sure the needs of the community are balanced with the intentions of the developers. I think the efforts be cellxgene are a great model for this, and I would happily get involved with figuring out the best way to incorporate community ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-609066004:582,access,access,582,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-609066004,2,['access'],['access']
Security,"Thanks for the quick responses @LuckyMD and @ivirshup.; If `obsm` entries were accessible for plotting functions that would be fantastic. It would really solve all our problems. Once this is implemented I would only need to write a wrapper to model differences of activities between groups and that's it.; Looking forward for this update, thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1724#issuecomment-795050056:79,access,accessible,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724#issuecomment-795050056,1,['access'],['accessible']
Security,"Thanks for the response! The core `reduce` function of SCA is not scanpy-based, but I wrote a very simple wrapper called `reduce_scanpy` to make it easier for scanpy users while this pull request is being considered. It would be even easier for scanpy users to access this code natively in `sc.tl.external`, and it seems odd that the existence of the wrapper (which just runs `reduce` and adds the result to the input AnnData) should disqualify it. Although the current pull request implements `sc.tl.external.sca`as an additional wrapper to `reduce_scanpy`, I could easily write it as a wrapper to `reduce`, which would remove the redundancy of having separate scanpy interfaces in the base package and in sc.tl.external. I would then mark `reduce_scanpy` as deprecated in further releases of SCA, and direct the user instead to `sc.tl.external.sca`. Does this seem reasonable? Of course, I'd be happy to be part of `ecosystem` if that's still where you think it belongs!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1780#issuecomment-825877662:261,access,access,261,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780#issuecomment-825877662,1,['access'],['access']
Security,"Thanks!. On Wed, Jun 7, 2023 at 9:34 AM Philipp A. ***@***.***> wrote:. > I had the same thought and opened #2505; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2505&g=NmVkM2RiMWY2M2U4YzZhYw==&h=YTlmZWU5MDlhNTJlOWJjMTkxZDczZTg2MGE2ODdiNzU2NmIwYjE2OTMzZTczY2M1ZjNlNzEyM2Q0Mjc1OWM5Yg==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > to track that!; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23issuecomment-1580835422&g=YWNlMjU3YjI5ODM4NTJkYQ==&h=ZTJiNzVlYzQ0NzM5YmY0ZTdiMWEzMDQ2MmQ0MGMwOWZmZTVlOGRhN2JmYjZiYTcxYjg1Nzg3OTRjMzEwZDY3OA==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAR6XJXLYMBK224NMETXKB7MDANCNFSM6AAAAAAY3HAO3E&g=OGRhMDE2YzcyZWIwNGMxNg==&h=M2I1NTIwM2JlNTIwNjA4MGViYjE3YTRmYjQ0MWM3NzNhYzNkNjBlNzVjYjg1NDUwMGVkMjJhNWFkYmZlZTIxYQ==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698:1357,confidential,confidential,1357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698,2,"['authoriz', 'confidential']","['authorized', 'confidential']"
Security,"That is a wonderful solution! I will give it a shot shortly. Thank you so much for your help!. Here's some example code of how Seurat handles cluster scoring and merging with random forests and OOBE:. ```; pbmc <- ValidateClusters(pbmc, pc.use = 1:30, top.genes = 30). pbmc <- BuildClusterTree(pbmc, ; do.reorder = T, ; reorder.numeric = T). node.scores <- AssessNodes(pbmc). node.scores[order(node.scores$oobe,decreasing = T),] -> node.scores. nodes.merge <- node.scores[which(node.scores[,2] > 0.1),]; nodes.to.merge <- sort(nodes.merge$node) ; pbmc.merged <- pbmc. for (n in nodes.to.merge); {; pbmc.merged <- MergeNode(pbmc.merged, n); }. ```. Here's an explanation, as this code was derived from this recent (and awesome) publication:; ; From page 6 of the Supplementary Methods of Plass et al 2018: http://science.sciencemag.org/content/early/2018/04/18/science.aaq1723. To prevent obtaining spurious clusters result of overclustering, the robustness of the clusters was calculated using the function AssessNodes from Seurat. For each cluster, the average expression of all variable genes (4910) is computed and a phylogenetic tree based on the distance matrix in gene expression space is computed. Next, it computes an Out of Bag Error for a random forest classifier trained on each internal node split of the tree. We recursively build a tree and assessed all its nodes, merging all clusters with an out of bag error bigger than 0.1 until no such nodes were found.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/362#issuecomment-440912410:214,Validat,ValidateClusters,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/362#issuecomment-440912410,1,['Validat'],['ValidateClusters']
Security,"That problem occurs within h5py (we just wrap the underlying OSError) and isn’t a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb; OSError: Can't read data (file read failed:; time = Sat Aug 1 13:27:54 2020,; filename = '/path.../filtered_gene_bc_matrices.h5ad',; file descriptor = 47,; errno = 5,; error message = 'Input/output error',; buf = 0x55ec782e9031,; total read size = 7011,; bytes this sub-read = 7011,; bytes actually read = 18446744073709551615,; offset = 0); ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because that’d explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too!. I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that there’s 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559; - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-667531196:1075,access,accessing-,1075,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-667531196,1,['access'],['accessing-']
Security,"The checks shouldn't take any time. But you're right; you're also slicing the `.var` and the `.varm` annotations if you make this call and we could check whether this perceivably slows down things (only for very large data, I guess). If it does, it would be very simple to add an accessor `.slice_X` that enables convenient slicing of the data matrix. That's a bit ugly but would vanish in the plotting function. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-422400480:280,access,accessor,280,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-422400480,1,['access'],['accessor']
Security,"The fact that `normalize_per_cell` filters cells caused me some trouble recently, especially because there is nothing in documentation that says this will happen and there the subset indices are not returned. My use case is a little different: I am running a K-fold cross validation and `normalize_per_cell` is a step in the process. Since this function filters out some cells, the array of predicted labels has fewer entries than I would expect for the fold. Ideally, this behavior could be switched off. For example, you could pass a `min_counts` argument to `normalize_per_cell`. I've made this change if this is an approach you would like to take: https://github.com/umangv/scanpy/tree/umangv-normalize",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/210#issuecomment-428983959:272,validat,validation,272,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/210#issuecomment-428983959,1,['validat'],['validation']
Security,"The reorganization of using the ""external API"" (shallow interfaces) via an `import scanpy.external as sce` and the ""internal API"" as accessible via `import scanpy as sc`, sort of, provided a solution to what bothered people the most: expecting the ""internal API"" to run through at a single install, be properly maintained etc. and the interfaces to external packages be clearly marked. I think this is a sustainable, long-term solution, which scales and is convenient for contributors. @flying-sheep agreed as I understood it. Do you think we need more?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/457#issuecomment-460063977:133,access,accessible,133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/457#issuecomment-460063977,1,['access'],['accessible']
Security,This is super cool!. Is the level of parallelism exposed here amenable to multi-machine parallelism (like the MapReduce strategy mentioned in the nn-descent paper)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/659#issuecomment-495225646:49,expose,exposed,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/659#issuecomment-495225646,1,['expose'],['exposed']
Security,"This is the error with the development version:. ```; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-36-2ee11f6b7699> in <module>; ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs); 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 733 """"""; --> 734 return embedding(adata, 'pca', **kwargs); 735 ; 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 243 itertools.product(color, idx_components); 244 ):; --> 245 color_source_vector = _get_color_source_vector(; 246 adata,; 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups); 1016 ):; 1017 # We should probably just make an index for this, and share it over runs; -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][; 1019 0; 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key); 4095 if is_scalar(key):; 4096 key = com.cast_scalar_indexer(key, warn_float=True); -> 4097 return getitem(key); 4098 ; 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-703912344:285,Access,Accession,285,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-703912344,1,['Access'],['Accession']
Security,"This should work for now. The problem is that this really needs to live in scanpydoc, where we have access to the fancy parsing. My plan is to merge this now, which has a solution for the simple case of. ```rst; parameter : some.type; Description; ```. Later I’ll introduce the same behavior as what scanpydoc does with the parameters:. If the return type is `...) -> Tuple[foo.bar, baz.zab]:`, then I’ll check if there’s a section like. ```rst; one_identifier; Desc; second_identifier; Desc; ```. and replace them with the same code as parameters. ----. This leaves 3 styles:. 1. Prose for a single return value; 2. The above for returning a tuple; 3. “this function adds some AnnData.obs/var fields”. For 3., we have like 3 styles floating around and need to fix one:. 1. ``**dpt_pseudotime** : :class:`pandas.Series` (`adata.obs`, dtype `float`)``; 2. ``` ``adata.obs['louvain']`` (:class:`pandas.Series`, dtype ``category``) ```; 3. `` `adata.uns['leiden']['params']` : `dict` ``",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/610#issuecomment-484124854:100,access,access,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484124854,1,['access'],['access']
Security,"Was there any progress on this? I also have an issue of non-reproducible UMAPs when re-starting Jupyter notebook. I have not been able to trace the exact cause of the issue, but it appears unrelated to the PCA step (I am using `svd_solver='arpack'`). In my case setting `random.seed` did not fix the issue. However, surprisingly, combining this with disabling hash randomization by setting `PYTHONHASHSEED` to `0` did generate reproducible results",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/313#issuecomment-551163746:360,hash,hash,360,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313#issuecomment-551163746,1,['hash'],['hash']
Security,"We are currently using `sklearn.utils.check_random_state` to validate the argument for `random_state` in most places. Sometime's (especially in external) we pass the argument directly to the wrapped tool. In sklearn `0.24.1`, this looks like `np.random.RandomState` if you pass an integer.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1626#issuecomment-773090710:61,validat,validate,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1626#issuecomment-773090710,1,['validat'],['validate']
Security,We'll see 😝. I'm hoping I might be able to help out with other things along these things which would make Scanpy more accessible for R users and hopefully expand the user base.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1186#issuecomment-623326183:118,access,accessible,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1186#issuecomment-623326183,1,['access'],['accessible']
Security,"Whoa, I had no idea you could have ever accessed elements of obsm and varm as attributes. That probably won't be the case for current and future versions of `anndata`, since `obsm` should be a `Mapping` subclass. What versions of scanpy and anndata are you using?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/778#issuecomment-521108926:40,access,accessed,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778#issuecomment-521108926,1,['access'],['accessed']
Security,"Why is it that .obs, .var, and .uns don't have data frames in them? `np.recarray` don't seem like a very popular data structure elsewhere. Also, I'd like to suggest that storing all differential expression within the anndata object might get complicated, and deserve it's own class. It'd be nice if it could be easy to tell what cells and genes were compared, what exactly was being tested, and which direction is ""up"". That said, the results should definitely be easily accessible as a data frame.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/562#issuecomment-483204895:471,access,accessible,471,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-483204895,1,['access'],['accessible']
Security,"Yeah, I had thought anyone could see that. I'll look into checking if we can make that happen. If not, I'll at least try and give everyone with commit rights to scanpy access. Can you see the docs when the build succeeds?. *Updates* . * You can at least see some of the most recent build logs [here](https://readthedocs.org/projects/icb-scanpy/builds/11406014/).; * It looks like you can see the PR logs for other projects, like [pip](https://readthedocs.org/projects/pip/builds/). I think the difference here is that we have a paid readthedocs account (pip is on `.org`, we are on `.com`), which may [make some things private](https://docs.readthedocs.io/en/latest/choosing-a-site.html). Hopefully we can make this not private?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1307#issuecomment-655302522:168,access,access,168,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307#issuecomment-655302522,1,['access'],['access']
Security,"Yeah, two out of three of the HPCs I have access to don't make using a jupyter server particularly easy (one corporate firewall, one government). I use that with the other one, but it's down this week 😢",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/263#issuecomment-422629703:42,access,access,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/263#issuecomment-422629703,2,"['access', 'firewall']","['access', 'firewall']"
Security,"Yes:. ```; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-39-2ee11f6b7699> in <module>; ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs); 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 725 """"""; --> 726 return embedding(adata, 'pca', **kwargs); 727 ; 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 226 itertools.product(color, idx_components); 227 ):; --> 228 color_vector, categorical = _get_color_values(; 229 adata,; 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer); 1031 ):; 1032 # We should probably just make an index for this, and share it over runs; -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][; 1034 0; 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key); 4095 if is_scalar(key):; 4096 key = com.cast_scalar_indexer(key, warn_float=True); -> 4097 return getitem(key); 4098 ; 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with siz",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-703860357:242,Access,Accession,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-703860357,1,['Access'],['Accession']
Security,"You can easily access the silhouette coefficient via scikit-learn. . I would be hesitant to base optimal numbers of clusters on the silhouette coefficient though. The number of clusters is typically dependent on the biological question of interest. There's not really a scale at which all biological questions can be answered. Therefore you have a resolution parameter to check multiple resolutions. For example, T cells could be taken as one cluster or sub-clustered into CD4+ and CD8+ (which is typically done). Here a problem with the silhouette coefficient also shows: often you have one big cluster of T-cells which reluctantly cluster into the CD4+ and CD8+ subtypes (early 10X datasets show this nicely). This will have a lower silhouette coefficient, but it is probably more informative for many people.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-498066846:15,access,access,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498066846,1,['access'],['access']
Security,"You can use `mp = rank_genes_groups_matrixplot(..., show=False, return_fig=True)` and then use `mp.get_axes()` to get a dict of axes you can manipulate, e.g. by accessing the xtickmarks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3149#issuecomment-2426878433:161,access,accessing,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3149#issuecomment-2426878433,1,['access'],['accessing']
Security,"[Here are the specific lines for their cluster ordering](https://github.com/GreenleafLab/ArchR/blob/6765ad962d4d8dcb292a326071c9b5c30c25918e/R/Clustering.R#L368-L383). They do a hierarchical clustering on the mean position of each cluster in the reduced dimensional space. We don't necessarily have access to that space (which may not even exist, e.g. BBKNN graph) at clustering time so we can't use this exact method. ### Current thoughts. My preferences in APIs lean towards modularity and shallowness. I like that the `leiden` function pretty much only computes `leiden` clusters, nothing else. I don't love the idea of adding complexity or computation on top of that. I also think ""gives better label orderings"" is a vague target which is hard to have meaningful tests for, so can be difficult to support. I think this would be a little convenient, but I don't see it being very convenient. I would like to hear if other people would really like this feature. At the moment, I don't think it's utility outweighs it's downsides to me. What I would be more for is some sort of `relabel_clusterings` utility function, which just does the relabelling and could have multiple ways of doing so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2016#issuecomment-948076348:299,access,access,299,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2016#issuecomment-948076348,1,['access'],['access']
Security,"[The documentation for `AnnData.write_csvs`](https://anndata.readthedocs.io/en/latest/anndata.AnnData.write_csvs.html) tells you. > It is not possible to recover the full AnnData from the output of this function. Use write() for this. Sorry for that! We thought that not having a function to read back those CSVs, we won’t lull people into the false security that the AnnData object can be safely restored from CSVs. But if you have nothing else but those files, you can of course try to use [`pandas.read_csv`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) to read the `.obs` and `.var` dataframes and do something like. ```py; adata = AnnData(; pd.read_csv('output/X.csv').asarray(),; pd.read_csv('output/obs.csv'),; pd.read_csv('output/var.csv'),; { # adata.uns; 'some_thing': pd.read_csv('output/some_thing.csv'),; },; pd.read_csv('output/obsm.csv'),; pd.read_csv('output/varm.csv'),; ); ```. You might have to fiddle with parameters to `pandas.read_csv`, like `index_col`, and obsm/varm might not be able to be specified as data frames.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/399#issuecomment-447793340:350,secur,security,350,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/399#issuecomment-447793340,1,['secur'],['security']
Security,"_DISABLE_FILE_VALIDATION=1 to disable this validation.; [I 2024-02-06 12:45:47.931 ServerApp] Connecting to kernel 9fd93000-73b0-4abb-8cf1-505bec376572.; [I 2024-02-06 12:45:47.936 ServerApp] Connecting to kernel 9fd93000-73b0-4abb-8cf1-505bec376572.; [I 2024-02-06 12:45:47.946 ServerApp] Connecting to kernel 9fd93000-73b0-4abb-8cf1-505bec376572.; [I 2024-02-06 12:45:52.822 ServerApp] Creating new directory in; [W 2024-02-06 12:46:00.673 ServerApp] delete /Untitled Folder; [I 2024-02-06 12:46:08.209 ServerApp] Kernel shutdown: 9fd93000-73b0-4abb-8cf1-505bec376572; [W 2024-02-06 12:46:08.330 ServerApp] delete /Untitled.ipynb; [I 2024-02-06 12:46:15.481 ServerApp] Kernel started: 54f6e9a0-500c-48ed-8d4d-49943b2f107c; 0.00s - Debugger warning: It seems that frozen modules are being used, which may; 0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off; 0.00s - to python to disable frozen modules.; 0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.; [I 2024-02-06 12:46:16.520 ServerApp] Connecting to kernel 54f6e9a0-500c-48ed-8d4d-49943b2f107c.; [I 2024-02-06 12:48:15.364 ServerApp] Saving file at /Tests/scanpytutorial/Untitled.ipynb; [I 2024-02-06 12:49:18.462 ServerApp] AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports; [W 2024-02-06 12:49:18.462 ServerApp] kernel 54f6e9a0-500c-48ed-8d4d-49943b2f107c restarted; [I 2024-02-06 12:49:18.468 ServerApp] Starting buffering for 54f6e9a0-500c-48ed-8d4d-49943b2f107c:df20bfae-3e78-44d6-b98f-42f032c621cb; [I 2024-02-06 12:49:18.476 ServerApp] Connecting to kernel 54f6e9a0-500c-48ed-8d4d-49943b2f107c.; [I 2024-02-06 12:49:18.476 ServerApp] Restoring connection for 54f6e9a0-500c-48ed-8d4d-49943b2f107c:df20bfae-3e78-44d6-b98f-42f032c621cb; 0.00s - Debugger warning: It seems that frozen modules are being used, which may; 0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off; 0.00s - to python to disable frozen module",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2840#issuecomment-1929361492:1386,validat,validation,1386,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2840#issuecomment-1929361492,1,['validat'],['validation']
Security,"`adata.var[""gene_name""]`. Traceback (most recent call last):; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py"", line 3361, in get_loc; return self._engine.get_loc(casted_key); File ""pandas/_libs/index.pyx"", line 76, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 108, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'gene_name'. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py"", line 3458, in __getitem__; indexer = self.columns.get_loc(key); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py"", line 3363, in get_loc; raise KeyError(key) from err; KeyError: 'gene_name'. Did something change in scanpy ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/455#issuecomment-1117713087:475,hash,hashtable,475,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-1117713087,2,['hash'],['hashtable']
Security,"aga_path(adata, nodes = [0, 5, 1], keys = ['IFNG', 'GZMB'], show = True)`. > TypeError: Image data of dtype object cannot be converted to float. What is the current solution to this issue?. Many thanks,; Lucy. ```; # Name Version Build Channel; alabaster 0.7.12 py_0 conda-forge; anndata 0.7.4 py38h32f6830_0 conda-forge; applaunchservices 0.2.1 py_0 conda-forge; appnope 0.1.0 py38h32f6830_1002 conda-forge; argh 0.26.2 py38_1001 conda-forge; astroid 2.4.2 py38h32f6830_1 conda-forge; async_generator 1.10 py_0 conda-forge; atomicwrites 1.4.0 pyh9f0ad1d_0 conda-forge; attrs 20.2.0 pyh9f0ad1d_0 conda-forge; autopep8 1.5.4 pyh9f0ad1d_0 conda-forge; babel 2.8.0 py_0 conda-forge; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backports 1.0 py_2 conda-forge; backports.functools_lru_cache 1.6.1 py_0 conda-forge; bleach 3.2.1 pyh9f0ad1d_0 conda-forge; blosc 1.20.1 hb1e8313_0 conda-forge; brotlipy 0.7.0 py38h94c058a_1001 conda-forge; bzip2 1.0.8 haf1e3a3_3 conda-forge; c-ares 1.16.1 haf1e3a3_3 conda-forge; ca-certificates 2020.10.14 0 ; cairo 1.16.0 h360c52f_1006 conda-forge; certifi 2020.6.20 py38h5347e94_2 conda-forge; cffi 1.14.3 py38h9edaa1b_1 conda-forge; chardet 3.0.4 py38h5347e94_1008 conda-forge; click 7.1.2 pyh9f0ad1d_0 conda-forge; cloudpickle 1.6.0 py_0 conda-forge; colorama 0.4.4 pyh9f0ad1d_0 conda-forge; cryptography 3.2 py38hf6767f5_0 conda-forge; cycler 0.10.0 py_2 conda-forge; dbus 1.13.18 h18a8e69_0 ; decorator 4.4.2 py_0 conda-forge; defusedxml 0.6.0 py_0 conda-forge; diff-match-patch 20200713 pyh9f0ad1d_0 conda-forge; docutils 0.16 py38h5347e94_2 conda-forge; entrypoints 0.3 py38h32f6830_1002 conda-forge; expat 2.2.10 hb1e8313_2 ; fa2 0.3.5 py38h4d0b108_0 conda-forge; flake8 3.8.4 py_0 conda-forge; fontconfig 2.13.1 h79c0d67_1002 conda-forge; freetype 2.10.4 ha233b18_0 conda-forge; future 0.18.2 py38h32f6830_2 conda-forge; get_version 2.1 py_1 conda-forge; gettext 0.19.8.1 haf92f58_1004 conda-forge; glib 2.66.2 hb1e8313_0 conda-forge; gmp 6.2.0 hb1e8313_3 conda-forge",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-719504684:1076,certificate,certificates,1076,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-719504684,1,['certificate'],['certificates']
Security,"agree with @grst -- also:. > I think if we are going to say ""here is the way to represent this kind of data"" we shouldn't just set that to be whatever we do currently and call it a standard. I mean this is what we are currently doing explicitly, it's just scattered across a few packages. We really need to fill the current gap in accessibility. The first hit below takes me to a package that doesn't have functioning API documentation (while it might work it's not clear if I don't know what I'm doing). <img width=""300"" alt=""Screen Shot 2022-04-28 at 8 29 52 AM"" src=""https://user-images.githubusercontent.com/10859440/165788872-442dff0f-64d4-4893-8a27-61a4a965e2f8.png"">",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1387#issuecomment-1112350973:331,access,accessibility,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1387#issuecomment-1112350973,1,['access'],['accessibility']
Security,"also as an aside, would it be appropriate to include some of @LuckyMD scIB integration metrics here? It would give people easier access and probably expand general use.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-763812897:129,access,access,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-763812897,1,['access'],['access']
Security,"are kept. If they're not the same shape, then I would expect the same error as pandas throws. For 2. I think its okay if you return a dense 1-d array when I access a single column vector. I don't understand where the confusion is coming in with adata.X changing when you access a single column, but that's not been an issue for me. For the rest, I hope you can survey the community to figure out how rare my use-cases are. I would like scanpy / anndata to fit into my existing workflow that I picked up while learning matplotlib / pandas / numpy. I want slicing an AnnData to behave like slicing a DataFrame; I want clusters to be ints; I want to apply a transformation to a data-container and get the whole container returned with the transformation applied to the values. . I can come up with workarounds for all of the choices you've made here. That's not the issue. I raised this comment because these workarounds add overhead to getting my work done. I'm not going to change my work flow to match your design choices where they diverge from the apis for sklearn / numpy / pandas etc. I know I'm not the only one with these wants (e.g. @scottgigante has similar frustrations), but I don't know how prevalent these frustrations are. I think at the end of the day, my concern here boils down to what infrastructure you put in place to make sure the needs of the community are balanced with the intentions of the developers. I think the efforts be cellxgene are a great model for this, and I would happily get involved with figuring out the best way to incorporate community feedback into the development of scanpy / anndata. All this said, your tools do provide a bunch of amazing functionality that I rely on for my PhD. I really appreciate all the effort you've put in. I especially love how easy it is to run louvain / leiden, and how supportive you've been to people adding external tools to scanpy so they can be made accessible to the broader community of single cell users in Python. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-609066004:2350,access,accessible,2350,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-609066004,1,['access'],['accessible']
Security,can you give me access to https://icb-scanpy.readthedocs-hosted.com?. I just have access to the public readthedocs.org,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/406#issuecomment-450485020:16,access,access,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406#issuecomment-450485020,2,['access'],['access']
Security,"ception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper; return f(*args, **kwargs); File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed; backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',; File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read; **kwargs,; File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read; is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,); File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download; _download(backup_url, path); File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download; urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:; File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen; return opener.open(url, data, timeout); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open; response = self._open(req, data); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open; '_open', req); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain; result = func(*args); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open; context=self._context, check_hostname=self._check_hostname); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open; raise URLError(err); urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1472#issuecomment-721326665:3584,certificate,certificate,3584,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472#issuecomment-721326665,2,['certificate'],['certificate']
Security,"earn` and I want this to ""just work"". I agree with you that `iloc` vs `loc` indexing is not straightforward to lay users, but I think it's a mistake to change the convention for how one indexes positionally vs using labels. _Especially when the underlying data structures is often a dataframe._ Instead of breaking these conventions, I would love to see the tool ""just work"" and make sure the tutorials and documentation make the conventions exceedingly clear for new users. I'm not sure what's the best way to resolve this, because I think this line of thinking results in a couple larger design questions for scanpy as well. For example, should AnnData objects be valid input for numpy ufuncs? I.e. should the following code work?. ```python; import numpy as np; import pandas as pd; import scanpy as sc. data = pd.DataFrame(np.random.normal(size=(100,2))); adata = sc.AnnData(data); np.sqrt(adata); ```; Currently this raises a `TypeError`. Why shouldn't this ""Just work""? What about the convention of returning a copy by default, instead of modifying objects in place? I can't think of many other Python toolkits that don't return a copy when you perform some operation on a data object. I would really love to use scanpy / anndata more in my day to day work. Right now, this lack of compatibility is the hurdle that prevents that. I disagree that people who are familiar with pandas and numpy will have an easy time coming to grips with leveraging a tool that doesn't interact well with the greater ecosystem of data analysis tools in Python. I think these users are more likely to use scanpy / anndata only to get access to the methods that are only implemented in scanpy, and then return to the ecosystem of tools that all work together. I can only speak to my experience, but this is how I use scanpy. If scanpy were to adopt greater inter-compatibility, I would be happy both to use it more and also to help contribute to its development and documentation. I'm excited to hear your thoughts!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-583875715:3107,access,access,3107,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-583875715,1,['access'],['access']
Security,"el 9fd93000-73b0-4abb-8cf1-505bec376572.; [I 2024-02-06 12:45:47.936 ServerApp] Connecting to kernel 9fd93000-73b0-4abb-8cf1-505bec376572.; [I 2024-02-06 12:45:47.946 ServerApp] Connecting to kernel 9fd93000-73b0-4abb-8cf1-505bec376572.; [I 2024-02-06 12:45:52.822 ServerApp] Creating new directory in; [W 2024-02-06 12:46:00.673 ServerApp] delete /Untitled Folder; [I 2024-02-06 12:46:08.209 ServerApp] Kernel shutdown: 9fd93000-73b0-4abb-8cf1-505bec376572; [W 2024-02-06 12:46:08.330 ServerApp] delete /Untitled.ipynb; [I 2024-02-06 12:46:15.481 ServerApp] Kernel started: 54f6e9a0-500c-48ed-8d4d-49943b2f107c; 0.00s - Debugger warning: It seems that frozen modules are being used, which may; 0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off; 0.00s - to python to disable frozen modules.; 0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.; [I 2024-02-06 12:46:16.520 ServerApp] Connecting to kernel 54f6e9a0-500c-48ed-8d4d-49943b2f107c.; [I 2024-02-06 12:48:15.364 ServerApp] Saving file at /Tests/scanpytutorial/Untitled.ipynb; [I 2024-02-06 12:49:18.462 ServerApp] AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports; [W 2024-02-06 12:49:18.462 ServerApp] kernel 54f6e9a0-500c-48ed-8d4d-49943b2f107c restarted; [I 2024-02-06 12:49:18.468 ServerApp] Starting buffering for 54f6e9a0-500c-48ed-8d4d-49943b2f107c:df20bfae-3e78-44d6-b98f-42f032c621cb; [I 2024-02-06 12:49:18.476 ServerApp] Connecting to kernel 54f6e9a0-500c-48ed-8d4d-49943b2f107c.; [I 2024-02-06 12:49:18.476 ServerApp] Restoring connection for 54f6e9a0-500c-48ed-8d4d-49943b2f107c:df20bfae-3e78-44d6-b98f-42f032c621cb; 0.00s - Debugger warning: It seems that frozen modules are being used, which may; 0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off; 0.00s - to python to disable frozen modules.; 0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2840#issuecomment-1929361492:2460,validat,validation,2460,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2840#issuecomment-1929361492,1,['validat'],['validation']
Security,"envs/scIB-python/lib/python3.7/http/client.py"", line 1275, in _send_request; self.endheaders(body, encode_chunked=encode_chunked); File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders; self._send_output(message_body, encode_chunked=encode_chunked); File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output; self.send(msg); File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send; self.connect(); File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect; server_hostname=server_hostname); File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket; session=session; File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create; self.do_handshake(); File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake; self._sslobj.do_handshake(); ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper; return f(*args, **kwargs); File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed; backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',; File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read; **kwargs,; File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read; is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,); File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1472#issuecomment-721326665:1538,certificate,certificate,1538,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472#issuecomment-721326665,2,['certificate'],['certificate']
Security,"hat'll modify `adata.obs`. A couple challenges/ideas to consider:. * at our facility, we're typically building the same Illumina i7 index (`ATTACTCG`) into all tag libraries. This leads to some tricky situations when using a NovaSeq for sequencing since the multiple tag libraries (with disjoint sets of tags) may be run on the same sequencing flowcell lane. This results in a single set of FASTQ files and thus a single barcode-tag matrix for all tag libraries on that lane. Therefore, the mapping between transcriptome AnnData objects <-> tag library matrices is not always 1-to-1.; * in my experience, HTO libraries have a large variance in quality, so for the most part I've been using the transcriptome as my ""ground truth"" as to what is a cell. However, I imagine others use HTOs to ""rescue"" cells that were not called by their pipeline of choice (and I hope to do this once I build enough trust in the data). In that case, one would want to intersect the HTO classifications with the raw cell-gene matrix.; * not all tags are antibody based, so I'd vote for naming all related functions `*hashtags()`. I'd therefore vote for something like the following design:; ```{python}; # htos is a AnnData object; htos = sc.read_hashtags(filename) . # classify_hashtags adds a classification to the hto AnnData object; # kwargs might involve things like `use_tags=[""tag1"", ""tag2"", ""tag3""]`; sc.pp.classify_hashtags(htos, **kwargs); print(htos.obs.classification) . # demuxing cell-gene matrix(es) could then be done like; rna1 = sc.read_10x_h5(...); rna2 = sc.read_10x_h5(...); # sc.pp.demux_by_hashtag(adata_hto, *adata_rna, tag_groups=None, ...); sc.pp.demux_by_hashtag(; htos, ; rna1, rna2, ; tag_groups=[(""tag1"", ""tag3"", ""tag5""), (""tag2"", ""tag4"", ""tag6"")]; ); ```; @gokceneraslan This is more complex than what you suggested, but I think is sufficiently general to cover my needs as listed above. Let me know what you think---I'll have some development time next week to possible contribute to this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-543387900:1829,hash,hashtags,1829,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-543387900,1,['hash'],['hashtags']
Security,"ith non-model species and the majority of gene names are non-informative like ""nbis-gene-11111"", but I am interested in some genes of actin that I deposited in GenBank. I would like to put GB accessions into the plot.) I created the column with following code: [""bob"" is the dataset name]. bob.var['GB_IDs'] = bob.var_names.copy(); ID_dict = {; ""nbis-gene-777"":""MT451954"",; ""nbis-gene-775"":""MT451955"",; ""nbis-gene-3785"":""MT451956"",; ""nbis-gene-3784"":""MT451957"",; ""nbis-gene-23114"":""MT451958"",; ""nbis-gene-25113"":""MT451959"",; ""nbis-gene-3783"":""MT518195""; }; bob.var['GB_IDs'].replace(ID_dict, inplace=True). After that GB_IDs column was present in the dataframe.; And then I tried to plot the dotplot:. dict = {; ""Actin 1"": [""nbis-gene-777""],; ""Actin 2"": [""nbis-gene-775""],; ""Actin 3"": [""nbis-gene-3785""],; ""Actin 4"": [""nbis-gene-3784""],; ""Actin 5"": [""nbis-gene-23114""],; ""Actin 6"": [""nbis-gene-25113""],; ""Actin 7"": [""nbis-gene-3783""]; }; dp=sc.pl.dotplot(bob, dict, ""scGate_multi"", dendrogram=False, return_fig=True, cmap='YlGnBu', gene_symbols='GB_IDs'). This results in an error: . ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); File ~/software/SAMap/lib/python3.9/site-packages/pandas/core/indexes/base.py:3791, in Index.get_loc(self, key); 3790 try:; -> 3791 return self._engine.get_loc(casted_key); 3792 except KeyError as err:. File index.pyx:152, in pandas._libs.index.IndexEngine.get_loc(). File index.pyx:181, in pandas._libs.index.IndexEngine.get_loc(). File pandas/_libs/hashtable_class_helper.pxi:7080, in pandas._libs.hashtable.PyObjectHashTable.get_item(). File pandas/_libs/hashtable_class_helper.pxi:7088, in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'GB_IDs'. If I correctly understand the docs (https://scanpy.readthedocs.io/en/latest/generated/scanpy.pl.dotplot.html), this code should work. I tried also to create such additional column in adata.raw.var, but that did not help as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1636#issuecomment-2048223788:1878,hash,hashtable,1878,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636#issuecomment-2048223788,2,['hash'],['hashtable']
Security,just want to say that even a first release with some of the easiest to implement metrics could help lead to greater widespread use and IMO would generally be appreciated by the community. Besides the fact that it seems like a perfect fit for this scanpy module as I understand it. Though I do understand the citation issue. Maybe it's time for a global citation table and each function can add to the table if there is an appropriate citation?! Maybe it could be accessed with `sc.citation_table` and displays which function calls used which paper's methods.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-764195420:463,access,accessed,463,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-764195420,1,['access'],['accessed']
Security,"like structure with clusters in rows. Completely agreed!; 1. agreed with @ivirshup that there should be a more comprehensive object (which can possibly simply be stored as a dataframe and params in `.uns['rank_genes_groups']`, that clarify what the reference for the test was, but that might be not powerful enough)... your latest suggestion, @ivirshup, representing things as in 3d array sounds very promising, too... how to make an intuitive object? represent the 3d array in a long-form dataframe where two axes are accessible from one multi-index? or store an actual 3d array in AnnData, which can be cast into a convenient object, through a casting namespace... the logic being `sc.tl....` computes some complicated annotation, `sc.pl...` visualizes this annotation and `sc.ex....` extracts and casts annotation into more easily manageable objects. One example is `sc.Neigbors` (which should go into `sc.ex...`) which takes the weird annotation that `sc.pp.neighbors` writes and casts them into an object that allows accessing things... ; 2. Related, but really independent of `rank_genes_groups`: I had implemented a [draft of a `.collapse()` function](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/zebrafish/zebrafish.ipynb#Collapsing-the-AnnData-object), which is very similar to the [`.groupby()` function](https://github.com/ivirshup/mantis#group-by) that @ivirshup suggests, but much less elegant (I would also never have put it into the main repo...). You take a summary metric like `.mean()` or `.std()` and collapse the object by that (in pandas, would be `df.groupby('louvain').mean()`. > Why is it that .obs, .var, and .uns don't have data frames in them? np.recarray don't seem like a very popular data structure elsewhere. We just did only allow rec arrays in `.uns` as they are natively supported by hdf5 and dataframes aren't. It was really just that reason, nothing else. As mentioned in anndata, I'd love to completely move away from rec arrays as a means of aggr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/562#issuecomment-487279241:1028,access,accessing,1028,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487279241,1,['access'],['accessing']
Security,"n't match with a 2D-gaussian; - skewing of the ""absence"" of a marker depending on presence of another marker; - a weird double-positive tail that extends along the diagonal. These types of effects are reminiscent of [flow cytometry artifacts](https://docs.flowjo.com/flowjo/graphs-and-gating/gw-transform-overview/gw-transform-digital/). However, without proving which one is ground truth, we don't know for sure which one is true. At least initially, I would think that the CLR plots look more plausible. ![image](https://user-images.githubusercontent.com/20694664/83360046-51985080-a34c-11ea-9ec0-2057301ae4fc.png). ![image](https://user-images.githubusercontent.com/20694664/83360065-74c30000-a34c-11ea-9e0b-d28cea53993e.png). ![image](https://user-images.githubusercontent.com/20694664/83360079-84dadf80-a34c-11ea-9026-4256d8a3199b.png). I used a neutral word earlier: that CLR ""injects"" additional changes, but now it seems that may be a positive thing because many of these empirical cases seem believable from a biological standpoint -- a more systematic validation/comparison might conclude that it ""corrects"" some aspect of the signal acquisition (e.g. combats protein differences simply due to cell size). Again, this is because by design, CLR isn't just a rescaling: it performs cell-specific centering relative to all markers in a relative ratio way, so doesn't preserve a 1-to-1 monotonic mapping as a rescaling function like log, asinh, biexponential/logicle/vlog would. But without having tested it in all cases, it's not clear that it will *always* be better with this kind of assumption for other types of markers that may have different fundamental characteristics. I would recommend that people plot both ways and decide on a case-by-case basis for each marker. . EDIT: I looked around a bit more in the literature and do think that the absolute count based transforms (i.e. all the ones not the CLRatio based), do seem to represent physical reality more: cell size (as one explana",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-636513215:1543,inject,injects,1543,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117#issuecomment-636513215,2,"['inject', 'validat']","['injects', 'validation']"
Security,nment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_kmp_llvm conda-forge; absl-py 1.4.0 pyhd8ed1ab_0 conda-forge; anndata 0.9.1 pyhd8ed1ab_0 conda-forge; annotated-types 0.5.0 pyhd8ed1ab_0 conda-forge; anyio 3.7.1 pyhd8ed1ab_0 conda-forge; arpack 3.7.0 hdefa2d7_2 conda-forge; arrow 1.2.3 pyhd8ed1ab_0 conda-forge; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; attrs 23.1.0 pyh71513ae_1 conda-forge; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.cached-property 1.0.2 pyhd8ed1ab_0 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pyha770c72_0 conda-forge; blas 1.0 mkl conda-forge; blessed 1.19.1 pyhe4f9e05_2 conda-forge; brotli 1.0.9 h166bdaf_9 conda-forge; brotli-bin 1.0.9 h166bdaf_9 conda-forge; brotlipy 0.7.0 py310h5764c6d_1005 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; c-ares 1.19.1 hd590300_0 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; cachecontrol 0.12.14 pyhd8ed1ab_0 conda-forge; cachecontrol-with-filecache 0.12.14 pyhd8ed1ab_0 conda-forge; cached-property 1.5.2 hd8ed1ab_1 conda-forge; cached_property 1.5.2 pyha770c72_1 conda-forge; certifi 2023.7.22 pyhd8ed1ab_0 conda-forge; cffi 1.15.1 py310h255011f_3 conda-forge; charset-normalizer 3.2.0 pyhd8ed1ab_0 conda-forge; chex 0.1.82 pyhd8ed1ab_0 conda-forge; cleo 2.0.1 pyhd8ed1ab_0 conda-forge; click 8.1.6 unix_pyh707e725_0 conda-forge; colorama 0.4.6 pyhd8ed1ab_0 conda-forge; comm 0.1.3 pyhd8ed1ab_0 conda-forge; contextlib2 21.6.0 pyhd8ed1ab_0 conda-forge; contourpy 1.1.0 py310hd41b1e2_0 conda-forge; crashtest 0.4.1 pyhd8ed1ab_0 conda-forge; croniter 1.3.15 pyhd8ed1ab_0 conda-forge; cryptography 41.0.2 py310h75e40e8_0 conda-forge; cuda-cudart 11.8.89 0 nvidia; cuda-cupti 11.8.87 0 nvidia; cuda-libraries 11.8.0 0 nvidia; cuda-nvrtc 11.8.89 0 nvidia; cuda-nvtx 11.8.86 0 nvidia; cuda-runtime 11.8.0 0 nvidia; cycler 0.11.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:9722,certificate,certificates,9722,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205,1,['certificate'],['certificates']
Security,or at least the people with commit access to scanpy should be able to see the PR doc builds.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1307#issuecomment-655013333:35,access,access,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307#issuecomment-655013333,1,['access'],['access']
Security,"round. > Who manages the sub-packages?. Scverse (also it's one package not many). We are talking about 5-15 readers that have been touched a handful of times in 4-5 years. I don't think this is a complicated package to maintain. Agree that one person needs to take the lead on releases (probably very infrequent). > I feel like complicated dependency management was what we were trying to avoid here. Where is the complicated dependency management? We have a core set of readers (h5, pandas, scipy) and more complex readers (lazy import). We can have a conda env file too for everything if we want. Even anndata lazy imports loom for example. It's a small price to pay for ecosystem synchronization and enhanced user experience. > Packages which read in package specific formats with a minimal set of dependencies. It's also unclear to me what package specific stuff muon has in particular. The way I see it there's one `read_10x_h5(return_anndata=True, return_mudata=False, gex_only=None)` I don't think muon is loading any extra information or putting it in any package specific places?. > How does this impact users vs. developers?. Developers: (1) export `scio` readers into their packages, can contribute improvements to readers, (2), access to many more practical readers for their packages (scvi-tools has no 10x h5 reader because we don't feel the need to depend on scanpy for one function). Users: (1) no impact if they continue using the packages they like (e.g., scanpy reader will be completely unchanged). (2) Can go ahead and just use `scio` and then be on their way (a reality that many people do not feel the need to use scanpy/muon). If there are R converters, this would be a major use case. > What we read in, and how we represent it, is very tightly coupled to the methods we have. Up for discussion, but read the maximal amount of information by default. If necessary (don't see any particular cases at the moment), package devs use the underlying `scio` function and reorganize.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1387#issuecomment-1059551352:1696,access,access,1696,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1387#issuecomment-1059551352,1,['access'],['access']
Security,s://download.pytorch.org/whl/cu118; ```. This allows me to have GPU support with scvi-tools and different runs are reproducible. The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; absl-py 1.4.0 pypi_0 pypi; adjusttext 0.8 pypi_0 pypi; aiohttp 3.8.5 pypi_0 pypi; aiosignal 1.3.1 pypi_0 pypi; airr 1.4.1 pypi_0 pypi; anndata 0.9.1 pypi_0 pypi; anyio 3.7.1 pypi_0 pypi; arrow 1.2.3 pypi_0 pypi; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; async-timeout 4.0.2 pypi_0 pypi; attrs 23.1.0 pypi_0 pypi; awkward 2.3.1 pypi_0 pypi; awkward-cpp 21 pypi_0 pypi; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backoff 2.2.1 pypi_0 pypi; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pypi_0 pypi; blessed 1.20.0 pypi_0 pypi; brotli-python 1.0.9 py311ha362b79_9 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; certifi 2022.12.7 pypi_0 pypi; charset-normalizer 2.1.1 pypi_0 pypi; chex 0.1.7 pypi_0 pypi; click 8.1.6 pypi_0 pypi; cmake 3.25.0 pypi_0 pypi; colorama 0.4.6 pyhd8ed1ab_0 conda-forge; comm 0.1.3 pyhd8ed1ab_0 conda-forge; contextlib2 21.6.0 pypi_0 pypi; contourpy 1.1.0 pypi_0 pypi; croniter 1.4.1 pypi_0 pypi; cycler 0.11.0 pypi_0 pypi; dateutils 0.6.12 pypi_0 pypi; debugpy 1.6.7 py311hcafe171_0 conda-forge; decorator 5.1.1 pyhd8ed1ab_0 conda-forge; deepdiff 6.3.1 pypi_0 pypi; dm-tree 0.1.8 pypi_0 pypi; docrep 0.3.2 pypi_0 pypi; etils 1.3.0 pypi_0 pypi; executing 1.2.0 pyhd8ed1ab_0 conda-forge; fa2 0.3.5 py311hd4cff14_2 conda-forge; fastapi 0.100.0 pypi_0 pypi; filelock 3.9.0 pypi_0 pypi; flax 0.7.0 pypi_0 pypi; fonttools 4.41.1 pypi_0 pypi; frozenlist 1.4.0 pypi_0 pypi; fsspec 2023.6.0 pypi_0 pypi; h11 0.14.0 pypi_0 pypi; h5py 3.9.0 pypi_0 pypi; idna 3.4 pyhd8ed1ab_0 conda-forge; igraph 0.10.6 pypi_0 pypi; importlib-metadata 6.8.0 pyh,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:1876,certificate,certificates,1876,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205,1,['certificate'],['certificates']
Security,"so have been running into issues when trying to use the `gene_symbols` parameter with the `sc.pl.dotplot()` function despite the column with the proper `gene_symbols` being in my `adata.var` Data Frame. . ```; $ adata.var.columns; $ sc.pl.dotplot(adata, marker_genes, 'clusters', dendrogram=True, gene_symbols='alternate_gene_symbols'). ==============================================================================. Index(['gene_symbols', 'feature_types', 'n_cells', 'highly_variable', 'means',; 'dispersions', 'dispersions_norm', 'mean', 'std',; 'alternate_gene_symbols'],; dtype='object'). ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); File ~/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621, in Index.get_loc(self, key, method, tolerance); 3620 try:; -> 3621 return self._engine.get_loc(casted_key); 3622 except KeyError as err:. File ~/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/_libs/index.pyx:136, in pandas._libs.index.IndexEngine.get_loc(). File ~/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/_libs/index.pyx:163, in pandas._libs.index.IndexEngine.get_loc(). File pandas/_libs/hashtable_class_helper.pxi:5198, in pandas._libs.hashtable.PyObjectHashTable.get_item(). File pandas/_libs/hashtable_class_helper.pxi:5206, in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'alternate_gene_symbols'; ... ```. When I tried setting `adata.var['gene_symbols'] = adata.var['alternate_gene_symbols']` and trying to generate a `dotplot` with a random gene present in `alternate_gene_symbols`, I ran into the following error: . ```; ...; KeyError: ""Could not find keys '['KH.C1.159.']' in columns of `adata.obs` or in adata.raw.var['gene_symbols'].""; ```. It seems that `sc.pl.dotplot()` is expecting `gene_symbols` that are present in the `adata.raw.var` Data Frame versus the `adata.var` Data Frame. Is this the expected behavior for this parameter?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1636#issuecomment-1284430963:1284,hash,hashtable,1284,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636#issuecomment-1284430963,2,['hash'],['hashtable']
Security,"ss dask checks""""""; def __new__(cls, shape, dtype):; return csr_callable(shape, dtype). def make_dask_chunk(x, start: int, end: int) -> da.Array:; def take_slice(x, idx):; return x[idx]. return da.from_delayed(; delayed(take_slice)(x, slice(start, end)),; dtype=x.dtype,; shape=(end - start, x.shape[1]),; meta=CSRCallable,; ). def sparse_dataset_as_dask(x, stride: int):; n_chunks, rem = divmod(x.shape[0], stride). chunks = []; cur_pos = 0; for i in range(n_chunks):; chunks.append(make_dask_chunk(x, cur_pos, cur_pos + stride)); cur_pos += stride; if rem:; chunks.append(make_dask_chunk(x, cur_pos, x.shape[0])). return da.concatenate(chunks, axis=0). def read_w_sparse_dask(group, obs_chunk: int = 1000) -> AnnData:; return AnnData(; X=sparse_dataset_as_dask(sparse_dataset(group[""X""]), obs_chunk),; ); ```; After this setup:; ```python; mapper = fsspec.get_mapper(; ""https://vitessce-demo-data.storage.googleapis.com/anndata-demos/BALF_VIB-UGent_processed_cleaned.zarr/""; ); store = AccessTrackingStore(mapper, max_size=2**28); adata = read_w_sparse_dask(zarr.convenience.open_consolidated(store)); ```; This takes a moment, but not too long. Separately, to see that nothing is happening unexpected on these two operations:; ```python; import scanpy as sc; sc.pp.normalize_total(adata); sc.pp.log1p(adata); ```. The missing parts are; 1. `filter_{genes,cells}`; 2. `scale`; 3. `highly_variable_genes`; 4. `normalize_total` with `key_added`; 5. `normalize_total` with `exclude_highly_expressed` (even minus the warning). . The first four of these do some storage into `obs`/`var` of values, which is a blocker to being completely lazy because the values need to be computed for that as you pointed out. We could of course just skip that step for dask for now. Or keep it and iterate later. Separately, both `filter_{genes,cells}`and `normalize_total` with `exclude_highly_expressed` also do an subset operation for which we will need to allow `dask` indexing into `AnnData`, which could get hairy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2856#issuecomment-1983048375:1879,Access,AccessTrackingStore,1879,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2856#issuecomment-1983048375,1,['Access'],['AccessTrackingStore']
Security,"t force. Didn't work. Proceed to Step2.; ```python; (base) C:\WINDOWS\system32>conda activate Python38; (Python38) C:\WINDOWS\system32>pip install scikit-misc; Requirement already satisfied: scikit-misc in c:\users\park_lab\appdata\roaming\python\python38\site-packages (0.1.4); Requirement already satisfied: numpy in c:\users\park_lab\anaconda3\envs\python38\lib\site-packages (from scikit-misc) (1.20.3); ```; Step2: force install.; ```python; (Python38) C:\WINDOWS\system32>pip install scikit-misc --force; Collecting scikit-misc; Using cached scikit_misc-0.1.4-cp38-cp38-win_amd64.whl (142 kB); Collecting numpy; Downloading numpy-1.21.5-cp38-cp38-win_amd64.whl (14.0 MB); |████████████████████████████████| 14.0 MB 3.3 MB/s; Installing collected packages: numpy, scikit-misc; Attempting uninstall: numpy; Found existing installation: numpy 1.20.3; Uninstalling numpy-1.20.3:; Successfully uninstalled numpy-1.20.3; ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\Users\\Park_Lab\\anaconda3\\envs\\Python38\\Lib\\site-packages\\~umpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll'; Consider using the `--user` option or check the permissions.; ```; Step3: same errors.; ```python; sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'); sc.pl.highly_variable_genes(adata); ImportError Traceback (most recent call last); ~\anaconda3\envs\Python38\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 52 try:; ---> 53 from skmisc.loess import loess; 54 except ImportError:. ~\AppData\Roaming\Python\Python38\site-packages\skmisc\loess\__init__.py in <module>; 50 """"""; ---> 51 from ._loess import (loess, loess_model, loess_inputs, loess_control,; 52 loess_outputs, loess_prediction,. ImportError: DLL load failed while importing _loess: The specified module could not be found. During",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:1148,Access,Access,1148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,1,['Access'],['Access']
Security,"tall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. […] Generally, I think there should be a longer planning discussion about how configuration works. Agreed, probably in an extra issue. > I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for expression_atlas would have a reference to dataset_dir?. sounds great!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:2617,access,access,2617,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940,1,['access'],['access']
Security,"theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/preprocessing/_highly_variable_genes.py#L81)), but it's not that widely used. I think this is because it has to be implemented manually in the code (not sure if this is what you mean by ""intrinsic""?), which makes it take some effort to implement and not all contributors are aware of. I think using a decorator would be nice for abstracting out the process. This would have benefits of consistency of usage by making it easy, consistency of logged messages, and separation of concerns between computation and tracking. I also think you'd be able to know the exact set of operations from this approach. Assuming all top level functions have been wrapped with a decorator like the one I presented above, this code:. ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""); ```. Should result in a set of (psuedo-)records like:. ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""read_10x_h5"", ""args"": {""filename"": ""./10x_run/outs/filtered_gene_matrix.h5""}, ""returned_adata"": id(1)}; {""call"": ""normalize_per_cell"", ""args"": {""counts_per_cell_after"": 1000}, ""adata_id"": id(1)}; {""call"": ""log1p"", ""adata_id"": id(1)}; {""call"": ""pca"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```. It's pretty trivial to go through these logs and figure out what happened to the AnnData, and made accessible through helper functions. Maybe they'd look like `sc.logging.get_operations(adata_id=id(adata))` or `sc.logging.get_operations(written_to=""./cache/01_simple_process.h5ad"")`. There could also be a helper function to add the relevant records to some field in `.uns` of the relevant AnnData object or a setting which has a log handler do that automatically. Is there some set of information this wouldn't capture?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063:1798,access,accessible,1798,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063,1,['access'],['accessible']
Security,"tically. However, I'm wary of abandoning a critical discussion of imputation methods in this space because other portions of the typical workflow have issues as well. Further, I think there are important distinctions to be made between different classes of methodology that are (mis)used in this problem space. I. Methods that are fundamentally flawed by their assumptions or algorithm. These should obviously be avoided.; II. Methods that are fundamentally sound but are not sufficiently validated, e.g. the validation doesn't exist in this problem space, isn't sufficiently comprehensive/relevant, performs poorly against other fundamentally sound methodologies, or has such restrictive assumptions it isn't broadly useful/applicable.; III. Methods that are fundamentally sound in assumption/algorithm and can be used by a competent practitioner but still have the potential to be abused through applying it to data that violate those assumptions. I'd consider t-SNE and a great deal of the clustering algorithms to be in class III for the reasons you said; they're valid, functional tools but can be applied in assumption-violating or quasi-valid ways. I'm pretty sure that scImpute, for example, belongs in class I because its description of dropout and simulated test cases are inappropriate. I'd put MAGIC and several other currently available imputation methods in class II as they've got strong foundations but currently insufficient validation IMO. I'm not trying to pick on MAGIC or any specific imputation method. Instead I'd like to have an open discussion about the benefits, limitations, and relative performance of the various imputation methods available with the goal leading to something like @gokceneraslan suggested. Well, and since you brought it up, batch correction and multimodal integration methods are in definite need of the same open discussion, which I'd be happy to have, and I think they should have the same disclaimer regarding their limitations in the documentation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189#issuecomment-417692893:1618,validat,validation,1618,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189#issuecomment-417692893,1,['validat'],['validation']
Security,verything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software as the problems being solved are very very similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3054#issuecomment-2117801388:1144,access,access,1144,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054#issuecomment-2117801388,1,['access'],['access']
Security,"我同样面临着这个 bug; 我的代码是; ```python; #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']; genes_to_plot = ['Blvrb',#MEP marker; 'Klf1',#MEP marker; 'Serpina3f']#CMP marker; sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'); genes_to_plot = ['Coro1a',#CMP and GMP marker; 'Napsa',#GMP marker; 'Ly6c2']#GMP marker; sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'); ```; 错误信息：; ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-13-61edd8063c25> in <module>(); 3 'Klf1',#MEP marker; 4 'Serpina3f']#CMP marker; ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'); 6 genes_to_plot = ['Coro1a',#CMP and GMP marker; 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 124 (x in adata.obs.keys() or x in adata.var.index); 125 and (y in adata.obs.keys() or y in adata.var.index); --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index); 127 ):; 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key); 4069 False; 4070 """"""; -> 4071 hash(key); 4072 try:; 4073 return key in self._engine. TypeError: unhashable type: 'list'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1497#issuecomment-729598041:1537,hash,hash,1537,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497#issuecomment-729598041,1,['hash'],['hash']
Testability, 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70149,test,testing,70149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability, 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mn,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74755,test,testing,74755,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability," 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ============== 252 failed, 650 passed, 59 skipped, 5 xfailed, 1038 warnings, 128 errors in 451.20s (0:07:31) ===============. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:75161,test,tests,75161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,10,['test'],"['testing', 'tests']"
Testability, (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'annda,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57849,test,tests,57849,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability, (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.t,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59185,test,tests,59185,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability, (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'annda,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56513,test,tests,56513,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability, (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59688,test,tests,59688,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability," (`as_dense_dask_array` is getting hit often); * Make a new package with just the test helpers? Probably too much of a pain. ### ImportError: cannot import name 'check_is_fitted' from 'sklearn.base'. <details>; <summary> Raw test output </summary>. ```python; FAILED scanpy/tests/test_datasets.py::test_krumsiek11 - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/test_datasets.py::test_toggleswitch - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/get/get.py::scanpy.get.get.obs_df; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_right-groups.all] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.on_data-groups.3] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.True-legend.on_right-groups.all] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_visium_circles - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.on_data-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.off-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.defa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:2466,test,tests,2466,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability, +0.24% ; ==========================================; Files 98 104 +6 ; Lines 11518 11678 +160 ; ==========================================; + Hits 8281 8425 +144 ; - Misses 3237 3253 +16 ; ```. | [Impacted Files](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `60.86% <60.86%> (ø)` | |; | [scanpy/testing/\_pytest/marks.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `84.61% <84.61%> (ø)` | |; | [scanpy/testing/\_helpers/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvZGF0YS5weQ==) | `88.57% <88.57%> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `76.77% <100.00%> (ø)` | |; | [scanpy/plotting/\_tools/scatterplots.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9zY2F0dGVycGxvdHMucHk=) | `87.20% <100.00%> (-1.22%)` | :arrow_down: |; | [scanpy/testing/\_helpers/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235#issuecomment-1098162430:1866,test,testing,1866,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1098162430,1,['test'],['testing']
Testability," ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[49], line 1; ----> 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. I've pasted the output of scanpy.logging.print_versions() details below as requested, which includes a verification of used scanpy version (latest version, 1.9.3). It may not be important, but I also had to install `leidenalg` manually in the middle of the tutorial. That's the only deviation I made from the original tutorial. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:1493,log,logarithmize,1493,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453,1,['log'],['logarithmize']
Testability," /Users/isaac/github/scanpy, inifile: pytest.ini, testpaths: scanpy/tests/; plugins: pylama-7.7.1, parallel-0.0.10, cov-2.7.1, black-0.3.7, hypothesis-5.6.0; collected 393 items / 389 deselected / 4 skipped . scanpy/tests/test_ingest.py ...F [100%]. ========================================================== FAILURES ===========================================================; _______________________________________________ test_ingest_map_embedding_umap ________________________________________________. def test_ingest_map_embedding_umap():; adata_ref = sc.AnnData(X); adata_new = sc.AnnData(T); ; sc.pp.neighbors(; adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0; ); sc.tl.umap(adata_ref, random_state=0); ; ing = sc.tl.Ingest(adata_ref); ing.fit(adata_new); ing.map_embedding(method='umap'); ; reducer = UMAP(min_dist=0.5, random_state=0, n_neighbors=4); reducer.fit(X); umap_transformed_t = reducer.transform(T); ; > assert np.allclose(ing._obsm['X_umap'], umap_transformed_t); E assert False; E + where False = <function allclose at 0x119616b00>(array([[16.566338, 20.174282],\n [15.368203, 20.291983]], dtype=float32), array([[16.502459, 20.157679],\n [15.581459, 20.302881]], dtype=float32)); E + where <function allclose at 0x119616b00> = np.allclose. scanpy/tests/test_ingest.py:140: AssertionError; ---------------------------------------------------- Captured stderr call -----------------------------------------------------; computing neighbors; finished: added to `.uns['neighbors']`; 'distances', distances for each pair of neighbors; 'connectivities', weighted adjacency matrix (0:00:00); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:00:00); ```. With these versions:. ```python; >>> sc.logging.print_versions() ; scanpy==1.4.5.2.dev37+g51dc038 anndata==0.7.2.dev13+g4440b90.d20200316 umap==0.4.0rc1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1036#issuecomment-599469073:1294,assert,assert,1294,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036#issuecomment-599469073,4,"['Assert', 'assert', 'log', 'test']","['AssertionError', 'assert', 'logging', 'tests']"
Testability, 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residual,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2125,test,tests,2125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['test'],['tests']
Testability, 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3004,test,tests,3004,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['test'],['tests']
Testability," ; if sp_sparse.issparse(batch_counts):; @@ -173,6 +176,7 @@ def _highly_variable_genes_seurat_v3(; df = df.drop(['highly_variable_nbatches'], axis=1); return df; ; +; def _highly_variable_pearson_residuals(; adata: AnnData,; layer: Optional[str] = None,; @@ -182,7 +186,7 @@ def _highly_variable_pearson_residuals(; clip: Union[Literal['auto', 'none'], float] = 'auto',; chunksize: int = 100,; subset: bool = False,; - inplace: bool = True; + inplace: bool = True,; ) -> Optional[pd.DataFrame]:; """"""\; See `highly_variable_genes`.; @@ -212,7 +216,7 @@ def _highly_variable_pearson_residuals(; in all batches; """"""; ; - view_to_actual(adata) ; + view_to_actual(adata); X = _get_obs_rep(adata, layer=layer); computed_on = layer if layer else 'adata.X'; ; @@ -328,8 +332,7 @@ def _highly_variable_pearson_residuals(; df = df.loc[adata.var_names]; ; if inplace or subset:; - adata.uns['hvg'] = {'flavor': 'pearson_residuals',; - 'computed_on':computed_on}; + adata.uns['hvg'] = {'flavor': 'pearson_residuals', 'computed_on': computed_on}; logg.hint(; 'added\n'; ' \'highly_variable\', boolean vector (adata.var)\n'. ...skipping 1 line; ['highly_variable_nbatches', 'highly_variable_intersection'], axis=1; ); return df; - ; - ; - ; +; ; def _highly_variable_genes_single_batch(; adata: AnnData,; @@ -479,7 +480,6 @@ def _highly_variable_genes_single_batch(; return df; ; ; -; def highly_variable_genes(; adata: AnnData,; layer: Optional[str] = None,; @@ -493,7 +493,9 @@ def highly_variable_genes(; theta: float = 100,; clip: Union[Literal['auto', 'none'], float] = 'auto',; chunksize: int = 1000,; - flavor: Literal['seurat', 'cell_ranger', 'seurat_v3', 'pearson_residuals'] = 'seurat',; + flavor: Literal[; + 'seurat', 'cell_ranger', 'seurat_v3', 'pearson_residuals'; + ] = 'seurat',; subset: bool = False,; inplace: bool = True,; batch_key: Optional[str] = None,; @@ -651,21 +653,20 @@ def highly_variable_genes(; if flavor == 'pearson_residuals':; if n_top_genes is None:; raise ValueError(; - ""`pp.hi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-794148562:10553,log,logg,10553,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-794148562,1,['log'],['logg']
Testability, ; liblief 0.10.1 he6710b0_0 ; libllvm10 10.0.1 hbcb73fb_5 ; libllvm9 9.0.1 h4a3c616_1 ; libpng 1.6.37 hbc83047_0 ; libsodium 1.0.18 h7b6447c_0 ; libspatialindex 1.9.3 h2531618_0 ; libssh2 1.9.0 h1ba5d50_1 ; libstdcxx-ng 9.1.0 hdf63c60_0 ; libtiff 4.2.0 h85742a9_0 ; libtool 2.4.6 h7b6447c_1005 ; libuuid 1.0.3 h1bed415_2 ; libuv 1.40.0 h7b6447c_0 ; libwebp-base 1.2.0 h27cfd23_0 ; libxcb 1.14 h7b6447c_0 ; libxml2 2.9.10 hb55368b_3 ; libxslt 1.1.34 hc22bd24_0 ; llvmlite 0.36.0 py38h612dafd_4 ; locket 0.2.1 py38h06a4308_1 ; loompy 2.0.16 py_0 bioconda; lxml 4.6.3 py38h9120a33_0 ; lz4-c 1.9.3 h2531618_0 ; lzo 2.10 h7b6447c_2 ; magic-impute 2.0.4 pypi_0 pypi; make 4.2.1 h1bed415_1 ; markupsafe 2.0.1 py38h27cfd23_0 ; matplotlib 3.3.4 py38h06a4308_0 ; matplotlib-base 3.3.4 py38h62a2d02_0 ; mccabe 0.6.1 py38_1 ; mistune 0.8.4 py38h7b6447c_1000 ; mkl 2021.2.0 h06a4308_296 ; mkl-service 2.3.0 py38h27cfd23_1 ; mkl_fft 1.3.0 py38h42c9631_2 ; mkl_random 1.2.1 py38ha9443f7_2 ; mnnpy 0.1.9.5 pypi_0 pypi; mock 4.0.3 pyhd3eb1b0_0 ; more-itertools 8.7.0 pyhd3eb1b0_0 ; mpc 1.1.0 h10f8cd9_1 ; mpfr 4.0.2 hb69a4c5_1 ; mpmath 1.2.1 py38h06a4308_0 ; msgpack-python 1.0.2 py38hff7bd54_1 ; multicoretsne 0.1 pypi_0 pypi; multidict 5.1.0 pypi_0 pypi; multipledispatch 0.6.0 py38_0 ; mypy_extensions 0.4.3 py38_0 ; natsort 7.1.1 pyhd3eb1b0_0 ; nbclassic 0.2.6 pyhd3eb1b0_0 ; nbclient 0.5.3 pyhd3eb1b0_0 ; nbconvert 6.0.7 py38_0 ; nbformat 5.1.3 pyhd3eb1b0_0 ; ncurses 6.2 he6710b0_1 ; nest-asyncio 1.5.1 pyhd3eb1b0_0 ; networkx 2.5 py_0 ; nltk 3.6.2 pyhd3eb1b0_0 ; nose 1.3.7 pyhd3eb1b0_1006 ; notebook 6.4.0 py38h06a4308_0 ; numba 0.53.1 py38ha9443f7_0 ; numexpr 2.7.3 py38h22e1b3c_1 ; numpy 1.20.2 py38h2d18471_0 ; numpy-base 1.20.2 py38hfae3a4d_0 ; numpydoc 1.1.0 pyhd3eb1b0_1 ; nvidia-ml-py3 7.352.0 pypi_0 pypi; olefile 0.46 py_0 ; opencensus 0.7.13 pypi_0 pypi; opencensus-context 0.1.2 pypi_0 pypi; openpyxl 3.0.7 pyhd3eb1b0_0 ; openssl 1.1.1k h27cfd23_0 ; packaging 20.9 pyhd3eb1b0_0 ; palantir 1.0.0 py,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310:11263,mock,mock,11263,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310,1,['mock'],['mock']
Testability," And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mea",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:1084,test,tested,1084,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823,2,['test'],"['tested', 'testing']"
Testability, AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image fi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48183,Assert,AssertionError,48183,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Assert'],['AssertionError']
Testability, ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74342,test,tests,74342,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability, ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportErro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68937,test,tests,68937,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability, FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_paga.py::test_paga_plots[compare-func4] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_pie - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_paga.py::test_paga_plots[compare_pca-func6] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:41708,test,tests,41708,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability, FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2228,test,tests,2228,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['test'],['tests']
Testability, FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_ordinal - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_layer - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_view - ImportError: cannot import name '_centered' from ',MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:5726,test,tests,5726,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['test'],['tests']
Testability, Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_paga.py::test_paga_plots[-paga] - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_paga.py::test_paga_plots[compare-func4] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_pie - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_paga.py::test_paga_plots[compare_pca-func6] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:41114,test,test,41114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['test']
Testability, Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2681,test,tests,2681,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['test'],['tests']
Testability, ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_layer - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_view - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_categorical - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants_equivalent - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tools/_dendrogram.py::scanpy.tools._,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:7256,test,test,7256,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['test'],['test']
Testability," No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/test_datasets.py::test_toggleswitch - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/get/get.py::scanpy.get.get.obs_df; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_right-groups.all] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.on_data-groups.3] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.True-legend.on_right-groups.all] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_visium_circles - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.on_data-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.off-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.True-legend.off-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.True-legend.off-groups.all] - numpy.core._exceptions",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:2813,test,tests,2813,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability, [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2563,test,tests,2563,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['test'],['tests']
Testability, [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3442,test,tests,3442,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['test'],['tests']
Testability," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; return dispatch(args[0].__class__)(*args, **kw); scanpy/preprocessing/_simple.py:888: in scale_anndata; X, adata.var[""mean""], adata.var[""std""] = do_scale(; ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; error_rewrite(e, 'typing'); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); issue_type = 'typing'. def error_rewrite(e, issue_type):; """"""; Rewrite and raise Exception `e` with help supplied based on the; specified issue_type.; """"""; if config.SHOW_HELP:; help_msg = errors.error_extras[issue_type]; e.patch_message('\n'.join((str(e).rstrip(), help_msg))); if config.FULL_TRACEBACKS:; raise e; else:; > raise e.with_traceback(None); E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); E non-precise type pyobject; E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); E ; E File ""scanpy/preprocessing/_simple.py"", line 763:; E def do_scale(X, maxv, nthr):; E <source elided>; E # t0= time.time(); E s = np.zeros((nthr, X.shape[1])); E ^ ; E ; E This error may have been caused by the following argument(s):; E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>. ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; ```. When trying to use the new flavor with the existing test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183:2716,test,test,2716,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183,1,['test'],['test']
Testability," all values set to `0`, anyway (but with less arbitrary magic numbers and maybe less rounding errors). But if `zero_zenter == False`, unscalable values are untouched. This only affected the dense codepath where zero-centering was done afterwards anyway due to the original bug. Therefore this is no code breaking change.; But I also moved this statement before the sparse check to have consistent handling of sparse and dense data. Before that the sparse path wrote infs in the values (unchecked divison by zero) - this is a potentially code breaking change, but it only leads to the behaviour already stated in the documentation. I personally think that code relying on this undocumented behaviour should be rewritten, anyway...; In the new test I explicitly check for this behaviour to make it well defined.; Similar for integer datatypes (resulted in an error), they are now converted to floating point for scaling and return a copy. BTW: In order to make the tests run in my conda environment, I had to remove every reference to compare_images from matplotlib.testing.compare. There seems to be a version conflict in the version checking... It always gave errors like the following:; `________________ ERROR collecting scanpy/tests/test_plotting.py ________________; scanpy/tests/test_plotting.py:16: in <module>; from matplotlib.testing.compare import compare_images; ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:240: in <module>; _update_converter(); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:222: in _update_converter; mpl._get_executable_info(""gs""); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/__init__.py:364: in _get_executable_info; return impl([e, ""--version""], ""(.*)"", ""9""); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/__init__.py:346: in impl; if min_ver is not None and version < min_ver:; ~/.conda/envs/custom/lib/python3.8/distutils/version.py:52: in __lt__; c = self._cmp(other);",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330:1318,test,tests,1318,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330,1,['test'],['tests']
Testability," arbitrary tiny variance, which arbitrarily blew up the scaled value and made it completely meaningless `scale[scale == 0] = 1e-12`.; Now I put instead `scale[scale == 0] = 1`. This yields the same result for `zero_center == True`: all values set to `0`, anyway (but with less arbitrary magic numbers and maybe less rounding errors). But if `zero_zenter == False`, unscalable values are untouched. This only affected the dense codepath where zero-centering was done afterwards anyway due to the original bug. Therefore this is no code breaking change.; But I also moved this statement before the sparse check to have consistent handling of sparse and dense data. Before that the sparse path wrote infs in the values (unchecked divison by zero) - this is a potentially code breaking change, but it only leads to the behaviour already stated in the documentation. I personally think that code relying on this undocumented behaviour should be rewritten, anyway...; In the new test I explicitly check for this behaviour to make it well defined.; Similar for integer datatypes (resulted in an error), they are now converted to floating point for scaling and return a copy. BTW: In order to make the tests run in my conda environment, I had to remove every reference to compare_images from matplotlib.testing.compare. There seems to be a version conflict in the version checking... It always gave errors like the following:; `________________ ERROR collecting scanpy/tests/test_plotting.py ________________; scanpy/tests/test_plotting.py:16: in <module>; from matplotlib.testing.compare import compare_images; ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:240: in <module>; _update_converter(); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:222: in _update_converter; mpl._get_executable_info(""gs""); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/__init__.py:364: in _get_executable_info; return impl([e, ""--version""], ""(.*)"", ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330:1097,test,test,1097,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330,1,['test'],['test']
Testability," been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:26: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:26: warning: 'PyUnicode_AsUnicode' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:262:14: note: expanded from macro 'PyUnicode_GET_SIZE'; ((void)PyUnicode_AsUnicode(_PyObject_CAST(op)),\; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:580:1: note: 'PyUnicode_AsUnicode' has been explicitly marked deprecated here; Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:26: warning: '_PyUnicode_ge",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:12203,test,test,12203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['test'],['test']
Testability," been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:59: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:59: warning: 'PyUnicode_AsUnicode' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:262:14: note: expanded from macro 'PyUnicode_GET_SIZE'; ((void)PyUnicode_AsUnicode(_PyObject_CAST(op)),\; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:580:1: note: 'PyUnicode_AsUnicode' has been explicitly marked deprecated here; Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:59: warning: '_PyUnicode_ge",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:14835,test,test,14835,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['test'],['test']
Testability," claims it makes. > it is not strictly a new method, but has several connections with previous sctransform and glm-pca (also, not sure on what basis you said that ""glm-pca is supposed to be better"", would be genuinely curious to see some evaluations). My point here was to say that historically Scanpy hasn't rushed to add _any_ method that is better than log normalization -> PCA. I was using GLM-PCA as a generic example, but I then realized that coincidentally in the GLM-PCA paper they describe a fast analytical approximation using deviance residuals, which is not compared to in the analytical Pearson residuals manuscript (and again highlights the potential role of peer-review IMO). If deviance residuals give a similar latent space, what do you do then? Add both?. > So, my take is: let's get the pearson residuals from @jlause @dkobak in scanpy, and keep pushing to get the others methods in here as well! at the end, this will ultimately benefit greatly the users. Personally this is how I feel -- the more the better! But historically getting a method in the scanpy core is not so easy (even just seeing the back and forth on the linked issue makes it seem like this is the case for this method). This is why I think it's practically important for Scanpy to be very choosy if it's not going to offer multiple competing workflows with really clear tutorials about which is appropriate and their limitations. Looking into this method further, I even have more questions in the context of Scanpy:. 1. How does this affect the workflow for DE? In scTransform I noticed they create some corrected counts by using the median library size to ""invert"" the regression. This should also be possible here? Though it's not exactly clear in Seurat what to use for DE, based on many issues I found.; 2. Should people be using these values for visualization?; 3. What's the workflow if people need both log normalized and pearson residuals?; 4. Will there be more tutorials covering all these use cases?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-799542693:2550,log,log,2550,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-799542693,1,['log'],['log']
Testability," cytof papers to deal with extreme outliers (believed to be technical artifacts); here, I simply use it to move the bulk of the data in visible range for the first two plots; while the values are merely a heuristic, the spirit of it follows nonparametric statistics so is pretty reliable in practice. ### raw (ADT counts):; ![image](https://user-images.githubusercontent.com/20694664/83345454-4956fb80-a2e1-11ea-8ae7-e13dfcc10cac.png). ### geometric mean (as used in Issac's notebook); ![image](https://user-images.githubusercontent.com/20694664/83345468-6f7c9b80-a2e1-11ea-8a42-acad50bfb66b.png). seems to only changes the scale, not the shape, so unless I made an error in implementation... it's probably not useful. ### simple log(n+1) (as used in RNAseq); ![image](https://user-images.githubusercontent.com/20694664/83345487-a05cd080-a2e1-11ea-858e-4d98621d12e6.png). can suffer from discretization at low values... note: even though Seurat/Scanpy/Loupe all use different bases, the log base doesn't really matter; it just changes the scale, not the shape/distinguishing power. ### hyperbolic arcsin (as used in CyTOF); ![image](https://user-images.githubusercontent.com/20694664/83345476-81f6d500-a2e1-11ea-8f68-ddff22ffe853.png). not as noisy as log at low values, and doesn't assert that zeros have to be Laplace smoothed with a pseudocount of +1. ### biexponential family (as used in flow cytometry); ![image](https://user-images.githubusercontent.com/20694664/83345554-6fc96680-a2e2-11ea-8112-3bdc09260e63.png). best smoothing so far in the low counts, because that's what it was designed to do. in this case, it is the newest of this family: `vlog(alpha=0, beta=12, xmax=70000, zmax=1)`; - https://doi.org/10.1002/cyto.a.23017; - https://doi.org/10.1002/cyto.a.22030; - https://doi.org/10.1002/cyto.a.20258. ### centered log ratio (as used in CITEseq paper); ![image](https://user-images.githubusercontent.com/20694664/83345643-a9e73800-a2e3-11ea-8303-365fccca16cc.png). not only does this ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-636429530:1115,log,log,1115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117#issuecomment-636429530,1,['log'],['log']
Testability, did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.default-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.default-na_in_legend.False-legend.on_right-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-200n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:14567,test,tests,14567,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability, did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_violin_without_raw - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_path - numpy.core._exceptions._UFu,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:44166,test,tests,44166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability, did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_violin - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_binary_scatter - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_color_cycler - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_repeated_colors_w_missing_value - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:50194,test,tests,50194,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability, errors include:. * A lot of `AssertionError: Error: Image files did not match.`; * Some missing function from scipy; * Missing pynndescent; * 3 or 4 more unique ones. <details>; <summary> </summary>. ```python; FAILED scanpy/get/get.py::scanpy.get.get.obs_df; FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_metrics.py::test_consistency[morans_i-allclose] - AssertionError: ; FAILED scanpy/tests/test_paga.py::test_paga_plots[-paga] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image fil,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:1180,Assert,AssertionError,1180,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Assert'],['AssertionError']
Testability," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:1542,log,log-mean,1542,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823,5,"['log', 'test']","['log', 'log-mean', 'log-transformation', 'test']"
Testability, files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:3662,Assert,AssertionError,3662,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Assert'],['AssertionError']
Testability, from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.t,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70978,test,testing,70978,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability, from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61322,test,tests,61322,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability, from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mn,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63128,test,testing,63128,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability, from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72299,test,tests,72299,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability, from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.pa,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68034,test,testing,68034,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability, import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Im,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47799,Assert,AssertionError,47799,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Assert'],['AssertionError']
Testability," improved!. 56 failed, 1236 passed, 96 skipped, 19 xfailed, 9 xpassed, 763 warnings in 595.02s (0:09:55). Remaining errors include:. * A lot of `AssertionError: Error: Image files did not match.`; * Some missing function from scipy; * Missing pynndescent; * 3 or 4 more unique ones. <details>; <summary> </summary>. ```python; FAILED scanpy/get/get.py::scanpy.get.get.obs_df; FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_metrics.py::test_consistency[morans_i-allclose] - AssertionError: ; FAILED scanpy/tests/test_paga.py::test_paga_plots[-paga] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED sc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:1079,Assert,AssertionError,1079,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Assert'],['AssertionError']
Testability," is more representative of the data than an arbitrary k neighbors. Even if you do use a hard cutoff on number of neighbors, I don't see how discounting all distance information would give a more accurate result. I would suspect using a weighted graph could perform better at identifying small subpopulations (where nearest neighbors from other cell types could be common), but that's just conjecture. That's just speculation to me. I never saw convincing benchmarks. No one claims that ""discounting all distance information gives a more accurate result"". It's just that it's computationally cheaper. I acknowledge that a ""non-fixed-degree knn graph"" varying say, between 5 and 100, would be computationally tractable and would carry information about the sampling density of the data in the given representation. This information is only indirectly available in the fixed-degree knn graph (more loops etc. in high-density regions). I never investigated this as I never saw fundamental results on such a non-fixed-degree knn graph. As it's also hard to benchmark this, I'd be afraid of getting into this if one doesn't have the time to get the fundamentals right. I want to note that even in the context of diffusion processes, we managed to obtain meaningful results with kNN graphs in practice. And this clearly contradicts the fundamental results found in all the Coifman papers. Having said that: if the code is simple, I don't mind at all to have the possibility that you suggest, @ivirshup. Please go ahead with a pull request and I'll see whether the changes are simple enough. The user will still use the default plain knn version, which is also what is done in Seurat. But my philosophy rests the same: rather than engineering the clustering or any other aspect of the manifold analysis, one should engineer the representation. Sorry that this got a bit length and confused. I hope I addressed everything but I feel I'm still missing something - I'm currently working through a lot of issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-416725777:2118,benchmark,benchmark,2118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/240#issuecomment-416725777,1,['benchmark'],['benchmark']
Testability," key, **kwargs). adata.obsm[adjusted_basis] = harmony_out.Z_corr.T. adata = sc.read_h5ad('adata.h5ad'). adata_merge = adata.copy(); adata_merge.X = adata_merge.layers['counts']; sc.experimental.pp.highly_variable_genes(adata_merge, n_top_genes=3000, batch_key='batch'). adata_merge = adata_merge[:, adata_merge.var['highly_variable']].copy(); sc.experimental.pp.normalize_pearson_residuals(adata_merge); adata_merge.layers['apr'] = adata_merge.X.copy(); sc.tl.pca(adata_merge, svd_solver=""arpack""); adata_merge.obsm['X_pca_30'] = adata_merge.obsm['X_pca'][:, :30]. adata1 = adata_merge.copy(); adata2 = adata_merge.copy(); ```. The frist test:. ```; # scanpy 1.9.6 that changes of this PR won't have taken effect yet.; # I copy the harmony_integrate from https://github.com/scverse/scanpy/blob/75cb4e750efaccc1413cb204ffa49d21db017079/scanpy/external/pp/_harmony_integrate.py; harmony_integrate(adata1, key='batch', basis='X_pca_30'); harmony_integrate(adata2, key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; y: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; ```. The second test:. ```; sc.pp.neighbors(adata1, n_pcs=30, use_rep='X_pca_harmony'); sc.pp.neighbors(adata2, n_pcs=30, use_rep='X_pca_harmony'); np.testing.assert_array_equal(adata1.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched eleme",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:1545,test,testing,1545,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227,1,['test'],['testing']
Testability," key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; y: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; ```. The second test:. ```; sc.pp.neighbors(adata1, n_pcs=30, use_rep='X_pca_harmony'); sc.pp.neighbors(adata2, n_pcs=30, use_rep='X_pca_harmony'); np.testing.assert_array_equal(adata1.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 268636 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 434492 (61.8%); Max absolute difference: 0.99820393; Max relative difference: 810.4644; x: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179325, 1. ],; dtype=float32); y: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179324, 1. ],; dtype=float32); ```. This is my session_info:. ```; Click to view session information; -----; anndata 0.9.2; loguru 0.7.2; matplotlib 3.8.0; numpy 1.26.0; pandas 1.4.3; scanpy 1.9.6; seaborn 0.12.2; session_info 1.0.0; -----; Click to view modules imported as dependencies; PIL 9.4.0; argcomplete NA; asttokens NA; attr 23.1.0; awkward 2.4.2; awkward_cpp NA; backcall 0.2.0; cffi 1.15.1; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; dot_parser NA; etils 1.4.1; exceptiongroup 1.1.3; executing 1.2.0; get_annotations NA; gmpy2 2.1.2; h5py 3.9.0; harmonypy NA; igraph 0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:2493,Assert,AssertionError,2493,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227,1,['Assert'],['AssertionError']
Testability, match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_ordinal - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_layer - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_view - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_categorical - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants_equivalent - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrix,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:6846,test,tests,6846,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['test'],['tests']
Testability," methods paper, e.g., the [scran pooling paper](http://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0947-7)), there are a couple of things to consider here:; 1. Do we even want relative expression counts?; 2. What assumptions do downstream methods have on the distribution of expression values. For the first question: relative gene expression values ignore differences in cell sizes/number of molecules in the cell. There are some molecules whose numbers scale with the size of the cell, and others that don't (e.g., many housekeeping genes). Choosing relative over absolute expression values to compare gene expression across cells would be helpful to compare expression of those genes that scale with size, but not the others.... so there's not really a perfect answer here. Thus, removing all effects of total counts may not be the desirable outcome. Secondly, many downstream methods assume normally distributed expression data (e.g., DE methods like: t-tests, limma, MAST, or several batch correction/data integration methods). Log transformation is used as a variance stabilization to approximate a normal distribution (quite often poorly, but better than without). This leads to many methods performing better with log transformation. IMO, the ideal approach is probably something like scVI, GLMPCA, or scTransform, where you fit a model directly to the count data and use the residuals to describe the data. This would address both steps of normalization and variance stabilization at the same time. If we have a good model to describe the data, the residuals should quantify the biological variance + normally distributed noise. Overall, I would use other normalization approaches than CPM, and use log-transformation with anything that uses size factors that scale per-cell expression values. . Note also that the effect described in the second paper you mention (from Aaron Lun) will mainly be relevant when you have biased distributions of sequencing depth between two samp",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643:1385,test,tests,1385,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643,1,['test'],['tests']
Testability," n_genes, groupby, key, show, save, **kwds); > 305 from ..anndata import stacked_violin; > 306 return stacked_violin(adata, gene_names, groupby, var_group_labels=group_names,; > --> 307 var_group_positions=group_positions, show=show, save=save, **kwds); > 308; > 309 elif plot_type == 'tracksplot':; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); > 819 if isinstance(var_names, str):; > 820 var_names = [var_names]; > --> 821 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer=layer); > 822; > 823 if 'color' in kwds:; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer); > 1983 matrix = adata[:, var_names].layers[layer]; > 1984 elif use_raw:; > -> 1985 matrix = adata.raw[:, var_names].X; > 1986 else:; > 1987 matrix = adata[:, var_names].X; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index); > 510; > 511 def __getitem__(self, index):; > --> 512 oidx, vidx = self._normalize_indices(index); > 513 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]; > 514 else: X = self._adata.file['raw.X'][oidx, vidx]; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_indices(self, packed_index); > 538 obs, var = super(Raw, self)._unpack_index(packed_index); > 539 obs = _normalize_index(obs, self._adata.obs_names); > --> 540 var = _normalize_index(var, self.var_names); > 541 return obs, var; > 542; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_index(index, names); > 270 raise KeyError(; > 271",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/438#issuecomment-456735910:2194,log,log,2194,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-456735910,1,['log'],['log']
Testability," not a drama, because Scanpy only writes ""storage-friendly"" values to AnnData, that is, arrays and dicts. HDF5 knows how to handle them and zarr also. If one uses xarray or dataframes, one has to think about how this gets written to disk. That being said: it's likely that we'll continue to choose representations for on-disk (and in-memory) storage that aren't convenient (rec arrays, for instance), a three-dimensional xarray and dicts. A general solution for this problem would be the mentioned `sc.extract` API, similar to `sc.plotting` (which also completely hides the complexity of the object from the user), but not for returning visualizations, but nice objects. The first function in that namespace should be `sc.ex.neighbors`, which should return an instance of `sc.Neighbors` (which can then disappear from the root API). Similarly, when `sc.pp.neighbors` is called with `inplace=False`, one should directly get a `Neighbors` object returned. Now, we can apply this logic to every single function that doesn't have a simple return value. Upon calling the function with `inplace=False`, you'll get a ""nice"" object that is convenient to handle. If you call a function `sc.tl.function` in a pipeline with `inplace=True` but later on, you'll want this nice object, you'd call `sc.ex.function`. I think DataFrames (a case like `tl.marker_gene_overlap`) should definitely be handled within AnnData and no `extract` function is necessary. But the differential expression result is a prime example for such a case. I think a function `rank_genes_groups` that returns a `RankGenesGroups` object, which then has `.to_df()` function (e.g. the function `rank_genes_groups` from (https://github.com/theislab/scanpy/pull/619) could immediately go into that namespace. Maybe we can even borrow a `diffxpy` object for that. The good thing is, we can keep the current rec arrays as they are very efficient and basic data types, which will work with hdf5 and zarr and xarray and everything else that might co",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:2726,log,logic,2726,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358,1,['log'],['logic']
Testability, not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_violin - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_binary_scatter - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_color_cycler - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:50054,test,tests,50054,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability, not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_ordinal - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_layer - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_view - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_categorical - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants_equivalent - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - Assertio,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:7030,test,test,7030,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['test'],['test']
Testability," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-801745797:2280,log,logical,2280,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-801745797,1,['log'],['logical']
Testability," of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:1327,test,tests,1327,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986,1,['test'],['tests']
Testability," one dataset, I can plot any gene I want and it succeeds. For the other dataset, I can't plot **any** gene, in any type of plot (tsne, violin, dotplot, matrixplot, etc.). ```; adata_1 = sc.read_h5ad(""path/to/file1.h5ad""); adata_2 = sc.read_h5ad(""path/to/file2.h5ad""); ```. ```; #this works; sc.pl.dotplot(adata_1, adata_1.var_names[0:4], groupby='clusters', color_map = 'Reds'). #these do not; sc.pl.dotplot(adata_2, adata_2.var_names[0:4], groupby='celltype', color_map = 'Reds'); ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-72-4fc81df5ca3f> in <module>; ----> 1 sc.pl.dotplot(adata_2, adata_2.var_names[0:4], groupby='celltype', color_map = 'Reds'). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\plotting\_anndata.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, color_map, dot_max, dot_min, standard_scale, smallest_dot, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, show, save, **kwds); 1809 num_categories,; 1810 layer=layer,; -> 1811 gene_symbols=gene_symbols,; 1812 ); 1813 . ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\plotting\_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 2911 matrix = adata[:, var_names].layers[layer]; 2912 elif use_raw:; -> 2913 matrix = adata.raw[:, var_names].X; 2914 else:; 2915 matrix = adata[:, var_names].X. ~\Anaconda3\envs\UMCU\lib\site-packages\anndata\_core\raw.py in __getitem__(self, index); 94 ; 95 def __getitem__(self, index):; ---> 96 oidx, vidx = self._normalize_indices(index); 97 ; 98 # To preserve two dimensional shape. ~\Anaconda3\envs\UMCU\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index); 154 obs, var = unpack_index(packed_index); 155 obs = _normalize_index(obs, self._adata.obs_names); --> 156 var = _normalize_index(var, self.var_na",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1406#issuecomment-704271652:1089,log,log,1089,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1406#issuecomment-704271652,1,['log'],['log']
Testability," other packages provide this value? If so, what do they call this column?. Again, mean expression and fraction of cells ""expressing"" a gene is expected by A LOT OF people running DE in any single cell tool. I am not asking for these features randomly or only bcs I personally need them, it is indeed needed by many people. Seurat users expect them too. scanpy API should prioritize the users a little bit more, in my opinion. If it sounds too subjective let's make an experiment: let's make a poll on Twitter using the scanpy account ask people if they think fractions are needed or not and how they feel about these names :). Main suggestion was indeed influenced by Seurat (see https://github.com/theislab/scanpy/pull/1081#issuecomment-595789816). But I don't really mind what the name will be. I think most people in the field are familiar with these names (even mu and alpha are used a lot for mean expression and fraction of cells expressing a gene, even though it is even more cryptic). . I do not think there is a super easy way to find a short and obvious name for the column, but I think using fraction_group and fraction_rest (or fraction_ref) are good enough. Reason I suggest fraction_rest is because ""rest"" is the default value of the reference argument in rank_genes_groups. We can also make it `f""fraction_{reference}""`, if this is the way it is implemented. Speaking of the column names, for example, do you think `score` is really obvious :) Try to ask a few regular scanpy users what `score` means in the DE results we generate. Even our documentation is wrong: `Structured array to be indexed by group id storing the z-score underlying the computation of a p-value for each gene for each group.` It is the logistic regression beta coef for logreg and t-statistic for t-test, it's not z-score at all... . So, even if the column name is not obvious, I think it's ok to explain it properly in the documentation and for `fraction_group`, it is easy (also easier than score) to explain.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1388#issuecomment-706623744:3398,log,logistic,3398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1388#issuecomment-706623744,3,"['log', 'test']","['logistic', 'logreg', 'test']"
Testability," sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20); ```. With an error output of the following:. ```pytb; ranking genes; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[49], line 1; ----> 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. I've pasted the output of scanpy.logging.print_versions() details below as requested, which includes a verification of used scanpy version (latest version, 1.9.3). It may not be important, but I also had to install `leidenalg` manually in the middle of the tutorial. That's the only deviation I made from the original tutorial. <details>. ```; -----; anndata 0.9.2; scanpy 1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:1386,log,logreg,1386,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453,2,['log'],"['logg', 'logreg']"
Testability, scanpy/tests/test_paga.py::test_paga_pie - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_paga.py::test_paga_plots[compare_pca-func6] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image f,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:42323,test,tests,42323,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability, scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48248,test,tests,48248,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability," setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:2021,test,test,2021,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986,6,['test'],"['test', 'tests']"
Testability," the question, now that similar panels are being used, which transform makes the most sense in terms of:; - preserving visual interpretation of absent/low/med/high (corresponding to expectations of cell subsets); - handling a variety of marker distribution shapes (unimodal/bimodal/trimodal, skewed shapes); - making it easier to spot nonspecific antibody staining / off-target effects; - not introducing more bias in downstream differential comparisons (fits with assumptions about variable distribution properties, based on the commonly used statistical testing methods). absent a convincing answer, it may be worth implementing multiple as options, leaving the choice to the user, and just documenting these use-cases through citations; eventually, someone can make a notebook that compares the behaviors, biological expectations, and/or impacts on statistical comparisons to inform which method should be the default. While the CITEseq paper applied CLR, it's not obvious that one is better than the ones used in more time-tested fields like mass cytometry and flow cytometry. ```python; def CLR_transform(df):; '''; implements the CLR transform used in CITEseq (need to confirm in Seurat's code); https://doi.org/10.1038/nmeth.4380; '''; logn1 = np.log(df + 1); T_clr = logn1.sub(logn1.mean(axis=1), axis=0); return T_clr. def asinh_transform(df, cofactor=5):; '''; implements the hyperbolic arcsin transform used in CyTOF/mass cytometry; https://doi.org/10.1038/nmeth.4380; '''; T_cytof = np.arcsinh(df / cofactor); return T_cytof. def geometric_transform(df):; '''; implements the scanpy transform originating from ivirshup:multimodal; '''; from scipy.stats.mstats import gmean; T_geometric = np.divide(df, gmean(df + 1, axis=0)); return T_geometric. #optionally, for each of these, similar to some cytof workflows, ; #anchor 1-99% quantiles to 0-1, to rescale distribution within a standardized range; #use quantiles as a simple heuristic, due to extreme signal outliers that throw off the sca",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-635963691:1533,test,tested,1533,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117#issuecomment-635963691,1,['test'],['tested']
Testability," to codeload.github.com (codeload.github.com)|140.82.114.9|:443... connected.; HTTP request sent, awaiting response... 200 OK; Length: unspecified [application/x-gzip]; Saving to: ‘v0.3.5.tar.gz’. v0.3.5.tar.gz [ <=> ] 434.98K 1.03MB/s in 0.4s . 2022-03-24 02:54:22 (1.03 MB/s) - ‘v0.3.5.tar.gz’ saved [445420]. test@mac ~/PythonPackages$ tar xvf v0.3.5.tar.gz ; x forceatlas2-0.3.5/; x forceatlas2-0.3.5/.gitignore; x forceatlas2-0.3.5/LICENSE; x forceatlas2-0.3.5/MANIFEST.in; x forceatlas2-0.3.5/README.md; x forceatlas2-0.3.5/examples/; x forceatlas2-0.3.5/examples/forceatlas2-layout.ipynb; x forceatlas2-0.3.5/examples/geometric_graph.png; x forceatlas2-0.3.5/examples/grid_graph.png; x forceatlas2-0.3.5/fa2/; x forceatlas2-0.3.5/fa2/__init__.py; x forceatlas2-0.3.5/fa2/fa2util.c; x forceatlas2-0.3.5/fa2/fa2util.pxd; x forceatlas2-0.3.5/fa2/fa2util.py; x forceatlas2-0.3.5/fa2/forceatlas2.py; x forceatlas2-0.3.5/setup.py; test@mac ~/PythonPackages$ cd forceatlas2-0.3.5/; test@mac ~/PythonPackages/forceatlas2-0.3.5$ pip3 install . --user; Processing /Users/test/PythonPackages/forceatlas2-0.3.5; Preparing metadata (setup.py) ... done; Requirement already satisfied: numpy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.21.5); Requirement already satisfied: scipy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.8.0); Requirement already satisfied: tqdm in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (4.63.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; error: subprocess-exited-with-error; ; × python setup.py bdist_wheel did not run successfully.; │ exit code: 1; ╰─> [214 lines of output]; Installing fa2 package (fastest forceatlas2 python implementation); ; >>>> Cython is installed?; Yes; ; >>>> Starting to install!; ; running bdist_wheel; running build; running build_py; creating build; creating build/lib.macosx-12.3-x86_64-3.10; creating build/lib.macosx-12.3-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:3340,test,test,3340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['test'],['test']
Testability," to start a flame war. Scanpy is an excellent piece of software, and I greatly appreciate at the work that goes into it. Responding to @LuckyMD, I again would just point out that returning cluster labels as ints is the standard for sklearn, and I would urge that scanpy serve as an access point to single cell analysis both for biologists and also for data science / machine learning researchers. Biologists will likely stick to using scanpy's plotting functions where you can handle default color maps for things that appear to be labels. We do this kind of checking in scprep: https://github.com/KrishnaswamyLab/scprep/blob/09de1bf41c4b42d331b29a4493c436110b641e07/scprep/plot/scatter.py#L206-L253. However, for machine learning researchers who likely have their own preferred plotting tools in matplotib or seaborn, might be trying to use the results from clustering in scanpy to compare to results from `sklearn.cluster`, or otherwise want to fit scanpy into their analysis pipelines, turning arrays of numerics into arrays of strings causes headaches that make the tools less accessible. The argument about the default colormap in matplotlib is continuous seems less important than making scanpy compatible with the larger ecosystem of data science tools in Python. Finally, I will note that in Python, strings are also defined ordinally, even if you might not think of them that way. Although in some respects the question, ""Is `'1'` less than `'a'`?"" is nonsensical, this is a well defined test in Python. ```python; In [1]: '1' < 'a'; Out[1]: True; ```. Again, I want to emphasize that I really love what has been done with scanpy / anndata so far. We use it in various places in our single cell workshop (https://krishnaswamylab.org/workshop), and I rely on the implementations of louvain / paga / dpt for my research. I bring up these issues here because I think changing some of these conventions could result in greater widespread adoption that I would love to see for scanpy and anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-582988545:2627,test,test,2627,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-582988545,1,['test'],['test']
Testability," tried with a minimum reproducible example and it seemed to work:; ```python; sc.__version__; >>> '1.4.5.1'; ```; ```python; adata = sc.datasets.pbmc68k_reduced(); sc.pp.neighbors(adata); sc.tl.louvain(adata); sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'); sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8); ```; ![image](https://user-images.githubusercontent.com/25887487/76887535-b7635900-6882-11ea-9a1c-65bd7d2e6721.png). Could you provide more inputs on the anndata object?. Also, does upgrading pandas help?. <details>; <summary> Versions</summary>. ```python; anndata==0.7.1; appnope==0.1.0; attrs==19.3.0; backcall==0.1.0; bleach==3.1.0; certifi==2019.11.28; cycler==0.10.0; decorator==4.4.2; defusedxml==0.6.0; entrypoints==0.3; get-version==2.1; h5py==2.10.0; importlib-metadata==1.5.0; ipykernel==5.1.4; ipython==7.13.0; ipython-genutils==0.2.0; jedi==0.16.0; Jinja2==2.11.1; joblib==0.14.1; json5==0.9.1; jsonschema==3.2.0; jupyter-client==5.3.4; jupyter-core==4.6.1; jupyterlab==1.2.6; jupyterlab-server==1.0.6; kiwisolver==1.1.0; legacy-api-wrap==1.2; leidenalg==0.7.0; llvmlite==0.31.0; louvain==0.6.1; MarkupSafe==1.1.1; matplotlib==3.2.0; mistune==0.8.4; natsort==7.0.1; nbconvert==5.6.1; nbformat==5.0.4; networkx==2.4; notebook==6.0.3; numba==0.48.0; numexpr==2.7.1; numpy==1.18.2; packaging==20.3; pandas==1.0.2; pandocfilters==1.4.2; parso==0.6.1; patsy==0.5.1; pexpect==4.8.0; pickleshare==0.7.5; prometheus-client==0.7.1; prompt-toolkit==3.0.3; ptyprocess==0.6.0; pycairo==1.19.0; Pygments==2.5.2; pyparsing==2.4.6; pyrsistent==0.15.7; python-dateutil==2.8.1; python-igraph==0.7.1.post7; pytz==2019.3; pyzmq==18.1.1; scanpy==1.4.5.1; scikit-learn==0.22.2.post1; scipy==1.4.1; seaborn==0.10.0; Send2Trash==1.5.0; setuptools-scm==3.5.0; six==1.14.0; statsmodels==0.11.1; tables==3.6.1; terminado==0.8.3; testpath==0.4.4; tornado==6.0.4; tqdm==4.43.0; traitlets==4.3.3; umap-learn==0.3.10; wcwidth==0.1.8; webencodings==0.5.1; zipp==2.2.0; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1114#issuecomment-600224021:1861,test,testpath,1861,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114#issuecomment-600224021,1,['test'],['testpath']
Testability," types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.off-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_combat.py::test_combat_obs_names - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/test_get.py::test_obs_df - AssertionError: Attributes of DataFrame.iloc[:, 0] (column name=""gene2"") are different; FAILED scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.on_right-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.on_data-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.on_data-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.off-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:5123,test,tests,5123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability," value.items():; --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs); 206 ; 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs); 103 if key in f:; 104 del f[key]; --> 105 _write_method(type(value))(f, key, value, dataset_kwargs); 106 ; 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_array(f, key, value, dataset_kwargs); 152 elif value.dtype.names is not None:; 153 value = _to_hdf5_vlen_strings(value); --> 154 f.create_dataset(key, data=value, **dataset_kwargs); 155 ; 156 . ~/new_anndata/anndata/anndata/h5py/h5sparse.py in create_dataset(self, name, data, chunk_size, **kwargs); 151 if not isinstance(data, SparseDataset) and not ss.issparse(data):; 152 return self.h5py_group.create_dataset(; --> 153 name=name, data=data, **kwargs; 154 ); 155 if self.force_dense:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 134 ; 135 with phil:; --> 136 dsid = dataset.make_new_dset(self, shape, dtype, data, **kwds); 137 dset = dataset.Dataset(dsid); 138 if name is not None:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl); 116 else:; 117 dtype = numpy.dtype(dtype); --> 118 tid = h5t.py_create(dtype, logical=1); 119 ; 120 # Legacy. h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t._c_compound(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). TypeError: Object dtype dtype('O') has no native HDF5 equivalent; ```. Everything however seems to work fine when I throw out the rank_genes_groups results from `adata.uns`. Edit: actually cellxgene still isn't working, but I could at least save again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/832#issuecomment-544968526:3771,log,logical,3771,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832#issuecomment-544968526,1,['log'],['logical']
Testability," we even want relative expression counts?; 2. What assumptions do downstream methods have on the distribution of expression values. For the first question: relative gene expression values ignore differences in cell sizes/number of molecules in the cell. There are some molecules whose numbers scale with the size of the cell, and others that don't (e.g., many housekeeping genes). Choosing relative over absolute expression values to compare gene expression across cells would be helpful to compare expression of those genes that scale with size, but not the others.... so there's not really a perfect answer here. Thus, removing all effects of total counts may not be the desirable outcome. Secondly, many downstream methods assume normally distributed expression data (e.g., DE methods like: t-tests, limma, MAST, or several batch correction/data integration methods). Log transformation is used as a variance stabilization to approximate a normal distribution (quite often poorly, but better than without). This leads to many methods performing better with log transformation. IMO, the ideal approach is probably something like scVI, GLMPCA, or scTransform, where you fit a model directly to the count data and use the residuals to describe the data. This would address both steps of normalization and variance stabilization at the same time. If we have a good model to describe the data, the residuals should quantify the biological variance + normally distributed noise. Overall, I would use other normalization approaches than CPM, and use log-transformation with anything that uses size factors that scale per-cell expression values. . Note also that the effect described in the second paper you mention (from Aaron Lun) will mainly be relevant when you have biased distributions of sequencing depth between two samples that you are comparing. If the size factors are similarly distributed between both conditions, then the DE effect will not be so dramatic (as far as I understood it anyway).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643:1649,log,log,1649,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643,2,['log'],"['log', 'log-transformation']"
Testability," what I mean:. <details>. <summary>Simple example. Logs `anndata` used, function called, time elapsed </summary>. ```python; from anndata import AnnData; from datetime import datetime; from functools import wraps; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(func):; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; call_start_record = dict(call_id=call_id, called_func=func.__name__); if type(args[0]) is AnnData:; call_start_record[""adata_id""] = id(args[0]); logger.msg(""call"", **call_start_record). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(called_func=func.__name__, elapsed=dt); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo; # 2019-02-13 19:28.03 call_finish call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo elapsed=datetime.timedelta(microseconds=505970) returned_adata_id=4940502352; ```. </details>. <details>; <summary>More complicated example with argument value logging</summary>. ```python; from anndata import AnnData; from copy import copy; from datetime import datetime; from functools import wraps; import inspect; from itertools import chain; fro",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:1498,log,logged,1498,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273,1,['log'],['logged']
Testability, with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files di,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48068,Assert,AssertionError,48068,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Assert'],['AssertionError']
Testability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1669?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > Merging [#1669](https://codecov.io/gh/theislab/scanpy/pull/1669?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (62eef47) into [master](https://codecov.io/gh/theislab/scanpy/commit/c488909a54e9ab1462186cca35b537426e4630db?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (c488909) will **increase** coverage by `0.02%`.; > The diff coverage is `100.00%`. ```diff; @@ Coverage Diff @@; ## master #1669 +/- ##; ==========================================; + Coverage 71.18% 71.21% +0.02% ; ==========================================; Files 92 92 ; Lines 11190 11180 -10 ; ==========================================; - Hits 7966 7962 -4 ; + Misses 3224 3218 -6 ; ```. | [Impacted Files](https://codecov.io/gh/theislab/scanpy/pull/1669?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://codecov.io/gh/theislab/scanpy/pull/1669/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `76.74% <100.00%> (+0.47%)` | :arrow_up: |; | [scanpy/logging.py](https://codecov.io/gh/theislab/scanpy/pull/1669/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `98.38% <0.00%> (+1.61%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1669#issuecomment-826382269:1520,log,logging,1520,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669#issuecomment-826382269,1,['log'],['logging']
Testability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1805?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > Merging [#1805](https://codecov.io/gh/theislab/scanpy/pull/1805?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (c6dc5f2) into [master](https://codecov.io/gh/theislab/scanpy/commit/7abd0724fc1684c018f55951108a07fa9eaf9911?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (7abd072) will **increase** coverage by `0.00%`.; > The diff coverage is `0.00%`. ```diff; @@ Coverage Diff @@; ## master #1805 +/- ##; =======================================; Coverage 71.18% 71.19% ; =======================================; Files 92 92 ; Lines 11190 11192 +2 ; =======================================; + Hits 7966 7968 +2 ; Misses 3224 3224 ; ```. | [Impacted Files](https://codecov.io/gh/theislab/scanpy/pull/1805?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_louvain.py](https://codecov.io/gh/theislab/scanpy/pull/1805/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L3Rvb2xzL19sb3V2YWluLnB5) | `59.57% <0.00%> (-1.30%)` | :arrow_down: |; | [scanpy/logging.py](https://codecov.io/gh/theislab/scanpy/pull/1805/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `98.38% <0.00%> (+1.61%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1805#issuecomment-827226658:1464,log,logging,1464,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805#issuecomment-827226658,1,['log'],['logging']
Testability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1807?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > Merging [#1807](https://codecov.io/gh/theislab/scanpy/pull/1807?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (b12b4ea) into [master](https://codecov.io/gh/theislab/scanpy/commit/c488909a54e9ab1462186cca35b537426e4630db?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (c488909) will **increase** coverage by `0.01%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #1807 +/- ##; ==========================================; + Coverage 71.18% 71.20% +0.01% ; ==========================================; Files 92 92 ; Lines 11190 11190 ; ==========================================; + Hits 7966 7968 +2 ; + Misses 3224 3222 -2 ; ```. | [Impacted Files](https://codecov.io/gh/theislab/scanpy/pull/1807?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) | Coverage Δ | |; |---|---|---|; | [scanpy/logging.py](https://codecov.io/gh/theislab/scanpy/pull/1807/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `98.38% <ø> (+1.61%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1807#issuecomment-827457169:1198,log,logging,1198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1807#issuecomment-827457169,1,['log'],['logging']
Testability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1810?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > Merging [#1810](https://codecov.io/gh/theislab/scanpy/pull/1810?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (2a449c7) into [master](https://codecov.io/gh/theislab/scanpy/commit/c488909a54e9ab1462186cca35b537426e4630db?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (c488909) will **increase** coverage by `0.02%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #1810 +/- ##; ==========================================; + Coverage 71.18% 71.21% +0.02% ; ==========================================; Files 92 92 ; Lines 11190 11180 -10 ; ==========================================; - Hits 7966 7962 -4 ; + Misses 3224 3218 -6 ; ```. | [Impacted Files](https://codecov.io/gh/theislab/scanpy/pull/1810?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://codecov.io/gh/theislab/scanpy/pull/1810/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `76.74% <ø> (+0.47%)` | :arrow_up: |; | [scanpy/logging.py](https://codecov.io/gh/theislab/scanpy/pull/1810/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `98.38% <0.00%> (+1.61%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1810#issuecomment-827491040:1510,log,logging,1510,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1810#issuecomment-827491040,1,['log'],['logging']
Testability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1812?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > Merging [#1812](https://codecov.io/gh/theislab/scanpy/pull/1812?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (d655718) into [master](https://codecov.io/gh/theislab/scanpy/commit/c488909a54e9ab1462186cca35b537426e4630db?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (c488909) will **increase** coverage by `0.02%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #1812 +/- ##; ==========================================; + Coverage 71.18% 71.21% +0.02% ; ==========================================; Files 92 92 ; Lines 11190 11180 -10 ; ==========================================; - Hits 7966 7962 -4 ; + Misses 3224 3218 -6 ; ```. | [Impacted Files](https://codecov.io/gh/theislab/scanpy/pull/1812?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://codecov.io/gh/theislab/scanpy/pull/1812/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `76.74% <ø> (+0.47%)` | :arrow_up: |; | [scanpy/logging.py](https://codecov.io/gh/theislab/scanpy/pull/1812/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `98.38% <0.00%> (+1.61%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1812#issuecomment-827502118:1510,log,logging,1510,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1812#issuecomment-827502118,1,['log'],['logging']
Testability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1814?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > Merging [#1814](https://codecov.io/gh/theislab/scanpy/pull/1814?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (2c1d01a) into [master](https://codecov.io/gh/theislab/scanpy/commit/c488909a54e9ab1462186cca35b537426e4630db?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (c488909) will **increase** coverage by `0.01%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #1814 +/- ##; ==========================================; + Coverage 71.18% 71.20% +0.01% ; ==========================================; Files 92 92 ; Lines 11190 11190 ; ==========================================; + Hits 7966 7968 +2 ; + Misses 3224 3222 -2 ; ```. | [Impacted Files](https://codecov.io/gh/theislab/scanpy/pull/1814?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_anndata.py](https://codecov.io/gh/theislab/scanpy/pull/1814/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L3Bsb3R0aW5nL19hbm5kYXRhLnB5) | `84.47% <ø> (ø)` | |; | [scanpy/logging.py](https://codecov.io/gh/theislab/scanpy/pull/1814/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `98.38% <0.00%> (+1.61%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1814#issuecomment-827514615:1467,log,logging,1467,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1814#issuecomment-827514615,1,['log'],['logging']
Testability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1815?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > Merging [#1815](https://codecov.io/gh/theislab/scanpy/pull/1815?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (aefcf1d) into [master](https://codecov.io/gh/theislab/scanpy/commit/c488909a54e9ab1462186cca35b537426e4630db?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (c488909) will **increase** coverage by `0.01%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #1815 +/- ##; ==========================================; + Coverage 71.18% 71.20% +0.01% ; ==========================================; Files 92 92 ; Lines 11190 11190 ; ==========================================; + Hits 7966 7968 +2 ; + Misses 3224 3222 -2 ; ```. | [Impacted Files](https://codecov.io/gh/theislab/scanpy/pull/1815?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://codecov.io/gh/theislab/scanpy/pull/1815/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `76.27% <ø> (ø)` | |; | [scanpy/logging.py](https://codecov.io/gh/theislab/scanpy/pull/1815/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `98.38% <0.00%> (+1.61%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1815#issuecomment-827526265:1490,log,logging,1490,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1815#issuecomment-827526265,1,['log'],['logging']
Testability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1819?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > Merging [#1819](https://codecov.io/gh/theislab/scanpy/pull/1819?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (9b117ae) into [master](https://codecov.io/gh/theislab/scanpy/commit/c488909a54e9ab1462186cca35b537426e4630db?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (c488909) will **increase** coverage by `0.01%`.; > The diff coverage is `0.00%`. ```diff; @@ Coverage Diff @@; ## master #1819 +/- ##; ==========================================; + Coverage 71.18% 71.20% +0.01% ; ==========================================; Files 92 92 ; Lines 11190 11190 ; ==========================================; + Hits 7966 7968 +2 ; + Misses 3224 3222 -2 ; ```. | [Impacted Files](https://codecov.io/gh/theislab/scanpy/pull/1819?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_louvain.py](https://codecov.io/gh/theislab/scanpy/pull/1819/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L3Rvb2xzL19sb3V2YWluLnB5) | `60.86% <0.00%> (ø)` | |; | [scanpy/logging.py](https://codecov.io/gh/theislab/scanpy/pull/1819/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `98.38% <0.00%> (+1.61%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1819#issuecomment-828341861:1466,log,logging,1466,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1819#issuecomment-828341861,1,['log'],['logging']
Testability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1820?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > Merging [#1820](https://codecov.io/gh/theislab/scanpy/pull/1820?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (0949bcb) into [master](https://codecov.io/gh/theislab/scanpy/commit/c488909a54e9ab1462186cca35b537426e4630db?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (c488909) will **increase** coverage by `0.01%`.; > The diff coverage is `0.00%`. ```diff; @@ Coverage Diff @@; ## master #1820 +/- ##; ==========================================; + Coverage 71.18% 71.20% +0.01% ; ==========================================; Files 92 92 ; Lines 11190 11190 ; ==========================================; + Hits 7966 7968 +2 ; + Misses 3224 3222 -2 ; ```. | [Impacted Files](https://codecov.io/gh/theislab/scanpy/pull/1820?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_louvain.py](https://codecov.io/gh/theislab/scanpy/pull/1820/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L3Rvb2xzL19sb3V2YWluLnB5) | `60.86% <0.00%> (ø)` | |; | [scanpy/logging.py](https://codecov.io/gh/theislab/scanpy/pull/1820/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `98.38% <0.00%> (+1.61%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1820#issuecomment-828458610:1466,log,logging,1466,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1820#issuecomment-828458610,1,['log'],['logging']
Testability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1822?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > Merging [#1822](https://codecov.io/gh/theislab/scanpy/pull/1822?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (62e48bc) into [master](https://codecov.io/gh/theislab/scanpy/commit/c488909a54e9ab1462186cca35b537426e4630db?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (c488909) will **increase** coverage by `0.01%`.; > The diff coverage is `50.00%`. ```diff; @@ Coverage Diff @@; ## master #1822 +/- ##; ==========================================; + Coverage 71.18% 71.20% +0.01% ; ==========================================; Files 92 92 ; Lines 11190 11192 +2 ; ==========================================; + Hits 7966 7969 +3 ; + Misses 3224 3223 -1 ; ```. | [Impacted Files](https://codecov.io/gh/theislab/scanpy/pull/1822?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_anndata.py](https://codecov.io/gh/theislab/scanpy/pull/1822/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L3Bsb3R0aW5nL19hbm5kYXRhLnB5) | `84.39% <50.00%> (-0.08%)` | :arrow_down: |; | [scanpy/logging.py](https://codecov.io/gh/theislab/scanpy/pull/1822/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `98.38% <0.00%> (+1.61%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1822#issuecomment-829484368:1496,log,logging,1496,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1822#issuecomment-829484368,1,['log'],['logging']
Testability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/2089?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > Merging [#2089](https://codecov.io/gh/theislab/scanpy/pull/2089?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (34640c0) into [master](https://codecov.io/gh/theislab/scanpy/commit/d805b415b732f69c639a3fec620b2bfee4ab934c?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (d805b41) will **decrease** coverage by `0.04%`.; > The diff coverage is `63.63%`. ```diff; @@ Coverage Diff @@; ## master #2089 +/- ##; ==========================================; - Coverage 71.42% 71.38% -0.05% ; ==========================================; Files 92 92 ; Lines 11286 11283 -3 ; ==========================================; - Hits 8061 8054 -7 ; - Misses 3225 3229 +4 ; ```. | [Impacted Files](https://codecov.io/gh/theislab/scanpy/pull/2089?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) | Coverage Δ | |; |---|---|---|; | [scanpy/logging.py](https://codecov.io/gh/theislab/scanpy/pull/2089/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `95.04% <63.63%> (-3.35%)` | :arrow_down: |,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2089#issuecomment-997386991:1204,log,logging,1204,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2089#issuecomment-997386991,1,['log'],['logging']
Testability,"# simple log(n+1) (as used in RNAseq); ![image](https://user-images.githubusercontent.com/20694664/83345487-a05cd080-a2e1-11ea-858e-4d98621d12e6.png). can suffer from discretization at low values... note: even though Seurat/Scanpy/Loupe all use different bases, the log base doesn't really matter; it just changes the scale, not the shape/distinguishing power. ### hyperbolic arcsin (as used in CyTOF); ![image](https://user-images.githubusercontent.com/20694664/83345476-81f6d500-a2e1-11ea-8f68-ddff22ffe853.png). not as noisy as log at low values, and doesn't assert that zeros have to be Laplace smoothed with a pseudocount of +1. ### biexponential family (as used in flow cytometry); ![image](https://user-images.githubusercontent.com/20694664/83345554-6fc96680-a2e2-11ea-8112-3bdc09260e63.png). best smoothing so far in the low counts, because that's what it was designed to do. in this case, it is the newest of this family: `vlog(alpha=0, beta=12, xmax=70000, zmax=1)`; - https://doi.org/10.1002/cyto.a.23017; - https://doi.org/10.1002/cyto.a.22030; - https://doi.org/10.1002/cyto.a.20258. ### centered log ratio (as used in CITEseq paper); ![image](https://user-images.githubusercontent.com/20694664/83345643-a9e73800-a2e3-11ea-8303-365fccca16cc.png). not only does this have good smoothing, but it differs in that it is injecting an additional aspect beyond just bringing high values into a linear range; specifically, the centering feature seems to impart an assumption about compositional data, giving higher preference to relative ratios, even if the absolute magnitude might be different -- this has the effect of counteracting cell size, but I've observed that it may introduce unexpected changes (not shown here) in the shape of the distribution that is different from all of the other transforms mentioned, so these need to be validated biologically against some ""ground truth"". for the time being though, the last few mentioned are all good candidates to include as transform options",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-636429530:1959,log,log,1959,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117#issuecomment-636429530,1,['log'],['log']
Testability,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up.; So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1528#issuecomment-738776290:25,test,tests,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528#issuecomment-738776290,5,['test'],"['test', 'testing', 'tests']"
Testability,"## Test failures on 141eb6a315542317ddab2f7a413a24559c84492f. 252 failed, 650 passed, 59 skipped, 5 xfailed, 1038 warnings, 128 errors in 451.20s (0:07:31). Noting some of the big causes:. ### Expected warnings not thrown. A few times. ### Older versions of pandas do not support `na_action`. Likely caused during [Fix more pandas warnings by flying-sheep · Pull Request #2789 · scverse/scanpy](https://github.com/scverse/scanpy/pull/2789). Which did also bump up the required pandas version to 2.1.3. However, I think we'll want to revert that bump because:. * According to the scientific python versioning specification we're still meant to be on 1.4 ; * More than half of pandas users are still on 1.*; * Bumping pandas up to 2.1.3 actually requires bumping the versions on a number of other dependencies whose current minimums do not work with pandas 2.1.3. ### ufunc equal. Something is happening in a lot of plotting functions with the `equal` ufunc. ### Numba NotImplementedError. During `test_highly_variable_genes_pearson_residuals_general`. ### AnnData private methods used in tests. A lot of private anndata methods are used at test time. But these didn't exist at the time. Not totally sure what the best solution here is. * Vendoring anndata test helpers over here.; * Literally pulling in the file is probably not so bad; * I will investigate to see how many functions are really needed, possible it's just a few one liners (`as_dense_dask_array` is getting hit often); * Make a new package with just the test helpers? Probably too much of a pain. ### ImportError: cannot import name 'check_is_fitted' from 'sklearn.base'. <details>; <summary> Raw test output </summary>. ```python; FAILED scanpy/tests/test_datasets.py::test_krumsiek11 - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/test_datasets.py::test_toggleswitch - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/get/get.py::",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:3,Test,Test,3,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Test'],['Test']
Testability,"## Tests. Fair enough. ## More graph/ neighbor representations. For sure, I'm thinking of just. I've taken another look at some of the Neighbors code, and am realizing the amount of code this touches. I still think this is important, but might be out of scope for this pull request. I'm probably going to hack together something for personal use first, and see where I go from there. Just to make sure anything I play around with isn't breaking other parts of `scanpy`, would you mind sharing how you run those notebook tests?. ## Partition. Would you mind if I change the requirement in `setup.py` from `louvain` to `louvain>=0.6`? It'd make adding this a bit cleaner. ## Doc changes. Sure! All that needs to change is specifying the default, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248#issuecomment-419007563:3,Test,Tests,3,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248#issuecomment-419007563,2,"['Test', 'test']","['Tests', 'tests']"
Testability,## [CodSpeed](https://codspeed.io/). Seems very promising:. - [Unlimited use from open source repos](https://codspeed.io/pricing); - Switch from asv to [`pytest-benchmark` / `pytest-codspeed`](https://docs.codspeed.io/benchmarks/python); - We can use our benchmark machine together with [codspeed-runner](https://github.com/CodSpeedHQ/runner) instead of a GitHub runner. Runner seems to not be supported on Rocky though: https://github.com/CodSpeedHQ/runner/issues/21,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3052#issuecomment-2107968319:161,benchmark,benchmark,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3052#issuecomment-2107968319,3,['benchmark'],"['benchmark', 'benchmarks']"
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2482?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`48b495d`)](https://app.codecov.io/gh/scverse/scanpy/commit/48b495d983a2873083b823e9be5e98f6082ac88c?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.81% compared to head [(`f8368c6`)](https://app.codecov.io/gh/scverse/scanpy/pull/2482?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.81%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2482 +/- ##; =======================================; Coverage 74.81% 74.81% ; =======================================; Files 116 116 ; Lines 12822 12822 ; =======================================; Hits 9593 9593 ; Misses 3229 3229 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2482#issuecomment-1535967746:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2482#issuecomment-1535967746,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2522?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > Merging [#2522](https://app.codecov.io/gh/scverse/scanpy/pull/2522?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (2753e48) into [test-utils](https://app.codecov.io/gh/scverse/scanpy/commit/9e21b23737eec3584f7ccfd1a73a36929064765e?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (9e21b23) will **decrease** coverage by `0.48%`.; > The diff coverage is `100.00%`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## test-utils #2522 +/- ##; ==============================================; - Coverage 72.20% 71.73% -0.48% ; ==============================================; Files 103 103 ; Lines 11687 11688 +1 ; ==============================================; - Hits 8439 8384 -55 ; - Misses 3248 3304 +56 ; ```. | [Impacted Files](https://app.codecov.io/gh/scverse/scanpy/pull/2522?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/fixtures/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2522?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9kYXRhLnB5) | `100.00% <100.00%> (ø)` | |. ... and [11 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2522/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2522#issuecomment-1598935568:387,test,test-utils,387,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2522#issuecomment-1598935568,3,['test'],"['test-utils', 'testing']"
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2566?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > Merging [#2566](https://app.codecov.io/gh/scverse/scanpy/pull/2566?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (485dfda) into [master](https://app.codecov.io/gh/scverse/scanpy/commit/0594b7f03917f8c5166d5bb2752031e1665065de?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (0594b7f) will **not change** coverage.; > The diff coverage is `n/a`. > :exclamation: Current head 485dfda differs from pull request most recent head f4ab24c. Consider uploading reports for the commit f4ab24c to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2566 +/- ##; =======================================; Coverage 72.12% 72.12% ; =======================================; Files 104 104 ; Lines 11688 11688 ; =======================================; Hits 8430 8430 ; Misses 3258 3258 ; ```. | [Impacted Files](https://app.codecov.io/gh/scverse/scanpy/pull/2566?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/logging.py](https://app.codecov.io/gh/scverse/scanpy/pull/2566?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `95.04% <ø> (ø)` | |; | [scanpy/testing/\_pytest/marks.py](https://app.codecov.io/gh/scverse/scanpy/pull/2566?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `84.61% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2566#issuecomment-1645346362:1408,log,logging,1408,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2566#issuecomment-1645346362,2,"['log', 'test']","['logging', 'testing']"
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2575?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > Merging [#2575](https://app.codecov.io/gh/scverse/scanpy/pull/2575?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (e178114) into [master](https://app.codecov.io/gh/scverse/scanpy/commit/d843918e82a1e01a64237f7a03ccfcb4c3ad8cc5?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (d843918) will **increase** coverage by `0.04%`.; > The diff coverage is `100.00%`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2575 +/- ##; ==========================================; + Coverage 72.17% 72.22% +0.04% ; ==========================================; Files 104 104 ; Lines 11718 11705 -13 ; ==========================================; - Hits 8458 8454 -4 ; + Misses 3260 3251 -9 ; ```. | [Files Changed](https://app.codecov.io/gh/scverse/scanpy/pull/2575?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2575?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `100.00% <100.00%> (+39.13%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2575#issuecomment-1650045709:1283,test,testing,1283,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2575#issuecomment-1650045709,1,['test'],['testing']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2585?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`8986921`)](https://app.codecov.io/gh/scverse/scanpy/commit/8986921216553cf08db98b37082fffc5714c970c?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.85% compared to head [(`8316a69`)](https://app.codecov.io/gh/scverse/scanpy/pull/2585?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.85%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2585 +/- ##; =======================================; Coverage 72.85% 72.85% ; =======================================; Files 111 111 ; Lines 12383 12383 ; =======================================; Hits 9022 9022 ; Misses 3361 3361 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2585?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/2585?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19hbm5kYXRhLnB5) | `84.97% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2585#issuecomment-1662126000:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2585#issuecomment-1662126000,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2658?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > Merging [#2658](https://app.codecov.io/gh/scverse/scanpy/pull/2658?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (32c1ab6) into [master](https://app.codecov.io/gh/scverse/scanpy/commit/3a50e60a77ced96d877448c6d9f8c27705ae949e?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (3a50e60) will **not change** coverage.; > The diff coverage is `100.00%`. > :exclamation: Current head 32c1ab6 differs from pull request most recent head 8e75cef. Consider uploading reports for the commit 8e75cef to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2658 +/- ##; =======================================; Coverage 72.16% 72.16% ; =======================================; Files 108 108 ; Lines 11906 11906 ; =======================================; Hits 8592 8592 ; Misses 3314 3314 ; ```. | [Files Changed](https://app.codecov.io/gh/scverse/scanpy/pull/2658?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/datasets/\_datasets.py](https://app.codecov.io/gh/scverse/scanpy/pull/2658?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2RhdGFzZXRzL19kYXRhc2V0cy5weQ==) | `69.29% <100.00%> (ø)` | |; | [scanpy/testing/\_helpers/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2658?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2658#issuecomment-1712098187:1688,test,testing,1688,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2658#issuecomment-1712098187,1,['test'],['testing']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2671?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 72.16%. Comparing base [(`0d4c6d2`)](https://app.codecov.io/gh/scverse/scanpy/commit/0d4c6d2b90c7c01a50ebffd33e6c79d2916b3f09?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3abf5c2`)](https://app.codecov.io/gh/scverse/scanpy/commit/3abf5c2b2893848fa5ded71f2b656e7d8833e53e?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 228 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2671 +/- ##; =======================================; Coverage 72.16% 72.16% ; =======================================; Files 108 108 ; Lines 11908 11908 ; =======================================; + Hits 8593 8594 +1 ; + Misses 3315 3314 -1 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/2671?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_tsne.py](https://app.codecov.io/gh/scverse/scanpy/pull/2671?src=pr&el=tree&filepath=scanpy%2Ftools%2F_tsne.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL190c25lLnB5) | `90.00% <ø> (ø)` | |. ... and [1 file with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2671/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2671#issuecomment-1733834995:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2671#issuecomment-1733834995,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2705?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`bf5f27a`)](https://app.codecov.io/gh/scverse/scanpy/commit/bf5f27aa9e968de6e73fc7abb46a89084ddf6880?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72% compared to head [(`28c2def`)](https://app.codecov.io/gh/scverse/scanpy/pull/2705?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72%.; > Report is 1 commits behind head on master. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2705 +/- ##; =======================================; Coverage 72.72% 72.72% ; =======================================; Files 111 111 ; Lines 12383 12383 ; =======================================; Hits 9005 9005 ; Misses 3378 3378 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2705?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/2705?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL191dGlscy5weQ==) | `56.33% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2705#issuecomment-1777219410:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2705#issuecomment-1777219410,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2723?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`42143d8`)](https://app.codecov.io/gh/scverse/scanpy/commit/42143d88a0d499130fac8e5ca60eef0c19163734?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 73.19% compared to head [(`bd47788`)](https://app.codecov.io/gh/scverse/scanpy/pull/2723?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.07%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## add-scrublet #2723 +/- ##; ================================================; + Coverage 73.19% 74.07% +0.88% ; ================================================; Files 116 115 -1 ; Lines 12634 12613 -21 ; ================================================; + Hits 9247 9343 +96 ; + Misses 3387 3270 -117 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2723?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/neighbors/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2723?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L25laWdoYm9ycy9fX2luaXRfXy5weQ==) | `80.75% <100.00%> (+3.28%)` | :arrow_up: |; | [scanpy/neighbors/\_common.py](https://app.codecov.io/gh/scverse/scanpy/pull/2723?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L25laWdoYm9ycy9fY29tbW9uLnB5) | `64.91% <100.00%> (ø)` | |; | [scanpy/neighbors/\_types.py](https://app.codecov.io/gh/scverse/scanpy/pull/2723?src=pr&el=tree&utm_medium=,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2723#issuecomment-1787464686:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2723#issuecomment-1787464686,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2793?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`d7e7132`)](https://app.codecov.io/gh/scverse/scanpy/commit/d7e713258ba130b5b96c5c785e259c8140d59f3a?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84% compared to head [(`d5f04fb`)](https://app.codecov.io/gh/scverse/scanpy/pull/2793?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2793 +/- ##; =======================================; Coverage 72.84% 72.84% ; =======================================; Files 111 111 ; Lines 12382 12382 ; =======================================; Hits 9020 9020 ; Misses 3362 3362 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2793?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_docs.py](https://app.codecov.io/gh/scverse/scanpy/pull/2793?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2RvY3MucHk=) | `100.00% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2793#issuecomment-1868667393:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2793#issuecomment-1868667393,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2794?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`d7e7132`)](https://app.codecov.io/gh/scverse/scanpy/commit/d7e713258ba130b5b96c5c785e259c8140d59f3a?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84% compared to head [(`d5144ce`)](https://app.codecov.io/gh/scverse/scanpy/pull/2794?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2794 +/- ##; =======================================; Coverage 72.84% 72.84% ; =======================================; Files 111 111 ; Lines 12382 12382 ; =======================================; Hits 9020 9020 ; Misses 3362 3362 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2794?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_baseplot\_class.py](https://app.codecov.io/gh/scverse/scanpy/pull/2794?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19iYXNlcGxvdF9jbGFzcy5weQ==) | `90.14% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2794#issuecomment-1869073837:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2794#issuecomment-1869073837,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2796?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > :exclamation: No coverage uploaded for pull request base (`1.9.x@1daae5b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2796 +/- ##; ========================================; Coverage ? 71.35% ; ========================================; Files ? 103 ; Lines ? 11645 ; Branches ? 0 ; ========================================; Hits ? 8309 ; Misses ? 3336 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2796#issuecomment-1870329572:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2796#issuecomment-1870329572,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2798?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`86b85ee`)](https://app.codecov.io/gh/scverse/scanpy/commit/86b85ee2f4e8acfc9db3ce4cfff6e905d96a59eb?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72% compared to head [(`7da3064`)](https://app.codecov.io/gh/scverse/scanpy/pull/2798?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.83%. > :exclamation: Current head 7da3064 differs from pull request most recent head 8a1e576. Consider uploading reports for the commit 8a1e576 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2798 +/- ##; ==========================================; + Coverage 72.72% 72.83% +0.11% ; ==========================================; Files 111 111 ; Lines 12384 12367 -17 ; ==========================================; + Hits 9006 9008 +2 ; + Misses 3378 3359 -19 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2798?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_rank\_genes\_groups.py](https://app.codecov.io/gh/scverse/scanpy/pull/2798?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19yYW5rX2dlbmVzX2dyb3Vwcy5weQ==) | `94.33% <ø> (-0.02%)` | :arrow_down: |. ... and [4 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2798/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scv,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2798#issuecomment-1879728557:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2798#issuecomment-1879728557,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2799?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`9b08d35`)](https://app.codecov.io/gh/scverse/scanpy/commit/9b08d35f00fc727d0b3c15f15bcb4059cd8055ac?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84% compared to head [(`554567f`)](https://app.codecov.io/gh/scverse/scanpy/pull/2799?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2799 +/- ##; =======================================; Coverage 72.84% 72.84% ; =======================================; Files 111 111 ; Lines 12367 12367 ; =======================================; Hits 9009 9009 ; Misses 3358 3358 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2799#issuecomment-1881589152:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2799#issuecomment-1881589152,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2801?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`61c6944`)](https://app.codecov.io/gh/scverse/scanpy/commit/61c6944f6d7014dc8ca9e886ce16ff79abedfc49?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84% compared to head [(`8c4ff13`)](https://app.codecov.io/gh/scverse/scanpy/pull/2801?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84%. > :exclamation: Current head 8c4ff13 differs from pull request most recent head ecc6337. Consider uploading reports for the commit ecc6337 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2801 +/- ##; =======================================; Coverage 72.84% 72.84% ; =======================================; Files 111 111 ; Lines 12382 12382 ; =======================================; Hits 9020 9020 ; Misses 3362 3362 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2801?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/readwrite.py](https://app.codecov.io/gh/scverse/scanpy/pull/2801?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3JlYWR3cml0ZS5weQ==) | `68.33% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2801#issuecomment-1882788091:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2801#issuecomment-1882788091,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2803?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 72.84%. Comparing base [(`c410cd1`)](https://app.codecov.io/gh/scverse/scanpy/commit/c410cd123f5487f25c08b421c8d06da50551ff73?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`88d721c`)](https://app.codecov.io/gh/scverse/scanpy/pull/2803?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 76 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2803 +/- ##; =======================================; Coverage 72.84% 72.84% ; =======================================; Files 111 111 ; Lines 12368 12368 ; =======================================; Hits 9009 9009 ; Misses 3359 3359 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2803?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_tsne.py](https://app.codecov.io/gh/scverse/scanpy/pull/2803?src=pr&el=tree&filepath=scanpy%2Ftools%2F_tsne.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL190c25lLnB5) | `90.69% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2803#issuecomment-1886074390:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2803#issuecomment-1886074390,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2805?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`c410cd1`)](https://app.codecov.io/gh/scverse/scanpy/commit/c410cd123f5487f25c08b421c8d06da50551ff73?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84% compared to head [(`db26f06`)](https://app.codecov.io/gh/scverse/scanpy/pull/2805?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.70%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2805 +/- ##; ==========================================; - Coverage 72.84% 72.70% -0.14% ; ==========================================; Files 111 111 ; Lines 12368 12368 ; ==========================================; - Hits 9009 8992 -17 ; - Misses 3359 3376 +17 ; ```. [see 1 file with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2805/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2805#issuecomment-1886674471:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2805#issuecomment-1886674471,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2812?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > :exclamation: No coverage uploaded for pull request base (`1.9.x@518e76a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2812 +/- ##; ========================================; Coverage ? 71.34% ; ========================================; Files ? 103 ; Lines ? 11632 ; Branches ? 0 ; ========================================; Hits ? 8299 ; Misses ? 3333 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2812#issuecomment-1893321168:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2812#issuecomment-1893321168,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2817?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`e00932b`)](https://app.codecov.io/gh/scverse/scanpy/commit/e00932b6d5b1694d7706b36a0dc604aa2c27d885?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72% compared to head [(`5bb6fad`)](https://app.codecov.io/gh/scverse/scanpy/pull/2817?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2817 +/- ##; =======================================; Coverage 72.72% 72.72% ; =======================================; Files 111 111 ; Lines 12384 12384 ; =======================================; Hits 9006 9006 ; Misses 3378 3378 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2817#issuecomment-1898650637:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2817#issuecomment-1898650637,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2818?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`f541346`)](https://app.codecov.io/gh/scverse/scanpy/commit/f541346b94bb67795c21bd2f58cb65d4ec65351a?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72% compared to head [(`6a1bb4c`)](https://app.codecov.io/gh/scverse/scanpy/pull/2818?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2818 +/- ##; =======================================; Coverage 72.72% 72.72% ; =======================================; Files 111 111 ; Lines 12384 12384 ; =======================================; Hits 9006 9006 ; Misses 3378 3378 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2818#issuecomment-1898766123:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2818#issuecomment-1898766123,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2820?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`f7f5d5c`)](https://app.codecov.io/gh/scverse/scanpy/commit/f7f5d5c6a51cc70599481da454f3c82c81b1e459?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72% compared to head [(`c5d8876`)](https://app.codecov.io/gh/scverse/scanpy/pull/2820?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2820 +/- ##; =======================================; Coverage 72.72% 72.72% ; =======================================; Files 111 111 ; Lines 12383 12383 ; =======================================; Hits 9005 9005 ; Misses 3378 3378 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2820#issuecomment-1904523323:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2820#issuecomment-1904523323,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2826?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`b6d0fc4`)](https://app.codecov.io/gh/scverse/scanpy/commit/b6d0fc4873b800a02209cc956891deeb6ba63b0d?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72% compared to head [(`0e22c55`)](https://app.codecov.io/gh/scverse/scanpy/pull/2826?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2826 +/- ##; =======================================; Coverage 72.72% 72.72% ; =======================================; Files 111 111 ; Lines 12383 12383 ; =======================================; Hits 9005 9005 ; Misses 3378 3378 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2826#issuecomment-1909955493:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2826#issuecomment-1909955493,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2831?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`6314190`)](https://app.codecov.io/gh/scverse/scanpy/commit/63141908601632638db8a79e8a1dfa8509cd27af?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72% compared to head [(`0d3f5e6`)](https://app.codecov.io/gh/scverse/scanpy/pull/2831?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2831 +/- ##; =======================================; Coverage 72.72% 72.72% ; =======================================; Files 111 111 ; Lines 12383 12383 ; =======================================; Hits 9005 9005 ; Misses 3378 3378 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2831#issuecomment-1911956969:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2831#issuecomment-1911956969,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2832?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`bf5f27a`)](https://app.codecov.io/gh/scverse/scanpy/commit/bf5f27aa9e968de6e73fc7abb46a89084ddf6880?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72% compared to head [(`11e93fe`)](https://app.codecov.io/gh/scverse/scanpy/pull/2832?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2832 +/- ##; =======================================; Coverage 72.72% 72.72% ; =======================================; Files 111 111 ; Lines 12383 12383 ; =======================================; Hits 9005 9005 ; Misses 3378 3378 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2832?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/2832?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL191dGlscy5weQ==) | `56.33% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2832#issuecomment-1911988897:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2832#issuecomment-1911988897,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2834?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`bf5f27a`)](https://app.codecov.io/gh/scverse/scanpy/commit/bf5f27aa9e968de6e73fc7abb46a89084ddf6880?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72% compared to head [(`cdd9177`)](https://app.codecov.io/gh/scverse/scanpy/pull/2834?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72%.; > Report is 1 commits behind head on master. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2834 +/- ##; =======================================; Coverage 72.72% 72.72% ; =======================================; Files 111 111 ; Lines 12383 12383 ; =======================================; Hits 9005 9005 ; Misses 3378 3378 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2834?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/2834?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL191dGlscy5weQ==) | `56.33% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2834#issuecomment-1912159219:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2834#issuecomment-1912159219,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2837?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`96e1954`)](https://app.codecov.io/gh/scverse/scanpy/commit/96e19540155c8aefcd8776e9348e432d52d3f090?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72% compared to head [(`a162042`)](https://app.codecov.io/gh/scverse/scanpy/pull/2837?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.85%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2837 +/- ##; ==========================================; + Coverage 72.72% 72.85% +0.13% ; ==========================================; Files 111 111 ; Lines 12383 12383 ; ==========================================; + Hits 9005 9022 +17 ; + Misses 3378 3361 -17 ; ```. [see 1 file with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2837/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2837#issuecomment-1914829755:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2837#issuecomment-1914829755,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2838?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`8986921`)](https://app.codecov.io/gh/scverse/scanpy/commit/8986921216553cf08db98b37082fffc5714c970c?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.85% compared to head [(`d184a9f`)](https://app.codecov.io/gh/scverse/scanpy/pull/2838?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 73.67%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2838 +/- ##; ==========================================; + Coverage 72.85% 73.67% +0.82% ; ==========================================; Files 111 111 ; Lines 12383 12386 +3 ; ==========================================; + Hits 9022 9126 +104 ; + Misses 3361 3260 -101 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2838?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_doctests.py](https://app.codecov.io/gh/scverse/scanpy/pull/2838?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2RvY3Rlc3RzLnB5) | `80.00% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2838?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `100.00% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/fixtures/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2838?src=pr&el=tree&utm_medium=referr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2838#issuecomment-1915069084:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2838#issuecomment-1915069084,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2843?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: `4 lines` in your changes are missing coverage. Please review.; > Comparison is base [(`585f58c`)](https://app.codecov.io/gh/scverse/scanpy/commit/585f58c9e4dd82dd7809a831538c4e230b008818?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 73.67% compared to head [(`8ee10ad`)](https://app.codecov.io/gh/scverse/scanpy/pull/2843?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 73.66%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2843 +/- ##; ==========================================; - Coverage 73.67% 73.66% -0.02% ; ==========================================; Files 111 111 ; Lines 12386 12395 +9 ; ==========================================; + Hits 9126 9131 +5 ; - Misses 3260 3264 +4 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2843?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2843?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `91.66% <55.55%> (-8.34%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2843#issuecomment-1934406672:1304,test,testing,1304,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2843#issuecomment-1934406672,1,['test'],['testing']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2848?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`0c82903`)](https://app.codecov.io/gh/scverse/scanpy/commit/0c82903db822324f28e5b04101381a6298f59f06?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.06% compared to head [(`9e53d01`)](https://app.codecov.io/gh/scverse/scanpy/pull/2848?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.05%.; > Report is 1 commits behind head on master. > :exclamation: Current head 9e53d01 differs from pull request most recent head 0ab034a. Consider uploading reports for the commit 0ab034a to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2848 +/- ##; ==========================================; - Coverage 74.06% 74.05% -0.02% ; ==========================================; Files 115 115 ; Lines 12644 12646 +2 ; ==========================================; Hits 9365 9365 ; - Misses 3279 3281 +2 ; ```. [see 3 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2848/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2848#issuecomment-1938900045:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2848#issuecomment-1938900045,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2849?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`c091999`)](https://app.codecov.io/gh/scverse/scanpy/commit/c09199928bd457459f43f72ab3aa114ac07f1249?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.05% compared to head [(`c51fc7b`)](https://app.codecov.io/gh/scverse/scanpy/pull/2849?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.05%.; > Report is 1 commits behind head on master. > :exclamation: Current head c51fc7b differs from pull request most recent head be10a25. Consider uploading reports for the commit be10a25 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2849 +/- ##; =======================================; Coverage 74.05% 74.05% ; =======================================; Files 115 115 ; Lines 12638 12638 ; =======================================; Hits 9359 9359 ; Misses 3279 3279 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2849?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_docs.py](https://app.codecov.io/gh/scverse/scanpy/pull/2849?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2RvY3MucHk=) | `100.00% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2849#issuecomment-1938925357:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2849#issuecomment-1938925357,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2850?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`c091999`)](https://app.codecov.io/gh/scverse/scanpy/commit/c09199928bd457459f43f72ab3aa114ac07f1249?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.05% compared to head [(`ba409af`)](https://app.codecov.io/gh/scverse/scanpy/pull/2850?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.05%.; > Report is 1 commits behind head on master. > :exclamation: Current head ba409af differs from pull request most recent head f3ffba8. Consider uploading reports for the commit f3ffba8 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2850 +/- ##; =======================================; Coverage 74.05% 74.05% ; =======================================; Files 115 115 ; Lines 12638 12638 ; =======================================; Hits 9359 9359 ; Misses 3279 3279 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2850#issuecomment-1939257630:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2850#issuecomment-1939257630,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2851?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`284df77`)](https://app.codecov.io/gh/scverse/scanpy/commit/284df7791575f1b5a4a484b4f647059fac366623?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.05% compared to head [(`5a05009`)](https://app.codecov.io/gh/scverse/scanpy/pull/2851?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.06%.; > Report is 2 commits behind head on master. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2851 +/- ##; =======================================; Coverage 74.05% 74.06% ; =======================================; Files 115 115 ; Lines 12646 12646 ; =======================================; + Hits 9365 9366 +1 ; + Misses 3281 3280 -1 ; ```. [see 2 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2851/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2851#issuecomment-1941162103:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2851#issuecomment-1941162103,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2852?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: `3 lines` in your changes are missing coverage. Please review.; > Comparison is base [(`c091999`)](https://app.codecov.io/gh/scverse/scanpy/commit/c09199928bd457459f43f72ab3aa114ac07f1249?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.05% compared to head [(`d44dad3`)](https://app.codecov.io/gh/scverse/scanpy/pull/2852?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.05%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2852 +/- ##; =======================================; Coverage 74.05% 74.05% ; =======================================; Files 115 115 ; Lines 12638 12646 +8 ; =======================================; + Hits 9359 9365 +6 ; - Misses 3279 3281 +2 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2852?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2852?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `86.20% <72.72%> (-1.80%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2852#issuecomment-1941313680:1286,test,testing,1286,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2852#issuecomment-1941313680,1,['test'],['testing']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2855?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`8f4243e`)](https://app.codecov.io/gh/scverse/scanpy/commit/8f4243e47fff5c2024679bbe16c1a04ad5b2b337?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.06% compared to head [(`592f738`)](https://app.codecov.io/gh/scverse/scanpy/pull/2855?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.06%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2855 +/- ##; =======================================; Coverage 74.06% 74.06% ; =======================================; Files 115 115 ; Lines 12646 12644 -2 ; =======================================; - Hits 9366 9365 -1 ; + Misses 3280 3279 -1 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2855?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/logging.py](https://app.codecov.io/gh/scverse/scanpy/pull/2855?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `95.86% <100.00%> (+0.74%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2855#issuecomment-1943754349:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2855#issuecomment-1943754349,2,"['log', 'test']","['logging', 'tests']"
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2859?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`d7607e5`)](https://app.codecov.io/gh/scverse/scanpy/commit/d7607e58f9540a8ae502ecae42db80598771f962?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.57% compared to head [(`217e597`)](https://app.codecov.io/gh/scverse/scanpy/pull/2859?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.15%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2859 +/- ##; ==========================================; - Coverage 74.57% 74.15% -0.43% ; ==========================================; Files 115 115 ; Lines 12714 12716 +2 ; ==========================================; - Hits 9481 9429 -52 ; - Misses 3233 3287 +54 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2859?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_qc.py](https://app.codecov.io/gh/scverse/scanpy/pull/2859?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3FjLnB5) | `82.14% <100.00%> (+0.21%)` | :arrow_up: |. ... and [9 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2859/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2859#issuecomment-1946865093:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2859#issuecomment-1946865093,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2860?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`ddeb820`)](https://app.codecov.io/gh/scverse/scanpy/commit/ddeb820620b48752d41d0903df0475c4a60d7b64?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.56% compared to head [(`a2f9962`)](https://app.codecov.io/gh/scverse/scanpy/pull/2860?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.57%.; > Report is 3 commits behind head on master. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2860 +/- ##; =======================================; Coverage 74.56% 74.57% ; =======================================; Files 115 115 ; Lines 12713 12716 +3 ; =======================================; + Hits 9480 9483 +3 ; Misses 3233 3233 ; ```. [see 5 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2860/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2860#issuecomment-1948175782:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2860#issuecomment-1948175782,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2863?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`ddeb820`)](https://app.codecov.io/gh/scverse/scanpy/commit/ddeb820620b48752d41d0903df0475c4a60d7b64?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.56% compared to head [(`cd33292`)](https://app.codecov.io/gh/scverse/scanpy/pull/2863?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.57%.; > Report is 2 commits behind head on master. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2863 +/- ##; =======================================; Coverage 74.56% 74.57% ; =======================================; Files 115 115 ; Lines 12713 12714 +1 ; =======================================; + Hits 9480 9481 +1 ; Misses 3233 3233 ; ```. [see 4 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2863/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2863#issuecomment-1948592777:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2863#issuecomment-1948592777,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2867?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`6ee18b9`)](https://app.codecov.io/gh/scverse/scanpy/commit/6ee18b954b743cba6b75ddf8bfe823cb287bf3b9?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.63% compared to head [(`fc5506c`)](https://app.codecov.io/gh/scverse/scanpy/pull/2867?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.80%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2867 +/- ##; ==========================================; - Coverage 74.63% 72.80% -1.83% ; ==========================================; Files 115 115 ; Lines 12756 12719 -37 ; ==========================================; - Hits 9520 9260 -260 ; - Misses 3236 3459 +223 ; ```. [see 27 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2867/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2867#issuecomment-1952977059:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2867#issuecomment-1952977059,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2868?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`383a61b`)](https://app.codecov.io/gh/scverse/scanpy/commit/383a61b2db0c45ba622f231f01d0e7546d99566b?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.83% compared to head [(`2c2eed8`)](https://app.codecov.io/gh/scverse/scanpy/pull/2868?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.83%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2868 +/- ##; =======================================; Coverage 74.83% 74.83% ; =======================================; Files 116 116 ; Lines 12891 12891 ; =======================================; Hits 9647 9647 ; Misses 3244 3244 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2868#issuecomment-1954138978:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2868#issuecomment-1954138978,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2870?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`d27ee7f`)](https://app.codecov.io/gh/scverse/scanpy/commit/d27ee7fad77c3691db2be932a254446f79f2c49c?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 73.04% compared to head [(`b331a32`)](https://app.codecov.io/gh/scverse/scanpy/pull/2870?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 73.14%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2870 +/- ##; ==========================================; + Coverage 73.04% 73.14% +0.09% ; ==========================================; Files 116 116 ; Lines 12854 12785 -69 ; ==========================================; - Hits 9389 9351 -38 ; + Misses 3465 3434 -31 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2870?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2870?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `67.26% <ø> (+0.09%)` | :arrow_up: |; | [scanpy/neighbors/\_connectivity.py](https://app.codecov.io/gh/scverse/scanpy/pull/2870?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L25laWdoYm9ycy9fY29ubmVjdGl2aXR5LnB5) | `85.96% <100.00%> (+1.21%)` | :arrow_up: |; | [scanpy/tools/\_ingest.py](https://app.codecov.io/gh/scverse/scanpy/pull/2870?src=pr&el=tree&utm_medium=referral&utm_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2870#issuecomment-1954154227:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2870#issuecomment-1954154227,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2872?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`21e6a75`)](https://app.codecov.io/gh/scverse/scanpy/commit/21e6a7503a7ee2649ba7a63f2366ba4729bc9c79?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 73.14% compared to head [(`5525b45`)](https://app.codecov.io/gh/scverse/scanpy/pull/2872?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.81%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2872 +/- ##; ==========================================; + Coverage 73.14% 74.81% +1.67% ; ==========================================; Files 116 116 ; Lines 12785 12822 +37 ; ==========================================; + Hits 9351 9593 +242 ; + Misses 3434 3229 -205 ; ```. [see 24 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2872/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2872#issuecomment-1954283244:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2872#issuecomment-1954283244,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2874?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`383a61b`)](https://app.codecov.io/gh/scverse/scanpy/commit/383a61b2db0c45ba622f231f01d0e7546d99566b?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.83% compared to head [(`81b4267`)](https://app.codecov.io/gh/scverse/scanpy/pull/2874?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 73.04%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2874 +/- ##; ==========================================; - Coverage 74.83% 73.04% -1.80% ; ==========================================; Files 116 116 ; Lines 12891 12854 -37 ; ==========================================; - Hits 9647 9389 -258 ; - Misses 3244 3465 +221 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2874?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_docs.py](https://app.codecov.io/gh/scverse/scanpy/pull/2874?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2RvY3MucHk=) | `100.00% <ø> (ø)` | |. ... and [28 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2874/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2874#issuecomment-1956814628:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2874#issuecomment-1956814628,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2876?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`4b77cf2`)](https://app.codecov.io/gh/scverse/scanpy/commit/4b77cf249c7ef404bea2b353fb86569a5eec4cd9?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.81% compared to head [(`c3d1ecd`)](https://app.codecov.io/gh/scverse/scanpy/pull/2876?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 73.14%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2876 +/- ##; ==========================================; - Coverage 74.81% 73.14% -1.68% ; ==========================================; Files 116 116 ; Lines 12822 12785 -37 ; ==========================================; - Hits 9593 9351 -242 ; - Misses 3229 3434 +205 ; ```. [see 24 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2876/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2876#issuecomment-1959351434:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2876#issuecomment-1959351434,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2877?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 74.83%. Comparing base [(`d15f4e7`)](https://app.codecov.io/gh/scverse/scanpy/commit/d15f4e7d8aade4fa65e25e0db71c764b6d3ac376?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`ad440f3`)](https://app.codecov.io/gh/scverse/scanpy/pull/2877?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2877 +/- ##; =======================================; Coverage 74.83% 74.83% ; =======================================; Files 116 116 ; Lines 12814 12814 ; =======================================; Hits 9589 9589 ; Misses 3225 3225 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2877#issuecomment-1961326675:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2877#issuecomment-1961326675,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2879?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 74.83%. Comparing base [(`48b495d`)](https://app.codecov.io/gh/scverse/scanpy/commit/48b495d983a2873083b823e9be5e98f6082ac88c?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7cebbe8`)](https://app.codecov.io/gh/scverse/scanpy/pull/2879?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2879 +/- ##; ==========================================; + Coverage 74.81% 74.83% +0.01% ; ==========================================; Files 116 116 ; Lines 12822 12814 -8 ; ==========================================; - Hits 9593 9589 -4 ; + Misses 3229 3225 -4 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2879?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2879?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L19faW5pdF9fLnB5) | `89.28% <100.00%> (ø)` | |; | [scanpy/testing/\_doctests.py](https://app.codecov.io/gh/scverse/scanpy/pull/2879?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2RvY3Rlc3RzLnB5) | `93.75% <100.00%> (+13.75%)` | :arrow_up: |; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2879?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2879#issuecomment-1959799975:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2879#issuecomment-1959799975,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2880?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.15%. Comparing base [(`48b495d`)](https://app.codecov.io/gh/scverse/scanpy/commit/48b495d983a2873083b823e9be5e98f6082ac88c?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`68c920a`)](https://app.codecov.io/gh/scverse/scanpy/pull/2880?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2880 +/- ##; ==========================================; - Coverage 74.81% 73.15% -1.67% ; ==========================================; Files 116 116 ; Lines 12822 12777 -45 ; ==========================================; - Hits 9593 9347 -246 ; - Misses 3229 3430 +201 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2880?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2880?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L19faW5pdF9fLnB5) | `89.28% <100.00%> (ø)` | |; | [scanpy/testing/\_doctests.py](https://app.codecov.io/gh/scverse/scanpy/pull/2880?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2RvY3Rlc3RzLnB5) | `93.75% <100.00%> (+13.75%)` | :arrow_up: |; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2880?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2880#issuecomment-1960898937:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2880#issuecomment-1960898937,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2882?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.15%. Comparing base [(`2be2eb0`)](https://app.codecov.io/gh/scverse/scanpy/commit/2be2eb09dc3933443ee6b2e46dfd6675b18478a7?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`1eb20dd`)](https://app.codecov.io/gh/scverse/scanpy/pull/2882?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2882 +/- ##; ==========================================; - Coverage 74.83% 73.15% -1.68% ; ==========================================; Files 116 116 ; Lines 12814 12777 -37 ; ==========================================; - Hits 9589 9347 -242 ; - Misses 3225 3430 +205 ; ```. [see 24 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2882/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2882#issuecomment-1960985417:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2882#issuecomment-1960985417,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2883?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 74.83%. Comparing base [(`d15f4e7`)](https://app.codecov.io/gh/scverse/scanpy/commit/d15f4e7d8aade4fa65e25e0db71c764b6d3ac376?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`bb43cff`)](https://app.codecov.io/gh/scverse/scanpy/pull/2883?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2883 +/- ##; =======================================; Coverage 74.83% 74.83% ; =======================================; Files 116 116 ; Lines 12814 12814 ; =======================================; Hits 9589 9589 ; Misses 3225 3225 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2883#issuecomment-1961362629:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2883#issuecomment-1961362629,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2884?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.15%. Comparing base [(`d15f4e7`)](https://app.codecov.io/gh/scverse/scanpy/commit/d15f4e7d8aade4fa65e25e0db71c764b6d3ac376?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a90579f`)](https://app.codecov.io/gh/scverse/scanpy/pull/2884?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2884 +/- ##; ==========================================; - Coverage 74.83% 73.15% -1.68% ; ==========================================; Files 116 116 ; Lines 12814 12777 -37 ; ==========================================; - Hits 9589 9347 -242 ; - Misses 3225 3430 +205 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2884?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_rank\_genes\_groups.py](https://app.codecov.io/gh/scverse/scanpy/pull/2884?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19yYW5rX2dlbmVzX2dyb3Vwcy5weQ==) | `94.33% <ø> (ø)` | |. ... and [24 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2884/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2884#issuecomment-1961392284:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2884#issuecomment-1961392284,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2886?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 74.83%. Comparing base [(`d102012`)](https://app.codecov.io/gh/scverse/scanpy/commit/d102012f1a2d293d6ab276a2d4dd602ed6f18a5e?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`5f0f7f2`)](https://app.codecov.io/gh/scverse/scanpy/pull/2886?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2886 +/- ##; =======================================; Coverage 74.83% 74.83% ; =======================================; Files 116 116 ; Lines 12814 12814 ; =======================================; Hits 9589 9589 ; Misses 3225 3225 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2886?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_rank\_genes\_groups.py](https://app.codecov.io/gh/scverse/scanpy/pull/2886?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19yYW5rX2dlbmVzX2dyb3Vwcy5weQ==) | `94.33% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2886#issuecomment-1961562971:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2886#issuecomment-1961562971,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2888?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.86%. Comparing base [(`3d03f2e`)](https://app.codecov.io/gh/scverse/scanpy/commit/3d03f2ed2c76279d864a8e22badb78896afa315a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d986e8d`)](https://app.codecov.io/gh/scverse/scanpy/commit/d986e8d30389f84fc95aff60cb9058b964fedf5b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 44 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2888 +/- ##; =======================================; Coverage 75.86% 75.86% ; =======================================; Files 110 110 ; Lines 12532 12535 +3 ; =======================================; + Hits 9507 9510 +3 ; Misses 3025 3025 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/2888?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/logging.py](https://app.codecov.io/gh/scverse/scanpy/pull/2888?src=pr&el=tree&filepath=scanpy%2Flogging.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `95.86% <ø> (ø)` | |; | [scanpy/plotting/\_docs.py](https://app.codecov.io/gh/scverse/scanpy/pull/2888?src=pr&el=tree&filepath=scanpy%2Fplotting%2F_docs.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19kb2NzLnB5) | `100.00% <100.00%>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2888#issuecomment-1961924329:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2888#issuecomment-1961924329,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2890?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 74.82%. Comparing base [(`91ea0fb`)](https://app.codecov.io/gh/scverse/scanpy/commit/91ea0fbb03392795d1506d297d4b4847c646db04?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6c254fe`)](https://app.codecov.io/gh/scverse/scanpy/pull/2890?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2890 +/- ##; ==========================================; - Coverage 74.83% 74.82% -0.01% ; ==========================================; Files 116 116 ; Lines 12814 12809 -5 ; ==========================================; - Hits 9589 9584 -5 ; Misses 3225 3225 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2890?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2890?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19zY29yZV9nZW5lcy5weQ==) | `85.18% <100.00%> (-0.87%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2890#issuecomment-1963764723:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2890#issuecomment-1963764723,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2891?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.14%. Comparing base [(`e6f3638`)](https://app.codecov.io/gh/scverse/scanpy/commit/e6f36384f0994c0d5dce459b2f528ae3b65d0a21?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6918ff4`)](https://app.codecov.io/gh/scverse/scanpy/pull/2891?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2891 +/- ##; ==========================================; - Coverage 73.15% 73.14% -0.02% ; ==========================================; Files 116 116 ; Lines 12777 12772 -5 ; ==========================================; - Hits 9347 9342 -5 ; Misses 3430 3430 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2891?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2891?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19zY29yZV9nZW5lcy5weQ==) | `85.18% <100.00%> (-0.87%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2891#issuecomment-1963867772:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2891#issuecomment-1963867772,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2893?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 74.82%. Comparing base [(`14555ba`)](https://app.codecov.io/gh/scverse/scanpy/commit/14555ba48537995acaa381b8b6ad5fc41e612510?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`21d4bb4`)](https://app.codecov.io/gh/scverse/scanpy/pull/2893?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2893 +/- ##; =======================================; Coverage 74.82% 74.82% ; =======================================; Files 116 116 ; Lines 12809 12809 ; =======================================; Hits 9584 9584 ; Misses 3225 3225 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2893?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/2893?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9fYWdncmVnYXRlZC5weQ==) | `95.04% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2893#issuecomment-1976851089:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2893#issuecomment-1976851089,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2896?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 74.82%. Comparing base [(`a956fa7`)](https://app.codecov.io/gh/scverse/scanpy/commit/a956fa781a8406fc5030093356c0372456d9184b?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a33eb04`)](https://app.codecov.io/gh/scverse/scanpy/pull/2896?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2896 +/- ##; =======================================; Coverage 74.82% 74.82% ; =======================================; Files 116 116 ; Lines 12809 12811 +2 ; =======================================; + Hits 9584 9586 +2 ; Misses 3225 3225 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2896?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_scrublet/core.py](https://app.codecov.io/gh/scverse/scanpy/pull/2896?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3NjcnVibGV0L2NvcmUucHk=) | `92.76% <100.00%> (+0.09%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2896#issuecomment-1978704713:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2896#issuecomment-1978704713,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2897?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.14%. Comparing base [(`9b41a2c`)](https://app.codecov.io/gh/scverse/scanpy/commit/9b41a2c23ba48842ae4cb0536ed76a231b74fff4?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`9a138c3`)](https://app.codecov.io/gh/scverse/scanpy/pull/2897?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2897 +/- ##; ==========================================; - Coverage 74.82% 73.14% -1.68% ; ==========================================; Files 116 116 ; Lines 12809 12772 -37 ; ==========================================; - Hits 9584 9342 -242 ; - Misses 3225 3430 +205 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2897?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/2897?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9fYWdncmVnYXRlZC5weQ==) | `95.04% <100.00%> (ø)` | |. ... and [24 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2897/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2897#issuecomment-1981171846:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2897#issuecomment-1981171846,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2900?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 74.82%. Comparing base [(`a956fa7`)](https://app.codecov.io/gh/scverse/scanpy/commit/a956fa781a8406fc5030093356c0372456d9184b?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`b4df37d`)](https://app.codecov.io/gh/scverse/scanpy/pull/2900?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2900 +/- ##; =======================================; Coverage 74.82% 74.82% ; =======================================; Files 116 116 ; Lines 12809 12809 ; =======================================; Hits 9584 9584 ; Misses 3225 3225 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2900#issuecomment-1991222746:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2900#issuecomment-1991222746,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2901?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.49%. Comparing base [(`f5edd43`)](https://app.codecov.io/gh/scverse/scanpy/commit/f5edd43fde1a4bd750482fa0def65e1d15a07653?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`b22084d`)](https://app.codecov.io/gh/scverse/scanpy/pull/2901?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2901 +/- ##; =======================================; Coverage 75.49% 75.49% ; =======================================; Files 116 116 ; Lines 12911 12911 ; =======================================; Hits 9747 9747 ; Misses 3164 3164 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2901?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/datasets/\_datasets.py](https://app.codecov.io/gh/scverse/scanpy/pull/2901?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2RhdGFzZXRzL19kYXRhc2V0cy5weQ==) | `86.04% <ø> (ø)` | |; | [scanpy/neighbors/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2901?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L25laWdoYm9ycy9fX2luaXRfXy5weQ==) | `80.75% <ø> (ø)` | |; | [scanpy/plotting/\_tools/scatterplots.py](https://app.codecov.io/gh/scverse/s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2901#issuecomment-1991466131:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2901#issuecomment-1991466131,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2903?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.14%. Comparing base [(`a956fa7`)](https://app.codecov.io/gh/scverse/scanpy/commit/a956fa781a8406fc5030093356c0372456d9184b?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`0e2d9c1`)](https://app.codecov.io/gh/scverse/scanpy/pull/2903?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2903 +/- ##; ==========================================; - Coverage 74.82% 73.14% -1.68% ; ==========================================; Files 116 116 ; Lines 12809 12772 -37 ; ==========================================; - Hits 9584 9342 -242 ; - Misses 3225 3430 +205 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2903?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/neighbors/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2903?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L25laWdoYm9ycy9fX2luaXRfXy5weQ==) | `80.75% <ø> (ø)` | |. ... and [24 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2903/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2903#issuecomment-1991587915:234,test,tests,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2903#issuecomment-1991587915,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2904?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.14%. Comparing base [(`b2c2e3c`)](https://app.codecov.io/gh/scverse/scanpy/commit/b2c2e3c795d9638603a735fd0c985ea1fb499658?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`b4547ae`)](https://app.codecov.io/gh/scverse/scanpy/pull/2904?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2904 +/- ##; ==========================================; - Coverage 74.49% 73.14% -1.35% ; ==========================================; Files 116 116 ; Lines 12811 12774 -37 ; ==========================================; - Hits 9544 9344 -200 ; - Misses 3267 3430 +163 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2904?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/neighbors/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2904?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L25laWdoYm9ycy9fX2luaXRfXy5weQ==) | `80.75% <ø> (ø)` | |. ... and [23 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2904/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2904#issuecomment-1991647118:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2904#issuecomment-1991647118,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2905?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.14%. Comparing base [(`e50d7fe`)](https://app.codecov.io/gh/scverse/scanpy/commit/e50d7fe48debb2242ce264d091a9299eabda7d98?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`c1e6602`)](https://app.codecov.io/gh/scverse/scanpy/pull/2905?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2905 +/- ##; ==========================================; - Coverage 74.49% 73.14% -1.35% ; ==========================================; Files 116 116 ; Lines 12809 12774 -35 ; ==========================================; - Hits 9542 9344 -198 ; - Misses 3267 3430 +163 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2905?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2905?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `65.60% <100.00%> (-30.02%)` | :arrow_down: |; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2905?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2905#issuecomment-1991700950:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2905#issuecomment-1991700950,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2913?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.16%. Comparing base [(`1fee6a1`)](https://app.codecov.io/gh/scverse/scanpy/commit/1fee6a1033669db8f0d1e4ade477b861174b5722?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`afaa6fe`)](https://app.codecov.io/gh/scverse/scanpy/pull/2913?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2913 +/- ##; ==========================================; - Coverage 74.82% 73.16% -1.67% ; ==========================================; Files 116 116 ; Lines 12811 12776 -35 ; ==========================================; - Hits 9586 9347 -239 ; - Misses 3225 3429 +204 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2913?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/2913?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3NpbXBsZS5weQ==) | `80.88% <100.00%> (-2.02%)` | :arrow_down: |. ... and [23 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2913/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2913#issuecomment-1997155571:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2913#issuecomment-1997155571,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2914?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.14%. Comparing base [(`1fee6a1`)](https://app.codecov.io/gh/scverse/scanpy/commit/1fee6a1033669db8f0d1e4ade477b861174b5722?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`359a071`)](https://app.codecov.io/gh/scverse/scanpy/pull/2914?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2914 +/- ##; ==========================================; - Coverage 74.82% 73.14% -1.68% ; ==========================================; Files 116 116 ; Lines 12811 12774 -37 ; ==========================================; - Hits 9586 9344 -242 ; - Misses 3225 3430 +205 ; ```. [see 24 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2914/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2914#issuecomment-1997215976:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2914#issuecomment-1997215976,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2915?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.14%. Comparing base [(`b2c2e3c`)](https://app.codecov.io/gh/scverse/scanpy/commit/b2c2e3c795d9638603a735fd0c985ea1fb499658?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`490f978`)](https://app.codecov.io/gh/scverse/scanpy/pull/2915?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2915 +/- ##; ==========================================; - Coverage 74.49% 73.14% -1.35% ; ==========================================; Files 116 116 ; Lines 12811 12774 -37 ; ==========================================; - Hits 9544 9344 -200 ; - Misses 3267 3430 +163 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2915?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2915?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `65.60% <100.00%> (-30.02%)` | :arrow_down: |; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2915?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `88.23% <100.00%> (+0.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2915#issuecomment-1997257856:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2915#issuecomment-1997257856,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2916?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 74.92%. Comparing base [(`1fee6a1`)](https://app.codecov.io/gh/scverse/scanpy/commit/1fee6a1033669db8f0d1e4ade477b861174b5722?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6b6fa3a`)](https://app.codecov.io/gh/scverse/scanpy/pull/2916?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 3 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2916 +/- ##; ==========================================; + Coverage 74.82% 74.92% +0.09% ; ==========================================; Files 116 116 ; Lines 12811 12802 -9 ; ==========================================; + Hits 9586 9592 +6 ; + Misses 3225 3210 -15 ; ```. [see 33 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2916/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2916#issuecomment-1997498536:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2916#issuecomment-1997498536,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2917?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.16%. Comparing base [(`545b0a6`)](https://app.codecov.io/gh/scverse/scanpy/commit/545b0a6c167c9968233d16526380256ae5bd06ab?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`4efa173`)](https://app.codecov.io/gh/scverse/scanpy/pull/2917?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2917 +/- ##; ==========================================; - Coverage 74.82% 73.16% -1.67% ; ==========================================; Files 116 116 ; Lines 12811 12776 -35 ; ==========================================; - Hits 9586 9347 -239 ; - Misses 3225 3429 +204 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2917?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/2917?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3NpbXBsZS5weQ==) | `80.88% <100.00%> (-2.02%)` | :arrow_down: |. ... and [23 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2917/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2917#issuecomment-1997393568:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2917#issuecomment-1997393568,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2918?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 74.82%. Comparing base [(`545b0a6`)](https://app.codecov.io/gh/scverse/scanpy/commit/545b0a6c167c9968233d16526380256ae5bd06ab?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`831be5b`)](https://app.codecov.io/gh/scverse/scanpy/pull/2918?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2918 +/- ##; =======================================; Coverage 74.82% 74.82% ; =======================================; Files 116 116 ; Lines 12811 12811 ; =======================================; Hits 9586 9586 ; Misses 3225 3225 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2918#issuecomment-1997428592:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2918#issuecomment-1997428592,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2920?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.22%. Comparing base [(`b08fea3`)](https://app.codecov.io/gh/scverse/scanpy/commit/b08fea371ea8a4d95c55e053237cc94894ba632a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`41a6aeb`)](https://app.codecov.io/gh/scverse/scanpy/pull/2920?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2920 +/- ##; ==========================================; - Coverage 74.90% 73.22% -1.68% ; ==========================================; Files 116 116 ; Lines 12802 12765 -37 ; ==========================================; - Hits 9589 9347 -242 ; - Misses 3213 3418 +205 ; ```. [see 24 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2920/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2920#issuecomment-1997993108:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2920#issuecomment-1997993108,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2921?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.35%. Comparing base [(`21aecd9`)](https://app.codecov.io/gh/scverse/scanpy/commit/21aecd974e6570f514bc5a0677b889a9e5d113c3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`72e2783`)](https://app.codecov.io/gh/scverse/scanpy/commit/72e27831b65d154077d13d6f7386bfcfe6961145?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 41 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2921 +/- ##; =======================================; Coverage 76.35% 76.35% ; =======================================; Files 110 110 ; Lines 12543 12543 ; =======================================; Hits 9577 9577 ; Misses 2966 2966 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/2921?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2921?src=pr&el=tree&filepath=scanpy%2Ftools%2F_score_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19zY29yZV9nZW5lcy5weQ==) | `85.54% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2921#issuecomment-1999229021:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2921#issuecomment-1999229021,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2922?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 74.92%. Comparing base [(`360e350`)](https://app.codecov.io/gh/scverse/scanpy/commit/360e3501460824906b0fef88c36f1d78364e6994?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`c54dd78`)](https://app.codecov.io/gh/scverse/scanpy/pull/2922?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2922 +/- ##; =======================================; Coverage 74.92% 74.92% ; =======================================; Files 116 116 ; Lines 12802 12802 ; =======================================; Hits 9592 9592 ; Misses 3210 3210 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2922#issuecomment-2002057287:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2922#issuecomment-2002057287,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2924?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.05%. Comparing base [(`b132f11`)](https://app.codecov.io/gh/scverse/scanpy/commit/b132f115385f1a917f3201dfcbf1f36dfa03235b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`243a859`)](https://app.codecov.io/gh/scverse/scanpy/pull/2924?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2924 +/- ##; ==========================================; + Coverage 74.92% 75.05% +0.12% ; ==========================================; Files 116 116 ; Lines 12802 12802 ; ==========================================; + Hits 9592 9608 +16 ; + Misses 3210 3194 -16 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2924?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_leiden.py](https://app.codecov.io/gh/scverse/scanpy/pull/2924?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19sZWlkZW4ucHk=) | `88.40% <100.00%> (ø)` | |; | [scanpy/tools/\_louvain.py](https://app.codecov.io/gh/scverse/scanpy/pull/2924?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19sb3V2YWluLnB5) | `59.18% <100.00%> (+37.75%)` | :arrow_up: |. ... and [9 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2924#issuecomment-2003934502:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2924#issuecomment-2003934502,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2925?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.22%. Comparing base [(`29b2ad3`)](https://app.codecov.io/gh/scverse/scanpy/commit/29b2ad35ac5a4be0bd490a1f77b38e48f2b3e300?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a26068f`)](https://app.codecov.io/gh/scverse/scanpy/pull/2925?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2925 +/- ##; ==========================================; - Coverage 75.24% 73.22% -2.03% ; ==========================================; Files 116 116 ; Lines 12802 12765 -37 ; ==========================================; - Hits 9633 9347 -286 ; - Misses 3169 3418 +249 ; ```. [see 27 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2925/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2925#issuecomment-2004020699:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2925#issuecomment-2004020699,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2926?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.24%. Comparing base [(`9fe9858`)](https://app.codecov.io/gh/scverse/scanpy/commit/9fe98587895c1457fb1bc024e607e7c9332d2a3a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`87ac7cf`)](https://app.codecov.io/gh/scverse/scanpy/pull/2926?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2926 +/- ##; =======================================; Coverage 75.24% 75.24% ; =======================================; Files 116 116 ; Lines 12802 12802 ; =======================================; Hits 9633 9633 ; Misses 3169 3169 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2926#issuecomment-2004616544:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2926#issuecomment-2004616544,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2927?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.24%. Comparing base [(`bb0899f`)](https://app.codecov.io/gh/scverse/scanpy/commit/bb0899ffa70442055acc3ab0c4c76d11c78ff1f9?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`e91e2e9`)](https://app.codecov.io/gh/scverse/scanpy/pull/2927?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2927 +/- ##; =======================================; Coverage 75.24% 75.24% ; =======================================; Files 116 116 ; Lines 12802 12802 ; =======================================; Hits 9633 9633 ; Misses 3169 3169 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2927#issuecomment-2005238929:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2927#issuecomment-2005238929,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2928?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.14%. Comparing base [(`e6c7251`)](https://app.codecov.io/gh/scverse/scanpy/commit/e6c7251d66eae3983baad37575a6b0bba8fe1318?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`ea6c7af`)](https://app.codecov.io/gh/scverse/scanpy/pull/2928?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2928 +/- ##; ==========================================; - Coverage 75.48% 73.14% -2.34% ; ==========================================; Files 116 116 ; Lines 12904 12875 -29 ; ==========================================; - Hits 9741 9418 -323 ; - Misses 3163 3457 +294 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2928?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_dendrogram.py](https://app.codecov.io/gh/scverse/scanpy/pull/2928?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19kZW5kcm9ncmFtLnB5) | `86.66% <100.00%> (ø)` | |. ... and [29 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2928/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2928#issuecomment-2006674951:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2928#issuecomment-2006674951,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2932?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.24%. Comparing base [(`8d32a51`)](https://app.codecov.io/gh/scverse/scanpy/commit/8d32a519e61607ed224c2844a841b12eb8eb31a9?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`4547def`)](https://app.codecov.io/gh/scverse/scanpy/pull/2932?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2932 +/- ##; =======================================; Coverage 75.24% 75.24% ; =======================================; Files 116 116 ; Lines 12802 12802 ; =======================================; Hits 9633 9633 ; Misses 3169 3169 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2932?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/2932?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9fYWdncmVnYXRlZC5weQ==) | `95.04% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2932#issuecomment-2007274551:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2932#issuecomment-2007274551,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2933?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.24%. Comparing base [(`0dc416f`)](https://app.codecov.io/gh/scverse/scanpy/commit/0dc416fe8e8d8bfd288ee190b25fe8f1f85e8aeb?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`233085e`)](https://app.codecov.io/gh/scverse/scanpy/pull/2933?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2933 +/- ##; =======================================; Coverage 75.24% 75.24% ; =======================================; Files 116 116 ; Lines 12802 12802 ; =======================================; Hits 9633 9633 ; Misses 3169 3169 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2933?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/2933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9fYWdncmVnYXRlZC5weQ==) | `95.04% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2933#issuecomment-2007353930:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2933#issuecomment-2007353930,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2934?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.14%. Comparing base [(`4b757d8`)](https://app.codecov.io/gh/scverse/scanpy/commit/4b757d85b015f028e7a283f509cbb77d82476754?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`0d9e650`)](https://app.codecov.io/gh/scverse/scanpy/pull/2934?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2934 +/- ##; ==========================================; - Coverage 75.47% 73.14% -2.34% ; ==========================================; Files 116 116 ; Lines 12896 12868 -28 ; ==========================================; - Hits 9733 9412 -321 ; - Misses 3163 3456 +293 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2934?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/2934?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9fYWdncmVnYXRlZC5weQ==) | `95.34% <100.00%> (+0.30%)` | :arrow_up: |. ... and [27 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2934/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2934#issuecomment-2007954902:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2934#issuecomment-2007954902,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2946?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.66%. Comparing base [(`c6766d7`)](https://app.codecov.io/gh/scverse/scanpy/commit/c6766d758b83410e9167578d22054f712d5bca4b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`603afb3`)](https://app.codecov.io/gh/scverse/scanpy/commit/603afb3ea48f4bf847c1fd0bda3c8d6d7fbafb7c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2946 +/- ##; ==========================================; + Coverage 76.63% 76.66% +0.03% ; ==========================================; Files 109 109 ; Lines 12533 12545 +12 ; ==========================================; + Hits 9605 9618 +13 ; + Misses 2928 2927 -1 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2946?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/tools/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2946?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fX2luaXRfXy5weQ==) | `91.30% <100.00%> (ø)` | |; | [src/scanpy/tools/\_umap.py](https://app.codecov.io/gh/scverse/scanpy/pull/2946?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_umap.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fdW1hcC5weQ==),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2946#issuecomment-2015221559:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2946#issuecomment-2015221559,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2948?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.14%. Comparing base [(`f8e1766`)](https://app.codecov.io/gh/scverse/scanpy/commit/f8e176662cf2143308086d250ce9f28ce514d357?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`b70d9ec`)](https://app.codecov.io/gh/scverse/scanpy/pull/2948?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2948 +/- ##; ==========================================; - Coverage 75.47% 73.14% -2.34% ; ==========================================; Files 116 116 ; Lines 12896 12868 -28 ; ==========================================; - Hits 9733 9412 -321 ; - Misses 3163 3456 +293 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2948?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/2948?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9fYWdncmVnYXRlZC5weQ==) | `95.34% <100.00%> (+0.30%)` | :arrow_up: |. ... and [27 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2948/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2948#issuecomment-2015591529:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2948#issuecomment-2015591529,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2951?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.49%. Comparing base [(`10a51d8`)](https://app.codecov.io/gh/scverse/scanpy/commit/10a51d8bdc489a5371a2c7e88d6bfe5d44b0b671?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`4900030`)](https://app.codecov.io/gh/scverse/scanpy/pull/2951?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2951 +/- ##; =======================================; Coverage 75.48% 75.49% ; =======================================; Files 116 116 ; Lines 12908 12911 +3 ; =======================================; + Hits 9744 9747 +3 ; Misses 3164 3164 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2951?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2951?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `74.62% <100.00%> (+0.21%)` | :arrow_up: |; | [scanpy/tools/\_leiden.py](https://app.codecov.io/gh/scverse/scanpy/pull/2951?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19sZWlkZW4ucHk=) | `88.23% <100.00%> (-0.18%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2951#issuecomment-2017738280:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2951#issuecomment-2017738280,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2953?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.14%. Comparing base [(`10a51d8`)](https://app.codecov.io/gh/scverse/scanpy/commit/10a51d8bdc489a5371a2c7e88d6bfe5d44b0b671?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3385aa6`)](https://app.codecov.io/gh/scverse/scanpy/pull/2953?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2953 +/- ##; ==========================================; - Coverage 75.48% 73.14% -2.34% ; ==========================================; Files 116 116 ; Lines 12908 12875 -33 ; ==========================================; - Hits 9744 9418 -326 ; - Misses 3164 3457 +293 ; ```. [see 28 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2953/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2953#issuecomment-2017880429:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2953#issuecomment-2017880429,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2958?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.49%. Comparing base [(`f60a0a0`)](https://app.codecov.io/gh/scverse/scanpy/commit/f60a0a09204592dc6c16622cab5b1ec2198a76fd?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`f37f987`)](https://app.codecov.io/gh/scverse/scanpy/pull/2958?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2958 +/- ##; =======================================; Coverage 75.49% 75.49% ; =======================================; Files 116 116 ; Lines 12911 12911 ; =======================================; Hits 9747 9747 ; Misses 3164 3164 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2958?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_dendrogram.py](https://app.codecov.io/gh/scverse/scanpy/pull/2958?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19kZW5kcm9ncmFtLnB5) | `86.66% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2958#issuecomment-2018380339:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2958#issuecomment-2018380339,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2959?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.49%. Comparing base [(`d7c943e`)](https://app.codecov.io/gh/scverse/scanpy/commit/d7c943e84e0973aef536f6adfd46121d73998c6b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`eaf567c`)](https://app.codecov.io/gh/scverse/scanpy/pull/2959?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2959 +/- ##; =======================================; Coverage 75.49% 75.49% ; =======================================; Files 116 116 ; Lines 12911 12911 ; =======================================; Hits 9747 9747 ; Misses 3164 3164 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2959#issuecomment-2018487480:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2959#issuecomment-2018487480,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2960?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.49%. Comparing base [(`f5edd43`)](https://app.codecov.io/gh/scverse/scanpy/commit/f5edd43fde1a4bd750482fa0def65e1d15a07653?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`708a5c6`)](https://app.codecov.io/gh/scverse/scanpy/pull/2960?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2960 +/- ##; =======================================; Coverage 75.49% 75.49% ; =======================================; Files 116 116 ; Lines 12911 12911 ; =======================================; Hits 9747 9747 ; Misses 3164 3164 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2960#issuecomment-2018603381:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2960#issuecomment-2018603381,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2961?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.49%. Comparing base [(`2e1c1a4`)](https://app.codecov.io/gh/scverse/scanpy/commit/2e1c1a41e1d12afd353cf62044274266324bc8d3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`147f711`)](https://app.codecov.io/gh/scverse/scanpy/pull/2961?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2961 +/- ##; =======================================; Coverage 75.49% 75.49% ; =======================================; Files 116 116 ; Lines 12911 12911 ; =======================================; Hits 9747 9747 ; Misses 3164 3164 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2961#issuecomment-2018933015:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2961#issuecomment-2018933015,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2962?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.49%. Comparing base [(`236cbf9`)](https://app.codecov.io/gh/scverse/scanpy/commit/236cbf923a6c0dc07e576d524a9f5c32d7f4cf89?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`2affa7f`)](https://app.codecov.io/gh/scverse/scanpy/pull/2962?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2962 +/- ##; =======================================; Coverage 75.49% 75.49% ; =======================================; Files 116 116 ; Lines 12911 12911 ; =======================================; Hits 9747 9747 ; Misses 3164 3164 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2962?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/datasets/\_datasets.py](https://app.codecov.io/gh/scverse/scanpy/pull/2962?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2RhdGFzZXRzL19kYXRhc2V0cy5weQ==) | `86.04% <ø> (ø)` | |; | [scanpy/neighbors/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2962?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L25laWdoYm9ycy9fX2luaXRfXy5weQ==) | `80.75% <ø> (ø)` | |; | [scanpy/plotting/\_tools/scatterplots.py](https://app.codecov.io/gh/scverse/scanpy/pull/2962?src=pr&el=tree&utm_medium=,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2962#issuecomment-2020453449:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2962#issuecomment-2020453449,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2965?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.49%. Comparing base [(`65f567e`)](https://app.codecov.io/gh/scverse/scanpy/commit/65f567e6905afbbf673ecf715ad0f796794ce9cb?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`f00e045`)](https://app.codecov.io/gh/scverse/scanpy/pull/2965?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2965 +/- ##; =======================================; Coverage 75.49% 75.49% ; =======================================; Files 116 116 ; Lines 12911 12911 ; =======================================; Hits 9747 9747 ; Misses 3164 3164 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2965?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/2965?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9fYWdncmVnYXRlZC5weQ==) | `94.73% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2965#issuecomment-2021402463:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2965#issuecomment-2021402463,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2968?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.49%. Comparing base [(`214e05b`)](https://app.codecov.io/gh/scverse/scanpy/commit/214e05bdc54df61c520dc563ab39b7780e6d3358?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3f93825`)](https://app.codecov.io/gh/scverse/scanpy/pull/2968?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2968 +/- ##; =======================================; Coverage 75.49% 75.49% ; =======================================; Files 116 116 ; Lines 12911 12911 ; =======================================; Hits 9747 9747 ; Misses 3164 3164 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2968?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/2968?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9fYWdncmVnYXRlZC5weQ==) | `94.73% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2968#issuecomment-2022525214:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2968#issuecomment-2022525214,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2972?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > :exclamation: No coverage uploaded for pull request base (`main@3ceb740`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2972 +/- ##; =======================================; Coverage ? 75.49% ; =======================================; Files ? 116 ; Lines ? 12911 ; Branches ? 0 ; =======================================; Hits ? 9747 ; Misses ? 3164 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2972#issuecomment-2029918769:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2972#issuecomment-2029918769,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2974?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.14%. Comparing base [(`c68557c`)](https://app.codecov.io/gh/scverse/scanpy/commit/c68557c5ba05484b1c2fc0c0fe9489affecdc318?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`cb5c676`)](https://app.codecov.io/gh/scverse/scanpy/pull/2974?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2974 +/- ##; ==========================================; - Coverage 75.49% 73.14% -2.35% ; ==========================================; Files 116 116 ; Lines 12911 12875 -36 ; ==========================================; - Hits 9747 9418 -329 ; - Misses 3164 3457 +293 ; ```. [see 27 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2974/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2974#issuecomment-2031884508:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2974#issuecomment-2031884508,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2976?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.49%. Comparing base [(`c68557c`)](https://app.codecov.io/gh/scverse/scanpy/commit/c68557c5ba05484b1c2fc0c0fe9489affecdc318?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`b253e93`)](https://app.codecov.io/gh/scverse/scanpy/pull/2976?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2976 +/- ##; =======================================; Coverage 75.49% 75.49% ; =======================================; Files 116 116 ; Lines 12911 12911 ; =======================================; Hits 9747 9747 ; Misses 3164 3164 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2976#issuecomment-2036457090:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2976#issuecomment-2036457090,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2983?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.19%. Comparing base [(`0370057`)](https://app.codecov.io/gh/scverse/scanpy/commit/0370057b6d19d118beefe109a036d135c850f1c5?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`992245b`)](https://app.codecov.io/gh/scverse/scanpy/pull/2983?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2983 +/- ##; ==========================================; - Coverage 75.53% 73.19% -2.35% ; ==========================================; Files 117 117 ; Lines 12950 12914 -36 ; ==========================================; - Hits 9782 9452 -330 ; - Misses 3168 3462 +294 ; ```. [see 29 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2983/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2983#issuecomment-2042202840:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2983#issuecomment-2042202840,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2984?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.14%. Comparing base [(`8d7473b`)](https://app.codecov.io/gh/scverse/scanpy/commit/8d7473bdb5d43561437ed568f136bd045efb2196?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`1bcc154`)](https://app.codecov.io/gh/scverse/scanpy/pull/2984?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2984 +/- ##; ==========================================; - Coverage 75.49% 73.14% -2.35% ; ==========================================; Files 116 116 ; Lines 12911 12875 -36 ; ==========================================; - Hits 9747 9418 -329 ; - Misses 3164 3457 +293 ; ```. [see 27 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2984/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2984#issuecomment-2042367700:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2984#issuecomment-2042367700,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2987?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.51%. Comparing base [(`3255fda`)](https://app.codecov.io/gh/scverse/scanpy/commit/3255fda60b98373488a1c03722e9e9fa05ed648d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`b0bb1b2`)](https://app.codecov.io/gh/scverse/scanpy/pull/2987?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2987 +/- ##; =======================================; Coverage 75.51% 75.51% ; =======================================; Files 117 117 ; Lines 12955 12955 ; =======================================; Hits 9783 9783 ; Misses 3172 3172 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2987#issuecomment-2043400946:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2987#issuecomment-2043400946,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2988?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.17%. Comparing base [(`41bc8fa`)](https://app.codecov.io/gh/scverse/scanpy/commit/41bc8fa7671e03e6b335670ebff9a3adaef595f4?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`610fff0`)](https://app.codecov.io/gh/scverse/scanpy/pull/2988?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2988 +/- ##; ==========================================; - Coverage 75.51% 73.17% -2.34% ; ==========================================; Files 117 117 ; Lines 12955 12919 -36 ; ==========================================; - Hits 9783 9454 -329 ; - Misses 3172 3465 +293 ; ```. [see 28 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2988/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2988#issuecomment-2044434400:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2988#issuecomment-2044434400,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2989?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.51%. Comparing base [(`5ea8cfe`)](https://app.codecov.io/gh/scverse/scanpy/commit/5ea8cfe67ce160f51979ca3b2170ffc38313bba4?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`99877ec`)](https://app.codecov.io/gh/scverse/scanpy/pull/2989?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2989 +/- ##; =======================================; Coverage 75.51% 75.51% ; =======================================; Files 117 117 ; Lines 12955 12955 ; =======================================; Hits 9783 9783 ; Misses 3172 3172 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2989#issuecomment-2044521238:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2989#issuecomment-2044521238,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2990?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.17%. Comparing base [(`4ce9c42`)](https://app.codecov.io/gh/scverse/scanpy/commit/4ce9c42d4d3bcb10fa363640005b018e8e45f9a6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`e8ff7ea`)](https://app.codecov.io/gh/scverse/scanpy/pull/2990?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2990 +/- ##; ==========================================; - Coverage 75.51% 73.17% -2.34% ; ==========================================; Files 117 117 ; Lines 12955 12919 -36 ; ==========================================; - Hits 9783 9454 -329 ; - Misses 3172 3465 +293 ; ```. [see 28 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2990/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2990#issuecomment-2044595550:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2990#issuecomment-2044595550,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2991?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.51%. Comparing base [(`9c8c095`)](https://app.codecov.io/gh/scverse/scanpy/commit/9c8c095daa6e411e73845ccca99d2c5171b3f059?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`64a0108`)](https://app.codecov.io/gh/scverse/scanpy/pull/2991?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2991 +/- ##; =======================================; Coverage 75.51% 75.51% ; =======================================; Files 117 117 ; Lines 12955 12955 ; =======================================; Hits 9783 9783 ; Misses 3172 3172 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2991#issuecomment-2044966293:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2991#issuecomment-2044966293,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2994?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.50%. Comparing base [(`4d82db0`)](https://app.codecov.io/gh/scverse/scanpy/commit/4d82db0cbd96e789884c22610f55ff8f5153b728?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`999e56b`)](https://app.codecov.io/gh/scverse/scanpy/pull/2994?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2994 +/- ##; ==========================================; - Coverage 75.51% 75.50% -0.01% ; ==========================================; Files 117 117 ; Lines 12955 12944 -11 ; ==========================================; - Hits 9783 9774 -9 ; + Misses 3172 3170 -2 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2994?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2994?src=pr&el=tree&filepath=scanpy%2Ftesting%2F_pytest%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `89.47% <ø> (+1.23%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2994#issuecomment-2045294552:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2994#issuecomment-2045294552,2,['test'],"['testing', 'tests']"
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2995?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.17%. Comparing base [(`4642cf8`)](https://app.codecov.io/gh/scverse/scanpy/commit/4642cf8e2e51b257371792cb4fcb9611c0a81123?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`0bd8364`)](https://app.codecov.io/gh/scverse/scanpy/pull/2995?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2995 +/- ##; ==========================================; - Coverage 75.51% 73.17% -2.34% ; ==========================================; Files 117 117 ; Lines 12955 12919 -36 ; ==========================================; - Hits 9783 9454 -329 ; - Misses 3172 3465 +293 ; ```. [see 28 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2995/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2995#issuecomment-2045283811:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2995#issuecomment-2045283811,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2996?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.52%. Comparing base [(`10f4ebc`)](https://app.codecov.io/gh/scverse/scanpy/commit/10f4ebc7c0ee834897ce8586ffe717e80f78ba58?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`ed228fc`)](https://app.codecov.io/gh/scverse/scanpy/pull/2996?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2996 +/- ##; =======================================; Coverage 75.52% 75.52% ; =======================================; Files 117 117 ; Lines 12951 12951 ; =======================================; Hits 9781 9781 ; Misses 3170 3170 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2996#issuecomment-2045442863:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2996#issuecomment-2045442863,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2997?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.50%. Comparing base [(`6eb6263`)](https://app.codecov.io/gh/scverse/scanpy/commit/6eb62635ddf1fb8c0dee7d3d63880d1c21d7c195?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`01c119a`)](https://app.codecov.io/gh/scverse/scanpy/pull/2997?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2997 +/- ##; ==========================================; - Coverage 75.51% 75.50% -0.01% ; ==========================================; Files 117 117 ; Lines 12955 12944 -11 ; ==========================================; - Hits 9783 9774 -9 ; + Misses 3172 3170 -2 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2997?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2997?src=pr&el=tree&filepath=scanpy%2Ftesting%2F_pytest%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `89.47% <ø> (+1.23%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2997#issuecomment-2045725652:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2997#issuecomment-2045725652,2,['test'],"['testing', 'tests']"
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2999?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.51%. Comparing base [(`2c2cd50`)](https://app.codecov.io/gh/scverse/scanpy/commit/2c2cd50213e250559944e7643b0c71b2b5c40807?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`037b67c`)](https://app.codecov.io/gh/scverse/scanpy/pull/2999?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). > :exclamation: Current head 037b67c differs from pull request most recent head 54332dc. Consider uploading reports for the commit 54332dc to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2999 +/- ##; =======================================; Coverage 75.50% 75.51% ; =======================================; Files 117 117 ; Lines 12944 12946 +2 ; =======================================; + Hits 9774 9776 +2 ; Misses 3170 3170 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2999?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/experimental/pp/\_normalization.py](https://app.codecov.io/gh/scverse/scanpy/pull/2999?src=pr&el=tree&filepath=scanpy%2Fexperimental%2Fpp%2F_normalization.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4cGVyaW1lbnRhbC9wcC9fbm9ybWFsaXphdGlvbi5weQ==) | `95.06% <100.00%> (ø)` | |; | [scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/2999?src=pr&el=tree&filepath=scanpy%2Fplotting%2F_a,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2999#issuecomment-2047535059:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999#issuecomment-2047535059,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3000?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.52%. Comparing base [(`303798a`)](https://app.codecov.io/gh/scverse/scanpy/commit/303798a715ac9a9332e211e9e2c393de108e2cb1?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`e74d3a2`)](https://app.codecov.io/gh/scverse/scanpy/pull/3000?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3000 +/- ##; ==========================================; + Coverage 75.50% 75.52% +0.01% ; ==========================================; Files 117 117 ; Lines 12944 12951 +7 ; ==========================================; + Hits 9774 9781 +7 ; Misses 3170 3170 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3000?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/experimental/pp/\_normalization.py](https://app.codecov.io/gh/scverse/scanpy/pull/3000?src=pr&el=tree&filepath=scanpy%2Fexperimental%2Fpp%2F_normalization.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4cGVyaW1lbnRhbC9wcC9fbm9ybWFsaXphdGlvbi5weQ==) | `95.06% <100.00%> (ø)` | |; | [scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3000?src=pr&el=tree&filepath=scanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19hbm5kYXRhLn,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3000#issuecomment-2047693389:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3000#issuecomment-2047693389,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3001?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.17%. Comparing base [(`496bbb6`)](https://app.codecov.io/gh/scverse/scanpy/commit/496bbb6e32a1f54944aa49835ac094763c937492?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`06516be`)](https://app.codecov.io/gh/scverse/scanpy/pull/3001?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3001 +/- ##; ==========================================; - Coverage 75.52% 73.17% -2.35% ; ==========================================; Files 117 117 ; Lines 12951 12915 -36 ; ==========================================; - Hits 9781 9451 -330 ; - Misses 3170 3464 +294 ; ```. [see 29 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3001/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3001#issuecomment-2050304023:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3001#issuecomment-2050304023,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3002?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.17%. Comparing base [(`b5bff91`)](https://app.codecov.io/gh/scverse/scanpy/commit/b5bff91ff28a72ea12873f82edfa753a2e95d43e?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`63a34aa`)](https://app.codecov.io/gh/scverse/scanpy/pull/3002?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3002 +/- ##; ==========================================; - Coverage 75.52% 73.17% -2.35% ; ==========================================; Files 117 117 ; Lines 12951 12915 -36 ; ==========================================; - Hits 9781 9451 -330 ; - Misses 3170 3464 +294 ; ```. [see 29 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3002/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3002#issuecomment-2050321617:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3002#issuecomment-2050321617,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3003?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.52%. Comparing base [(`5762139`)](https://app.codecov.io/gh/scverse/scanpy/commit/5762139fbadba7f208f4066af92db03579597f61?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`62d0a8f`)](https://app.codecov.io/gh/scverse/scanpy/pull/3003?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3003 +/- ##; =======================================; Coverage 75.52% 75.52% ; =======================================; Files 117 117 ; Lines 12951 12951 ; =======================================; Hits 9781 9781 ; Misses 3170 3170 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3003#issuecomment-2050404062:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3003#issuecomment-2050404062,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3008?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.52%. Comparing base [(`d22ac43`)](https://app.codecov.io/gh/scverse/scanpy/commit/d22ac43e4d0a8cc473b7c37299c1c911a3603409?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`1ad2e8f`)](https://app.codecov.io/gh/scverse/scanpy/pull/3008?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3008 +/- ##; =======================================; Coverage 75.52% 75.52% ; =======================================; Files 117 117 ; Lines 12951 12951 ; =======================================; Hits 9781 9781 ; Misses 3170 3170 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3008#issuecomment-2057533919:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3008#issuecomment-2057533919,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3009?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.17%. Comparing base [(`a9855b9`)](https://app.codecov.io/gh/scverse/scanpy/commit/a9855b916a5144770019b15e7deacfc4f3133039?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`9eeb055`)](https://app.codecov.io/gh/scverse/scanpy/pull/3009?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3009 +/- ##; ==========================================; - Coverage 75.52% 73.17% -2.35% ; ==========================================; Files 117 117 ; Lines 12951 12915 -36 ; ==========================================; - Hits 9781 9451 -330 ; - Misses 3170 3464 +294 ; ```. [see 29 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3009/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3009#issuecomment-2057673710:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3009#issuecomment-2057673710,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3015?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.27%. Comparing base [(`ee8505b`)](https://app.codecov.io/gh/scverse/scanpy/commit/ee8505b1c1578af0c50defdb3cf64ec18713669e?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d982936`)](https://app.codecov.io/gh/scverse/scanpy/pull/3015?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3015 +/- ##; ==========================================; + Coverage 75.53% 76.27% +0.74% ; ==========================================; Files 117 117 ; Lines 12950 12795 -155 ; ==========================================; - Hits 9782 9760 -22 ; + Misses 3168 3035 -133 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3015?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3015?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3V0aWxzLnB5) | `97.36% <100.00%> (+42.70%)` | :arrow_up: |. ... and [4 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3015/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3015#issuecomment-2066105796:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3015#issuecomment-2066105796,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3020?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.53%. Comparing base [(`443f76c`)](https://app.codecov.io/gh/scverse/scanpy/commit/443f76c5defe7932b0b1132b35a57f42fed8fbbb?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`21e2a45`)](https://app.codecov.io/gh/scverse/scanpy/pull/3020?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3020 +/- ##; =======================================; Coverage 75.53% 75.53% ; =======================================; Files 117 117 ; Lines 12950 12950 ; =======================================; Hits 9782 9782 ; Misses 3168 3168 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3020#issuecomment-2069636460:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3020#issuecomment-2069636460,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3022?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.53%. Comparing base [(`dbea062`)](https://app.codecov.io/gh/scverse/scanpy/commit/dbea0620036d79224f4fc09899cf26e3fdec462d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`5d98942`)](https://app.codecov.io/gh/scverse/scanpy/pull/3022?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3022 +/- ##; =======================================; Coverage 75.53% 75.53% ; =======================================; Files 117 117 ; Lines 12950 12950 ; =======================================; Hits 9782 9782 ; Misses 3168 3168 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3022#issuecomment-2070502233:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3022#issuecomment-2070502233,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3023?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.19%. Comparing base [(`b12a8b7`)](https://app.codecov.io/gh/scverse/scanpy/commit/b12a8b70ed7a431e6f5d20e1923034cca0585cf0?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d3c7dfd`)](https://app.codecov.io/gh/scverse/scanpy/pull/3023?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3023 +/- ##; ==========================================; - Coverage 75.53% 73.19% -2.35% ; ==========================================; Files 117 117 ; Lines 12950 12914 -36 ; ==========================================; - Hits 9782 9452 -330 ; - Misses 3168 3462 +294 ; ```. [see 29 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3023/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3023#issuecomment-2071676753:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3023#issuecomment-2071676753,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3024?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.27%. Comparing base [(`73dc2d5`)](https://app.codecov.io/gh/scverse/scanpy/commit/73dc2d57f7023a56528afb1e421b300cd599ca03?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`13d6968`)](https://app.codecov.io/gh/scverse/scanpy/pull/3024?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3024 +/- ##; ==========================================; + Coverage 75.53% 76.27% +0.74% ; ==========================================; Files 117 117 ; Lines 12950 12795 -155 ; ==========================================; - Hits 9782 9760 -22 ; + Misses 3168 3035 -133 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3024?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3024?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3V0aWxzLnB5) | `97.36% <100.00%> (+42.70%)` | :arrow_up: |. ... and [4 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3024/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </det,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3024#issuecomment-2072667399:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3024#issuecomment-2072667399,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3032?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.90%. Comparing base [(`a70582e`)](https://app.codecov.io/gh/scverse/scanpy/commit/a70582ee03556cf6821eb45148560cb259a5fb34?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`cf54425`)](https://app.codecov.io/gh/scverse/scanpy/pull/3032?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3032 +/- ##; ==========================================; - Coverage 76.27% 73.90% -2.38% ; ==========================================; Files 117 117 ; Lines 12795 12759 -36 ; ==========================================; - Hits 9760 9430 -330 ; - Misses 3035 3329 +294 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3032?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/datasets/\_datasets.py](https://app.codecov.io/gh/scverse/scanpy/pull/3032?src=pr&el=tree&filepath=scanpy%2Fdatasets%2F_datasets.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2RhdGFzZXRzL19kYXRhc2V0cy5weQ==) | `86.04% <ø> (ø)` | |; | [scanpy/experimental/pp/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3032?src=pr&el=tree&filepath=scanpy%2Fexperimental%2Fpp%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4cGVyaW1lbnRhbC9w,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3032#issuecomment-2079356059:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3032#issuecomment-2079356059,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3033?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.90%. Comparing base [(`eb077e3`)](https://app.codecov.io/gh/scverse/scanpy/commit/eb077e3a89ac2b00314555e63b34c1f9d74ccd9e?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`b9099a1`)](https://app.codecov.io/gh/scverse/scanpy/pull/3033?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3033 +/- ##; ==========================================; - Coverage 76.27% 73.90% -2.38% ; ==========================================; Files 117 117 ; Lines 12795 12759 -36 ; ==========================================; - Hits 9760 9430 -330 ; - Misses 3035 3329 +294 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3033?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/datasets/\_datasets.py](https://app.codecov.io/gh/scverse/scanpy/pull/3033?src=pr&el=tree&filepath=scanpy%2Fdatasets%2F_datasets.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2RhdGFzZXRzL19kYXRhc2V0cy5weQ==) | `86.04% <ø> (ø)` | |; | [scanpy/experimental/pp/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3033?src=pr&el=tree&filepath=scanpy%2Fexperimental%2Fpp%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4cGVyaW1lbnRhbC,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3033#issuecomment-2079679321:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3033#issuecomment-2079679321,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3034?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.90%. Comparing base [(`fd48fa0`)](https://app.codecov.io/gh/scverse/scanpy/commit/fd48fa0ea3b7eaa7f7829cda7603d2f13eaa54f0?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`2239aa7`)](https://app.codecov.io/gh/scverse/scanpy/pull/3034?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3034 +/- ##; ==========================================; - Coverage 76.27% 73.90% -2.38% ; ==========================================; Files 117 117 ; Lines 12795 12759 -36 ; ==========================================; - Hits 9760 9430 -330 ; - Misses 3035 3329 +294 ; ```. [see 29 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3034/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3034#issuecomment-2082811822:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034#issuecomment-2082811822,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3035?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.27%. Comparing base [(`fd48fa0`)](https://app.codecov.io/gh/scverse/scanpy/commit/fd48fa0ea3b7eaa7f7829cda7603d2f13eaa54f0?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`43c5a22`)](https://app.codecov.io/gh/scverse/scanpy/pull/3035?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3035 +/- ##; =======================================; Coverage 76.27% 76.27% ; =======================================; Files 117 117 ; Lines 12795 12795 ; =======================================; Hits 9760 9760 ; Misses 3035 3035 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3035#issuecomment-2082829092:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3035#issuecomment-2082829092,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3036?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.27%. Comparing base [(`38818ac`)](https://app.codecov.io/gh/scverse/scanpy/commit/38818acad9cbad95d794b337d28de64c388e9982?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`75082dd`)](https://app.codecov.io/gh/scverse/scanpy/pull/3036?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3036 +/- ##; =======================================; Coverage 76.27% 76.27% ; =======================================; Files 117 117 ; Lines 12795 12795 ; =======================================; Hits 9760 9760 ; Misses 3035 3035 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3036#issuecomment-2082875855:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3036#issuecomment-2082875855,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3037?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.90%. Comparing base [(`e1cf0fa`)](https://app.codecov.io/gh/scverse/scanpy/commit/e1cf0fa9b7bacc220dcb7a06ce5e0f9ccca10a32?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`196a7a0`)](https://app.codecov.io/gh/scverse/scanpy/pull/3037?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3037 +/- ##; ==========================================; - Coverage 76.27% 73.90% -2.38% ; ==========================================; Files 117 117 ; Lines 12795 12759 -36 ; ==========================================; - Hits 9760 9430 -330 ; - Misses 3035 3329 +294 ; ```. [see 29 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3037/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3037#issuecomment-2083184227:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3037#issuecomment-2083184227,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3040?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.90%. Comparing base [(`c3cfa74`)](https://app.codecov.io/gh/scverse/scanpy/commit/c3cfa74b1316d780568411175316cd9f139efb22?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`37c57d9`)](https://app.codecov.io/gh/scverse/scanpy/pull/3040?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3040 +/- ##; ==========================================; - Coverage 76.27% 73.90% -2.38% ; ==========================================; Files 117 117 ; Lines 12795 12759 -36 ; ==========================================; - Hits 9760 9430 -330 ; - Misses 3035 3329 +294 ; ```. [see 29 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3040/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3040#issuecomment-2085014090:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3040#issuecomment-2085014090,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3041?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.88%. Comparing base [(`8d046ff`)](https://app.codecov.io/gh/scverse/scanpy/commit/8d046ff37e024ae88eadfb22ea8fd142a6b95aa1?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d9877c9`)](https://app.codecov.io/gh/scverse/scanpy/commit/d9877c996b655a236f14fc242717a637365cd7d8?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3041 +/- ##; ==========================================; + Coverage 75.87% 75.88% +0.01% ; ==========================================; Files 110 110 ; Lines 12536 12542 +6 ; ==========================================; + Hits 9512 9518 +6 ; Misses 3024 3024 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3041?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3041?src=pr&el=tree&filepath=scanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `75.41% <100.00%> (+0.31%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3041#issuecomment-2085184960:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041#issuecomment-2085184960,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3042?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`896e249`)](https://app.codecov.io/gh/scverse/scanpy/commit/896e24906edd8a6f03c97c590838ca20b3f1d127?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`13b1f6c`)](https://app.codecov.io/gh/scverse/scanpy/commit/13b1f6c3dae78ee038b66535993415bf7eaf66a1?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 50 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3042 +/- ##; =======================================; Coverage 76.31% 76.31% ; =======================================; Files 109 109 ; Lines 12513 12515 +2 ; =======================================; + Hits 9549 9551 +2 ; Misses 2964 2964 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3042?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3042?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19oaWdobHlfdmFyaWFibGVfZ2VuZXMucHk=) | `95.23% <100.00%> (+0.03%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3042#issuecomment-2090681654:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042#issuecomment-2090681654,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3045?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.98%. Comparing base [(`0d4554b`)](https://app.codecov.io/gh/scverse/scanpy/commit/0d4554b44e301c9c1e78e80e21b5e4a6642e156a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`32e944b`)](https://app.codecov.io/gh/scverse/scanpy/pull/3045?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3045 +/- ##; ==========================================; - Coverage 76.27% 73.98% -2.30% ; ==========================================; Files 117 117 ; Lines 12795 12795 ; ==========================================; - Hits 9760 9466 -294 ; - Misses 3035 3329 +294 ; ```. [see 26 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3045/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3045#issuecomment-2096614640:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3045#issuecomment-2096614640,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3046?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.90%. Comparing base [(`dbe902e`)](https://app.codecov.io/gh/scverse/scanpy/commit/dbe902ea2c1fbbfa337a5a2eae0c698cafb6f43d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`66ab7cc`)](https://app.codecov.io/gh/scverse/scanpy/pull/3046?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3046 +/- ##; ==========================================; - Coverage 76.27% 73.90% -2.38% ; ==========================================; Files 117 117 ; Lines 12799 12763 -36 ; ==========================================; - Hits 9763 9433 -330 ; - Misses 3036 3330 +294 ; ```. [see 29 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3046/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3046#issuecomment-2097676744:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3046#issuecomment-2097676744,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3048?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.87%. Comparing base [(`23c20bc`)](https://app.codecov.io/gh/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`b0ca228`)](https://app.codecov.io/gh/scverse/scanpy/commit/b0ca228156a621e6f8144fb9b751303b81e67757?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 47 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3048 +/- ##; ==========================================; + Coverage 75.80% 75.87% +0.06% ; ==========================================; Files 110 110 ; Lines 12502 12533 +31 ; ==========================================; + Hits 9477 9509 +32 ; + Misses 3025 3024 -1 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3048?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3048?src=pr&el=tree&filepath=scanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `75.05% <100.00%> (+0.48%)` | :arrow_up: |; | [scanpy/preprocessing/\_pca.py](https://app.codecov.io/gh/scverse/scanpy/pull/3048?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_pca.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_t,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2100465428:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2100465428,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3053?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.27%. Comparing base [(`d2a5368`)](https://app.codecov.io/gh/scverse/scanpy/commit/d2a53680e312835b998077b4e25b254e98bcb5ba?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d212a6b`)](https://app.codecov.io/gh/scverse/scanpy/pull/3053?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3053 +/- ##; =======================================; Coverage 76.27% 76.27% ; =======================================; Files 117 117 ; Lines 12799 12799 ; =======================================; Hits 9763 9763 ; Misses 3036 3036 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3053#issuecomment-2108477823:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3053#issuecomment-2108477823,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3055?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.95%. Comparing base [(`6232816`)](https://app.codecov.io/gh/scverse/scanpy/commit/62328169ea640a578fa7a036a68214fd29bfd51e?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d67bd5a`)](https://app.codecov.io/gh/scverse/scanpy/pull/3055?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3055 +/- ##; ==========================================; - Coverage 76.27% 75.95% -0.33% ; ==========================================; Files 117 117 ; Lines 12799 12799 ; ==========================================; - Hits 9763 9722 -41 ; - Misses 3036 3077 +41 ; ```. [see 1 file with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3055/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3055#issuecomment-2109649240:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3055#issuecomment-2109649240,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3057?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.85%. Comparing base [(`c26480e`)](https://app.codecov.io/gh/scverse/scanpy/commit/c26480ed0dc2f7d27b796e0e355b29a8305886c6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`b1fbd98`)](https://app.codecov.io/gh/scverse/scanpy/pull/3057?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3057 +/- ##; ==========================================; - Coverage 76.27% 75.85% -0.43% ; ==========================================; Files 117 110 -7 ; Lines 12803 12529 -274 ; ==========================================; - Hits 9766 9504 -262 ; + Misses 3037 3025 -12 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3057?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_doctests.py](https://app.codecov.io/gh/scverse/scanpy/pull/3057?src=pr&el=tree&filepath=scanpy%2F_utils%2F_doctests.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fZG9jdGVzdHMucHk=) | `93.75% <ø> (ø)` | |; | [scanpy/external/pl.py](https://app.codecov.io/gh/scverse/scanpy/pull/3057?src=pr&el=tree&filepath=scanpy%2Fexternal%2Fpl.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3BsLnB5) | `32.63% <100.00,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3057#issuecomment-2110161647:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057#issuecomment-2110161647,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3059?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 73.47%. Comparing base [(`3d0cd15`)](https://app.codecov.io/gh/scverse/scanpy/commit/3d0cd15a006e35d83622ca812c85ba326bd40f3c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6a52edc`)](https://app.codecov.io/gh/scverse/scanpy/pull/3059?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3059 +/- ##; ==========================================; - Coverage 76.28% 73.47% -2.82% ; ==========================================; Files 117 110 -7 ; Lines 12802 12493 -309 ; ==========================================; - Hits 9766 9179 -587 ; - Misses 3036 3314 +278 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3059?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_doctests.py](https://app.codecov.io/gh/scverse/scanpy/pull/3059?src=pr&el=tree&filepath=scanpy%2F_utils%2F_doctests.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fZG9jdGVzdHMucHk=) | `93.75% <ø> (ø)` | |; | [scanpy/external/pl.py](https://app.codecov.io/gh/scverse/scanpy/pull/3059?src=pr&el=tree&filepath=scanpy%2Fexternal%2Fpl.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3BsLnB5) | `32.63% <100.00%> (ø)` | |; | [scanpy/external/pp/\_bbkn,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3059#issuecomment-2110419057:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3059#issuecomment-2110419057,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3060?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.35%. Comparing base [(`8d046ff`)](https://app.codecov.io/gh/scverse/scanpy/commit/8d046ff37e024ae88eadfb22ea8fd142a6b95aa1?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`0cb201f`)](https://app.codecov.io/gh/scverse/scanpy/commit/0cb201f9876b2212e49ebb3198d481db9869cabe?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). > :exclamation: **Current head 0cb201f differs from pull request most recent head 0caa293**; > ; > Please [upload](https://docs.codecov.com/docs/codecov-uploader) reports for the commit 0caa293 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3060 +/- ##; ==========================================; + Coverage 75.87% 76.35% +0.47% ; ==========================================; Files 110 110 ; Lines 12536 12545 +9 ; ==========================================; + Hits 9512 9579 +67 ; + Misses 3024 2966 -58 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3060?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_doctests.py](https://app.codecov.io/gh/scverse/scanpy/pull/3060?src=pr&el=tree&filepath=scanpy%2F_utils%2F_doctests.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fZG9jdGVzdHMucHk=) | `94.73% <100.00%> (+0.98%)` | :arrow_up: |; | [scanpy/datasets/\_datasets.py](https://app.codeco,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3060#issuecomment-2110535233:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060#issuecomment-2110535233,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3064?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.80%. Comparing base [(`cc26569`)](https://app.codecov.io/gh/scverse/scanpy/commit/cc2656957202d5c649a059cd147d2dd58517c2e0?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6af8e44`)](https://app.codecov.io/gh/scverse/scanpy/commit/6af8e442a1819cb341f177ae7e32cb9964bd01db?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 48 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3064 +/- ##; ==========================================; - Coverage 75.85% 75.80% -0.06% ; ==========================================; Files 110 110 ; Lines 12529 12502 -27 ; ==========================================; - Hits 9504 9477 -27 ; Misses 3025 3025 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3064?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_settings.py](https://app.codecov.io/gh/scverse/scanpy/pull/3064?src=pr&el=tree&filepath=scanpy%2F_settings.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L19zZXR0aW5ncy5weQ==) | `90.20% <100.00%> (-0.04%)` | :arrow_down: |; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3064?src=pr&el=tree&filepath=scanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dG,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3064#issuecomment-2115202773:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3064#issuecomment-2115202773,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3065?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.85%. Comparing base [(`8fe4c3a`)](https://app.codecov.io/gh/scverse/scanpy/commit/8fe4c3a32bb931d1b5760e3982f03cae805bd88c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`5f796b5`)](https://app.codecov.io/gh/scverse/scanpy/pull/3065?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3065 +/- ##; =======================================; Coverage 75.85% 75.85% ; =======================================; Files 110 110 ; Lines 12529 12529 ; =======================================; Hits 9504 9504 ; Misses 3025 3025 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3065?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/experimental/\_docs.py](https://app.codecov.io/gh/scverse/scanpy/pull/3065?src=pr&el=tree&filepath=scanpy%2Fexperimental%2F_docs.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4cGVyaW1lbnRhbC9fZG9jcy5weQ==) | `100.00% <ø> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3065?src=pr&el=tree&filepath=scanpy%2Fplotting%2F_tools%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `77.28% <100.00%> (ø)` | |. </details,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3065#issuecomment-2117154655:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3065#issuecomment-2117154655,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3066?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.85%. Comparing base [(`8ba0023`)](https://app.codecov.io/gh/scverse/scanpy/commit/8ba00230285541e7a4ac569f8edf81275d731cc0?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6897a2a`)](https://app.codecov.io/gh/scverse/scanpy/commit/6897a2a42847fd13179fd487d002209a59d5053d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 41 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3066 +/- ##; =======================================; Coverage 75.85% 75.85% ; =======================================; Files 110 110 ; Lines 12529 12529 ; =======================================; Hits 9504 9504 ; Misses 3025 3025 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3066?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/experimental/\_docs.py](https://app.codecov.io/gh/scverse/scanpy/pull/3066?src=pr&el=tree&filepath=scanpy%2Fexperimental%2F_docs.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4cGVyaW1lbnRhbC9fZG9jcy5weQ==) | `100.00% <ø> (ø)` | |; | [scanpy/plotting/\_docs.py](https://app.codecov.io/gh/scverse/scanpy/pull/3066?src=pr&el=tree&filepath=scanpy%2Fplotting%2F_docs.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19kb2NzLnB5) |,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3066#issuecomment-2117197724:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3066#issuecomment-2117197724,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3067?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.80%. Comparing base [(`698313b`)](https://app.codecov.io/gh/scverse/scanpy/commit/698313b5f38ed726c5b8093c155482d1bfdaf4bc?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`38369c0`)](https://app.codecov.io/gh/scverse/scanpy/commit/38369c0ba7e55f4e266f950f4a971829e436f1a2?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 40 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3067 +/- ##; ==========================================; - Coverage 75.85% 75.80% -0.06% ; ==========================================; Files 110 110 ; Lines 12529 12502 -27 ; ==========================================; - Hits 9504 9477 -27 ; Misses 3025 3025 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3067?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_settings.py](https://app.codecov.io/gh/scverse/scanpy/pull/3067?src=pr&el=tree&filepath=scanpy%2F_settings.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L19zZXR0aW5ncy5weQ==) | `90.20% <100.00%> (-0.04%)` | :arrow_down: |; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3067?src=pr&el=tree&filepath=scanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3067#issuecomment-2291142936:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3067#issuecomment-2291142936,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3069?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.73%. Comparing base [(`78b738b`)](https://app.codecov.io/gh/scverse/scanpy/commit/78b738bdf8c3521f2bb8ccd2e386ec9bf69481c2?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`9c1a28c`)](https://app.codecov.io/gh/scverse/scanpy/commit/9c1a28ce04907d3eb9bc9f27dac030a6dd4a83ae?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 5 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3069 +/- ##; =======================================; Coverage 76.73% 76.73% ; =======================================; Files 109 109 ; Lines 12529 12529 ; =======================================; Hits 9614 9614 ; Misses 2915 2915 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3069#issuecomment-2117802554:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069#issuecomment-2117802554,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3072?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.87%. Comparing base [(`b3b9d05`)](https://app.codecov.io/gh/scverse/scanpy/commit/b3b9d0576897a8da5a4ae765b4b0b5609cebc890?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`0948c80`)](https://app.codecov.io/gh/scverse/scanpy/commit/0948c80e31e755089b05344e2d0cf9762491bccf?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 39 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3072 +/- ##; ==========================================; + Coverage 75.80% 75.87% +0.07% ; ==========================================; Files 110 110 ; Lines 12500 12532 +32 ; ==========================================; + Hits 9475 9509 +34 ; + Misses 3025 3023 -2 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3072?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3072?src=pr&el=tree&filepath=scanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `75.10% <100.00%> (+0.53%)` | :arrow_up: |; | [scanpy/preprocessing/\_pca.py](https://app.codecov.io/gh/scverse/scanpy/pull/3072?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_pca.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_cam,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3072#issuecomment-2122076190:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3072#issuecomment-2122076190,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3075?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.86%. Comparing base [(`a20334f`)](https://app.codecov.io/gh/scverse/scanpy/commit/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3a84581`)](https://app.codecov.io/gh/scverse/scanpy/commit/3a8458176205c474ed494a644c423db76338c20e?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3075 +/- ##; =======================================; Coverage 75.86% 75.86% ; =======================================; Files 110 110 ; Lines 12531 12531 ; =======================================; Hits 9507 9507 ; Misses 3024 3024 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3075?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_ingest.py](https://app.codecov.io/gh/scverse/scanpy/pull/3075?src=pr&el=tree&filepath=scanpy%2Ftools%2F_ingest.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19pbmdlc3QucHk=) | `77.33% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3075#issuecomment-2125125263:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3075#issuecomment-2125125263,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3076?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.87%. Comparing base [(`3ba3f46`)](https://app.codecov.io/gh/scverse/scanpy/commit/3ba3f46b4e6e77e8c6f0551db9663822097b486a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`10c4e0e`)](https://app.codecov.io/gh/scverse/scanpy/pull/3076?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3076 +/- ##; =======================================; Coverage 75.87% 75.87% ; =======================================; Files 110 110 ; Lines 12533 12533 ; =======================================; Hits 9509 9509 ; Misses 3024 3024 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3076?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3076?src=pr&el=tree&filepath=scanpy%2Fplotting%2F_tools%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `77.28% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3076#issuecomment-2125533947:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3076#issuecomment-2125533947,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3078?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.86%. Comparing base [(`3ba3f46`)](https://app.codecov.io/gh/scverse/scanpy/commit/3ba3f46b4e6e77e8c6f0551db9663822097b486a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`30bcef4`)](https://app.codecov.io/gh/scverse/scanpy/commit/30bcef491e349c9ef1e2c6c08626836b6668dc04?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 47 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3078 +/- ##; ==========================================; - Coverage 75.87% 75.86% -0.01% ; ==========================================; Files 110 110 ; Lines 12533 12531 -2 ; ==========================================; - Hits 9509 9507 -2 ; Misses 3024 3024 ; ```. [see 2 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3078/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3078#issuecomment-2133897573:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3078#issuecomment-2133897573,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3079?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.86%. Comparing base [(`874d99b`)](https://app.codecov.io/gh/scverse/scanpy/commit/874d99b3fae696427b9fa2c6ec870cc5fb28e9c1?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`26173ed`)](https://app.codecov.io/gh/scverse/scanpy/commit/26173edb6845bee8c642e66dfd27f959f2dcd134?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 45 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3079 +/- ##; =======================================; Coverage 75.85% 75.86% ; =======================================; Files 110 110 ; Lines 12531 12532 +1 ; =======================================; + Hits 9506 9507 +1 ; Misses 3025 3025 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3079?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3079?src=pr&el=tree&filepath=scanpy%2Ftools%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL191dGlscy5weQ==) | `70.00% <100.00%> (+0.37%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3079#issuecomment-2135593503:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3079#issuecomment-2135593503,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3089?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.88%. Comparing base [(`874d99b`)](https://app.codecov.io/gh/scverse/scanpy/commit/874d99b3fae696427b9fa2c6ec870cc5fb28e9c1?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`9fe6555`)](https://app.codecov.io/gh/scverse/scanpy/commit/9fe65556ce87f50dac5388caab83db45571b7945?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 45 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3089 +/- ##; ==========================================; + Coverage 75.85% 75.88% +0.02% ; ==========================================; Files 110 110 ; Lines 12531 12555 +24 ; ==========================================; + Hits 9506 9527 +21 ; - Misses 3025 3028 +3 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3089?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3089?src=pr&el=tree&filepath=scanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `75.10% <100.00%> (+0.05%)` | :arrow_up: |. ... and [2 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3089/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3089#issuecomment-2144834846:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3089#issuecomment-2144834846,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3090?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.80%. Comparing base [(`b3b9d05`)](https://app.codecov.io/gh/scverse/scanpy/commit/b3b9d0576897a8da5a4ae765b4b0b5609cebc890?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`ef7a0b5`)](https://app.codecov.io/gh/scverse/scanpy/commit/ef7a0b56ce149fab269982ddb74d586a3f45bafd?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 39 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3090 +/- ##; =======================================; Coverage 75.80% 75.80% ; =======================================; Files 110 110 ; Lines 12500 12501 +1 ; =======================================; + Hits 9475 9477 +2 ; + Misses 3025 3024 -1 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3090?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3090?src=pr&el=tree&filepath=scanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `74.62% <100.00%> (+0.05%)` | :arrow_up: |. ... and [1 file with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3090/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3090#issuecomment-2145017693:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3090#issuecomment-2145017693,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3091?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.80%. Comparing base [(`b3b9d05`)](https://app.codecov.io/gh/scverse/scanpy/commit/b3b9d0576897a8da5a4ae765b4b0b5609cebc890?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`76007e5`)](https://app.codecov.io/gh/scverse/scanpy/commit/76007e5f12e07f2f5b5b13fdb812ad3d7de3c60e?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 39 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3091 +/- ##; =======================================; Coverage 75.80% 75.80% ; =======================================; Files 110 110 ; Lines 12500 12503 +3 ; =======================================; + Hits 9475 9478 +3 ; Misses 3025 3025 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3091?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/logging.py](https://app.codecov.io/gh/scverse/scanpy/pull/3091?src=pr&el=tree&filepath=scanpy%2Flogging.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `95.86% <ø> (ø)` | |; | [scanpy/plotting/\_docs.py](https://app.codecov.io/gh/scverse/scanpy/pull/3091?src=pr&el=tree&filepath=scanpy%2Fplotting%2F_docs.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19kb2NzLnB5) | `100.00% <100.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3091#issuecomment-2145058855:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3091#issuecomment-2145058855,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3092?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`5d5d873`)](https://app.codecov.io/gh/scverse/scanpy/commit/5d5d873b1fb0353089569f85580b43437df9c6cd?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d1bfb13`)](https://app.codecov.io/gh/scverse/scanpy/commit/d1bfb139e08410692410197d462995e3ce4ba7ba?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 39 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3092 +/- ##; ==========================================; - Coverage 76.40% 76.31% -0.10% ; ==========================================; Files 110 109 -1 ; Lines 12543 12515 -28 ; ==========================================; - Hits 9584 9551 -33 ; - Misses 2959 2964 +5 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3092?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/\_\_main\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3092?src=pr&el=tree&filepath=src%2Fscanpy%2F__main__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fX21haW5fXy5weQ==) | `0.00% <ø> (ø)` | |; | [src/scanpy/\_compat.py](https://app.codecov.io/gh/scverse/scanpy/pull/3092?src=pr&el=tree&filepath=src%2Fscanpy%2F_compat.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjY,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3092#issuecomment-2145299708:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3092#issuecomment-2145299708,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3093?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 75.87%. Comparing base [(`de38381`)](https://app.codecov.io/gh/scverse/scanpy/commit/de38381211d7f5881b83ab34169d54aa4b884f6b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`63f4514`)](https://app.codecov.io/gh/scverse/scanpy/commit/63f451446282f407a4611728190fc8a5fc2ff293?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 42 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3093 +/- ##; =======================================; Coverage 75.87% 75.87% ; =======================================; Files 110 110 ; Lines 12536 12536 ; =======================================; Hits 9512 9512 ; Misses 3024 3024 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3093#issuecomment-2145832840:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3093#issuecomment-2145832840,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3094?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.33%. Comparing base [(`0f9ff18`)](https://app.codecov.io/gh/scverse/scanpy/commit/0f9ff18a80559dececcd7cdae6bb8d676d76a18b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3168692`)](https://app.codecov.io/gh/scverse/scanpy/commit/316869258dfa793142fc0c818df9148afaab909f?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 36 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3094 +/- ##; ==========================================; + Coverage 75.87% 76.33% +0.46% ; ==========================================; Files 110 110 ; Lines 12535 12544 +9 ; ==========================================; + Hits 9511 9576 +65 ; + Misses 3024 2968 -56 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3094?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_doctests.py](https://app.codecov.io/gh/scverse/scanpy/pull/3094?src=pr&el=tree&filepath=scanpy%2F_utils%2F_doctests.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fZG9jdGVzdHMucHk=) | `94.73% <100.00%> (+0.98%)` | :arrow_up: |; | [scanpy/datasets/\_datasets.py](https://app.codecov.io/gh/scverse/scanpy/pull/3094?src=pr&el=tree&filepath=scanpy%2Fdatasets%2F_datasets.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_camp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3094#issuecomment-2147614845:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3094#issuecomment-2147614845,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3099?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`896e249`)](https://app.codecov.io/gh/scverse/scanpy/commit/896e24906edd8a6f03c97c590838ca20b3f1d127?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7a1a62e`)](https://app.codecov.io/gh/scverse/scanpy/commit/7a1a62ec8f9a0f13fdc8952ff946ce12102542a3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3099 +/- ##; ==========================================; - Coverage 76.31% 76.31% -0.01% ; ==========================================; Files 109 109 ; Lines 12513 12516 +3 ; ==========================================; + Hits 9549 9551 +2 ; - Misses 2964 2965 +1 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3099?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3099?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL191dGlscy5weQ==) | `95.12% <100.00%> (-2.25%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3099#issuecomment-2149373126:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099#issuecomment-2149373126,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3100?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`126d730`)](https://app.codecov.io/gh/scverse/scanpy/commit/126d7305fbf1150b1eeb13a53be5f3d9abf7ed14?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`ec30620`)](https://app.codecov.io/gh/scverse/scanpy/commit/ec306202e7228e914bb4a5865965e958459de01c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 39 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3100 +/- ##; ==========================================; - Coverage 76.31% 76.31% -0.01% ; ==========================================; Files 109 109 ; Lines 12514 12513 -1 ; ==========================================; - Hits 9550 9549 -1 ; Misses 2964 2964 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3100?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_scale.py](https://app.codecov.io/gh/scverse/scanpy/pull/3100?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_scale.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zY2FsZS5weQ==) | `91.89% <100.00%> (-0.08%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3100#issuecomment-2150068804:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100#issuecomment-2150068804,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3101?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`f03d4f4`)](https://app.codecov.io/gh/scverse/scanpy/commit/f03d4f40594a1f1b3216212dc60273c809882a4c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`274a197`)](https://app.codecov.io/gh/scverse/scanpy/commit/274a1975a3c422a404406419f6d28cba7c5b3eec?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 40 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3101 +/- ##; ==========================================; - Coverage 76.31% 76.31% -0.01% ; ==========================================; Files 109 109 ; Lines 12515 12514 -1 ; ==========================================; - Hits 9551 9550 -1 ; Misses 2964 2964 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3101?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/plotting/\_baseplot\_class.py](https://app.codecov.io/gh/scverse/scanpy/pull/3101?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_baseplot_class.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYmFzZXBsb3RfY2xhc3MucHk=) | `89.91% <100.00%> (ø)` | |; | [src/scanpy/plotting/\_dotplot.py](https://app.codecov.io/gh/scverse/scanpy/pull/3101?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_dotplot.py&utm_medium=referral&utm_source=github&utm_c,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3101#issuecomment-2152323292:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3101#issuecomment-2152323292,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3104?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.35%. Comparing base [(`706d4ef`)](https://app.codecov.io/gh/scverse/scanpy/commit/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`0cb0687`)](https://app.codecov.io/gh/scverse/scanpy/commit/0cb068756f143f10f9466c378c006f2fdece3ebf?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 40 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3104 +/- ##; =======================================; Coverage 76.35% 76.35% ; =======================================; Files 110 110 ; Lines 12543 12543 ; =======================================; Hits 9577 9577 ; Misses 2966 2966 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3104#issuecomment-2160072533:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3104#issuecomment-2160072533,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3105?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`41f613c`)](https://app.codecov.io/gh/scverse/scanpy/commit/41f613cacfd4279f07d8103d64e94523f86ac3d9?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`f3e2135`)](https://app.codecov.io/gh/scverse/scanpy/commit/f3e2135885f333599e268f9f1ccda19b5d95c1c8?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 35 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3105 +/- ##; ==========================================; - Coverage 76.35% 76.31% -0.04% ; ==========================================; Files 110 109 -1 ; Lines 12542 12514 -28 ; ==========================================; - Hits 9576 9550 -26 ; + Misses 2966 2964 -2 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3105?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/\_\_main\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3105?src=pr&el=tree&filepath=src%2Fscanpy%2F__main__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fX21haW5fXy5weQ==) | `0.00% <ø> (ø)` | |; | [src/scanpy/\_compat.py](https://app.codecov.io/gh/scverse/scanpy/pull/3105?src=pr&el=tree&filepath=src%2Fscanpy%2F_compat.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3105#issuecomment-2165828002:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3105#issuecomment-2165828002,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3107?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`48e9b84`)](https://app.codecov.io/gh/scverse/scanpy/commit/48e9b849197f9fbb20e224fbcf63ff9e27e29a61?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`cf68d1b`)](https://app.codecov.io/gh/scverse/scanpy/commit/cf68d1b3b620f27e9d019f319af737865221aa87?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 36 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3107 +/- ##; ==========================================; - Coverage 76.31% 76.31% -0.01% ; ==========================================; Files 109 109 ; Lines 12514 12513 -1 ; ==========================================; - Hits 9550 9549 -1 ; Misses 2964 2964 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3107?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/plotting/\_baseplot\_class.py](https://app.codecov.io/gh/scverse/scanpy/pull/3107?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_baseplot_class.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYmFzZXBsb3RfY2xhc3MucHk=) | `89.91% <100.00%> (ø)` | |; | [src/scanpy/plotting/\_dotplot.py](https://app.codecov.io/gh/scverse/scanpy/pull/3107?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_dotplot.py&utm_medium=referral&utm_source=github&u,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3107#issuecomment-2173019046:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3107#issuecomment-2173019046,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3108?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`48e9b84`)](https://app.codecov.io/gh/scverse/scanpy/commit/48e9b849197f9fbb20e224fbcf63ff9e27e29a61?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`ca838ab`)](https://app.codecov.io/gh/scverse/scanpy/commit/ca838ab213b26b1c3589966a286794ef5a05efe2?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 36 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3108 +/- ##; =======================================; Coverage 76.31% 76.31% ; =======================================; Files 109 109 ; Lines 12514 12515 +1 ; =======================================; + Hits 9550 9551 +1 ; Misses 2964 2964 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3108?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/tools/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3108?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fdXRpbHMucHk=) | `70.00% <100.00%> (+0.37%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3108#issuecomment-2173098494:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3108#issuecomment-2173098494,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3109?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`126d730`)](https://app.codecov.io/gh/scverse/scanpy/commit/126d7305fbf1150b1eeb13a53be5f3d9abf7ed14?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`01d06e3`)](https://app.codecov.io/gh/scverse/scanpy/commit/01d06e3cddd2d993faa747a44dd989f4caa3b29a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 39 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3109 +/- ##; =======================================; Coverage 76.31% 76.31% ; =======================================; Files 109 109 ; Lines 12514 12514 ; =======================================; Hits 9550 9550 ; Misses 2964 2964 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3109#issuecomment-2174030966:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3109#issuecomment-2174030966,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3110?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.39%. Comparing base [(`ad657ed`)](https://app.codecov.io/gh/scverse/scanpy/commit/ad657edfb52e9957b9a93b3a16fc8a87852f3f09?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`5e4df8c`)](https://app.codecov.io/gh/scverse/scanpy/commit/5e4df8c8f24f3066e5d11974793f7dba33859f3b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3110 +/- ##; ==========================================; + Coverage 76.31% 76.39% +0.08% ; ==========================================; Files 109 109 ; Lines 12513 12526 +13 ; ==========================================; + Hits 9549 9569 +20 ; + Misses 2964 2957 -7 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3110?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/3110?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zaW1wbGUucHk=) | `88.10% <100.00%> (+0.15%)` | :arrow_up: |. ... and [1 file with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3110/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </detai,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110#issuecomment-2175277166:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110#issuecomment-2175277166,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3112?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`5f2f84b`)](https://app.codecov.io/gh/scverse/scanpy/commit/5f2f84bd6b59622bbc92703fe9fec9c55e9ec5de?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`cb54e0c`)](https://app.codecov.io/gh/scverse/scanpy/commit/cb54e0c455db867cb8d85009a2021e4712de31b7?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 33 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3112 +/- ##; ==========================================; - Coverage 76.31% 76.31% -0.01% ; ==========================================; Files 109 109 ; Lines 12514 12513 -1 ; ==========================================; - Hits 9550 9549 -1 ; Misses 2964 2964 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3112?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_scale.py](https://app.codecov.io/gh/scverse/scanpy/pull/3112?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_scale.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zY2FsZS5weQ==) | `91.89% <100.00%> (-0.08%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3112#issuecomment-2175950507:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3112#issuecomment-2175950507,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3119?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`ad657ed`)](https://app.codecov.io/gh/scverse/scanpy/commit/ad657edfb52e9957b9a93b3a16fc8a87852f3f09?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`399ab4e`)](https://app.codecov.io/gh/scverse/scanpy/commit/399ab4ed7707c295e09fdab260b27408d6b07d76?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 53 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3119 +/- ##; =======================================; Coverage 76.31% 76.31% ; =======================================; Files 109 109 ; Lines 12513 12513 ; =======================================; Hits 9549 9549 ; Misses 2964 2964 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3119#issuecomment-2187150241:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3119#issuecomment-2187150241,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3121?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`ad657ed`)](https://app.codecov.io/gh/scverse/scanpy/commit/ad657edfb52e9957b9a93b3a16fc8a87852f3f09?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`1c98fd1`)](https://app.codecov.io/gh/scverse/scanpy/commit/1c98fd19522f2726fea7d69fa11959137480e489?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 50 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3121 +/- ##; =======================================; Coverage 76.31% 76.31% ; =======================================; Files 109 109 ; Lines 12513 12513 ; =======================================; Hits 9549 9549 ; Misses 2964 2964 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3121#issuecomment-2188467846:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3121#issuecomment-2188467846,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3122?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`896e249`)](https://app.codecov.io/gh/scverse/scanpy/commit/896e24906edd8a6f03c97c590838ca20b3f1d127?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`8504e62`)](https://app.codecov.io/gh/scverse/scanpy/commit/8504e62bd0f13a8934dbf54538b9bdac90a06374?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 51 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3122 +/- ##; =======================================; Coverage 76.31% 76.31% ; =======================================; Files 109 109 ; Lines 12513 12513 ; =======================================; Hits 9549 9549 ; Misses 2964 2964 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3122#issuecomment-2188488501:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3122#issuecomment-2188488501,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3123?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`27583a7`)](https://app.codecov.io/gh/scverse/scanpy/commit/27583a7d61f8013a6a307db2568b3522780c8cdc?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7cfd357`)](https://app.codecov.io/gh/scverse/scanpy/commit/7cfd35743dca866ad51b9ce2efee26265b1370cf?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 45 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3123 +/- ##; =======================================; Coverage 76.31% 76.31% ; =======================================; Files 109 109 ; Lines 12513 12513 ; =======================================; Hits 9549 9549 ; Misses 2964 2964 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3123#issuecomment-2188730936:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3123#issuecomment-2188730936,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3125?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`5cd9a44`)](https://app.codecov.io/gh/scverse/scanpy/commit/5cd9a44dd677721314eb9a603408e5464f1525ca?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`80dfaa4`)](https://app.codecov.io/gh/scverse/scanpy/commit/80dfaa459ad607c99240d166161e59a0f0025b25?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 49 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3125 +/- ##; =======================================; Coverage 76.31% 76.31% ; =======================================; Files 109 109 ; Lines 12513 12513 ; =======================================; Hits 9549 9549 ; Misses 2964 2964 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3125#issuecomment-2188822314:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3125#issuecomment-2188822314,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3126?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`551dbf9`)](https://app.codecov.io/gh/scverse/scanpy/commit/551dbf9fb20889199168439491eafe8d6231a131?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`ea7d69c`)](https://app.codecov.io/gh/scverse/scanpy/commit/ea7d69c499e6c925ad85e282ac572a72083066dd?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 44 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3126 +/- ##; =======================================; Coverage 76.31% 76.31% ; =======================================; Files 109 109 ; Lines 12513 12513 ; =======================================; Hits 9549 9549 ; Misses 2964 2964 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3126#issuecomment-2188959885:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3126#issuecomment-2188959885,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3128?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`af88467`)](https://app.codecov.io/gh/scverse/scanpy/commit/af88467bd49ef1dcdd192405bee0514123a1f748?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`21db5f9`)](https://app.codecov.io/gh/scverse/scanpy/commit/21db5f9db03cfc3a3b6560d3f71973fa32b4343c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 45 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3128 +/- ##; =======================================; Coverage 76.31% 76.31% ; =======================================; Files 109 109 ; Lines 12513 12515 +2 ; =======================================; + Hits 9549 9551 +2 ; Misses 2964 2964 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3128?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3128?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19oaWdobHlfdmFyaWFibGVfZ2VuZXMucHk=) | `95.23% <100.00%> (+0.03%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3128#issuecomment-2196445309:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3128#issuecomment-2196445309,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3131?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`8d9a5f0`)](https://app.codecov.io/gh/scverse/scanpy/commit/8d9a5f0d2b303abeb42f7e4c9252d505000fd05c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`44c69e5`)](https://app.codecov.io/gh/scverse/scanpy/commit/44c69e503ff9233c9f120214e1aead3944d75342?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3131 +/- ##; =======================================; Coverage 76.31% 76.31% ; =======================================; Files 109 109 ; Lines 12515 12515 ; =======================================; Hits 9551 9551 ; Misses 2964 2964 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3131#issuecomment-2200763736:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3131#issuecomment-2200763736,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3132?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`aabc420`)](https://app.codecov.io/gh/scverse/scanpy/commit/aabc420bfc3eaca51c09cf7f20083911a2ec7c24?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6c50262`)](https://app.codecov.io/gh/scverse/scanpy/commit/6c50262b0c4906726d80d5c6261d198badf013b6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 44 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3132 +/- ##; =======================================; Coverage 76.31% 76.31% ; =======================================; Files 109 109 ; Lines 12515 12515 ; =======================================; Hits 9551 9551 ; Misses 2964 2964 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3132#issuecomment-2202518082:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3132#issuecomment-2202518082,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3133?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.31%. Comparing base [(`a5eadd5`)](https://app.codecov.io/gh/scverse/scanpy/commit/a5eadd5b723799105d724b5e9f80b711e0be87ca?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6bcb5ae`)](https://app.codecov.io/gh/scverse/scanpy/commit/6bcb5ae570583ccec7600708a37aa27fbabb9fc0?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 43 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3133 +/- ##; =======================================; Coverage 76.31% 76.31% ; =======================================; Files 109 109 ; Lines 12515 12515 ; =======================================; Hits 9551 9551 ; Misses 2964 2964 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3133#issuecomment-2202664120:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3133#issuecomment-2202664120,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3145?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.52%. Comparing base [(`db2118e`)](https://app.codecov.io/gh/scverse/scanpy/commit/db2118e8eb60bbf6287ce1413477480e16b2508b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`67043f3`)](https://app.codecov.io/gh/scverse/scanpy/commit/67043f3a1a3ba4bb02afe94298882037f333d003?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 47 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3145 +/- ##; ==========================================; + Coverage 76.50% 76.52% +0.01% ; ==========================================; Files 109 109 ; Lines 12485 12480 -5 ; ==========================================; - Hits 9552 9550 -2 ; + Misses 2933 2930 -3 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3145?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/\_compat.py](https://app.codecov.io/gh/scverse/scanpy/pull/3145?src=pr&el=tree&filepath=src%2Fscanpy%2F_compat.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fY29tcGF0LnB5) | `77.77% <100.00%> (+3.77%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3145#issuecomment-2213534346:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3145#issuecomment-2213534346,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3147?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.52%. Comparing base [(`4269ed2`)](https://app.codecov.io/gh/scverse/scanpy/commit/4269ed23616a0e9c5a53ca25f45856e908bfb025?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`bc1d658`)](https://app.codecov.io/gh/scverse/scanpy/commit/bc1d658438873c686c942aa1770f170353b4da13?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 56 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3147 +/- ##; =======================================; Coverage 76.52% 76.52% ; =======================================; Files 109 109 ; Lines 12480 12480 ; =======================================; Hits 9550 9550 ; Misses 2930 2930 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3147#issuecomment-2213711099:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3147#issuecomment-2213711099,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3148?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.52%. Comparing base [(`0583594`)](https://app.codecov.io/gh/scverse/scanpy/commit/0583594dd4b70f5472e93bee1be2c60ccf217cea?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7212584`)](https://app.codecov.io/gh/scverse/scanpy/commit/72125841fac84fdd4e906ffd4c85c9c4dce9b949?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 46 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3148 +/- ##; =======================================; Coverage 76.52% 76.52% ; =======================================; Files 109 109 ; Lines 12480 12480 ; =======================================; Hits 9550 9550 ; Misses 2930 2930 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3148#issuecomment-2214848602:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3148#issuecomment-2214848602,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3150?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.52%. Comparing base [(`0583594`)](https://app.codecov.io/gh/scverse/scanpy/commit/0583594dd4b70f5472e93bee1be2c60ccf217cea?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`5af38e4`)](https://app.codecov.io/gh/scverse/scanpy/commit/5af38e4652eaf421910f3e2348a701689fc83a2e?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 46 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3150 +/- ##; =======================================; Coverage 76.52% 76.52% ; =======================================; Files 109 109 ; Lines 12480 12482 +2 ; =======================================; + Hits 9550 9552 +2 ; Misses 2930 2930 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3150?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3150?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | `74.89% <100.00%> (+0.10%)` | :arrow_up: |; | [src/scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3150?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_score_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaig,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3150#issuecomment-2222450502:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3150#issuecomment-2222450502,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3151?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.52%. Comparing base [(`ea546fe`)](https://app.codecov.io/gh/scverse/scanpy/commit/ea546feeceb4c3afca2b7200058f5db1dcc4539e?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`c9c06dc`)](https://app.codecov.io/gh/scverse/scanpy/commit/c9c06dcf6bd6ad87a81f3ed1a3bf6bd5834795a5?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 41 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3151 +/- ##; =======================================; Coverage 76.52% 76.52% ; =======================================; Files 109 109 ; Lines 12480 12480 ; =======================================; Hits 9550 9550 ; Misses 2930 2930 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3151#issuecomment-2222493388:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3151#issuecomment-2222493388,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3154?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.52%. Comparing base [(`284c987`)](https://app.codecov.io/gh/scverse/scanpy/commit/284c987dedfcf2fc28dd79e682ef721ccd3ff40d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`be6de17`)](https://app.codecov.io/gh/scverse/scanpy/commit/be6de1708f0c548bc0679e1968392b0a7ea3d67b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 44 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3154 +/- ##; ==========================================; - Coverage 76.52% 76.52% -0.01% ; ==========================================; Files 109 109 ; Lines 12482 12480 -2 ; ==========================================; - Hits 9552 9550 -2 ; Misses 2930 2930 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3154?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3154?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | `74.78% <100.00%> (-0.11%)` | :arrow_down: |; | [src/scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3154?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_score_genes.py&utm_medium=referral&utm_source=github&utm_content,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3154#issuecomment-2225871167:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3154#issuecomment-2225871167,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3155?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.52%. Comparing base [(`71fd59a`)](https://app.codecov.io/gh/scverse/scanpy/commit/71fd59aa3955bd4cc96d5eba874c5c719e60f3f1?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7c8ccc2`)](https://app.codecov.io/gh/scverse/scanpy/commit/7c8ccc216644f146376a29f58b08b74b112de44b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 54 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3155 +/- ##; =======================================; Coverage 76.52% 76.52% ; =======================================; Files 109 109 ; Lines 12483 12483 ; =======================================; Hits 9553 9553 ; Misses 2930 2930 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3155?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3155?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | `74.89% <100.00%> (+0.10%)` | :arrow_up: |; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3155?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+commen,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3155#issuecomment-2225995745:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3155#issuecomment-2225995745,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3156?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.52%. Comparing base [(`b918a23`)](https://app.codecov.io/gh/scverse/scanpy/commit/b918a23eb77462837df90d7b3a30a573989d4d48?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`be04fd9`)](https://app.codecov.io/gh/scverse/scanpy/commit/be04fd96a4c24b46424096141cc4ffd4eeefe76a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 51 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3156 +/- ##; =======================================; Coverage 76.52% 76.52% ; =======================================; Files 109 109 ; Lines 12480 12480 ; =======================================; Hits 9550 9550 ; Misses 2930 2930 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3156#issuecomment-2229124135:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3156#issuecomment-2229124135,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3161?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.52%. Comparing base [(`2eb1448`)](https://app.codecov.io/gh/scverse/scanpy/commit/2eb144855885d9b0e37ca26a5d87ad671fe10b7d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d6051a6`)](https://app.codecov.io/gh/scverse/scanpy/commit/d6051a620bbc26599bef5ce140ba43ae2f02308a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 50 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3161 +/- ##; =======================================; Coverage 76.52% 76.52% ; =======================================; Files 109 109 ; Lines 12480 12480 ; =======================================; Hits 9550 9550 ; Misses 2930 2930 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3161#issuecomment-2244531452:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3161#issuecomment-2244531452,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3162?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.52%. Comparing base [(`9fa55b8`)](https://app.codecov.io/gh/scverse/scanpy/commit/9fa55b84a2f17b4c0aca5cb848097aabff9092e9?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`87afc4a`)](https://app.codecov.io/gh/scverse/scanpy/commit/87afc4ac812422a924739bcacb7b58a308b35493?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 55 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3162 +/- ##; =======================================; Coverage 76.52% 76.52% ; =======================================; Files 109 109 ; Lines 12483 12483 ; =======================================; Hits 9553 9553 ; Misses 2930 2930 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3162#issuecomment-2245456997:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162#issuecomment-2245456997,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3163?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.52%. Comparing base [(`4269ed2`)](https://app.codecov.io/gh/scverse/scanpy/commit/4269ed23616a0e9c5a53ca25f45856e908bfb025?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6801394`)](https://app.codecov.io/gh/scverse/scanpy/commit/68013946e1abd9f0b3e091ba8fbfd7a693e79226?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 56 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3163 +/- ##; =======================================; Coverage 76.52% 76.52% ; =======================================; Files 109 109 ; Lines 12480 12483 +3 ; =======================================; + Hits 9550 9553 +3 ; Misses 2930 2930 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3163?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3163?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYW5uZGF0YS5weQ==) | `85.02% <100.00%> (ø)` | |; | [src/scanpy/plotting/\_docs.py](https://app.codecov.io/gh/scverse/scanpy/pull/3163?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_docs.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_ter,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3163#issuecomment-2249721390:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3163#issuecomment-2249721390,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3164?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.52%. Comparing base [(`2eb1448`)](https://app.codecov.io/gh/scverse/scanpy/commit/2eb144855885d9b0e37ca26a5d87ad671fe10b7d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`12b4cd7`)](https://app.codecov.io/gh/scverse/scanpy/commit/12b4cd78c6f22542299d7151045d73d7ce2a583e?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3164 +/- ##; =======================================; Coverage 76.52% 76.52% ; =======================================; Files 109 109 ; Lines 12480 12483 +3 ; =======================================; + Hits 9550 9553 +3 ; Misses 2930 2930 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3164?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3164?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYW5uZGF0YS5weQ==) | `85.02% <100.00%> (ø)` | |; | [src/scanpy/plotting/\_docs.py](https://app.codecov.io/gh/scverse/scanpy/pull/3164?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_docs.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3164#issuecomment-2249964541:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3164#issuecomment-2249964541,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3165?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.52%. Comparing base [(`d894167`)](https://app.codecov.io/gh/scverse/scanpy/commit/d8941678c5499a007c3d05d8caa857953624667c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`85ec553`)](https://app.codecov.io/gh/scverse/scanpy/commit/85ec5530a5c73e73cfeb0af86622bf4d0c45eefc?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 48 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3165 +/- ##; =======================================; Coverage 76.52% 76.52% ; =======================================; Files 109 109 ; Lines 12483 12483 ; =======================================; Hits 9553 9553 ; Misses 2930 2930 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3165#issuecomment-2250141808:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3165#issuecomment-2250141808,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3167?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.54%. Comparing base [(`62454de`)](https://app.codecov.io/gh/scverse/scanpy/commit/62454dedfe820d9cf02c9cce070bfdd011a143df?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`51f2f5f`)](https://app.codecov.io/gh/scverse/scanpy/commit/51f2f5f19ebbc48a15f65373abde5d7c8ec6a663?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 39 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3167 +/- ##; =======================================; Coverage 76.54% 76.54% ; =======================================; Files 109 109 ; Lines 12490 12492 +2 ; =======================================; + Hits 9560 9562 +2 ; Misses 2930 2930 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3167?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3167?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_score_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fc2NvcmVfZ2VuZXMucHk=) | `86.40% <100.00%> (+0.26%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3167#issuecomment-2251404446:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167#issuecomment-2251404446,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3170?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.54%. Comparing base [(`208115d`)](https://app.codecov.io/gh/scverse/scanpy/commit/208115dd78046af3258da3a756f36dda34e5aba8?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6e0a3aa`)](https://app.codecov.io/gh/scverse/scanpy/commit/6e0a3aa4dda8a4fab1ca89ff1ee8c55afcb54086?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3170 +/- ##; ==========================================; + Coverage 76.52% 76.54% +0.01% ; ==========================================; Files 109 109 ; Lines 12483 12490 +7 ; ==========================================; + Hits 9553 9560 +7 ; Misses 2930 2930 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3170?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3170?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_score_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fc2NvcmVfZ2VuZXMucHk=) | `86.13% <100.00%> (+1.03%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3170#issuecomment-2252418129:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3170#issuecomment-2252418129,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3172?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.54%. Comparing base [(`62454de`)](https://app.codecov.io/gh/scverse/scanpy/commit/62454dedfe820d9cf02c9cce070bfdd011a143df?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`e5ab2cd`)](https://app.codecov.io/gh/scverse/scanpy/commit/e5ab2cd43f430a12266cbf8bf68a48b5c0caa2aa?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 53 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3172 +/- ##; =======================================; Coverage 76.54% 76.54% ; =======================================; Files 109 109 ; Lines 12490 12490 ; =======================================; Hits 9560 9560 ; Misses 2930 2930 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3172#issuecomment-2252627948:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3172#issuecomment-2252627948,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3174?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.54%. Comparing base [(`b78e9dc`)](https://app.codecov.io/gh/scverse/scanpy/commit/b78e9dcc0ad26bed344456b0fa219f26606a3a6b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`2a00eba`)](https://app.codecov.io/gh/scverse/scanpy/commit/2a00ebafcf221e8e5a257db065584042ac571178?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 55 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3174 +/- ##; =======================================; Coverage 76.54% 76.54% ; =======================================; Files 109 109 ; Lines 12490 12490 ; =======================================; Hits 9560 9560 ; Misses 2930 2930 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3174#issuecomment-2256621904:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3174#issuecomment-2256621904,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3175?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.54%. Comparing base [(`71db9b6`)](https://app.codecov.io/gh/scverse/scanpy/commit/71db9b68db14360f70936025ff02f89acee78d6e?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`0dabf6c`)](https://app.codecov.io/gh/scverse/scanpy/commit/0dabf6cab35adfa2fe32dc1b50959d96ada8247d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 49 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3175 +/- ##; =======================================; Coverage 76.54% 76.54% ; =======================================; Files 109 109 ; Lines 12490 12490 ; =======================================; Hits 9560 9560 ; Misses 2930 2930 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3175#issuecomment-2257973833:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3175#issuecomment-2257973833,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3176?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.54%. Comparing base [(`333f6c8`)](https://app.codecov.io/gh/scverse/scanpy/commit/333f6c815469bd4178f211d7d0abb69b6b723eae?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`712066f`)](https://app.codecov.io/gh/scverse/scanpy/commit/712066f11ef437ff6cb1087102150d952b6cccff?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 54 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3176 +/- ##; =======================================; Coverage 76.54% 76.54% ; =======================================; Files 109 109 ; Lines 12490 12490 ; =======================================; Hits 9560 9560 ; Misses 2930 2930 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3176?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3176?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19oaWdobHlfdmFyaWFibGVfZ2VuZXMucHk=) | `95.23% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3176#issuecomment-2258121667:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3176#issuecomment-2258121667,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3177?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.54%. Comparing base [(`333f6c8`)](https://app.codecov.io/gh/scverse/scanpy/commit/333f6c815469bd4178f211d7d0abb69b6b723eae?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`eeeef7d`)](https://app.codecov.io/gh/scverse/scanpy/commit/eeeef7dfd67fbaba1a94908e4873358549e4388d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 54 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3177 +/- ##; =======================================; Coverage 76.54% 76.54% ; =======================================; Files 109 109 ; Lines 12490 12490 ; =======================================; Hits 9560 9560 ; Misses 2930 2930 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3177#issuecomment-2258214893:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3177#issuecomment-2258214893,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3178?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.54%. Comparing base [(`7055b5e`)](https://app.codecov.io/gh/scverse/scanpy/commit/7055b5e58e484d6b949042d3596db08158850fe2?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`c5423dc`)](https://app.codecov.io/gh/scverse/scanpy/commit/c5423dcbee605b480ad3e579dc44911769257539?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 48 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3178 +/- ##; =======================================; Coverage 76.54% 76.54% ; =======================================; Files 109 109 ; Lines 12490 12490 ; =======================================; Hits 9560 9560 ; Misses 2930 2930 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3178?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3178?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19oaWdobHlfdmFyaWFibGVfZ2VuZXMucHk=) | `95.23% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3178#issuecomment-2258265127:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3178#issuecomment-2258265127,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3179?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.54%. Comparing base [(`7055b5e`)](https://app.codecov.io/gh/scverse/scanpy/commit/7055b5e58e484d6b949042d3596db08158850fe2?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`59bc046`)](https://app.codecov.io/gh/scverse/scanpy/commit/59bc046fd86bbfc6489f6a7a65b82b0a42f1c7ef?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 48 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3179 +/- ##; =======================================; Coverage 76.54% 76.54% ; =======================================; Files 109 109 ; Lines 12490 12490 ; =======================================; Hits 9560 9560 ; Misses 2930 2930 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3179#issuecomment-2441597462:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3179#issuecomment-2441597462,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3180?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.76%. Comparing base [(`8b7673d`)](https://app.codecov.io/gh/scverse/scanpy/commit/8b7673d11fc77b4ed5d92e252dc069e69bd4f018?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`e6c61a8`)](https://app.codecov.io/gh/scverse/scanpy/commit/e6c61a861adf22e896ecbe69cfb9855be6fd1022?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3180 +/- ##; ==========================================; + Coverage 76.40% 76.76% +0.35% ; ==========================================; Files 109 109 ; Lines 12529 12544 +15 ; ==========================================; + Hits 9573 9629 +56 ; + Misses 2956 2915 -41 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3180?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/3180?src=pr&el=tree&filepath=src%2Fscanpy%2Fget%2F_aggregated.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9nZXQvX2FnZ3JlZ2F0ZWQucHk=) | `95.23% <100.00%> (+0.54%)` | :arrow_up: |. ... and [1 file with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3180/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_cam,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3180#issuecomment-2258682536:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180#issuecomment-2258682536,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3184?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.58%. Comparing base [(`3ba0d30`)](https://app.codecov.io/gh/scverse/scanpy/commit/3ba0d30a4a03e20e2e70f789c1a56490aa352751?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`4ce69d3`)](https://app.codecov.io/gh/scverse/scanpy/commit/4ce69d3b534f37d0b2c1c86942c45eb526e49b62?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 50 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3184 +/- ##; =======================================; Coverage 76.58% 76.58% ; =======================================; Files 109 109 ; Lines 12511 12511 ; =======================================; + Hits 9581 9582 +1 ; + Misses 2930 2929 -1 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3184?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_pca.py](https://app.codecov.io/gh/scverse/scanpy/pull/3184?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_pca.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19wY2EucHk=) | `93.44% <100.00%> (+0.54%)` | :arrow_up: |; | [src/scanpy/tools/\_tsne.py](https://app.codecov.io/gh/scverse/scanpy/pull/3184?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_tsne.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+co,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3184#issuecomment-2262677412:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3184#issuecomment-2262677412,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3186?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.58%. Comparing base [(`13a3706`)](https://app.codecov.io/gh/scverse/scanpy/commit/13a3706bbefe9d5a1a11e26db29f14798d3accbf?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`e285c0f`)](https://app.codecov.io/gh/scverse/scanpy/commit/e285c0f6ec77631d14d748d0927d38aae4391886?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 51 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3186 +/- ##; =======================================; Coverage 76.58% 76.58% ; =======================================; Files 109 109 ; Lines 12511 12511 ; =======================================; Hits 9581 9581 ; Misses 2930 2930 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3186?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_pca.py](https://app.codecov.io/gh/scverse/scanpy/pull/3186?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_pca.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19wY2EucHk=) | `92.89% <ø> (ø)` | |; | [src/scanpy/tools/\_tsne.py](https://app.codecov.io/gh/scverse/scanpy/pull/3186?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_tsne.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3J,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3186#issuecomment-2446872485:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3186#issuecomment-2446872485,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3187?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.58%. Comparing base [(`eda3bde`)](https://app.codecov.io/gh/scverse/scanpy/commit/eda3bde217ce870d5ca418dd4770646cd722e239?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`9b634c0`)](https://app.codecov.io/gh/scverse/scanpy/commit/9b634c0e4dcfa532a3b9ccc75c70d43363422882?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 45 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3187 +/- ##; =======================================; Coverage 76.58% 76.58% ; =======================================; Files 109 109 ; Lines 12511 12511 ; =======================================; Hits 9581 9581 ; Misses 2930 2930 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3187?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_pca.py](https://app.codecov.io/gh/scverse/scanpy/pull/3187?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_pca.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19wY2EucHk=) | `92.89% <ø> (ø)` | |; | [src/scanpy/tools/\_tsne.py](https://app.codecov.io/gh/scverse/scanpy/pull/3187?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_tsne.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3187#issuecomment-2446872710:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3187#issuecomment-2446872710,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3189?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.61%. Comparing base [(`3ba0d30`)](https://app.codecov.io/gh/scverse/scanpy/commit/3ba0d30a4a03e20e2e70f789c1a56490aa352751?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d33d23e`)](https://app.codecov.io/gh/scverse/scanpy/commit/d33d23eb53816684b7347e0b217cad9f7835184c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 50 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3189 +/- ##; ==========================================; + Coverage 76.58% 76.61% +0.03% ; ==========================================; Files 109 109 ; Lines 12511 12529 +18 ; ==========================================; + Hits 9581 9599 +18 ; Misses 2930 2930 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3189?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3189?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | `75.25% <100.00%> (ø)` | |; | [src/scanpy/experimental/pp/\_normalization.py](https://app.codecov.io/gh/scverse/scanpy/pull/3189?src=pr&el=tree&filepath=src%2Fscanpy%2Fexperimental%2Fpp%2F_normalization.py&utm_medium=referral&utm_source=github&ut,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3189#issuecomment-2263307778:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3189#issuecomment-2263307778,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3194?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.61%. Comparing base [(`b7e599a`)](https://app.codecov.io/gh/scverse/scanpy/commit/b7e599a9acc887013bc824f3a550a7607002d455?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`9d949c4`)](https://app.codecov.io/gh/scverse/scanpy/commit/9d949c459c1c69e5ca47ff017d666952159650ed?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 49 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3194 +/- ##; =======================================; Coverage 76.61% 76.61% ; =======================================; Files 109 109 ; Lines 12532 12532 ; =======================================; Hits 9602 9602 ; Misses 2930 2930 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3194#issuecomment-2453411150:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3194#issuecomment-2453411150,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3196?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.63%. Comparing base [(`bb66827`)](https://app.codecov.io/gh/scverse/scanpy/commit/bb6682799f4137a6ec9f49270929de6b260c0520?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`f5ea470`)](https://app.codecov.io/gh/scverse/scanpy/commit/f5ea47084d3cf864b988c33534da6cfbfb85eccc?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 47 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3196 +/- ##; ==========================================; + Coverage 76.61% 76.63% +0.01% ; ==========================================; Files 109 109 ; Lines 12532 12533 +1 ; ==========================================; + Hits 9602 9605 +3 ; + Misses 2930 2928 -2 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3196?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/3196?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_stacked_violin.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fc3RhY2tlZF92aW9saW4ucHk=) | `84.57% <100.00%> (+0.07%)` | :arrow_up: |. ... and [2 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3196/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=gith,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3196#issuecomment-2269551792:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196#issuecomment-2269551792,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3197?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.61%. Comparing base [(`746b02c`)](https://app.codecov.io/gh/scverse/scanpy/commit/746b02c4d8f66c9f79a920755773ef2bac34e577?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`5f32592`)](https://app.codecov.io/gh/scverse/scanpy/commit/5f3259292f89611f3cda36aaad8e8a7247563b75?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 48 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3197 +/- ##; =======================================; Coverage 76.61% 76.61% ; =======================================; Files 109 109 ; Lines 12532 12532 ; =======================================; Hits 9602 9602 ; Misses 2930 2930 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3197#issuecomment-2269663207:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3197#issuecomment-2269663207,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3198?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.61%. Comparing base [(`be2dec1`)](https://app.codecov.io/gh/scverse/scanpy/commit/be2dec1e1922180ded38e175f1ebbc18eeb3d7ed?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`c9b8fe2`)](https://app.codecov.io/gh/scverse/scanpy/commit/c9b8fe21a5e2a5267471e885e9967ffeab6a5f9d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 42 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3198 +/- ##; =======================================; Coverage 76.61% 76.61% ; =======================================; Files 109 109 ; Lines 12532 12532 ; =======================================; Hits 9601 9601 ; Misses 2931 2931 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3198#issuecomment-2270695311:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3198#issuecomment-2270695311,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3200?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.62%. Comparing base [(`18c4607`)](https://app.codecov.io/gh/scverse/scanpy/commit/18c4607d8fce66f8d5d42b989508bab247070d66?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`49bbe54`)](https://app.codecov.io/gh/scverse/scanpy/commit/49bbe540d39527cb62c605faf15ddd3444bcefb0?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 42 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3200 +/- ##; ==========================================; + Coverage 76.61% 76.62% +0.01% ; ==========================================; Files 109 109 ; Lines 12532 12533 +1 ; ==========================================; + Hits 9601 9604 +3 ; + Misses 2931 2929 -2 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3200?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/3200?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_stacked_violin.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fc3RhY2tlZF92aW9saW4ucHk=) | `84.57% <100.00%> (+0.07%)` | :arrow_up: |. ... and [2 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3200/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3200#issuecomment-2271880236:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3200#issuecomment-2271880236,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3206?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.85%. Comparing base [(`874ce15`)](https://app.codecov.io/gh/scverse/scanpy/commit/874ce151d466de03d74da39be925be739483e678?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`fe1ab42`)](https://app.codecov.io/gh/scverse/scanpy/commit/fe1ab429d273a6dcf6a3f3381b9cffc28b935eab?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3206 +/- ##; ==========================================; + Coverage 76.74% 76.85% +0.11% ; ==========================================; Files 109 109 ; Lines 12559 12554 -5 ; ==========================================; + Hits 9638 9648 +10 ; + Misses 2921 2906 -15 ; ```. | [Flag](https://app.codecov.io/gh/scverse/scanpy/pull/3206/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [](https://app.codecov.io/gh/scverse/scanpy/pull/3206/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | `76.63% <100.00%> (?)` | |. Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#carryforward-flags-in-the-pull-request-comment) to find out more. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3206?dropd,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3206#issuecomment-2283913995:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3206#issuecomment-2283913995,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3207?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.63%. Comparing base [(`c6766d7`)](https://app.codecov.io/gh/scverse/scanpy/commit/c6766d758b83410e9167578d22054f712d5bca4b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`e90077e`)](https://app.codecov.io/gh/scverse/scanpy/commit/e90077ed4601f8223b2dd78d3302d6a7f6b9a0cd?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3207 +/- ##; =======================================; Coverage 76.63% 76.63% ; =======================================; Files 109 109 ; Lines 12533 12533 ; =======================================; Hits 9605 9605 ; Misses 2928 2928 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3207#issuecomment-2284634069:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3207#issuecomment-2284634069,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3208?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.62%. Comparing base [(`51733cc`)](https://app.codecov.io/gh/scverse/scanpy/commit/51733cc919e786dba1b648b7a2cf887f0df89165?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`cc3f748`)](https://app.codecov.io/gh/scverse/scanpy/commit/cc3f748af6c1824702ee6cf6daaf41741db2d76c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3208 +/- ##; =======================================; Coverage 76.62% 76.62% ; =======================================; Files 109 109 ; Lines 12533 12533 ; =======================================; Hits 9604 9604 ; Misses 2929 2929 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3208#issuecomment-2285962019:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3208#issuecomment-2285962019,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3210?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.63%. Comparing base [(`89dcf21`)](https://app.codecov.io/gh/scverse/scanpy/commit/89dcf21e858702d6aa35dedd44dfcb9a831ad76a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`f024311`)](https://app.codecov.io/gh/scverse/scanpy/commit/f024311ba58e3a4026edc5c5b7f548234d002dbc?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3210 +/- ##; =======================================; Coverage 76.63% 76.63% ; =======================================; Files 109 109 ; Lines 12533 12533 ; =======================================; Hits 9605 9605 ; Misses 2928 2928 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3210#issuecomment-2297166243:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3210#issuecomment-2297166243,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3213?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.63%. Comparing base [(`3c13495`)](https://app.codecov.io/gh/scverse/scanpy/commit/3c1349529fa0c0385c0f6bbc313ceb9bcdc84b8d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`e8ccd40`)](https://app.codecov.io/gh/scverse/scanpy/commit/e8ccd402ec4c1f27575ca3663216bbfd067f7dfe?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3213 +/- ##; =======================================; Coverage 76.63% 76.63% ; =======================================; Files 109 109 ; Lines 12533 12533 ; =======================================; Hits 9605 9605 ; Misses 2928 2928 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3213#issuecomment-2310803362:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3213#issuecomment-2310803362,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3216?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.63%. Comparing base [(`8159592`)](https://app.codecov.io/gh/scverse/scanpy/commit/8159592a70688488815c4e3120d9920ab7e3e4b9?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3f446f3`)](https://app.codecov.io/gh/scverse/scanpy/commit/3f446f3f470a8359db342e359b340997d93aa78b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3216 +/- ##; =======================================; Coverage 76.63% 76.63% ; =======================================; Files 109 109 ; Lines 12533 12533 ; =======================================; Hits 9605 9605 ; Misses 2928 2928 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3216#issuecomment-2321506839:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3216#issuecomment-2321506839,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3217?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.63%. Comparing base [(`b619350`)](https://app.codecov.io/gh/scverse/scanpy/commit/b6193502e11b84fc1b4a011ee9cf08a19da22ebf?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`068ecce`)](https://app.codecov.io/gh/scverse/scanpy/commit/068ecce0c50d010b3ae56e2ba577161187482c98?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3217 +/- ##; =======================================; Coverage 76.63% 76.63% ; =======================================; Files 109 109 ; Lines 12533 12533 ; =======================================; Hits 9605 9605 ; Misses 2928 2928 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3217#issuecomment-2321619540:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3217#issuecomment-2321619540,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3218?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.62%. Comparing base [(`ccbae49`)](https://app.codecov.io/gh/scverse/scanpy/commit/ccbae49b08825e348227389f3d741756e352be4b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3d5761f`)](https://app.codecov.io/gh/scverse/scanpy/commit/3d5761f21a87b70d68af28cb5e060ce9a8a6dece?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3218 +/- ##; =======================================; Coverage 76.62% 76.62% ; =======================================; Files 109 109 ; Lines 12533 12533 ; =======================================; Hits 9604 9604 ; Misses 2929 2929 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3218#issuecomment-2321752694:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3218#issuecomment-2321752694,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3223?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.62%. Comparing base [(`2f80d74`)](https://app.codecov.io/gh/scverse/scanpy/commit/2f80d74722255f6df7a5c970817ccafbaad24bfd?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`af59217`)](https://app.codecov.io/gh/scverse/scanpy/commit/af5921702646c300f181f17c4d391e44fdca8663?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3223 +/- ##; =======================================; Coverage 76.62% 76.62% ; =======================================; Files 109 109 ; Lines 12533 12533 ; =======================================; Hits 9604 9604 ; Misses 2929 2929 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3223#issuecomment-2325217033:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3223#issuecomment-2325217033,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3225?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.63%. Comparing base [(`bec794c`)](https://app.codecov.io/gh/scverse/scanpy/commit/bec794c7e7e28393e7cb6ae6624ecdbd187868ac?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`bebdcc5`)](https://app.codecov.io/gh/scverse/scanpy/commit/bebdcc52ee7f6bf7cc82bf843d8208b232ad838f?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3225 +/- ##; =======================================; Coverage 76.63% 76.63% ; =======================================; Files 109 109 ; Lines 12533 12533 ; =======================================; Hits 9605 9605 ; Misses 2928 2928 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3225#issuecomment-2338796117:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3225#issuecomment-2338796117,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3229?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.62%. Comparing base [(`f51543d`)](https://app.codecov.io/gh/scverse/scanpy/commit/f51543d9ed1e4eeda0e784ecfd395f55a87a3e39?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`f07b1b9`)](https://app.codecov.io/gh/scverse/scanpy/commit/f07b1b9ecff5109736bc3d8da4dc328fbb052ed1?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3229 +/- ##; =======================================; Coverage 76.62% 76.62% ; =======================================; Files 109 109 ; Lines 12533 12533 ; =======================================; Hits 9604 9604 ; Misses 2929 2929 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3229#issuecomment-2348408946:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3229#issuecomment-2348408946,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3231?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.73%. Comparing base [(`9d8b164`)](https://app.codecov.io/gh/scverse/scanpy/commit/9d8b1648daca94a7d879fdc9a84600d5611817e2?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`0cd8304`)](https://app.codecov.io/gh/scverse/scanpy/commit/0cd830439792ab5e03dc2cbcff653ba141c043e9?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3231 +/- ##; =======================================; Coverage 76.73% 76.73% ; =======================================; Files 109 109 ; Lines 12529 12529 ; =======================================; Hits 9614 9614 ; Misses 2915 2915 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3231#issuecomment-2352587896:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3231#issuecomment-2352587896,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3232?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.73%. Comparing base [(`9d8b164`)](https://app.codecov.io/gh/scverse/scanpy/commit/9d8b1648daca94a7d879fdc9a84600d5611817e2?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3e813c4`)](https://app.codecov.io/gh/scverse/scanpy/commit/3e813c434d2229e7773d28bb1069c9b79ed49d77?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3232 +/- ##; =======================================; Coverage 76.73% 76.73% ; =======================================; Files 109 109 ; Lines 12529 12529 ; =======================================; Hits 9614 9614 ; Misses 2915 2915 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3232#issuecomment-2353599855:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3232#issuecomment-2353599855,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3233?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.72%. Comparing base [(`5bb5542`)](https://app.codecov.io/gh/scverse/scanpy/commit/5bb55428938813c865107df603873aaf36a53967?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`56bff94`)](https://app.codecov.io/gh/scverse/scanpy/commit/56bff949604e898af8e82c32b6edcde76bbcfc17?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3233 +/- ##; =======================================; Coverage 76.72% 76.72% ; =======================================; Files 109 109 ; Lines 12529 12529 ; =======================================; Hits 9613 9613 ; Misses 2916 2916 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3233#issuecomment-2355178219:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3233#issuecomment-2355178219,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3234?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.72%. Comparing base [(`76cb5e2`)](https://app.codecov.io/gh/scverse/scanpy/commit/76cb5e277c348580ebf79971bf66c82369081d9c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6a0679a`)](https://app.codecov.io/gh/scverse/scanpy/commit/6a0679a8213801e40676bbea78f008be0a46cf32?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3234 +/- ##; =======================================; Coverage 76.72% 76.72% ; =======================================; Files 109 109 ; Lines 12529 12529 ; =======================================; Hits 9613 9613 ; Misses 2916 2916 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3234#issuecomment-2355553018:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3234#issuecomment-2355553018,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3235?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.72%. Comparing base [(`31ea148`)](https://app.codecov.io/gh/scverse/scanpy/commit/31ea148ac8d49bf3844a33390288baa4acbd41b6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`32eeee9`)](https://app.codecov.io/gh/scverse/scanpy/commit/32eeee9d103d96fda3eaff48a50dfd8c35fd86cf?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3235 +/- ##; =======================================; Coverage 76.72% 76.72% ; =======================================; Files 109 109 ; Lines 12529 12529 ; =======================================; Hits 9613 9613 ; Misses 2916 2916 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3235#issuecomment-2355704502:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3235#issuecomment-2355704502,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3238?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.73%. Comparing base [(`8a44ef6`)](https://app.codecov.io/gh/scverse/scanpy/commit/8a44ef62f2848a4532f290cf5396503815c2b197?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a78a286`)](https://app.codecov.io/gh/scverse/scanpy/commit/a78a28607fdf37fc45b97eeb41b98eca60af77f9?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3238 +/- ##; =======================================; Coverage 76.73% 76.73% ; =======================================; Files 109 109 ; Lines 12529 12529 ; =======================================; Hits 9614 9614 ; Misses 2915 2915 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3238#issuecomment-2355901850:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3238#issuecomment-2355901850,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3239?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.40%. Comparing base [(`7ab0bfe`)](https://app.codecov.io/gh/scverse/scanpy/commit/7ab0bfeafa2f4890ae9667c0a44986c0bfdaa360?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`2b740c8`)](https://app.codecov.io/gh/scverse/scanpy/commit/2b740c8148834b83978ca096ddfbf37ea3b66f1a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3239 +/- ##; ==========================================; - Coverage 76.73% 76.40% -0.33% ; ==========================================; Files 109 109 ; Lines 12529 12529 ; ==========================================; - Hits 9614 9573 -41 ; - Misses 2915 2956 +41 ; ```. [see 1 file with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3239/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3239#issuecomment-2356025412:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3239#issuecomment-2356025412,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3242?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.45%. Comparing base [(`1cd88fa`)](https://app.codecov.io/gh/scverse/scanpy/commit/1cd88fa034c82a5404691b7b9204d5fc3c6160ad?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`aaeaeea`)](https://app.codecov.io/gh/scverse/scanpy/commit/aaeaeea5c9cd8e45979940e3cc026df11e39ff86?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3242 +/- ##; ==========================================; - Coverage 76.72% 76.45% -0.28% ; ==========================================; Files 109 109 ; Lines 12529 12529 ; ==========================================; - Hits 9613 9579 -34 ; - Misses 2916 2950 +34 ; ```. [see 2 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3242/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3242#issuecomment-2360428654:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3242#issuecomment-2360428654,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3244?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.77%. Comparing base [(`bd75839`)](https://app.codecov.io/gh/scverse/scanpy/commit/bd758395a669c31a6c9eaa9239750fde368d3ca7?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`32279bf`)](https://app.codecov.io/gh/scverse/scanpy/commit/32279bf6967b397710cf520895f0a8ad7105811b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3244 +/- ##; ==========================================; + Coverage 76.49% 76.77% +0.27% ; ==========================================; Files 109 109 ; Lines 12544 12550 +6 ; ==========================================; + Hits 9596 9635 +39 ; + Misses 2948 2915 -33 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3244?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3244?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYW5uZGF0YS5weQ==) | `85.02% <100.00%> (+0.03%)` | :arrow_up: |; | [src/scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/3244?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_stacked_violin.py&utm_medium=referral&utm_sourc,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3244#issuecomment-2363351271:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3244#issuecomment-2363351271,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3247?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.73%. Comparing base [(`2553c67`)](https://app.codecov.io/gh/scverse/scanpy/commit/2553c67af6e47992abde5cb13e4c9deb82a3adbc?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`9e6664b`)](https://app.codecov.io/gh/scverse/scanpy/commit/9e6664b1854914b52c465585a08d5fd35e8ad93b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3247 +/- ##; ==========================================; - Coverage 76.76% 76.73% -0.03% ; ==========================================; Files 109 109 ; Lines 12529 12535 +6 ; ==========================================; + Hits 9618 9619 +1 ; - Misses 2911 2916 +5 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3247?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3247?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYW5uZGF0YS5weQ==) | `85.05% <100.00%> (+0.03%)` | :arrow_up: |; | [src/scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/3247?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_stacked_violin.py&utm_medium=referral&utm_sou,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3247#issuecomment-2363461111:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3247#issuecomment-2363461111,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3254?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.81%. Comparing base [(`aeabbc1`)](https://app.codecov.io/gh/scverse/scanpy/commit/aeabbc1e5ec4ace4fd873442ad3c4d3a60a8449c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`72cce47`)](https://app.codecov.io/gh/scverse/scanpy/commit/72cce47d82d45cc1e3865b8ddaf6772082c34b5c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3254 +/- ##; ==========================================; + Coverage 76.70% 76.81% +0.11% ; ==========================================; Files 109 109 ; Lines 12544 12539 -5 ; ==========================================; + Hits 9622 9632 +10 ; + Misses 2922 2907 -15 ; ```. | [Flag](https://app.codecov.io/gh/scverse/scanpy/pull/3254/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [](https://app.codecov.io/gh/scverse/scanpy/pull/3254/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | `76.81% <100.00%> (?)` | |. Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#carryforward-flags-in-the-pull-request-comment) to find out more. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3254?d,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3254#issuecomment-2364007377:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3254#issuecomment-2364007377,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3256?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.85%. Comparing base [(`7ae1216`)](https://app.codecov.io/gh/scverse/scanpy/commit/7ae12167f582935a8c6f9c06fff9cda99a4eedc6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`8e93029`)](https://app.codecov.io/gh/scverse/scanpy/commit/8e930295522478666eae88b7e7821fba73db319f?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3256 +/- ##; =======================================; Coverage 76.85% 76.85% ; =======================================; Files 109 109 ; Lines 12554 12554 ; =======================================; Hits 9648 9648 ; Misses 2906 2906 ; ```. | [Flag](https://app.codecov.io/gh/scverse/scanpy/pull/3256/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [](https://app.codecov.io/gh/scverse/scanpy/pull/3256/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | `76.85% <ø> (ø)` | |. Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#carryforward-flags-in-the-pull-request-comment) to find out more. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3256#issuecomment-2369029007:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3256#issuecomment-2369029007,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3257?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.81%. Comparing base [(`b23a5ca`)](https://app.codecov.io/gh/scverse/scanpy/commit/b23a5ca6aa8038a4716c59bf6ee5d999cca8703c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`4567c77`)](https://app.codecov.io/gh/scverse/scanpy/commit/4567c777dcd04e34e358c3bffe20f03361a71457?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3257 +/- ##; =======================================; Coverage 76.81% 76.81% ; =======================================; Files 109 109 ; Lines 12539 12539 ; =======================================; Hits 9632 9632 ; Misses 2907 2907 ; ```. | [Flag](https://app.codecov.io/gh/scverse/scanpy/pull/3257/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [](https://app.codecov.io/gh/scverse/scanpy/pull/3257/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | `76.81% <ø> (ø)` | |. Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#carryforward-flags-in-the-pull-request-comment) to find out more. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3257#issuecomment-2370576220:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3257#issuecomment-2370576220,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3262?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.97%. Comparing base [(`d998742`)](https://app.codecov.io/gh/scverse/scanpy/commit/d9987426be03f9ef1bdab065f50959d046734ea4?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d09d0d1`)](https://app.codecov.io/gh/scverse/scanpy/commit/d09d0d12c2193ba36d928a744fbfadf0bfcd82c0?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3262 +/- ##; ==========================================; + Coverage 76.96% 76.97% +0.01% ; ==========================================; Files 109 109 ; Lines 12469 12475 +6 ; ==========================================; + Hits 9597 9603 +6 ; Misses 2872 2872 ; ```. | [Flag](https://app.codecov.io/gh/scverse/scanpy/pull/3262/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [](https://app.codecov.io/gh/scverse/scanpy/pull/3262/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | `76.97% <100.00%> (+0.01%)` | :arrow_up: |. Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#carryforward-flags-in-the-pull-request-comment) to find out more. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3262?dropdown=coverage&src=pr&el=tree&utm_med,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3262#issuecomment-2376374423:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3262#issuecomment-2376374423,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3263?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.18%. Comparing base [(`121f2db`)](https://app.codecov.io/gh/scverse/scanpy/commit/121f2dbdbf97f42506dcaecf3f698cca406ffe2a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`97c3812`)](https://app.codecov.io/gh/scverse/scanpy/commit/97c3812b49b1f0684979915c4eceb6a4fc1f19b9?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3263 +/- ##; ==========================================; + Coverage 77.01% 77.18% +0.16% ; ==========================================; Files 110 111 +1 ; Lines 12492 12582 +90 ; ==========================================; + Hits 9621 9711 +90 ; Misses 2871 2871 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3263?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_pca/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3263?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_pca%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19wY2EvX19pbml0X18ucHk=) | `90.81% <100.00%> (+0.70%)` | :arrow_up: |; | [src/scanpy/preprocessing/\_pca/\_dask\_sparse.py](https://app.codecov.io/gh/scverse/scanpy/pull/3263?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3263#issuecomment-2376354893:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263#issuecomment-2376354893,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3268?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.95%. Comparing base [(`48706ca`)](https://app.codecov.io/gh/scverse/scanpy/commit/48706caa5e3b0b5076b4156249acc3579f1e20bc?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`0722c91`)](https://app.codecov.io/gh/scverse/scanpy/commit/0722c912efa86d0a591ef2a86fbf955a16d9e314?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3268 +/- ##; ==========================================; + Coverage 76.74% 76.95% +0.20% ; ==========================================; Files 109 109 ; Lines 12466 12466 ; ==========================================; + Hits 9567 9593 +26 ; + Misses 2899 2873 -26 ; ```. | [Flag](https://app.codecov.io/gh/scverse/scanpy/pull/3268/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [](https://app.codecov.io/gh/scverse/scanpy/pull/3268/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | `76.95% <ø> (+0.20%)` | :arrow_up: |. Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#carryforward-flags-in-the-pull-request-comment) to find out more. [see 10 files with indirect coverage changes](https://app.codecov.io/gh/scvers,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3268#issuecomment-2383244980:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3268#issuecomment-2383244980,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3269?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.91%. Comparing base [(`ae926b8`)](https://app.codecov.io/gh/scverse/scanpy/commit/ae926b8ca31228b055df83603168dc5a975b838d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`c8efab2`)](https://app.codecov.io/gh/scverse/scanpy/commit/c8efab261c5c3a2cd9b8860a5404ad6c249afb76?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3269 +/- ##; =======================================; Coverage 76.91% 76.91% ; =======================================; Files 109 109 ; Lines 12451 12451 ; =======================================; Hits 9577 9577 ; Misses 2874 2874 ; ```. | [Flag](https://app.codecov.io/gh/scverse/scanpy/pull/3269/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [](https://app.codecov.io/gh/scverse/scanpy/pull/3269/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | `76.91% <ø> (ø)` | |. Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#carryforward-flags-in-the-pull-request-comment) to find out more. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3269#issuecomment-2383365723:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3269#issuecomment-2383365723,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3270?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.95%. Comparing base [(`2e208a3`)](https://app.codecov.io/gh/scverse/scanpy/commit/2e208a34a0affe8e89a0e5c44984b318622914f4?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6cac292`)](https://app.codecov.io/gh/scverse/scanpy/commit/6cac2928f87805811775e2ebbffc9f48a702d8c4?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3270 +/- ##; =======================================; Coverage 76.95% 76.95% ; =======================================; Files 109 109 ; Lines 12466 12466 ; =======================================; Hits 9593 9593 ; Misses 2873 2873 ; ```. | [Flag](https://app.codecov.io/gh/scverse/scanpy/pull/3270/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [](https://app.codecov.io/gh/scverse/scanpy/pull/3270/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | `76.95% <100.00%> (ø)` | |. Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#carryforward-flags-in-the-pull-request-comment) to find out more. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3270?dropdown=coverage&src=pr&el=tree&utm_m,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3270#issuecomment-2383895093:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3270#issuecomment-2383895093,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3271?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.91%. Comparing base [(`dd638be`)](https://app.codecov.io/gh/scverse/scanpy/commit/dd638bef684ca655fdee1ac9bcdf0381860ca2f5?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`2df8033`)](https://app.codecov.io/gh/scverse/scanpy/commit/2df80339a504077d4907e93fdecb542d47af1777?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3271 +/- ##; =======================================; Coverage 76.91% 76.91% ; =======================================; Files 109 109 ; Lines 12451 12451 ; =======================================; Hits 9577 9577 ; Misses 2874 2874 ; ```. | [Flag](https://app.codecov.io/gh/scverse/scanpy/pull/3271/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [](https://app.codecov.io/gh/scverse/scanpy/pull/3271/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | `?` | |. Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#carryforward-flags-in-the-pull-request-comment) to find out more. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3271?dropdown=coverage&src=pr&el=tree&utm_medium=referral&,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3271#issuecomment-2385583428:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3271#issuecomment-2385583428,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3274?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.21%. Comparing base [(`f0b8d6b`)](https://app.codecov.io/gh/scverse/scanpy/commit/f0b8d6bc491ac85d31e81e9c469bbf10aecbf55f?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`f5d4acb`)](https://app.codecov.io/gh/scverse/scanpy/commit/f5d4acb5f10e0808bf925a777756f164aae1b3b4?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3274 +/- ##; =======================================; Coverage 77.21% 77.21% ; =======================================; Files 111 111 ; Lines 12594 12594 ; =======================================; Hits 9724 9724 ; Misses 2870 2870 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3274#issuecomment-2397662171:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3274#issuecomment-2397662171,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3278?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.95%. Comparing base [(`be99b23`)](https://app.codecov.io/gh/scverse/scanpy/commit/be99b230fa84e077f5167979bc9f6dacc4ad0d41?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`33d2591`)](https://app.codecov.io/gh/scverse/scanpy/commit/33d2591bb58f80704245d15d8bd0776f754a6d9b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3278 +/- ##; =======================================; Coverage 76.95% 76.95% ; =======================================; Files 109 109 ; Lines 12466 12466 ; =======================================; Hits 9593 9593 ; Misses 2873 2873 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3278?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/readwrite.py](https://app.codecov.io/gh/scverse/scanpy/pull/3278?src=pr&el=tree&filepath=src%2Fscanpy%2Freadwrite.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9yZWFkd3JpdGUucHk=) | `77.53% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3278#issuecomment-2406312796:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3278#issuecomment-2406312796,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3279?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.95%. Comparing base [(`be99b23`)](https://app.codecov.io/gh/scverse/scanpy/commit/be99b230fa84e077f5167979bc9f6dacc4ad0d41?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`8c4a56e`)](https://app.codecov.io/gh/scverse/scanpy/commit/8c4a56e6baab5b65a173418d7f1cd04c849e5b21?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3279 +/- ##; ==========================================; - Coverage 76.95% 76.95% -0.01% ; ==========================================; Files 109 109 ; Lines 12466 12469 +3 ; ==========================================; + Hits 9593 9595 +2 ; - Misses 2873 2874 +1 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3279?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/tools/\_tsne.py](https://app.codecov.io/gh/scverse/scanpy/pull/3279?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_tsne.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fdHNuZS5weQ==) | `91.83% <100.00%> (-1.65%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3279#issuecomment-2409951608:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3279#issuecomment-2409951608,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3280?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.95%. Comparing base [(`be99b23`)](https://app.codecov.io/gh/scverse/scanpy/commit/be99b230fa84e077f5167979bc9f6dacc4ad0d41?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`e4b82c8`)](https://app.codecov.io/gh/scverse/scanpy/commit/e4b82c8244f3b46e2c00e2de0ba2b734058139bb?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3280 +/- ##; ==========================================; - Coverage 76.95% 76.95% -0.01% ; ==========================================; Files 109 109 ; Lines 12466 12469 +3 ; ==========================================; + Hits 9593 9595 +2 ; - Misses 2873 2874 +1 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3280?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3280?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL191dGlscy5weQ==) | `95.12% <100.00%> (-2.25%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3280#issuecomment-2406552747:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3280#issuecomment-2406552747,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3281?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.95%. Comparing base [(`be99b23`)](https://app.codecov.io/gh/scverse/scanpy/commit/be99b230fa84e077f5167979bc9f6dacc4ad0d41?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3565191`)](https://app.codecov.io/gh/scverse/scanpy/commit/356519196dc9eeff6a0a570135a3b7dcadd0b469?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3281 +/- ##; =======================================; Coverage 76.95% 76.95% ; =======================================; Files 109 109 ; Lines 12466 12466 ; =======================================; Hits 9593 9593 ; Misses 2873 2873 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3281#issuecomment-2410908338:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3281#issuecomment-2410908338,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3285?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.21%. Comparing base [(`9a9f17e`)](https://app.codecov.io/gh/scverse/scanpy/commit/9a9f17e4d4afdd3c2e1395dfe9aec5cce5489248?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`9d4e1ab`)](https://app.codecov.io/gh/scverse/scanpy/commit/9d4e1abea71854814b968a3a8fed39f0cd263b29?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3285 +/- ##; =======================================; Coverage 77.21% 77.21% ; =======================================; Files 111 111 ; Lines 12597 12597 ; =======================================; Hits 9727 9727 ; Misses 2870 2870 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3285?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/tools/\_rank\_genes\_groups.py](https://app.codecov.io/gh/scverse/scanpy/pull/3285?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_rank_genes_groups.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fcmFua19nZW5lc19ncm91cHMucHk=) | `94.52% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3285#issuecomment-2413281428:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3285#issuecomment-2413281428,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3286?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.94%. Comparing base [(`842b68f`)](https://app.codecov.io/gh/scverse/scanpy/commit/842b68f98e6a3644d64770c254833abbf829395a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d1e8812`)](https://app.codecov.io/gh/scverse/scanpy/commit/d1e881266b26c70b7b26c7493a3da0e31722f2d4?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 8 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3286 +/- ##; =======================================; Coverage 76.94% 76.94% ; =======================================; Files 109 109 ; Lines 12461 12462 +1 ; =======================================; + Hits 9588 9589 +1 ; Misses 2873 2873 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3286?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3286?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL191dGlscy5weQ==) | `97.43% <100.00%> (+0.06%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3286#issuecomment-2413888389:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3286#issuecomment-2413888389,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3287?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.94%. Comparing base [(`842b68f`)](https://app.codecov.io/gh/scverse/scanpy/commit/842b68f98e6a3644d64770c254833abbf829395a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d5e0d2c`)](https://app.codecov.io/gh/scverse/scanpy/commit/d5e0d2cb1b9fe9ef7cd4d1342407590ad8335e33?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3287 +/- ##; =======================================; Coverage 76.94% 76.94% ; =======================================; Files 109 109 ; Lines 12461 12461 ; =======================================; Hits 9588 9588 ; Misses 2873 2873 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3287#issuecomment-2413957982:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3287#issuecomment-2413957982,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3289?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.95%. Comparing base [(`7268e53`)](https://app.codecov.io/gh/scverse/scanpy/commit/7268e537468182858fd48cf6136a168804ee1763?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`17eefd3`)](https://app.codecov.io/gh/scverse/scanpy/commit/17eefd3ec41ddec182f23a25b81653a1567bc39a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3289 +/- ##; =======================================; Coverage 76.94% 76.95% ; =======================================; Files 109 109 ; Lines 12461 12465 +4 ; =======================================; + Hits 9588 9592 +4 ; Misses 2873 2873 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3289?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/readwrite.py](https://app.codecov.io/gh/scverse/scanpy/pull/3289?src=pr&el=tree&filepath=src%2Fscanpy%2Freadwrite.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9yZWFkd3JpdGUucHk=) | `77.75% <100.00%> (+0.21%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3289#issuecomment-2414490766:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3289#issuecomment-2414490766,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3290?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.92%. Comparing base [(`e177e99`)](https://app.codecov.io/gh/scverse/scanpy/commit/e177e99c672d31f5a0952c94ca65bda321c5d0bb?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`40fc6f2`)](https://app.codecov.io/gh/scverse/scanpy/commit/40fc6f260318f6bca4a91443da1802d2ffed9883?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3290 +/- ##; =======================================; Coverage 76.91% 76.92% ; =======================================; Files 109 109 ; Lines 12451 12455 +4 ; =======================================; + Hits 9577 9581 +4 ; Misses 2874 2874 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3290?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/readwrite.py](https://app.codecov.io/gh/scverse/scanpy/pull/3290?src=pr&el=tree&filepath=src%2Fscanpy%2Freadwrite.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9yZWFkd3JpdGUucHk=) | `77.75% <100.00%> (+0.21%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3290#issuecomment-2419546222:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3290#issuecomment-2419546222,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3292?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.95%. Comparing base [(`3da6891`)](https://app.codecov.io/gh/scverse/scanpy/commit/3da6891e232570907db036392771262fefa13ef5?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`86de33f`)](https://app.codecov.io/gh/scverse/scanpy/commit/86de33f3c3d0b252af35836d619ac836c8887a54?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3292 +/- ##; =======================================; Coverage 76.95% 76.95% ; =======================================; Files 109 109 ; Lines 12465 12465 ; =======================================; Hits 9592 9592 ; Misses 2873 2873 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3292#issuecomment-2419700972:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3292#issuecomment-2419700972,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3294?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.03%. Comparing base [(`3570cd1`)](https://app.codecov.io/gh/scverse/scanpy/commit/3570cd1e4cd717cd7cd15929059c84cf7eb6d396?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7ea21bc`)](https://app.codecov.io/gh/scverse/scanpy/commit/7ea21bc5cb5e107b995d39e7894accd3155f78b3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3294 +/- ##; ==========================================; + Coverage 77.01% 77.03% +0.01% ; ==========================================; Files 110 110 ; Lines 12492 12492 ; ==========================================; + Hits 9621 9623 +2 ; + Misses 2871 2869 -2 ; ```. [see 1 file with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3294/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3294#issuecomment-2421880018:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3294#issuecomment-2421880018,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3295?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.04%. Comparing base [(`bbcd4b1`)](https://app.codecov.io/gh/scverse/scanpy/commit/bbcd4b173aabebb8b4793cf2cdd6ea8b31e31005?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`4eba4a8`)](https://app.codecov.io/gh/scverse/scanpy/commit/4eba4a84d5a6726a01ef7ca07d4397220ca59c33?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3295 +/- ##; ==========================================; + Coverage 76.95% 77.04% +0.09% ; ==========================================; Files 109 110 +1 ; Lines 12465 12494 +29 ; ==========================================; + Hits 9592 9626 +34 ; + Misses 2873 2868 -5 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3295?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/tools/\_umap.py](https://app.codecov.io/gh/scverse/scanpy/pull/3295?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_umap.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fdW1hcC5weQ==) | `74.19% <100.00%> (+2.52%)` | :arrow_up: |. ... and [4 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3295/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3295#issuecomment-2421946619:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3295#issuecomment-2421946619,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3296?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.01%. Comparing base [(`f28c8c6`)](https://app.codecov.io/gh/scverse/scanpy/commit/f28c8c662c928332b7bb19d1576d7b6d975e6f93?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`028a680`)](https://app.codecov.io/gh/scverse/scanpy/commit/028a6808fcfde015e02da6ba73f6f68678978dfd?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3296 +/- ##; ==========================================; - Coverage 77.03% 77.01% -0.02% ; ==========================================; Files 110 110 ; Lines 12492 12492 ; ==========================================; - Hits 9623 9621 -2 ; - Misses 2869 2871 +2 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3296?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_pca/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3296?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_pca%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19wY2EvX19pbml0X18ucHk=) | `90.10% <100.00%> (-1.10%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3296#issuecomment-2422558709:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3296#issuecomment-2422558709,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3298?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.18%. Comparing base [(`bae1610`)](https://app.codecov.io/gh/scverse/scanpy/commit/bae1610ab2d54213eba5ff2879c6b6f4e2761342?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`9231258`)](https://app.codecov.io/gh/scverse/scanpy/commit/9231258f9eb6356f0f907fbc43a2bef56dc39e45?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 3 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3298 +/- ##; =======================================; Coverage 77.18% 77.18% ; =======================================; Files 111 111 ; Lines 12582 12582 ; =======================================; Hits 9711 9711 ; Misses 2871 2871 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3298?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/readwrite.py](https://app.codecov.io/gh/scverse/scanpy/pull/3298?src=pr&el=tree&filepath=src%2Fscanpy%2Freadwrite.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9yZWFkd3JpdGUucHk=) | `77.75% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3298#issuecomment-2426094471:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3298#issuecomment-2426094471,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3299?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.21%. Comparing base [(`bae1610`)](https://app.codecov.io/gh/scverse/scanpy/commit/bae1610ab2d54213eba5ff2879c6b6f4e2761342?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`70ba5cf`)](https://app.codecov.io/gh/scverse/scanpy/commit/70ba5cff67021c3881488a63c16054900690e3b4?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3299 +/- ##; ==========================================; + Coverage 77.18% 77.21% +0.02% ; ==========================================; Files 111 111 ; Lines 12582 12594 +12 ; ==========================================; + Hits 9711 9724 +13 ; + Misses 2871 2870 -1 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3299?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3299?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYW5uZGF0YS5weQ==) | `85.58% <100.00%> (+0.16%)` | :arrow_up: |. ... and [2 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3299/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3299#issuecomment-2426253357:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3299#issuecomment-2426253357,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3301?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.94%. Comparing base [(`4591f0d`)](https://app.codecov.io/gh/scverse/scanpy/commit/4591f0dcf9c9bbde35e41d6d4ebf169b7bd8b98a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`019eb72`)](https://app.codecov.io/gh/scverse/scanpy/commit/019eb723d7c194392ebca272f4103f6ff686e756?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3301 +/- ##; ==========================================; + Coverage 76.91% 76.94% +0.02% ; ==========================================; Files 109 109 ; Lines 12451 12462 +11 ; ==========================================; + Hits 9577 9589 +12 ; + Misses 2874 2873 -1 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3301?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3301?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYW5uZGF0YS5weQ==) | `85.61% <100.00%> (+0.16%)` | :arrow_up: |. ... and [1 file with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3301/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3301#issuecomment-2426936271:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3301#issuecomment-2426936271,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3302?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.21%. Comparing base [(`f0b8d6b`)](https://app.codecov.io/gh/scverse/scanpy/commit/f0b8d6bc491ac85d31e81e9c469bbf10aecbf55f?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`c0acca0`)](https://app.codecov.io/gh/scverse/scanpy/commit/c0acca0417cb95a4e71a5352f3363af434cabc8f?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 4 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3302 +/- ##; =======================================; Coverage 77.21% 77.21% ; =======================================; Files 111 111 ; Lines 12594 12594 ; =======================================; Hits 9724 9724 ; Misses 2870 2870 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3302?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/plotting/\_qc.py](https://app.codecov.io/gh/scverse/scanpy/pull/3302?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_qc.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fcWMucHk=) | `86.84% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3302#issuecomment-2427039678:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3302#issuecomment-2427039678,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3304?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.94%. Comparing base [(`4d26104`)](https://app.codecov.io/gh/scverse/scanpy/commit/4d26104fe2eec3e69d71cec4cc5d9422c9d21463?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a6a0fa4`)](https://app.codecov.io/gh/scverse/scanpy/commit/a6a0fa4b1215de708c5f10360256cef18be8dc1c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3304 +/- ##; =======================================; Coverage 76.94% 76.94% ; =======================================; Files 109 109 ; Lines 12462 12462 ; =======================================; Hits 9589 9589 ; Misses 2873 2873 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3304?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/readwrite.py](https://app.codecov.io/gh/scverse/scanpy/pull/3304?src=pr&el=tree&filepath=src%2Fscanpy%2Freadwrite.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9yZWFkd3JpdGUucHk=) | `77.75% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3304#issuecomment-2428708791:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3304#issuecomment-2428708791,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3305?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.94%. Comparing base [(`f13ce9e`)](https://app.codecov.io/gh/scverse/scanpy/commit/f13ce9e7002223a139ebe43ccaefd4c51dc15ac5?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`b51d5a8`)](https://app.codecov.io/gh/scverse/scanpy/commit/b51d5a85d42256f7c7d91e8a5067c8b6c5e494a5?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3305 +/- ##; =======================================; Coverage 76.94% 76.94% ; =======================================; Files 109 109 ; Lines 12462 12462 ; =======================================; Hits 9589 9589 ; Misses 2873 2873 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3305#issuecomment-2429099834:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3305#issuecomment-2429099834,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3306?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.22%. Comparing base [(`b73fb59`)](https://app.codecov.io/gh/scverse/scanpy/commit/b73fb59253bf7b1933e4073acca0837de2be09ca?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7ceef70`)](https://app.codecov.io/gh/scverse/scanpy/commit/7ceef70cd1c13e5bb55d7152f1766e15f2a7703f?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3306 +/- ##; ==========================================; + Coverage 77.21% 77.22% +0.01% ; ==========================================; Files 111 111 ; Lines 12594 12600 +6 ; ==========================================; + Hits 9724 9730 +6 ; Misses 2870 2870 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3306?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_pca/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3306?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_pca%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19wY2EvX19pbml0X18ucHk=) | `90.81% <ø> (ø)` | |; | [src/scanpy/preprocessing/\_pca/\_dask\_sparse.py](https://app.codecov.io/gh/scverse/scanpy/pull/3306?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_pca%2F_dask_sparse.py&utm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3306#issuecomment-2429123156:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3306#issuecomment-2429123156,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3308?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.94%. Comparing base [(`ef0bda8`)](https://app.codecov.io/gh/scverse/scanpy/commit/ef0bda889b7ef5b4cd24ea208e2212f7163d5fe1?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a9bd6b4`)](https://app.codecov.io/gh/scverse/scanpy/commit/a9bd6b4e7420ab5ec22d684e0e5de9be97728f87?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3308 +/- ##; =======================================; Coverage 76.94% 76.94% ; =======================================; Files 109 109 ; Lines 12462 12462 ; =======================================; Hits 9589 9589 ; Misses 2873 2873 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3308?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/plotting/\_qc.py](https://app.codecov.io/gh/scverse/scanpy/pull/3308?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_qc.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fcWMucHk=) | `86.84% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3308#issuecomment-2429412524:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3308#issuecomment-2429412524,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3311?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.22%. Comparing base [(`39c6532`)](https://app.codecov.io/gh/scverse/scanpy/commit/39c6532d276ca83cc0548546c3d73ebee6eec0c1?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`728e877`)](https://app.codecov.io/gh/scverse/scanpy/commit/728e87723571a7e1dfbf9b38af76ae598e122542?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3311 +/- ##; =======================================; Coverage 77.22% 77.22% ; =======================================; Files 111 111 ; Lines 12600 12600 ; =======================================; Hits 9730 9730 ; Misses 2870 2870 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3311?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_combat.py](https://app.codecov.io/gh/scverse/scanpy/pull/3311?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_combat.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19jb21iYXQucHk=) | `91.47% <ø> (ø)` | |; | [src/scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3311?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_conte,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3311#issuecomment-2432886734:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3311#issuecomment-2432886734,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3312?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.94%. Comparing base [(`f2281dd`)](https://app.codecov.io/gh/scverse/scanpy/commit/f2281ddb5c9e51ad2eb2153410a5d61e967b4bac?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`1f9bb40`)](https://app.codecov.io/gh/scverse/scanpy/commit/1f9bb40fc36c337d89a5f41c864aa999bb3fa276?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3312 +/- ##; =======================================; Coverage 76.94% 76.94% ; =======================================; Files 109 109 ; Lines 12462 12462 ; =======================================; Hits 9589 9589 ; Misses 2873 2873 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3312?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_combat.py](https://app.codecov.io/gh/scverse/scanpy/pull/3312?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_combat.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19jb21iYXQucHk=) | `91.47% <ø> (ø)` | |; | [src/scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3312?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_c,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3312#issuecomment-2433160774:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3312#issuecomment-2433160774,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3315?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.23%. Comparing base [(`3d220a9`)](https://app.codecov.io/gh/scverse/scanpy/commit/3d220a93c83fdd60ee3220c94db3dd8d5533c60d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`9a72e2a`)](https://app.codecov.io/gh/scverse/scanpy/commit/9a72e2a08c747d14000fa43fccad9c0e4e7ce02e?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3315 +/- ##; =======================================; Coverage 77.23% 77.23% ; =======================================; Files 111 111 ; Lines 12605 12605 ; =======================================; Hits 9735 9735 ; Misses 2870 2870 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3315?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/3315?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zaW1wbGUucHk=) | `90.77% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3315#issuecomment-2435176566:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3315#issuecomment-2435176566,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3319?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.23%. Comparing base [(`8e64165`)](https://app.codecov.io/gh/scverse/scanpy/commit/8e6416570d421a5da2862541690e17e0647dc683?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`1909f4c`)](https://app.codecov.io/gh/scverse/scanpy/commit/1909f4c3d4f478c4cfcf406899029e184fefdef0?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 3 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3319 +/- ##; =======================================; Coverage 77.22% 77.23% ; =======================================; Files 111 111 ; Lines 12600 12605 +5 ; =======================================; + Hits 9730 9735 +5 ; Misses 2870 2870 ; ```. [see 1 file with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3319/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3319#issuecomment-2435756098:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3319#issuecomment-2435756098,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3321?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.23%. Comparing base [(`3d220a9`)](https://app.codecov.io/gh/scverse/scanpy/commit/3d220a93c83fdd60ee3220c94db3dd8d5533c60d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`c1ff8d7`)](https://app.codecov.io/gh/scverse/scanpy/commit/c1ff8d78ce5e65051179596d8c5cf62be4ec51e5?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3321 +/- ##; =======================================; Coverage 77.23% 77.23% ; =======================================; Files 111 111 ; Lines 12605 12605 ; =======================================; Hits 9735 9735 ; Misses 2870 2870 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3321?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3321?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYW5uZGF0YS5weQ==) | `85.58% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3321#issuecomment-2437169224:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3321#issuecomment-2437169224,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3324?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.21%. Comparing base [(`2f0afac`)](https://app.codecov.io/gh/scverse/scanpy/commit/2f0afac72be3644624cf996323197239580f14f9?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`5bb0363`)](https://app.codecov.io/gh/scverse/scanpy/commit/5bb03631c833220df29c286d76c5412469063963?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 3 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3324 +/- ##; =======================================; Coverage 77.21% 77.21% ; =======================================; Files 111 111 ; Lines 12597 12597 ; =======================================; Hits 9727 9727 ; Misses 2870 2870 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3324?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/plotting/\_qc.py](https://app.codecov.io/gh/scverse/scanpy/pull/3324?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_qc.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fcWMucHk=) | `86.84% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3324#issuecomment-2437731519:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3324#issuecomment-2437731519,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3328?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.24%. Comparing base [(`60d30a4`)](https://app.codecov.io/gh/scverse/scanpy/commit/60d30a40de65b4e9dacb9578f074f9e8565621dc?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a0eb18d`)](https://app.codecov.io/gh/scverse/scanpy/commit/a0eb18da26a491f88156100f94ce491e20968b25?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3328 +/- ##; ==========================================; + Coverage 77.21% 77.24% +0.03% ; ==========================================; Files 111 111 ; Lines 12597 12610 +13 ; ==========================================; + Hits 9727 9741 +14 ; + Misses 2870 2869 -1 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3328?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3328?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | `75.51% <ø> (ø)` | |; | [src/scanpy/get/get.py](https://app.codecov.io/gh/scverse/scanpy/pull/3328?src=pr&el=tree&filepath=src%2Fscanpy%2Fget%2Fget.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3328#issuecomment-2449886093:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3328#issuecomment-2449886093,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3329?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.22%. Comparing base [(`a22997e`)](https://app.codecov.io/gh/scverse/scanpy/commit/a22997e106d0e7ff944967613d71c2d41d0da89a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3a81e04`)](https://app.codecov.io/gh/scverse/scanpy/commit/3a81e04ec599c05e4c8cb58848b5359b9b541dd7?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3329 +/- ##; =======================================; Coverage 77.22% 77.22% ; =======================================; Files 111 111 ; Lines 12601 12601 ; =======================================; Hits 9731 9731 ; Misses 2870 2870 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3329#issuecomment-2455437886:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3329#issuecomment-2455437886,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3334?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.94%. Comparing base [(`7df4ee8`)](https://app.codecov.io/gh/scverse/scanpy/commit/7df4ee85c308de4e15a819aa251da29e92515519?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`915795f`)](https://app.codecov.io/gh/scverse/scanpy/commit/915795f7385c211f9bbfdee07723b50ac5f22a77?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3334 +/- ##; =======================================; Coverage 76.94% 76.94% ; =======================================; Files 109 109 ; Lines 12459 12463 +4 ; =======================================; + Hits 9586 9590 +4 ; Misses 2873 2873 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3334?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3334?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | `75.41% <ø> (ø)` | |; | [src/scanpy/get/get.py](https://app.codecov.io/gh/scverse/scanpy/pull/3334?src=pr&el=tree&filepath=src%2Fscanpy%2Fget%2Fget.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3N,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3334#issuecomment-2450010617:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3334#issuecomment-2450010617,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3337?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 77.22%. Comparing base [(`a22997e`)](https://app.codecov.io/gh/scverse/scanpy/commit/a22997e106d0e7ff944967613d71c2d41d0da89a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`5647152`)](https://app.codecov.io/gh/scverse/scanpy/commit/5647152125b020dc79c02a38f2adaee024bdd3dc?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3337 +/- ##; =======================================; Coverage 77.22% 77.22% ; =======================================; Files 111 111 ; Lines 12601 12601 ; =======================================; Hits 9731 9731 ; Misses 2870 2870 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3337#issuecomment-2455217190:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3337#issuecomment-2455217190,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3338?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 76.74%. Comparing base [(`c7a24e6`)](https://app.codecov.io/gh/scverse/scanpy/commit/c7a24e65b2af395d841d99c2307367c8ea68560d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`ceff4f3`)](https://app.codecov.io/gh/scverse/scanpy/commit/ceff4f3f071b9c9ef42a29e6fe5039dffe07ec74?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3338 +/- ##; ==========================================; - Coverage 76.94% 76.74% -0.21% ; ==========================================; Files 109 109 ; Lines 12463 12463 ; ==========================================; - Hits 9590 9565 -25 ; - Misses 2873 2898 +25 ; ```. [see 10 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3338/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3338#issuecomment-2456495375:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3338#issuecomment-2456495375,1,['test'],['tests']
Testability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/624?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`86b85ee`)](https://app.codecov.io/gh/scverse/scanpy/commit/86b85ee2f4e8acfc9db3ce4cfff6e905d96a59eb?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72% compared to head [(`f233d75`)](https://app.codecov.io/gh/scverse/scanpy/pull/624?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #624 +/- ##; =======================================; Coverage 72.72% 72.72% ; =======================================; Files 111 111 ; Lines 12384 12384 ; =======================================; Hits 9006 9006 ; Misses 3378 3378 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `96.17% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/624#issuecomment-1900349804:233,test,tests,233,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/624#issuecomment-1900349804,1,['test'],['tests']
Testability,"## `X`. So, the first and third result have the same values of `X`. . ```python; assert np.array_equal(pc1.X, pc3.X); ```. The second is only slightly different:. ```python; diff = pc2.X - pc1.X; diff[diff != 0]; ```. ```; array([7.450581e-09], dtype=float32); ```. This might be adjustable by setting ""regress out"" to a fixed number of jobs. ## PCA. The results of the PCA differ more significantly, but here you should just be calling scikit-learn's implementation. Could you try calling that directly and letting us know the results?. E.g. ```python; from sklearn.decomposition import PCA. pca = PCA(n_components=50, solver=""arpack"", random_state=0); result = pca.fit_transform(adata.X); ```. If this doesn't give consistent results on your machines, the issue is upstream in scikit-learn. If you need reproducibility now, I would suggest switching out the solver for the PCA and/ or using 64 bit values for `X`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021048765:81,assert,assert,81,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021048765,1,['assert'],['assert']
Testability,"### Test failures as of d36b977fa0c85d67b96799da4cb86b8582868048. Significantly improved!. 56 failed, 1236 passed, 96 skipped, 19 xfailed, 9 xpassed, 763 warnings in 595.02s (0:09:55). Remaining errors include:. * A lot of `AssertionError: Error: Image files did not match.`; * Some missing function from scipy; * Missing pynndescent; * 3 or 4 more unique ones. <details>; <summary> </summary>. ```python; FAILED scanpy/get/get.py::scanpy.get.get.obs_df; FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_metrics.py::test_consistency[morans_i-allclose] - AssertionError: ; FAILED scanpy/tests/test_paga.py::test_paga_plots[-paga] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:4,Test,Test,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,10,"['Assert', 'Test', 'test']","['AssertionError', 'Test', 'tests']"
Testability,%> (-0.16%)` | :arrow_down: |; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `95.61% <100.00%> (+0.03%)` | :arrow_up: |; | [scanpy/preprocessing/\_pca.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3BjYS5weQ==) | `93.25% <100.00%> (+0.11%)` | :arrow_up: |; | [scanpy/testing/\_helpers/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `87.87% <100.00%> (+1.67%)` | :arrow_up: |; | [scanpy/testing/\_pytest/params.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9wYXJhbXMucHk=) | `100.00% <100.00%> (ø)` | |; | ... and [2 more](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | |. ... and [5 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2816/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895706976:3972,test,testing,3972,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895706976,1,['test'],['testing']
Testability,&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `67.20% <100.00%> (+0.35%)` | :arrow_up: |; | [scanpy/external/pl.py](https://app.codecov.io/gh/scverse/scanpy/pull/2703?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3BsLnB5) | `32.63% <100.00%> (-17.74%)` | :arrow_down: |; | [scanpy/external/pp/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2703?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3BwL19faW5pdF9fLnB5) | `100.00% <100.00%> (ø)` | |; | [scanpy/get/get.py](https://app.codecov.io/gh/scverse/scanpy/pull/2703?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9nZXQucHk=) | `92.59% <ø> (ø)` | |; | [scanpy/logging.py](https://app.codecov.io/gh/scverse/scanpy/pull/2703?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `95.12% <ø> (ø)` | |; | [scanpy/neighbors/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2703?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L25laWdoYm9ycy9fX2luaXRfXy5weQ==) | `80.75% <100.00%> (+3.28%)` | :arrow_up: |; | [scanpy/neighbors/\_common.py](https://app.codecov.io/gh/scverse/scanpy/pull/2703?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L25laWdoYm9ycy9fY29tbW9uLnB5) | `64.91% <100.00%> (ø)` | |; | [scanpy/neighbors/\_types.py](https://app.codecov.io/gh/scverse/scanpy/pull/2703?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2703#issuecomment-1775039451:2451,log,logging,2451,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2703#issuecomment-1775039451,1,['log'],['logging']
Testability,"'m not a big fan of trying 5 clustering algorithms to produce sensible results. Either a given representation of the data clusters clearly or it doesn't. If it doesn't, Louvain clustering just gives you one possible, representative partitioning of the data. But there are many others that are equally meaningful. Similar for other graph clustering algorithms. Now, running Louvain clustering on a fully connected graph is prohibitive computationally (memory and CPU time wise).; > Intuitively, I'd think having a more complete graph with weighted edges is more representative of the data than an arbitrary k neighbors. Even if you do use a hard cutoff on number of neighbors, I don't see how discounting all distance information would give a more accurate result. I would suspect using a weighted graph could perform better at identifying small subpopulations (where nearest neighbors from other cell types could be common), but that's just conjecture. That's just speculation to me. I never saw convincing benchmarks. No one claims that ""discounting all distance information gives a more accurate result"". It's just that it's computationally cheaper. I acknowledge that a ""non-fixed-degree knn graph"" varying say, between 5 and 100, would be computationally tractable and would carry information about the sampling density of the data in the given representation. This information is only indirectly available in the fixed-degree knn graph (more loops etc. in high-density regions). I never investigated this as I never saw fundamental results on such a non-fixed-degree knn graph. As it's also hard to benchmark this, I'd be afraid of getting into this if one doesn't have the time to get the fundamentals right. I want to note that even in the context of diffusion processes, we managed to obtain meaningful results with kNN graphs in practice. And this clearly contradicts the fundamental results found in all the Coifman papers. Having said that: if the code is simple, I don't mind at all to hav",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-416725777:1521,benchmark,benchmarks,1521,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/240#issuecomment-416725777,1,['benchmark'],['benchmarks']
Testability,'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/work,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67551,test,testing,67551,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/wo,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64613,test,testing,64613,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74105,test,testing,74105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/work,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68211,test,testing,68211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64436,test,testing,64436,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,"'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ============== 252 failed, 650 passed, 59 skipped, 5 xfailed, 1038 warnings, 128 errors in 451.20s (0:07:31) ===============. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:75093,test,testing,75093,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/work,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61005,test,testing,61005,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,"(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:59: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; 12 warnings and 3 errors generated.; error: command '/usr/bin/clang' failed with exit code 1; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; WARNING: No metadata found in /Users/test/.local/lib/python3.10/site-packages; Rolling back uninstall of fa2; Moving to /Users/test/.local/lib/python3.10/site-packages/fa2-0.3.5.dist-info/; from /Users/test/.local/lib/python3.10/site-packages/~a2-0.3.5.dist-info; Moving to /Users/test/.local/lib/python3.10/site-packages/fa2/; from /Users/test/.local/lib/python3.10/site-packages/~a2; error: legacy-install-failure. × Encountered error while trying to install package.; ╰─> fa2. note: This is an issue with the package mentioned above, not pip.; hint: See above for output from the failure.; test@mac ~/PythonPackages/forceatlas2-0.3.5$; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:30151,test,test,30151,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,6,['test'],['test']
Testability,(https://app.codecov.io/gh/scverse/scanpy/pull/2810?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.70%.; > Report is 1 commits behind head on master. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2810 +/- ##; ==========================================; - Coverage 72.84% 72.70% -0.14% ; ==========================================; Files 111 111 ; Lines 12368 12368 ; ==========================================; - Hits 9009 8992 -17 ; - Misses 3359 3376 +17 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2810?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/experimental/pp/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2810?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4cGVyaW1lbnRhbC9wcC9faGlnaGx5X3ZhcmlhYmxlX2dlbmVzLnB5) | `63.46% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/fixtures/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2810?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9kYXRhLnB5) | `100.00% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2810?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `96.17% <90.47%> (ø)` | |. ... and [1 file with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2810/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2810#issuecomment-1892337785:1672,test,testing,1672,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2810#issuecomment-1892337785,1,['test'],['testing']
Testability,(https://app.codecov.io/gh/scverse/scanpy/pull/2811?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.37%.; > Report is 1 commits behind head on master. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2811 +/- ##; ==========================================; - Coverage 72.70% 72.37% -0.34% ; ==========================================; Files 111 111 ; Lines 12368 12368 ; ==========================================; - Hits 8992 8951 -41 ; - Misses 3376 3417 +41 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2811?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/experimental/pp/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2811?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4cGVyaW1lbnRhbC9wcC9faGlnaGx5X3ZhcmlhYmxlX2dlbmVzLnB5) | `63.46% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/fixtures/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2811?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9kYXRhLnB5) | `100.00% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2811?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `96.17% <90.47%> (ø)` | |. ... and [1 file with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2811/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2811#issuecomment-1893455599:1672,test,testing,1672,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2811#issuecomment-1893455599,1,['test'],['testing']
Testability,(step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_violin_without_raw - numpy.core._exceptions._U,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:43996,test,tests,43996,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"); Requirement already satisfied: numexpr>=2.6.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (2.8.1); Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from packaging->tables) (3.0.4). import tables. ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/574719567.py in <module>; ----> 1 import tables. ~\.conda\envs\NewPy38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsextension import get_hdf5_version as _get_hdf5_version; 46 ; 47 . ImportError: DLL load failed while importing utilsextension; ```; Step 3: As you recommend, I do `!pip uninstall tables` and `conda install -c conda-forge pytables`, then; ```python; import tables # pass. import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_15024/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 4 ; 5 if not within_flit(): # see function docstring on why this is there; ----> 6 from ._utils import check_versions; 7 ; 8 check_versions(). ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\__init__.py in <module>; 19 from numpy import random; 20 from scipy import sparse; ---> 21 from anndata import AnnData, __version__ as anndata_version; 22 from textwrap import dedent; 23 from packaging import version. ~\.conda\envs\NewPy38\lib\site-packages\anndata\__init__.py in <module>; 5 if not within_flit():; 6 del within_flit; ----> 7 from ._core.anndata import AnnData, ImplicitModificationWarning; 8 from ._core.merge impo",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:3801,log,logging,3801,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841,1,['log'],['logging']
Testability,)` | |; | [scanpy/datasets/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3047?src=pr&el=tree&filepath=scanpy%2Fdatasets%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2RhdGFzZXRzL191dGlscy5weQ==) | `100.00% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3047?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3V0aWxzLnB5) | `92.10% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/fixtures/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/3047?src=pr&el=tree&filepath=scanpy%2Ftesting%2F_pytest%2Ffixtures%2Fdata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9kYXRhLnB5) | `100.00% <ø> (ø)` | |; | [scanpy/testing/\_pytest/marks.py](https://app.codecov.io/gh/scverse/scanpy/pull/3047?src=pr&el=tree&filepath=scanpy%2Ftesting%2F_pytest%2Fmarks.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `100.00% <100.00%> (ø)` | |; | [scanpy/tools/\_ingest.py](https://app.codecov.io/gh/scverse/scanpy/pull/3047?src=pr&el=tree&filepath=scanpy%2Ftools%2F_ingest.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19pbmdlc3QucHk=) | `77.23% <100.00%> (ø)` | |; | [scanpy/tools/\_tsne.py](https://app.codecov.io/gh/scverse/scanpy/pull/3047?src=pr&el=tree&filepath=scanpy%2Ftools%2F_tsne.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL190c25lLnB5) | `93.02% <100.00%> (ø)` | |; | [scanpy/external/pp/\_magic.py](https://app.codecov.io/gh/scverse/scanpy/pull/30,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3047#issuecomment-2097731381:2710,test,testing,2710,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047#issuecomment-2097731381,1,['test'],['testing']
Testability,"* I think it fits the standard tutorial, I calculate these things all the time. All the tutorials are in the [`scanpy_usage`](https://github.com/theislab/scanpy_usage) repo, right?; * Do you mean the `top_segment_proportions` and/ or `top_proportions` functions?. ## Sparse matrix support. I took the easy way out for calculations on other sparse matrices types – just converted them to a `CSR` – so there's room for improvement. I'm considering writing a more involved implementation, but I'd have to benchmark it against conversion. . I'd probably try an online sort (insertion?) for each cell, keeping only the top `max(ns)` expression values, while iterating through the `COO` or `CSC` matrix. ## Numba. This currently throws a lot of warnings about `np.partition` not being implemented in `numba`. This should change with their next release, and give some speedup here. ## `cell_controls`. I'm trying to decide on including this. I haven't used data with control wells, so I don't know how common it is. It could be nice to implement it a bit differently, and have able to get something like`.var[""mean_counts_in_sampletype-CD8""]`, but I'm already returning a lot of values. Any thoughts?. ## f-strings. Just noticed this is why my builds are failing. This might get ugly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/316#issuecomment-432531663:502,benchmark,benchmark,502,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316#issuecomment-432531663,1,['benchmark'],['benchmark']
Testability,"**Tests**. For the present changes, these tests are sufficient. Only since recently, Scanpy is becoming properly tested via the example notebooks (previously, I always ran everything manually). So, if you want to test this properly, come up with an interesting use case that uses clustering on weighted graphs, make a pull request for a notebook on `theislab/scanpy_usage`, link to it in the docs (https://scanpy.readthedocs.io/en/latest/examples.html) and commit a corresponding test in `tests/notebooks`. That's a lot of work and I think too much for this present case. Eventually, most of Scanpy's functionality should be tested this way. A lot will also be covered by extending existing notebooks. But I don't think it's possible to meaningfully add the weighted graphs to the present standard Louvain clustering example. **Multiple network representations**. I don't mind as long as the standard user still uses a single one - otherwise people will get confused. But let's not call these grahs ""networks"". The notion ""network"" suggests that nodes ""interact"". The current graphs in Scanpy, however, are all proxies for manifolds. Edges only represent similarity and, through that, have a topological interpretation. I'd really like to reserve the notion ""network"" for cases where nodes possibly or actually interact. Hence, a gene regulatory network or a network of cells with cell-cell interactions. Both are completely different things compared to the ""neighbors"" stuff in Scanpy. **Allow more choice of partition method for louvain-igraph package**. Fine for me as long as the default stays unchanged. I'm not sure whether it adds a lot of value but it will also not be harmful. ---. Could you also fix the docs for the `flavor` parameter and specify the default? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248#issuecomment-418079395:2,Test,Tests,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248#issuecomment-418079395,7,"['Test', 'test']","['Tests', 'test', 'tested', 'tests']"
Testability,+comments&utm_term=scverse#diff-c2NhbnB5L2RhdGFzZXRzL19lYmlfZXhwcmVzc2lvbl9hdGxhcy5weQ==) | `90.36% <100.00%> (ø)` | |; | [scanpy/external/pp/\_bbknn.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3BwL19iYmtubi5weQ==) | `50.00% <ø> (+3.84%)` | :arrow_up: |; | [scanpy/external/pp/\_hashsolo.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3BwL19oYXNoc29sby5weQ==) | `89.56% <ø> (+0.67%)` | :arrow_up: |; | [scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3NpbXBsZS5weQ==) | `82.81% <ø> (+0.54%)` | :arrow_up: |; | [scanpy/testing/\_helpers/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvZGF0YS5weQ==) | `89.47% <100.00%> (+2.98%)` | :arrow_up: |; | [scanpy/tools/\_rank\_genes\_groups.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19yYW5rX2dlbmVzX2dyb3Vwcy5weQ==) | `94.30% <100.00%> (+0.78%)` | :arrow_up: |; | [scanpy/readwrite.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3JlYWR3cml0ZS5weQ==) | `67.95% <0.00%> (-0.08%)` | :arrow_down: |; | [scanpy/testing/\_pytest/fixtures/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_med,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2779#issuecomment-1846869505:2460,test,testing,2460,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2779#issuecomment-1846869505,1,['test'],['testing']
Testability,", groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. I've pasted the output of scanpy.logging.print_versions() details below as requested, which includes a verification of used scanpy version (latest version, 1.9.3). It may not be important, but I also had to install `leidenalg` manually in the middle of the tutorial. That's the only deviation I made from the original tutorial. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; h5py 3.9.0; igraph 0.10.6; ipykernel 6.25.0; jedi 0.18.2; joblib 1.3.1; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 23.1; pandas 2.0.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.9.1; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:1946,log,log,1946,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453,1,['log'],['log']
Testability,"- numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.on_data-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.off-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_get.py::test_var_df - AssertionError: Attributes of DataFrame.iloc[:, 0] (column name=""cell2"") are different; FAILED scanpy/tests/test_get.py::test_repeated_index_vals[var_df] - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.on_right-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.off-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.False-legend.on_data-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loo",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:6244,Assert,AssertionError,6244,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Assert'],['AssertionError']
Testability,- numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plottin,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47972,test,tests,47972,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,-12.3-x86_64-3.10; creating build/temp.macosx-12.3-x86_64-3.10/fa2; clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Users/test/.pyenv/versions/3.10.3/include/python3.10 -c fa2/fa2util.c -o build/temp.macosx-12.3-x86_64-3.10/fa2/fa2util.o; fa2/fa2util.c:10939:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Node.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10947:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Edge.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10960:35: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Region.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:12133:22: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:22: warning: 'PyUnicode_AsUnicode' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Use,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:6383,test,test,6383,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['test'],['test']
Testability,-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_nor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3997,test,tests,3997,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['test'],['tests']
Testability,-200n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytec,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:42808,test,tests,42808,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_data-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-100theta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:37135,test,tests,37135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"-a34c-11ea-9ec0-2057301ae4fc.png). ![image](https://user-images.githubusercontent.com/20694664/83360065-74c30000-a34c-11ea-9e0b-d28cea53993e.png). ![image](https://user-images.githubusercontent.com/20694664/83360079-84dadf80-a34c-11ea-9026-4256d8a3199b.png). I used a neutral word earlier: that CLR ""injects"" additional changes, but now it seems that may be a positive thing because many of these empirical cases seem believable from a biological standpoint -- a more systematic validation/comparison might conclude that it ""corrects"" some aspect of the signal acquisition (e.g. combats protein differences simply due to cell size). Again, this is because by design, CLR isn't just a rescaling: it performs cell-specific centering relative to all markers in a relative ratio way, so doesn't preserve a 1-to-1 monotonic mapping as a rescaling function like log, asinh, biexponential/logicle/vlog would. But without having tested it in all cases, it's not clear that it will *always* be better with this kind of assumption for other types of markers that may have different fundamental characteristics. I would recommend that people plot both ways and decide on a case-by-case basis for each marker. . EDIT: I looked around a bit more in the literature and do think that the absolute count based transforms (i.e. all the ones not the CLRatio based), do seem to represent physical reality more: cell size (as one explanation). For example, the CD4intermediate/CD3up_skewed include classical monocytes (and might be larger than the CD4negative/CD3negative); while the CD16high/CD3down_skewed include a nonclassical monocyte subset (and might be smaller cellsize, one example in mouse [Fig2](https://www.nature.com/articles/s41467-019-11843-0)). While CLR makes it easier for biologists to intuitively grasp ""negative/positive"" cell types for a particular marker without having to worry about subtle shifts in intensity (and therefore would be a better first transformation to more easily interpret data), ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-636513215:2164,test,tested,2164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117#issuecomment-636513215,1,['test'],['tested']
Testability,-forge; libffi 3.2.1 1 bioconda; libgfortran 4.0.0 h50e675f_13 conda-forge; libgfortran4 7.5.0 h50e675f_13 conda-forge; libglib 2.66.2 hdb5fb44_0 conda-forge; libiconv 1.16 haf1e3a3_0 conda-forge; liblapack 3.9.0 2_openblas conda-forge; libllvm10 10.0.1 h009f743_3 conda-forge; libnghttp2 1.41.0 h7580e61_2 conda-forge; libopenblas 0.3.12 openmp_h63d9170_1 conda-forge; libpng 1.6.37 hb0a8c7a_2 conda-forge; libpq 12.3 haa216e0_2 conda-forge; libsodium 1.0.18 haf1e3a3_1 conda-forge; libspatialindex 1.9.3 h4a8c4bd_3 conda-forge; libssh2 1.9.0 h39bdce6_5 conda-forge; libtiff 4.1.0 h2ae36a8_6 conda-forge; libwebp-base 1.1.0 h0b31af3_3 conda-forge; libxml2 2.9.10 h7fdee97_2 conda-forge; llvm-openmp 11.0.0 h73239a0_1 conda-forge; llvmlite 0.34.0 py38h3707e27_2 conda-forge; loompy 3.0.6 py_0 conda-forge; lz4-c 1.9.2 hb1e8313_3 conda-forge; markupsafe 1.1.1 py38h94c058a_2 conda-forge; matplotlib-base 3.3.2 py38had0acaf_1 conda-forge; mccabe 0.6.1 py_1 conda-forge; mistune 0.8.4 py38h4d0b108_1002 conda-forge; mock 4.0.2 py38h32f6830_1 conda-forge; mysql-common 8.0.21 2 conda-forge; mysql-libs 8.0.21 hfb8f7af_2 conda-forge; natsort 7.0.1 py_0 conda-forge; nbclient 0.5.1 py_0 conda-forge; nbconvert 6.0.7 py38h32f6830_2 conda-forge; nbformat 5.0.8 py_0 conda-forge; ncurses 6.2 hb1e8313_2 conda-forge; nest-asyncio 1.4.1 py_0 conda-forge; networkx 2.5 py_0 conda-forge; nspr 4.29 hb1e8313_1 conda-forge; nss 3.47 hcec2283_0 conda-forge; numba 0.51.2 py38h6be0db6_0 conda-forge; numexpr 2.7.1 py38h6be0db6_3 conda-forge; numpy 1.19.2 py38ha98150c_1 conda-forge; numpy_groupies 0.9.13 pyh9f0ad1d_1 conda-forge; numpydoc 1.1.0 py_1 conda-forge; olefile 0.46 pyh9f0ad1d_1 conda-forge; openssl 1.1.1h haf1e3a3_0 conda-forge; packaging 20.4 pyh9f0ad1d_0 conda-forge; pandas 1.1.3 py38h48ddb8e_2 conda-forge; pandoc 2.11.0.4 h22f3db7_0 conda-forge; pandocfilters 1.4.2 py_1 conda-forge; parso 0.7.0 pyh9f0ad1d_0 conda-forge; pathtools 0.1.2 py_1 conda-forge; patsy 0.5.1 py_0 conda-forge; pcre 8.44 hb1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-719504684:4409,mock,mock,4409,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-719504684,1,['mock'],['mock']
Testability,-func2] - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_paga.py::test_paga_plots[-paga] - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_paga.py::test_paga_plots[compare-func4] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_pie - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_paga.py::test_paga_plots[compare_pca-func6] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:40731,test,tests,40731,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambd,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4583,test,tests,4583,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['test'],['tests']
Testability,"-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/; Complete output (15 lines):; running bdist_wheel; /home/mischko/test/python_virtual/bin/python /tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py; LLVM version... 11.1.0; ; Traceback (most recent call last):; File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 181, in main; main_posix('linux', '.so'); File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 143, in main_posix; raise RuntimeError(msg); RuntimeError: Building llvmlite requires LLVM 10.0.x or 9.0.x, got '11.1.0'. Be sure to set LLVM_CONFIG to the right executable path.; Read the documentation at http://llvmlite.pydata.org/ for more information about building llvmlite.; ; error: command '/home/mischko/test/python_virtual/bin/python' failed with exit code 1; ; ERROR: Failed building wheel for llvmlite; ```. </details>. Any ideas about that?. When using **python 3.8** in a fresh new virtual environment, I get, installation of the development version works fine, but when importing scvelo. `Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/mischko/test/python_virtual/lib/python3.8/site-packages/scvelo/__init__.py"", line 5, in <module>; from scvelo import datasets, logging, pl, pp, settings, tl, utils; File ""/home/mischko/test/python_virtual/lib/python3.8/site-packages/scvelo/datasets.py"", line 10, in <module>; from scvelo.core import cleanup, SplicingDynamics; File ""/home/mischko/test/python_virtual/lib/python3.8/site-packages/scvelo/core/__init__.py"", line 1, in <module>; from ._anndata import (; File ""/home/mischko/test/python_virtual/lib/python3.8/site-packages/scvelo/core/_anndata.py"", line 4, in <module>; from typing_extensions import Literal; ModuleNotFoundError: No module named 't",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799#issuecomment-830137752:1939,test,test,1939,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799#issuecomment-830137752,1,['test'],['test']
Testability,"-legend.off-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_get.py::test_var_df - AssertionError: Attributes of DataFrame.iloc[:, 0] (column name=""cell2"") are different; FAILED scanpy/tests/test_get.py::test_repeated_index_vals[var_df] - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.on_right-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.off-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.False-legend.on_data-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.off-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_spatial_general - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categoric",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:6771,test,tests,6771,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,-legend.on_data-groups.3] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.True-legend.on_right-groups.all] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_visium_circles - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.on_data-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.off-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.True-legend.off-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.True-legend.off-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.off-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not co,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:3354,test,tests,3354,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"-legend.on_data-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.off-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_get.py::test_var_df - AssertionError: Attributes of DataFrame.iloc[:, 0] (column name=""cell2"") are different; FAILED scanpy/tests/test_get.py::test_repeated_index_vals[var_df] - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.on_right-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.off-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.False-legend.on_data-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.off-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:6496,test,tests,6496,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"-na_color.default-na_in_legend.True-legend.off-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.off-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_combat.py::test_combat_obs_names - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/test_get.py::test_obs_df - AssertionError: Attributes of DataFrame.iloc[:, 0] (column name=""gene2"") are different; FAILED scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.on_right-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.on_data-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.on_data-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_pl",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:4709,test,tests,4709,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"-na_in_legend.False-legend.on_data-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.on_data-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.off-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_get.py::test_var_df - AssertionError: Attributes of DataFrame.iloc[:, 0] (column name=""cell2"") are different; FAILED scanpy/tests/test_get.py::test_repeated_index_vals[var_df] - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.on_right-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.off-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.False-legend.on_data-groups.3] - numpy.core._exceptions._UFuncNoLo",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:6211,test,tests,6211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,-na_in_legend.True-legend.off-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.True-legend.on_data-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.default-na_in_legend.False-legend.on_data-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.True-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.default-na_in_legend.False-legend.on_data-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.default-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.default-na_in_legend.False-legend.on_right-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching ty,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:13297,test,tests,13297,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"-packages/anndata/compat.py in pkg_version(package); 56 try:; ---> 57 from importlib.metadata import version as v; 58 except ImportError:. ModuleNotFoundError: No module named 'importlib.metadata'. During handling of the above exception, another exception occurred:. ModuleNotFoundError Traceback (most recent call last); <ipython-input-11-495a6d84c058> in <module>; 1 import os; ----> 2 import scanpy as sc; 3 import numpy as np; 4 import pandas as pd; 5 import loompy as lp. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/__init__.py in <module>; 1 # some technical stuff; 2 import sys; ----> 3 from .utils import check_versions, annotate_doc_types; 4 from ._version import get_versions # version generated by versioneer; 5 . ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/utils.py in <module>; 17 from pandas.api.types import CategoricalDtype; 18 ; ---> 19 from ._settings import settings; 20 from . import logging as logg; 21 import warnings. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/_settings.py in <module>; 7 from typing import Tuple, Union, Any, List, Iterable, TextIO, Optional; 8 ; ----> 9 from . import logging; 10 from .logging import _set_log_level, _set_log_file, RootLogger; 11 . ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/logging.py in <module>; 7 from typing import Optional; 8 ; ----> 9 import anndata.logging; 10 ; 11 . ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/__init__.py in <module>; 93 from .compat import pkg_version; 94 ; ---> 95 __version__ = pkg_version(__name__); 96 del pkg_version. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/compat.py in pkg_version(package); 57 from importlib.metadata import version as v; 58 except ImportError:; ---> 59 from importlib_metadata import version as v; 60 return version.parse(v(package)); 61 . ModuleNotFoundError: No module named 'importlib_metadata'. And, when I try to install the module, it says that I already installed it. Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-611202845:2944,log,logging,2944,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-611202845,4,['log'],['logging']
Testability,". in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > that this takes long and is frustrating. If this is the case, just step; > away for a while and do something else! But I think you won’t regret doing; > this. You’re learning good coding practices here that will come in handy in; > the future, I promise!; >; > Thank you for your contribution 🎉; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGODHLQPIDWZGLGTKXGLPWJUZNA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVYG3VA#issuecomment-493907412>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOG73UUYPXGY7UICKODPWJUZNANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:1795,test,test,1795,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578,2,['test'],['test']
Testability,".); 768 **kwds,; 769 ):; 770 """"""\; 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`); 772 ; (...); 872 tl.rank_genes_groups; 873 """"""; --> 874 return _rank_genes_groups_plot(; 875 adata,; 876 plot_type='dotplot',; 877 groups=groups,; 878 n_genes=n_genes,; 879 groupby=groupby,; 880 values_to_plot=values_to_plot,; 881 var_names=var_names,; 882 gene_symbols=gene_symbols,; 883 key=key,; 884 min_logfoldchange=min_logfoldchange,; 885 show=show,; 886 save=save,; 887 return_fig=return_fig,; 888 **kwds,; 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 529 values_df = None; 530 if values_to_plot is not None:; --> 531 values_df = _get_values_to_plot(; 532 adata,; 533 values_to_plot,; 534 var_names_list,; 535 key=key,; 536 gene_symbols=gene_symbols,; 537 ); 538 title = values_to_plot; 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols); 1629 message = (; 1630 ""Please run `sc.tl.rank_genes_groups` with ""; 1631 ""'n_genes=adata.shape[1]' to save all gene ""; 1632 f""scores. Currently, only {df.shape[0]} ""; 1633 ""are found""; 1634 ); 1635 logg.error(message); -> 1636 raise ValueError(message); 1637 df['group'] = group; 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107618181:2678,log,logg,2678,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107618181,1,['log'],['logg']
Testability,...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - Impo,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69752,test,tests,69752,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - Im,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65663,test,tests,65663,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,..; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70885,test,tests,70885,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,..; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normal,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63526,test,tests,63526,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,..; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportErr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69418,test,tests,69418,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,.5/.gitignore; x forceatlas2-0.3.5/LICENSE; x forceatlas2-0.3.5/MANIFEST.in; x forceatlas2-0.3.5/README.md; x forceatlas2-0.3.5/examples/; x forceatlas2-0.3.5/examples/forceatlas2-layout.ipynb; x forceatlas2-0.3.5/examples/geometric_graph.png; x forceatlas2-0.3.5/examples/grid_graph.png; x forceatlas2-0.3.5/fa2/; x forceatlas2-0.3.5/fa2/__init__.py; x forceatlas2-0.3.5/fa2/fa2util.c; x forceatlas2-0.3.5/fa2/fa2util.pxd; x forceatlas2-0.3.5/fa2/fa2util.py; x forceatlas2-0.3.5/fa2/forceatlas2.py; x forceatlas2-0.3.5/setup.py; test@mac ~/PythonPackages$ cd forceatlas2-0.3.5/; test@mac ~/PythonPackages/forceatlas2-0.3.5$ pip3 install . --user; Processing /Users/test/PythonPackages/forceatlas2-0.3.5; Preparing metadata (setup.py) ... done; Requirement already satisfied: numpy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.21.5); Requirement already satisfied: scipy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.8.0); Requirement already satisfied: tqdm in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (4.63.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; error: subprocess-exited-with-error; ; × python setup.py bdist_wheel did not run successfully.; │ exit code: 1; ╰─> [214 lines of output]; Installing fa2 package (fastest forceatlas2 python implementation); ; >>>> Cython is installed?; Yes; ; >>>> Starting to install!; ; running bdist_wheel; running build; running build_py; creating build; creating build/lib.macosx-12.3-x86_64-3.10; creating build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/__init__.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/forceatlas2.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; running egg_info; creating fa2.egg-info; writing fa2.egg-info/PKG-INFO; writing dependency_links to fa2.egg-info/dependency_links.txt; writing requirements to fa2.egg-info/requires.txt;,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:3782,test,test,3782,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['test'],['test']
Testability,.; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61073,test,tests,61073,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:4226,Assert,AssertionError,4226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Assert'],['AssertionError']
Testability,".; ```; GSM3852752_E12_5_counts.tar.gz; GSM3852753_E13_5_counts.tar.gz; GSM3852754_E14_5_counts.tar.gz; GSM3852755_E15_5_counts.tar.gz; ```; Uncompress: ; ```; mkdir -p E12_5_counts/; tar zxvf GSM3852752_E12_5_counts.tar.gz --directory E12_5_counts/; mkdir -p E13_5_counts/; tar zxvf GSM3852753_E13_5_counts.tar.gz --directory E13_5_counts/; mkdir -p E14_5_counts/; tar zxvf GSM3852754_E14_5_counts.tar.gz --directory E14_5_counts/; mkdir -p E15_5_counts/; tar zxvf GSM3852755_E15_5_counts.tar.gz --directory E15_5_counts/; ```. Code:. ```; import numpy as np; import matplotlib.pyplot as pl; import numpy as np; import scanpy as sc; import scanpy.external as sce; import pandas as pd; from anndata import AnnData; import seaborn as sns; from scipy.sparse import csr_matrix; import networkx as nx; import xlsxwriter; from matplotlib import rcParams; import seaborn as sns; import scipy as sci; #GSEApy: Gene Set Enrichment Analysis in Python.; #import gseapy as gp; sc.settings.verbosity = 3; sc.logging.print_versions(). # Read cellranger files for all four samples; filename = './E12_5_counts/mm10/matrix.mtx'; filename_genes = './E12_5_counts/mm10/genes.tsv'; filename_barcodes = './E12_5_counts/mm10/barcodes.tsv'. e125 = sc.read(filename).transpose(); e125.var_names = np.genfromtxt(filename_genes, dtype=str)[:, 1]; e125.obs_names = np.genfromtxt(filename_barcodes, dtype=str). filename = './E13_5_counts/mm10/matrix.mtx'; filename_genes = './E13_5_counts/mm10/genes.tsv'; filename_barcodes = './E13_5_counts/mm10/barcodes.tsv'. e135 = sc.read(filename).transpose(); e135.var_names = np.genfromtxt(filename_genes, dtype=str)[:, 1]; e135.obs_names = np.genfromtxt(filename_barcodes, dtype=str). filename = './E14_5_counts/mm10/matrix.mtx'; filename_genes = './E14_5_counts/mm10/genes.tsv'; filename_barcodes = './E14_5_counts/mm10/barcodes.tsv'. e145 = sc.read(filename).transpose(); e145.var_names = np.genfromtxt(filename_genes, dtype=str)[:, 1]; e145.obs_names = np.genfromtxt(filename_barcod",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1409#issuecomment-694668315:1671,log,logging,1671,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1409#issuecomment-694668315,1,['log'],['logging']
Testability,".default-na_in_legend.True-legend.off-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.True-legend.off-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.off-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_combat.py::test_combat_obs_names - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/test_get.py::test_obs_df - AssertionError: Attributes of DataFrame.iloc[:, 0] (column name=""gene2"") are different; FAILED scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.on_right-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.False-legend.on_data-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_mi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:4432,test,tests,4432,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklea,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56179,test,tests,56179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/work,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60187,test,tests,60187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base',MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58521,test,tests,58521,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:71316,test,testing,71316,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,.off-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-200n-100theta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-200n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-200n-100theta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-200n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILE,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:16947,test,tests,16947,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2387,test,tests,2387,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['test'],['tests']
Testability,.py::test_scatterplots[pca-fn0] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_with_fonts-fn1] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_markers_colors_with_dimensions-fn10] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_mask-fn19] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:54710,test,tests,54710,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,.tar.gz’ saved [445420]. test@mac ~/PythonPackages$ tar xvf v0.3.5.tar.gz ; x forceatlas2-0.3.5/; x forceatlas2-0.3.5/.gitignore; x forceatlas2-0.3.5/LICENSE; x forceatlas2-0.3.5/MANIFEST.in; x forceatlas2-0.3.5/README.md; x forceatlas2-0.3.5/examples/; x forceatlas2-0.3.5/examples/forceatlas2-layout.ipynb; x forceatlas2-0.3.5/examples/geometric_graph.png; x forceatlas2-0.3.5/examples/grid_graph.png; x forceatlas2-0.3.5/fa2/; x forceatlas2-0.3.5/fa2/__init__.py; x forceatlas2-0.3.5/fa2/fa2util.c; x forceatlas2-0.3.5/fa2/fa2util.pxd; x forceatlas2-0.3.5/fa2/fa2util.py; x forceatlas2-0.3.5/fa2/forceatlas2.py; x forceatlas2-0.3.5/setup.py; test@mac ~/PythonPackages$ cd forceatlas2-0.3.5/; test@mac ~/PythonPackages/forceatlas2-0.3.5$ pip3 install . --user; Processing /Users/test/PythonPackages/forceatlas2-0.3.5; Preparing metadata (setup.py) ... done; Requirement already satisfied: numpy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.21.5); Requirement already satisfied: scipy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.8.0); Requirement already satisfied: tqdm in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (4.63.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; error: subprocess-exited-with-error; ; × python setup.py bdist_wheel did not run successfully.; │ exit code: 1; ╰─> [214 lines of output]; Installing fa2 package (fastest forceatlas2 python implementation); ; >>>> Cython is installed?; Yes; ; >>>> Starting to install!; ; running bdist_wheel; running build; running build_py; creating build; creating build/lib.macosx-12.3-x86_64-3.10; creating build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/__init__.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/forceatlas2.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; running egg_info; creating fa2.egg-info; writing fa2.egg-info/PKG-INFO;,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:3668,test,test,3668,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['test'],['test']
Testability,.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/sc,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64947,test,testing,64947,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/tes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:73185,test,tests,73185,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_me,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63029,test,tests,63029,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,/app.codecov.io/gh/scverse/scanpy/commit/edd613026cd5991baf92c8308b5ee2375089adc8?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (edd6130) will **increase** coverage by `0.03%`.; > The diff coverage is `88.46%`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2577 +/- ##; ==========================================; + Coverage 72.12% 72.16% +0.03% ; ==========================================; Files 104 105 +1 ; Lines 11688 11714 +26 ; ==========================================; + Hits 8430 8453 +23 ; - Misses 3258 3261 +3 ; ```. | [Files Changed](https://app.codecov.io/gh/scverse/scanpy/pull/2577?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/external/tl/\_palantir.py](https://app.codecov.io/gh/scverse/scanpy/pull/2577?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3RsL19wYWxhbnRpci5weQ==) | `22.58% <ø> (ø)` | |; | [scanpy/testing/\_pytest/marks.py](https://app.codecov.io/gh/scverse/scanpy/pull/2577?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `84.61% <ø> (ø)` | |; | [scanpy/external/tl/\_mellon.py](https://app.codecov.io/gh/scverse/scanpy/pull/2577?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3RsL19tZWxsb24ucHk=) | `88.00% <88.00%> (ø)` | |; | [scanpy/external/tl/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2577?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3RsL19faW5pdF9fLnB5) | `100.00% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2577#issuecomment-1654888369:1564,test,testing,1564,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2577#issuecomment-1654888369,1,['test'],['testing']
Testability,"/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve; failure_causes = self._attempt_to_pin_criterion(name); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion; criteria = self._get_updated_criteria(candidate); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria; self._add_to_criteria(criteria, requirement, parent=candidate); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria; if not criterion.candidates:; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__; return bool(self._sequence); ^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__; return any(self); ^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>; return (c for c in iterator if id(c) not in self._incompatible_ids); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built; candidate = func(); ^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link; self._link_candidate_cache[link] = LinkCandidate(; ^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:7529,test,test,7529,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['test'],['test']
Testability,"/local/lib/python3.6/site-packages/pandas/io/parsers.py in _read(filepath_or_buffer, kwds); 438 ; 439 # Create the parser.; --> 440 parser = TextFileReader(filepath_or_buffer, **kwds); 441 ; 442 if chunksize or iterator:. /usr/local/lib/python3.6/site-packages/pandas/io/parsers.py in __init__(self, f, engine, **kwds); 785 self.options['has_index_names'] = kwds['has_index_names']; 786 ; --> 787 self._make_engine(self.engine); 788 ; 789 def close(self):. /usr/local/lib/python3.6/site-packages/pandas/io/parsers.py in _make_engine(self, engine); 1012 def _make_engine(self, engine='c'):; 1013 if engine == 'c':; -> 1014 self._engine = CParserWrapper(self.f, **self.options); 1015 else:; 1016 if engine == 'python':. /usr/local/lib/python3.6/site-packages/pandas/io/parsers.py in __init__(self, src, **kwds); 1706 kwds['usecols'] = self.usecols; 1707 ; -> 1708 self._reader = parsers.TextReader(src, **kwds); 1709 ; 1710 passed_names = self.names is None. pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader.__cinit__(). EmptyDataError: No columns to parse from file; ```. </details>. But it seems to work no matter what server I choose in R, here's the test code. ```R; library(biomaRt). wwwmart = useMart(biomart=""ensembl"", dataset=""hsapiens_gene_ensembl"", host=""www.ensembl.org""); asiamart = useMart(biomart=""ensembl"", dataset=""hsapiens_gene_ensembl"", host=""asia.ensembl.org""); useastmart = useMart(biomart=""ensembl"", dataset=""hsapiens_gene_ensembl"", host=""useast.ensembl.org""). wwwresult = getBM(attributes=c(""hgnc_symbol"", ""chromosome_name""), mart=wwwmart); asiaresult = getBM(attributes=c(""hgnc_symbol"", ""chromosome_name""), mart=asiamart); useastresult = getBM(attributes=c(""hgnc_symbol"", ""chromosome_name""), mart=useastmart). assertthat::assert_that(all(wwwresult == asiaresult)); assertthat::assert_that(all(useastresult == asiaresult)); ```. I don't think the issue is with ensembl's servers. Is it possible you have a config for this `bioservices` module you've done anything with?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/242#issuecomment-416814067:3004,test,test,3004,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/242#issuecomment-416814067,3,"['assert', 'test']","['assertthat', 'test']"
Testability,/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - I,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60417,test,tests,60417,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,/preprocessing/_simple.py::scanpy.preprocessing._simple.filter_cells; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILE,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:27586,test,tests,27586,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/experimental/pp/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4cGVyaW1lbnRhbC9wcC9faGlnaGx5X3ZhcmlhYmxlX2dlbmVzLnB5) | `63.69% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3V0aWxzLnB5) | `45.16% <100.00%> (+1.82%)` | :arrow_up: |; | [scanpy/testing/\_pytest/fixtures/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9fX2luaXRfXy5weQ==) | `94.11% <ø> (-2.44%)` | :arrow_down: |; | [scanpy/tools/\_rank\_genes\_groups.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19yYW5rX2dlbmVzX2dyb3Vwcy5weQ==) | `92.77% <100.00%> (-0.03%)` | :arrow_down: |; | [scanpy/testing/\_pytest/params.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9wYXJhbXMucHk=) | `94.73% <94.73%> (ø)` | |; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `65.32% <94.11%> (+2.05%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2696#issuecomment-1766017585:2535,test,testing,2535,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2696#issuecomment-1766017585,1,['test'],['testing']
Testability,/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERRO,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70551,test,tests,70551,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scan,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70718,test,tests,70718,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66305,test,tests,66305,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"/scanpy/readwrite.py"", line 268, in _read_v3_10x_h5; _collect_datasets(dsets, f[""matrix""]); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 256, in _collect_datasets; dsets[k] = v[:]; File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/dataset.py"", line 738, in __getitem__; selection = sel2.select_read(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 101, in select_read; return ScalarReadSelection(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 86, in __init__; raise ValueError(""Illegal slicing argument for scalar dataspace""). > **ValueError: Illegal slicing argument for scalar dataspace**; ```. `>>> scanpy.logging.print_versions()`. anndata 0.8.0; scanpy 1.9.1. PIL 8.4.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; defusedxml 0.7.1; encodings NA; fsspec 2021.08.1; genericpath NA; h5py 3.3.0; igraph 0.9.6; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.37.0; markupsafe 1.1.1; matplotlib 3.4.3; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; ntpath NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; opcode NA; packaging 21.0; pandas 1.3.4; pkg_resources NA; posixpath NA; psutil 5.8.0; pyexpat NA; pyparsing 3.0.4; pytz 2021.3; scipy 1.7.1; scrublet NA; session_info 1.0.0; six 1.16.0; sklearn 0.24.2; sphinxcontrib NA; sre_compile NA; sre_constants NA; sre_parse NA; tblib 1.7.0; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zope NA. Python 3.9.7 (default, Sep 16 2021, 13:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572:1594,log,logging,1594,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572,1,['log'],['logging']
Testability,/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/tes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72527,test,tests,72527,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74656,test,tests,74656,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Erro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:43040,test,tests,43040,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_paga.py::test_paga_plots[-paga] - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variabl,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:39853,test,test,39853,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['test']
Testability,/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67130,test,tests,67130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] -,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:4118,Assert,AssertionError,4118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Assert'],['AssertionError']
Testability,/tests/test_plotting.py::test_scatterplots[pca_markers_colors_with_dimensions-fn10] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_mask-fn19] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/te,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55081,test,testing,55081,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65174,test,tests,65174,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - I,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74183,test,tests,74183,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:22: warning: 'PyUnicode_AsUnicode' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:262:14: note: expanded from macro 'PyUnicode_GET_SIZE'; ((void)PyUnicode_AsUnicode(_PyObject_CAST(op)),\; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:580:1: note: 'PyUnicode_AsUnicode' has been explicitly marked deprecated here; Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:22: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((Py",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:7493,test,test,7493,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['test'],['test']
Testability,"/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:52: warning: 'PyUnicode_AsUnicode' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:262:14: note: expanded from macro 'PyUnicode_GET_SIZE'; ((void)PyUnicode_AsUnicode(_PyObject_CAST(op)),\; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:580:1: note: 'PyUnicode_AsUnicode' has been explicitly marked deprecated here; Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:52: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((Py",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:10116,test,test,10116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['test'],['test']
Testability,"0.01; variable_genes_max_mean = 5; variable_genes_min_disp = 0.5. sc.pp.highly_variable_genes(adata_gex, ; min_mean=variable_genes_min_mean, ; max_mean=variable_genes_max_mean, ; min_disp=variable_genes_min_disp,; flavor = 'seurat') ; ```. Throws the following error: ; ```; /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scipy/sparse/data.py:135: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: overflow encountered in log; dispersion = np.log(dispersion); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-71-69d6424effb2> in <module>; 3 max_mean=variable_genes_max_mean,; 4 min_disp=variable_genes_min_disp,; ----> 5 flavor = 'seurat') . /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key); 255 n_top_genes=n_top_genes,; 256 n_bins=n_bins,; --> 257 flavor=flavor); 258 else:; 259 sanitize_anndata(adata). /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026:1416,log,log,1416,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026,1,['log'],['log']
Testability,00n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-100theta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:38318,test,tests,38318,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,00theta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.True-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.True-legend.on_right-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-100theta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-100theta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-100theta-30clip-subset] - NotImplementedError: Failed in,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:32049,test,tests,32049,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"04ffa49d21db017079/scanpy/external/pp/_harmony_integrate.py; harmony_integrate(adata1, key='batch', basis='X_pca_30'); harmony_integrate(adata2, key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; y: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; ```. The second test:. ```; sc.pp.neighbors(adata1, n_pcs=30, use_rep='X_pca_harmony'); sc.pp.neighbors(adata2, n_pcs=30, use_rep='X_pca_harmony'); np.testing.assert_array_equal(adata1.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 268636 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 434492 (61.8%); Max absolute difference: 0.99820393; Max relative difference: 810.4644; x: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179325, 1. ],; dtype=float32); y: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179324, 1. ],; dtype=float32); ```. This is my session_info:. ```; Click to view session information; -----; anndata 0.9.2; loguru 0.7.2; matplotlib 3.8.0; numpy 1.26.0; pandas 1.4.3; scanpy 1.9.6; seaborn 0.12.2; session_info 1.0.0; -----; Click to view modules imported as dependencies; PIL 9.4.0; argcomplete NA; asttokens NA; attr 23.1.0; awkward 2.4.2; awkward_cpp NA; backcall 0.2.0; cffi 1.15.1; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decora",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:2361,test,testing,2361,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227,1,['test'],['testing']
Testability,"0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(), help_msg))); > if config.FULL_TRACEBACKS:; > raise e; > else:; > > raise e.with_traceback(None); > E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); > E non-precise type pyobject; > E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); > E ; > E File ""scanpy/preprocessing/_simple.py"", line 763:; > E def do_scale(X, maxv, nthr):; > E <source elided>; > E # t0= time.time(); > E s = np.zeros((nthr, X.shape[1])); > E ^ ; > E ; > E This error may have been caused by the following argument(s):; > E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>; > ; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; > ```; > ; > When trying to use the new flavor with the existing test. Hi @Zethson ,; We are not able to see this issue with the latest commit. Can you please retry with the latest commit in scale branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:2852,test,test,2852,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717,1,['test'],['test']
Testability,0n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[spatial] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_dimension_broadcasting - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_marker_broadcasting - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:46537,test,tests,46537,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"1. How do we xfail stuff from `dev`? https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=108 It looks like the UMAP package via `pynndescent` is using something that has been removed (`np.infty`) in an upcoming release of numpy; 2. Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2112257384:107,log,logs,107,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2112257384,2,"['log', 'test']","['logs', 'test']"
Testability,"1. You could create a heuristic grid size depending on cell numbers, or it's probably easier to just put grid dimensions as a user parameter with some (low) default value.; 2. I've been approaching this from the perspective that you care about where the densities occur on the visualization. That's why you can change the `basis` for the calculations and plotting. From my perspective, calculating densities over clusters and comparing these is actually just a sub-optimal replacement for testing for differential compositions. This is a separate problem, where the data should be modeled statistically, accounting for the compositional nature of the data. So sticking to the visualization is probably the right way forward for this function. On that note... we could use a seaborn heatmap function to plot the differential grid points. Overall I reckon we are moving toward a new plotting function here which does some calculations on the backend. Something like `sc.pl.embedding_density_diff()` where you take the output from `sc.tl.embedding_density()` and interpolate to a grid layout, rescale to sum to 1 across each grid separately, take the diff of two conditions, and then plot everything in a heatmap. Doesn't seem as difficult as I thought. I will get onto this when (read: if) I (ever) have some spare time 😉.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/575#issuecomment-478914589:489,test,testing,489,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-478914589,1,['test'],['testing']
Testability,"1. for now, only partially fixed through more verbose logging output: https://github.com/theislab/scanpy/commit/8dcacda93c91a5466c2ff23bceb6120ce1d5e0cf; 2. was a bug that only affected ""inplace subsetting"", fixed via https://github.com/theislab/anndata/commit/0becb7b068dda31a60fd0ecb24360d0b5e3d3d7f and in anndata 0.6.6; 3. hm, of course you should be able to call `tl.rank_genes_groups` and `pl.rank_genes_groups`, but https://github.com/theislab/scanpy/blob/8dcacda93c91a5466c2ff23bceb6120ce1d5e0cf/scanpy/plotting/tools/__init__.py#L271-L282 should do the job for `pl.rank_genes_groups` and https://github.com/theislab/scanpy/blob/8dcacda93c91a5466c2ff23bceb6120ce1d5e0cf/scanpy/plotting/tools/__init__.py#L355-L358 for `pl.rank_genes_groups_violin`, right? I don't see how you can observe what you describe. let's look an example together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/210#issuecomment-407213235:54,log,logging,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/210#issuecomment-407213235,1,['log'],['logging']
Testability,"10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:22: warning: 'PyUnicode_AsUnicode' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:262:14: note: expanded from macro 'PyUnicode_GET_SIZE'; ((void)PyUnicode_AsUnicode(_PyObject_CAST(op)),\; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:580:1: note: 'PyUnicode_AsUnicode' has been explicitly marked deprecated here; Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:22: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:52: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:8078,test,test,8078,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['test'],['test']
Testability,"10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:52: warning: 'PyUnicode_AsUnicode' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:262:14: note: expanded from macro 'PyUnicode_GET_SIZE'; ((void)PyUnicode_AsUnicode(_PyObject_CAST(op)),\; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:580:1: note: 'PyUnicode_AsUnicode' has been explicitly marked deprecated here; Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:52: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:26: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:10701,test,test,10701,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['test'],['test']
Testability,19tYXRyaXhwbG90LnB5) | `96.70% <100.00%> (ø)` | |; | [scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19zdGFja2VkX3Zpb2xpbi5weQ==) | `84.18% <100.00%> (-0.16%)` | :arrow_down: |; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `95.61% <100.00%> (+0.03%)` | :arrow_up: |; | [scanpy/preprocessing/\_pca.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3BjYS5weQ==) | `93.25% <100.00%> (+0.11%)` | :arrow_up: |; | [scanpy/testing/\_helpers/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `87.87% <100.00%> (+1.67%)` | :arrow_up: |; | [scanpy/testing/\_pytest/params.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9wYXJhbXMucHk=) | `100.00% <100.00%> (ø)` | |; | ... and [2 more](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree-more&utm_medium=referral&utm_so,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895706976:3364,test,testing,3364,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895706976,1,['test'],['testing']
Testability,2-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_violin_without_raw - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_path - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[pca] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_highly_variable_genes.py::test_high,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:44481,Assert,AssertionError,44481,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Assert'],['AssertionError']
Testability,2-200n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_paga.py::test_paga_plots[-paga] - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200n-full] - NotImplementedError: Failed in nopython mode pi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:39887,test,tests,39887,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"29909 5.807068 7.896862; YPEL2 0.242923 5.806298 7.895356; UBE2D4 0.254622 5.778868 7.841706; FAM210B 0.266598 5.724431 7.735234; CTB-113I20.2 0.126570 5.654503 7.598464; GBGT1 0.177501 5.604167 7.500014; LRRIQ3 0.098048 5.437717 7.174459; MTIF2 0.220279 5.371215 7.044389; ```. To generate seurat_hvg_mvp.csv, I used; ```R; library(dplyr); library(Seurat); library(patchwork). ################################################################################; ### FindVariableFeatures (no batch covariate). # Load the PBMC dataset - load the data from the link above!; # pbmc.data <- Read10X(data.dir = ""<INSERT_PATH_TO_DATA_HERE>/filtered_gene_bc_matrices/hg19/""); pbmc.data <- Read10X(data.dir = ""/Users/eljas.roellin/Documents/R_stuff/filtered_gene_bc_matrices/hg19/""). # Initialize the Seurat object with the raw (non-normalized data).; pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k"", min.cells = 3, min.features = 200); pbmc <- NormalizeData(pbmc, normalization.method=""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot""). hvf_info <- HVFInfo(pbmc). write.csv(hvf_info, ""seurat_hvg_mvp.csv""); ```. And to generate seurat_hvg_v3.csv, I used; ```R; ################################################################################; ### FindVariableFeatures (no batch covariate). # Load the PBMC dataset - load the data from the link above!; # pbmc.data <- Read10X(data.dir = ""<INSERT_PATH_TO_DATA_HERE>/filtered_gene_bc_matrices/hg19/""); pbmc.data <- Read10X(data.dir = ""/Users/eljas.roellin/Documents/R_stuff/filtered_gene_bc_matrices/hg19/""). # Initialize the Seurat object with the raw (non-normalized data).; pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k"", min.cells = 3, min.features = 200); pbmc. pbmc <- FindVariableFeatures(pbmc, mean.function=ExpMean, selection.method = 'vst', nfeatures = 2000). hvf_info <- HVFInfo(pbmc). write.csv(hvf_info, ""seurat_hvg_v3.csv""); ```. *unless when using `batche",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892766132:4043,Log,LogNormalize,4043,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892766132,1,['Log'],['LogNormalize']
Testability,2xpbi5weQ==) | `84.18% <100.00%> (-0.16%)` | :arrow_down: |; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `95.61% <100.00%> (+0.03%)` | :arrow_up: |; | [scanpy/preprocessing/\_pca.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3BjYS5weQ==) | `93.25% <100.00%> (+0.11%)` | :arrow_up: |; | [scanpy/testing/\_helpers/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `87.87% <100.00%> (+1.67%)` | :arrow_up: |; | [scanpy/testing/\_pytest/params.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9wYXJhbXMucHk=) | `100.00% <100.00%> (ø)` | |; | ... and [2 more](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | |. ... and [5 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2816/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895706976:3661,test,testing,3661,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895706976,1,['test'],['testing']
Testability,"3 install . --user; Processing /Users/test/PythonPackages/forceatlas2; Preparing metadata (setup.py) ... done; Requirement already satisfied: numpy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.21.5); Requirement already satisfied: scipy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.8.0); Requirement already satisfied: tqdm in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (4.63.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... done; Created wheel for fa2: filename=fa2-0.3.5-cp310-cp310-macosx_12_0_x86_64.whl size=155419 sha256=23d907bfec5df0e9d0d522865d1c288b1f8894134bd61b6c5a02467128dfd102; Stored in directory: /private/var/folders/0s/67yn6b6n3lx4882xx_86ps2m0000gp/T/pip-ephem-wheel-cache-i69s_t3j/wheels/51/1c/a5/5a9ef4f0bc9387d300190bc15adbb98dbda9d90c6da9c2da04; Successfully built fa2; Installing collected packages: fa2; Successfully installed fa2-0.3.5 ; test@mac ~/PythonPackages/forceatlas2$; ```. However, if you try to install the release version you get an error:. ```; test@mac ~/PythonPackages$ wget https://github.com/bhargavchippada/forceatlas2/archive/refs/tags/v0.3.5.tar.gz; --2022-03-24 02:54:21-- https://github.com/bhargavchippada/forceatlas2/archive/refs/tags/v0.3.5.tar.gz; Resolving github.com (github.com)... 140.82.114.3; Connecting to github.com (github.com)|140.82.114.3|:443... connected.; HTTP request sent, awaiting response... 302 Found; Location: https://codeload.github.com/bhargavchippada/forceatlas2/tar.gz/refs/tags/v0.3.5 [following]; --2022-03-24 02:54:21-- https://codeload.github.com/bhargavchippada/forceatlas2/tar.gz/refs/tags/v0.3.5; Resolving codeload.github.com (codeload.github.com)... 140.82.114.9; Connecting to codeload.github.com (codeload.github.com)|140.82.114.9|:443... connected.; HTTP request sent, awaiting response... 200 OK; Length: unspecified [application/x-gzip]; Saving to: ‘v0.3.5.tar.gz’. v0.3.5.tar.gz [ <=> ] 434.9",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:1562,test,test,1562,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['test'],['test']
Testability,3.6.1 pyhd3eb1b0_1001 ; sip 4.19.13 py38he6710b0_0 ; six 1.15.0 py38h06a4308_0 ; sklearn 0.0 pypi_0 pypi; snappy 1.1.8 he6710b0_0 ; sniffio 1.2.0 py38h06a4308_1 ; snowballstemmer 2.1.0 pyhd3eb1b0_0 ; sortedcollections 2.1.0 pyhd3eb1b0_0 ; sortedcontainers 2.3.0 pyhd3eb1b0_0 ; soupsieve 2.2.1 pyhd3eb1b0_0 ; sphinx 4.0.1 pyhd3eb1b0_0 ; sphinxcontrib 1.0 py38_1 ; sphinxcontrib-applehelp 1.0.2 pyhd3eb1b0_0 ; sphinxcontrib-devhelp 1.0.2 pyhd3eb1b0_0 ; sphinxcontrib-htmlhelp 1.0.3 pyhd3eb1b0_0 ; sphinxcontrib-jsmath 1.0.1 pyhd3eb1b0_0 ; sphinxcontrib-qthelp 1.0.3 pyhd3eb1b0_0 ; sphinxcontrib-serializinghtml 1.1.4 pyhd3eb1b0_0 ; sphinxcontrib-websupport 1.2.4 py_0 ; spyder 4.2.5 py38h06a4308_0 ; spyder-kernels 1.10.2 py38h06a4308_0 ; sqlalchemy 1.4.15 py38h27cfd23_0 ; sqlite 3.35.4 hdfb4753_0 ; statsmodels 0.12.2 py38h27cfd23_0 ; stdlib-list 0.7.0 py_2 conda-forge; sympy 1.8 py38h06a4308_0 ; tasklogger 1.0.0 pypi_0 pypi; tbb 2020.3 hfd86e86_0 ; tblib 1.7.0 py_0 ; terminado 0.9.4 py38h06a4308_0 ; testpath 0.4.4 pyhd3eb1b0_0 ; textdistance 4.2.1 pyhd3eb1b0_0 ; threadpoolctl 2.1.0 pyh5ca1d4c_0 ; three-merge 0.1.1 pyhd3eb1b0_0 ; tk 8.6.10 hbc83047_0 ; tktable 2.10 h14c3975_0 ; tokenize-rt 4.1.0 pyhd8ed1ab_0 conda-forge; toml 0.10.2 pyhd3eb1b0_0 ; toolz 0.11.1 pyhd3eb1b0_0 ; tornado 6.1 py38h27cfd23_0 ; tqdm 4.59.0 pyhd3eb1b0_1 ; traitlets 5.0.5 pyhd3eb1b0_0 ; triku 1.3.1 pypi_0 pypi; tslearn 0.5.0.5 pypi_0 pypi; typed-ast 1.4.2 py38h27cfd23_1 ; typing 3.10.0.0 py38h06a4308_0 ; typing-extensions 3.10.0.0 pypi_0 pypi; typing_extensions 3.7.4.3 pyha847dfd_0 ; tzlocal 2.1 py38_0 ; ujson 4.0.2 py38h2531618_0 ; umap-learn 0.5.1 py38h578d9bd_0 conda-forge; unicodecsv 0.14.1 py38_0 ; unixodbc 2.3.9 h7b6447c_0 ; urllib3 1.26.4 pyhd3eb1b0_0 ; vendorize 0.2.1 pypi_0 pypi; watchdog 1.0.2 py38h06a4308_1 ; wcwidth 0.2.5 py_0 ; webencodings 0.5.1 py38_1 ; werkzeug 1.0.1 pyhd3eb1b0_0 ; wheel 0.36.2 pyhd3eb1b0_0 ; widgetsnbextension 3.5.1 py38_0 ; wrapt 1.12.1 py38h7b6447c_1 ; wurlitzer 2.1.0 ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310:17270,test,testpath,17270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310,1,['test'],['testpath']
Testability,4-100n-100theta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED sca,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:38554,test,tests,38554,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,4-200n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-100n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-int64-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/preprocessing/_simple.py::scanpy.preprocessing._simple.filter_cells; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-infclip-subset] - NotImplementedError: ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:26828,test,tests,26828,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"4-3.10/fa2/fa2util.o; fa2/fa2util.c:10939:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Node.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10947:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Edge.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10960:35: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Region.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:12133:22: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:22: warning: 'PyUnicode_AsUnicode' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:262:14: note: expanded from macro 'PyUnicode_GET_SIZE'; ((void)PyUnicode_AsUnicode(_PyObject_CAST(op)),\; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:580:1: note: 'PyUnicode_AsUnicode' has been explicitly marked deprecated here; Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:6767,test,test,6767,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['test'],['test']
Testability,"4.8.0=py37hc8dfbb8_1; pickleshare=0.7.5=py37hc8dfbb8_1001; pip=20.0.2=py37_1; pixman=0.38.0=h516909a_1003; prometheus_client=0.7.1=py_0; prompt-toolkit=3.0.5=py_0; psutil=5.7.0=py37h8f50634_1; pthread-stubs=0.4=h14c3975_1001; ptyprocess=0.6.0=py_1001; pycairo=1.19.1=py37h01af8b0_3; pycparser=2.20=py_0; pygments=2.6.1=py_0; pyopenssl=19.1.0=py_1; pyparsing=2.4.7=pypi_0; pyrsistent=0.16.0=py37h8f50634_0; pysocks=1.7.1=py37hc8dfbb8_1; python=3.7.7=hcf32534_0_cpython; python-dateutil=2.8.1=py_0; python-igraph=0.8.1=pypi_0; python_abi=3.7=1_cp37m; pytz=2019.3=pypi_0; pyyaml=5.3.1=py37h8f50634_0; pyzmq=19.0.0=py37hac76be4_1; readline=8.0=h7b6447c_0; requests=2.23.0=pyh8c360ce_2; scanpy=1.4.6=pypi_0; scikit-learn=0.22.2.post1=pypi_0; scipy=1.4.1=pypi_0; seaborn=0.10.1=pypi_0; send2trash=1.5.0=py_0; setuptools=46.1.3=py37_0; setuptools-scm=3.5.0=pypi_0; six=1.14.0=py_1; sqlite=3.31.1=h62c20be_1; statsmodels=0.11.1=pypi_0; tables=3.6.1=pypi_0; tbb=2020.0.133=pypi_0; terminado=0.8.3=py37hc8dfbb8_1; testpath=0.4.4=py_0; texttable=1.6.2=py_0; tk=8.6.8=hbc83047_0; tornado=6.0.4=py37h8f50634_1; tqdm=4.45.0=pypi_0; traitlets=4.3.3=py37hc8dfbb8_1; umap-learn=0.4.1=pypi_0; urllib3=1.25.9=py_0; wcwidth=0.1.9=pyh9f0ad1d_0; webencodings=0.5.1=py_1; wheel=0.34.2=py37_0; xorg-kbproto=1.0.7=h14c3975_1002; xorg-libice=1.0.10=h516909a_0; xorg-libsm=1.2.3=h84519dc_1000; xorg-libx11=1.6.9=h516909a_0; xorg-libxau=1.0.9=h14c3975_0; xorg-libxdmcp=1.1.3=h516909a_0; xorg-libxext=1.3.4=h516909a_0; xorg-libxrender=0.9.10=h516909a_1002; xorg-renderproto=0.11.1=h14c3975_1002; xorg-xextproto=7.3.0=h14c3975_1002; xorg-xproto=7.0.31=h14c3975_1007; xz=5.2.5=h7b6447c_0; yaml=0.2.4=h516909a_0; zeromq=4.3.2=he1b5a44_2; zipp=3.1.0=py_0; zlib=1.2.11=h7b6447c_3; ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash; # Where the output you pasted above is in scanpy_1183_env.txt; $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1183#issuecomment-620988575:3685,test,testpath,3685,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183#issuecomment-620988575,1,['test'],['testpath']
Testability,"47-7)), there are a couple of things to consider here:; 1. Do we even want relative expression counts?; 2. What assumptions do downstream methods have on the distribution of expression values. For the first question: relative gene expression values ignore differences in cell sizes/number of molecules in the cell. There are some molecules whose numbers scale with the size of the cell, and others that don't (e.g., many housekeeping genes). Choosing relative over absolute expression values to compare gene expression across cells would be helpful to compare expression of those genes that scale with size, but not the others.... so there's not really a perfect answer here. Thus, removing all effects of total counts may not be the desirable outcome. Secondly, many downstream methods assume normally distributed expression data (e.g., DE methods like: t-tests, limma, MAST, or several batch correction/data integration methods). Log transformation is used as a variance stabilization to approximate a normal distribution (quite often poorly, but better than without). This leads to many methods performing better with log transformation. IMO, the ideal approach is probably something like scVI, GLMPCA, or scTransform, where you fit a model directly to the count data and use the residuals to describe the data. This would address both steps of normalization and variance stabilization at the same time. If we have a good model to describe the data, the residuals should quantify the biological variance + normally distributed noise. Overall, I would use other normalization approaches than CPM, and use log-transformation with anything that uses size factors that scale per-cell expression values. . Note also that the effect described in the second paper you mention (from Aaron Lun) will mainly be relevant when you have biased distributions of sequencing depth between two samples that you are comparing. If the size factors are similarly distributed between both conditions, then the DE effect",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643:1460,Log,Log,1460,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643,1,['Log'],['Log']
Testability,"477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; y: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; ```. The second test:. ```; sc.pp.neighbors(adata1, n_pcs=30, use_rep='X_pca_harmony'); sc.pp.neighbors(adata2, n_pcs=30, use_rep='X_pca_harmony'); np.testing.assert_array_equal(adata1.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 268636 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 434492 (61.8%); Max absolute difference: 0.99820393; Max relative difference: 810.4644; x: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179325, 1. ],; dtype=float32); y: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179324, 1. ],; dtype=float32); ```. This is my session_info:. ```; Click to view session information; -----; anndata 0.9.2; loguru 0.7.2; matplotlib 3.8.0; numpy 1.26.0; pandas 1.4.3; scanpy 1.9.6; seaborn 0.12.2; session_info 1.0.0; -----; Click to view modules imported as dependencies; PIL 9.4.0; argcomplete NA; asttokens NA; attr 23.1.0; awkward 2.4.2; awkward_cpp NA; backcall 0.2.0; cffi 1.15.1; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; dot_parser NA; etils 1.4.1; exceptiongroup 1.1.3; executing 1.2.0; get_annotations NA; gmpy2 2.1.2; h5py 3.9.0; harmonypy NA; igraph 0.10.8; importlib_metadata NA; importlib_resources NA; ipykernel 6.25.2; ipywidgets 8.1.1; jax 0.4.20; jaxlib 0.4.20; jedi 0.19.0; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.41.1; ml_dtypes 0.2.0; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; numba 0.58.1; nvfuser NA; opt_einsum v3.0.0; packaging 23.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 13.0.0; p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:3003,log,loguru,3003,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227,1,['log'],['loguru']
Testability,"5: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:52: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:52: warning: 'PyUnicode_AsUnicode' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:262:14: note: expanded from macro 'PyUnicode_GET_SIZE'; ((void)PyUnicode_AsUnicode(_PyObject_CAST(op)),\; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:580:1: note: 'PyUnicode_AsUnicode' has been explicitly marked deprecated here; Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:9390,test,test,9390,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['test'],['test']
Testability,63c60_0; libgfortran-ng=7.3.0=hdf63c60_5; libiconv=1.15=h516909a_1006; libpng=1.6.37=hed695b0_1; libsodium=1.0.17=h516909a_0; libstdcxx-ng=9.1.0=hdf63c60_0; libuuid=2.32.1=h14c3975_1000; libxcb=1.13=h14c3975_1002; libxml2=2.9.10=hee79883_0; libxslt=1.1.33=h31b3aaa_0; llvmlite=0.32.0=pypi_0; lxml=4.5.0=py37he3881c9_1; markupsafe=1.1.1=py37h8f50634_1; matplotlib=3.2.1=pypi_0; mistune=0.8.4=py37h8f50634_1001; natsort=7.0.1=pypi_0; nbconvert=5.6.1=py37hc8dfbb8_1; nbformat=5.0.6=py_0; ncurses=6.2=he6710b0_0; networkx=2.4=pypi_0; notebook=6.0.3=py37_0; numba=0.49.0=pypi_0; numexpr=2.7.1=pypi_0; numpy=1.18.3=pypi_0; openssl=1.1.1g=h516909a_0; packaging=20.3=pypi_0; pandas=1.0.3=pypi_0; pandoc=2.9.2.1=0; pandocfilters=1.4.2=py_1; parso=0.7.0=pyh9f0ad1d_0; patsy=0.5.1=pypi_0; pcre=8.44=he1b5a44_0; pexpect=4.8.0=py37hc8dfbb8_1; pickleshare=0.7.5=py37hc8dfbb8_1001; pip=20.0.2=py37_1; pixman=0.38.0=h516909a_1003; prometheus_client=0.7.1=py_0; prompt-toolkit=3.0.5=py_0; psutil=5.7.0=py37h8f50634_1; pthread-stubs=0.4=h14c3975_1001; ptyprocess=0.6.0=py_1001; pycairo=1.19.1=py37h01af8b0_3; pycparser=2.20=py_0; pygments=2.6.1=py_0; pyopenssl=19.1.0=py_1; pyparsing=2.4.7=pypi_0; pyrsistent=0.16.0=py37h8f50634_0; pysocks=1.7.1=py37hc8dfbb8_1; python=3.7.7=hcf32534_0_cpython; python-dateutil=2.8.1=py_0; python-igraph=0.8.1=pypi_0; python_abi=3.7=1_cp37m; pytz=2019.3=pypi_0; pyyaml=5.3.1=py37h8f50634_0; pyzmq=19.0.0=py37hac76be4_1; readline=8.0=h7b6447c_0; requests=2.23.0=pyh8c360ce_2; scanpy=1.4.6=pypi_0; scikit-learn=0.22.2.post1=pypi_0; scipy=1.4.1=pypi_0; seaborn=0.10.1=pypi_0; send2trash=1.5.0=py_0; setuptools=46.1.3=py37_0; setuptools-scm=3.5.0=pypi_0; six=1.14.0=py_1; sqlite=3.31.1=h62c20be_1; statsmodels=0.11.1=pypi_0; tables=3.6.1=pypi_0; tbb=2020.0.133=pypi_0; terminado=0.8.3=py37hc8dfbb8_1; testpath=0.4.4=py_0; texttable=1.6.2=py_0; tk=8.6.8=hbc83047_0; tornado=6.0.4=py37h8f50634_1; tqdm=4.45.0=pypi_0; traitlets=4.3.3=py37hc8dfbb8_1; umap-learn=0.4.1=pypi_0; urllib3=1.25.9=py,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1183#issuecomment-620988575:2882,stub,stubs,2882,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183#issuecomment-620988575,1,['stub'],['stubs']
Testability,"827 plot_type='matrixplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds); 448 from .._matrixplot import matrixplot; 449 ; --> 450 _pl = matrixplot(; 451 adata, var_names, groupby, values_df=values_df, return_fig=True, **kwds; 452 ). ~/projects/scanpy/scanpy/plotting/_matrixplot.py in matrixplot(adata, var_names, groupby, use_raw, log, num_categories, figsize, dendrogram, title, cmap, colorbar_title, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, values_df, swap_axes, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 345 """"""; 346 ; --> 347 mp = MatrixPlot(; 348 adata,; 349 var_names,. ~/projects/scanpy/scanpy/plotting/_matrixplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, ax, values_df, vmin, vmax, vcenter, norm, **kwds); 109 **kwds,; 110 ):; --> 111 BasePlot.__init__(; 112 self,; 113 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds); 109 self._update_var_groups(); 110 ; --> 111 self.categories, self.obs_tidy = _prepare_dataframe(; 112 adata,; 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1864 groupby.remove(groupby_index); 1865 keys = list(groupby) + list(np.unique(var_names)); -> 1866 obs_tidy = get.obs_df(; 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols; 1868 ). ~/projects/scanpy/scanpy/get/get.py in obs_df",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1758#issuecomment-851701172:1783,log,log,1783,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758#issuecomment-851701172,1,['log'],['log']
Testability,"97, in __init__; super().__init__(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__; self.dist = self._prepare(); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare; dist = self._prepare_distribution(); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution; return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement; return self._prepare_linked_requirement(req, parallel_builds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement; dist = _get_prepared_distribution(; ^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution; abstract_dist.prepare_distribution_metadata(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata; self.req.prepare_metadata(); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata; self.metadata_directory = generate_metadata_legacy(; ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata; r",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:9568,test,test,9568,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['test'],['test']
Testability,: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - Assertion,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:3978,Assert,AssertionError,3978,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Assert'],['AssertionError']
Testability,: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[r,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2943,Assert,AssertionError,2943,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Assert'],['AssertionError']
Testability,": expanded from macro 'PyUnicode_GET_SIZE'; ((void)PyUnicode_AsUnicode(_PyObject_CAST(op)),\; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:580:1: note: 'PyUnicode_AsUnicode' has been explicitly marked deprecated here; Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:22: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:52: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:8460,test,test,8460,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['test'],['test']
Testability,": expanded from macro 'PyUnicode_GET_SIZE'; ((void)PyUnicode_AsUnicode(_PyObject_CAST(op)),\; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:580:1: note: 'PyUnicode_AsUnicode' has been explicitly marked deprecated here; Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:52: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:26: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Us",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:11083,test,test,11083,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['test'],['test']
Testability,":+1: to twine check :-1: to the python versions. Ultimately, we do have a limited amount of CI, so I think it's important to be a bit cautious adding many jobs. Of the dependencies I'm worried about being an issue: generally not newer python versions. Minimum python versions are important for catching us using newer features. . I am up for swapping python 3.7 with 3.8. I don't think 3.9 is going to work for now. Last time I tried to use 3.9 (a month ago) numpy builds weren't working. I believe numba currently isn't working: https://github.com/numba/numba/issues/6345. Higher priorities to me (roughly in order):. * Test on windows; * Test against lower bounds of our requirements; * Test on Mac; * Dev builds",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1602#issuecomment-763582191:621,Test,Test,621,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1602#issuecomment-763582191,3,['Test'],['Test']
Testability,://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (fcb0a06) into [master](https://app.codecov.io/gh/scverse/scanpy/commit/06802b459648a219a10f74243efe4d6c2f912016?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (06802b4) will **increase** coverage by `0.24%`.; > The diff coverage is `85.84%`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2235 +/- ##; ==========================================; + Coverage 71.89% 72.14% +0.24% ; ==========================================; Files 98 104 +6 ; Lines 11518 11678 +160 ; ==========================================; + Hits 8281 8425 +144 ; - Misses 3237 3253 +16 ; ```. | [Impacted Files](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `60.86% <60.86%> (ø)` | |; | [scanpy/testing/\_pytest/marks.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `84.61% <84.61%> (ø)` | |; | [scanpy/testing/\_helpers/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvZGF0YS5weQ==) | `88.57% <88.57%> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.io/gh/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235#issuecomment-1098162430:1289,test,testing,1289,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1098162430,1,['test'],['testing']
Testability,::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_paga.py::test_paga_plots[compare-func4] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_pie - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_paga.py::test_paga_plots[compare_pca-func6] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highl,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:41339,test,tests,41339,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,":; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve; state = resolution.resolve(requirements, max_rounds=max_rounds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve; failure_causes = self._attempt_to_pin_criterion(name); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion; criteria = self._get_updated_criteria(candidate); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria; self._add_to_criteria(criteria, requirement, parent=candidate); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria; if not criterion.candidates:; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:6497,test,test,6497,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['test'],['test']
Testability,":; Variables (genes) that do not display any variation (are constant across; all observations) are retained and set to 0 during this operation. In; the future, they might be set to NaNs.; Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; zero_center; If `False`, omit zero-centering variables, which allows to handle sparse; input efficiently.; max_value; Clip (truncate) to this value after scaling. If `None`, do not clip.; copy; If an :class:`~anndata.AnnData` is passed,; determines whether a copy is returned.; Returns; -------; Depending on `copy` returns or updates `adata` with a scaled `adata.X`,; annotated with `'mean'` and `'std'` in `adata.var`.; """"""; return scale_array(X, *args, **kwargs). @scale.register(np.ndarray); def scale_array(; X,; zero_center: bool = True,; max_value: Optional[float] = None,; copy: bool = False,; return_mean_var=False,; ):; if copy:; X = X.copy(); if not zero_center and max_value is not None:; logg.info( # Be careful of what? This should be more specific; '... be careful when using `max_value` '; 'without `zero_center`.'; ); if max_value is not None:; logg.debug(f'... clipping at max_value {max_value}'); mean, std = _scale(X, zero_center) # the code from here could probably just be ; # do the clipping; if max_value is not None:; X[X > max_value] = max_value; if return_mean_var:; return X, mean, var; else:; return X. @scale.register(AnnData); def scale_anndata(; adata: AnnData,; *,; zero_center: bool = True,; max_value: Optional[float] = None,; copy: bool = False,; ) -> Optional[AnnData]:; adata = adata.copy() if copy else adata; view_to_actual(adata); adata.X, adata.var[""mean""], adata.var[""std""] = scale(; X, ; zero_center=zero_center, ; max_value=max_value, ; copy=False, # because a copy has already been made, if it were to be made; return_mean_var=True; ); if copy:; return adata. @scale.register(sparse.spmatrix); def scale_sparse(; X, ; *, ; zero_ce",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1135#issuecomment-608200735:1973,log,logg,1973,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1135#issuecomment-608200735,1,['log'],['logg']
Testability,:test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-float32-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-int64-200n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-100n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-int64-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/preprocessing/_simple.py::scanpy.preprocessing._simple.filter_cells; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-subset] - NotImplementedError: Failed in nopython mode pipeli,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:26071,test,tests,26071,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,:test_paga_path - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[pca] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-float32-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[spatial] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_dimension_broadcasting - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_marker_broadcasting - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plott,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:46128,test,tests,46128,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,:test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_violin - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_binary_scatter - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_color_cycler - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_repeated_colors_w_missing_value - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_no_copy - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[list-named] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-named] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:50802,test,tests,50802,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,:test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_ordinal - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_layer - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_view - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_categorical - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants_equivalent - ImportError: cannot import name '_cente,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:6403,test,tests,6403,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['test'],['tests']
Testability,; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - Impor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61725,test,tests,61725,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_ut,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66959,test,tests,66959,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,; creating fa2.egg-info; writing fa2.egg-info/PKG-INFO; writing dependency_links to fa2.egg-info/dependency_links.txt; writing requirements to fa2.egg-info/requires.txt; writing top-level names to fa2.egg-info/top_level.txt; writing manifest file 'fa2.egg-info/SOURCES.txt'; reading manifest file 'fa2.egg-info/SOURCES.txt'; reading manifest template 'MANIFEST.in'; adding license file 'LICENSE'; writing manifest file 'fa2.egg-info/SOURCES.txt'; copying fa2/fa2util.c -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.pxd -> build/lib.macosx-12.3-x86_64-3.10/fa2; running build_ext; skipping 'fa2/fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; creating build/temp.macosx-12.3-x86_64-3.10; creating build/temp.macosx-12.3-x86_64-3.10/fa2; clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Users/test/.pyenv/versions/3.10.3/include/python3.10 -c fa2/fa2util.c -o build/temp.macosx-12.3-x86_64-3.10/fa2/fa2util.o; fa2/fa2util.c:10939:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Node.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10947:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Edge.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10960:35: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Region.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:12133:22: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:5601,test,test,5601,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['test'],['test']
Testability,"; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo; # 2019-02-13 19:28.03 call_finish call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo elapsed=datetime.timedelta(microseconds=505970) returned_adata_id=4940502352; ```. </details>. <details>; <summary>More complicated example with argument value logging</summary>. ```python; from anndata import AnnData; from copy import copy; from datetime import datetime; from functools import wraps; import inspect; from itertools import chain; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(logged_args=None):; """"""; Params; ------; logged_args : list[str], optional (default: `None`); Names of arguments to log.; """"""; if logged_args is None:; logged_args = []; def logged_decorator(func):; argnames = inspect.getfullargspec(func).args; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; logged_params = {}. for param, val in chain(zip(argnames, args), kwargs.items()):; if type(val) is AnnData:; logged_params[param] = id(val); elif param in logged_args:; logged_params[param] = copy(val) # Probably need to consider how these values get logged. logger.msg(""call"", called_func=func.__name__,; logged_args=logged_params, call_id=call_id). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(; called_func=func.__name__, elapsed=dt,; ); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish""",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:2589,log,logger,2589,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273,1,['log'],['logger']
Testability,; rope 0.18.0 pyh9f0ad1d_0 conda-forge; rtree 0.9.4 py38h08f867b_1 conda-forge; scanpy 1.6.0 py_0 bioconda; scikit-learn 0.23.2 py38hc63f23e_1 conda-forge; scipy 1.5.2 py38hf17e0cf_2 conda-forge; seaborn 0.11.0 0 conda-forge; seaborn-base 0.11.0 py_0 conda-forge; setuptools 50.3.0 py38h0dc7051_1 ; setuptools-scm 4.1.2 pyh9f0ad1d_0 conda-forge; setuptools_scm 4.1.2 0 conda-forge; sinfo 0.3.1 py_0 conda-forge; six 1.15.0 pyh9f0ad1d_0 conda-forge; snowballstemmer 2.0.0 py_0 conda-forge; sortedcontainers 2.2.2 pyh9f0ad1d_0 conda-forge; sphinx 3.2.1 py_0 conda-forge; sphinxcontrib-applehelp 1.0.2 py_0 conda-forge; sphinxcontrib-devhelp 1.0.2 py_0 conda-forge; sphinxcontrib-htmlhelp 1.0.3 py_0 conda-forge; sphinxcontrib-jsmath 1.0.1 py_0 conda-forge; sphinxcontrib-qthelp 1.0.3 py_0 conda-forge; sphinxcontrib-serializinghtml 1.1.4 py_0 conda-forge; spyder 4.1.5 py38h32f6830_0 conda-forge; spyder-kernels 1.9.4 py38h32f6830_0 conda-forge; sqlite 3.33.0 h960bd1c_1 conda-forge; statsmodels 0.12.0 py38h174b24a_1 conda-forge; stdlib-list 0.7.0 py38h32f6830_1 conda-forge; tbb 2020.3 h879752b_0 ; testpath 0.4.4 py_0 conda-forge; texttable 1.6.3 pyh9f0ad1d_0 conda-forge; threadpoolctl 2.1.0 pyh5ca1d4c_0 conda-forge; tk 8.6.10 hb0a8c7a_1 conda-forge; toml 0.10.1 pyh9f0ad1d_0 conda-forge; tornado 6.0.4 py38h4d0b108_2 conda-forge; tqdm 4.51.0 pyh9f0ad1d_0 conda-forge; traitlets 5.0.5 py_0 conda-forge; ujson 4.0.1 py38h11c0d25_1 conda-forge; umap-learn 0.4.6 py38h32f6830_0 conda-forge; urllib3 1.25.11 py_0 conda-forge; watchdog 0.10.3 py38h4d0b108_2 conda-forge; wcwidth 0.2.5 pyh9f0ad1d_2 conda-forge; webencodings 0.5.1 py_1 conda-forge; wheel 0.35.1 pyh9f0ad1d_0 conda-forge; wrapt 1.11.2 py38h4d0b108_1 conda-forge; wurlitzer 2.0.1 py38_0 ; xz 5.2.5 haf1e3a3_1 conda-forge; yaml 0.2.5 haf1e3a3_0 conda-forge; yapf 0.30.0 pyh9f0ad1d_0 conda-forge; zeromq 4.3.3 hb1e8313_2 conda-forge; zipp 3.4.0 py_0 conda-forge; zlib 1.2.11 h7795811_1010 conda-forge; zstd 1.4.5 h0384e3a_2 conda-forge; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-719504684:8179,test,testpath,8179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-719504684,1,['test'],['testpath']
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. ## Benchmark changes. | Change | Before [126d7305] | After [ec306202] | Ratio | Benchmark (Parameter) |; |----------|----------------------|---------------------|---------|----------------------------------------------------|; | + | 321M | 423M | 1.32 | preprocessing_log.peakmem_pca('pbmc68k_reduced') |; | + | 244M | 291M | 1.19 | preprocessing_log.peakmem_scale('pbmc68k_reduced') |; | + | 4.08±0.2ms | 5.12±0.1ms | 1.25 | preprocessing_log.time_scale('pbmc68k_reduced') |. Comparison: <https://github.com/scverse/scanpy/compare/126d7305fbf1150b1eeb13a53be5f3d9abf7ed14..ec306202e7228e914bb4a5865965e958459de01c>; Last changed: <time datetime=""2024-06-17T15:58:36.829328353+00:00"">Mon, 17 Jun 2024 15:58:36 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/3100/checks?check_run_id=26323363402>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3100#issuecomment-2173142624:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100#issuecomment-2173142624,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark']"
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. ## Benchmark changes. | Change | Before [19a0bb8f] | After [0e144411] | Ratio | Benchmark (Parameter) |; |----------|----------------------|---------------------|---------|----------------------------------------------------------|; | - | 1.32G | 1.13G | 0.85 | preprocessing_counts.peakmem_scrublet('pbmc3k') |; | - | 473M | 406M | 0.86 | preprocessing_counts.peakmem_scrublet('pbmc68k_reduced') |; | - | 11.7±0.07s | 3.28±0.2s | 0.28 | preprocessing_counts.time_scrublet('pbmc3k') |; | - | 2.48±0s | 407±100ms | 0.16 | preprocessing_counts.time_scrublet('pbmc68k_reduced') |; | - | 639M | 527M | 0.83 | preprocessing_log.peakmem_pca('pbmc3k') |. Comparison: <https://github.com/scverse/scanpy/compare/19a0bb8fd3601c3b39e242ff6419fb73e59cf67a..0e14441111e310d30d8bd539062093f9b640e29c>; Last changed: <time datetime=""2024-05-14T10:15:55.664354107+00:00"">Tue, 14 May 2024 10:15:55 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/3056/checks?check_run_id=24941793644>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3056#issuecomment-2109790649:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3056#issuecomment-2109790649,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark']"
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. ## Benchmark changes. | Change | Before [3ba3f46b] | After [277c1bfb] | Ratio | Benchmark (Parameter) |; |----------|----------------------|---------------------|---------|-------------------------------------------|; | - | 9.09±1ms | 6.90±0.06ms | 0.76 | preprocessing_counts.time_log1p('pbmc3k') |. Comparison: <https://github.com/scverse/scanpy/compare/3ba3f46b4e6e77e8c6f0551db9663822097b486a..277c1bfb0885234aa757d0fdaeaa9103eb8568e2>; Last changed: <time datetime=""2024-05-23T12:59:15.701852120+00:00"">Thu, 23 May 2024 12:59:15 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/3017/checks?check_run_id=25329779518>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3017#issuecomment-2069221257:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017#issuecomment-2069221257,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark']"
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. ## Benchmark changes. | Change | Before [4269ed23] | After [bc1d6584] | Ratio | Benchmark (Parameter) |; |----------|----------------------|---------------------|---------|--------------------------------------------------------|; | + | 525M | 640M | 1.22 | preprocessing_log.peakmem_pca('pbmc3k', 'off-axis') |; | + | 570M | 687M | 1.21 | preprocessing_log.peakmem_pca('pbmc3k', None) |; | - | 415M | 335M | 0.81 | preprocessing_log.peakmem_pca('pbmc68k_reduced', None) |. Comparison: <https://github.com/scverse/scanpy/compare/4269ed23616a0e9c5a53ca25f45856e908bfb025..bc1d658438873c686c942aa1770f170353b4da13>; Last changed: <time datetime=""2024-07-25T09:58:11.260598676+00:00"">Thu, 25 Jul 2024 09:58:11 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/3147/checks?check_run_id=27903061371>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3147#issuecomment-2214058637:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3147#issuecomment-2214058637,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark']"
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. ## Benchmark changes. | Change | Before [5f2f84bd] | After [cb54e0c4] | Ratio | Benchmark (Parameter) |; |----------|----------------------|---------------------|---------|----------------------------------------------------|; | + | 248M | 290M | 1.17 | preprocessing_log.peakmem_scale('pbmc68k_reduced') |; | - | 842±30ms | 731±6ms | 0.87 | preprocessing_log.time_scale('pbmc3k') |; | + | 3.82±0.1ms | 5.92±0.7ms | 1.55 | preprocessing_log.time_scale('pbmc68k_reduced') |. Comparison: <https://github.com/scverse/scanpy/compare/5f2f84bd6b59622bbc92703fe9fec9c55e9ec5de..cb54e0c455db867cb8d85009a2021e4712de31b7>; Last changed: <time datetime=""2024-06-18T11:40:58.330897814+00:00"">Tue, 18 Jun 2024 11:40:58 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/3112/checks?check_run_id=26363911376>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3112#issuecomment-2175872159:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3112#issuecomment-2175872159,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark']"
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. ## Benchmark changes. | Change | Before [6440515e] | After [b4260358] | Ratio | Benchmark (Parameter) |; |----------|----------------------|---------------------|---------|--------------------------------------------------------|; | - | 526M | 475M | 0.9 | preprocessing_log.peakmem_pca('pbmc3k', 'off-axis') |; | + | 337M | 427M | 1.27 | preprocessing_log.peakmem_pca('pbmc68k_reduced', None) |. Comparison: <https://github.com/scverse/scanpy/compare/6440515ebce6e38b62bac5bce6d656f71fbeaa5b..b4260358866324a1097cdce17315ceebfe0cef0b>; Last changed: <time datetime=""2024-11-05T17:45:59.140604492+00:00"">Tue, 5 Nov 2024 17:45:59 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/3335/checks?check_run_id=32547112235>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3335#issuecomment-2450337223:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335#issuecomment-2450337223,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark']"
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. ## Benchmark changes. | Change | Before [73dc2d57] | After [13d69687] | Ratio | Benchmark (Parameter) |; |----------|----------------------|---------------------|---------|-----------------------------------------------------------|; | + | 235M | 270M | 1.15 | preprocessing.SparseDenseSuite.peakmem_mean_var('pbmc3k') |; | - | 506±2ms | 33.3±1ms | 0.07 | preprocessing.SparseDenseSuite.time_mean_var('lung93k') |; | + | 9.98±0.07ms | 11.9±0.3ms | 1.19 | preprocessing.time_highly_variable_genes |. Comparison: <https://github.com/scverse/scanpy/compare/73dc2d57f7023a56528afb1e421b300cd599ca03..13d6968735aadd965b0c18fbf081bd7cace43ac2>; Last changed: <time datetime=""2024-04-23T15:10:02.966082287+00:00"">Tue, 23 Apr 2024 15:10:02 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/3024/checks?check_run_id=24158988977>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3024#issuecomment-2072610500:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3024#issuecomment-2072610500,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark']"
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. ## Benchmark changes. | Change | Before [8d046ff3] | After [d9877c99] | Ratio | Benchmark (Parameter) |; |----------|----------------------|---------------------|---------|-------------------------|; | + | 15.1±0.05ms | 17.2±0.1ms | 1.14 | tools.time_leiden |. Comparison: <https://github.com/scverse/scanpy/compare/8d046ff37e024ae88eadfb22ea8fd142a6b95aa1..d9877c996b655a236f14fc242717a637365cd7d8>; Last changed: <time datetime=""2024-06-04T12:01:33.019653852+00:00"">Tue, 4 Jun 2024 12:01:33 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/3041/checks?check_run_id=25784166991>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3041#issuecomment-2085223116:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041#issuecomment-2085223116,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark']"
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. ## Benchmark changes. | Change | Before [ad657edf] | After [3e3ca9dc] | Ratio | Benchmark (Parameter) |; |----------|----------------------|---------------------|---------|-------------------------------------------------------|; | - | 404M | 339M | 0.84 | preprocessing_log.peakmem_pca('pbmc68k_reduced') |; | - | 1.61±0.01s | 11.6±0.4ms | 0.01 | preprocessing_log.time_regress_out('pbmc68k_reduced') |. Comparison: <https://github.com/scverse/scanpy/compare/ad657edfb52e9957b9a93b3a16fc8a87852f3f09..3e3ca9dcb2e77e72b75095ff895cb55aeb7f98bc>; Last changed: <time datetime=""2024-06-19T06:43:50.224108692+00:00"">Wed, 19 Jun 2024 06:43:50 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/3110/checks?check_run_id=26405245612>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110#issuecomment-2175920188:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110#issuecomment-2175920188,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark']"
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. ## Benchmark changes. | Change | Before [ad657edf] | After [e7a46626] | Ratio | Benchmark (Parameter) |; |----------|----------------------|---------------------|---------|--------------------------------------------------------------------|; | + | 259M | 310M | 1.2 | preprocessing_log.FastSuite.peakmem_mean_var('pbmc68k_reduced') |; | + | 1.16±0.04ms | 1.97±0.5ms | 1.69 | preprocessing_log.FastSuite.time_mean_var('pbmc68k_reduced') |; | + | 255M | 315M | 1.23 | preprocessing_log.peakmem_highly_variable_genes('pbmc68k_reduced') |; | - | 373M | 322M | 0.86 | preprocessing_log.peakmem_pca('pbmc68k_reduced') |; | - | 1.03G | 779M | 0.76 | preprocessing_log.peakmem_scale('pbmc3k') |; | - | 729±5ms | 517±5ms | 0.71 | preprocessing_log.time_scale('pbmc3k') |. Comparison: <https://github.com/scverse/scanpy/compare/ad657edfb52e9957b9a93b3a16fc8a87852f3f09..e7a466265b08f6973a5cf3fecfc27879104c02f4>; Last changed: <time datetime=""2024-06-18T18:39:49.652804667+00:00"">Tue, 18 Jun 2024 18:39:49 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/3099/checks?check_run_id=26384736173>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3099#issuecomment-2173199129:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099#issuecomment-2173199129,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark']"
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. ## Benchmark changes. | Change | Before [b3b9d057] | After [2709e08f] | Ratio | Benchmark (Parameter) |; |----------|----------------------|---------------------|---------|-----------------------------------------|; | - | 555M | 504M | 0.91 | preprocessing_log.peakmem_pca('pbmc3k') |. Comparison: <https://github.com/scverse/scanpy/compare/b3b9d0576897a8da5a4ae765b4b0b5609cebc890..2709e08fe39d3440c904b3cfcb1913611d9bc672>; Last changed: <time datetime=""2024-06-03T11:53:59.063275619+00:00"">Mon, 3 Jun 2024 11:53:59 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/3082/checks?check_run_id=25730907542>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3082#issuecomment-2141591369:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3082#issuecomment-2141591369,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark']"
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. ## Benchmark changes. | Change | Before [c26480ed] | After [57732d09] | Ratio | Benchmark (Parameter) |; |----------|----------------------|---------------------|---------|-------------------------------------------------------------------|; | - | 8.01±0.2ms | 7.05±0.07ms | 0.88 | preprocessing_counts.time_calculate_qc_metrics('pbmc68k_reduced') |; | + | 526M | 611M | 1.16 | preprocessing_log.peakmem_pca('pbmc3k') |. Comparison: <https://github.com/scverse/scanpy/compare/c26480ed0dc2f7d27b796e0e355b29a8305886c6..57732d095a98202237b0a0882dc072aba9cb6a64>; Last changed: <time datetime=""2024-05-14T11:28:07.702931216+00:00"">Tue, 14 May 2024 11:28:07 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/3044/checks?check_run_id=24945403112>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3044#issuecomment-2096259843:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044#issuecomment-2096259843,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark']"
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. ## Benchmark changes. | Change | Before [d2a53680] | After [69f9781b] | Ratio | Benchmark (Parameter) |; |----------|----------------------|---------------------|---------|----------------------------------------------------------|; | - | 1.24G | 1.03G | 0.83 | preprocessing_counts.peakmem_scrublet('pbmc3k') |; | - | 466M | 366M | 0.79 | preprocessing_counts.peakmem_scrublet('pbmc68k_reduced') |; | - | 7.53±0.3ms | 6.76±0.08ms | 0.9 | preprocessing_counts.time_log1p('pbmc3k') |; | - | 11.2±0.06s | 3.22±0.08s | 0.29 | preprocessing_counts.time_scrublet('pbmc3k') |. Comparison: <https://github.com/scverse/scanpy/compare/d2a53680e312835b998077b4e25b254e98bcb5ba..69f9781b5ae3970d735c3b68879a791164d6a54d>; Last changed: <time datetime=""2024-05-13T14:51:19.793580061+00:00"">Mon, 13 May 2024 14:51:19 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/3031/checks?check_run_id=24903996679>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3031#issuecomment-2098845648:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031#issuecomment-2098845648,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark']"
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. ## Benchmark changes. | Change | Before [d8941678] | After [25153094] | Ratio | Benchmark (Parameter) |; |----------|----------------------|---------------------|---------|------------------------------------------------------------------------|; | - | 417±30μs | 368±10μs | 0.88 | preprocessing_counts.FastSuite.time_log1p('pbmc68k_reduced', 'counts') |; | + | 1.06±0.03ms | 1.22±0.04ms | 1.15 | preprocessing_log.FastSuite.time_mean_var('pbmc68k_reduced', None) |. Comparison: <https://github.com/scverse/scanpy/compare/d8941678c5499a007c3d05d8caa857953624667c..25153094340bdb53a809c83e8ccb5ca4c3907277>; Last changed: <time datetime=""2024-07-25T13:13:34.147306645+00:00"">Thu, 25 Jul 2024 13:13:34 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/3166/checks?check_run_id=27909511375>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3166#issuecomment-2250211497:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3166#issuecomment-2250211497,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark']"
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. ## Benchmark changes. | Change | Before [dea050f6] | After [968b5f10] | Ratio | Benchmark (Parameter) |; |----------|----------------------|---------------------|---------|---------------------------------------------------|; | + | 7.32±0.3ms | 11.3±0.3ms | 1.54 | preprocessing_log.FastSuite.time_mean_var('bmmc') |; | - | 585M | 530M | 0.91 | preprocessing_log.peakmem_pca('pbmc3k') |. Comparison: <https://github.com/scverse/scanpy/compare/dea050f63f252d73f4716145e8a166f6ffc043dd..968b5f103083fa98026ad54895422d9497e0bc9f>; Last changed: <time datetime=""2024-05-14T13:44:50.161067475+00:00"">Tue, 14 May 2024 13:44:50 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/3058/checks?check_run_id=24950898322>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3058#issuecomment-2110261194:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3058#issuecomment-2110261194,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark']"
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. ## Benchmark changes. | Change | Before [ee8505b1] | After [d9829365] | Ratio | Benchmark (Parameter) |; |----------|----------------------|---------------------|---------|-----------------------------------------------------------------|; | - | 508±2ms | 31.9±1ms | 0.06 | preprocessing.SparseDenseSuite.time_mean_var('lung93k') |; | + | 1.09±0.04ms | 1.22±0.04ms | 1.12 | preprocessing.SparseDenseSuite.time_mean_var('pbmc68k_reduced') |; | + | 241M | 330M | 1.37 | preprocessing.peakmem_pca |; | + | 5.86±0.01ms | 6.86±0.03ms | 1.17 | preprocessing.time_calculate_qc_metrics |. Comparison: <https://github.com/scverse/scanpy/compare/ee8505b1c1578af0c50defdb3cf64ec18713669e..d9829365d7e23aea5680990ea8570d0a384291d3>; Last changed: <time datetime=""2024-04-23T09:27:27.323605771+00:00"">Tue, 23 Apr 2024 09:27:27 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/3015/checks?check_run_id=24144155267>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3015#issuecomment-2066282949:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3015#issuecomment-2066282949,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark']"
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. No changes in benchmarks. > [!WARNING]; > Some benchmarks failed. Comparison: <https://github.com/scverse/scanpy/compare/3d220a93c83fdd60ee3220c94db3dd8d5533c60d..1909f4c3d4f478c4cfcf406899029e184fefdef0>; Last changed: <time datetime=""2024-10-25T10:27:40.594535670+00:00"">Fri, 25 Oct 2024 10:27:40 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/3319/checks?check_run_id=32055740492>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3319#issuecomment-2437435413:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3319#issuecomment-2437435413,3,['benchmark'],"['benchmark', 'benchmarks']"
Testability,"<!-- DO NOT REMOVE: Scverse benchmark run comment marker -->. No changes in benchmarks. Comparison: <https://github.com/scverse/scanpy/compare/4f6e69005547647da24f8e212474f27f54f5da89..7378b49766e962d66480fceef63f9dfa0e0bd0fd>; Last changed: <time datetime=""2024-04-16T09:08:31.433837523+00:00"">Tue, 16 Apr 2024 09:08:31 +0000</time>. More details: <https://github.com/scverse/scanpy/pull/2977/checks?check_run_id=23867949423>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2977#issuecomment-2035033923:28,benchmark,benchmark,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2977#issuecomment-2035033923,2,['benchmark'],"['benchmark', 'benchmarks']"
Testability,"<notifications@github.com> wrote:. > Hi, looks great!; >; > The only duplicated code left is that _prepare_weighted_dataframe is very; > similar to _prepare_dataframe. I think you can delete; > _prepare_weighted_dataframe and just change _prepare_dataframe so it does return; > categories, obs_tidy, categorical. Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > that this takes long and is frustrating. If this is the case, just step; > away for a while and do something else! But I think you won’t regret doing; > this. You’re learning good coding pra",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:1116,test,test,1116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578,1,['test'],['test']
Testability,=) | `74.94% <100.00%> (ø)` | |; | [scanpy/datasets/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3050?src=pr&el=tree&filepath=scanpy%2Fdatasets%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2RhdGFzZXRzL191dGlscy5weQ==) | `100.00% <100.00%> (ø)` | |; | [scanpy/external/pp/\_magic.py](https://app.codecov.io/gh/scverse/scanpy/pull/3050?src=pr&el=tree&filepath=scanpy%2Fexternal%2Fpp%2F_magic.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3BwL19tYWdpYy5weQ==) | `86.11% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3050?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3V0aWxzLnB5) | `97.36% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/fixtures/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/3050?src=pr&el=tree&filepath=scanpy%2Ftesting%2F_pytest%2Ffixtures%2Fdata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9kYXRhLnB5) | `100.00% <ø> (ø)` | |; | [scanpy/testing/\_pytest/marks.py](https://app.codecov.io/gh/scverse/scanpy/pull/3050?src=pr&el=tree&filepath=scanpy%2Ftesting%2F_pytest%2Fmarks.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `100.00% <100.00%> (ø)` | |; | [scanpy/tools/\_ingest.py](https://app.codecov.io/gh/scverse/scanpy/pull/3050?src=pr&el=tree&filepath=scanpy%2Ftools%2F_ingest.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19pbmdlc3QucHk=) | `77.23% <100.00%> (ø)` | |; | [scanpy/tools/\_louvain.py,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3050#issuecomment-2104675113:2679,test,testing,2679,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3050#issuecomment-2104675113,1,['test'],['testing']
Testability,==================; Files 110 111 +1 ; Lines 12100 12133 +33 ; ==========================================; + Hits 8818 8848 +30 ; - Misses 3282 3285 +3 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/experimental/pp/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4cGVyaW1lbnRhbC9wcC9faGlnaGx5X3ZhcmlhYmxlX2dlbmVzLnB5) | `63.69% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3V0aWxzLnB5) | `45.16% <100.00%> (+1.82%)` | :arrow_up: |; | [scanpy/testing/\_pytest/fixtures/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9fX2luaXRfXy5weQ==) | `94.11% <ø> (-2.44%)` | :arrow_down: |; | [scanpy/tools/\_rank\_genes\_groups.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19yYW5rX2dlbmVzX2dyb3Vwcy5weQ==) | `92.77% <100.00%> (-0.03%)` | :arrow_down: |; | [scanpy/testing/\_pytest/params.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9wYXJhbXMucHk=) | `94.73% <94.73%> (ø)` | |; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2696#issuecomment-1766017585:1896,test,testing,1896,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2696#issuecomment-1766017585,1,['test'],['testing']
Testability,"> ## Question; > ; > Does this interact with group colors and dendrograms at all?. Dendrogram and colors seem not affected. > ## Test change; > ; > All of the plots will start failing because this will change the output for every test. I have a few concerns here:; > ; > * I'm worried about repo bloat from the plotting tests. Ideally we could just store the reference images outside of git (git lfs maybe?). Updating all the plots with `tight_layout` would increase repo size by 10%; > ; > * Is `tight_layout` deterministic ([matplotlib/matplotlib#11809 (comment)](https://github.com/matplotlib/matplotlib/issues/11809#issuecomment-432726600))? Also, is matplotlib trying to replace it with [`constrained_layout`](https://matplotlib.org/stable/tutorials/intermediate/constrainedlayout_guide.html)?; > ; > * Does globally adding `tight_layout` add to test times? My impression was that it basically rendered the plot, fixed the borders, then rendered it again.; > ; > ; > Proposed solution:; > ; > Can we just explicitly extend the borders for this test? At a later point we can move plots to a different storage system, then have much more freedom in making changes to how they render. Sounds great, I think I managed to do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1735#issuecomment-796812772:129,Test,Test,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1735#issuecomment-796812772,5,"['Test', 'test']","['Test', 'test', 'tests']"
Testability,"> 'outline' could be good. We already have font outline that works similarly. Great!. > Can you take a look at the new type hints that I added. I am not sure if I did it right?. The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient.; - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return.; - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`; - `Sequence`→`Sequence[?]`; - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py; def _get_vmin_vmax(; […]; color_vector: Sequence[float],; ):; '''; […]; ```. ```py; logg.error(; ""The parameter […]""; […]; ""of plots.""; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/794#issuecomment-523541089:1229,log,logg,1229,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794#issuecomment-523541089,1,['log'],['logg']
Testability,"> * Make a case where a threshold can't be found (not sure how this would be done). Obviously I can test the plotting by directly unsetting the relevant things, but I'm not actually sure how to trigger a failure with the test data I'm afraid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2023#issuecomment-963035287:100,test,test,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2023#issuecomment-963035287,2,['test'],['test']
Testability,> * Not all methods have log fold changes (`'logreg'` for example). This will hopefully be fixed: https://github.com/theislab/scanpy/pull/1081#discussion_r393315428,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1152#issuecomment-610639662:25,log,log,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152#issuecomment-610639662,2,['log'],"['log', 'logreg']"
Testability,"> * Shouldn't `var_df` should get similar updates to `obs_df`?. I would suggest a different PR to address this. . > * Could we get tests for `get.obs_df`/ `get.var_df` for the issues you addressed here (repeated indices)?. Sure, I added new tests to `get.obs_df` to check duplicated keys.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-765255875:131,test,tests,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-765255875,2,['test'],['tests']
Testability,"> 2 sc.pl.rank_genes_groups_dotplot(adata, values_to_plot=possible_vals.pop()); 3 . ~/github/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_groups_plot(; 864 adata,; 865 plot_type='dotplot',. ~/github/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 534 from .._dotplot import dotplot; 535 ; --> 536 _pl = dotplot(; 537 adata,; 538 var_names,. ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 940 del kwds['color_map']; 941 ; --> 942 dp = DotPlot(; 943 adata,; 944 var_names,. ~/github/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds); 215 # get the same order for rows and columns in the dot_color_df; 216 # using the order from the doc_size_df; --> 217 dot_color_df = dot_color_df.loc[dot_size_df.index][dot_size_df.columns]; 218 ; 219 self.dot_color_df = dot_color_df. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key); 929 ; 930 maybe_callable = com.apply_if_callable(key, self.obj); --> 931 return s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911:1816,log,log,1816,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911,1,['log'],['log']
Testability,"> ; > ; > I had a same issue; > ; > My environment is; > ; > ```; > windows10; > python3.8.8 (conda env); > ```; > ; > scanpy installation; > `conda install -c conda-forge -c bioconda scanpy`; > ; > It looks work well on command prompt, but it wasn't work on jupyterlab(3.0); > ; > To solve this, I just installed all packages using pip, not conda.; > here is my install procedure; > ; > ```; > conda create -n test python=3.8; > pip install ipykernel; > pip install jupyterlab; > pip install scanpy; > pip install python-igraph; > pip install leidenalg; > pip install fa2; > ```; > ; > I tired a lot of install and environment combination, but always there was a problem with conda. Thanks! my scanpy was working but stopped reinstalling everything in a new environment again with pip got it working as you suggested",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872:411,test,test,411,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872,1,['test'],['test']
Testability,"> > I'm actually testing and tweaking someone else's code that was written a while ago. I assume they used; > > `import scanpy.api as sc` because it was appropriate then. I personally resolved my issue by downgrading versions, I just wanted to bring this up!; > ; > I encountered the same issue. Which version are you using to fix this?. nm, downgrading to 1.5.1 fixed my problem. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397#issuecomment-684933191:17,test,testing,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397#issuecomment-684933191,1,['test'],['testing']
Testability,"> > In the other word, the scvelo's 'scv.pl.velocity_embedding_stream' showing terminal differentiation cells develop to original cells. this was incorrected logically. why the scvelo showed the inverted result contrast with monocle result.; > ; > As @LuckyMD said, this is a question for `scvelo`.; > ; > > I guess what i make the cell order was wrong ?; > ; > The best way to check if ordering went wrong is to plot an embedding colored by some known grouping. If colors are all mixed up you know a mistake has done.; > ; > > i wonder whether the code just sorted the cell barcode on annData.obs but the annData.X's matrix? why was the order runing so quickly that the matrix of annData not be sorted at the same time?; > ; > Luckily `AnnData` is quite robust and it reorder any slot (`obs`, `obsp`, `obsm`…) according to the specified cell names.; > ; > d; Thanks i would check currently, and reported the result as soon as possible. ; Best,; hanhuihong",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1718#issuecomment-802436872:158,log,logically,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718#issuecomment-802436872,1,['log'],['logically']
Testability,"> > ooh, this time the benchmark shows really nicely how much faster it is!; > ; > Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time. @flying-sheep , can you look at the this benchmark test?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110#issuecomment-2181072184:23,benchmark,benchmark,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110#issuecomment-2181072184,3,"['benchmark', 'test']","['benchmark', 'test']"
Testability,"> > what about `X_coords` ?; > ; > Ha, I was mostly just trying to get rid of the `X_`! . ah right, anyway good for me!; > ; > > What about re-open the theislab/spatial branch and merge this PR there? I could then work on how to handle the new uns structure in the plotting functions and have a definitive version of multiple slices support in anndata.; > ; > I'd like to merge the changes currently in this PR to master since it fixes a bug with dataset reading. The changes to uns structure could go in another PR, but I'm waiting for an email back from 10x to make sure using the `library_id` as a key makes sense. Either way, the logic of getting the transformed coordinates etc. should be abstracted into a function so it's easy to change.; > . What do you mean by transformed coordinates? Also, to understand the inputs for anndata (output of spaceranger) you might have a look at this, if you are not already familiar with https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview. ; Also, ok for having `uns` changes in another PR, I can work on that as soon as this is merged.; > Update: heard back, the `library_id` should be fine, at least for this version.; > . good !. > > support for multiple slices should be first; > ; > I'm not sure I'm convinced of this. I've also already got some code ready to go for the connectivities and some examples of what can be done with it.; > ; > I'd like to hear what kind of stuff you want to be able to do with multiple slices. Are you interested in stitching together slides or holding arbitrary slides in an AnnData? I think I'd like to see a more fleshed out idea of what kinds of analysis could be done here before deciding on what kind of an API this should have, and cases we should be ready to handle.; > . support for multiple slices and concatenation of anndata objects is by far the priority to me. It's a really useful functionality since:; * most people don't work with one slide; * having the same ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1088#issuecomment-596965855:634,log,logic,634,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088#issuecomment-596965855,1,['log'],['logic']
Testability,"> @THZ34 can you create a reproducer where this happens, so I can add a test?. OK, I've upload the h5ad file to onedrive: https://bioplot-my.sharepoint.com/:u:/g/personal/tanghongzhen_bioplot_onmicrosoft_com/EUbNHPuin5pGuMPrmch6rsQBjHojfikr38EYgZEL4KAZ2A?e=T2YfkO.; The error will reapper in these code:; import anndata; import scanpy as sc; adata = ad.read_h5ad('debug.h5ad'); sc.tl.dendrogram(adata,groupby='leiden')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2804#issuecomment-2014432043:72,test,test,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2804#issuecomment-2014432043,1,['test'],['test']
Testability,> @Zethson do we really need a test here?. Yes!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2460#issuecomment-1493979120:31,test,test,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460#issuecomment-1493979120,1,['test'],['test']
Testability,"> @awnimo , for me test_phenograph.py fails with `E TypeError: Expected list, got numpy.ndarray`.; > Could you check please?; > This is certainly related to scipy 1.5. With scipy 1.4 the test works fine. Indeed, this error is related to scipy, and we have fixed that in Phenograph new release [1.5.7](https://github.com/dpeerlab/PhenoGraph#version-157). The `test_phenograph.py` does not fail with the new Phenograph release (`pip install -U phenograph`)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1080#issuecomment-703773746:187,test,test,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080#issuecomment-703773746,1,['test'],['test']
Testability,> @awnimo can you please test this? Does the plot look like you want it to?. @flying-sheep The plots look the same as expected. Compared plots using methods from Scanpy and Harmony,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1004#issuecomment-577771644:25,test,test,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1004#issuecomment-577771644,1,['test'],['test']
Testability,"> @eroell, what do you think?. See Phil's comment above, one more thing would be to add a test I suppose. If you want to try Phil's comments yourself @farhadmd7 please go ahead, else you can write here for more help as Phil mentioned!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3180#issuecomment-2263237897:90,test,test,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180#issuecomment-2263237897,1,['test'],['test']
Testability,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion?. Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python; sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False); ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/512#issuecomment-469760800:17,Test,Tests,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512#issuecomment-469760800,1,['Test'],['Tests']
Testability,"> @gokceneraslan here's a quick example:. Oh man, just noticed a horrible bug which leads to zero HVGs if batch_key is given but n_top_genes is not 😓 Somehow, highly_variable_genes with batch_key but without n_top_genes (which is the option I always use :) ) is never tested :/ Fixing now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032#issuecomment-617446080:268,test,tested,268,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032#issuecomment-617446080,1,['test'],['tested']
Testability,"> @pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:; > You'll need to add a scrublet entry to `extras_require` here:. Ahh, I see- thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-734715153:20,test,tests,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-734715153,2,"['log', 'test']","['logs', 'tests']"
Testability,"> @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]). Hi @Zethson ,; I tried running the modified testcase mentioned above , but it seems it is failing because sparse matrix is being passed in it as a parameter. As of now, our scale function is not implemented for the sparse matrices. It is expected that these tests will fail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1566771839:109,test,testcase,109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1566771839,2,['test'],"['testcase', 'tests']"
Testability,"> About the commit process: That's far far too much work to do it like you suggested. I don't have the time for this. As a general point about this PR: to me, the fair amount of the work of turning on flake8 deciding on the rules. Perhaps we should start with a subset of files then? I realize you did not come to the meeting where we talked about this, so perhaps there is a difference of expectations here, but we agreed to be conservative about the rules we turned on in `pre-commit`. Going through everything to make sure changes are correctly reverted is also takes a lot of time for me as the reviewer. I'd also like to limit that. ----------------. You said you used some automated tools to get faster compliance. What were these? In general, I would prefer to have a formatter that automatically ran than a tool that told me I formatted something wrong. -----------------. > `@ivirshup` I would keep the noqas. They are very easily searchable across the whole project and can be fixed later. I'm pretty strongly against this. `noqa`s just look like the formatter/ linter was wrong, and I'm not accepting that having no plan to address bugs. I think this should be a discussion with a broader set of the team. > ""Whats up with removing leading #s from comments?"" Not my choice either. What we have now is pep8 and flake8 compliant. If you're not happy with this we can ignore the rule. Yes, lets ignore this. >> ""I don't like replacing x == False with not x in all cases. Sometimes a variable could be a container, and an error should be thrown. I think cases have to be evaluated for this.""; >; > This should be covered by tests. In any case it is not good style and a violation. I will try and take a closer look at these changes. I'm particularly concerned that there will be cases where possible values are `None`, `True`, and `False`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-785871670:1631,test,tests,1631,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-785871670,1,['test'],['tests']
Testability,"> After #1156 I will update the function. Wait, does it use OR logic now?? Doesn't AND logic make more sense???",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1213#issuecomment-696776848:63,log,logic,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213#issuecomment-696776848,2,['log'],['logic']
Testability,"> Ah I think I see the issue! Feature branches should be based off `master` and directing the pull request there! I think what's happening is that a pre-commit hook was installed, but the config only exists on the `master` branch.; > ; > I think this should largely be manageable by rebasing onto master (e.g. `git rebase --onto master 1.7.x`) and changing the branch the PR is targeting via the github interface:. Thanks a lot, I rebased and changed the PR target to `master` so I hope everything is on track now! ; The pre-commit style checks were working as expected now (auto-edits only in the files / parts I edited). > Side note: We're considering separating the highly_variable_genes interface into multiple functions, since the arguments to the different methods don't always overlap in meaningful or intuitive ways. There's nothing you need to do about this right now, but just a heads up to keep the logic for this method separate from the main function. Sounds good!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-795469189:910,log,logic,910,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-795469189,1,['log'],['logic']
Testability,"> All tests in test_highly_variable_genes.py pass, but others like test_plotting.py::test_violin fail. I'm not sure why -- anyone have an idea?. They also fail for me for an unrelated change that does not even change code.; @ivirshup got any idea?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1985#issuecomment-907001063:6,test,tests,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985#issuecomment-907001063,1,['test'],['tests']
Testability,"> Also I don't think it returns a copy, so you would need to handle that. I've got a branch which implements cached datasets for testing as:. we could overcome this by simply updating anndata in the test then. > @cache is new in 3.8, but the implementation is:. what do you suggest to do? use your implementation or implement this wrapper?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1053622705:129,test,testing,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1053622705,2,['test'],"['test', 'testing']"
Testability,"> Also isn’t it cool that it points exactly to the problematic line?. Currently, I think the line number reported is the number of lines past the `:` in the function definition. It'd be really nice if it could tell you which line number in the file it was (which might be difficult for manipulated doc-strings). Also, from what the error message says, isn't the `any(broken)` check testing the same thing as assert lines[0], `f""{name} needs a single-line summary""`? Isn't the first one sufficient?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1492#issuecomment-725996519:382,test,testing,382,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492#issuecomment-725996519,2,"['assert', 'test']","['assert', 'testing']"
Testability,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?); > ; > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-733750462:58,test,test,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-733750462,1,['test'],['test']
Testability,"> Although it states so:. UMAP only uses the representation of a data matrix for determining the number of connected components of the graph for the init conditions [if these aren't explicitly defined (they are if choosing `init_pos='paga'`): https://github.com/lmcinnes/umap/blob/948f60ff0caf7ccef0ab68626c7b99a11e66f1bb/umap/umap_.py#L958-L965. In fact, the only place where it enters is for the computation of the mean positions of the disconnected components: https://github.com/lmcinnes/umap/blob/948f60ff0caf7ccef0ab68626c7b99a11e66f1bb/umap/spectral.py#L50. Implementation-wise, it's a bit unfortunate that the data matrix is carried through all these functions just for that reason... But it's not a problem for the results. The confusing logging is fixed via; https://github.com/theislab/scanpy/commit/a5bd1ecd8ab04ec79369f60d3656f578a4cde40c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666#issuecomment-497630093:747,log,logging,747,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-497630093,1,['log'],['logging']
Testability,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:266,log,logging,266,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804,2,"['log', 'test']","['logging', 'test']"
Testability,"> Are we documenting here which of these have counts vs log vs normalized?. yeah, I’d like to do that! It’s really not bad. ```console; ❯ hatch test --internet-tests scanpy/tests/test_datasets.py::test_doc_shape scanpy/datasets/; [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent; ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮; │ # │ path │ physical │; ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤; │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │; ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent; ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮; │ # │ path │ physical │; ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤; │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │; │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │; │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │; │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │; │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │; │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │; │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │; │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │; ╰───┴──────────────────────────────────────────────────────────────────────",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3060#issuecomment-2117262252:56,log,log,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060#issuecomment-2117262252,4,"['log', 'test']","['log', 'test', 'tests']"
Testability,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > ; > Also: If trying to call a t-test with non-logarithmized data, a warning should be written.; > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?. Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-478377325:214,test,test,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-478377325,4,"['log', 'test']","['log', 'logarithmized', 'test']"
Testability,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial?. no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python; img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]; scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][; ""tissue_hires_scalef""; ]; sc.pl.spatial(; adata,; color=""leiden"",; scale_factor=scalef,; img=img,; size=100,; basis=""spatial"",; groups=[""0""],; ); ```; ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-750338610:1433,test,tests,1433,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-750338610,1,['test'],['tests']
Testability,"> Can we keep the docs on what exactly is happening + how to troubleshoot somewhere in this doc? This means things like: How to tag + build locally, twine check, list contents of distributed file etc. Sure, as we agreed on in person, I’ll just add a section to the end of the document.; If the build process or package structure aren’t touched, doing things manually isn’t necessary. > We should also automate some checks to avoid broken releases. As we agreed in person: Let’s postpone this. E.g. don't allow this except on specific branches + probably turn on merge queue so we know only commits that pass tests + doc builds get to those branches. This PR automatically does `twine check`, which is enough improvement over “trust the person doing the release to do that” to be worth the change, even if it wasn’t for the added convenience!. /edit: all addressed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678:608,test,tests,608,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678,1,['test'],['tests']
Testability,"> Can you point to a package whose test organization you would like our tests to emulate?. - pytest: https://github.com/pytest-dev/pytest/tree/main/testing; - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:35,test,test,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986,8,['test'],"['test', 'testing', 'tests']"
Testability,> Could you add a test to make sure the correct values are being used?. What did you have in mind? A minimum value (e.g. 20?) for the max to check that unlogged values are input?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2025#issuecomment-963032563:18,test,test,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2025#issuecomment-963032563,1,['test'],['test']
Testability,"> Do you know why the test is failing?. @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that?. I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/797#issuecomment-536861482:22,test,test,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797#issuecomment-536861482,2,['test'],['test']
Testability,"> Do you think you could make a PR with this to sklearn? I'd like to see the response it gets, and judge based on that. My preference would be for this to go there, but I'm very open to having this in our codebase until it's in a `sklearn` release. I'll try and do that soon. For now, I'll focus on providing you with the benchmarks you requested!. > * Datasets size (one small, one large (>50k cells)); > * Implicit centering, densifying centering, no centering; > * single threaded, multi-threaded <---------. I could not find a `n_jobs` argument in `scanpy.pp.pca`. Can you elaborate a little on the single threaded, multi-threaded bit?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589512273:322,benchmark,benchmarks,322,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-589512273,1,['benchmark'],['benchmarks']
Testability,> Failing test looks similar to what happens when I run out of memory locally. I’ve mostly seen these “illegal instruction” errors in a case where something is run on the wrong CPU architecture (e.g. compiled for a newer architecture than supported on that specific runner),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2815#issuecomment-1905756533:10,test,test,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1905756533,1,['test'],['test']
Testability,"> First, thanks for adding more tests!. Sure thing. Thanks for all the great feedback!. > 1. Is the file `scanpy/tests/_images/scatter_filtered_genes_raw.png` meant to be here?. No, thanks for catching that. > 2. Could the tests be broken up by what they are asserting? I would prefer to break up what is being tested by test case ; rather than values of parameters. Yes, I've broken both of the tests down into multiple tests. > 3. Could we cut down on the number of reference images generated since those cause manual maintenance burden on some matplotlib updates. These reference based tests are not great for confirming the correct plot is output, only that their output is consistent across commits.; > I think some of these cases could instead be tested with `check_same_image`, e.g. where it doesn't matter whether raw is `True` or `None`. Also testing for checking cases where `use_raw=True` would be equivalent to passing `pbmc.raw.to_adata()`. I've cut the number of reference images down to two. I couldn't figure out a clever way to use `check_same_image()` instead of `save_and_compare_images()` for these as you did for the others. See below for comments about individual suggestions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027#issuecomment-966240677:32,test,tests,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027#issuecomment-966240677,11,"['assert', 'test']","['asserting', 'test', 'tested', 'testing', 'tests']"
Testability,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE?. ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py; if use_fast_tsne is not None:; warnings.warn(""..."", FutureWarning); match (use_fast_tsne, flavor):; case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'; case (None, _): ... # use specified flavor; case (True, 'auto'): ... # use 'multicore'; case (True, 'sklearn'): ... # throw error; case (True, _): ... # use specified flavor; case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'; case (False, _): ... # Throw error; case _: ... raise AssertionError(); ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668:445,log,logic,445,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668,2,"['Assert', 'log']","['AssertionError', 'logic']"
Testability,"> From my error log it seems the only non-noarch dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py). That’s surprising! I think numba is our most complex dependency, and umap’s dependency PyNNDescent is also compiled. I think if this isn’t a mistake and it’s really just about h5py, we can think about it. Trying to install scanpy and following JupyterLite’s debug instructions gives:. ![image](https://github.com/scverse/scanpy/assets/291575/07a30013-e78d-46af-80fd-fb48af71d45b). ```pytb; ValueError: Can't find a pure Python 3 wheel for: 'umap-learn>=0.3.10', 'session-info', 'numba>=0.41.0'; See: https://pyodide.org/en/stable/usage/faq.html#why-can-t-micropip-find-a-pure-python-wheel-for-a-package; ```. (session-info isn’t a problem, it’s just an old package that doesn’t publish wheels)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731:16,log,log,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731,1,['log'],['log']
Testability,"> Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries?. Sorry yep tests added. And yep, the value_counts() will also catch empty categories (though added a test for that too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490#issuecomment-727864463:30,test,test,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490#issuecomment-727864463,3,['test'],"['test', 'tests']"
Testability,"> Had this problem, followed the `scikit-misc` package [issue](https://github.com/has2k1/scikit-misc/issues/12) on a related problem and installed the recommended patch with; > ; > ```; > pip install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1""; > ```; > ; > Seems to work now for me. Thank you. It just worked for me, in July 2024.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559:211,test,test,211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559,1,['test'],['test']
Testability,"> Hello @LuckyMD Thanks for the response! Could you please also check why the logFC becomes negative and disappear for the marker genes of clusters? #2057 Thanks! Best, YJ. Because adata was regressed, gene expression will become negative, cannot be loged.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2110#issuecomment-1103470609:78,log,logFC,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110#issuecomment-1103470609,2,['log'],"['logFC', 'loged']"
Testability,"> Hello, For information: if I understood correctly, there could be a risk on the current version of `score_genes_cell_cycle` method when the `adata.raw` is present:; > ; > * `score_genes_cell_cycle` is based on `score_genes` method which seems to use `adata.raw` to estimate gene score when it is present by default. As far as I know, people often store log-transformed counts to `adata.raw` (an example could be found [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html)).; > * However, according to [here](https://nbviewer.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb), ""Log-transformation of data and scaling should always be performed before scoring.""; > ; > In this situation, when people use `adata.raw` to store logged values, and apply `score_genes_cell_cycle` method to the object without explicitly setting `use_raw = False`, the results could be problematic, unless there is some specific processing overwritting `score_genes`' initial behaviour that I was not aware of. Hi @LuckyMD , I also have a few uncertainties regarding the `score_genes` function in scanpy. Although the documentation states that it behaves similarly to seurat, I came across some references ([here](https://github.com/satijalab/seurat/blob/763259d05991d40721dee99c9919ec6d4491d15e/R/utilities.R#L273) and [here](https://github.com/mojaveazure/seurat-object/blob/3c9e3df0b44a7f6e31e8e0af5d04d398b2b1f004/R/assay.R#L1040)) that suggest seurat operates on the slot of data corresponding to the value after logNormalize. I would appreciate it if you could help me understand why scanpy suggests operating on the matrix after scale instead. Please forgive me if I missed something obvious.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1599#issuecomment-1466032257:355,log,log-transformed,355,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1599#issuecomment-1466032257,4,"['Log', 'log']","['Log-transformation', 'log-transformed', 'logNormalize', 'logged']"
Testability,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion!; > ; > To me, this looks pretty close to ready. Just a few things to address:; > ; > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this.; > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns?; > * Any thoughts on solutions for the name collision?; > ; > Thanks!. Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1; Please let me know if there is anything else needed to merge.; Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/503#issuecomment-562279386:209,test,test,209,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503#issuecomment-562279386,2,['test'],['test']
Testability,"> Hey @ywen1407!; > ; > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though.; > ; > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1431#issuecomment-699114229:1130,test,tested,1130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431#issuecomment-699114229,1,['test'],['tested']
Testability,"> Hi @sygongcode,; > ; > Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy). Yes, that is what I want to do. Thank you so much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/821#issuecomment-529218989:70,test,testing,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821#issuecomment-529218989,1,['test'],['testing']
Testability,"> Hi, It's not available in scanpy at the moment, but I wrote a wrapper for it via `rpy2` and `anndata2ri` which is available here:; > https://github.com/normjam/benchmark/blob/master/normbench/methods/ad2seurat.py. Hi,. I have been trying to use this wrapper, but seems like there's some error during the conversion process:. RRuntimeError: Error in validObject(.Object) : ; invalid class “dgCMatrix” object: 1: invalid object for slot ""i"" in class ""dgCMatrix"": got class ""array"", should be or extend class ""integer""; invalid class “dgCMatrix” object: 2: invalid object for slot ""p"" in class ""dgCMatrix"": got class ""array"", should be or extend class ""integer""; invalid class “dgCMatrix” object: 3: invalid object for slot ""Dim"" in class ""dgCMatrix"": got class ""array"", should be or extend class ""integer""; invalid class “dgCMatrix” object: 4: invalid object for slot ""x"" in class ""dgCMatrix"": got class ""array"", should be or extend class ""numeric"". Any pointers to get around this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-866121061:162,benchmark,benchmark,162,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-866121061,1,['benchmark'],['benchmark']
Testability,"> Hi, for `method='wilcoxon'` this is [Wilcoxon rank-sum test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test), and the scores are U_1 from methods in in the link. Higher absolute value of score -> lower p-value (more evidence the levels of expression between groups are different), higher score indicates higher expression, lower score -> lower expression. Thank you very much !!!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1688#issuecomment-785029681:57,test,test,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1688#issuecomment-785029681,1,['test'],['test']
Testability,"> How do we xfail stuff from dev?. [`pytest.mark.xfail`](https://docs.pytest.org/en/6.2.x/reference.html#pytest-mark-xfail) takes a condition:. ```py; xfail_if_dev_tests = pytest.mark.xfail(; os.environ.get(""DEPENDENCIES_VERSION"", ""latest"") == ""pre-release"",; reason=""..."",; ). @xfail_if_dev_tests; def test_xzy(): ...; ```. You probably need to change the tests so it makes the CI variable visible as an env variable, I’m not an Azure expert so I don’t know if it already is. > Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test. Yeah, maybe, let’s see once everything passes. I’m also OK with lowering the percentage, I just set it to 75% to have some indication if codecov is broken or working. (Before it would report 20% for a PR and there would be no visual indication that that’s a problem)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2114691148:357,test,tests,357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2114691148,2,['test'],"['test', 'tests']"
Testability,"> Huh. This is really weird, since it looks like it's almost entirely due to scipy sparse indexing. Must have something to do with versions. Two things:; > ; > * If you upgrade scipy, do you still run into this error?; > * Could you get the version info from an environment where you've only imported scanpy and run this command?. I will try to update scipy. Here is the output from only import scanpy:; BTW, everything works fine until I updated scanpy to 1.7.0. ```; anndata 0.7.4; scanpy 1.7.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; backcall 0.2.0; cairo 1.19.1; cffi 1.14.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; future_fstrings NA; get_version 2.1; h5py 2.10.0; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.1; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.8; pandas 1.2.1; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.6; psutil 5.7.2; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.7.0; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; storemagic NA; tables 3.6.1; texttable 1.6.2; tornado 6.0.4; traitlets 4.3.3; wcwidth 0.2.5; zmq 19.0.2; zope NA; -----; IPython 7.17.0; jupyter_client 6.1.6; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]; Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-02-21 23:42; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1670#issuecomment-783075376:1596,log,logical,1596,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670#issuecomment-783075376,1,['log'],['logical']
Testability,"> I doubt that it would be considered a branch of logic. What do you define as logic here? I was talking about the logic theory that encompasses formal systems and so on. > [Union and intersection are bad names]. I agree, wikipedia enumerates more names, and explains where “union” comes from:. > tagged union, variant, variant record, choice type, discriminated union, disjoint union, or sum type; > …; > Mathematically, tagged unions correspond to disjoint or discriminated unions, usually written using +. Given an element of a disjoint union A + B, it is possible to determine whether it came from A or B. If an element lies in both, there will be two effectively distinct copies of the value in A + B, one from A and one from B. . I think “discriminated union/intersection of types” would make sense here. leaving out the “discriminated/tagged/disjoint” here is the problem. in C there’s actual *untagged* unions, which simply means that C reserves the memory for the largest of the intersected types and you need to keep track yourself of which the type of the value is. In python you can always do `isinstance`, so a more correct name for `Union[A, B]` would be `TaggedUnion[A, B]`. I’d also like `OneOf[A, B]`, but that ship has sailed. And intersections are basically duck types or structural types (when anonymous) and traits/interfaces (when named). (i.e. `hasattr(obj, 'foo')` defines an intersection type of all types having that attribute. So it makes sense for python, it’s just defined more explicitly than by literally intersecting types.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-443178140:50,log,logic,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-443178140,3,['log'],['logic']
Testability,"> I had also thought isort could be a good starting place, but it might actually be some work to turn on due to ""partially initialized module"" errors (imperative programming strikes again!). Yeah, I ran into this stuff when creating the flake8 PR (#1689). isort is dangerous with Scanpy and requires good testing and many exceptions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-785092164:305,test,testing,305,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-785092164,1,['test'],['testing']
Testability,"> I haven't worked much with h5py or tables, is it time-consuming to refactor these functions? It seems like moving to anndata is the most straightforward solution at least logically to me. In this case, I think it should be fine. It might not happen too soon if we're left to our own devices, so a PR is welcome. > I could just see a standalone package being widely used and community driven. What formats that aren't in `anndata` would you see in this package? I'm trying to get an idea of the kind of scope you're thinking of here. I think there are formats where there isn't one obvious ""right way"" to represent them as an AnnData object (e.g. visium), so having a canonical reading/ writing function is difficult.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1387#issuecomment-683586582:173,log,logically,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1387#issuecomment-683586582,1,['log'],['logically']
Testability,"> I know all that. :wink:. And I know that you know! I just like to be comprehensive when presenting my arguments!. > But numpy, pandas, scikit learn, tensorflow, seaborn all have the comma-separated list as a convention and I'd really like to stick to that convention. OK. I’d prefer “a, b, or c”, but I’ll concede. It would also be no problem to change it later since all will be automated :+1: . > No, the optional keyword always means that a parameter has a default. Very often, people forget to append ""or None"" (, None) to the list of possible types. Well, when I open scanpy in PyCharm and someone forgot that in a type annotation, it highlights that fact to me. Pretty nice. > As mentioned before, there is no point in using set-theoretic/logical notions like union or intersection as the topic is so simple that it doesn't need it (no need for an intersection, it's not even clear what that would mean; if you're stringent about it, it's also not clear for union). Oh, then you didn’t hear of type theory. It’s a branch of logic: Type systems are formal systems, and in most of them the terms I used are well defined. The kinds of composite types I mentioned are:. - `Union` of types / Sum Type / [Tagged Union](https://en.wikipedia.org/wiki/Tagged_union): Variables with one of those have one of several fixed types.; - Subtype / [Intersection Type](https://en.wikipedia.org/wiki/Type_system#Intersection_types): Variables have all the properties of the supertypes.; - `Tuple` / [Product Type](https://en.wikipedia.org/wiki/Product_type): Variables contain multiple entries that each have one corresponding type.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-442007106:747,log,logical,747,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-442007106,2,['log'],"['logic', 'logical']"
Testability,"> I saw some of the github automated tests test are failing now, but I don't really understand the error messages tbh ;) Are they even related to the execution of the code provided by this PR?. yeah also don't understand them, it might be @cache in py 3.7 has issues? will investigate next week and report back!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1050003610:37,test,tests,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1050003610,2,['test'],"['test', 'tests']"
Testability,"> I see them more as TODOs for later since the ""bad code"" is in master at the moment anyways. But if you want to discuss that - sure. I think it's hard to tell the difference between a `noqa` that was added because: ""most of the time, this rule is right, this time it is wrong"" vs. ""added to get rid of warning"". Could any `noqa`s added in this PR get something searchable added to them (like `# noqa: {rule} TODO: fix me`) so we know why it was added?. In a future meeting we can discuss with the whole team how we will actually fix these. I think it's a good task for a hackathon/ sprint. ------------. Looking at this again, I think this is pretty close to done. Just a few documentation/ minor rule changes left. - [x] Document how to turn off these checks in dev docs; - [x] Document the rules that are turned off (similar to [pandas](https://github.com/pandas-dev/pandas/blob/879cd22dd58b0574cdcaa7a26e396d5ec71a615a/setup.cfg#L71-L79)); - [x] Add autopep8 to precommit. If things can be fixed automatically, they should be. autopep8 should be able to get it's rules from the flake8 config.; - [x] Add annotation to `noqa`s.; - [x] Also add `TODO` annotation to `except Exception`s that have been added.; - [x] Turn off E731; - [x] Turn off the rule that doesn't allow multiple leading `#` in comments; - [x] Turn off F811 for tests (rule violated by using fixture as test argument); - Possible solution: add noqa for this to all files under `tests`, separate check that all files under tests have this.; - [x] Ignore `build` `docs/_build` directories",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-787412099:1333,test,tests,1333,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-787412099,4,['test'],"['test', 'tests']"
Testability,"> I suppose to do this properly one ought to scan the code base for uses of igraph, check which among them require the RNG and then add the seeding to those modules?. This would be nice, but would also be a lot of work. I was thinking a PR would just make the layouts for PAGA reproducible, and add a test making sure this is the case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1859#issuecomment-866576277:301,test,test,301,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859#issuecomment-866576277,1,['test'],['test']
Testability,"> I think that literally nobody is using this function for arrays and sparse matrices. I'm not sure about that. I got the impression from https://github.com/theislab/scanpy/issues/1030#issuecomment-607952458 and (IIRC) a conversation with @scottgigante that people would like these functions to work on arrays as well as AnnData objects. > In the very early days of Scanpy, I thought it'd be nice to also accept other formats of data matrices. I still think it would be nice to support that, it just requires factoring the code better. I agree recursively calling the same function for argument handling gets very confusing. However, I think we could do something more like this (note, it's not tested yet, and could be cleaner... it's my ten minute version):. <details>; <summary> Alternative implementation of scale </summary>. ```python; @singledispatch; def scale(X, *args, **kwargs):; """"""\; Scale data to unit variance and zero mean.; .. note::; Variables (genes) that do not display any variation (are constant across; all observations) are retained and set to 0 during this operation. In; the future, they might be set to NaNs.; Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; zero_center; If `False`, omit zero-centering variables, which allows to handle sparse; input efficiently.; max_value; Clip (truncate) to this value after scaling. If `None`, do not clip.; copy; If an :class:`~anndata.AnnData` is passed,; determines whether a copy is returned.; Returns; -------; Depending on `copy` returns or updates `adata` with a scaled `adata.X`,; annotated with `'mean'` and `'std'` in `adata.var`.; """"""; return scale_array(X, *args, **kwargs). @scale.register(np.ndarray); def scale_array(; X,; zero_center: bool = True,; max_value: Optional[float] = None,; copy: bool = False,; return_mean_var=False,; ):; if copy:; X = X.copy(); if not zero_center and max_value is not None:; logg.info( # Be careful of w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1135#issuecomment-608200735:695,test,tested,695,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1135#issuecomment-608200735,1,['test'],['tested']
Testability,"> I think the result in such a case could just contain nans and emit a warning. This sounds reasonable to me. With sparse values, it's consistently giving results, but it's the wrong results. The iteration is being chunked (probably related to number of available cores), and it looks like within each chunk all values after the constant one are filled with zeros. I should look into whether this is also numba, or a logic bug. If it's numba, it's strange that it's zeros and not `inf` or `nan`. If it's on our end, I'm not sure why the later iterations would be skipped. ----------. > p.s.: I really like how you document everything you do so nicely 😃. Thanks! Is mostly so I can remember my reasoning a month later 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-827271245:417,log,logic,417,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698#issuecomment-827271245,1,['log'],['logic']
Testability,"> I trust you that this helps 🤷. I guess we can add a test that cements this behavior, but it's tough to test that swap=original-transpose for the underlying data. I tried applying the ordering to what changed in the PR you referenced but that didn't help unfortunately. I don't know the provenance of that change, so I think this is fair. We are using the public API of seaborn in a way that fixes the underlying issue as one would expect.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3196#issuecomment-2271777638:54,test,test,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196#issuecomment-2271777638,2,['test'],['test']
Testability,"> I was considering to use the same tests from scanpy to identify marker genes but with a given set of markers as I want to know if a cluster could be annotated with a marker (which is different than to annotate a single cell). Any thoughts on this idea?. I think that makes sense too. Without multiple testing correction, I feel like that should be equivalent to just filtering the results for the marker genes you have. And as the scores/p-values of that test are not really measures of significance (#270), it would be difficult to evaluate whether the score/p-value is sufficient to assign the cluster annotation. However, this approach is no worse than mine... I wonder how you can evaluate these approaches? Is there a dataset with very similar cells? Maybe gut with goblet and tuft cells appearing annoyingly similar (@mbuttner)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/290#issuecomment-428506572:36,test,tests,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290#issuecomment-428506572,3,['test'],"['test', 'testing', 'tests']"
Testability,"> I wasn't really expecting this feature PR to also include such a large refactor. It would have been necessary for the Dask Dataframe version. Now I 1. did the work and 2. improved readability, so it would be counter productive to undo it. > I'm still not 100% convinced the behaviour here is exactly the same as before. I have done a few tests, which have been okay, but I haven't tried much parameterization. I'm ~80% convinced the results should be the same. If you have any specific things in mind, you should probably make a PR that adds tests for the properties you think we should preserve. We can then merge that one, update this one, and see if it actually breaks something. I can’t check for speculative differences if I have no idea where those could be. > I would note that the dataframe returned when inplace=False has a different index than it did previously. Yup, now it actually matches instead of discarding the original Index and replacing it with a RangeIndex for no reason. > Apart from the comments, can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. Sure! That’s a concrete thing I can do. I’ll do that on thursday, I did the rest of what you asked today",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931:340,test,tests,340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931,4,['test'],"['test', 'tests']"
Testability,"> I wonder why the tests are not working now?. Sorry, I forgot to update `violin.png` after the latest changes to `_anndata.py`. Let's see if the tests pass now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-696705252:19,test,tests,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-696705252,2,['test'],['tests']
Testability,"> I'd really like to have scanpy and anndata work better with dask, but am wary of a high code overhead. Could you provide examples of where you were running into issues with arrays being materialized?. You can see where the materialization occurs by looking for references to `materialize_as_ndarray` in the existing code. For example, in `filter_genes`: https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/_simple.py#L215, where the gene subset of materialized as an ndarray, then used to subset the anndata. Contrast this to the optimized version where the materialize step is not needed, and the data remains a dask array throughout the `filter_genes` method: https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/preprocessing/_dask_optimized.py#L18. > I think this can be worked around in AnnData side in many cases. That would be great. > Any chance you did any profiling of these runs? I'd be interested in seeing the performance impact across the pipeline. The closest I got to this was using the Dask web UI to watch tasks being run (see this part of the benchmark script: https://github.com/tomwhite/scanpy/blob/sparse-dask/benchmark.py#L54-L55). This is useful to see what operations are bottlenecks. The only timings I did were to run the complete recipe. On the GPU questions, these all sound like promising avenues, but I haven't looked into any of them.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-555940037:1086,benchmark,benchmark,1086,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921#issuecomment-555940037,2,['benchmark'],['benchmark']
Testability,"> I'm actually testing and tweaking someone else's code that was written a while ago. I assume they used; > `import scanpy.api as sc` because it was appropriate then. I personally resolved my issue by downgrading versions, I just wanted to bring this up!. I encountered the same issue. Which version are you using to fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397#issuecomment-684930174:15,test,testing,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397#issuecomment-684930174,1,['test'],['testing']
Testability,"> I'm curious about how much the backend changes the runtime and results of nearest neighbors methods. You can see some quick comparisons between Pynndescent and Annoy here: https://github.com/pavlin-policar/openTSNE/issues/101#issuecomment-597178379. But I have not investigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal t",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-633735833:548,benchmark,benchmarks,548,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233#issuecomment-633735833,1,['benchmark'],['benchmarks']
Testability,"> I'm not sure I know what the pytest execution model is like, but does it ever start new processes for different tests?. Apparently [it needs a plugin](https://pypi.org/project/pytest-parallel/) for that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/724#issuecomment-513132199:114,test,tests,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/724#issuecomment-513132199,1,['test'],['tests']
Testability,"> I'm not sure we're looking at the same code. I was looking at this:. I was looking at the [TruncatedSVD](https://github.com/scikit-learn/scikit-learn/blob/b194674c4/sklearn/decomposition/_truncated_svd.py#L186) code. Either way, I'm not able to reproduce your assertion error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-593744652:262,assert,assertion,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-593744652,1,['assert'],['assertion']
Testability,"> I'm not to sure what the assumptions are behind each method though. @falexwolf, any reason in particular you've chosen UMAP's method for the KNN calculation?. It's highly competitive in terms of speed and accuracy with other libraries (https://github.com/erikbern/ann-benchmarks, pynndescent is what umap uses, wasn't available at the time for Scanpy), it's a lot easier to install than everything else, and the result has been shown to harmonize well with UMAP, which I expected would become the canonical way of visualizing things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/277#issuecomment-427333649:270,benchmark,benchmarks,270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/277#issuecomment-427333649,1,['benchmark'],['benchmarks']
Testability,"> If I understand the .raw removal alternative correctly, then you would want to add masks to every operation in scanpy that is not DE and work with .layers?. Pretty much every function where you would want to use `highly_variable`. > It seems to me that adding masking like this would be quite a large endeavour, no?. I think a similarly sized endeavor to adding `highly_variable`, except we can use the `highly_variable` code where it's been implemented. I would expect this to be less effort than supporting `raw`, which is a constant maintenance burden, especially for `anndata`. I think this logic could be added to the `_get_obs_rep`, and `_set_obs_rep` functions. --------------. > If you assume anything filtered out was removed because it was predominantly 0. I'm not sure I like having this assumption. Especially when a collaborator asks ""what about gene X"", but it just wasn't in the table I received. Maybe it's an annotation issue, maybe it wasn't expressed, or maybe it wasn't expressed globally at a high enough level – but could have been expressed in the cells of interest. > you can assume it would not be in the HVG intersection for that dataset and if you add it,. Is intersection the way to go? If you have cell types which are only present in some datasets, wouldn't you want to take the union?. > Typically there is sufficient gene-gene covariance that you still keep this signal somehow. I would agree that it is unlikely that this would have a huge effect on analyses like PCA or UMAP. When it comes time to do differential expression or show expression on an embedding, then it starts to be an issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-822937305:597,log,logic,597,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-822937305,1,['log'],['logic']
Testability,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python; import vega_datasets; import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(; iris[""sepalLength""],; iris[""sepalWidth""],; c=iris[""petalLength""],; norm=norm,; vmin=3,; ); plt.colorbar(); ```. ```; MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax ; simultaneously is deprecated since 3.3 and will become an error two minor releases ; later. Please pass vmin/vmax directly to the norm when creating it.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-748567569:453,Log,LogNorm,453,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-748567569,1,['Log'],['LogNorm']
Testability,"> If we return an array of integers we run into trouble downstream with functions that aren't tested with integer arrays. Issues from this have been opened a few times, so when I wrote this I thought it might be worth just maintaining the input type. I'm not sure I agree with that now. This is quite a compelling argument for me (as I was one of the people who reported an issue like this). If an integer matrix is generally returned, then one would have to ensure all other functions will work with this data type as intended (sc.pp.log1p for example). Otherwise this would be backward-breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865#issuecomment-552814583:94,test,tested,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865#issuecomment-552814583,1,['test'],['tested']
Testability,"> If you don’t specify a seed, nondeterminism is to be expected. In general, I thought we went for determinism with default arguments in scanpy. I believe pynndescent faster, if non-deterministic, but I get constant output from scanpy. <details>; <summary> Test case </summary>. ```python; import scanpy as sc; import numpy as np. pbmc = sc.datasets.pbmc3k(). sc.pp.filter_genes(pbmc, min_counts=1); sc.pp.normalize_total(pbmc); sc.pp.log1p(pbmc). adatas = [pbmc.copy() for _ in range(10)]; for adata in adatas:; sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.umap(adata). umap_coords = [adata.obsm[""X_umap""] for adata in adatas]; assert all([np.array_equal(umap_coords[i], umap_coords[i+1]) for i in range(9)]); ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1363#issuecomment-674658333:257,Test,Test,257,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1363#issuecomment-674658333,2,"['Test', 'assert']","['Test', 'assert']"
Testability,"> In docstrings, why would you interpret a comma separated list as intersection or a tuple?. In natural language “a, b, c” usually means “a, b, and c” (i.e. a composite or a logical intersection). And an intersection type is one that has all the attributes of all the types, like in `class x(a, b, c): ...` (where commas are also used). In Python plain `a, b, c` constructs a tuple (a composite type): `tup = a, b, c`. It took me a long time to find a numpy function that uses commas for anything other than the “, optional”, but of course [you’re right](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.matrix_rank.html). They do it like that. Why don’t people think before establishing conventions…. A good example of that function’s docs is also how braindead the “optional” is: for `tol`, it means “or None”, for `hermetian` it means “has a default” (probably, no way to know for sure). Goddamn. > Ah, we already have a contributing sheet. oh, is this visible? or does it need to be uppercase for that? CONTRIBUTING.md? I don’t see it when creating an issue, but maybe because I’m an organization member?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441693979:174,log,logical,174,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441693979,1,['log'],['logical']
Testability,"> In natural language... ... I know all that. :wink: But numpy, pandas, scikit learn, tensorflow, seaborn all have the comma-separated list as a convention and I'd really like to stick to that convention. > A good example... . No, the `optional` keyword always means that a parameter has a default. Very often, people forget to append ""or None"" (`, None`) to the list of possible types. Btw: that's maybe a nice way of thinking about it for you: you use a ""tuple of possible types"" to denote that any of these types can be passed in the function. As mentioned before, there is no point in using set-theoretic/logical notions like union or intersection as the topic is so simple that it doesn't need it (no need for an intersection, it's not even clear what that would mean; if you're stringent about it, it's also not clear for union). So, let's simply take the comma-separated list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441771308:609,log,logical,609,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441771308,1,['log'],['logical']
Testability,"> In the other word, the scvelo's 'scv.pl.velocity_embedding_stream' showing terminal differentiation cells develop to original cells. this was incorrected logically. why the scvelo showed the inverted result contrast with monocle result. As @LuckyMD said, this is a question for `scvelo`. . > I guess what i make the cell order was wrong ? . The best way to check if ordering went wrong is to plot an embedding colored by some known grouping. If colors are all mixed up you know a mistake has done. > i wonder whether the code just sorted the cell barcode on annData.obs but the annData.X's matrix? why was the order runing so quickly that the matrix of annData not be sorted at the same time?. Luckily `AnnData` is quite robust and it reorder any slot (`obs`, `obsp`, `obsm`…) according to the specified cell names. d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1718#issuecomment-801970805:156,log,logically,156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718#issuecomment-801970805,1,['log'],['logically']
Testability,> In the tests that I have the heatmap seems to be ok. See https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Visualize-marker-genes-using-heatmap; > ; > Do you think that the problem occurs when lot of cells/genes are plotted?. It's possible.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/637#issuecomment-517332847:9,test,tests,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-517332847,1,['test'],['tests']
Testability,"> Is this enough to get started?. For sure, thank you for the context!. Is it possible to add a unit test that checks that with this set to `True`, clusters are better separated?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2731#issuecomment-1803331795:101,test,test,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2731#issuecomment-1803331795,1,['test'],['test']
Testability,> It is also an easy fix but requires the modification of adata.uns to save the colors. This seems reasonable since we already do it. Can you make sure to use the same `_get_palette` function for this? Maybe that should be moved out of `scatterplots.py` to somewhere more general?. We should probably have some logic for not saving the colors if the object is a view. Would have to think about this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1591#issuecomment-762781618:311,log,logic,311,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1591#issuecomment-762781618,1,['log'],['logic']
Testability,"> Moving 10x reading functions to anndata. I haven't worked much with h5py or tables, is it time-consuming to refactor these functions? It seems like moving to anndata is the most straightforward solution at least logically to me. > scanpy as a requirement. I like scanpy, but the only thing we really *require* in scvi is the data loading part. A user could take their scvi outputs and go use Seurat if that makes them happy. And then like the data loading functions are simple enough that we could just implement them ourselves. I'm sure a lot of people are currently doing this, which inspired the idea to have a standalone package. > Splitting off new modules. Your questions are very valid. I don't really have good answers for them. I could just see a standalone package being widely used and community driven, especially if there is some scanpy backing + maybe optional dependencies/functionality to get your objects ready for R analysis pipelines.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1387#issuecomment-680188365:214,log,logically,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1387#issuecomment-680188365,1,['log'],['logically']
Testability,"> My current thinking is that Gearys C is more sensitive to sparse features, and may be more in need of significance testing. I think this is not as visible for visium data since features are less sparse. Really interesting comparison @ivirshup . I think it makes sense that is more sensible to sparsity because the score is not computed ""against a mean"" but against the neighborhood graph. In some sense, Moran's I is more smooth. . > And this was the problem with p-values in squdpy-s Moran's I (plot for first 100 genes in my adata, using 100 permutations - but this should not really lead to low pvalues as I think that the reported pvalues are estimated based on null distn shape - not 100% sure though). indeed, they are computed against the null distribution that is computed from permutations. As a personal opinion, I don't think reporting p values for these type of statistics is very useful (as in, I personally wouldn't draw conclusions on significance, but more on effect size, and this holds true for a t-test as well imho...).; I should also say that for squidpy we might want to compute p-values out of completeness... but again I would refrain from looking at them. In that case I also think it's more fair since the graph comes from another source, and is not computed from gexp similarity.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-805613901:117,test,testing,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698#issuecomment-805613901,2,['test'],"['test', 'testing']"
Testability,"> My impression has been that doing the densifying scale transform didn't seem to show performance improvements in a number of benchmarks. This is also the workflow used in [sc-best-practices](https://www.sc-best-practices.org/preprocessing_visualization/normalization.html); > ; > @Zethson do you have a good citation for this?. Here's the English version of the reply:. Thank you very much for your authoritative answer! You mentioned that in some benchmarks, performing the densifying scale transform didn't show significant performance improvements. I also noticed that sc-best-practices adopts a similar workflow. However, I have a further question: if the step of adding this densifying scale transform is included, would it negatively impact the overall performance? For example, would it reduce the training or inference speed? Or would the impact be negligible?. Thank you again for taking the time to answer my questions! Your opinions are very insightful and helpful to me. I look forward to your further guidance!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034431485:127,benchmark,benchmarks,127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034431485,2,['benchmark'],['benchmarks']
Testability,"> New analysis tool: A simple analysis tool you have been using and are missing in sc.tools. What about alternative normalization tools like SCTransform? I read that they are supposed to be better for spatial data. As non-mathematician of course I'm not sure how big the difference will really be in the end but it would be great if there was a easy way to call and test them if it's worth it. > New plotting function: A kind of plot you would like to seein sc.pl?. I think a plot that shows the gene expression profile along a spatial axis would be nice if this is not planned yet. So to draw in e.g. a line in napari and get the gene expression of certain genes along this line. > External tools: Do you know an existing package that should go into sc.external.*?. A package I found very useful and easy to integrate with scanpy is SpatialDE. Are you planning to provide this in `sc.external.*`? And of course tools to integrate sc-RNA-seq and spatial data (like Stereoscope, cell2location,...) would be great! But I think you mentioned that there are plans for own tools, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1653#issuecomment-782699618:366,test,test,366,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1653#issuecomment-782699618,1,['test'],['test']
Testability,"> Nice! Needs some testing though to make sure it works (e.g. specifying a sequence of markers); > ; > You should also make sure the types are correct: `Optional[X]` means `X | None`. Is `None` a valid option? Does it make sense that the type is different in multiple spots? (`Optional[Sequence[str]]` vs `Union[str, Sequence[str], None]` vs `Union[str, Sequence[str]]`). You're absolutely right about the types. I changed the types such as all are accepting the same `Union[str, Sequence[str]]` now.; I also tested several situations I could think of, in [this notebook](https://colab.research.google.com/drive/1ltg0Qs_dlxS_RMuN7z1DdLLV7VLBtZtd?usp=sharing) and they all worked fine. If any more tests (different situations) are needed, please let me know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2545#issuecomment-1626372312:19,test,testing,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1626372312,3,['test'],"['tested', 'testing', 'tests']"
Testability,"> Oh interesting, I thought it was clear :) I mean you even contributed to the function, no?; > ; > I think we also discussed why not to use intersection by default in the PR: [#614 (comment)](https://github.com/theislab/scanpy/pull/614#issuecomment-485875031); > ; > If intersection is not used by default, why would we write in the documentation that it acts as a lightweight batch correction method. I'm as surprised as you are :). Yes, I fixed sth and reorganized a bit. I also recall our disc on `highly_variable_intersection`. However, I thought your organization of HVGs was only for the ranking in `highly_variable_nbatches`. Didn't see it's also the default for `highly_variable`. I never really looked at the docs... that would have given a hint... I still feel as though I have sth slightly different though if I recall. Will look more carefully once this benchmarking data integration thing is out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032#issuecomment-617120764:867,benchmark,benchmarking,867,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032#issuecomment-617120764,1,['benchmark'],['benchmarking']
Testability,"> Oh, then you didn’t hear of type theory. It’s a branch of logic:. Indeed, I have never heard of that. But I doubt that it would be considered a branch of logic. 1. `Union type` is a pretty bad descriptor for a variable that can take _one_ of a set of fixed types. A union usually denotes a composition of multiple sets giving rise to a new set that contains all elements from these sets.; 2. `Subtype` is a great descriptor for a type that has properties of supertypes.; 3. `Intersection type` is an insanely bad descriptor for a variable that denotes the intersection of _properties_ of supertypes; the concept of such a subtype might be something useful in some languages and some cases and it might deserve a special name as it's the converse behavior of subclassing. But I have no idea how such a type would be useful in Python and in all cases that I've encountered. The [example on Wikipedia](https://en.wikipedia.org/wiki/Type_system#Intersection_types) already constructs a highly artificial case, whose relevance is opaque to me even though Scanpy features it in many instances: functions that overload parameters and have different overloading-dependent return types (standard example is passing an array instead of an AnnData, which triggers the automatic return of the computed annotation). What do you think about 3, @flying-sheep?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-443072359:60,log,logic,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-443072359,2,['log'],['logic']
Testability,"> One thing that the deviances did was perform a chi-square test on the obtained values, with degrees of freedom based on the number of cells. I was fond of that as it translated into a data-driven cutoff for feature selection rather than requiring some number of top genes. @ktpolanski Thanks for the suggestion. Can you clarify which implementation you used where this is implemented?. I think one can essentially convert the variance of Pearson residuals into a p-value using a chi-square test. Then instead of the fixed number of HVG genes one could use some p-value cutoff. We have not experimented with this approach at all though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-874558246:60,test,test,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-874558246,2,['test'],['test']
Testability,"> One thing we had discussed was moving out the merge logic for multiple batches from being specified by `flavor` to being specified by a different argument, maybe `merge_flavor` or `batch_flavor`. Have you thought about/ looked into this?. I see what you mean. Not yet looked into that here, indeed. Slight risk of increasing confusion potential for users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2792#issuecomment-1892781138:54,log,logic,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1892781138,1,['log'],['logic']
Testability,"> Please deduplicate the tests though, they have too many identical lines. To do so did across-setting tests with for loop on top of former test... Would you prefer one separate test with that for loop for the across-settings check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3042#issuecomment-2121847271:25,test,tests,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042#issuecomment-2121847271,4,['test'],"['test', 'tests']"
Testability,"> Regarding generated, there’s both no need. I disagree with this. I think we definitely should not be intermingling source and generated files, especially when it's one source file to many generated. This is not a pleasant way to navigate files:. <details>; <summary> </summary>. <img width=""182"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113657454-543ca280-96e1-11eb-901c-675e8f248150.png"">. </details>. Also, looking around at other big projects with sphinx documentation, this is the way they all handled autosummary stub files. > `git clean -fx -- ./docs`. This is a bit of a nuke. I've added removing the generated docs to `make clean`, but we wouldn't want to run `git clean -fx -- ./docs` for `make clean`. > 2. Changing anything wide-reaching this would break many of our incoming links. This would be solved with [redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html). I would be happy to have `docs.scanpy.org/en/latest/api/dotplot.html` be the canonical url, but not if it requires mixing generated and source files. > 3. For case insensitivity let’s use the feature that specifically exists for that problem instead: autosummary_filename_map. Doesn't this only half solve the issue? Since (AFAIK) the generated html page has to have the same name as the rst file, this would break links (as you mentioned above). While we could do a redirect from here, what do we redirect too? Do we have special names for urls for classes which have an associated function? I don't think that would be cleaner than just having all classes be put in a `classes` subdirectory.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1753#issuecomment-813822197:546,stub,stub,546,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753#issuecomment-813822197,1,['stub'],['stub']
Testability,"> Removed 3.6. We should keep 3.6 as long as we support it. It's easy to accidentally add features which only work with 3.7+ otherwise. I'd be happy to drop 3.6 once numpy does (and in general roughly follow [NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html) as soon as the ecosystem does). > is there any reason why we are currently not additionally using Github Actions?. Depends on the task. Also depends on the definition of github actions I think? We aren't using any of their runners for testing because we'd like the ability to integrate with hosted resources on azure. Also, azure seemed like much more of a standard for numeric python packages at the time we chose it. I'd be happy to have github actions for other things, like `precommit`. `twine check` could be another one, but I haven't looked in to how ""artifact"" type things are handled with github actions to know if we'd be able to recover the built objects. We'd talked about using codecov too, which I'd like to add a check for. I'm not totally clear on the distinction between checks and actions yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1602#issuecomment-763590019:509,test,testing,509,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1602#issuecomment-763590019,1,['test'],['testing']
Testability,"> Scipy is actually under ~/.cache on my mac, ¯\\_(ツ)_/¯. Sorry, I was too terse here: What I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:336,log,logging,336,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940,3,['log'],"['log', 'logging']"
Testability,> Skip seurat v3 tests with numpy 2 . Sorry does this mean it doesn't work with numpy 2?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3115#issuecomment-2182427293:17,test,tests,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115#issuecomment-2182427293,1,['test'],['tests']
Testability,"> So I guess the real culprit is the float32 issue with AnnData. Is this something you all plan to address soon?. I think we can do that. I did a quick check and it's pretty benign in anndata. It causes test failures a few places in scanpy, but I think that's solvable with some conversion. It is a breaking change, so it will need to be in anndata 0.8. But there's a few more minor changes I'd like to make, so maybe we can be quick on that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1415#issuecomment-696580713:203,test,test,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1415#issuecomment-696580713,1,['test'],['test']
Testability,"> So I think the issue is the `foldchanges[global_indices]` that has values that you can't input into `np.log2`. That can be `NaN` or negative values. A fold change is something like `(average expression in condition 1)/(average expression in condition 2)` if expression values can be negative, then one of those values can be negative, giving a negative fold change. I would guess that these testing frameworks don't play well with negative values. I believe this is the reason why it happens. If one of those two averages are negative, then your fold change is negative, and you get an error when feeding that into `np.log2()`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/653#issuecomment-494541028:393,test,testing,393,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494541028,1,['test'],['testing']
Testability,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted?. ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-777382118:2,Test,Test,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-777382118,3,"['Test', 'test']","['Test', 'test']"
Testability,"> Tests are failing and I suspect that this is caused by an update on seaborn or matplotlib... Yes, should be as the introduced changes are not linked to the failing tests. I also checked and both `seaborn` and `matplotlib` have been updated in the last few days. See [here](https://pypi.org/project/seaborn/#history) and [here](https://pypi.org/project/matplotlib/#history).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1417#issuecomment-693331949:2,Test,Tests,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1417#issuecomment-693331949,2,"['Test', 'test']","['Tests', 'tests']"
Testability,"> Thank you! With “tests” I mean “functions named `test_*` with `assert ...` statements inside”; ; Thanks for your guidance, I have added `test_weightedSampling.py` with a folder named `weighted_sampled` in _data folder. . I have updated scanpy for weighted sampling for later tasks (clustering, finding marking genes and plotting). I also suggest to support it for initial tasks like PCA for data where each observation has weight (as in MATLAB). . Regards, ; Khalid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-493362243:19,test,tests,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493362243,2,"['assert', 'test']","['assert', 'tests']"
Testability,"> That's a great idea. It might require some reorganization, though, because currently use_raw is checked two places: once in sc.pl.scatter(), because it needs to know whether to look for variables in raw or not when deciding how to call _scatter_obs(), and again in _scatter_obs() itself. Would it be possible to not call it again in `scatter_obs`? E.g. could `_scatter_obs` not even need to know about the `raw` field?. > On another note, some pytests that are in files I did not edit are now failing because they can't find anndata.tests to import. I'm not sure if I messed something up by adding tests to test_plotting.py or whether this is a different issue. Aww crap, I think that was me making a new release. On the plus side it means our build system is now working as it's supposed to.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027#issuecomment-964279124:535,test,tests,535,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027#issuecomment-964279124,2,['test'],['tests']
Testability,"> That’s great! I don’t see much change in the test suite duration on Azure, should we expect any change?. I wouldn't expect a change on CI, we're not using pytest-xdist here plus I'm not sure if we have enough CPUs to bother. Mainly for dev machine testing",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2843#issuecomment-1934493747:47,test,test,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2843#issuecomment-1934493747,2,['test'],"['test', 'testing']"
Testability,"> The following test passes with the fix, and fails with the unfixed prior version. Ah, with `normalize_total`, it works with `seurat`, thank you!. > When multiple genes have the same value of `disp_cut_off`. I think when the n-th highest value is tied with others, returning more than the specified number makes total sense. As done by [`scipy.stats.rankdata`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rankdata.html), the rank of identical data points is identical. So the “values up to the 4th-highest” of the array `[6,5,3,3,3,1,0]` are `[6,5,3,3,3]`, not `[6,5,3,3]`. It makes no sense to include fewer than all of the 3s here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3157#issuecomment-2258094147:16,test,test,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157#issuecomment-2258094147,1,['test'],['test']
Testability,"> The principle should be that Anndata doesn't change array types to numpy arrays. I mostly agree with this, but think there would be a fair amount of work needed in AnnData. Most array types have special treatment in at least one place. A lot of this is due to our need to support sparse matrices. I'm hoping this can be reduced with some new stuff I'm adding though. This is definitely a good use case to test with. There's also the issue of when converting implicitly makes sense. We will do transformations from sparse to dense if the values becomes dense. We will also convert between sparse matrix formats if it will make calculations more efficient. On the topic of Zappy arrays. Can you take a `view` of a zappy array? This would be useful for some of the expectations around subsetting AnnData objects.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/733#issuecomment-515320589:407,test,test,407,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/733#issuecomment-515320589,1,['test'],['test']
Testability,"> The tests don’t fail, but you should still add the extra to setup.py. Is the fact that you don't list `'docs'` in your pip thing (`pip install -e .[louvain,leiden,test]`) purposeful?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/361#issuecomment-438320501:6,test,tests,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/361#issuecomment-438320501,2,['test'],"['test', 'tests']"
Testability,"> The tests have a tolerance parameter that is set high. The problem is that the stripplot shows different results each time. Also, different versions of matplotlib and seaborn have slight differences. Ah yes, I see. The stripplot result could be fixed by setting a seed with `np.random.seed`. I doubt it will fix the difference due to the used version, though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-696710488:6,test,tests,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-696710488,1,['test'],['tests']
Testability,> The tolerances need to be tight enough that the tests do anything though …; > ; > I’ve seen and fixed quite some tests where the tolerances meant that completely broken output was accepted. This is exactly what I'm seeing in my PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1899355829:50,test,tests,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1899355829,2,['test'],['tests']
Testability,"> The tsne test is giving me a headache. There are some small difference even setting a `random_state`. I will remove the test. I completely get this... the exact UMAP and tSNE plots are simply not _exactly_ reproducible, just very similar... fortunately, clustering (even though that's also a greedy algorithm) and everything else are exactly reproducible. I also removed the tests for UMAP: https://github.com/theislab/scanpy/blob/1df151f678c50b9f85f5d65e7a47d061e4e6784b/scanpy/tests/notebooks/pbmc3k.py#L88-L91 :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-423783837:11,test,test,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-423783837,4,['test'],"['test', 'tests']"
Testability,"> The underlying issues were with a missing .copy() (now added) and with log'd values getting into the simulation process. So a test could be checking that if you passed correctly simulated data into `sc.external.pp.scrublet` as `adata_sim`, you get the same result as letting the function simulate the data itself. You could recreate the simulation using the `.uns['scrublet']['doublet_parents']` field:. ```python; def create_sim_from_parents(adata, parents):; N_sim = parents.shape[0]; I = sparse.coo_matrix(; (; np.ones(2 * N_sim),; (np.repeat(np.arange(N_sim), 2), parents.flat),; ),; (N_sim, adata.n_obs); ); X = I @ adata.X; return ad.AnnData(; X,; var=pd.DataFrame(index=adata.var_names),; obs=pd.DataFrame({""total_counts"": np.ravel(X.sum(axis=1))}),; obsm={""doublet_parents"": parents.copy()},; ); ```. > (which is now prevented with a simple code rearrangement). I think those fixes are pretty self-evident. Yeah, I do see from the code what was going wrong. The issue is more that I want a check to be sure it does not go wrong again. These things clearly get through code review, but it's harder for them to get through a test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2025#issuecomment-963418664:73,log,log,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2025#issuecomment-963418664,3,"['log', 'test']","['log', 'test']"
Testability,"> There’s a few items I’d like to see changed, and you should add tests. I have modified your suggestions , thanks. For tests you mean the 'test cases' or some 'example' data to run the program? . Thanks ...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-492920628:66,test,tests,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-492920628,3,['test'],"['test', 'tests']"
Testability,"> This is actually something I've been meaning to bug you about @WeilerP, why does scvelo pin umap below 0.5?. This was only a dirty hack to make our unit tests pass (see e.g. [here](https://github.com/WeilerP/scvelo/runs/2112241472?check_suite_focus=true)). It's no longer pinned on `scvelo@develop` which we plan on merging into master in the following days to tag a new version. > We can ban umap 0.5.0 specifically. It's generally important that scanpy has a broad-ish range of versions it's comparable with, since there's a lot downstream. I'd be happy bump umap to above 0.4 though, since it has been a while for that. I believe the problem is using `umap-learn<=0.5.0` with new `numba` versions (I think `numba>=0.53.0`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-846973729:155,test,tests,155,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-846973729,1,['test'],['tests']
Testability,"> This is how I understood it anyway. You circumvent the problems caused by random sampling by doing a biased sampling, and the weights correspond to the size of the represented community. If the weights are just cluster-size-related, then this would not be necessary as you are calculating cluster-specific values to compare them in e.g., dot plots and statistical tests. This is a weighting that affects the relative importance of cells in the same cluster.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494348675:366,test,tests,366,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494348675,1,['test'],['tests']
Testability,"> This is mainly a fix for cases when multiple genes have zero variance. Could you add that as the test case? When some genes aren't expressed in a batch you won't get an error. > the best way forward would be to exclude those genes from the function. I think the approach of masking out the non-expressed genes sounds reasonable, since that's what you'd probably do if it were just one dataset. I'd definitely defer to @gokceneraslan on any more about the appropriateness of the approach.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/824#issuecomment-529851678:99,test,test,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824#issuecomment-529851678,1,['test'],['test']
Testability,"> This is strange, i also tried to run the tests multiple times at the time of committing this and they failed every time. Maybe a dependency had a bugged release at the time?. > I am not sure what king of test. I don't want to add another save_and_compare_images test because plots seem to depend on the system at least sometimes. You could instead use `check_same_image`. Check that running `filter_rank_genes_group` then plotting is equivalent to manually passing those genes to `sc.pl.rank_genes_groups_*` plot on an object that hasn't had `filter_rank_genes_group` run on it. You can search the tests for examples of `check_same_image`. > (i have 3 failing plotting tests locally but they run fine here). Could you open an issue for this and note which tests they are? It would be good to make the tests as resilient as possible on other people's systems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1942#issuecomment-878134649:43,test,tests,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1942#issuecomment-878134649,7,['test'],"['test', 'tests']"
Testability,"> This will hopefully be fixed: [#1081 (comment)](https://github.com/theislab/scanpy/pull/1081#discussion_r393315428). Interesting... a logFC is not sth that comes naturally out of a logistic regression model, no? Sergei would have to add a separate calculation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1152#issuecomment-610653258:136,log,logFC,136,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152#issuecomment-610653258,2,['log'],"['logFC', 'logistic']"
Testability,"> Unfortunately, I run into; > ; > ```; > __________________________________________________________________________________ test_scale[use_fastpp] ___________________________________________________________________________________; > ; > flavor = 'use_fastpp'; > ; > @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); > def test_scale(flavor):; > adata = pbmc68k_reduced(); > adata.X = adata.raw.X; > v = adata[:, 0 : adata.shape[1] // 2]; > # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; > assert v.is_view; > with pytest.warns(Warning, match=""view""):; > > sc.pp.scale(v, flavor=flavor); > ; > scanpy/tests/test_preprocessing.py:127: ; > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; > return dispatch(args[0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:554,assert,assert,554,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717,2,"['assert', 'test']","['assert', 'tests']"
Testability,"> We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. So that's what this PR would replace. The reason I thought this could be replaced is that `numba` now allows on-disk cacheing of parallelized functions. This means that the function would only have to be compiled once per install. That cache only get's invalidated if function's source code get's modified, so this shouldn't cause too much pain for development testing times. I've added a note to the documentation mentioning this, so I think it's fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/844#issuecomment-534371715:480,test,testing,480,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844#issuecomment-534371715,1,['test'],['testing']
Testability,"> Well you have to build the wheels to run the check anyways. Oh, what I meant is that we sorta do a check in the same job as running the tests. I was thinking this should be separated out into a job which does ""build and check"" together, rather than including it in the testing job.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1585#issuecomment-763462643:138,test,tests,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1585#issuecomment-763462643,2,['test'],"['testing', 'tests']"
Testability,"> What I basically do from raw UMI counts:; > 1. total counts normalization / logarithmization; > 2. PCA, bbknn, louvain; > 3. combat, HVG, PCA, UMAP (works well). Just out of curiousity, you use both BBKNN and combat? Does Louvain after ComBat, HVG, and PCA not work as well for you? It's interesting that you go with two different knn graphs for clustering and visualization.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666#issuecomment-496845038:78,log,logarithmization,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496845038,1,['log'],['logarithmization']
Testability,"> What I was thinking: if it's a string get the array from obsm, if it's an array, check that it's shape is right, then use the array directly. I'm really sorry but I still don't get it 😅 . What I unnderstand is to modify `adata.obsm[spatial]` in `pl.spatial` and pass that to emebdding. However, I don't want to modify the adata in place or pass a copy. Maybe I'm missing something fundamental, but I could see doing this only if modifying the adata or passing the spatial coordinates as array (but is it possible in sc.pl.embedding? I couldn't find a way). For the rest, I've added docs and added a test, should be ready to go (?). Thanks again for bearing with me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-755199967:601,test,test,601,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-755199967,1,['test'],['test']
Testability,"> What do you define as logic here?. [Logic](https://en.wikipedia.org/wiki/Logic) as the mother of all formal reasoning and its close relative set theory in mathematics. When you say type theory is a branch of logic then 90% of computer science is a branch of logic. In many contexts this might be a valid but not a very useful statement. > I’d also like `OneOf[A, B]`. I love `OneOf[A, B]`. This also doesn't pretend to be logic or set stuff. > `hasattr(obj, 'foo')` defines an intersection type of all types having that attribute. This is what I meant when I said _intersection of properties of supertypes_. But I still don't know when you'd need such a type in a practical context, given that we just keep overloading functions like crazy and simply treat passed arguments dependent on their type. Any example when intersection types are actually useful? In a function we might see in Scanpy (this was the whole beginning of this discussion; I cannot imagine a case in which we need to label something _intersection type_ in the docs).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-443397973:24,log,logic,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-443397973,6,"['Log', 'log']","['Logic', 'logic']"
Testability,"> What do you think of that?. I actually prefer my current layout- it accomplishes your logic without duplication of arguments etc, and from a user perspective I prefer having one main function I can use in the two ways (one anndata you get 3., Two anndata you get 2). But I'm also very happy for you to tweak things to match your vision!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-730987904:88,log,logic,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-730987904,1,['log'],['logic']
Testability,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using?. <details>; <summary> My versions </summary>. ```; -----; sinfo 0.3.1; -----; IPython 7.23.1; jupyter_client 6.1.11; jupyter_core 4.7.0; jupyterlab 2.2.9; notebook 6.3.0; -----; Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]; macOS-10.15.7-x86_64-i386-64bit; 16 logical CPU cores, i386; -----; Session information updated at 2021-05-10 10:13; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1477#issuecomment-835965024:446,log,logical,446,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477#issuecomment-835965024,1,['log'],['logical']
Testability,"> `paul15` is downloaded automatically, very practical. Yeah, it’s really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364372580:122,test,testing,122,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364372580,1,['test'],['testing']
Testability,"> adata.rename_categories doesn't work with dataframes in uns. * What problem is this causing?; * @falexwolf, why did this method get un-deprecated?. > Looks fine with miltindex dataframe. However a bit awkward with this names column when n_genes is set. I will set n_genes to all by default but do we need this at all?. I personally find MultiIndexes a bit hard to work with. Could you show how they would be used here? For example, how would I just get a dataframe for the naive T cells vs. rest?. I'm also not sure I get why we'd order genes by rank, when there are multiple comparisons in the table. What operations does this make easier?. **Most importantly**, I don't think we have support for reading and writing multi indexes in anndata. An alternative would be to just have an entry in `uns` that looked like:. ```python; adata.uns[key_added] = {; ""params"": {; ""groupby"": ""leiden"",; ""reference"": ""rest"",; ""test"": ""wilcoxon"",; ""rep"": ""X""; },; ""results"": {; ""1"": ..., # pd.DataFrame, with index of .var_names; ""2"": ..., #etc; },; }; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1156#issuecomment-620393866:915,test,test,915,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1156#issuecomment-620393866,1,['test'],['test']
Testability,"> can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. I’ll do that today if you can give me more info. Usually “regression test” refers to testing specific properties that were broken in a bug and subsequently fixed. What properties exactly are you looking for? Why `cell_ranger` and not `seurat`? Are you implying that we do that already for seurat?. /edit: done in https://github.com/scverse/scanpy/pull/2851. > There are two more lines which aren't covered, but I believe they should be unreachable (both just ValueError that the arg should be ""cell_ranger"" or ""seurat"") so it's fine. yeah, lines like that are more defensive coding. I add them even to internal code to force us to look at everything instead of having a `else: # flavor == ""cell_ranger""` branch or so. > I'm a little concerned about changing the return for inplace=False, in case anyone was relying on that. You mean the fact that the index makes the dataframe now actually useful? I can’t think of a way in which this breaks things in a way that isn’t immediately obvious and welcome. Of course, code can be infinitely weird, but can you think of a scenario?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1940849400:26,test,test,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1940849400,4,['test'],"['test', 'testing']"
Testability,"> clipping function. I think it's not so bad. I think you can use similar logic. Numpy version is something like:. ```python; if axis == 0:; data_mask = np.repeat(row_mask, np.diff(X.indptr)); elif axis == 1:; data_mask = obs_mask.take(X.indices, mode=""clip""); X.data[(X.data > max_value) & data_mask] = max_value; ```. right?. For numba, I'd just include the clipping in the inner loop so it's still single pass.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2025129938:74,log,logic,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2942#issuecomment-2025129938,1,['log'],['logic']
Testability,"> do you have any references on t-test_overestim_var ? I cannot find papers on this test method. what's the difference from t-test ? @falexwolf. I am also interested in formal descriptions about t-test_overestim_var or related publications, thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/365#issuecomment-994325045:84,test,test,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365#issuecomment-994325045,2,['test'],['test']
Testability,"> hmm, you didn’t test with the new changes. please do so for the next PR, I’m trusting you with these! Check out [ce06987](https://github.com/theislab/scanpy/commit/ce06987e6824471d0fe22c5cc7f9faf8840bf5da). sorry about that forgot to do this with the last changes I made!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1063#issuecomment-589706044:18,test,test,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1063#issuecomment-589706044,1,['test'],['test']
Testability,"> like pip install .[dev,test$(test_extras))], and run things once with test_extras='' and once with test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'. Yeah, I was thinking something like this. Except we could just reduce `test` to include the barebones needed to make tests run, and separately have optional dependencies. The hard part here is structuring the tests so they can run without optional dependencies being present. We'd need to establish patterns for optional dependencies in fixtures and parameterized tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539:25,test,test,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539,5,['test'],"['test', 'tests']"
Testability,"> obs-like structure with clusters in rows. Completely agreed!; 1. agreed with @ivirshup that there should be a more comprehensive object (which can possibly simply be stored as a dataframe and params in `.uns['rank_genes_groups']`, that clarify what the reference for the test was, but that might be not powerful enough)... your latest suggestion, @ivirshup, representing things as in 3d array sounds very promising, too... how to make an intuitive object? represent the 3d array in a long-form dataframe where two axes are accessible from one multi-index? or store an actual 3d array in AnnData, which can be cast into a convenient object, through a casting namespace... the logic being `sc.tl....` computes some complicated annotation, `sc.pl...` visualizes this annotation and `sc.ex....` extracts and casts annotation into more easily manageable objects. One example is `sc.Neigbors` (which should go into `sc.ex...`) which takes the weird annotation that `sc.pp.neighbors` writes and casts them into an object that allows accessing things... ; 2. Related, but really independent of `rank_genes_groups`: I had implemented a [draft of a `.collapse()` function](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/zebrafish/zebrafish.ipynb#Collapsing-the-AnnData-object), which is very similar to the [`.groupby()` function](https://github.com/ivirshup/mantis#group-by) that @ivirshup suggests, but much less elegant (I would also never have put it into the main repo...). You take a summary metric like `.mean()` or `.std()` and collapse the object by that (in pandas, would be `df.groupby('louvain').mean()`. > Why is it that .obs, .var, and .uns don't have data frames in them? np.recarray don't seem like a very popular data structure elsewhere. We just did only allow rec arrays in `.uns` as they are natively supported by hdf5 and dataframes aren't. It was really just that reason, nothing else. As mentioned in anndata, I'd love to completely move away from rec arrays as a means o",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/562#issuecomment-487279241:273,test,test,273,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487279241,2,"['log', 'test']","['logic', 'test']"
Testability,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata.; 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized.; 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-730939013:133,log,logic,133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-730939013,1,['log'],['logic']
Testability,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```; …; tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]; tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]; tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]; …; tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]; tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]; tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]; …; tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]; tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]; tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]; …; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3180#issuecomment-2263349948:35,test,test,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180#issuecomment-2263349948,11,['test'],"['test', 'tests']"
Testability,"> only working on genes. technically it could work on continuos covariates as well, should I add that option?. Sure. I think it would make sense to mimic the API of `gearys_c` as much as possible here. > I think it could be worth it to add a row wise normalization of the weights (standard in pysal). What would this entail? I wonder if this is best left up to the user, who can just chose what values to pass in?. > should consider to skip permutation entirely as well. Yeah, I'm not sure if we need this at the moment. I wonder if calculating p-values should even be a separate method? I would like to understand more about how p-values are calculated, and what you're getting out of this. . For instance, I would assume it's not appropriate to calculate a p-value for gene expression using a nearest neighbor network based on gene expression. --------------------. Side note, on performance. So right now it looks like computing one permutation is fairly fast (which makes sense). Most of the time comes from the permutation testing. After that, most of the time looks like it's coming from `adata.obs_vector`, which is a bit slow especially if you're getting many genes with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1740#issuecomment-799062288:1028,test,testing,1028,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1740#issuecomment-799062288,1,['test'],['testing']
Testability,"> ooh, this time the benchmark shows really nicely how much faster it is!. Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110#issuecomment-2177815754:21,benchmark,benchmark,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110#issuecomment-2177815754,1,['benchmark'],['benchmark']
Testability,"> probably we had never tested that combination of parameters because the output was a broking image. got it!. > If I understand you correctly, black can by applied to only some lines? Apparently PyCharm can be used with black, do you have any experience?. AFAIK black can’t be applied to some lines only. Thus my suggestion to just run it on files where you changed a lot. [about pycharm](https://black.readthedocs.io/en/stable/editor_integration.html)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/893#issuecomment-546448504:24,test,tested,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/893#issuecomment-546448504,1,['test'],['tested']
Testability,"> rp_forest storage is still broken though. Is this something you are planning on fixing in this pr?. Also, what's broken about it? I would have thought we'd have a failing test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1601#issuecomment-763606483:173,test,test,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1601#issuecomment-763606483,1,['test'],['test']
Testability,"> sklearn has also had a PR on this topic out for a long time and it just does not seem to budge. Allowing sparse support for PCA doesn't seem to be high on their priority list(?). I've read that situation as that particular PR being stalled, but it's also just for the random solver. I think sklearn would really like to have this feature. I think there's support for this from the community (where the referenced comment is yours):. > The perfect implementation of implicit data centering must be solver agnostic, allowing any matrix-free sparse PCA and SVD solver from scipy and scikit to be used. E.g., adding support to call any matrix-free scikit SVD/PCA solver in #12794 (comment) would make it perfect PR for implicit data centering. Do you think you could make a PR with this to sklearn? I'd like to see the response it gets, and judge based on that. My preference would be for this to go there, but I'm very open to having this in our codebase until it's in a `sklearn` release. > what's the best way of sharing the reproducing jupyter notebook with you?. Ha, that's actually a difficult question. I'm not quite sure, zip file should be fine. Thanks for sharing!. Ideally what I'd like from a benchmark of performance would be time and memory usage for the product of these conditions:. * Datasets size (one small, one large (>50k cells)); * Implicit centering, densifying centering, no centering; * single threaded, multi-threaded. I'd also lean towards making this the default for sparse data. But to do that, I will need to look a little closer at correctness. For that, could you show the average residual from a few runs (with different seeds) for all output values between implicit vs explicit centering?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589500984:1203,benchmark,benchmark,1203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-589500984,1,['benchmark'],['benchmark']
Testability,"> sparse_indicator doesn’t have its weights branches hit at all, maybe we should remove that? Or will this be used at some point?. I think it will be used at some point, but also happy to remove. I think parameterizing `test_aggregate_axis_specification` is overkill for what the test does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2590#issuecomment-1953840990:280,test,test,280,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590#issuecomment-1953840990,1,['test'],['test']
Testability,"> tests that check if combinations of input arguments lead to expected output (in terms of returned shapes/columns/...) and don't break the function; tests that check if warnings/errors are raised for ""common mistakes"" (inappropriate data, nonsense input argument combinations..). yes both makes sense, it would also be useful to come up with a dummy example for which the actual output could be tested against. This is done in seurat_v3 for instance, but in that case it's kind of straightforward because the ""expected"" is the output computed with original implementation (and as you catched in #1732 it's still might not be enough 😄 ).; another random thing that comes to mind re this specific case is to make sure that indexing etc. is consistent and robust, as you seem to have to sort and resort a fair bit in the hvg implementation. on another note, I was thinking if it makes sense to also release a short tutorial together with the PR (that would be on theislab/scanpy_tutorials) ? I think that for a lot of people the term ""pearson residuals"" could be alienating, and so they'd rather stick to `normalize_total` for comfort (but they shouldn't!). So maybe just something easy like pearson res norm + umap and hvg plots ? curious to hear what you and the others @ivirshup @LuckyMD think about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-797462245:2,test,tests,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-797462245,3,['test'],"['tested', 'tests']"
Testability,"> thank you @jlause for the PR! This is really exciting and super useful!; > This is a first round of review, most comments are re types, args and function behviour. I think it looks really good overall and maybe it's time to start writing tests ?; > please let me know if anything unclear and also thanks in advance for code explanations!. Hey @giovp ,; thanks a lot for the review, this looks very helpful! I'll address the single points above one-by-one and make the required changes over the next few days! Will also add some first tests - are there formal guidelines what you expect to be tested? After looking at the tests for `highly_variable_genes`, from my naive perspective I'd test the following:. - tests that check if combinations of input arguments lead to expected output (in terms of returned shapes/columns/...) and don't break the function; - tests that check if warnings/errors are raised for ""common mistakes"" (inappropriate data, nonsense input argument combinations..). Any advice/ideas what else should be tested?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-797435681:240,test,tests,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-797435681,8,['test'],"['test', 'tested', 'tests']"
Testability,"> this is not a test of `filter_rank_genes_groups`. To me the point of the test is that `filter_rank_genes_groups` followed by `.pl.rank_genes_groups_*` returns the right image by comparing it to a reference. I mainly prefer that the reference is generated by as orthogonal a method as possible, since then we're closer to testing functionality than implementation. I also think that this strategy forms a more flexible implementation that can be extended to test other properties. For example, it's easy to modify this to check that the `sc.pl.rank_genes_groups_*(..., min_logfoldchange=)` argument plays well with `filter_rank_genes_groups`. I also like having an example of an equivalent implementation in the test suite.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1942#issuecomment-880411601:16,test,test,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1942#issuecomment-880411601,5,['test'],"['test', 'testing']"
Testability,"> we're not using pytest-xdist here. Ah. you do install it in the minimum-tests PR though. I guess that means that you intended the min-deps install script for local CI as well. anyway, LGTM!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2843#issuecomment-1934505176:74,test,tests,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2843#issuecomment-1934505176,1,['test'],['tests']
Testability,"> what about `X_coords` ?. Ha, I was mostly just trying to get rid of the `X_`!. > What about re-open the theislab/spatial branch and merge this PR there? I could then work on how to handle the new uns structure in the plotting functions and have a definitive version of multiple slices support in anndata. I'd like to merge the changes currently in this PR to master since it fixes a bug with dataset reading. The changes to uns structure could go in another PR, but I'm waiting for an email back from 10x to make sure using the `library_id` as a key makes sense. Either way, the logic of getting the transformed coordinates etc. should be abstracted into a function so it's easy to change. Update: heard back, the `library_id` should be fine, at least for this version. > support for multiple slices should be first. I'm not sure I'm convinced of this. I've also already got some code ready to go for the connectivities and some examples of what can be done with it. I'd like to hear what kind of stuff you want to be able to do with multiple slices. Are you interested in stitching together slides or holding arbitrary slides in an AnnData? I think I'd like to see a more fleshed out idea of what kinds of analysis could be done here before deciding on what kind of an API this should have, and cases we should be ready to handle. Also, I think spatial plotting code should get moved out of `sc.pl.embedding` before we allow plotting multiple slides at a time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1088#issuecomment-596860000:581,log,logic,581,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088#issuecomment-596860000,1,['log'],['logic']
Testability,"> which did the expected thing, @flying-sheep introduced the bug 22 days ago in ce10d02. damn, the only thing I could have done wrong there…. It went into that commit because the previous code was too convoluted to understand, and I needed to understand that line to improve the docs! I ended up understanding it it but rewrote the line incorrectly. I’m sorry!. Did you add a test after 15593d5?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/393#issuecomment-446532755:376,test,test,376,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446532755,1,['test'],['test']
Testability,> why no test for a longer collection of colors?. what do you mean? just a longer list? what would that test?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3299#issuecomment-2426516514:9,test,test,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3299#issuecomment-2426516514,2,['test'],['test']
Testability,"> yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. . @fidelram, from your comment (https://github.com/theislab/scanpy/pull/1551#issuecomment-761117523), makes me think you'd like to enable this? If you okay this, all this needs to be ready to merge is: . - [x] Figure out where result xml should live; - [x] `.gitignore` update; - [x] Remove failing test (just there as an example); - [x] Document where to find this stuff",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1587#issuecomment-761748373:86,test,test,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1587#issuecomment-761748373,2,['test'],['test']
Testability,"> your logging still has fractions of a second in there. Shouldn’t be possible, in 709bafb8ed600daf5f9ee995a0dc845ac1e7e605 I set the microseconds to 0, and in `timedelta.__str__`, microseconds [only get added](https://github.com/python/cpython/blob/83cec020ba177fa27727330ba4ccf60eebc22a54/Lib/datetime.py#L596-L597) if they’re >0. > I tried updating datetime in case that's secretly responsible, as you seem to use it internally for time tracking. How so? It’s a stdlib module, you can’t update it without updating Python itself.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/746#issuecomment-514121664:7,log,logging,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746#issuecomment-514121664,1,['log'],['logging']
Testability,">It appears to me that the benchmarks show that this only becomes relevant for very large data. Hm, even for my example it is 77.14 MiB vs 893.92 MiB, so 10 times difference. This seems large to me, no?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/403#issuecomment-450029072:27,benchmark,benchmarks,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-450029072,1,['benchmark'],['benchmarks']
Testability,?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19hbm5kYXRhLnB5) | `84.98% <100.00%> (ø)` | |; | [scanpy/plotting/\_docs.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19kb2NzLnB5) | `100.00% <ø> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `77.28% <ø> (ø)` | |; | [scanpy/testing/\_helpers/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |; | [scanpy/plotting/\_matrixplot.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19tYXRyaXhwbG90LnB5) | `95.69% <66.66%> (-1.01%)` | :arrow_down: |; | [scanpy/plotting/\_dotplot.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19kb3RwbG90LnB5) | `91.28% <71.42%> (-0.61%)` | :arrow_down: |; | [scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2769#issuecomment-1830133314:2235,test,testing,2235,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2769#issuecomment-1830133314,1,['test'],['testing']
Testability,"@Hrovatin, if you haven't read it yet I think you would find the [Hotspot](https://www.cell.com/cell-systems/fulltext/S2405-4712(21)00114-9) method from the Yosef lab interesting. It uses something similar to Morans I for feature selection and local Morans I for gene module detection. They use parametric null models to get significances for their scores, which would be significantly faster than permutation testing. I'm a little unsure of how the parametric null models correspond to the non-parametric ones since the only comparison I've found so far is some Q-Q plots in the supp.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-846745204:410,test,testing,410,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698#issuecomment-846745204,1,['test'],['testing']
Testability,"@Intron7 this was surprisingly hard to get right. Unfortunately, there are now a few more checks and some `hstack`ing. Do those tank the performance?. /edit: I benchmarked some, this is better than what we had before",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2756#issuecomment-1816509533:160,benchmark,benchmarked,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2756#issuecomment-1816509533,1,['benchmark'],['benchmarked']
Testability,@Koncopd ; This is weird never noticed. How can I restore it??; I only built the docs for me to test the outputs. Could be that building the docs affected somehow docs/api/scanpy.external.rst??,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1080#issuecomment-703785741:96,test,test,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080#issuecomment-703785741,1,['test'],['test']
Testability,"@Koncopd Currently breaking test for me:. ```pytb; $ pytest -k test_ingest; ===================================================== test session starts =====================================================; platform darwin -- Python 3.7.6, pytest-5.3.5, py-1.8.0, pluggy-0.12.0; rootdir: /Users/isaac/github/scanpy, inifile: pytest.ini, testpaths: scanpy/tests/; plugins: pylama-7.7.1, parallel-0.0.10, cov-2.7.1, black-0.3.7, hypothesis-5.6.0; collected 393 items / 389 deselected / 4 skipped . scanpy/tests/test_ingest.py ...F [100%]. ========================================================== FAILURES ===========================================================; _______________________________________________ test_ingest_map_embedding_umap ________________________________________________. def test_ingest_map_embedding_umap():; adata_ref = sc.AnnData(X); adata_new = sc.AnnData(T); ; sc.pp.neighbors(; adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0; ); sc.tl.umap(adata_ref, random_state=0); ; ing = sc.tl.Ingest(adata_ref); ing.fit(adata_new); ing.map_embedding(method='umap'); ; reducer = UMAP(min_dist=0.5, random_state=0, n_neighbors=4); reducer.fit(X); umap_transformed_t = reducer.transform(T); ; > assert np.allclose(ing._obsm['X_umap'], umap_transformed_t); E assert False; E + where False = <function allclose at 0x119616b00>(array([[16.566338, 20.174282],\n [15.368203, 20.291983]], dtype=float32), array([[16.502459, 20.157679],\n [15.581459, 20.302881]], dtype=float32)); E + where <function allclose at 0x119616b00> = np.allclose. scanpy/tests/test_ingest.py:140: AssertionError; ---------------------------------------------------- Captured stderr call -----------------------------------------------------; computing neighbors; finished: added to `.uns['neighbors']`; 'distances', distances for each pair of neighbors; 'connectivities', weighted adjacency matrix (0:00:00); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:00:00); ``",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1036#issuecomment-599469073:28,test,test,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036#issuecomment-599469073,5,['test'],"['test', 'testpaths', 'tests']"
Testability,@Koncopd I made an actual test from your notebook :smile:: https://github.com/theislab/scanpy/commit/8d4ec6376c5b338456ced0bc051683052f15aa37,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/191#issuecomment-404142288:26,test,test,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191#issuecomment-404142288,1,['test'],['test']
Testability,"@Koncopd has looked at refactoring the `rank_genes_groups` methods, but in the big picture we don't really love the output format that `rank_genes_groups` uses. Maybe an easier path forward would be to be able to directly pass values into the various plotting functions? You can already generate mostly similar plots from `sc.pl.rank_genes_groups_{plot_func}` and `sc.pl.{plot_func}` apart from using logfc and pvalues. If we allowed passing those in, it would be simple enough to make the same plots/ add a wrapper that generates the plots into `diffxpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1955#issuecomment-886408954:401,log,logfc,401,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955#issuecomment-886408954,1,['log'],['logfc']
Testability,"@Koncopd pre-commit doesn’t *have* to be configured, you can choose not to enable it. Of course tests will fail then. regarding mypy: I guess it’s possible to make everything return `-> t.Any: # TODO fix typing`. I like isort!. Also we should get #1527 in before doing any big restructuring: It’s been through too many rounds of delays and I had to resolve conflicts so many times.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-757907537:96,test,tests,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-757907537,1,['test'],['tests']
Testability,"@Koncopd when we talked about this last there were concerns about backwards reproducibility. I'm wondering if this logic would fix that:. * If the dataset is ""small"" and the metric is defined by scikit-learn, compute complete distances; * For all other cases use pynndescent. Would this be sufficient to keep results the same, or do we compute dense distances for the more esoteric metrics now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1413#issuecomment-861371191:115,log,logic,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1413#issuecomment-861371191,1,['log'],['logic']
Testability,"@Koncopd yes, I believe that should cover everything (maybe test to make sure I'm not missing sth here). However, I still think taking adjacency matrix powers will not be as fast as a BFS/DFS.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-701344124:60,test,test,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-701344124,1,['test'],['test']
Testability,"@Koncopd, can we merge this without the `neighbors_update` function and without writing the `rp_forest` to the AnnData object? Your code is good, but we should put it into another PR. > Can you investigate and if it's easy cover in this PR? If it's tricky, let's wait for another PR. Is what I wrote in the beginning. I think it turned out tricky and is a case for https://github.com/theislab/scanpy/issues/562#issuecomment-487409358. So, let's keep this PR really simple and just be about removing the legacy code. Your statement about ""all tests pass except for the PAGA tests"" is still true? Did you manually inspect the PAGA notebook and does it look consistent? Just a few cosmetic things should have changed, I guess. If yes, we'll merge this, now that `1.4.1` is out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-487410333:542,test,tests,542,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-487410333,2,['test'],['tests']
Testability,"@Koncopd, updating `logreg` with a proper implementation accounting for `reference` is another story. We can talk about it sometime soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-474305372:20,log,logreg,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-474305372,1,['log'],['logreg']
Testability,"@LisaSikkema, current behavior just changes the groups which are tested (I'd call this the ""left hand side"" in `group vs reference`) not what they are tested against. That is controlled by the `reference` argument. I agree this could be more clear. It would also be nice if `reference` was more flexible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1519#issuecomment-743963259:65,test,tested,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519#issuecomment-743963259,2,['test'],['tested']
Testability,"@LisaSikkema, no worries there's been some flakiness of that test. Can this get a test case like ? Maybe even two, one where groups match, one where they don't?. I'm thinking something that calls `save_and_compare_images`, like https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L272",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1511#issuecomment-739663476:61,test,test,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511#issuecomment-739663476,3,['test'],"['test', 'tests']"
Testability,@LuckyMD . Thank you for the whole in-depth discussion. It makes a lot of sense! :smile:. To your question: Scanpy has used Welch's adaption of Student's t-test from the very beginning. @davidsebfischer . Thank you! I guess it would be nice to have a single-cell tutorial in diffxpy that shows higher sensitivity by accounting for technical covariates.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-450025261:156,test,test,156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-450025261,1,['test'],['test']
Testability,"@LuckyMD @maximilianh Thanks guys for the reply. ; Sorry I'm just used to Seurat setup and kind of got lost. Long story short my issue is negative values, after data processing and scaling I have negative values in the expression matrix that throughs off my downstream analysis. But before scaling adata.X format looks completely different (as I mentioned in my previous post). I just want to have a matrix of gene/cell. . If I export using cell browser tool I get same values as processed adata.X ; If I do ; `adata.to_df().to_csv('./adata.csv', sep=',')`. or if I do . ```; import scanpy.external as sce; sce.exporting.cellbrowser(adata, './test', 'adata', embedding_keys=None, annot_keys=['louvain'], cluster_field='louvain'); ```. it generates exactly same expression matrix, I don't really see the raw value matrix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/506#issuecomment-468460649:643,test,test,643,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506#issuecomment-468460649,1,['test'],['test']
Testability,@LuckyMD I would be interested into looking at your method. It is different than that of `score_genes`. . I was considering to use the same tests from scanpy to identify marker genes but with a given set of markers as I want to know if a cluster could be annotated with a marker (which is different than to annotate a single cell). Any thoughts on this idea?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/290#issuecomment-428457349:140,test,tests,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290#issuecomment-428457349,1,['test'],['tests']
Testability,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:78,log,log-scale,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609,14,"['log', 'test']","['log', 'log-mean', 'log-scale', 'loge', 'test', 'testing', 'tests']"
Testability,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:; * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. ; * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1529#issuecomment-738733928:1430,log,logfoldchange,1430,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529#issuecomment-738733928,2,['log'],['logfoldchange']
Testability,"@LuckyMD genes at the bottom simply have the lowest rank but they could be expressed. By default the ranking is taking directly from `sc.get.rank_genes_groups_df` which ranks the genes by log fold change. Bottom genes tend to have significant p-value. . To make this more transparent we can add a parameter to select how to rank for example by p-value or log fold change. . But, first I need to figure out what is this mess with the new tests....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1529#issuecomment-738292854:188,log,log,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529#issuecomment-738292854,3,"['log', 'test']","['log', 'tests']"
Testability,@LuckyMD why don't you add a test to `scanpy/tests/test_plotting.py`. Thus we can guarantee that future changes do not break your code.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/543#issuecomment-476209255:29,test,test,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-476209255,2,['test'],"['test', 'tests']"
Testability,"@LuckyMD, I think you can get the docker environment travis uses. * [Docker image for travis python env](https://hub.docker.com/r/travisci/ci-python); * [Guide on running it](https://andy-carter.com/blog/setting-up-travis-locally-with-docker-to-test-continuous-integration). I did this a couple years ago, but I know travis has changed a bunch since then. Another good first step would be to figure out if it only fails on the first build, and if caches are being used in any way. Also, do the builds ever fail for forks? I don't think they've been failing [for me](https://travis-ci.org/ivirshup/scanpy/builds).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/580#issuecomment-478823933:245,test,test-continuous-integration,245,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478823933,1,['test'],['test-continuous-integration']
Testability,"@LuckyMD, do you think you ever saw a change without version updates? I'd like to think we were aware of changes through our tests (in particular tests for plotting and the pbmc notebook). However calculations change for different dataset sizes, so we could be missing cases where there's instability.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1363#issuecomment-678129332:125,test,tests,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1363#issuecomment-678129332,2,['test'],['tests']
Testability,"@LustigePerson, would you be able to add a quick test here? Then this could get into the next release",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2190#issuecomment-1081869351:49,test,test,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190#issuecomment-1081869351,1,['test'],['test']
Testability,@Marius1311 Thanks a lot for adding this. I reviewed the code and do not have any objections to merge it. Would be possible to add or modify one of the plotting tests where this new parameter is used?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1161#issuecomment-620661211:161,test,tests,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1161#issuecomment-620661211,1,['test'],['tests']
Testability,"@MichaelPeibo @falexwolf I started working on points 2 and 3, but it is better if you will work on these points.; I wrote the code for points 1 and 4.; In order to generate volcano plots, I calculated the log2FC relying on the `diffxpy` library.; I can push again the code for tSNE and also the code for volcano plots. Please, check the `rank_genes_groups` function.; Considering 2 groups of cells and using the Wilcoxon test (`de.test.wilcoxon`) provided by the `diffxpy` library, I obtained different marker genes with respect to those calculated by using `rank_genes_groups` function (Wilcoxon test). Many thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471321592:421,test,test,421,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471321592,3,['test'],['test']
Testability,"@PrimozGodec, probably don't add this to `requirements.txt`, since the requirement should be optional for install. I think instead you should mark it with something like:. ```python; from importlib.util import find_spec. @pytest.mark.skipif(find_spec('pointannotator') is None, reason=""pointannotator not installed""); ```. You can add a requirement for the package to this line in `setup.py`: https://github.com/theislab/scanpy/blob/d8f32c040f3a5f4fc07998b269796ca58de84b40/setup.py#L41. Maybe we should eventually have a second requirements file for CI testing, like we do for anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/812#issuecomment-537465652:554,test,testing,554,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812#issuecomment-537465652,1,['test'],['testing']
Testability,"@THZ34 can you create a reproducer where this happens, so I can add a test?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2804#issuecomment-2012516645:70,test,test,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2804#issuecomment-2012516645,1,['test'],['test']
Testability,@WeilerP probably there is a more direct way to overlay the stripplot but I don't think that it makes any big difference. . Can you make a PR to see how the tests work?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1420#issuecomment-694327799:157,test,tests,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1420#issuecomment-694327799,1,['test'],['tests']
Testability,"@WeilerP would you be willing to write a tiny test and to add the release note, please?. Thanks! Happy to merge this then if you ping me. @ivirshup generally, I agree. Think that this tiny change doesn't harm though and deprecating the magic ""read"" is something bigger.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1969#issuecomment-1291807007:46,test,test,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1969#issuecomment-1291807007,1,['test'],['test']
Testability,@WeipengMO if you calculate it like this you are right. However when we move from 64Bit to 32Bit for neighbors the results are reproducible at least to the best of my testing. I would still be open to round the results. @flying-sheep what do you think?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822393557:167,test,testing,167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822393557,1,['test'],['testing']
Testability,"@Xparx Thanks for reporting the problem an a potential solution. . Each plotting function has a save parameter which does:; ```; pl.savefig(filename, dpi=dpi, bbox_inches='tight'); ```; So, instead of calling `fig.savefig()`, what you can do in your example is to add `save='test.png'`:. ```; sc.pl.matrixplot(adata, save='test.png', var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/418#issuecomment-453006714:275,test,test,275,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418#issuecomment-453006714,2,['test'],['test']
Testability,"@Zethson I’m adding some in #3031, but it needs more thought: 30 minutes for a benchmark run is too long …",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3044#issuecomment-2100696528:79,benchmark,benchmark,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044#issuecomment-2100696528,1,['benchmark'],['benchmark']
Testability,@Zethson do we really need a test here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2460#issuecomment-1493446043:29,test,test,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460#issuecomment-1493446043,1,['test'],['test']
Testability,"@a-munoz-rojas Thanks for checking and thank you very much for the PR :smile! I like your version of the implementation a lot better than the manual one, as the code is much more readable. I don't know why @tcallies added the wilcoxon this way at the time, but I assume for speed and memory reasons. So, I'm very happy to merge this PR; I'll just briefly give this another check today or tomorrow and update the tests so that they don't fail anymore. Regarding the general discussion: Yes, let's just add a disclaimer that several assumptions on how meaningful the null hypotheses are both for wilxocon and t-test for single-cell data, should do the job. Then people will interpret the p-values with care.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-427040589:412,test,tests,412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-427040589,2,['test'],"['test', 'tests']"
Testability,@adamgayoso A recent update of seaborn caused some trouble with the tests but is now fixed. Can you merge with master to trigger again the tests?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1421#issuecomment-697317906:68,test,tests,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1421#issuecomment-697317906,2,['test'],['tests']
Testability,"@adamgayoso This is a fair point and thanks for raising this issue. Just to clarify, Jan started this PR because we were explicitly asked by some of the Scanpy core developers to prepare it for the core library. Whether this goes into `external` or into the core, is definitely not our call, so let's see what the Scanpy team says. . --------------------. I just wanted to make some small comments to what you wrote. The main comment is that we don't view this as a ""new method"". We view it basically as ""scTransform done right"". And scTransform is already published and is being used. . > It feels like something that should more go to external, considering the method itself will undergo the peer-review process. . I understand this point, but I guess the distinction here is not only published vs not-yet-published. A lot of stuff gets published but is not included into Scanpy... > As another example, why not add GLM-PCA to sc.tl.glm_pca? It's supposed to be better. See our preprint regarding ""supposed to be better""... . > I even think in GLM-PCA they describe a fast approximation using deviance residuals, so why not add that?. Deviance residuals are very similar to Pearson residuals. We could consider adding deviance residuals as an option to the functions suggested in this PR, it would be all the same logic, just deviance vs. Pearson. Hmm, actually I would need to check what exactly is the expression for deviance residuals for NB model. > shouldn't we put more weight on the peer-review process here?. One option would be to hold this PR until our paper is formally accepted...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-798444591:1316,log,logic,1316,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-798444591,1,['log'],['logic']
Testability,"@adamgayoso, I should definitely get around to merging this. I think I can pretty much do it as is, and open a second issue for getting the docs looking good. I'd like to target an initial `metrics` module for `1.8` (we're working on upping the release cadence as well). Question for your lab, are our implementations equivalent? I haven't actually gotten around to testing against the `VISION` R/C++ version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-763302767:366,test,testing,366,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-763302767,1,['test'],['testing']
Testability,"@aditisk that depends on what you put in `adata.raw` ;). Initially `adata.raw` was used to store the full gene object when `adata.X` was filtered to only include HVGs or remove genes that aren't expressed in enough cells. Now, we just have a boolean mask in `adata.var['highly_variable']` for HVGs and so it's often not used anymore. I typically store my log-normalized expression data there if I do batch correction or regress anything out, as `adata.raw` is used as default to compute `rank_genes_groups` and to show expression values on an embedding plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1039#issuecomment-617882284:355,log,log-normalized,355,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039#issuecomment-617882284,1,['log'],['log-normalized']
Testability,"@aeisenbarth Could you provide a small code sample or point to one of our unit tests where this happens? I am not seeing what you are referring to. For example:. ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.leiden(adata, flavor=""igraph"", resolution=5, directed=False, n_iterations=2, copy=True); sc.tl.leiden(adata, flavor=""leidenalg"", resolution=5, copy=True); ```; do not seem to yield the warnings you describe. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2865#issuecomment-2122066123:79,test,tests,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2865#issuecomment-2122066123,1,['test'],['tests']
Testability,"@andrea-tango ; Really awesome!; I am also wondering to find some parameters to tune in scanpy's `rank_genes_groups` like in Seurat. . Because I found there is some difference in makers by scanpy's default(using `wilcoxon` ) and Seurat's default parameters` only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25`. (Seurat's default method is wilcoxon), in this case, I can find interesting markers calculated by Seurat but not in Scanpy's. However, when I tried scanpy's `logreg` method, I found many overlap DEGs between two calculations, aka, scanpy's `logreg` and Seurat's `wilcox`. Have you ever came into similar results?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471241654:291,log,logfc,291,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471241654,3,['log'],"['logfc', 'logreg']"
Testability,"@andrea-tango @MichaelPeibo To address the filtering of rank_genes_groups (eg. `min.pct = 0.25, logfc.threshold = 0.25`) I recently added a function called `sc.tl.filter_rank_genes_groups`. See https://github.com/theislab/scanpy/pull/425. @falexwolf I don't know why`sc.tl.filter_rank_genes_groups` does not show up in the docs. I will take a look. Also, I just noticed that this PR with updated examples is still open. I think it would be useful to merge: https://github.com/theislab/scanpy_usage/pull/11",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471531524:96,log,logfc,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471531524,1,['log'],['logfc']
Testability,"@ashish615 after doing some benchmarking myself I found out that your solution for `axis=1` is under performing compared to `axis=0` for larger arrays. I think that is because of the memory access pattern you choose. I rewrote the function with that in mind. I'll again make a PR to you, because for some reason you disallow us from making changes to your PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3099#issuecomment-2191349887:28,benchmark,benchmarking,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099#issuecomment-2191349887,1,['benchmark'],['benchmarking']
Testability,"@atarashansky sorry for getting back to you late! I played around with the implementation, thanks a lot for the notebooks!. few questions before opening the PR:; - do you think it's worth it to allow users to add other variables (beside log_umi) ?; - do you think it would be useful to add other models other than poisson?; - there are other outputs provided by R implementation other than pearson residuals. Do you think it's worth to include them?; - testing: how do you think it should be best tested? we thought about saving results from original implementation in R and test against those (as it's done for others seurat re-implementation like highly variable genes). looking forward to hear what you think! thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1643#issuecomment-783547730:453,test,testing,453,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1643#issuecomment-783547730,3,['test'],"['test', 'tested', 'testing']"
Testability,"@atarashansky, the performance is looking very very good:. ```python; import scanpy as sc; import numpy as np; from sklearn.datasets import fetch_20newsgroups_vectorized. X = fetch_20newsgroups_vectorized(""all"").data; # 18846 x 130107 csr_matrix. a = sc.AnnData(X, dtype=np.float64); %time implicit = sc.pp.pca(a, pca_sparse=True, dtype=np.float64, copy=True); # CPU times: user 34.8 s, sys: 5.52 s, total: 40.3 s; # Wall time: 2.93 s; # Peak memory (including dataset) is about 770 MB; %time explicit = sc.pp.pca(a, pca_sparse=False, dtype=np.float64, copy=True); # CPU times: user 55min 37s, sys: 1min 50s, total: 57min 28s; # Wall time: 7min 43s; # Peak memory is about 36 GB. assert np.allclose(implicit.obsm[""X_pca""], explicit.obsm[""X_pca""]); assert np.allclose(implicit.varm[""PCs""], explicit.varm[""PCs""]); ```. But the variance and explained variance ratio are still off. Why not calculate them the same way sklearn does?. Also, any thoughts on making a PR there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-593738303:680,assert,assert,680,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-593738303,2,['assert'],['assert']
Testability,"@awnimo , for me test_phenograph.py fails with `E TypeError: Expected list, got numpy.ndarray`.; Could you check please?; This is certainly related to scipy 1.5. With scipy 1.4 the test works fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1080#issuecomment-702669779:181,test,test,181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080#issuecomment-702669779,1,['test'],['test']
Testability,"@cchrysostomou Indeed the mean will no longer be zero, I was merely reimplementing exactly what was done in Seurat, and we have tests to show in the single batch case that we get the same exact genes. No need to delete this comment. . I suppose you can think of it as the second moment instead of the variance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/993#issuecomment-1040470890:128,test,tests,128,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993#issuecomment-1040470890,1,['test'],['tests']
Testability,"@coh-racng, I've merged your fix in #790 with a test added. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/764#issuecomment-522894347:48,test,test,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/764#issuecomment-522894347,1,['test'],['test']
Testability,"@dawe ; - the coding style is the [official python coding style](https://www.python.org/dev/peps/pep-0008/), we should all stick to that. in particular: [white spaces](https://www.python.org/dev/peps/pep-0008/#whitespace-in-expressions-and-statements) around operators but **not** around optional keyword arguments; - thank you for a notebook!; - gene list: why not add it as an attribute of your module? or make a class `GeneLists` with a few gene lists in your model? of course, these will not be comprehensive, but might provide a good starting point; - in a few instances, I had to go through the reverse R engineering myself - in particular, if it comes to benchmarking code to floating point precision, it's really a hassle to dig out all the hidden different conventions... but I think it really pays off in the sense that it provides a lot more confidence in code and methods if several tools provide the same result on basic things - even across languages",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/76#issuecomment-363733820:662,benchmark,benchmarking,662,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76#issuecomment-363733820,1,['benchmark'],['benchmarking']
Testability,"@dawe Could you also please provide a brief tutorial on how to install `scanpy` on M1? I am having troubles. I have followed [this tutorial ](https://medium.com/geekculture/the-best-way-to-setup-your-m1-mac-for-python-development-fb5dffd08fd) to set up python on my M1 Mac. Thus I have installed `miniforge` with `brew`. My versions are `Python 3.9.6` and `pip 21.2.4`. Also I have read that you succeed in install `scanpy` with `python 3.8` but I am not able to downgrade version. The error I face when I run `pip3 install scanpy` is:. ```; ERROR: Command errored out with exit status 1: /opt/homebrew/Caskroom/miniforge/base/bin/python3.9 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/y_/5kkrlhbj2v1bch8snxxws28c0000gn/T/pip-install-6blz73pw/h5py_c0efce6062af4b4d9f6564a97c24d1a7/setup.py'""'""'; __file__='""'""'/private/var/folders/y_/5kkrlhbj2v1bch8snxxws28c0000gn/T/pip-install-6blz73pw/h5py_c0efce6062af4b4d9f6564a97c24d1a7/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/y_/5kkrlhbj2v1bch8snxxws28c0000gn/T/pip-record-lf5rwuj7/install-record.txt --single-version-externally-managed --compile --install-headers /opt/homebrew/Caskroom/miniforge/base/include/python3.9/h5py Check the logs for full command output.```. Thank you in advance!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1840#issuecomment-930949004:1491,log,logs,1491,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840#issuecomment-930949004,1,['log'],['logs']
Testability,"@dawe In all benchmarks that I did maybe a bit less than a year ago, the `python-louvain` didn't seem to produce satisfying results... But maybe I did something stupid. I'll reevaluate this, thanks, Davide! PS: One can easily switch between implementations; simply pass `flavor='taynaud'` to `sc.tl.louvain` and you'll use `python-louvain`. See [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L118-L125). However, I removed this from the docs as I was not so satisfied with it... @flying-sheep the only thing where `igraph` is used in Scanpy is for graph drawing, where it's incredibly faster than `networkx` (completely forget about `networkx` in this respect); the performant `louvain` implementation is due to the `louvain` package, which simply uses `igraph`'s graph data structures",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97#issuecomment-370393215:13,benchmark,benchmarks,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/97#issuecomment-370393215,1,['benchmark'],['benchmarks']
Testability,"@dawe a cell cycle scoring function would be great! everything that's a bit more extensive and non-standard should go into [sc.tl](https://github.com/theislab/scanpy/tree/master/scanpy/tools), everything that's really just simple preprocessing and stats with a few lines can go to [sc.pp](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/simple.py). usually, there should be a plotting function in sc.pl that presents a canonical visualization of the annotation added in with the tool... writing a test for your function would also be great ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/45#issuecomment-363250398:517,test,test,517,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45#issuecomment-363250398,1,['test'],['test']
Testability,"@falexwolf . Hi, Alex.; Yes, i'm checking these. Actually, it somehow passes [test_pbmc3k](https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/test_pbmc3k.py). Only [test_paga_paul15_subsampled](https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/test_paga_paul15_subsampled.py) fails. It seems that adjacency matrix is a bit different after the change and this affects paga connectivities. But it is preliminary, i'm checking still.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-478741723:145,test,tests,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-478741723,2,['test'],['tests']
Testability,"@falexwolf ; Hi, Alex. What i figured out for now. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L105; This can be replaced by importing this; https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L148. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L258; This is basicly this; https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L329; But this `fuzzy_simplicial_set` doesn't calculate `distances`, only `connectivities`. What is the right approach to solve this? Writing PR to umap that adds `distances` as a return value for `fuzzy_simplicial_set`?. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/tools/_umap.py#L107; This line can be directly imported from umap of course, but now their `simplicial_set_embedding` requres also `adata.X` as an input, because the case with the number of connected components > 1 is treated differently. It should not be a problem as we have this in adata. I comment it just because this changes the logic a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/522#issuecomment-476643493:1182,log,logic,1182,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522#issuecomment-476643493,1,['log'],['logic']
Testability,@falexwolf ; It is strange that there are no tests for this. I thought i added them...; I will try to do all these thing in two days. Sorry for the delays.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/594#issuecomment-481276242:45,test,tests,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/594#issuecomment-481276242,1,['test'],['tests']
Testability,"@falexwolf ; MAGIC uses root square transformation, not the frequently used log transformation, which causes the incompatibility with batch correction methods, such as CCA and MNN. Is DCA compatible with MNN and CCA ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/187#issuecomment-403407217:76,log,log,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187#issuecomment-403407217,1,['log'],['log']
Testability,@falexwolf ; This is just a small test for the existing pca. You asked me to write it some time ago.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/466#issuecomment-471328945:34,test,test,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/466#issuecomment-471328945,1,['test'],['test']
Testability,"@falexwolf ; Yes, i inspected the notebook, everything looks the same. Also this PR passes all tests now. So, yes, i think it can be merged",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-487414554:95,test,tests,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-487414554,1,['test'],['tests']
Testability,@falexwolf ; some usage examples; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/use_Ingest.ipynb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651#issuecomment-510218093:76,benchmark,benchmarks,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-510218093,1,['benchmark'],['benchmarks']
Testability,@falexwolf @andrea-tango ; I have a question regarding point 2 (log2FC values in `rank_genes_groups`). I see that only `'logreg'` method doesn't return logfoldchanges. But logfoldchanges don't seem natural for `'logreg'` as this method doesn't even use `reference` for calculation.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471938514:121,log,logreg,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471938514,4,['log'],"['logfoldchanges', 'logreg']"
Testability,@falexwolf @ivirshup ; New Ingest api usage; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/Ingest.ipynb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651#issuecomment-515261645:87,benchmark,benchmarks,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-515261645,1,['benchmark'],['benchmarks']
Testability,@falexwolf @ivirshup ; Tests are also ready.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651#issuecomment-524670031:23,Test,Tests,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-524670031,1,['Test'],['Tests']
Testability,"@falexwolf @willtownes @LuckyMD Valentine Svensson suggests that zero inflation does not exist in droplet protocols, but that log-transforming data could be responsible for the apparent zero inflation. Further, the high number of zeros can be accurately modeled with a non-zero-inflated model: https://www.nature.com/articles/s41587-019-0379-5. Since GLM-PCA doesn’t model zero inflation, it’s probably a really good base for distance calculations in scanpy in cases where its performance is sufficient. [From the paper](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1861-6):. > The multinomial model adequately describes negative control data, and there is no need to model zero inflation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-592476723:126,log,log-transforming,126,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-592476723,1,['log'],['log-transforming']
Testability,"@falexwolf Do you know a more efficient way to get the value of a single column given the gene name. Currently, I am using:. ```; adata[:, 'gene_name'].X; ```. This is easy but not optimal. Any idea?. I will start updating the test once we are happy we the new results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-421258458:227,test,test,227,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-421258458,1,['test'],['test']
Testability,"@falexwolf I agree with you about the `diffxpy` a `scanpy` dependencies, Tensorflow is a very important dependency!. > would you make a PR?. I did it, I pushed the code where I added the parameter `n_components` for `scanpy.tl.tsne` function. > Why not using `diffxpy` Volcano plots right away?. I wrote a function in which you can change the colour of the genes, you can add the names of the genes etc. > How did you write your tests?. I tried them on data coming from the lab in which I am working.; I can write a jupyter notebook using public dataset and push it on my copy of the `scanpy` repository.; Give me a couple of days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471324466:429,test,tests,429,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471324466,1,['test'],['tests']
Testability,"@falexwolf I have the functions in my scanpy branch, right now. It seems to be properly working (take a look, if you want to). I'll add the tests as soon as possibile (now getting back to ""ordinary work"")",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/45#issuecomment-363458980:140,test,tests,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45#issuecomment-363458980,1,['test'],['tests']
Testability,"@falexwolf I took the opportunity to add a change that I wanted with respect to the palette which is the ability to set a palette based on a matplotlib colormap. For example using `palette='tab20'`:. ![image](https://user-images.githubusercontent.com/4964309/46139067-dcf34180-c24d-11e8-892a-a6f3bbda2c4b.png). or using `palette='Set3'`. ![image](https://user-images.githubusercontent.com/4964309/46139126-feecc400-c24d-11e8-9e34-f8395c70aeb9.png). I didn't want to modify the previous code that handles setting the palette to avoid breaking other code, but if we have some tests for other functions that use that functionality I could try to update the original methods.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-425036021:574,test,tests,574,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-425036021,1,['test'],['tests']
Testability,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:123,test,tests,123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088,10,"['log', 'test']","['log', 'test', 'testing', 'tests']"
Testability,@falexwolf Is there anyplace where we can read into `diffxpy`? I've been benchmarking available marker gene detection algorithms and am interested to see what is included in this new package.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/159#issuecomment-420362783:73,benchmark,benchmarking,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159#issuecomment-420362783,1,['benchmark'],['benchmarking']
Testability,"@falexwolf Thanks for the support. . I agree that this is not an urgent changes that can quietly be tested. Have you consider having a 'develop' branch were we can put all code like this? . As you point out some differences are seen with respect to the shape of the plot when multiple panels are plot. This is mostly due to some code to add space for the colorbar and legends that can overlap nearby figures. Nevertheless, I can further adjust this to get plots that are more similar to the actual ones. I think that the tests are failing because there is a clash between the module and a method called `scatter`. Once the code is cleaned this should go away. . If you don't mind I would slowly start removing redundant code and adding further tests. So, lets keep this PR open.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-416855357:100,test,tested,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-416855357,3,['test'],"['tested', 'tests']"
Testability,"@falexwolf The UMAP test works because the umap coordinates are saved along the pbmc datataset that I am using. In contrast, the tsne coordinates need to be computed. Thus I suggest to leave the UMAP test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-424247659:20,test,test,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-424247659,2,['test'],['test']
Testability,"@falexwolf the problem is that there are functions that do now work without them and our down stream packages do not work ootb. Would it be possible to add a second file, e.g. `requirements-ect.txt` to keep track of this?. This file could also be used to create testing environments easily.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/305#issuecomment-433357089:262,test,testing,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/305#issuecomment-433357089,1,['test'],['testing']
Testability,@falexwolf you were a little quick: @davidsebfischer didn’t turn it public yet. maybe david would like to send it to you for beta testing?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/159#issuecomment-420550464:130,test,testing,130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159#issuecomment-420550464,1,['test'],['testing']
Testability,"@fidelram Since we are not using tight layout when we save figures for the plotting tests, axis labels are cut off. I enabled it to avoid that with the following modification:. <img width=""759"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/110717685-87ba0900-81d7-11eb-8cfd-a1c71155d276.png"">. Here is the new plot testing this PR without the tight layout:. ![master_dotplot_groupby_list_catorder](https://user-images.githubusercontent.com/1140359/110726467-6cef9080-81e7-11eb-971d-e6b87dd92f6e.png). which is pretty bad because what really matters in this plot for this PR is the labels of the x axis. Here is the same plot with the tight layout:. ![master_dotplot_groupby_list_catorder-tightlayout](https://user-images.githubusercontent.com/1140359/110726408-534e4900-81e7-11eb-9931-adae793d099e.png). However, many plotting tests fail now due to this change :/ Do you mind helping me with the failing tests?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1735#issuecomment-796324421:84,test,tests,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1735#issuecomment-796324421,4,['test'],"['testing', 'tests']"
Testability,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why?. Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6?. Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-751396676:38,test,tests,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-751396676,10,['test'],"['test', 'tests']"
Testability,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1531#issuecomment-739436787:1551,log,log-norm,1551,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531#issuecomment-739436787,1,['log'],['log-norm']
Testability,@fidelram sorry it took so long... I've added the param to one of the tests.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1161#issuecomment-653802860:70,test,tests,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1161#issuecomment-653802860,1,['test'],['tests']
Testability,"@fidelram that's a really great point and something I'd like to discuss at next meeting (already put it in the agenda). Another great example of such examples 😅 is the way @michalk8 set it up for [cellrank](https://cellrank.readthedocs.io/en/latest/auto_examples/index.html) and squidpy [not yet public].; The even nicer thing is that @michalk8 implemented a CI pipeline for the tutorials/examples part of the repo so that every time there is a change in master of the original repo, the examples are refreshed in the notebooks repo, so to have them always up to date. Would be really cool to concentrate efforts and try to get this logic also in scanpy (makes it both very user friendly and robust from a maintainer perspective)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1604#issuecomment-765363376:633,log,logic,633,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1604#issuecomment-765363376,1,['log'],['logic']
Testability,"@fidelram, I merged with master and all tests pass. Should be ready to merge.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1417#issuecomment-696939838:40,test,tests,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1417#issuecomment-696939838,1,['test'],['tests']
Testability,"@fidelram, I've updated this so the tests pass, and think I've caught a few more bugs. Hopefully I didn't misinterpret your intent here, but I'm merging as we'd like to get a release out. Please let me know if I've messed anything up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1529#issuecomment-865866325:36,test,tests,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529#issuecomment-865866325,1,['test'],['tests']
Testability,"@fidelram, we are still working paper/preprint. I will post it soon. . I will add tests. So in order for the test to work should I add my library in the requirements.txt? What I observed is that other external packages are not included in project requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/812#issuecomment-537410912:82,test,tests,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812#issuecomment-537410912,2,['test'],"['test', 'tests']"
Testability,"@flying-sheep , haven't considered all combinations yet but wanted to check if this way is good for testing warnings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2563#issuecomment-1682154329:100,test,testing,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2563#issuecomment-1682154329,1,['test'],['testing']
Testability,"@flying-sheep ; Because the paper have not been published, so i can't offer the data to reproduce this problem.; Here are the codes:; ```python; import scanpy as sc; import numpy as np; import pandas as pd; import matplotlib.pyplot as plt; import seaborn as sns; import anndata; import matplotlib as mpl; import scipy; from IPython.core.display import display, HTML; display(HTML(""<style>.container { width:90% !important; }</style>"")). ###settings###; sc.settings.verbosity = 1; sc.logging.print_versions(); results_file = './write/sp.h5ad'; sc.settings.set_figure_params(dpi=150). sp=sc.read('sp_velo.loom'); sc.pp.normalize_total(sp,target_sum=1e6,key_added='norm_factor'); sc.pp.log1p(sp); sp.raw=sp; sc.pp.highly_variable_genes(sp, n_top_genes=2000); sc.pl.highly_variable_genes(sp); sp = sp[:, sp.var['highly_variable']]; sc.pp.combat(sp,key='batch',covariates=['sample']); sc.pp.scale(sp, max_value=10); sc.tl.pca(sp, svd_solver='arpack'); sc.pl.pca_variance_ratio(sp, log=True); sc.pp.neighbors(sp, n_neighbors=10, n_pcs=30); sc.tl.diffmap(sp); sc.pp.neighbors(sp, n_neighbors=20, use_rep='X_diffmap'); sc.tl.louvain(sp,resolution=1); sc.tl.paga(sp); _, axs = plt.subplots(ncols=1, figsize=(24, 10), gridspec_kw={'wspace': 0.05, 'left': 0.12}); sc.pl.paga(sp,color='louvain',layout='fa',pos=pos_coord,threshold=0.2,ax=axs); from scanpy.tools._utils import get_init_pos_from_paga as init; sc.tl.umap(sp,init_pos=init(sp)); sc.pl.umap(sp,color='louvain'); ```; Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/918#issuecomment-555510263:483,log,logging,483,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/918#issuecomment-555510263,2,['log'],"['log', 'logging']"
Testability,@flying-sheep @gokceneraslan great! I agree it's hard to compare these algorithms as the performance of an imputation strategy often depends on the downstream use case. I'm looking forward to checking out the countae preprint. I find the [scVI](https://github.com/YosefLab/scVI) benchmark of imputation methods to be useful for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/45#issuecomment-367680111:279,benchmark,benchmark,279,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45#issuecomment-367680111,1,['benchmark'],['benchmark']
Testability,"@flying-sheep Do you want me to resolve your comments as I addressed them or do you prefer to do that yourself? I've seen it done both ways. Once I know, I'll either resolve or not and then re-request your review. The only thing I'm personally still curious about is if you think the tests are ""too"" duplicated still, but there might be other new things/poorly-fixed old things to look at.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2590#issuecomment-1677604847:284,test,tests,284,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590#issuecomment-1677604847,1,['test'],['tests']
Testability,"@flying-sheep For #890 probably we had never tested that combination of parameters because the output was a broking image. . If I understand you correctly, black can by applied to only some lines? Apparently PyCharm can be used with black, do you have any experience?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/893#issuecomment-546330077:45,test,tested,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/893#issuecomment-546330077,1,['test'],['tested']
Testability,@flying-sheep I see that the same tests are failing in other PRs. Do you have any idea what and when some change was introduced that broke the tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/661#issuecomment-495543522:34,test,tests,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495543522,2,['test'],['tests']
Testability,"@flying-sheep I think that your changes should produce images that are almost equal to the ones on the tests as your changes simply introduce a different way to get the colormap. Btw, what is the advantage of using `ListedColormap` and `BoundaryNorm` instead of `LinearSegmentedColormap` ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/369#issuecomment-441619642:103,test,tests,103,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369#issuecomment-441619642,1,['test'],['tests']
Testability,"@flying-sheep I think the [code added in that PR](https://github.com/scverse/scanpy/pull/2816/files#diff-5d0e683154209be7830f09b5389551bf9700a4184d08e97c46c23e2e4beb54a0) is minimally relevant to what happened here. > when user specifies an order, we use that. Right, so here the issue is that the category ordering is used for the labelling but we were not imposing it on the data itself when the violin plots render (separate from the axis labels, as the actual violin plots are added row-by-row). > if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly. In some sense the above also applies. If we want to add some sort of user-facing part of the API to allow for ordering, that is fine, but I think that should be separate as it would go into the next minor release and this is a fairly large bug. I'm fine not testing this because I genuinely don't know how and I spent a few hours yesterday trying different things to no avail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3196#issuecomment-2271132251:860,test,testing,860,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196#issuecomment-2271132251,1,['test'],['testing']
Testability,"@flying-sheep Not sure. Now that you mention it, the rapids benchmark also takes more time than I'd expect as well...The functions themselves are quite fast.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3031#issuecomment-2100566909:60,benchmark,benchmark,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031#issuecomment-2100566909,1,['benchmark'],['benchmark']
Testability,"@flying-sheep and idea what's up with this build error? Docstrings are failing tests, but look fine to me. Seems related to https://github.com/theislab/scanpy/commit/3cacdc87ab47bae70b415e93f2fea74a018c39e2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/615#issuecomment-488208287:79,test,tests,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/615#issuecomment-488208287,1,['test'],['tests']
Testability,@flying-sheep can you cite a reference for scImpute and countae outperforming MAGIC? I'd be curious to learn which hyperparameter optimization methods and performance measures were used in the benchmark.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/45#issuecomment-367378135:193,benchmark,benchmark,193,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45#issuecomment-367378135,1,['benchmark'],['benchmark']
Testability,"@flying-sheep no worries! We'll steadily increase test coverage. I assume that almost no one should have run into the bug in the past 22 days. Among those that updated their version, only very few will have run the PCA with sparse data... @Koncopd, I'm very happy if you move forward with a proper sparse implementation of PCA! :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/393#issuecomment-447614569:50,test,test,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-447614569,1,['test'],['test']
Testability,"@flying-sheep, I made two small changes:. * The 10x readers should no longer return views, fixing `test_read_10x`; * Slightly cleaner providing of categories for leiden/ louvain code. For the clustermap test, it's not clear to me that the problems are even related to pandas, though the cause might be: https://github.com/pandas-dev/pandas/issues/18720. There are two images which are compared in this test. I'll post the comparisons here:. # `master_clustermap.png`. I believe the difference is just the margin, so we should be good to just change the test image. ## Expected. ![master_clustermap](https://user-images.githubusercontent.com/8238804/73589759-d73af980-452e-11ea-9a77-89ecf9e752dc.png). ## Actual. ![master_clustermap](https://user-images.githubusercontent.com/8238804/73589766-e5891580-452e-11ea-9762-aa483399c8b3.png). # `master_clustermap_withcolor.png`. This one looks worse, but I'm not sure how to fix it. @fidelram might know better?. ## Expected. ![master_clustermap_withcolor](https://user-images.githubusercontent.com/8238804/73589782-123d2d00-452f-11ea-828c-5e6fdc0b6091.png). ## Actual. ![master_clustermap_withcolor](https://user-images.githubusercontent.com/8238804/73589788-21bc7600-452f-11ea-9661-ec55aeee07de.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1015#issuecomment-581011973:203,test,test,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1015#issuecomment-581011973,3,['test'],['test']
Testability,"@flying-sheep, I'm pretty sure the logical conclusion of any long discussion about types is that everything should be done in Haskell. I don't like the use of branches with `isinstance` because it breaks polymorphism, which is a key part of pythonic code to me. @falexwolf, I completely agree with you on ""what makes a good docstring"". The knowledge overhead for numeric python doesn't include type theory, so the docs should be interpretable without them. Ideally, interfaces are simple and the documentation makes the expected behavior clear. I'm still not sure I totally understand what the intent of the ""type"" vs. ""class"" system is in python, so I'm often a little unsure what to do with heavily typed code. That said, if expected behaviors could be encapsulated (both formally and intuitively) with some abstract types (representing interfaces or traits) that would be a nicer solution. I don't think we're near that point in python. ## Lattices. Sorry about not giving some info on lattices, I'd thought you didn't want to get into it. It's the [partially ordered set kind](https://en.wikipedia.org/wiki/Lattice_(order)) of lattice, where each type is an element or subset. I'll give a short python based example (ignoring that `Union[]` can't be instantiated). <details>. <summary>The code:</summary>. ```python; from typing import Any, Union. class A():; pass. class B(A):; pass. class C(A):; pass. class D():; pass. class E(D):; pass; ```. </details>. that defines a lattice, which can be represented as a DAG like this:. ```; Any; / \; A D; / \ |; B C E; \ | /; Union[]; ```. It's partially ordered in that you can't say A contains E or vice-versa, but you can say things like A is contains B, and `Any` is a supertype of (contains) everything else. I think that how you're viewing it is pretty close, except the elements are types instead of their properties. My mental model has types being a collection of properties, and being a subtype means an object inherits it's supertypes properti",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-444715545:35,log,logical,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-444715545,1,['log'],['logical']
Testability,"@flying-sheep, do you know of a large package (ideally in our dependencies) which uses the directory structure you're advocating for? I'd ideally like to have another repo to look at/ crib from for test organization strategies.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090364103:198,test,test,198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090364103,1,['test'],['test']
Testability,"@galamm, thanks for the report! Also thanks for the example, very useful!. I think I see what the issue is here, though your error is unexpected. Are you using the most recent version of scanpy (1.7.0)?. The `gene_symbols` argument is supposed to refer to column in `var` that has more human readable gene names. The idea here is that you might have some unique identifier as `var_names` (like ensembl ids), but would have something more interpretable sorted in `adata.var[gene_symbols]`. On my machine, I get a `KeyError` when I run your example since there is no column `""TEST""` in `adata.var`. This is expected. It's strange to me that you get a `NameError`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1636#issuecomment-776540580:574,TEST,TEST,574,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636#issuecomment-776540580,1,['TEST'],['TEST']
Testability,"@giovp ; In the docs it is mentioned that it expects logarithmized data.; As for `raw=True` i am not sure it is a problem. For example, in [the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html) normalized and logarithmized data is saved to `raw` to be used further in `rank_genes_groups`. Do you think it is a problem?. I don't actually consider raw as a container only for raw counts, i think it is a matter of filtered genes vs unfiltered and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/967#issuecomment-795139196:53,log,logarithmized,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/967#issuecomment-795139196,2,['log'],['logarithmized']
Testability,"@giovp Cool! I hadn't seen this. If this is referenced in their paper, then multiplex leiden would fit into the category of ""used in sc analysis"" that I was arguing before, and I would be happy with it being in here. I do think that some testing should ideally happen on our side, so it would be great if you want to take this on, @bio-la !",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1818#issuecomment-860807165:238,test,testing,238,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818#issuecomment-860807165,1,['test'],['testing']
Testability,@giovp Could you check why the visium test fails? I don't think it is related to this PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2255#issuecomment-1143708886:38,test,test,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255#issuecomment-1143708886,1,['test'],['test']
Testability,"@giovp thanks for your reply, I agree on all points :) Have a good vacation!; @ivirshup Let me know if you have any feedback on the open points or if I can do anything in the meantime (e.g. failing tests, docs, fast-lane HVG).; Cheers, Jan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-912511459:198,test,tests,198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-912511459,1,['test'],['tests']
Testability,"@giovp, @stephenwilliams22, @Zethson. This PR seems to have broken a number of tests. I believe due to the change in `pixel_row`/ `pixel_col` order, resulting in a number of test plots now being transposed. If this was always wrong... surely usage would have caught that, so we must be correcting for this somewhere else. What's the correction here? And is it something that should be done quickly, or should I revert this PR until we can figure it out?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2296#issuecomment-1433124648:79,test,tests,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296#issuecomment-1433124648,2,['test'],"['test', 'tests']"
Testability,"@giovp, I'll merge this. I'm merging a couple other things first though. I'm not super happy with the logic flow here at the moment. Could we aim for separating out the code for scatter plots, and overlaying grids on-top of images in the next release cycle?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1217#issuecomment-630021238:102,log,logic,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217#issuecomment-630021238,1,['log'],['logic']
Testability,"@gokceneraslan Do you know why the test is failing? Did you change some of the defaults? I like the change, is really an improvement.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/640#issuecomment-495542139:35,test,test,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/640#issuecomment-495542139,1,['test'],['test']
Testability,@gokceneraslan I've been thinking we should have options like `layer` and `obsm` in many more places. I've started trying to implement this in a systemic way with an internal API and some test helpers in: #1173. What would you think of using that here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/959#issuecomment-617017283:188,test,test,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/959#issuecomment-617017283,1,['test'],['test']
Testability,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-761117523:29,test,tests,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-761117523,6,['test'],"['test', 'tests']"
Testability,"@gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/512#issuecomment-469609880:15,Test,Tests,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512#issuecomment-469609880,1,['Test'],['Tests']
Testability,@gokceneraslan Thanks for looking at this. Can you add test for this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/776#issuecomment-521567791:55,test,test,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/776#issuecomment-521567791,1,['test'],['test']
Testability,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download?. @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`; * `seaborn` – `~/seaborn-data`; * `NLTK` – `~/nltk_data`; * `keras` and `tensorflow` – `~/.keras/datasets`; * `conda` – `~/miniconda3/`; * `intake` – `~/.intake/cache/` (specifically for caching feature); * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448:852,log,log,852,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448,1,['log'],['log']
Testability,"@gokceneraslan Yes, I agree a transparent benchmark repo would be very valuable. . I'd also like to see a detailed breakdown of the limitations of each method or imputation in general. It seems problematic to me to use imputed data for all downstream analyses, for example sub-clustering or DGE analysis, but I can't find a discussion of those limitations anywhere. I'm a little wary of imputation methods being part of a standard toolkit without sufficient discussion of limitations in the documentation somewhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189#issuecomment-404866769:42,benchmark,benchmark,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189#issuecomment-404866769,1,['benchmark'],['benchmark']
Testability,"@gokceneraslan here's a quick example:. ```python; import scanpy as sc; pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.pp.highly_variable_genes(pbmc, batch_key=""louvain""). assert not pbmc.var[""highly_variable""].any(); ```. Alternatively:. ```python; pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); pbmc.obs[""batch""] = ""a""; sc.pp.highly_variable_genes(pbmc, batch_key=""batch""); assert not pbmc.var[""highly_variable""].any(). pbmc.obs[""batch""] = ""a""; pbmc.obs[""batch""][::2] = ""b""; sc.pp.highly_variable_genes(pbmc, batch_key=""batch""); assert not pbmc.var[""highly_variable""].any(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032#issuecomment-616960210:182,assert,assert,182,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032#issuecomment-616960210,3,['assert'],['assert']
Testability,"@gokceneraslan that might have been an issue before... however I have now specified the tests via column and row names, and generated named recarrays, so I'm still looking now...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/583#issuecomment-479508416:88,test,tests,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-479508416,1,['test'],['tests']
Testability,"@grst Thanks it seems logical, but,. It is mentioned in Seurat Pbmc3k example that best resolution parameter is 0.6-1.2 , but you used less and get more clusters. May be because i didn't explore random seed in leiden. ; In louvain and leiden we usually optimize 'modularity' value, what if we just calculate modularity values for different resolution instead of optimizing for given resolution and then for resolution where 'modularity' is maximum, we optimized 'modalarity'. Is this ok ? But i also think that 'modularity' increases when we have small number of clusters. Any suggestion ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-498158306:22,log,logical,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498158306,1,['log'],['logical']
Testability,"@ilan-gold, could you remind me of what you thought should happen with the PCA test case here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1934501172:79,test,test,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1934501172,1,['test'],['test']
Testability,@ivirshup . `exclude: scanpy/tests/_data`. Added for trailing-whitespace and end-of-file-fixer.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1848#issuecomment-848597315:29,test,tests,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1848#issuecomment-848597315,1,['test'],['tests']
Testability,@ivirshup : Thanks for the background explanation. . @njbernstein Can you move the import statements inside the `_demultiplex_per_barcode` to remove the test errors? . I think the tool should go to `external` to point out that this is based on a method that we have not tested and thus the responsibility of its accuracy and implementation lies on the external contributor.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/797#issuecomment-537023624:153,test,test,153,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797#issuecomment-537023624,2,['test'],"['test', 'tested']"
Testability,"@ivirshup ; > * Could you show some examples of the new additions/ let me know where you are on tutorials?. I will do that once we are happy with the current code and naming conventions used. My goal was to update this tutorial https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html but suggestions are welcome. . > * Could you add tests for functionality where the underlying code is changing, but doesn't have coverage yet? I would mostly just like to see more tests of the plotting code. I will try to do that. > * What do you think about the idea of splitting up `_anndata.py` into a few more files? I think it's getting a bit too big, which can make reviewing difficult. We should to that. Currently, as I see it we have two types of plots: ; * embedding scatter plots which are separated already; * the type of plots in this PR that I would describe as `grouping` plots, because they visualize the AnnData matrix subdivided based on a .`obs` column. Any better name for this?. > * Could you run `black` over this?. Will do it at the end. Do we have some style policies for black or the defaults are fine?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1127#issuecomment-608262723:357,test,tests,357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127#issuecomment-608262723,2,['test'],['tests']
Testability,"@ivirshup ; Thanks, i'll add tests ofc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1118#issuecomment-600689830:29,test,tests,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1118#issuecomment-600689830,1,['test'],['tests']
Testability,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this?. Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-822033944:183,test,tests,183,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-822033944,1,['test'],['tests']
Testability,"@ivirshup @flying-sheep I would like to merge this code but I have some questions:. - Do you know why the test is failing?; - Currently, this is located in `preprocessing`, but I think that the right place is `external.pp` would you agree on that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/797#issuecomment-536570108:106,test,test,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797#issuecomment-536570108,1,['test'],['test']
Testability,"@ivirshup @ilan-gold just got back to this, thought i could not install wsl as I am on a somewhat company restricted laptop, but turns out i can. installing it now (and probably using that from here on out). will run the tester in a bit and let you know",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2039290843:221,test,tester,221,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2039290843,1,['test'],['tester']
Testability,@ivirshup Honestly don't know what I was thinking here- the parameters are clearly not passed through. Perhaps I broke things when rearranging logic in the PR. In in any case I'll submit a fix soon.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1644#issuecomment-781238831:143,log,logic,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1644#issuecomment-781238831,1,['log'],['logic']
Testability,@ivirshup I am getting same numba errors on windows 10 machine. I can test the workaround if you provide a fix. Currently to make the function working I set `percent_top=None`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/843#issuecomment-542784036:70,test,test,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843#issuecomment-542784036,1,['test'],['test']
Testability,"@ivirshup I checked and now I don't get warnings :). However, I could not plot the layer. In the following example, I make a new layer that is the negative of the default layer. As you see, bot the default and the negative ('test') layer are identical. ![image](https://user-images.githubusercontent.com/4964309/61049083-df411980-a3e3-11e9-8508-978a78d7f3b4.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/730#issuecomment-510456004:225,test,test,225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730#issuecomment-510456004,1,['test'],['test']
Testability,@ivirshup I didn't notice until now that you requested the review. The code looks ok but I will do some tests.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/713#issuecomment-509109864:104,test,tests,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/713#issuecomment-509109864,1,['test'],['tests']
Testability,@ivirshup I don't know where the crash in the build is coming from I change nothing in those parts. However I rewrote the sparse logic and to me it's now a lot better.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2025622010:129,log,logic,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2942#issuecomment-2025622010,1,['log'],['logic']
Testability,"@ivirshup I don't think so, unless there's work towards https://github.com/scverse/anndata/issues/244. To follow the ideas in https://github.com/scverse/anndata/issues/706, seems like the steps would be:. - [ ] add an attribute `._X_layer` to store which layer `.X` references;; - [ ] use `.X` to reference `.layers[._X_layer]`;; - [ ] add `in_layer=` and `out_layer=` arguments to scanpy's `.pp` functions;; - [ ] these functions will also alter `._X_layer`. The second to last point can actually be implemented irrespective of the AnnData change as `in_layer=None` will mean taking `.X`. ; The question is, should we consider changing the defaults right away, e.g. `in_layer=""counts"", out_layer=""lognorm""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2261#issuecomment-1157056525:698,log,lognorm,698,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-1157056525,1,['log'],['lognorm']
Testability,@ivirshup I tested and now is working as expected. Thanks for adding the new tests. From my side is ready to go.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/730#issuecomment-510800095:12,test,tested,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730#issuecomment-510800095,2,['test'],"['tested', 'tests']"
Testability,@ivirshup I think the benchmarks have shown satisfactory performance of this PR. Should we move on to polishing the code organization?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-591647662:22,benchmark,benchmarks,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-591647662,1,['benchmark'],['benchmarks']
Testability,"@ivirshup I think this needs some tweaking... ```python; import dask.array as da; import numpy as np; import dask. X = da.random.poisson(2, (1_000, ), chunks = (100, )); def nonzero_median(x):; return np.ma.median(np.ma.masked_array(x, x > 0)); dask_median = da.from_delayed(dask.delayed(nonzero_median)(X), shape=(), meta=X._meta, dtype=X.dtype).compute(); np_median = np.median(X.compute()[X.compute() > 0]); np_ma_median = nonzero_median(X.compute()); assert np_median == dask_median; assert np_ma_median == dask_median; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2856#issuecomment-1981155670:455,assert,assert,455,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2856#issuecomment-1981155670,2,['assert'],['assert']
Testability,"@ivirshup I will revert those, and hopefully tests pass",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952629319:45,test,tests,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952629319,1,['test'],['tests']
Testability,"@ivirshup I'd actually be interest in hearing those. My packages also have the test folder outside the package, but I am happy to learn why many major packages have theirs in the actual package and why that might be a good idea.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1528#issuecomment-1089291545:79,test,test,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528#issuecomment-1089291545,1,['test'],['test']
Testability,"@ivirshup I've merged the changes in master from those factored-out PRs, and added a couple of tests. Ready for review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1965#issuecomment-1017444179:95,test,tests,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965#issuecomment-1017444179,1,['test'],['tests']
Testability,"@ivirshup If I remember correctly, you said that there was a specific anndata operation within the scanpy `pca` that was causing the order to change. And you were comparing the output of that to something else that did not do that operation. So my suggestion was to just do that operation and add a note. If you could point me to the test/line of code causing the order to change, I'd have a better sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1935905257:334,test,test,334,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1935905257,1,['test'],['test']
Testability,"@ivirshup In the last few commits, I added some things to skip some unnecessary computation steps (which were only used for logging/warning). Here's a quick example:. ```python; import fsspec; import zarr; from anndata.experimental import sparse_dataset; from anndata import AnnData; import dask.array as da; from dask import delayed; from scipy import sparse. class AccessTrackingStore(zarr.LRUStoreCache):; def __init__(self, *args, **kwargs):; super().__init__(*args, **kwargs). def __getitem__(self, key):; if key not in self._values_cache:; print(key); return super().__getitem__(key). def csr_callable(shape: tuple[int, int], dtype) -> sparse.csr_matrix:; if len(shape) == 0:; shape = (0, 0); if len(shape) == 1:; shape = (shape[0], 0); elif len(shape) == 2:; pass; else:; raise ValueError(shape). return sparse.csr_matrix(shape, dtype=dtype). class CSRCallable:; """"""Dummy class to bypass dask checks""""""; def __new__(cls, shape, dtype):; return csr_callable(shape, dtype). def make_dask_chunk(x, start: int, end: int) -> da.Array:; def take_slice(x, idx):; return x[idx]. return da.from_delayed(; delayed(take_slice)(x, slice(start, end)),; dtype=x.dtype,; shape=(end - start, x.shape[1]),; meta=CSRCallable,; ). def sparse_dataset_as_dask(x, stride: int):; n_chunks, rem = divmod(x.shape[0], stride). chunks = []; cur_pos = 0; for i in range(n_chunks):; chunks.append(make_dask_chunk(x, cur_pos, cur_pos + stride)); cur_pos += stride; if rem:; chunks.append(make_dask_chunk(x, cur_pos, x.shape[0])). return da.concatenate(chunks, axis=0). def read_w_sparse_dask(group, obs_chunk: int = 1000) -> AnnData:; return AnnData(; X=sparse_dataset_as_dask(sparse_dataset(group[""X""]), obs_chunk),; ); ```; After this setup:; ```python; mapper = fsspec.get_mapper(; ""https://vitessce-demo-data.storage.googleapis.com/anndata-demos/BALF_VIB-UGent_processed_cleaned.zarr/""; ); store = AccessTrackingStore(mapper, max_size=2**28); adata = read_w_sparse_dask(zarr.convenience.open_consolidated(store)); ```; T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2856#issuecomment-1983048375:124,log,logging,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2856#issuecomment-1983048375,1,['log'],['logging']
Testability,"@ivirshup Indeed the problem is `use_raw=True` by default. In the test, I think what happens is that the raw data is being plotted and thus no error appears. The tolerance for the image difference may hide the problem if indeed the test image is correct. To avoid this confusion when plotting a layer I think it is better to override `use_raw`. This is how it was supposed to be working before the changes according to the documentation:. ```; layer : typing.Union[str, NoneType], optional (default: None); Name of the AnnData object layer that wants to be plotted. By default; adata.raw.X is plotted. If `use_raw=False` is set, then `adata.X` is plotted.; If `layer` is set to a valid layer name, then the layer is plotted. `layer`; takes precedence over `use_raw`.; ``` ; The current logic is around this lines https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L744. PS: the `use_raw` has been a source of many confusions for me. Now I know when raw is used by default but for new users this may not be obvious. One solution is to add a warning message everytime that `use_raw` is set to `True` by the code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/730#issuecomment-510785080:66,test,test,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730#issuecomment-510785080,3,"['log', 'test']","['logic', 'test']"
Testability,"@ivirshup Looks great! I like the new spatial test image ;) well done!. I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1356#issuecomment-678099918:46,test,test,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356#issuecomment-678099918,1,['test'],['test']
Testability,@ivirshup Re: `AssertionError: Error: Image files did not match.` See https://github.com/scverse/scanpy/pull/2815/files#diff-79d72f67d7be639d5fcd7d63a006524d1317f16261044fdeeae6f6da4d14e88aR30-R34 - I suspect the tolerances need to be udpated and checked. I was getting the opposite (I assume) - images that should be different were not picked up as such for sparse plots (like gene rankings).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896481527:15,Assert,AssertionError,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896481527,1,['Assert'],['AssertionError']
Testability,"@ivirshup Thank you for the feedback. I will add a release note soon. I also thought about the naming of the parameter. However, if we assume that also in the future it is mostly used to subset the number of PCs in PCA arrays stored under different names, it should be fine?. I can not comment further on what these changes may break, at least ideally they should make the use of n_pcs more consistent and as expected. Would you suggest, I implement some further, more comprehensive tests?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2179#issuecomment-1076393928:483,test,tests,483,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1076393928,1,['test'],['tests']
Testability,@ivirshup Thanks for letting me know. It will also update for me once 1.10.1 is out. I use the logic from scanpy for this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2964#issuecomment-2021388747:95,log,logic,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2964#issuecomment-2021388747,1,['log'],['logic']
Testability,"@ivirshup The code diff is [here](https://github.com/scverse/scanpy/compare/master...ilan-gold:scanpy:igraph_leiden?expand=1#diff-9b0695a74ff6002a10a74cef4b450792a39038f204ce166f7cce1b3274b77816) but I'll explain the logic of the changes. . 1. `igraph`'s implementation does not allow directed graphs; we throw a ValueError if someone tries to do directed + `igraph`.; 2. `igraph`'s default resolution parameter is 2, so that changed as well. I don't think we should swap it back to -1 for `leidenalg`.; 3. Of course `use_igraph` is now `True` (and a new argument). I'll look into some larger datasets. ~~Also there is no plotting test from what I see. Should we add that?~~",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1892447669:217,log,logic,217,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053#issuecomment-1892447669,2,"['log', 'test']","['logic', 'test']"
Testability,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308:14,test,test,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308,3,['test'],"['test', 'tests']"
Testability,"@ivirshup This looks great! Thanks. The issue with the cropping of the labels is quite annoying and indeed `bbox_inches=""tight""` should help. However, I don't think is nice to add that line for each example, but, on the other hand, if we add this to the scanpy code, many figures will be affected and would need to be updated. The same issue also affects the test images which most are cropped.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1632#issuecomment-775750950:359,test,test,359,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1632#issuecomment-775750950,1,['test'],['test']
Testability,"@ivirshup coloring by boolean values `(True, False)` is now possible:. 1) The solution is based on casting the boolean columns to string columns, so that they can be colored in a categorical way. Actual columns in the anndata object are not modified. 2) I was thinking about the case where True is 1 and False is 0. Current behaviour: colorbar is plotted, since 0 and 1 are treated like continuous variables. Does it make sense to handle this case in scanpy?. 3) Tests fail due to new pandas version, they do not fail locally though. . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2460#issuecomment-1500883671:463,Test,Tests,463,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460#issuecomment-1500883671,1,['Test'],['Tests']
Testability,"@ivirshup okay, I've tried that (thanks for the snazzy function), fingers crossed on tests. This is somewhat involved. When providing adata_sim I had, by design, made the assumption that the user will have done all their own preprocessing. So to make the comparison you requested (sc.external.pp.scrublet with/without adata_sim) I needed to basically replicate all that preprocessing verbatim in the test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2025#issuecomment-969366293:85,test,tests,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2025#issuecomment-969366293,2,['test'],"['test', 'tests']"
Testability,@ivirshup perfectly fine with me.; Removed 3.6 . So we are now testing against 3.7 and 3.8.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1602#issuecomment-763583210:63,test,testing,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1602#issuecomment-763583210,1,['test'],['testing']
Testability,"@ivirshup sorry super late on this, added a default test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1255#issuecomment-657567661:52,test,test,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255#issuecomment-657567661,1,['test'],['test']
Testability,"@ivirshup, the tests now copies the prefix data into a temp dir.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1250#issuecomment-635277251:15,test,tests,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1250#issuecomment-635277251,1,['test'],['tests']
Testability,"@jarny I have the same error still, but when testing on travis it doesn't fail so I have no clue. Locally I create the `__init__.py` file though to make it work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/585#issuecomment-480651534:45,test,testing,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-480651534,1,['test'],['testing']
Testability,"@jlause sorry for not getting back. I just had a look at tests and it looks good!; as discussed via email, we would like to first add this to an `experimental` API before including it in code. Tomorrow I will arrange the code slots were you'd have to copy over the functions from their current places. It's a bit of tedious work but shouldn't take much. Will elaborate better on comments!; I will then take care of fixing docs and links. . Another thing still left to be done would be a tutorial on how to use these function and a more elaborate explanation. We will add that tutorial to `scanpy-tutorials` and link from main docs. Maybe you could start already briefly fleshing it out? I'd move the conversation of the tutorial to https://github.com/theislab/scanpy-tutorials",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-873639813:57,test,tests,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-873639813,1,['test'],['tests']
Testability,"@jlause, thanks for figuring this out as well!. A separate PR for this fix would be great. There should definitely be tests targeting this, since changing how the sort is done doesn't seem to break anything.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1733#issuecomment-802581847:118,test,tests,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733#issuecomment-802581847,1,['test'],['tests']
Testability,"@karenlawwc ; For the test.h5ad that you’ve saved using adata.write, I think you want to load it with sc.read_h5ad() rather than sc.read_10x_h5(), since the saved test file will be in AnnData h5ad format",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2246#issuecomment-1255636170:22,test,test,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1255636170,2,['test'],['test']
Testability,@lazappi you are now the chosen one :). Think that using the size attribute like in https://github.com/scverse/scanpy/pull/1985/files is maybe nicer and more explicit. `len()` could technically be overwritten and return anything. It's less explicit. Could you maybe add a quick test which covers this case?. Thank you very much!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2231#issuecomment-1117367877:278,test,test,278,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1117367877,1,['test'],['test']
Testability,@maarten-hifibio we are indeed actively working on this again. Feel free to join our zulip https://scverse.zulipchat.com/login/ and ping me. I can add you to the conversation.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1793#issuecomment-1102832260:121,log,login,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793#issuecomment-1102832260,1,['log'],['login']
Testability,@meeseeksdev backport to test-backports,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1384#issuecomment-740500580:25,test,test-backports,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1384#issuecomment-740500580,1,['test'],['test-backports']
Testability,"@michalk8 , would be great to add a test for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1161#issuecomment-621051643:36,test,test,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1161#issuecomment-621051643,1,['test'],['test']
Testability,"@michalk8 thanks for the extensive recommendations!. I think I'd like to keep the number of tools used small. It's the worst when you want to fix a bug, but instead have to learn about configuring a linter. More tools means more configurations people need to be familiar with, and the goal is reducing cognitive load. > Also fixing types for `mypy` takes a while, I'd do it as last. Yeah, I figured this would be the case. Does `mypy` allow partial typing these days? Also, I haven't found the numpy or pandas type stubs to always be great. Have you run into problems around this?. I think this would also need to wait at least until we can drop python 3.6 for `anndata`, since adding types there currently means circular dependencies. > `rstcheck` to check the syntax of .rst files. I would particularly like a linter for `rst`. I noticed you also had `doc8`, but you'd recommend `rstcheck` check over this? I'm a little worried, considering its last release was over a year ago. Spell check for prose in doc-strings could also be great, but I could see this being overzealous (is there a good way to notify about misspelled words, while not being annoying about technical terms?). I'm a little worried about some custom sphinx extensions we have, and conflicting with this, any experience here?. --------------------------------------------. @Koncopd, I think I agree with your concern, as I said above: it's the worst when you want to fix a bug, but instead have to learn about configuring a linter. I also think it's very easy to add new checks, so someone complaining about new ones is valuable. Per commit, this should always be an option with `git commit --no-verify`, though you could also just not install `pre-commit`. I would like to keep the required checks limited, ideally formatting tasks that can be automated as opposed ""this is poor style"" warnings. I also know these tools can be wrong (e.g. `black` when expression's have many operators, sometimes with chaining) so it would be goo",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-754352635:515,stub,stubs,515,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-754352635,1,['stub'],['stubs']
Testability,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:; ```sh; pip install --user scikit-misc; ```; But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:; ```py; # find the highly variable genes...; # Since we are using seurat_v3 as the flavor,; # we have to do this before normalization; sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', ; n_top_genes=2000). # Normalize and log transform (over all genes); sc.pp.normalize_total(sc96, target_sum=1e4); sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting; # to just the highly variable genes else our normalization ; # for reads will only be counting the subset. # now select the subset; sc96 = sc96[:,sc96.var.highly_variable]; ```; With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1531#issuecomment-1079775692:906,log,log,906,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531#issuecomment-1079775692,1,['log'],['log']
Testability,"@njbernstein Probably not the right place for this discussion, but a couple of follow-up questions for you:; - Do you happen to have a benchmark of `hashsolo` vs the other demuxing algos? It's been on my todo list for ..a while.. but still haven't gotten around to doing it. I've seen the benchmarks of the doublet finding capabilities of `solo` and they look good. As a user of scrublet, it'd be nice to have one tool/codebase that handles both transcriptomic and tag multiplets.; - Are you open to PRs? I'd at least like to have functionality to generate the initial h5ad object containing the tag counts from the output of `CITE-seq-Count`.; - Regarding non-antibody tags, have you noticed celltype-specific preferential binding? I've had problems with LMO/CMOs where not tagging particular celltypes (like some epithelial subtypes where we had 2-3 orders of magnitude lower tag counts).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-759587209:135,benchmark,benchmark,135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-759587209,2,['benchmark'],"['benchmark', 'benchmarks']"
Testability,"@ontsilla We can take a look at this, but I'm not sure if there will be a solution soon. Have you tried using [conda](https://conda.io/en/latest/miniconda.html) on this system? I think it might be your best bet here. @flying-sheep I can recreate with:. ```; conda create -yn testenv python=3.5.2; conda activate testenv; pip install scanpy; python -c ""import scanpy"" ; ```. It looks like there were a lot of bug fixes to python's `typing` module between v3.5.2 and v3.5.4 ([changelog](https://docs.python.org/3.5/whatsnew/changelog.html#python-3-5-4rc1)). I don't get this error with v3.5.4. Are pre-bugfix versions of python supported?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/561#issuecomment-476952168:275,test,testenv,275,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-476952168,2,['test'],['testenv']
Testability,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/525#issuecomment-471592072:83,test,tests,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471592072,1,['test'],['tests']
Testability,@outlace I will check the problem with the test and integrate your changes in a new PR that addresses #512 and #524 if this is OK with you.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/525#issuecomment-471455638:43,test,test,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471455638,1,['test'],['test']
Testability,"@pati-ni ; I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy.; Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1298#issuecomment-653900843:192,test,tested,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298#issuecomment-653900843,1,['test'],['tested']
Testability,@patrick-nicodemus What we need more than anything is someone to test out a fix and to confirm that using `wsl` prevents the problem. See https://github.com/scverse/scanpy/pull/3041. The issue is that we don't have windows machines.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2328153544:65,test,test,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2328153544,1,['test'],['test']
Testability,"@pedrofale would you be able to add the suggested test for this, please?; If not, @lazappi PR will succeed this one and we will close this one. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1985#issuecomment-1105164387:50,test,test,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985#issuecomment-1105164387,1,['test'],['test']
Testability,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```; 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]; 204Processing /home/travis/build/theislab/scanpy; 205 Installing build dependencies ... done; 206 Getting requirements to build wheel ... done; 207 Preparing wheel metadata ... done; 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'; ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-734643707:18,test,tests,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-734643707,3,"['log', 'test']","['logs', 'test', 'tests']"
Testability,"@pranzatelli, could you open a new issue for this? In that issue, could you also report what versions of the dependencies you're using via `sc.logging.print_versions()`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1823#issuecomment-983618113:143,log,logging,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823#issuecomment-983618113,1,['log'],['logging']
Testability,"@shendong124 @ivirshup I assume `normalize_geometric` was intended to be similar to Seurat's centered log ratio transformation, which is implemented as follows in R: `log1p(x = x / (exp(x = sum(log1p(x = x[x > 0]), na.rm = TRUE) / length(x = x))))`. This is CLR with some safeguards for 0 counts. Here's a reimplementation of the Seurat CLR transformation for scanpy. Call this with `clr_normalize_each_cell(adata)`:. ```; def clr_normalize_each_cell(adata, inplace=True):; """"""Normalize count vector for each cell, i.e. for each row of .X"""""". import numpy as np; import scipy. def seurat_clr(x):; # TODO: support sparseness; s = np.sum(np.log1p(x[x > 0])); exp = np.exp(s / len(x)); return np.log1p(x / exp). if not inplace:; adata = adata.copy(). # apply to dense or sparse matrix, along axis. returns dense matrix; adata.X = np.apply_along_axis(; seurat_clr, 1, (adata.X.A if scipy.sparse.issparse(adata.X) else adata.X); ); return adata; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1208#issuecomment-638496235:102,log,log,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208#issuecomment-638496235,1,['log'],['log']
Testability,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:394,test,test,394,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051,4,['test'],['test']
Testability,@stefanpeidli is currently testing whether scVelo `pl.scatter` entails all scanpy functionality. @fidelram Can you give me a very brief outline of what functionality you added in `pl.embedding` so that I can account for these as well?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/617#issuecomment-554375694:27,test,testing,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554375694,1,['test'],['testing']
Testability,@swolock why don't you submit a PR? I just tested your code and seems to work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-508722585:43,test,tested,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-508722585,1,['test'],['tested']
Testability,"@tomwhite OK, I added this to the release notes (https://github.com/theislab/scanpy/commit/cee23dc13cf2b77d8e23ee0f91eb55fac0e35ed8, sorry confounded with some style change); it would be nice to have a link to your performance benchmarks... Let me know when we should announce it on twitter. I'm also happy to retweet...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/371#issuecomment-456647889:227,benchmark,benchmarks,227,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/371#issuecomment-456647889,1,['benchmark'],['benchmarks']
Testability,"@wangjiawen2013 we recommend using square root transform with MAGIC but it's certainly not incompatible. So long as the inputs have been library size normalized and transformed with any of log, sqrt, arcsinh or some other sublinear transformation, MAGIC will work just fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/187#issuecomment-403501006:189,log,log,189,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187#issuecomment-403501006,1,['log'],['log']
Testability,"@wflynny `hashsolo` allows you to set a prior for your expected rate negatives, singlets, and doublets, which helps quite a bit with the issue you described despite modeling the log CMO counts as a normal distribution. Additionally, you can also add cell types if you've done cell-type annotation or even leiden clustering labels to help with cell type variability with CMO counts. This helped me quite a bit in kidney where NK cells had far fewer CMO counts than other cells despite being apparently live cells, e.g. good gene diversity and low mitochondrial gene percentage. @fidelram I'd be happy to add a visualization tool like you suggested if you have the code laying around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-759575072:178,log,log,178,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-759575072,1,['log'],['log']
Testability,"A few comments from my endeavors:; - Not sure how good is max scaling on groups for differently strongly expressed genes, especially due to mean-var bias - e.g. 0.8 of max expression for highly expressed genes is probably more meaningful difference than for a lowly expressed one.; - m=0 s=1 z-standardisation can be problematic if you have a small vs large population that has high expression (relatively to the size of whole data) - in former case you get much higher scores than in the latter as whole data seems higher; - If you have many cells doing [0,1] across cells rather than groups and then averaging may be good option as well (see below). Potential problem if you have outlier cells (less likely if log-norm before), but in this case you could normalise from 1st to 99th percentile - still may be problem for rare populations but at least you can regulate the threshold (so better than z-standardisation maybe).; - [0,1] on groups is not too bad when you expect large variation anyway by definition (e.g. plotting top data-defined markers), but agreed too often misleading so should not be default. Example: See gene Trp53bp1 under old - not much difference across groups:; - [0,1] on groups - seems very variable; ![image](https://user-images.githubusercontent.com/47607471/160437189-dd2c3deb-786e-4317-a4cf-fd31fdbd7f19.png); - no normalisation (currently only other option) - bad for multiple marker comparison; ![image](https://user-images.githubusercontent.com/47607471/160437292-daf03941-1e9a-44ed-8942-f2a180ec2c85.png); - max_abs scale on groups - probably still exaggerates variability; ![image](https://user-images.githubusercontent.com/47607471/160456753-c211d7da-1f72-46f3-9355-87eebc649472.png); - [0,1] on cells (before averaging) - the only one that does not exaggerate between group variability; similar with max_abs scaling on cells - probably as some cells are 0 - but much better in terms of time for large sparse matrices. however, this type of normalisation makes dif",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1757#issuecomment-1080962638:712,log,log-norm,712,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757#issuecomment-1080962638,1,['log'],['log-norm']
Testability,"A quick reproducible example:. ```python; import scanpy as sc; pbmc = sc.datasets.pbmc68k_reduced(); pbmc.X = pbmc.raw.X; sc.tl.rank_genes_groups( ; pbmc, ; groupby=""bulk_labels"", ; groups=[""CD14+ Monocyte"", ""Dendritic""], ; reference=""Dendritic"", ; n_genes=pbmc.shape[1], ; method='wilcoxon' ; ) ; md_d = ( ; sc.get.rank_genes_groups_df(pbmc, group=""CD14+ Monocyte"") ; .set_index(""names"", drop=False) ; ) ; ; sc.tl.rank_genes_groups( ; pbmc, ; groupby=""bulk_labels"", ; groups=[""CD14+ Monocyte"", ""Dendritic""], ; reference=""CD14+ Monocyte"", ; n_genes=pbmc.shape[1], ; method='wilcoxon' ; ) ; md_m = ( ; sc.get.rank_genes_groups_df(pbmc, group=""Dendritic"") ; .set_index(""names"", drop=False) ; ). md_d.head(); # scores names logfoldchanges pvals pvals_adj; # names ; # FTL 13.163277 FTL 1.600541 1.427571e-39 1.092092e-36; # AIF1 12.768205 AIF1 1.882886 2.467807e-37 9.439361e-35; # FCGR3A 12.733917 FCGR3A 4.500901 3.831234e-37 9.769647e-35; # PSAP 12.576810 PSAP 1.998426 2.832393e-36 5.416951e-34; # FCER1G 12.152568 FCER1G 1.596950 5.559192e-34 8.505565e-32; md_m.tail()[::-1]; # scores names logfoldchanges pvals pvals_adj; # names ; # FTL -12.616215 FTL -1.600541 1.718871e-36 1.314936e-33; # FCGR3A -12.204766 FCGR3A -4.500901 2.931495e-34 7.919483e-32; # AIF1 -12.176620 AIF1 -1.882886 4.140906e-34 7.919483e-32; # PSAP -12.115210 PSAP -1.998426 8.773953e-34 1.342415e-31; # FCER1G -11.519019 FCER1G -1.596950 1.058089e-30 8.094380e-29; ```. I think the log fold changes are pretty close, and those small changes could be occurring due to different order of operations and the use of single precision. I'm not to worried about these. . Could someone more familiar with the differential expression code comment about p-value correctness? @falexwolf @a-munoz-rojas? A few of the values look pretty different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/754#issuecomment-517541034:721,log,logfoldchanges,721,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754#issuecomment-517541034,3,['log'],"['log', 'logfoldchanges']"
Testability,A rough implementation of glmpca in python is now available here: https://github.com/willtownes/glmpca-py . I will try to get it organized as an installable package tomorrow and add unit tests. Issues/ pull requests welcome.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-541384867:187,test,tests,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-541384867,1,['test'],['tests']
Testability,"A student of @mbuttner started this, and yes, I believe it's only missing tests. I would probably make a small test case and record the results of the `R` version on there, and use it as a test for this. You can check out the `testing/` directory for tests. . To start, just fetch this branch and you should be able to commit to it directly as a member of theislab github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/823#issuecomment-718863510:74,test,tests,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823#issuecomment-718863510,5,['test'],"['test', 'testing', 'tests']"
Testability,"AFAICT `ubuntu 16.04` is what they use in most of their examples. Considering many of our users will be on academic clusters, I think old-ish versions of linux are reasonable to test against. The alternative would probably be `ubuntu-18.04`, which we should switch to when `16` is out of support. [Here are the options](https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=azure-devops&tabs=yaml#software).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1520#issuecomment-738557948:178,test,test,178,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1520#issuecomment-738557948,1,['test'],['test']
Testability,AILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_ordinal - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_layer - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_view - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_categorical - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants_equivalent - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_plotting.py,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:6581,test,test,6581,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['test'],['test']
Testability,ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68521,test,testing,68521,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.pa,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74587,test,tests,74587,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.pa,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66237,test,testing,66237,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74916,test,testing,74916,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,"About the commit process: That's far far too much work to do it like you suggested. I don't have the time for this. . About the rules: . 1. ""I don't like replacing `x == False` with `not x` in all cases. Sometimes a variable could be a container, and an error should be thrown. I think cases have to be evaluated for this."" . This should be covered by tests. In any case it is not good style and a violation. 2. ""Whats with changing from single letter variables inside expressions? Seems fine to me."". They are redefinitions of earlier variables and trip up flake8. We can call them whatever we want as long it s not `l` again. . 3. ""`lambda's also are generally fine."". See comment at the section. 4. ""Whats up with removing leading `#`s from comments?"" Not my choice either. What we have now is pep8 and flake8 compliant. If you're not happy with this we can ignore the rule. 5. ""So, some of the things you've adding a `# noqa` to look like bugs. I think we need to have a plan in place for doing something about these. Do you have any suggestions?"". The noqa ignore a rule for a specific line. I did not want to ""fix"" these things myself since Python is a dynamic language and you never know what happens :) Ideally we eventually get rid of all noqas, but not in this PR and not by me. I don't know the internals well enough to know whether this could have any side effects.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-785831068:352,test,tests,352,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-785831068,1,['test'],['tests']
Testability,About the preprocessing plots:. `scanpy/tests/notebooks/_images_pbmc3k/filter_genes_dispersion/expected.png`. * Text and some points are shifted slightly. I'm not totally sure whether any points are actually in a different place. `scanpy/tests/notebooks/_images_pbmc3k/highest_expr_genes/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca_variance_ratio/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/scatter_2/expected.png`. * Axis text shifted slightly; * Can probably be reverted if the tests still pass. `scanpy/tests/notebooks/_images_pbmc3k/scatter_1/expected.png`. * y axis moved,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321:40,test,tests,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321,7,['test'],['tests']
Testability,"Actually deploying this is probably blocked by correcting CPU affinities on the benchmarking machine, but writing the code for this should be manageable otherwise.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3013#issuecomment-2275866445:80,benchmark,benchmarking,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013#issuecomment-2275866445,1,['benchmark'],['benchmarking']
Testability,"Actually this broke our tests (you probably missed it because numba broke them before) and has no type annotations. I’d also like to see a few changes, please fix and resubmit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/976#issuecomment-572730320:24,test,tests,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/976#issuecomment-572730320,1,['test'],['tests']
Testability,"Actually, I call bullshit even more:. ```py; class seq_array(np.ndarray):; def __reversed__(self):; return iter(self[::-1]); def index(self, value) -> int:; return np.in1d(self, value).nonzero()[0]; def count(self, value) -> int:; return (self == value).sum(). assert issubclass(seq_array, cabc.Collection); assert issubclass(seq_array, cabc.Reversible); for meth in ""__contains__ __iter__ __reversed__ index count"".split():; assert hasattr(seq_array, meth), meth; print(issubclass(seq_array, cabc.Sequence)); ```. prints `False`. wat.jpg. /edit: Hilarious. Sequence doesn’t implement `__subclasscheck__`, so only things that are `Sequence.register`ed are considered sequences.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/839#issuecomment-531701106:261,assert,assert,261,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839#issuecomment-531701106,3,['assert'],['assert']
Testability,Added PAGA plotting tests and merged.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/806#issuecomment-527687681:20,test,tests,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/806#issuecomment-527687681,1,['test'],['tests']
Testability,Added a quick test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1078#issuecomment-593925534:14,test,test,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1078#issuecomment-593925534,1,['test'],['test']
Testability,"Added tests, too. (Tests fail in my setup, though. RMS is usually around 50-60, rather than 15.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/512#issuecomment-469320886:6,test,tests,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512#issuecomment-469320886,2,"['Test', 'test']","['Tests', 'tests']"
Testability,"Again, everyone has raised fair points. Thank you for the responses. > Should this process be somehow formalized, e.g. a common issue title like [new method] My new method ?. Yes!. > I also disagree about peer-review being a gold standard about legitimacy of the method: I find it a bit unusual in light of the ever-lasting discussion of peer-review flaws in academia, and I personally use non-peer-reviewed computational tools all the time. Peer-review is not the gold standard. As far as I understand, cell ranger has not been peer reviewed and everyone I know uses it. IMO this particular paper could benefit from the process based on the sorts of claims it makes. > it is not strictly a new method, but has several connections with previous sctransform and glm-pca (also, not sure on what basis you said that ""glm-pca is supposed to be better"", would be genuinely curious to see some evaluations). My point here was to say that historically Scanpy hasn't rushed to add _any_ method that is better than log normalization -> PCA. I was using GLM-PCA as a generic example, but I then realized that coincidentally in the GLM-PCA paper they describe a fast analytical approximation using deviance residuals, which is not compared to in the analytical Pearson residuals manuscript (and again highlights the potential role of peer-review IMO). If deviance residuals give a similar latent space, what do you do then? Add both?. > So, my take is: let's get the pearson residuals from @jlause @dkobak in scanpy, and keep pushing to get the others methods in here as well! at the end, this will ultimately benefit greatly the users. Personally this is how I feel -- the more the better! But historically getting a method in the scanpy core is not so easy (even just seeing the back and forth on the linked issue makes it seem like this is the case for this method). This is why I think it's practically important for Scanpy to be very choosy if it's not going to offer multiple competing workflows with reall",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-799542693:1006,log,log,1006,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-799542693,1,['log'],['log']
Testability,"Ah I think I see the issue! Feature branches should be based off `master` and directing the pull request there! I think what's happening is that a pre-commit hook was installed, but the config only exists on the `master` branch. I think this should largely be manageable by rebasing onto master (e.g. `git rebase --onto master 1.7.x`) and changing the branch the PR is targeting via the github interface:. <img width=""300"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/110570131-9093e600-81a9-11eb-9223-5b7bc233d75c.png"">. --------------. Side note: We're considering separating the `highly_variable_genes` interface into multiple functions, since the arguments to the different methods don't always overlap in meaningful or intuitive ways. There's nothing you need to do about this right now, but just a heads up to keep the logic for this method separate from the main function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-794790768:847,log,logic,847,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-794790768,1,['log'],['logic']
Testability,"Ah, it looks like `use_raw` was being set to True, even if `layers` was passed. . https://github.com/theislab/scanpy/blob/c748b3558b38e908f00b16b0c18e2846d3599e5c/scanpy/plotting/_tools/scatterplots.py#L74-L76. Any idea why this didn't trigger this test?. https://github.com/theislab/scanpy/blob/c748b3558b38e908f00b16b0c18e2846d3599e5c/scanpy/tests/test_plotting.py#L294-L298. Edit: I'm guessing vmin.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/730#issuecomment-510467988:249,test,test,249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730#issuecomment-510467988,2,['test'],"['test', 'tests']"
Testability,"Ah, sorry for being in the way here with the unrelated logging changes. Alex is currently a bit ill I learned, which is why he probably didn’t do it yet. I didn’t have time to review the whole thing, but if y’all want I can do that too",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/425#issuecomment-462858876:55,log,logging,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-462858876,1,['log'],['logging']
Testability,"Ah, sorry, maybe this wasn't clear. You need to set the `.raw` attribute of `AnnData` for doing that at some point.; ```; adata.raw = adata # at the point during preprocessing at which you wish store a copy for visualization and differential testing; ```. You can then set `use_raw=False` in several functions, if you want to acess `.X` instead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/168#issuecomment-395589629:242,test,testing,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/168#issuecomment-395589629,1,['test'],['testing']
Testability,"Ah, sorry, that was introduced by a PR quite a while ago; fixed it via https://github.com/theislab/anndata/commit/90bea2c1721d5dbfad20975b14809c63cc126ae8. Added a test that will make sure it doesn't happen again in the future:; https://github.com/theislab/anndata/commit/8737bc2c3fe7946fdab0f6f63f36695e86a4b6a3",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/547#issuecomment-475415786:164,test,test,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/547#issuecomment-475415786,1,['test'],['test']
Testability,"Ah, thank you! This might break some small things, as you replaced an exact search with an approximate neighbor search. It might not affect the tests as this is hard to test. Nonetheless, you're completely right, there shouldn't be two neighbor functions... I'll briefly check the harder cases and see whether I can reproduce some old notebooks. Please remind me if I don't get back to this very soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/245#issuecomment-416728795:144,test,tests,144,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/245#issuecomment-416728795,2,['test'],"['test', 'tests']"
Testability,"Ah, that makes sense. Either way, I don't think the intent of the function was to have the axis bounds determined by how many DE tests were saved.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1335#issuecomment-666158255:129,test,tests,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335#issuecomment-666158255,1,['test'],['tests']
Testability,"Ah, yeah that's what I meant. If I use `setup()`, the tests on the linux server fail. However, the images generated are similar (RMSD < 10) to images made on my MacBook after running `setup()`. On the PAGA notebook, I saw errors like that when I was playing around with the dpi. Maybe fig size or dpi is being changed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-435728828:54,test,tests,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-435728828,1,['test'],['tests']
Testability,"Ahh, I think this is just because of the way I've tried to translate into to the Scanpy workflow. There's a sparsing step [at the start of the basic Scrublet workflow](https://github.com/swolock/scrublet/blob/67f8ecbad14e8e1aa9c89b43dac6638cebe38640/src/scrublet/scrublet.py#L100), but I'm [injecting](https://github.com/theislab/scanpy/blob/76814588696d00183e5f6f02e64f145dbcf944a0/scanpy/external/pp/_scrublet.py#L360) the normalised matrix and effectively skipping that step. I'll PR a sparsing check and conversion (and yes @ivirshup , I'll add a test :-) ), but the workaround is perfectly valid for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1645#issuecomment-788832663:551,test,test,551,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1645#issuecomment-788832663,1,['test'],['test']
Testability,"Ahh... this makes sense. And this makes it a bit dangerous as well. I would generally compute HVGs after batch correction.. and batch correction generally takes log-normalized data, so the data you have before performing this function will be log-normalized most of the time. I assume this is true not just for me. Maybe log=False should be the default? Or at least a warning should be output I feel.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/172#issuecomment-398721208:161,log,log-normalized,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/172#issuecomment-398721208,3,['log'],"['log', 'log-normalized']"
Testability,"All plotting functions should return an ax or an ax list if `show=False`. `_rank_genes_groups_plot` returns whatever the internally called function returns (which could be tracksplot or heatmap etc). However, I don't recall testing this output in all cases. . Can you provide a non working example using the test data? Here you can see how to use one of the test datasets: https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html. I think that @falexwolf can comment on the original reason to set `show=False` to return the axes. . I agree with @Xparx that is more standard to always return the axes as you usually don't dig into the parameter list for this functionality. However, changing this behaviour now could break some code so I don't know if the benefits are greater than the drawbacks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/419#issuecomment-453012463:224,test,testing,224,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419#issuecomment-453012463,3,['test'],"['test', 'testing']"
Testability,"Alright! I've got a little example case I'd probably be using for a test case [here](https://gist.github.com/ivirshup/2a0d9a785339b719e7d372027ae2df31) (doublet prediction by simulation and projection). My current thoughts:. * Since we need to be working in the same feature space, we'll at least need PCA projection, but this is pretty easy:. <details>; <summary> Basic PCA projection </summary>. ```python; def pca_update(tgt, src, inplace=True):; # TODO: Make sure we know the settings (just whether to center?) from src; if not inplace:; tgt = tgt.copy(); if sparse.issparse(tgt.X):; X = tgt.X.toarray(); else:; X = tgt.X.copy(); X -= np.asarray(tgt.X.mean(axis=0)); tgt_pca = np.dot(X, src.varm[""PCs""]); tgt.obsm[""X_pca""] = tgt_pca; return tgt; ```. </details>. * Are you planning on storing the UMAP object in the AnnData? That would make transformation easier, but I see how on-disk representation could get complicated.; * What order should we do this in? Would you like everything to be accomplished by this PR or should we break it up?; * Are we introducing a general transfer learning api? Probably worth considering that a bit. Some relevant questions:; * Does the syntax still work for cases other than 1-to-1 transfer? ; * How do we deal with concatenation/ joins? The current `concatenate` doesn't join things like `obsm`.; * Alternatively, does everything have to be in the same AnnData? It would solve issues with having `var` be the same, but could complicate a lot of other code (many functions would need some kind of masking argument).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-481525842:68,test,test,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-481525842,1,['test'],['test']
Testability,Also @flying-sheep coming back to this - why doesn't this break tests? The underlying number generation mechanism is the same somehow? Or similar enough?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3041#issuecomment-2090759838:64,test,tests,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041#issuecomment-2090759838,1,['test'],['tests']
Testability,Also posted here: https://scanpy.discourse.group/t/sc-tl-rank-genes-groups-specify-groups-and-implementation-for-multiple-tests/328 to try to follow the issue submission guidelines. . Expanded documentation on how to to use ```sc.tl.rank_genes_groups``` in conjunction with ```sc.get.rank_genes_groups_df``` would be much appreciated.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1360#issuecomment-719807138:122,test,tests,122,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1360#issuecomment-719807138,1,['test'],['tests']
Testability,"Also sc.tl.dpt and sc.tl.diffmap functions are not tested in tests, AFAICS.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1118#issuecomment-616759417:51,test,tested,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1118#issuecomment-616759417,2,['test'],"['tested', 'tests']"
Testability,Also there are 2 numerical tests here; https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py; https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups_logreg.py,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1081#issuecomment-595753282:27,test,tests,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1081#issuecomment-595753282,3,['test'],['tests']
Testability,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-733652124:56,test,test,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-733652124,1,['test'],['test']
Testability,"Also, I just found time to read the links you posted @davidsebfischer. Shouldn't we always use a welch t-test instead of a t-test in marker gene detection according to your second stackexchange link? They state that If you don't have a good reason to assume equal variances in the groups, then use the Welch correction... if we have a `group` vs `rest` type of setup as we do in `rank_genes_groups()` at the moment, then we would definitely not expect a single cluster to have an equal variance to the combination of all other cells in other clusters. I think the default is currently `t-test-overestimate-var`... being oblivious to exactly how that works, might it not be better to adapt that to a `welch-t-test-overestimate-var` or something like that @falexwolf?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-449358857:105,test,test,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-449358857,4,['test'],"['test', 'test-overestimate-var']"
Testability,"Also, btw, I like the memory-profiler `mprof` sampling plots a lot for this kind of benchmarking. I took a look at this with this script:. <details>; <summary> `sparse_pca.py` </summary>. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k(); sc.pp.log1p(pbmc). @profile; def implicit_mean_pca():; sc.pp.pca(pbmc, pca_sparse=True). @profile; def explicit_mean_pca():; sc.pp.pca(pbmc). @profile; def nomean_pca():; sc.pp.pca(pbmc, zero_center=False). if __name__ == ""__main__"":; implicit_mean_pca(). nomean_pca(). explicit_mean_pca(). ```. </details>. Run with. ```sh; $ mprof run --interval=0.01 ./sparse_pca.py; ...; $ mprof plot; ```. Shows:. ![pca_mem_benchmark](https://user-images.githubusercontent.com/8238804/75006460-f7266300-54c5-11ea-9378-4fedc2c6d73c.png). So this is looking very good!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589503209:84,benchmark,benchmarking,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-589503209,1,['benchmark'],['benchmarking']
Testability,"Although `adata.uns['log1p'][""base""] = None` seems work for `tl.rank_genes_groups` the results is weird in my analysis. When I check, logfoldchange, values didn't make any sense. Some of them are almost near 100. Is there any case also or maybe I'm wrong.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2239#issuecomment-1338287283:134,log,logfoldchange,134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1338287283,1,['log'],['logfoldchange']
Testability,"An error was raised when values_to_plot=""logfoldchanges"" was provided.; ```python; sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=5,; groupby='leiden_0.1',; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmax=20,; vmin=-20,; key='leiden_0.1_marker_filtered',; show=False; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107458334:41,log,logfoldchanges,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107458334,2,['log'],['logfoldchanges']
Testability,Any idea why `scanpy. logging.print_versions()` is reporting a different version that you've reported above it? . Could be that there's an issue with this environment. Can you replicate the issue in a fresh conda environment?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1872#issuecomment-862230678:22,log,logging,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872#issuecomment-862230678,1,['log'],['logging']
Testability,Any one can help?; All my logFoldChange are NAN.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2338#issuecomment-1274522724:26,log,logFoldChange,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2338#issuecomment-1274522724,1,['log'],['logFoldChange']
Testability,Any update on this? Can you add a test (probably reusing the example already in the method docstring)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/812#issuecomment-537020598:34,test,test,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812#issuecomment-537020598,1,['test'],['test']
Testability,"Apologies for again, the late response @fidel! I married and moved to the US with twin babies last week. And in between, I spilled something over my laptop... Yes, please go ahead and remove redundant code and add further tests. We'll merge this PR eventually. And yes, we can think about a `develop` branch starting from 1.3. What do you say, @flying-sheep?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-418062501:222,test,tests,222,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-418062501,1,['test'],['tests']
Testability,"Apologies for the late response @ivirshup! I married and moved to the US with twin babies last week. And in between, I spilled something over my laptop... I reproduced all the old notebooks. :smile:. PS: As mentioned, things might ""break"" as you replaced something exact with something approximate. The difference becomes pronounced on ""hard datasets"", which are not present in the test of the neighborhood search but only for the ""standard clustering tutorial"", which doesn't use `knn=False`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/245#issuecomment-418072872:382,test,test,382,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/245#issuecomment-418072872,1,['test'],['test']
Testability,"Are the bottom ranked really not expressed, or just not differentially expressed? The former could still have significant p-values. I guess I wonder if you rank by logFC or by adjusted p-value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1529#issuecomment-738210245:164,log,logFC,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529#issuecomment-738210245,1,['log'],['logFC']
Testability,"Are we committing to support sparse-in-dask?. I’m defaulting to `ARRAY_TYPES_SUPPORTED`, which marks sparse as xfail. That’s how we treat other dask-capable utils so far. You can see the errors with. ```console; $ pytest -vv --runxfail scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_{subset_inplace_consistency,no_inplace} -k sparse; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_su",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122:243,test,tests,243,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122,4,['test'],['tests']
Testability,"Arguments for and against converting values in `downsample_counts`:. If we don't convert dtypes back to what they originally were, there's a slight performance boost since we don't have to have two copies. I we return an array of integers we run into trouble downstream with functions that aren't tested with integer arrays. Issues from this have been opened a few times, so when I wrote this I thought it might be worth just maintaining the input type. I'm not sure I agree with that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865#issuecomment-552292197:297,test,tested,297,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865#issuecomment-552292197,1,['test'],['tested']
Testability,"As a quick test, I tried the weighted version of the louvain method and it was able to identify small clusters that are no identified with the non weighted louvain. However, I did not use `knn=False` as this does not work well with the UMAP representation. Still, I could see differences (eg. cluster 6 and 9 in the top figure):. ![image](https://user-images.githubusercontent.com/4964309/44581659-e85ed300-a79e-11e8-8236-cc149e9c17d4.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-415728359:11,test,test,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/240#issuecomment-415728359,1,['test'],['test']
Testability,"As an additional example, I was thinking about using [zebra-stripes (like a camera)](https://en.wikipedia.org/wiki/Zebra_patterning) for showing when information was hidden. Not sure if it's quite there yet, but its something:. <img width=""1318"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/104683802-c2f60980-574b-11eb-9a96-8d65e853739d.png"">. <details>; <summary> Code </summary>. ```python; import datashader as ds; from datashader import transfer_functions as tf. import numpy as np; import pandas as pd; from scipy import sparse; import xarray as xr. import scanpy as sc. def diagonal_bands_like(arr, width=3):; assert arr.ndim == 2; a = np.zeros_like(arr, dtype=bool); step = a.shape[1] + 1; # Not sure why end isn't making a difference; end = None; # end = a.shape[1] * a.shape[1]; fill = True; for i in range(arr.shape[0]):; if (i + width // 2) % width == 0:; fill = not fill; if fill:; a.flat[i:end:step] = True; return a. # Setup; adata = sc.read(""/Users/isaac/data/10x_mouse_13MM_processed.h5ad"", backed=""r""); df = sc.get.obs_df(; adata,; [""Sox17"", ""louvain""],; obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]; ); louvain_colors = dict(; zip(; adata.obs[""louvain""].cat.categories, ; adata.uns[""louvain_colors""]; ); ); pts = (; ds.Canvas(1000, 1000); .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")); ). # Make images; pts_ncats = (pts != 0).sum(axis=2); overlap_idx = pts_ncats == 1; zebra_source = xr.DataArray(; diagonal_bands_like(overlap_idx, 13),; coords=overlap_idx.coords; ). color_by_cluster = tf.shade(pts, color_key=louvain_colors); tf.Images(; color_by_cluster,; tf.stack(; tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),; tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")); ),; tf.stack(; color_by_cluster,; tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")); ),; ); ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show tho",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1263#issuecomment-760657953:639,assert,assert,639,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263#issuecomment-760657953,1,['assert'],['assert']
Testability,"As an intermediate solution, we could. 1. implement https://github.com/scverse/anndata/issues/679; 2. write recarrays as dataframes; 3. make sure tests run successfully on anndata objects where `adata.uns[""rank_genes_groups_filtered""][""names""]` has been converted into a DataFrame",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/61#issuecomment-1874144812:146,test,tests,146,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61#issuecomment-1874144812,1,['test'],['tests']
Testability,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):; """"""; Choose array aligned with obs annotation.; """"""; is_layer = layer is not None; is_raw = use_raw is not False; is_obsm = obsm is not None; is_obsp = obsp is not None; choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)); assert choices_made <= 1; if choices_made == 0:; return adata.X; elif is_layer:; return adata.layers[layer]; elif use_raw:; return adata.raw.X; elif is_obsm:; return adata.obsm[obsm]; elif is_obsp:; return adata.obsp[obsp]; else:; assert False, (; ""That was unexpected. Please report this bug at:\n\n\t""; "" https://github.com/theislab/scanpy/issues""; ); ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/828#issuecomment-560072919:401,assert,assert,401,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828#issuecomment-560072919,2,['assert'],['assert']
Testability,"As far as I can tell, #1527 still doesn't install all packages in a dev installation required to run the entire code base and tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1419#issuecomment-777252906:126,test,tests,126,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1419#issuecomment-777252906,1,['test'],['tests']
Testability,"As in most Python projects, functions that aren’t in the docs are considered private and not for use from different packages. This is therefore a bug in `desc`: eleozzr/desc#13. As a workaround, you can of course assign the function: `scanpy.api.logging.msg = lambda ...: ...`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/895#issuecomment-546839182:246,log,logging,246,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/895#issuecomment-546839182,1,['log'],['logging']
Testability,AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2781,Assert,AssertionError,2781,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Assert'],['AssertionError']
Testability,"At some point we changed the return values of the anndata slicing and that is why I think the check for sparse was needed. My recommendation is to replace this whole block. ```python; for g in _gene_names:; if adata.raw is not None and use_raw:; X_col = adata.raw[:, g].X; if gene_symbols:; g = adata.raw.var[gene_symbols][g]; else:; X_col = adata[:, g].X; if gene_symbols:; g = adata.var[gene_symbols][g]; if issparse(X_col):; X_col = X_col.toarray().flatten(); X_col = X_col.toarray().flatten(); new_gene_names.append(g); df[g] = X_col; ```. by ; ```python; df = sc.get.obs_df(adata, _gene_names, use_raw=use_raw, gene_symbols=gene_symbols; new_gene_names = df.columns; ```. `sc.get.obs_df` is a well tested function and using it makes it easier for maintenance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1669#issuecomment-801174773:703,test,tested,703,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669#issuecomment-801174773,1,['test'],['tested']
Testability,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1332#issuecomment-665719954:203,benchmark,benchmarking,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332#issuecomment-665719954,2,"['benchmark', 'test']","['benchmarking', 'tests']"
Testability,"B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 # 0,11 stalled cycles per insn ( +- 9,57% ) (83,34%); 	 67.830.590.839 branches:u # 1,093 G/sec ( +- 9,58% ) (83,35%); 	 1.702.825.180 branch-misses:u # 4,56% of all branches ( +- 9,56% ) (83,28%); 	; 	 7,1623 +- 0,0560 seconds time elapsed ( +- 0,78% ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:1316,test,test,1316,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266,4,['test'],"['test', 'tests']"
Testability,BTW I have successfully run the distributed tests with this change (`pytest scanpy/tests/test_preprocessing_distributed.py`).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/439#issuecomment-456365133:44,test,tests,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-456365133,2,['test'],['tests']
Testability,"Basically just a test to make sure the underlying issue is actually corrected. In this example:. ```python; adata_sim = scrublet_simulate_doublets(; adata_obs,; layer='raw',; sim_doublet_ratio=sim_doublet_ratio,; synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,; ); ```. `.layer[""raw""]` should contain integer data, which you should be able to reconstruct from the parent cells, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2025#issuecomment-963265836:17,test,test,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2025#issuecomment-963265836,1,['test'],['test']
Testability,"Below is the traceback:. ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[10], line 1; ----> 1 sc.pl.rank_genes_groups_dotplot(; 2 adata,; 3 n_genes=5,; 4 groupby='leiden_0.1',; 5 values_to_plot=""logfoldchanges"",; 6 cmap='bwr',; 7 vmax=20,; 8 vmin=-20,; 9 key='leiden_0.1_marker_filtered',; 10 show=False; 11 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:874](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=873), in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 741 @_doc_params(; 742 params=doc_rank_genes_groups_plot_args,; 743 vals_to_plot=doc_rank_genes_groups_values_to_plot,; (...); 768 **kwds,; 769 ):; 770 """"""\; 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`); 772 ; (...); 872 tl.rank_genes_groups; 873 """"""; --> 874 return _rank_genes_groups_plot(; 875 adata,; 876 plot_type='dotplot',; 877 groups=groups,; 878 n_genes=n_genes,; 879 groupby=groupby,; 880 values_to_plot=values_to_plot,; 881 var_names=var_names,; 882 gene_symbols=gene_symbols,; 883 key=key,; 884 min_logfoldchange=min_logfoldchange,; 885 show=show,; 886 save=save,; 887 return_fig=return_fig,; 888 **kwds,; 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 529 values_df = None; 530 if values_to_plot is not None:; --> 531 values_df = _get_values_to_plot(; 532 adata,; 533 values_to_plot,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107618181:283,log,logfoldchanges,283,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107618181,1,['log'],['logfoldchanges']
Testability,"Benchmark results from my laptop:. | | Parallel | Single |; |-|--------|--------|; | Compilation | ~12s | ~5s |; | Run (3k cells, 37k genes) | ~70ms | ~120ms | ; | Run (50k cells, 35k genes) | ~3.8s | ~8.1s | ; | Run (370k cells, 33k genes) | ~13.7s | ~17.4 s |. So... probably worth it? I recall the difference being more pronounced with larger dataset sizes, but that was with a different numba version and maybe a different machine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/844#issuecomment-534015240:0,Benchmark,Benchmark,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844#issuecomment-534015240,1,['Benchmark'],['Benchmark']
Testability,"Both of these files would need some major clean up, some tests and some documentation, also in notebooks. I'm also happy to merge a pull request adding the new functionality, but I can't do this myself right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/269#issuecomment-426990596:57,test,tests,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/269#issuecomment-426990596,1,['test'],['tests']
Testability,"Btw, I've separated the visium and non-visium case (since they don't share much code), added tests for the visium case, and removed the warnings. I've rebased so I could re-use some test data from another PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-704130199:93,test,tests,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-704130199,2,['test'],"['test', 'tests']"
Testability,Btw. I think scanpy uses Welch's t-test and not the standard t-test. So the comparison with `stats.ttest_ind` is not entirely correct. I guess `stats.ttest_ind` calculates the asymptote of the statistic (`-inf`) and uses that to give a p-value of 0.0.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/620#issuecomment-486585476:35,test,test,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/620#issuecomment-486585476,2,['test'],['test']
Testability,Btw: I plan to release version 0.1 later today. Together with benchmarks and many examples for the 10x datasets. Any objections?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/16#issuecomment-298884393:62,benchmark,benchmarks,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16#issuecomment-298884393,1,['benchmark'],['benchmarks']
Testability,"Bumping pandas up to 2.1.3 actually requires bumping the versions on a number of other dependencies whose current minimums do not work with pandas 2.1.3. ### ufunc equal. Something is happening in a lot of plotting functions with the `equal` ufunc. ### Numba NotImplementedError. During `test_highly_variable_genes_pearson_residuals_general`. ### AnnData private methods used in tests. A lot of private anndata methods are used at test time. But these didn't exist at the time. Not totally sure what the best solution here is. * Vendoring anndata test helpers over here.; * Literally pulling in the file is probably not so bad; * I will investigate to see how many functions are really needed, possible it's just a few one liners (`as_dense_dask_array` is getting hit often); * Make a new package with just the test helpers? Probably too much of a pain. ### ImportError: cannot import name 'check_is_fitted' from 'sklearn.base'. <details>; <summary> Raw test output </summary>. ```python; FAILED scanpy/tests/test_datasets.py::test_krumsiek11 - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/test_datasets.py::test_toggleswitch - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/get/get.py::scanpy.get.get.obs_df; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_right-groups.all] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.on_data-groups.3] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.True-legend.on_right-groups.all] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:1711,test,tests,1711,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"CC @flying-sheep this is an untested as I don't have a windows machine handy to trigger the platform-int-size problem. I'm also somewhat guessing at the fix! From looking at the scanpy source, I don't think that changing the `dtype` of `ns` to a platform consistent and wider `int` will do anything catastrophic to performance or alter the logic in the alg in which it's used as it seems to be a simple index. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1359#issuecomment-670421732:340,log,logic,340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1359#issuecomment-670421732,1,['log'],['logic']
Testability,"Calculating the variance on 32 bit floats, especially in the value ranges you have for counts, will result in a fair bit of inaccuracy. Because of this, we calculate variance with 64 bit values internally. To demonstrate:. ```python; import scanpy as sc, numpy as np; from scanpy.pp._utils import _get_mean_var. pbmc = sc.datasets.pbmc3k(). var_np32 = np.var(pbmc.X.toarray(), axis=0, ddof=1); var_np64 = np.var(pbmc.X.toarray(), axis=0, ddof=1, dtype=np.float64); _, var_scanpy = _get_mean_var(pbmc.X). # These are close; np.testing.assert_allclose(var_np64, var_scanpy). # Same values are different; assert (np.isclose(var_np32, var_np64) == np.isclose(var_np32, var_scanpy)).all(); ```. We don't use the numpy function for variance because then we'd need to create a dense intermediate array. We've previously used `sklearn.utils.sparsefuncs.mean_variance_axis` but that didn't let us control `ddof` or collect to 64 bit values from 32 bit input.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1732#issuecomment-799050440:526,test,testing,526,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732#issuecomment-799050440,2,"['assert', 'test']","['assert', 'testing']"
Testability,"Can rank_genes_groups be linked to use diffxpy on top of the available methods? . I am using the following code to convert the output of rank_genes_groups to a data frame, in case is useful:. ```PYTHON; def rank_genes_groups_df(adata, key='rank_genes_groups'):; # create a data frame with columns from .uns['rank_genes_groups'] (eg. names, ; # logfoldchanges, pvals). ; # Ideally, the list of columns should be consistent between methods; # but 'logreg' does not return logfoldchanges for example. dd = []; groupby = adata.uns['rank_genes_groups']['params']['groupby']; for group in adata.obs[groupby].cat.categories:; cols = []; # inner loop to make data frame by concatenating the columns per group; for col in adata.uns[key].keys():; if col != 'params':; cols.append(pd.DataFrame(adata.uns[key][col][group], columns=[col])); ; df = pd.concat(cols,axis=1); df['group'] = group; dd.append(df). # concatenate the individual group data frames into one long data frame; rgg = pd.concat(dd); rgg['group'] = rgg['group'].astype('category'); return rgg.set_index('group'); ```. This results on a table like this:. ![image](https://user-images.githubusercontent.com/4964309/64006299-5789a880-cb12-11e9-9196-305a318b9395.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/723#issuecomment-526515294:344,log,logfoldchanges,344,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/723#issuecomment-526515294,3,['log'],"['logfoldchanges', 'logreg']"
Testability,Can someone at ICB make the S3 bucket happen and give me the login creds? Then I can merge this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-622393426:61,log,login,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-622393426,1,['log'],['login']
Testability,Can we add a test here to find out (or to at least know) how far our implementation here is from https://github.com/scverse/scanpy/pull/3296 for sparse?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3263#issuecomment-2422635711:13,test,test,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263#issuecomment-2422635711,1,['test'],['test']
Testability,"Can we keep this open until the anndata pr has merged? For instance, I'd like to check this all works after merging #1702. I'm a bit concerned about `scanpy.tests` using stuff from `anndata.tests` while those are being ignored from the `sdist`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1700#issuecomment-788509083:157,test,tests,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1700#issuecomment-788509083,2,['test'],['tests']
Testability,"Can you give me the full code you ran for testing and the results from numpy testing for; `np.testing.assert_array_equal(adata.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""])`; `np.testing.assert_array_equal(adata.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data)`.; The first one should give you an error. The second one shouldn't. How big is your dataset?; Please note that if you use scanpy 1.9.6 that changes of this PR won't have taken effect yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952:42,test,testing,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952,4,['test'],['testing']
Testability,"Can you point to a package whose test organization you would like our tests to emulate?. I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib?. Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863:33,test,test,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863,4,['test'],"['test', 'testing', 'tests']"
Testability,"Can you provide an example that we can test for this?. On Fri, Mar 29, 2019 at 8:37 AM jiawen wang <notifications@github.com>; wrote:. > Dear,; > I used sc.pl.rank_genes_groups_heatmap(adata) to create a heatmap of; > top100 marker genes of 8,000 cells, 4 clusters, but it ran slowly, about 30; > times slowers than seurat's Doheatmap(). Could you modify it to accelerate; > the process ?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/569>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1VPvaV-CHAOc88jcDpj8iSlwQgqUks5vbcK7gaJpZM4cRzgZ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/569#issuecomment-477995981:39,test,test,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/569#issuecomment-477995981,1,['test'],['test']
Testability,Can you run black (https://black.readthedocs.io/en/stable/) on the new files. A test is failing because of this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1432#issuecomment-700582572:80,test,test,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432#issuecomment-700582572,1,['test'],['test']
Testability,Can you share the output of `sc.logging.print_versions()` in the environment that's causing you problems?. I'm unable to reproduce with recent cellranger outputs.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2203#issuecomment-1087572087:32,log,logging,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1087572087,1,['log'],['logging']
Testability,Can you type the command you are using? Or better set up a test case. See the example on #293 maybe you can reproduce your problem with that set up.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/286#issuecomment-429728146:59,test,test,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286#issuecomment-429728146,1,['test'],['test']
Testability,Cancel that @flying-sheep sheep helped me find a way around to test with `pbmc68k_reduced`. This should speed up Travis again.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/824#issuecomment-530432997:63,test,test,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824#issuecomment-530432997,1,['test'],['test']
Testability,"Changing it to a property throws a different error:. <details>; <summary> from make html </summary>. ```sh; reading sources... [ 5%] generated/classes/scanpy.pl.DotPlot ; Exception occurred:; File ""/usr/local/lib/python3.8/site-packages/sphinx/util/docfields.py"", line 369, in transform; new_list += fieldtype.make_field(fieldtypes, self.directive.domain, items,; TypeError: make_field() got an unexpected keyword argument 'inliner'; The full traceback has been saved in /var/folders/bd/43q20k0n6z15tdfzxvd22r7c0000gn/T/sphinx-err-qbzn5se8.log, if you want to report the issue to the developers.; Please also report this if it was a user error, so that a better error message can be provided next time.; A bug report can be filed in the tracker at <https://github.com/sphinx-doc/sphinx/issues>. Thanks!; make: *** [html] Error 2; ```. </details>. <details>; <summary> contents of the referenced log file </summary>. ```python; # Sphinx version: 4.1.0; # Python version: 3.8.10 (CPython); # Docutils version: 0.16 release; # Jinja2 version: 2.11.2; # Last messages:; # reading sources... [ 2%] dev/documentation; # reading sources... [ 2%] dev/external-tools; # reading sources... [ 3%] dev/getting-set-up; # reading sources... [ 3%] dev/index; # reading sources... [ 3%] dev/release; # reading sources... [ 4%] dev/testing; # reading sources... [ 4%] dev/versioning; # reading sources... [ 4%] ecosystem; # reading sources... [ 5%] external; # reading sources... [ 5%] generated/classes/scanpy.pl.DotPlot; # Loaded extensions:; # sphinx.ext.mathjax (4.1.0) from /usr/local/lib/python3.8/site-packages/sphinx/ext/mathjax.py; # sphinxcontrib.applehelp (1.0.2) from /usr/local/lib/python3.8/site-packages/sphinxcontrib/applehelp/__init__.py; # sphinxcontrib.devhelp (1.0.2) from /usr/local/lib/python3.8/site-packages/sphinxcontrib/devhelp/__init__.py; # sphinxcontrib.htmlhelp (2.0.0) from /usr/local/lib/python3.8/site-packages/sphinxcontrib/htmlhelp/__init__.py; # sphinxcontrib.serializinghtml (1.1.5",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1946#issuecomment-877995557:540,log,log,540,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946#issuecomment-877995557,2,['log'],['log']
Testability,Closing due to lack of information. @jsteward2930 please reopen if the problem persists and you can provide us with the logs.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2675#issuecomment-1801420450:120,log,logs,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675#issuecomment-1801420450,1,['log'],['logs']
Testability,"Completely agree, Gökcen!. How I just thought about dealing with this in the past couple of minutes: could we not make a submodule *rtools*? We could show the contained wrapper functions on an extra page of the API. All of the dependencies of this would be optional. In effect, this would be a very shallow wrapper that is only interesting for people who already have a working R installation etc. and use Scanpy along with R packages. As there are quite many of these people, this is definitely meaningful. The code would still look proper. Implementing tests for these wrappers is maybe not so important as these are only shallow interfaces. It would be easier to have this in the main scanpy repository than setting up a `scanpy-contrib`: I imagine less people will like to contribute and take the burden of maintaining another repository. PS: `anndata` is a different story. That's something that is meant to be so basic that it doesn't need a lot of maintenance an contributions. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-381984759:555,test,tests,555,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-381984759,1,['test'],['tests']
Testability,Cool solution! Really cool new logging module! :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/676#issuecomment-499025670:31,log,logging,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499025670,1,['log'],['logging']
Testability,"Cool! . > * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them). I think masking out might be problematic because, `n_genes=adata.n_vars` should return all genes in any case. . > * Revert change (would bring back issue of genes with variance of 0). I feel like using scipy function will slightly increase the maintainability (and simplicity) of the code, so I'm fine with keeping the scipy switch. > * Wrap the t-test with something like `np.errstate` to hide the warning. This sounds good. Replacing weird scipy warning with a proper scanpy warning would also make sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/629#issuecomment-489105754:501,test,test,501,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-489105754,1,['test'],['test']
Testability,"Cool! Can you also try to run the test that fails in the PR please?. Should be `PYTHONPATH=. pytest scanpy/tests/test_plotting.py::test_paga_path`. I have no idea why it does that, as it works for me. If it fails for you, please attach the failed-diff image and the corresponding plot image in a comment here (they’re in `scanpy/tests/figures`)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-586339424:34,test,test,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-586339424,3,['test'],"['test', 'tests']"
Testability,"Could this get a test?. Also, should this be documented somewhere?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1111#issuecomment-629592851:17,test,test,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1111#issuecomment-629592851,1,['test'],['test']
Testability,Could you add a test to make sure the correct values are being used?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2025#issuecomment-959531315:16,test,test,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2025#issuecomment-959531315,1,['test'],['test']
Testability,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096435446:36,test,testing,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096435446,6,['test'],"['test', 'testing']"
Testability,"Current thinking on the test failures: #2129 was fixed upstream in pandas, so is no longer needed. This is needed, but I can't retrigger the builds because Azure is down in Europe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2120#issuecomment-1040372589:24,test,test,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2120#issuecomment-1040372589,1,['test'],['test']
Testability,"Currently there are no tests, so those packages aren't actually needed. Looks good to me!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/361#issuecomment-438352107:23,test,tests,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/361#issuecomment-438352107,1,['test'],['tests']
Testability,"Currently there's an error being raised because the following images in don't match. path: `scanpy/tests/notebooks/_images_paga_paul15_subsampled/paga_path.png`. **Expected**; ![paga_path](https://user-images.githubusercontent.com/8322751/90666060-de033280-e21a-11ea-83f9-684908586f6e.png). **Actual**; ![paga_path](https://user-images.githubusercontent.com/8322751/90666074-e2c7e680-e21a-11ea-9f08-fc495d6762b0.png). **Diff**; ![paga_path-failed-diff](https://user-images.githubusercontent.com/8322751/90666089-e78c9a80-e21a-11ea-9e0c-4e7e6a80d140.png). I'm going to update expected to match actual, but I need some help to see if this is okay",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1382#issuecomment-676542244:99,test,tests,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1382#issuecomment-676542244,1,['test'],['tests']
Testability,"D scanpy/tests/test_plotting.py::test_binary_scatter - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_color_cycler - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_repeated_colors_w_missing_value - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_no_copy - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[list-named] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-named] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_sim.py::test_sim_toggleswitch - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/anndata-min...; FAILED scanpy/tools/_dendrogram.py::scanpy.tools._dendrogram.dendrogram; FAILED scanpy/tests/test_neighbors.py::test_connectivities_euclidean[gauss] - AssertionError: ; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_one_marker_multiple_colors-fn6] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_multiple_markers_multiple_colors-fn7] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_marker_with_dimensio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:51794,test,tests,51794,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,D scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stack,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2616,Assert,AssertionError,2616,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Assert'],['AssertionError']
Testability,DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:26: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:59: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:13902,test,test,13902,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['test'],['test']
Testability,"DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:59: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; 12 warnings and 3 errors generated.; error: command '/usr/bin/clang' failed with exit code 1; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Attempting uninstall: fa2; Found existing installation: fa2 0.3.5; Uninstalling fa2-0.3.5:; Successfully uninstalled fa2-0.3.5; Running setup.py install for fa2 ... error; error: subprocess-exited-with-error; ; × Running setup.py install for fa2 did not run successfully.; │ exit code: 1; ╰─> [212 lines of output]; Installing fa2 package (fastest forceatlas2 python implementation); ; >>>> Cython is installed?; Yes; ; >>>> Starting to install!; ; running install; running build; running ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:16534,test,test,16534,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['test'],['test']
Testability,"DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:59: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; 12 warnings and 3 errors generated.; error: command '/usr/bin/clang' failed with exit code 1; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; WARNING: No metadata found in /Users/test/.local/lib/python3.10/site-packages; Rolling back uninstall of fa2; Moving to /Users/test/.local/lib/python3.10/site-packages/fa2-0.3.5.dist-info/; from /Users/test/.local/lib/python3.10/site-packages/~a2-0.3.5.dist-info; Moving to /Users/test/.local/lib/python3.10/site-packages/fa2/; from /Users/test/.local/lib/python3.10/site-packages/~a2; error: legacy-install-failure. × Encountered error while trying to install package.; ╰─> fa2. note: This is an issue with the package mentioned above, not pip.; hint: See above for output from the failure.; test@mac ~/PythonPackag",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:29734,test,test,29734,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['test'],['test']
Testability,"Damn … it’s going to be hard to find out why the test fails on Travis then, and I don’t feel comfortable not adding a test. Do we have an Amazon web service (AWS) subscription at ICB that we could use to upload failed image tests?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-586596871:49,test,test,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-586596871,3,['test'],"['test', 'tests']"
Testability,"Dear @wangjiawen2013,. what is the interest behind your question? Do you have many datasets with very few cells?; Scanpy itself can easily work with very small datasets, but you should always be aware of statistical limitations when performing statistical tests etc on very few cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1764#issuecomment-815287672:256,test,tests,256,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1764#issuecomment-815287672,1,['test'],['tests']
Testability,"Dear All,; running the tutorial `pbmc3k.ipynb`. I get a similar error than above:; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-ea8d9dc47463> in <module>; ----> 1 sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace); 115 # a normalized disperion of 1; 116 one_gene_per_bin = disp_std_bin.isnull(); --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(); 118 if len(gen_indices) > 0:; 119 logg.msg(. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key); 909 key = check_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:764,log,logg,764,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264,1,['log'],['logg']
Testability,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. ; I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. ; _name_list_ is a string containing gene names and should be specified. ; _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data ; _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/72#issuecomment-361891662:361,test,testing,361,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72#issuecomment-361891662,2,['test'],"['tested', 'testing']"
Testability,"Definitely a heavy dependency, you should see the size of the conda environment you need to test it. I think it'd be useful for playing around with ideas on how you'd like to aggregate and scale the values, since they've already got a bunch of methods implemented. Plus the plots often look pretty good.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/575#issuecomment-479510188:92,test,test,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-479510188,1,['test'],['test']
Testability,"Definitely love to have more contributions! I believe @LuckyMD and @giovp are quite keen on having this in the library. Excited to see your benchmarks!. Side note: I'd definitely recommend looking into using `joblib` instead of `multiprocessing` for parallelization. It's a bit more simple to use, is much better about not oversubscribing your resources, and copying less data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1643#issuecomment-777194405:140,benchmark,benchmarks,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1643#issuecomment-777194405,1,['benchmark'],['benchmarks']
Testability,"DeprecationWarning is silenced by [default](https://python.readthedocs.io/en/stable/library/warnings.html#default-warning-filters), for not annoying users. But I get all when running unit tests with pytest. Here with all warnings enabled:; ```pycon; >>> import warnings; >>> warnings.filterwarnings(""always""); >>> import scanpy as sc; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.pca(adata); >>> sc.pp.neighbors(adata); >>> sc.tl.leiden(adata, flavor=""igraph"", n_iterations=2); …/lib/python3.9/site-packages/scanpy/tools/_leiden.py:185: DeprecationWarning: resolution_parameter keyword argument is deprecated, use resolution=... instead; part = g.community_leiden(**clustering_args); ```. ```shell; $ pip freeze | grep -E ""anndata|scanpy|igraph|python-igraph|leidenalg""; anndata==0.10.7; igraph==0.11.5; leidenalg==0.10.2; python-igraph==0.11.5; scanpy==1.10.1; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2865#issuecomment-2123565254:188,test,tests,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2865#issuecomment-2123565254,1,['test'],['tests']
Testability,"Description of the bug for anyone interested. As @SabrinaRichter and @TyberiusPrime noted, `sc.pp.highly_variable_genes` modified the `layer` used in one case, which is; 1. `sc.pp.log1p(adata, base=b)` with `b != None` has been done (so another log than the default natural logarithm); 2. `sc.highly_variable_genes(adata, flavor='seurat') `has been used (note that flavor='seurat' is the default). (Reproducible) example:. ```py; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_counts=1); sc.pp.log1p(adata, base=10). print('original'); print(adata.X.A[1:6,10:15]). sc.pp.highly_variable_genes(adata, flavor='seurat'); print('after hvg'); print(adata.X.A[1:6,10:15]); ```. Output; ```; original; [[0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.30102998]; [0. 0. 0. 0. 1. ]; [0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.30102998]]; after hvg; [[0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.6931472]; [0. 0. 0. 0. 2.3025851]; [0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.6931472]]; ```. The modification of the data which happened in this case is a rebasing; the data in X is log1p transformed with the natural logarithm, instead of the logarithm previously selected by the user. This is unintended and fixed for the next scanpy version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2668#issuecomment-1768622814:245,log,log,245,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668#issuecomment-1768622814,4,['log'],"['log', 'logarithm']"
Testability,Did anyone run scanpy tests with umap 0.4 branch?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/784#issuecomment-522566850:22,test,tests,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/784#issuecomment-522566850,1,['test'],['tests']
Testability,"Didn’t you rephrase the message?. > scanpy/tests/test_read_10x.py: +3 -1; > ; > This above file has < {thresh} changes to black formatting. Please black format it and afterwards remove it from “tool.black.exclude"" in pyproject.toml. Anyway, it should be “remove it from ‘tool.black.exclude’ *and then* black-format it”, as black won’t run on it if it’s excluded.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/989#issuecomment-577155563:43,test,tests,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/989#issuecomment-577155563,1,['test'],['tests']
Testability,Do you guys still want me to try and run the test from @ilan-gold ? Or is it fine now that it is reproduced on your side as well?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2042430100:45,test,test,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2042430100,1,['test'],['test']
Testability,"Do you mean to add a test for TravisCI (sorry, I'm new to this)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1070#issuecomment-590137345:21,test,test,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1070#issuecomment-590137345,1,['test'],['test']
Testability,"Do your input objects have different `dtype` values in `X`? I suspect that is what's causing this. If so, are the results very different? I would expect normalizing 64 bit vs 32 bit values to not be exactly the same (which is what `np.array_equal` is testing), but it's not good if the function is returning very different values. You can check this with `np.all_close`/ `np.isclose` or by looking at the distribution of the differences of the results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1612#issuecomment-768657586:251,test,testing,251,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1612#issuecomment-768657586,1,['test'],['testing']
Testability,Done! I've changed the random vector generation to use the code you suggested and added a test to test_embedding.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1858#issuecomment-864529782:90,test,test,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858#issuecomment-864529782,1,['test'],['test']
Testability,Done! Tests fixed in 478e3dcb4706328bb3726fb674473e490f353a33,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/162#issuecomment-392000010:6,Test,Tests,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162#issuecomment-392000010,1,['Test'],['Tests']
Testability,"Due to a misconfiguration in Travis setup, all tests are now running only with Python 3.7 now and there is a mysterious HDF error somewhat related to Python 3.7 and pytables.; Python version is fixed in https://github.com/theislab/scanpy/pull/201, so until we have Python 3.7 tests, we are good.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/199#issuecomment-405085782:47,test,tests,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/199#issuecomment-405085782,2,['test'],['tests']
Testability,ED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exc,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49501,test,tests,49501,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - I,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62053,test,tests,62053,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63367,test,tests,63367,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68112,test,tests,68112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"Err, hopefully this isn't inconvenient. Here's a zip file containing the relevant notebook.; [benchmarks_PR1066.zip](https://github.com/theislab/scanpy/files/4234288/benchmarks_PR1066.zip). Benchmarking was done on the raw pbmc3k data. . Summary of the timing and memory results:. With `pca_sparse=False`,; ```; %%memit; t=time.time(); sc.tl.pca(adata1,pca_sparse=False,svd_solver='arpack',random_state=0,zero_center=True); print(str(time.time()-t)+' seconds'); ```; ```; 6.122049570083618 seconds; peak memory: 1332.33 MiB, increment: 1047.04 MiB; ```. With `pca_sparse=True`,; ```; %%memit; t=time.time(); sc.tl.pca(adata2,pca_sparse=True,random_state=0); print(str(time.time()-t)+' seconds'); ```; ```; 2.373802423477173 seconds; peak memory: 401.17 MiB, increment: 56.26 MiB; ```. There are very slight differences between the eigenvalues output by the different methods, which translates to slightly different cluster assignments when using euclidean distance (this is probably exacerbated by the fact that I am benchmarking on raw data). However, for correlation distance, the output is exactly the same. See the attached notebook for more details.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589495486:190,Benchmark,Benchmarking,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-589495486,2,"['Benchmark', 'benchmark']","['Benchmarking', 'benchmarking']"
Testability,Especially weird for since (at least for `scvelo 0.1.25`):. ```python; import scanpy; import scvelo; import anndata; assert scvelo.read_loom == scanpy.read_loom == anndata.read_loom; assert scvelo.read == scanpy.read; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1074#issuecomment-592301994:117,assert,assert,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1074#issuecomment-592301994,2,['assert'],['assert']
Testability,"Even something simple doesn't work anymore, without going through h5ad:. ```; adata = adata[adata.obs['n_genes'] < up_thrsh_genes, :]; Traceback (most recent call last):; File ""/cluster/home/max/projects/czi/cellBrowser/src/cbScanpy"", line 11, in <module>; cellbrowser.cbScanpyCli(); File ""/cluster/home/max/projects/czi/cellBrowser/src/cbPyLib/cellbrowser/cellbrowser.py"", line 4655, in cbScanpyCli; adata, params = cbScanpy(matrixFname, metaFname, inCluster, confFname, figDir, logFname); File ""/cluster/home/max/projects/czi/cellBrowser/src/cbPyLib/cellbrowser/cellbrowser.py"", line 4353, in cbScanpy; adata = adata[adata.obs['n_genes'] < up_thrsh_genes, :]; File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py"", line 1224, in __getitem__; return self._getitem_view(index); File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py"", line 1228, in _getitem_view; return AnnData(self, oidx=oidx, vidx=vidx, asview=True); File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py"", line 557, in __init__; self._init_as_view(X, oidx, vidx); File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py"", line 629, in _init_as_view; self._raw = adata_ref.raw[oidx]; File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py"", line 333, in __getitem__; oidx, vidx = self._normalize_indices(index); File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py"", line 361, in _normalize_indices; obs = _normalize_index(obs, self._adata.obs_names); File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py"", line 160, in _normalize_index; positions = positions[index]; File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/series.py"", line 911, in __getitem__; return self._get_with(key); File ""/cluster/home/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-508526138:480,log,logFname,480,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-508526138,1,['log'],['logFname']
Testability,"Everything runs fine on the current master branch, I uploaded the current version of the notebook: https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/paul15/paul15.ipynb. I'll release either 1.3.3 or 1.4 very soon and if there should have been a bug at some point, it seems to have been fixed at some point. Finally, PAGA is also in the continuous integration tests, so no bugs in the future anymore for this. ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/333#issuecomment-435728872:377,test,tests,377,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333#issuecomment-435728872,1,['test'],['tests']
Testability,"Extracting it would be great. What triggered the test to fail on other branches, I'd assume a matplotlib update?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235#issuecomment-1598724173:49,test,test,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1598724173,1,['test'],['test']
Testability,FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_ordinal - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_layer - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:5572,test,tests,5572,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['test'],['tests']
Testability,FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plot,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48956,test,tests,48956,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"FYI, it appears that this bug remains in louvain version 0.7 ; ```python; In [1]: import numpy as np; ...: import scanpy as sc; ...:; ...: adata = sc.AnnData(np.random.normal(size=(100,3))); ...:; ...: sc.pp.neighbors(adata); ...: sc.tl.louvain(adata); ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-1-3505d1878068> in <module>; 5; 6 sc.pp.neighbors(adata); ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy); 136 partition_kwargs[""weights""] = weights; 137 logg.info(' using the ""louvain"" package of Traag (2017)'); --> 138 louvain.set_rng_seed(random_state); 139 part = louvain.find_partition(; 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__; Out[3]: '0.7.0'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1191#issuecomment-627466608:743,log,logg,743,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191#issuecomment-627466608,1,['log'],['logg']
Testability,Failing test looks similar to what happens when I run out of memory locally: https://dev.azure.com/scverse/scanpy/_build/results?buildId=5329&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=a42f7c48-3122-5ff2-641c-e8a7971de511&l=86. and now this again only on the CI: https://github.com/scverse/scanpy/pull/2815#issuecomment-1894530944,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2815#issuecomment-1903722027:8,test,test,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1903722027,2,"['log', 'test']","['logs', 'test']"
Testability,"Feature selection refers to excluding uninformative genes such as those which exhibit no meaningful biological variation across samples. Since scRNA-Seq experiments usually examine cells within a single tissue, only a small fraction of genes are expected to be informative since many genes are biologically variable only across different tissues (adopted from https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1861-6).; But, in fact some experimental design are very complex, such single-cell RNAseq of tissues from different development stage. The tissues can vary a log along the development timeline.; I find that the number of HVGs can affect data integration and batch effects correction. I've integrated seven cell samples collected at different development stage(1day, 2 day, 3 day, 4day, 5 day, 6 day, 7day after fertilization) with SCVI-tools, using 2000 HVGs, which then shows no ""batch effect"" (cells were mixed with no correlation among samples) left; on the other hand, using all genes, which shows still some extent of ""batch effect"" (some cells were clustered by time obviously) left. This could definitely affect the biological explaination, because the ""batch effect"" can be regarded as the difference of true biological difference at different development stage. The tissues are undergoing intensive differentiation process, so that the cell population are changing a lot during this process. Using only HVGs might lost these development process. ; In sum, HVGs are good for batch effect correction. The ""batch effects"" become less obvious when using less genes and more obvious when using more genes. However, more genes are good for discovery of new cell population. Does this make sense ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1578#issuecomment-764494020:586,log,log,586,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1578#issuecomment-764494020,1,['log'],['log']
Testability,"First step: removed logging of `asctime`, which we never had before: https://github.com/theislab/scanpy/commit/4650568cf61d8a654e64abd1ec0807e19423f1ff",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/684#issuecomment-500209907:20,log,logging,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684#issuecomment-500209907,1,['log'],['logging']
Testability,"Fixed. Also added a couple tests. I didn't change the test mentioned above though, which might be a good thing to do.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/730#issuecomment-510771212:27,test,tests,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730#issuecomment-510771212,2,['test'],"['test', 'tests']"
Testability,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2117664638:6,test,tests,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2117664638,5,"['log', 'test']","['logs', 'tests']"
Testability,"For me is working properly with an earlier version of scanpy and the same matplotlib version. Can you downgrade and test if the problem is only happening in the last version. Also, you can try to see if the problem is related to some matplotlib parameters by resetting them.; ```PYTHON; matplotlib.rcdefaults(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/998#issuecomment-575066688:116,test,test,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/998#issuecomment-575066688,1,['test'],['test']
Testability,"For me, exactly the opposite happens; adding; ```; from matplotlib.testing import setup; setup(); ```; makes almost all tests fail. If I use it from the beginning and produce all test images with it, then, of course, it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-435647914:67,test,testing,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-435647914,3,['test'],"['test', 'testing', 'tests']"
Testability,"For naming, I'd ask @adamgayoso, since he implemented it. I'm also fine with leaving it for now and merging this as is (pending tests passing). > Would be easier if there was a good declarative plot API for python . Have you seen how `seaborn` does it's tests? Not so many pixel comparison ones.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2087#issuecomment-998842552:128,test,tests,128,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2087#issuecomment-998842552,2,['test'],['tests']
Testability,"For the 3k test dataset, introducing edge weights with; ```; import random; random.seed(1234) . adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None); g = sc._utils.get_igraph_from_adjacency(adjacency); clustering = g.community_leiden(objective_function='modularity', weights='weight'); adata.obs['leiden_igraph_edge_weighted'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index); ```; Leads to a more similar clustering to `sc.tl.leiden`. Setting the seed makes all reproducible.; ![image](https://user-images.githubusercontent.com/25825809/154090475-9b5afd35-f254-4c30-92d5-c1a1a86d797d.png). Including igraph edge weights does not seem to impact run times on my larger datasets vs. igraph without weights.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1040389317:11,test,test,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053#issuecomment-1040389317,1,['test'],['test']
Testability,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:; https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1106431960:310,test,tested,310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-1106431960,1,['test'],['tested']
Testability,"Fresh install in a new env gives me the same error (jupyter kernel crashes):; ```; conda create --name squidpy python=3.8 seaborn scikit-learn statsmodels numba pytables; conda activate squidpy; conda install -c conda-forge leidenalg python-igraph; pip install scanpy squidpy imctools stardist; ```; And here's the `sc.logging.print_versions()`:; ```; -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; PIL 8.1.2; anndata 0.7.5; asciitree NA; backcall 0.2.0; cairo 1.20.0; cffi 1.14.5; cmocean 2.0; constants NA; cycler 0.10.0; cython_runtime NA; dask 2021.03.0; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.2; fasteners NA; get_version 2.1; h5py 2.10.0; highs_wrapper NA; igraph 0.8.3; imagecodecs 2020.12.24; imageio 2.9.0; ipykernel 5.5.0; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; networkx 2.5; numba 0.52.0; numcodecs 0.7.3; numexpr 2.7.3; numpy 1.20.1; packaging 20.9; pandas 1.2.3; parso 0.8.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.17; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.1; pyparsing 2.4.7; pytz 2021.1; pywt 1.1.1; scanpy 1.7.1; scipy 1.6.0; seaborn 0.11.1; sinfo 0.3.1; six 1.15.0; skimage 0.18.1; sklearn 0.24.1; squidpy 1.0.0; statsmodels 0.12.2; storemagic NA; tables 3.6.1; texttable 1.6.3; tifffile 2021.3.5; tornado 6.1; traitlets 5.0.5; typing_extensions NA; wcwidth 0.2.5; xarray 0.17.0; yaml 5.4.1; zarr 2.6.1; zmq 22.0.3; -----; IPython 7.21.0; jupyter_client 6.1.11; jupyter_core 4.7.1; notebook 6.2.0; -----; Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]; Linux-3.10.0-1062.1.2.el7.x86_64-x86_64-with-glibc2.10; 72 logical CPU cores, x86_64; -----; Session information updated at 2021-03-12 11:42; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-797629745:319,log,logging,319,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-797629745,2,['log'],"['logging', 'logical']"
Testability,"From the methods of the paper mentioned by @wangjiawen2013:. > our results were not sensitive to the default values of nPC_max. which reinforces my thinking that overshooting the number of PCs isn't a problem for typical clustering and visualization purposes. For interpreting the variable loadings, some selection might be helpful. I'd definitely be interested in having methods like these for use with other latent variable methods. Also that MCV paper's Figure 2b should probably have the APOE axis share a scale, maybe by removing the cell that has ~twice the APOE log expression of any others. I'd be interested in seeing how different the plots look after that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/872#issuecomment-559334707:569,log,log,569,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/872#issuecomment-559334707,1,['log'],['log']
Testability,FuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-100theta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_data-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_data-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mo,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:36166,test,tests,36166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"Getting back to this. I still have the same issue as before. For some reason this does not work on my data. I don't have any `raw` set at all in this data.; ```; sc.tl.rank_genes_groups(adata, 'celltypes', method='t-test'); sc.pl.rank_genes_groups_matrixplot(adata, n_genes=5, cmap='viridis', gene_symbols='Uniq_Name'); ```. ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-41-3b246f8b6bcc> in <module>; ----> 1 sc.pl.rank_genes_groups_matrixplot(adata, n_genes=5, use_raw=False, cmap='viridis', gene_symbols='Uniq_Name'). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_matrixplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds); 823 """"""; 824 ; --> 825 return _rank_genes_groups_plot(; 826 adata,; 827 plot_type='matrixplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds); 448 from .._matrixplot import matrixplot; 449 ; --> 450 _pl = matrixplot(; 451 adata, var_names, groupby, values_df=values_df, return_fig=True, **kwds; 452 ). ~/projects/scanpy/scanpy/plotting/_matrixplot.py in matrixplot(adata, var_names, groupby, use_raw, log, num_categories, figsize, dendrogram, title, cmap, colorbar_title, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, values_df, swap_axes, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 345 """"""; 346 ; --> 347 mp = MatrixPlot(; 348 adata,; 349 var_names,. ~/projects/scanpy/scanpy/plotting/_matrixplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, ax, values_df, vmin, vmax, vcenter, norm, **kwds); 109 **kwds,; 110",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1758#issuecomment-851701172:216,test,test,216,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758#issuecomment-851701172,1,['test'],['test']
Testability,"Goal:. Add `dask` use-cases to the scanpy benchmarks so we can understand performance changes. . Nice links:. 1. Example benchmark: https://github.com/scverse/scanpy/blob/main/benchmarks/benchmarks/preprocessing_counts.py; 2. Project we use for benchmarking: https://asv.readthedocs.io/projects/asv-runner/en/latest/index.html; 3. Dask local cluster: https://distributed.dask.org/en/stable/api.html#cluster; 4. Using scanpy and dask: https://scanpy.readthedocs.io/en/stable/tutorials/experimental/dask.html. NOTE: this `read_elem_as_dask` function in the notebook is with anndata 0.11 i.e., `pip install --pre anndata`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3013#issuecomment-2419644519:42,benchmark,benchmarks,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013#issuecomment-2419644519,5,['benchmark'],"['benchmark', 'benchmarking', 'benchmarks']"
Testability,"Good, yes, in the meanwhile, test coverage should be high enough. I can't think of any major hole anymore. Still, it would be nice to briefly coordinate for Scanpy; at least, still these days. But yes, in this case, please make release 1.3.8!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450#issuecomment-460614412:29,test,test,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460614412,1,['test'],['test']
Testability,Gotcha! I'll prioritize getting the benchmarks up and then I'll need some guidance on how to organize it to fit in scanpy's codebase. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1643#issuecomment-777196655:36,benchmark,benchmarks,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1643#issuecomment-777196655,1,['benchmark'],['benchmarks']
Testability,"Great! Can’t say I understand the #890-related fix though: What went wrong before? Is there a test for it?. Please use 4 space indentation, not visual indentation. Basically, running `black` on the any newly changed code should yield minimal changes. Feel free to remove a file where you changed a lot from here:. https://github.com/theislab/scanpy/blob/b3933ac185f9af3908261e939fc5df2336f1932e/pyproject.toml#L9-L13. Then everything will be done automatically. You’ll just have to go through the changes and fix ugly ones like black making `some = code[:] # comment` into `some = (\n code\n) # comment` instead of `#comment\nsome = code`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/893#issuecomment-546319097:94,test,test,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/893#issuecomment-546319097,1,['test'],['test']
Testability,Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490#issuecomment-727717155:28,test,test,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490#issuecomment-727717155,1,['test'],['test']
Testability,"Great! I'll check it out when I have a chance. If this is close to ready, could it also start getting some tests?. Just to clarify, would a notebook with the pancreas integration stuff be useful to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651#issuecomment-519798857:107,test,tests,107,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-519798857,1,['test'],['tests']
Testability,Great! Will this change the test pics? If not LGTM.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/806#issuecomment-527404432:28,test,test,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/806#issuecomment-527404432,1,['test'],['test']
Testability,Great! so that test succeeded because it was testing the wrong thing?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/494#issuecomment-465918085:15,test,test,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/494#issuecomment-465918085,2,['test'],"['test', 'testing']"
Testability,"Great!. I'll replace the dataset in the tests in that case. > It would be good to have tests that actually hit the parts of neighbors where non-pairwise distances are found (>4096 cells I think). We're just completely migrating to a shallow wrapper of umap there, where this is tested. I talked to Leland and he said it should be stable. At some point, we might move to `pynndescent` (when it get's introduced into umap). Long story short, I don't think we need to test the neighbors module within scanpy beyond testing the interface. > I've been pretty successful at speeding up the tests by just running them in parallel. Stuff like this might be good to have in some dev docs. Is there a place for that kind of thing right now?. No, happy to have you put some dev docs in a location that you find sensible. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/581#issuecomment-479472437:40,test,tests,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479472437,6,['test'],"['test', 'tested', 'testing', 'tests']"
Testability,"Great!. Some tests should fail as there are probably differences in the neighbor algorithm. This is also why this is a backwards-compat breaking change. Can you just visually inspect https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html and see what's going on?. This is another notebook that should still do something meaningful after the change: https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb. And finally, of course, https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html should give somewhat consistent results. But I expect slight variations and no perfect consistence... Actually, I'd expect the associated tests (https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/test_pbmc3k.py) to fail. Can you check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-478373219:13,test,tests,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-478373219,3,['test'],['tests']
Testability,"Great!. Yes, I would have expected that the adjacency matrix will differ slightly and hence, `test_paga_paul15` fails. We'll need to rerun and upload https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html with the new version in that case and also update the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-479420690:271,test,tests,271,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-479420690,1,['test'],['tests']
Testability,"Great, just wanted to make sure that we had that out of the way first. About the tie correction, I'm not the most knowledgeable person about our differential expression testing. Maybe @falexwolf or @a-munoz-rojas would be able to comment on this?. @idavydov, what do you think our results should be? Is there a gold standard in scipy.stats which we should be returning the same results as?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/698#issuecomment-513445670:169,test,testing,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/698#issuecomment-513445670,1,['test'],['testing']
Testability,"Great, thank you for summarizing this so neatly. We could even link from the PBMC3k tutorial to this. Quick answer: yes, there are many situations in which `pp.regress_out` can do more harm than good. In most cases, I personally don't correct for mitochondrial gene expression, for instance. Quite a few people will agree with that. Whether a certain processing step makes sense or not depends on the data. You should choose with subject knowledge. Because, of that, I found it hard to come up with a best practice tutorial; what came into life as Benchmark with Seurat, remained Seurat's way of defining best practice. Many papers stick to this. But I'm sure that also many Seurat users won't always regress out mitochondrial genes and number of counts per cell. I'm sure @LuckyMD has a lot to say on this. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/526#issuecomment-471317931:548,Benchmark,Benchmark,548,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526#issuecomment-471317931,1,['Benchmark'],['Benchmark']
Testability,"Great, thank you! I wasn't completely happy with how Tobias wrote these tests on pickled files - they never actually passed on travis, it's much better that now, they pass! :smile: :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/60#issuecomment-355011043:72,test,tests,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/60#issuecomment-355011043,1,['test'],['tests']
Testability,"Great, thank you, @andrea-tango and @Koncopd!. @andrea-tango, would you make a PR? We can then look at how you solved this. In principle, I'm very hesitant to add `diffxpy` as a dependency of Scanpy. It depends on Tensorflow itself, which is a large dependency. What would be OK would be to have a wrapper in `scanpy.external`, but I don't know whether this makes sense. Why not using `diffxpy`s Volcano plots right away?. Regarding the discrepancy between `wilxocon` in `diffxpy` and `scanpy`. There obviously shouldn't be any and there also shouldn't be duplicated code, here, at all. The only reason that Scanpy has its own Wilcoxon implementation was that there was no implementation available that would scale to large sparse data. That's why @tcallies wrote the present implementation about 1.5 years ago. He benchmarked with scipy's Wilcoxon test. @davidsebfischer, can you shed light on why and how you implemented your Wilcoxon? Shouldn't we have a comparison? At the time, @tcallies wrote [this](https://github.com/theislab/scanpy_usage/blob/master/171106_t-test_wilcoxon_comparison/Generic%20Comparison%20T-Test%20Wilcoxon-Rank-Sum%20Test.ipynb) and these [tests](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py). How did you write your tests?. We were just talking about `log2FC`, which is such a simple quantity and should evidently be properly computed by `rank_genes_groups`. We just had this other PR on it (https://github.com/theislab/scanpy/pull/519). @tcallies, any thoughts from your side?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809:815,benchmark,benchmarked,815,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809,6,"['Test', 'benchmark', 'test']","['Test', 'benchmarked', 'test', 'tests']"
Testability,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. ; What I did : ; - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently); - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf).; How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot); Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1259#issuecomment-992636183:319,log,lognormalize,319,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259#issuecomment-992636183,2,['log'],"['log', 'lognormalize']"
Testability,"Ha, got it! Seems like all tools break differently on multiline strings in the metadata. I changed the string back to single ticks to test that metadata problem and then forgot. Now it works and is tested!. Also I checked and `flit build` seems to be working with `setup.py` existing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-760774086:134,test,test,134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-760774086,2,['test'],"['test', 'tested']"
Testability,"Ha, yeah, the issue number definitely encouraged me to fix it. That's a good idea! I'm not sure I know what the pytest execution model is like, but does it ever start new processes for different tests?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/724#issuecomment-510418413:195,test,tests,195,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/724#issuecomment-510418413,1,['test'],['tests']
Testability,"Had this problem, followed the `scikit-misc` package [issue](https://github.com/has2k1/scikit-misc/issues/12) on a related problem and installed the recommended patch with ; ```; pip install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1""; ```. Seems to work now for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1489019996:202,test,test,202,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1489019996,1,['test'],['test']
Testability,"Haven't tried again but I have a suggestion. Since umap (or pynndescent) is a critical component of scanpy, I think it'd be great to run our tests against both ""stable"" and ""development"" branches of umap. However in order for this to happen, umap needs proper naming for the development and stable branches. Right now, there are master, 0.3dev and 0.4dev, therefore the names are version-dependent. . Does it make sense to file a bug report in umap repo? It'd be a lot easier to run test against two major branches of umap without changing the names in every major release. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/779#issuecomment-524128498:141,test,tests,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779#issuecomment-524128498,2,['test'],"['test', 'tests']"
Testability,"Hej,. I stumbled upon your issue. Test for my PR #1440:. ```; python3 -m venv venv; source venv/bin/activate; pip install -e . ; pip install ""anndata<=0.7.3""; python3 -c ""import scanpy as sc""; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1439#issuecomment-703157510:34,Test,Test,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439#issuecomment-703157510,1,['Test'],['Test']
Testability,"Hello ; I am also facing the same problem.; I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that; ` ; sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'); pd.DataFrame(adata.uns['rank_genes_groups']['names']); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names; df= pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}); df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`; ; Any idea how to get in the single file along with pts??; ; Thanks; Akila",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1455#issuecomment-1164848375:75,log,log,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455#issuecomment-1164848375,3,"['log', 'test']","['log', 'logfoldchanges', 'test']"
Testability,"Hello @Koncopd ,; Thanks for the response!. Step 1: I created a fresh new environment (py3.8.12); ```python; !pip install scanpy[leiden]. Successfully installed anndata-0.7.8 cycler-0.11.0 fonttools-4.28.5 h5py-3.6.0 igraph-0.9.9 joblib-1.1.0 kiwisolver-1.3.2 leidenalg-0.8.8 llvmlite-0.38.0 matplotlib-3.5.1 natsort-8.0.2 networkx-2.6.3 numba-0.55.0 numexpr-2.8.1 numpy-1.21.5 pandas-1.3.5 patsy-0.5.2 pillow-9.0.0 pynndescent-0.5.5 python-igraph-0.9.9 scanpy-1.8.2 scikit-learn-1.0.2 scipy-1.7.3 seaborn-0.11.2 sinfo-0.3.4 statsmodels-0.13.1 stdlib-list-0.8.0 tables-3.7.0 texttable-1.6.4 threadpoolctl-3.0.0 tqdm-4.62.3 umap-learn-0.5.2 xlrd-1.2.0. import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from ma",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:789,log,logging,789,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841,1,['log'],['logging']
Testability,"Hello @LuckyMD ; Thanks for the response!; Could you please also check why the logFC becomes negative and disappear for the marker genes of clusters? https://github.com/theislab/scanpy/issues/2057; Thanks!; Best,; YJ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2110#issuecomment-1013526622:79,log,logFC,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110#issuecomment-1013526622,1,['log'],['logFC']
Testability,"Hello @Zethson ; Thanks for the response.; I read the paper. I understand that using the raw data to calculate the maker genes of clusters is an appropriate way, but the raw data was not regressed out with mitochondrial genes, gene counts, cell cycle scores...So there will be so many mito genes ranked on the top of the marker gene list. What shall we do with these mito genes?. In Seurat, they did every downstream analysis and plotting by using the log-transformed and scaled data (see below, the scaled dots in Seurat violin plot). Scanpy draws all plots by setting `use_raw=True`. I'm wondering which method is better?; ![image](https://user-images.githubusercontent.com/75048821/149460182-c5c11295-ca78-4bfe-aa8b-d13bade4b21f.png). Thanks!; Best,; YJ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2029#issuecomment-1012803791:452,log,log-transformed,452,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2029#issuecomment-1012803791,1,['log'],['log-transformed']
Testability,"Hello, ; I have run this command again in the fresh conda environment. Again I get the same error as before. AttributeError Traceback (most recent call last); c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 194 try:; --> 195 mod_version = _find_version(mod.__version__); 196 except AttributeError:. AttributeError: module 'importlib_metadata' has no attribute '__version__'. During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last); <ipython-input-3-c71c26e11b3b> in <module>; ----> 1 sc.logging.print_versions(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\logging.py in print_versions(file); 159 try:; 160 buf = sys.stdout = io.StringIO(); --> 161 sinfo(dependencies=True); 162 finally:; 163 sys.stdout = stdout. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 196 except AttributeError:; 197 try:; --> 198 mod_version = _find_version(mod.version); 199 except AttributeError:; 200 try:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in _find_version(mod_version_attr); 40 return joined_tuple; 41 elif callable(mod_version_attr):; ---> 42 return mod_version_attr(); 43 else:; 44 # print(f'Does not support module version of type {type(mod_ver_attr)}'). TypeError: version() missing 1 required positional argument: 'distribution_name'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1932#issuecomment-883208028:697,log,logging,697,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932#issuecomment-883208028,2,['log'],['logging']
Testability,"Hello, I get the same error when importing scanpy on 7bridges. ```pytb; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); /tmp/ipykernel_109/912249142.py in <module>; ----> 1 import scanpy as sc. /opt/conda/lib/python3.9/site-packages/scanpy/__init__.py in <module>; 14 from . import tools as tl; 15 from . import preprocessing as pp; ---> 16 from . import plotting as pl; 17 from . import datasets, logging, queries, external, get, metrics, experimental; 18 . /opt/conda/lib/python3.9/site-packages/scanpy/plotting/__init__.py in <module>; 14 from ._preprocessing import filter_genes_dispersion, highly_variable_genes; 15 ; ---> 16 from ._tools.scatterplots import (; 17 embedding,; 18 pca,. /opt/conda/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in <module>; 8 from matplotlib.colors import Normalize; 9 from matplotlib import pyplot as pl; ---> 10 from matplotlib import rcParams, colormaps; 11 from anndata import AnnData; 12 from typing import Union, Optional, List, Sequence, Iterable, Mapping, Literal. ImportError: cannot import name 'colormaps' from 'matplotlib' (/opt/conda/lib/python3.9/site-packages/matplotlib/__init__.py); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1693404137:474,log,logging,474,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1693404137,1,['log'],['logging']
Testability,"Hello,; For information: if I understood correctly, there could be a risk on the current version of `score_genes_cell_cycle` method when the `adata.raw` is present:; - `score_genes_cell_cycle` is based on `score_genes` method which seems to use `adata.raw` to estimate gene score when it is present by default. As far as I know, people often store log-transformed counts to `adata.raw` (an example could be found [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html)).; - However, according to [here](https://nbviewer.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb), ""Log-transformation of data and scaling should always be performed before scoring."". In this situation, when people use `adata.raw` to store logged values, and apply `score_genes_cell_cycle` method to the object without explicitly setting `use_raw = False`, the results could be problematic, unless there is some specific processing overwritting `score_genes`' initial behaviour that I was not aware of.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1599#issuecomment-1465898381:348,log,log-transformed,348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1599#issuecomment-1465898381,3,"['Log', 'log']","['Log-transformation', 'log-transformed', 'logged']"
Testability,"Hello,; I am now facing a problem of failure in computing neighbours when using scanpy or scvelo; when I tried to use the . `sc.pp.neighbors(labelled, n_neighbors=5, n_pcs=4)`; or; `scv.pp.moments(raw, n_pcs=30, n_neighbors=30)`; it will always reports that. ```pytb; `computing neighbors; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 743 try:; --> 744 yield; 745 except NumbaError as e:. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/lowering.py in lower_block(self, block); 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block). ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/lowering.py in lower_inst(self, inst); 327 val = self.lower_assign(ty, inst); --> 328 self.storevar(val, inst.target.name); 329 . ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/lowering.py in storevar(self, value, name); 1277 name=name); -> 1278 raise AssertionError(msg); 1279 . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-37-db298150880d> in <module>; ----> 1 scv.pp.moments(raw, n_pcs=30, n_neighbors=30). ~/.conda/envs/rpy/lib/python3.9/site-packages/scvelo/preprocessing/moments.py in moments(data, n_neighbors, n_pcs, mode, method, use_rep, use_highly_variable, copy); 62 ; 63 if n_neighbors is not None and n_neighbors > get_n_neighs(adata):; ---> 64 neighbors(; 65 adata,; 66 n_neighbors=n_neighbors,. ~/.conda/envs/rpy/lib/python3.9/site-packages/scvelo/preprocessing/neighbors.py in neighbors(adata, n_neighbors, n_pcs, use_rep, use_highly_variable, knn, random_state, method, metric, metric_kwds, num_threads, copy); 161 warnings.simplefilter(""ignore""); 162 neighbors = Neighbors(adata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796:367,Assert,AssertionError,367,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796,1,['Assert'],['AssertionError']
Testability,"Hello,; This command (sc.logging.print_versions()) gives me the error pasted below:; AttributeError Traceback (most recent call last); c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 194 try:; --> 195 mod_version = _find_version(mod.__version__); 196 except AttributeError:. AttributeError: module 'importlib_metadata' has no attribute '__version__'. During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last); <ipython-input-19-c71c26e11b3b> in <module>; ----> 1 sc.logging.print_versions(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\logging.py in print_versions(file); 159 try:; 160 buf = sys.stdout = io.StringIO(); --> 161 sinfo(dependencies=True); 162 finally:; 163 sys.stdout = stdout. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 196 except AttributeError:; 197 try:; --> 198 mod_version = _find_version(mod.version); 199 except AttributeError:; 200 try:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in _find_version(mod_version_attr); 40 return joined_tuple; 41 elif callable(mod_version_attr):; ---> 42 return mod_version_attr(); 43 else:; 44 # print(f'Does not support module version of type {type(mod_ver_attr)}'). TypeError: version() missing 1 required positional argument: 'distribution_name'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1932#issuecomment-874660246:25,log,logging,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932#issuecomment-874660246,3,['log'],['logging']
Testability,Hello. Sorry I have been silent but I haven't used scanpy for a few months and thought there was nothing more for me to do with this pull request. @Koncopd: the commit I made in September last year (e4483e9) triggered the CI and passed the tests. Is there something further you need me to do?. Thanks.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1413#issuecomment-846628296:240,test,tests,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1413#issuecomment-846628296,1,['test'],['tests']
Testability,"Here are some updates:; - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors!; - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1138619110:711,test,tested,711,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-1138619110,1,['test'],['tested']
Testability,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb; Initial shape: 737280x28002; After min_genes: 5128x28002; After max_genes: 1431x28002; Traceback (most recent call last):; File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>; sc.pp.filter_genes(adata, min_cells=3); File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes; adata.var['n_cells'] = number; File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__; self._set_item(key, value); File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item; value = self._sanitize_column(key, value); File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column; value = _sanitize_index(value, self.index, copy=False); File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index; raise ValueError('Length of values does not match length of ' 'index'); ValueError: Length of values does not match length of index; ```. Note that this same error displays on both of the following lines:. ```python; sc.pp.filter_genes(adata, min_cells=3); sc.pp.filter_genes(adata, max_cells=1000); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364468317:8,test,test,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364468317,1,['test'],['test']
Testability,"Here's a demo implementation using `python-graphblas` for `max`:; Setup:. ```python; from scipy import sparse; import numpy as np. N_OBS, N_VAR = 2_000, 10_000; N_CLASSES = N_VAR - int(N_VAR / 1000); rng = np.random.default_rng(0). X = sparse.random(N_OBS, N_VAR, density=0.01, format=""csr"", random_state=rng); var_labels = np.concatenate([np.arange(N_CLASSES), rng.choice(N_CLASSES, size=N_VAR - N_CLASSES)]); ```. Implementation:. ```python; import graphblas as gb; from sklearn.preprocessing import label_binarize. var_labels_mtx = label_binarize(var_labels, classes=np.arange(N_CLASSES), sparse_output=True). result = gb.io.to_scipy_sparse(; gb.semiring.max_times(; gb.io.from_scipy_sparse(X) @ gb.io.from_scipy_sparse(var_labels_mtx); ).new(); ); ```. <details>; <summary> Test </summary>. ```python; import numpy_groupies as npg. npg_result = npg.aggregate(var_labels, X.toarray(), func=""max"", axis=1). np.testing.assert_array_equal(npg_result, result.toarray()); ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2898#issuecomment-1981863739:778,Test,Test,778,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2898#issuecomment-1981863739,2,"['Test', 'test']","['Test', 'testing']"
Testability,"Here's some initial distribution plots for comparison:. Legend: ; - red lines are 0.5% and 99.5% quantiles, a trick used in some cytof papers to deal with extreme outliers (believed to be technical artifacts); here, I simply use it to move the bulk of the data in visible range for the first two plots; while the values are merely a heuristic, the spirit of it follows nonparametric statistics so is pretty reliable in practice. ### raw (ADT counts):; ![image](https://user-images.githubusercontent.com/20694664/83345454-4956fb80-a2e1-11ea-8ae7-e13dfcc10cac.png). ### geometric mean (as used in Issac's notebook); ![image](https://user-images.githubusercontent.com/20694664/83345468-6f7c9b80-a2e1-11ea-8a42-acad50bfb66b.png). seems to only changes the scale, not the shape, so unless I made an error in implementation... it's probably not useful. ### simple log(n+1) (as used in RNAseq); ![image](https://user-images.githubusercontent.com/20694664/83345487-a05cd080-a2e1-11ea-858e-4d98621d12e6.png). can suffer from discretization at low values... note: even though Seurat/Scanpy/Loupe all use different bases, the log base doesn't really matter; it just changes the scale, not the shape/distinguishing power. ### hyperbolic arcsin (as used in CyTOF); ![image](https://user-images.githubusercontent.com/20694664/83345476-81f6d500-a2e1-11ea-8f68-ddff22ffe853.png). not as noisy as log at low values, and doesn't assert that zeros have to be Laplace smoothed with a pseudocount of +1. ### biexponential family (as used in flow cytometry); ![image](https://user-images.githubusercontent.com/20694664/83345554-6fc96680-a2e2-11ea-8112-3bdc09260e63.png). best smoothing so far in the low counts, because that's what it was designed to do. in this case, it is the newest of this family: `vlog(alpha=0, beta=12, xmax=70000, zmax=1)`; - https://doi.org/10.1002/cyto.a.23017; - https://doi.org/10.1002/cyto.a.22030; - https://doi.org/10.1002/cyto.a.20258. ### centered log ratio (as used in CITEseq paper); ![im",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-636429530:858,log,log,858,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117#issuecomment-636429530,1,['log'],['log']
Testability,"Here's the test I ran for commit 82e3a59b5905. ```python; import scanpy as sc; import numpy as np. pbmc = sc.datasets.pbmc3k(); pbmc.X = pbmc.X.astype(np.float64); sc.pp.log1p(pbmc). implicit = sc.pp.pca(pbmc, pca_sparse=True, dtype=np.float64, copy=True); explicit = sc.pp.pca(pbmc, pca_sparse=False, dtype=np.float64, copy=True). assert not np.allclose(implicit.uns[""pca""][""variance""], explicit.uns[""pca""][""variance""]); assert not np.allclose(implicit.uns[""pca""][""variance_ratio""], explicit.uns[""pca""][""variance_ratio""]); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-593746949:11,test,test,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-593746949,3,"['assert', 'test']","['assert', 'test']"
Testability,"Hey @LouisFaure,. During the Hackathlon last week we talked again about this PR. For the time being we will keep GPU computing functionality out of scanpy and in rapids-singlecell. RSC is now tested with a CI solution. If you want to contribute to rapids-singlecell I would be very happy. Missing functions like Umap and Neighbors are currently getting updated and also ported to RSC.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1671325998:192,test,tested,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-1671325998,1,['test'],['tested']
Testability,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this!. However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values.; ```; log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2); ```; In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. ; ```; log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))); ```; Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-471321720:192,log,log,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471321720,6,"['log', 'test']","['log', 'tests']"
Testability,"Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion!. To me, this looks pretty close to ready. Just a few things to address:. * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this.; * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns?; * Any thoughts on solutions for the name collision?. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/503#issuecomment-520200213:195,test,test,195,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503#issuecomment-520200213,1,['test'],['test']
Testability,"Hey @chris-rands,. This is a really interesting topic. Sorry in advance for the wordy reply... You are absolutely correct that log transformation removes the perfect comparison of relative expression values that mean normalization provides. Aside from CPM normalization (as provided by `sc.pp.normalize_total()`) not being a good normalization technique anyway (this is argued by any more advanced normalization methods paper, e.g., the [scran pooling paper](http://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0947-7)), there are a couple of things to consider here:; 1. Do we even want relative expression counts?; 2. What assumptions do downstream methods have on the distribution of expression values. For the first question: relative gene expression values ignore differences in cell sizes/number of molecules in the cell. There are some molecules whose numbers scale with the size of the cell, and others that don't (e.g., many housekeeping genes). Choosing relative over absolute expression values to compare gene expression across cells would be helpful to compare expression of those genes that scale with size, but not the others.... so there's not really a perfect answer here. Thus, removing all effects of total counts may not be the desirable outcome. Secondly, many downstream methods assume normally distributed expression data (e.g., DE methods like: t-tests, limma, MAST, or several batch correction/data integration methods). Log transformation is used as a variance stabilization to approximate a normal distribution (quite often poorly, but better than without). This leads to many methods performing better with log transformation. IMO, the ideal approach is probably something like scVI, GLMPCA, or scTransform, where you fit a model directly to the count data and use the residuals to describe the data. This would address both steps of normalization and variance stabilization at the same time. If we have a good model to describe the data, the residuals should",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643:127,log,log,127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643,1,['log'],['log']
Testability,"Hey @esrice, thanks for the PR! Those tests are failing due to a recent umap release. This should be fixed on master now, so just merge master into this branch and they should be fixed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027#issuecomment-959614946:38,test,tests,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027#issuecomment-959614946,1,['test'],['tests']
Testability,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. ; I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-474084027:358,test,testing,358,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-474084027,1,['test'],['testing']
Testability,"Hey @giovp !. Thanks for your review and sorry for the delay, but I think I addressed all requests now:; - code moved to experimental; - fixed broken column ordering when batch argument was used with HVG selection; - tests adapted to the new code location. I was not sure how the `highly_variable_genes()` should look like in its experimental version. For now, I removed everything that is not related Pearson residuals, including input arguments and docstring. I also left a note in non-experimental `highly_variable_genes()`'s docstring that mentions the experimental version with the additional Pearson flavor. Feel free to remove again if you don't like it. Regarding the tutorial: Sure, that would be nice! I can prepare a short demo notebook. Do you think we could start with a rather concise notebook now to package it with the initial release in `experimental` (basically demonstrating how to use it on some example data, and some theory/background info how it works / why it makes sense), and then prepare a longer later on? Then I'd just open a pull request (?) in your tutorial-github for that?. Let me know if there is more to do here :). Cheers, Jan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-879988467:217,test,tests,217,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-879988467,1,['test'],['tests']
Testability,"Hey @giovp @LuckyMD @ivirshup @adamgayoso @dkobak !. I just finished writing a set of tests for all four functions I currently have implemented! I also made some minor changes to the original code of the PR because (as probably intended by tests in general ;)) I found some inconsistencies when developing the tests. For the tests, I tried to test all input arguments and outputs. Only exception was when a bundle function (e.g. `sc.pp.recipe_pearson_residuals`) passes on an argument directly to a lower level function (e.g. `sc.pp.pca`) that has its own tests. But of course, also here, one could include extra tests. Looking forward to your feedback here, as this is my first time writing a larger set of tests. I will be on vacation until June 27th, but after that I can prioritize working on your suggestions for this! Thanks in advance :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-859688292:86,test,tests,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-859688292,8,['test'],"['test', 'tests']"
Testability,"Hey @gokceneraslan,. I'm surprised at how you describe the contents of `adata.var['highly_variable']` when `batch_key` is set. I wrote a function that does pretty much exactly the same thing building upon use of `batch_key` for our data integration benchmarking, as I thought this wasn't available in scanpy. I recall looking through the code and thinking this was missing. Maybe we can compare functions for that to see if we're doing exactly the same thing or not?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032#issuecomment-616820714:249,benchmark,benchmarking,249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032#issuecomment-616820714,1,['benchmark'],['benchmarking']
Testability,"Hey @ivirshup,. thank you for your reply. I was not aware of that issue, but yes, this PR should solve it. I did not know where and how exactly you would prefer the test to be. So for now I put it in test_pca.py and I run a full pca on the pbmc3k data. This might of course be a bit much. Shall I provide and/or use some even smaller sample data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2179#issuecomment-1074432061:165,test,test,165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1074432061,1,['test'],['test']
Testability,"Hey @ivirshup,; below is the output after making a small test edit to `_highly_variable_genes.py` and trying to commit.; Could it be that the file has not been style-checked so far (or not on the branch/version I was forking from?), leading to all these automatic changes/style violations in the old part of the code?. hope this helps, let me know if you need anything else. <details>; <summary> </summary>. ```; jlause@8b38045532aa:~/libs/scanpy/scanpy/preprocessing$ git commit -m ""test commit""; black....................................................................Failed; - hook id: black; - files were modified by this hook. reformatted scanpy/preprocessing/_highly_variable_genes.py; All done! ✨ 🍰 ✨; 1 file reformatted. flake8...................................................................Failed; - hook id: flake8; - exit code: 1. scanpy/preprocessing/_highly_variable_genes.py:33:80: E501 line too long (84 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:37:80: E501 line too long (81 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:49:80: E501 line too long (102 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:51:80: E501 line too long (89 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:108:80: E501 line too long (82 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:123:80: E501 line too long (83 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:204:27: W291 trailing whitespace; scanpy/preprocessing/_highly_variable_genes.py:219:5: F821 undefined name 'view_to_actual'; scanpy/preprocessing/_highly_variable_genes.py:220:9: F821 undefined name '_get_obs_rep'; scanpy/preprocessing/_highly_variable_genes.py:244:80: E501 line too long (85 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:257:80: E501 line too long (85 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:282:80: E501 line too long (88 > 79 characters); scanpy/preprocessing/_highly_va",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-794148562:57,test,test,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-794148562,2,['test'],['test']
Testability,"Hey @ywen1407!. The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1431#issuecomment-698818414:1115,test,tested,1115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431#issuecomment-698818414,1,['test'],['tested']
Testability,"Hey Simon,. Thanks for your suggestions. I agree that 1 would be very useful indeed and would be worth implementing.. this is not in the making yet is it @ivirshup ?; As to point 2, this would statistically be difficult as you're comparing a group to itself, which I think should not be done when testing differences between two groups.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2317#issuecomment-1257063310:297,test,testing,297,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317#issuecomment-1257063310,1,['test'],['testing']
Testability,"Hey again,. I addressed many of @ivirshup's comments by now and think I am almost done - will finish up the rest next week if all goes well. What is left todo:; - [ ] Make tests faster (re-use results where possible); - [ ] Make tests more code-efficient by code-sharing between functions where possible. Where I could use your / @giovp's input to continue:; - on the keyword/positional argument issue; - on the the ""is median rank a good way to do HVG selection across batches""-issue; - on the question what the final names of the functions should be - your suggestions were:; > `normalize_pearson_residuals` -> `pearson_residuals`; > It's a bit more like log1p; >; > `sc.experimental.pp.highly_variable_genes` -> something else; > I think using an already used function name (highly_variable_genes) and giving it a different API can be confusing. Would calling this pearson_deviant_genes or something like that be better? I do generally dislike how many methods highly_variable_genes wraps already though. Looking forward to the last bits :) ; Cheers, Jan. PS: I'm sorry for the problems that my dirty force-pushing caused before, I hope now everything works fine! I was not aware of the consequences for the comment history back then, but will now take care not to do it again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-902985395:172,test,tests,172,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-902985395,2,['test'],['tests']
Testability,"Hey all!; Sorry for the delay, I finally went over the comments of @ivirshup. Thanks again for the feedback! I think I could address everything, except:. - the issue of how exactly we should select HVGs with simple batch correction. @adamgayoso and @gokceneraslan (and maybe @dkobak ?) might have an opinion here as well. See [thread](https://github.com/theislab/scanpy/pull/1715#discussion_r774980182).; - how to best cache raw data to save time while testing. I proposed a solution but not sure if it is a good-style solution, maybe have another look! See [thread](https://github.com/theislab/scanpy/pull/1715/#discussion_r774915501). Btw, I've also posted a tutorial for PRs a while back (https://github.com/theislab/scanpy-tutorials/pull/43) - any comments to that?. Hope you enjoy your Christmas holidays!; Best,; Jan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1000800467:453,test,testing,453,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1000800467,1,['test'],['testing']
Testability,"Hey everyone, thanks for the discussion so far! I don't have much to add to what @dkobak said earlier, so let me summarize a bit from my perspective:. I am motivated to contribute the method here because people were interested to use it with scanpy after seeing the preprint, and scanpy devs reached out to us to implement it here. For that it does not matter if it ends up in `external` or `core`, but as @giovp mentioned, the code is easy to integrate into the existing normalize/hvg-selection workflow and the method itself is well connected to established workflows. @adamgayoso raised the question if new preprint methods should be allowed in `core` at all, had several suggestions how this PR could be handled (halt until peer review publication/put in `external` for now/extend method to support also e.g. deviance residuals and others), and some open questions about the exact workflow integration. I would like to clarify with everyone how to proceed now. @ivirshup @LuckyMD, could you help us a bit to decide how to move forward?. In terms of development, I answered all of your code review comments @giovp, so maybe you can briefly check & resolve those you are happy with..?! I am also ready to finally write tests once we are decided on where this PR is going.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-801883490:1221,test,tests,1221,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-801883490,1,['test'],['tests']
Testability,"Hey everyone, thanks for your feedback! In the latest commit, I have tried to include all of your comments, including the more stylistic comments, the references, the numba integration, the unit tests and so on. Have a look and see what you think. I won't be able to work on this any more this year because I am going on holidays. Merry Christmas everyone!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/398#issuecomment-448304646:195,test,tests,195,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-448304646,1,['test'],['tests']
Testability,"Hey guys @LuckyMD, @Koncopd, @falexwolf, @flying-sheep. I think this feature would be very useful to have in Scanpy, but this PR has been sort of forgotten. . I would be up to take care of this, but it would be my first contribution and I'd like some advice on how to move forward on this. I take it the main issue with the PR is the missing test for the scran normalization, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/823#issuecomment-718745640:342,test,test,342,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823#issuecomment-718745640,1,['test'],['test']
Testability,"Hey! Check out [scCoda](https://github.com/theislab/scCODA) for a differential abundance testing framework in python that is anndata compatible. As statistics are calculated on the sample level, you would however need more than 2 samples to be able to assess significance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1831#issuecomment-845926484:89,test,testing,89,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831#issuecomment-845926484,1,['test'],['testing']
Testability,"Hey!. Just something that crossed my mind... could it be that after subsetting, you have 0 variance in some genes? You may have to rerun `sc.pp.filter_genes()` to take out genes that are 0 everywhere after subsetting. This would give you an `NaN` in the testing. Maybe check that the genes you filter out are the ones that gave you the issues in the initial run.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/653#issuecomment-494316752:254,test,testing,254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494316752,1,['test'],['testing']
Testability,"Hey!. Logistic regression currently doesn’t output p-values i believe. Either way, it also treats genes as independent variables, so no need for subsetting here either. As for your second question, you may have misunderstood my answer. `sc.tl.rank_genes_groups()` gives you marker genes just as MAST or diffxpy do (but with more complex models that can incorporate covariates). I was just commenting on the interpretation of marker genes. They tell you which genes characterize a cluster, but don’t necessary tell you which genes contributed most to the global split of clusters that was generated (which i thought you were asking about). That type of question would require a feature importance metric on a multiclass classification problem. For example training a random forest to predict the clusters and then using gini importance to rank the features. That is not a common question asked of single-cell data though, so there’s no tool i’m familiar with that does this. I hope that is clearer.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/748#issuecomment-515168347:6,Log,Logistic,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748#issuecomment-515168347,1,['Log'],['Logistic']
Testability,"Hey, just as a quick summary of how things stand from my view:. ; - [x] Make tests faster (re-use results where possible); - [x] Make tests more code-efficient by code-sharing between functions where possible. Both done, hopefully enough to address @ivirshup 's comments :) Now both tests take less than 20secs (which is a lot shorter than before). These issues are still up for discussion/here I need your input to finish up:. - the keyword/positional argument issue (see [this](https://github.com/theislab/scanpy/pull/1715#discussion_r687448287) code comment) -- here @giovp also mentioned that he could fix it?; - the ""is median rank a good way to do HVG selection across batches""-issue (see [this](https://github.com/theislab/scanpy/pull/1715#discussion_r687465687) code comment); - the question what the final names of the functions should be (see @ivirshup's [last post](https://github.com/theislab/scanpy/pull/1715#pullrequestreview-728217616)); - add an option for fast-lane feature selection? (see my [last post](https://github.com/theislab/scanpy/pull/1715#issuecomment-903315698)); - docs consistency (see @ivirshup's [last post](https://github.com/theislab/scanpy/pull/1715#pullrequestreview-728217616)); - [failing tests](https://github.com/theislab/scanpy/pull/1715#issuecomment-902986463) - I hope I did not break anything here, but I don't really understand how the problems in `scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k` could be caused by changes in my code?!. I'll be off for vacation until Thursday and can respond to any feedback after that - looking forward!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-907829207:77,test,tests,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-907829207,5,['test'],['tests']
Testability,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account; * Set up containers; * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-815455859:163,test,test,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-815455859,1,['test'],['test']
Testability,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. ; [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf); [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-475983631:225,log,log,225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-475983631,2,['log'],"['log', 'log-mean']"
Testability,"Hey, thanks for your reply!. I looked a bit around, and here is what the Seurat 3.1.4 docs say:. > Choose the features to use when integrating multiple datasets. This function ranks features by the number of datasets they appear in, breaking ties by the median rank across datasets. It returns the highest features by this ranking. from https://www.rdocumentation.org/packages/Seurat/versions/3.1.4/topics/SelectIntegrationFeatures. From this, I'd conclude that the current docs are correct, but in the sorting order of `_highly_variable_genes_seurat_v3` has it the wrong way around. Also, the test for the `_highly_variable_genes_seurat_v3()` method seems to assume that the method sorts the other way around than it currently does:. From within the method:. https://github.com/theislab/scanpy/blob/ca07fc12bbcd87e4cf67da56f52525a1e519711b/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. From the test:. https://github.com/theislab/scanpy/blob/ca07fc12bbcd87e4cf67da56f52525a1e519711b/scanpy/tests/test_highly_variable_genes.py#L138-L151. So from this it seems save to say that the sorting order should be reversed in `_highly_variable_genes_seurat_v3()`..?!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1733#issuecomment-802052402:594,test,test,594,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733#issuecomment-802052402,3,['test'],"['test', 'tests']"
Testability,"Hey,; So I don't understand how I can get around this issue with the wilcoxon test. I'm following the scanpy tutorial and getting this 'ValueError: math domain error'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/566#issuecomment-582366998:78,test,test,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566#issuecomment-582366998,1,['test'],['test']
Testability,"Hi @JayalalKJ ,; as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial; It's best if you open an issue there and directly address maintainers of that repo. ; Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo.; Hope this is helpful",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1220#issuecomment-702550857:437,log,log,437,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220#issuecomment-702550857,1,['log'],['log']
Testability,"Hi @Koncopd ,. The error fixed here [df8bbaf](https://github.com/theislab/scanpy/pull/1248/commits/df8bbaf5ffb58eb37d4b80ef62819f69b8fce023). Thank you!. > Hi, @awnimo , sorry for the delay.; > It seems that this PR breaks test_harmony_timeseries.py. I get; > ; > ```; > E ValueError: 'time_points' column does not contain Categorical data; > ; > ../../external/tl/_harmony_timeseries.py:140: ValueError; > ```; > ; > On master the test works fine.; > Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1248#issuecomment-703754388:432,test,test,432,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248#issuecomment-703754388,1,['test'],['test']
Testability,"Hi @LuckyMD - thanks for your reply! Yeah that makes sense. I'm performing these corrections using a subset of highly variable genes, so I guess to ""make up"" for the loss of ""true"" HVGs in the new subclusters of cells I could select a higher number of HVGs to perform the original alignment? As well as maybe using a larger number of components for downstream applications from the low-dimensional embedding outputted by the original alignment. Does that make sense to you?. One more question - when performing differential gene expression analysis, what is your preferred pipeline/method when using aligned datasets? I generally do not perform the correction on the gene expression matrix when aligning, and I think doing DE with corrected matrices is not as common. So maybe other methods that use batch as a covariate would be preferable (e.g. diffxpy or others?) Would really appreciate any suggestions here!. PS. many congratulations on the benchmarking integration paper in Nature Methods - excellent work and very useful resource for the field!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766:946,benchmark,benchmarking,946,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766,1,['benchmark'],['benchmarking']
Testability,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```; adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X; ```; It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ ; Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/510#issuecomment-488001552:883,log,log-normalization,883,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-488001552,1,['log'],['log-normalization']
Testability,"Hi @Pawan291, It seems `louvain` has not been properly installed in your environment. Could you post the output of `scanpy.logging.print_versions()` as suggested in the template? You should just need to `pip install louvain`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1566#issuecomment-753946626:123,log,logging,123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1566#issuecomment-753946626,1,['log'],['logging']
Testability,"Hi @Pawan291,; It looks like your `adata.var_names` do not contain the cell cycle genes you are testing for. Is your dataset human or mouse?. Could you just print `adata.var_names[:10]`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1599#issuecomment-762792128:96,test,testing,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1599#issuecomment-762792128,1,['test'],['testing']
Testability,"Hi @PedroRaposo, unfortunately not. My colleague told me that this issue could be related to the versions of scanpy, anndata or loompy. I have the same scanpy version with the successful test above. Maybe, it is related to loompy and anndata version but I'm not sure...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-493118269:187,test,test,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-493118269,1,['test'],['test']
Testability,"Hi @ThomasThaewel,; In the current best-practices paper the recommendation is to use ""measured data"" as input for marker gene detection. This includes both raw, normalized, and log-normalized data formats. If you are using a count modelling approach for differential expression analysis (e.g., negative binomial, poisson), then you should use raw data (not-normalized) and include size factors in the model. For non-parametric approaches like the ones implemented in `sc.tl.rank_genes_groups()` log-normalized data is better. Hope that clarifies things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2180#issuecomment-1073786068:177,log,log-normalized,177,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180#issuecomment-1073786068,2,['log'],['log-normalized']
Testability,"Hi @Zethson I am the creator of Cirun.io, ""GPU"" and ""CI"" caught my eye. FWIW I'll share my two cents. I created a service for problems like these, which is basically running custom machines (including GPUs) in GitHub Actions: https://cirun.io/. It is used in multiple open source projects needing GPU support like the following:. https://github.com/pystatgen/sgkit/; https://github.com/qutip/qutip-cupy. It is fairly simple to setup, all you need is a cloud account (AWS or GCP) and a simple yaml file describing what kind of machines you need and Cirun will spin up ephemeral machines on your cloud for GitHub Actions to run. It's native to GitHub ecosystem, which mean you can see logs/trigger in the Github's interface itself, just like any Github Action run. Also, note that Cirun is free for Open source projects. (You only pay to your cloud provider for machine usage)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1793#issuecomment-881043172:683,log,logs,683,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793#issuecomment-881043172,1,['log'],['logs']
Testability,"Hi @a-munoz-rojas, diffxpy will be public very soon, once we finished running all benchmarks that we need for validation. I would be happy to help you set it up if you still want to give it a go then!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/159#issuecomment-421157493:82,benchmark,benchmarks,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159#issuecomment-421157493,1,['benchmark'],['benchmarks']
Testability,"Hi @arutik,. The reason the two DE gene sets are not the same is that `sc.tl.rank_genes_groups()` only reports genes that are upregulated in one cluster (the one in specified in the `group` parameter) compared to the other. The test itself should be symmetric if I'm not mistaken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/919#issuecomment-554271061:228,test,test,228,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/919#issuecomment-554271061,1,['test'],['test']
Testability,"Hi @davidsebfischer, I am writing a simple jupyter notebook where I am analysing the 10x_pbmc68k_reduced.h5ad data. I selected only clusters 0 and 1:; `twoClusters = adata[np.logical_or(adata.obs.louvain == '0', adata.obs.louvain == '1')]; `. Running `sc.tl.rank_genes_groups(twoClusters, groupby='louvain, method='wilcoxon', corr_method=''bonferroni)`, I obtained the following genes. ![image](https://user-images.githubusercontent.com/26186755/54123532-ec2f0b80-43f7-11e9-8c2f-f506b9170e55.png). Trying with `diffxxy` library,; `test = de.test.wilcoxon(data=twoClusters, grouping=""louvain""); `; there is the following error: _All numbers are identical in mannwhitneyu_. > @andrea-tango please use dev right now. For this test, I used the version downloaded with pip.; I can clone the repository and use the diffxpy dev branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471519124:531,test,test,531,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471519124,3,['test'],['test']
Testability,"Hi @dawe ,; I follow your code and it work well, but the result showing weird, the scvelo arrow indicate the development direction just was in contrast to the monocle direction.; In the other word, the scvelo's 'scv.pl.velocity_embedding_stream' showing terminal differentiation cells develop to original cells. this was incorrected logically. why the scvelo showed the inverted result contrast with monocle result.; I guess what i make the cell order was wrong ? i follow your code-adata = adata[cell_names]- to order the cell , i wonder whether the code just sorted the cell barcode on annData.obs but the annData.X's matrix?; why was the order runing so quickly that the matrix of annData not be sorted at the same time?; Best,; hanhuihong",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1718#issuecomment-799993218:333,log,logically,333,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718#issuecomment-799993218,1,['log'],['logically']
Testability,"Hi @erikadudki,. Sorry for the slow replies to this post. There is no test implemented for bimodality in scanpy at the moment. For modeling you could look into [diffxpy](https://github.com/theislab/diffxpy), where you may be able to fit a gaussian mixture model to do model selection. Otherwise I guess `statsmodels` is the way forward for this in python.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1086#issuecomment-603904135:70,test,test,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1086#issuecomment-603904135,1,['test'],['test']
Testability,"Hi @falexwolf, thanks a lot for the clarifications. This helps me a lot. In the example I provided yesterday, `louvain` found 5 clusters, so 0, 1, 2 made up only part of the data. I should have provided the output as well to make this clear right away. Concerning a PR for the documentation, I think I would wait until you will update the behaviour of `logreg`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/278#issuecomment-427339773:353,log,logreg,353,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/278#issuecomment-427339773,1,['log'],['logreg']
Testability,"Hi @fidelram, good to see you :smile:. I was working on the Galaxy integration. I tested that with the `1.3.2` version from Bioconda. I tested with adata from krumsiek11. - For colors, I tried with `sc.pl.scatter(adata=adata, x='EKLF', y='Cebpa', color=['EgrNab', 'cJun']) and I got the error:. ```; ...; and (color is None or color in adata.obs.keys() or color in adata.var.index)):; File ""path/to/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 2035, in __contains__; hash(key); TypeError: unhashable type: 'list'; ```. - For components: the command was . ```; sc.pl.scatter(; adata=adata,; x='EKLF',; y='Cebpa',; color='EgrNab',; layers=('X', 'X', 'X'),; use_raw=False,; sort_order=True,; components='all',; projection='2d',; legend_loc='right margin',; legend_fontsize=1,; legend_fontweight='normal',; palette='viridis',; frameon=True,; right_margin=1.0,; size=1.0,; show=False,; save='.png'); ```; and the error:. ```; components = np.array(components).astype(int) - 1; ValueError: invalid literal for int() with base 10: 'all'; ```. Did I put the parameters in a wrong way?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/311#issuecomment-431284136:82,test,tested,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311#issuecomment-431284136,2,['test'],['tested']
Testability,"Hi @fidelram,; One way in which I'd like to do it is like the following:. ```python; sc.pl.scatter(adata, x='<gene1>', y='<gene2>', color=['Mki67', 'Pclaf'],; save=False, use_raw=False); ```. to show the relationship between two genes (i.e. gene1 and gene2), and one third gene (in this case Mki67 in one subplot, Pclaf in the second).; One of the subplots could be like the following:. ![test](https://user-images.githubusercontent.com/697622/52814026-1e538480-3069-11e9-9af5-ef7a4761ff25.png). Hope this is clear. Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/311#issuecomment-463771320:389,test,test,389,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311#issuecomment-463771320,1,['test'],['test']
Testability,"Hi @flying-sheep @ilan-gold ,; Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2122306265:613,log,logging,613,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061#issuecomment-2122306265,1,['log'],['logging']
Testability,"Hi @genecell,. We have a review paper on current best-practices in scRNA-seq analysis which is coming out soon in Molecular Systems Biology that discusses this a bit. The issue with batch correction in scRNA-seq data isn't that batch affects different cell types differently, but rather that if cell type compositions change between batches, then transcriptional differences between the cell types that differ between the batches confound the technical batch effect estimation. So you end up correcting for more than just the technical effect. This means that you can use Combat if the cell type compositions are expected to be similar between batches. Indeed, ComBat is shown to outperform MNN for simple batch correction scenarios ([kBet paper](http://www.nature.com/articles/s41592-018-0254-1)). Inspite of the above argument, the better way to do things is definitely to include batch as a covariate. That way you don't underestimate your background variance. In the case of marker gene detection, this is not quite so problematic as:; 1. It is an easy problem, as cell-type differences tend to be very pronounced so you should always detect a signal even with non-optimal methods.; 2. The p-values you calculate from marker gene detection are inflated anyway and therefore not meaningful. We discuss the above points in our manuscript. I'm not aware whether using corrected data for differential expression testing is discussed anywhere else though. If you email me, I could forward you a copy of the manuscript, but it should be available in MSB in the next weeks. The issue with inflated p-values is also discussed is a few other places like [here](https://www.biorxiv.org/content/early/2018/11/05/463265).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/691#issuecomment-502582404:1412,test,testing,1412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691#issuecomment-502582404,1,['test'],['testing']
Testability,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1333#issuecomment-664944535:121,log,log,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333#issuecomment-664944535,2,['log'],['log']
Testability,"Hi @giovp still up for adding a test dataset and tests? If so, this would be a good moment in time, as we should merge this quickly before more changes to master cause conflicts",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1024#issuecomment-584591351:32,test,test,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024#issuecomment-584591351,2,['test'],"['test', 'tests']"
Testability,"Hi @giovp! The test data is too large, it’ll take scanpy a long time to clone once this is in `master`. The way we fix it is that we replace the data and then merge our changes into commit bb70446 (creating a new commit from the two and eliminating any trace of the big dataset). For reference, the test data `filtered_feature_bc_matrix.h5` is <100kb. I’d say you find the smallest of the 10x example datasets, reduce it so the (non-image) data is <100kb all in all, and delete the hires pic. The code should work if there’s only the lores pic anyway, right?. An alternative would be to mark our tests as “internet” tests and dynamically download the data, but I think it’s better to always run the spatial tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1024#issuecomment-586185661:15,test,test,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024#issuecomment-586185661,5,['test'],"['test', 'tests']"
Testability,"Hi @giovp,; no worries, I hope you had a good TAC meeting! And thanks a lot for picking this up again, fixing the docs and also for starting the new issue on batch integration. I saw some of the github automated tests test are failing now, but I don't really understand the error messages tbh ;) Are they even related to the execution of the code provided by this PR?. If there is anything I should look into, let me know - I have some time for this next week!; Best, Jan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1049902277:212,test,tests,212,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1049902277,2,['test'],"['test', 'tests']"
Testability,"Hi @ivirshup , I replaced the one test image that was causing a failure, as you suggested. (And I checked to make sure the image makes sense... it does...) I think this should do it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1771#issuecomment-844219743:34,test,test,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1771#issuecomment-844219743,1,['test'],['test']
Testability,"Hi @ivirshup ,. Actually we can't see the PR doc builds, for https://readthedocs.com/projects/icb-scanpy/builds/361157/ for example this is what I see:. ![image](https://user-images.githubusercontent.com/1140359/86819388-93a46880-c055-11ea-8f62-458508a6f614.png). It's a bit annoying especially when it build fine locally but fails at readthedocs.com, it would be great if the person who sends the PR can also see the build log on the website.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1307#issuecomment-655012955:424,log,log,424,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307#issuecomment-655012955,1,['log'],['log']
Testability,"Hi @ivirshup ,. just checked #1529 , that's a more general additions to `rank_genes_groups_matrixplot` and `rank_genes_groups_dotplot`, but does not address this bug of `violinplot` which has to do with sparse `adata.X`. This also adds a test for that case. Thanks for pointing it out.; I'll add release note and merge it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1669#issuecomment-827461688:238,test,test,238,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669#issuecomment-827461688,1,['test'],['test']
Testability,"Hi @ivirshup this would be ready for review. ; Travis test are failing for some figure in diffusion maps, not sure why though :(. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105#issuecomment-606045652:54,test,test,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105#issuecomment-606045652,1,['test'],['test']
Testability,"Hi @ivirshup, ; I am part of Intel Labs and we are trying to accelerate the genomics pipeline. We are trying to push some changes into scanpy details about which are mentioned in the blog : [https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Intel-Labs-Accelerates-Single-cell-RNA-Seq-Analysis/post/1390715#:~:text=Intel%20Labs%20has%20accelerated%20a,of%20a%20single%20A100%20GPU.](url) ; We are facing some issues while pushing some changes in the leiden and louvain. The error states some issues with pca in the scanpy/tests/external/test_scrublet.py::test_scrublet_params when we have not made any changes for the same. Can you please help us to resolve this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2409#issuecomment-1429441613:551,test,tests,551,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2409#issuecomment-1429441613,1,['test'],['tests']
Testability,"Hi @ivirshup,. This looks like a great function but it's not super clear what the ```group``` arg is. Is it supposed to be one of the levels of the ```groupby``` arg in ```sc.tl.rank_genes_groups```? I would guess so based on the example here: https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html but that does not work for me. ```; # compare expression levels of mel vs all other cell types in pairwise manner; sc.tl.rank_genes_groups(noncycling_adult, groupby='class_1', groups = ['T-cell', 'eccrine', 'mel', 'dendritic', 'krt'], reference = 'mel', key_added='DE_results', method = 'wilcoxon'). results = sc.get.rank_genes_groups_df(noncycling_adult, key = 'DE_results', group = 'mel'). ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-32-73add1f79f3a> in <module>; 1 # save as a data frame; 2 ; ----> 3 results = sc.get.rank_genes_groups_df(noncycling_adult, key = 'DE_results', group = 'mel'); 4 ; 5 . ~/software/pkg/miniconda3/envs/melanocyte_env/lib/python3.7/site-packages/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols); 53 d = pd.DataFrame(); 54 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:; ---> 55 d[k] = adata.uns[""rank_genes_groups""][k][group]; 56 if pval_cutoff is not None:; 57 d = d[d[""pvals_adj""] < pval_cutoff]. ~/software/pkg/miniconda3/envs/melanocyte_env/lib/python3.7/site-packages/numpy/core/records.py in __getitem__(self, indx); 517 ; 518 def __getitem__(self, indx):; --> 519 obj = super(recarray, self).__getitem__(indx); 520 ; 521 # copy behavior of getattr, except that here. ValueError: no field of name mel; ```. Thanks for your help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1360#issuecomment-717575616:1262,log,logfoldchanges,1262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1360#issuecomment-717575616,1,['log'],['logfoldchanges']
Testability,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1266#issuecomment-639506245:486,log,log-normalized,486,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266#issuecomment-639506245,3,"['log', 'test']","['log-normalized', 'test']"
Testability,"Hi @r-reeves,; Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-734426157:466,benchmark,benchmark,466,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289#issuecomment-734426157,1,['benchmark'],['benchmark']
Testability,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python; de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""); de_df.query(""abs(logfoldchanges) > 1""); ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API – but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1325#issuecomment-777203347:357,log,logfoldchanges,357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325#issuecomment-777203347,1,['log'],['logfoldchanges']
Testability,"Hi @sygongcode,. Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/821#issuecomment-529213147:62,test,testing,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821#issuecomment-529213147,1,['test'],['testing']
Testability,"Hi @transcriptomics, ; If you want to learn a little more about confounding, there's a pretty nice recent guide to setting up design matrices for differential expression testing [here](https://f1000research.com/articles/9-1444/v1). This is a very related issue as ComBat essentially fits the statistical model that you specify with your parameters in a similar manner than you would with a DE model. In brief, the issue is that the distribution of covariates makes it impossible for the statistical fit to prioritize whether to assign the variation in cells that are e.g., on plates starting with ""F"" to variation from being fetal or variation due to being on those plates.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1606#issuecomment-766739616:170,test,testing,170,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1606#issuecomment-766739616,1,['test'],['testing']
Testability,"Hi Alex, ; The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`; , I get the following error. The igraph I am using is V 0.1.11.; Many thanks; Hashem; `DeprecationWarning Traceback (most recent call last); <ipython-input-20-fb44185f2d28> in <module>(); 1 ; ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True); 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy); 78 directed = False; 79 if not directed: logg.m(' using the undirected graph', v=4); ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed); 81 if flavor == 'vtraag':; 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed); 41 def get_igraph_from_adjacency(adjacency, directed=None):; 42 """"""Get igraph graph from adjacency matrix.""""""; ---> 43 import igraph as ig; 44 sources, targets = adjacency.nonzero(); 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(); 6 __license__ = ""MIT""; 7 ; ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, ""; 9 ""this visualization library has been renamed to ""; 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324587457:756,log,logg,756,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324587457,1,['log'],['logg']
Testability,"Hi Alex,; I managed to get the log working by using your function to convert to AnnData rather than mine. (adata = sc.AnnData(x)). However, coloring the plots still does not work. I get the following error.; TypeError: object of type 'numpy.int64' has no len(). You can reproduce the error by the following; ### Load Data; x = pd.read_csv('Trial_data.csv', delimiter=',', index_col=0); ### Drop DAPI; x = x.drop(list(x.filter(regex='DAPI.', axis=1)), axis=1); ### Convert to AnnData; adata = sc.AnnData(x); ### Filter cells; sc.pp.filter_cells(adata, min_genes=1); sc.pp.filter_genes(adata, min_cells=1); adata.obs['n_counts'] = adata.X.sum(axis=1); ### Normalize data; sc.pp.log1p(adata); ### PCA; sc.tl.pca(adata, svd_solver='arpack'); sc.pl.pca(adata); sc.pl.pca(adata, color='CD3D'). I also tried it on a different dataset.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-456461004:31,log,log,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-456461004,1,['log'],['log']
Testability,"Hi Alexis,; sorry about that. I made substantial changes to set up and build the [docs](https://scanpy.readthedocs.io) remotely just in the past days and for that had to experiment on the master branch. I'm fixing everything tonight running tests on all example notebooks. I will also incude more tests in the future so that stuff like this doesn't happen anymore.; Cheers,; Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/34#issuecomment-324337710:241,test,tests,241,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34#issuecomment-324337710,2,['test'],['tests']
Testability,"Hi Alma,. thanks for raising your thoughts here!. I’ll try to clarify the output a bit and tag @ivirshup here. `sc.pp.neighbors` produces two main results, which it indeed stores in the `ad.obsp`:. 1. A distance matrix in `adata.obsp['distances']`. This matrix has shape (n_obs, n_obs): for each observation, only `n_neighbors-1 `entries will be non-zero. The nearest neighbor of an observation, itself with distance 0, is discarded, hence the `-1`. It is probably what you have been thinking of in your description. 2. A connectivity graph in `adata.obsp['connectivity']`. This graph has shape (n_obs, flexible), where the flexible number of connections for each observation are determined during the UMAP algorithm. Hence if you’re interested in the distance matrix, `adata.obsp['distances']` would be what you’re looking for! Coming back to your code example, here the test should be a pass:; ```py; # Import packages. import scanpy as sc; import anndata as ad; import numpy as np. # set random seed; np.random.seed(42). # create dummy data; adata = ad.AnnData(shape=(1000,1)); adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities; k = 10; sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell; gr = adata.obsp['distances']; nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k-1; np.testing.assert_equal(nn, k-1); ```. Might actually try to clarify this in documentation, small PR addressing this will follow soon. How does that sound to you? Please persist if you think I miss the point!. That being said, I think that the computation of the distance matrix and the connectivity graph are both correct.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2587#issuecomment-1691673182:872,test,test,872,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587#issuecomment-1691673182,2,['test'],"['test', 'testing']"
Testability,"Hi Davide!. Thank you very much for this! Sorry that I tend to be late these days, have two 6 week old baby twins to take care of... I'm happy to merge this and I'll add you to the author list! I hope it is ok if I rename the module and the top-level function to `score_gene_lists` and the second top-level function to `score_cell_cylce_genes`? Simply `score` is a bit generic... there might be many other scores in the future and then people will get confused. It's also good if both start with `score` so that auto-lookup gives you directly these suggestions? . Also, do you have a notebook with an example? It would be cool to see this at work. You could push this to a new subdirectory in `scanpy_usage`: https://github.com/theislab/scanpy_usage. I just sent you a collaborator invitation. From the example, we can then mayb design a test that goes a bit more into detail. Would be cool to benchmark with Seurat, for example. Also, one could think about providing a default list of genes, right? In particular for the cell cycle, it would be nice to directly call the function with default parameters - one can then still add user-specified lists. Do you want to provide such a list? I also sent you collaborator invitation for scanpy - maybe only temporarily if we get too many people at some point - so that you can quickly add this, if you like. Cheers,; Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/76#issuecomment-363587569:838,test,test,838,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76#issuecomment-363587569,2,"['benchmark', 'test']","['benchmark', 'test']"
Testability,"Hi Davide,. I like the preprint and the blog post. I agree that differential expression testing deserves a classification perspective. Coincidentally, we (with @tcallies) were also working on a little paper that makes this point but used neither logistic regression nor TCCs as covariates... unfortunately, we still haven't updated our benchmarks, but I'd assume that what Lior Pachter does works best. :smile:. Anyways, yes, we should include it at some point but let's still collect some experience... Until then, people can use your two-line workaround. :wink:. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/95#issuecomment-369860454:88,test,testing,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95#issuecomment-369860454,3,"['benchmark', 'log', 'test']","['benchmarks', 'logistic', 'testing']"
Testability,"Hi I had this problem as well with 1.6.0 it was triggered by scanpy's test code. ```; scanpy.api (unittest.loader._FailedTest) ... ERROR. ======================================================================; ERROR: scanpy.api (unittest.loader._FailedTest); ----------------------------------------------------------------------; ImportError: Failed to import test module: scanpy.api; Traceback (most recent call last):; File ""/usr/lib/python3.9/unittest/loader.py"", line 470, in _find_test_path; package = self._get_module_from_name(name); File ""/usr/lib/python3.9/unittest/loader.py"", line 377, in _get_module_from_name; __import__(name); File ""/<<PKGBUILDDIR>>/.pybuild/cpython3_3.9_scanpy/build/scanpy/api/__init__.py"", line 27, in <module>; from . import pl; File ""/<<PKGBUILDDIR>>/.pybuild/cpython3_3.9_scanpy/build/scanpy/api/pl.py"", line 1, in <module>; from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot; ImportError: cannot import name 'stacked_violin' from 'scanpy.plotting._anndata' (/<<PKGBUILDDIR>>/.pybuild/cpython3_3.9_scanpy/build/scanpy/plotting/_anndata.py). ----------------------------------------------------------------------; Ran 1 test in 0.000s. ```. I ended up with this patch to get the tests to run successfully.; ```; --- a/scanpy/api/pl.py; +++ b/scanpy/api/pl.py; @@ -1,4 +1,7 @@; -from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot; +from ..plotting._anndata import scatter, violin, ranking, clustermap, heatmap, tracksplot; +from ..plotting._stacked_violin import stacked_violin; +from ..plotting._dotplot import dotplot; +from ..plotting._matrixplot import matrixplot; ; from ..plotting._preprocessing import filter_genes_dispersion, highly_variable_genes; ; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397#issuecomment-765003952:70,test,test,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397#issuecomment-765003952,4,['test'],"['test', 'tests']"
Testability,"Hi Isaac, I've updated to v1.4.4 but I'm still getting this problem. I've finally produced a minimal test case:. ```; import scanpy as sc; sc.logging.print_versions(); #adata = sc.datasets.pbmc3k(); adata = sc.read(""orig/transpose_rsem_cell_by_gene.tsv.gz""); print(adata); adata = adata.T; print(adata); adata.raw = adata; print(adata); sc.pp.filter_cells(adata, min_genes=200); print(adata); adata = adata[adata.obs['n_genes'] < 5000, :]; print(adata); adata = adata[adata.obs['n_genes'] > 100, :]; print(adata); ```. output is:; ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 ; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; AnnData object with n_obs × n_vars = 60498 × 466 ; AnnData object with n_obs × n_vars = 466 × 60498 ; AnnData object with n_obs × n_vars = 466 × 60498 ; AnnData object with n_obs × n_vars = 466 × 60498 ; obs: 'n_genes'; View of AnnData object with n_obs × n_vars = 311 × 60498 ; obs: 'n_genes'; Traceback (most recent call last):; File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/series.py"", line 977, in _get_values; return self._constructor(self._data.get_slice(indexer),; File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/internals/managers.py"", line 1510, in get_slice; return self.__class__(self._block._slice(slobj),; File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/internals/blocks.py"", line 268, in _slice; return self.values[slicer]; IndexError: boolean index did not match indexed array along dimension 0; dimension is 466 but corresponding boolean di",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-516194235:101,test,test,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-516194235,2,"['log', 'test']","['logging', 'test']"
Testability,"Hi Pawel, sorry for the confusion, yes, we just did a major revision. The package is still in the testing phase even though everything should work fine. Any comments from your side would be greatly appreciated!. Packaging will start soon. Development will happen on a development branch from now on. The notebooks are currently being migrated to another repo, links will be updated tomorrow or day after tomorrow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/7#issuecomment-281458534:98,test,testing,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7#issuecomment-281458534,1,['test'],['testing']
Testability,"Hi Philipp,. I have updated accordingly, again no issue but the duplication and i; analysed most of them are from previous code. Regards,; Khalid. On Mon, May 20, 2019 at 5:23 PM Philipp A. <notifications@github.com> wrote:. > Hi, looks great!; >; > The only duplicated code left is that _prepare_weighted_dataframe is very; > similar to _prepare_dataframe. I think you can delete; > _prepare_weighted_dataframe and just change _prepare_dataframe so it does return; > categories, obs_tidy, categorical. Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:712,test,tests,712,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578,5,"['assert', 'test']","['assert', 'assertions', 'test', 'tests']"
Testability,"Hi Phillip,. I have removed issue from the pull request by the testing tool, now the; tools showed me duplications, which are mostly from other code and 1-2 from; my code. Please have a look into it. It's my first pull request and its; taking too much time :(. Thanks; Khalid. On Tue, May 14, 2019 at 9:28 PM khalid usman <khalid0491@gmail.com> wrote:. > Ok , thanks for letting me know. Please check the pull request. I have; > verified my code by keeping weights 1 and it has same values when; > observations has no weights or all weights equal to 1.; >; > I also suggest to update PCA for weighted sampled data.; >; > Thanks,; > Khalid Usman; >; > On Tue, May 14, 2019 at 7:53 PM Philipp A. <notifications@github.com>; > wrote:; >; >> You can just open a new one, I’ll close this one then 🙂; >>; >> —; >> You are receiving this because you authored the thread.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/theislab/scanpy/pull/630?email_source=notifications&email_token=ABREGOFHXLS2NZRCDSLJHE3PVKR2ZA5CNFSM4HKUCBXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVLHMMQ#issuecomment-492205618>,; >> or mute the thread; >> <https://github.com/notifications/unsubscribe-auth/ABREGOBMZBMFMNA6FCEMFULPVKR2ZANCNFSM4HKUCBXA>; >> .; >>; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/630#issuecomment-493836074:63,test,testing,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-493836074,1,['test'],['testing']
Testability,"Hi Sarah,; thanks for the note and sorry about that; would you install a stable release from PyPi in the meanwhile `pip install scanpy`? I'm currently rewriting quite substantial parts and yes, this is clearly a bug I caused on the weekend; testing will also be more extensive in the future so that this stuff does happen anymore. This kind of stuff will also not happen on master branch in the future; but this rewriting goes along with building some [documentation](https://scanpy.readthedocs.io) and this builds from master... ; Cheers,; Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/32#issuecomment-324116498:241,test,testing,241,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32#issuecomment-324116498,1,['test'],['testing']
Testability,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:; `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`; The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2242#issuecomment-1256969218:82,log,log-transformed,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242#issuecomment-1256969218,2,['log'],"['log-transformed', 'logarithmized']"
Testability,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)); * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. 😄",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/26#issuecomment-312623579:950,log,log-normalization,950,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26#issuecomment-312623579,1,['log'],['log-normalization']
Testability,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:278,test,tests,278,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617,19,['test'],"['test', 'testing', 'tests']"
Testability,"Hi all,. Sorry I sent a PR(https://github.com/theislab/scanpy/pull/1271) without reading any of these, it's my bad. Some thoughts are as follows:. - I think it's fairly straightforward to check for R dependencies in runtime, please see the PR for more info. - For Travis, I used Ubuntu packages for base R installation and then rest of the R deps are installed by the Travis user in home directory, which is cached. apt-install R installation takes around a minute. This is really hard to reduce, I think. . - After the caching, the installation of sctransform itself take around 15-20sec. This can even be reduced to zero if I check whether it's already installed. See https://travis-ci.org/github/theislab/scanpy/jobs/697070834 for a better breakdown. You can compare this with an existing test run e.g. https://travis-ci.org/github/theislab/scanpy/jobs/696758553. - sctransform test overhead is around 30sec, which can also be reduced. Overall, it adds 4 minutes to the travis test time. I don't know exactly where the remaining difference comes from. - However, if we keep adding more Ubuntu and/or R packages in the scanpy travis, it can get a bit bloated. Even if things are cached, for some reason, there is a 45-50 second cache upload overhead which is not negligible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-642835553:792,test,test,792,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-642835553,3,['test'],['test']
Testability,"Hi danli249, . what dataset are you using? If this is your own dataset, can you instead replicate this behavior on a public dataset? e.g. the clustering tutorial https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html?. without much needed context, this looks like some oversight in the preprocessing, for example not normalizing your data or not log-transforming it. Michael",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364138151:353,log,log-transforming,353,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364138151,1,['log'],['log-transforming']
Testability,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611:219,test,test,219,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611,2,"['log', 'test']","['logreg', 'test']"
Testability,"Hi thinks for the answer and thanks for the link on the test data and visualization, I will try to use that going forward. I will cook up a non working example if needed, however just looking at the code https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L302 there is missing return statements for a few of the plotting functions in the `_rank_genes_groups_plot` unless I missed something they will then not return an axes?. The [heatmap]( https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L1044) function itself return an axis but there is no return statement from the `_rank_genes_groups_plot`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/419#issuecomment-453587853:56,test,test,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419#issuecomment-453587853,1,['test'],['test']
Testability,"Hi! ; Sorry, I don't really have the time to get into this atm, but I have an idea... I think the default for expecting logarithmized data vs non-logarithmized data changed between the two functions for the `method='seurat'` case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-598855980:120,log,logarithmized,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598855980,2,['log'],['logarithmized']
Testability,"Hi! Can you explain a bit what use cases this helps people with? When would one want to set this to True?. Once we have a good example, you can use that to write a small test that checks if it works as intended.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2731#issuecomment-1798081456:170,test,test,170,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2731#issuecomment-1798081456,1,['test'],['test']
Testability,"Hi! Here is the source code with data [Nestorowa et al., 2016](https://doi.org/10.1182/blood-2016-05-716480) with added diagnostic tests to produce these results. https://github.com/gmvaccaro/scanpy.tl.score_genes_fix/blob/main/score_genes_diagnostics_tests2.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3167#issuecomment-2383992046:131,test,tests,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167#issuecomment-2383992046,1,['test'],['tests']
Testability,"Hi! I just wrote a quick solution in https://github.com/theislab/scanpy/pull/586; I tested it manually and it seems to work (I used louvain code as template).; I assumed it could be interesting to work on a separate leiden function, due to possible argument clashes with louvain, instead of merging the two functions together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/582#issuecomment-479187750:84,test,tested,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/582#issuecomment-479187750,1,['test'],['tested']
Testability,"Hi! I think we have a different focus here, and not all of what you stated as fact is correct, so I’ll do my best to clear this up:. 1. There is an advantage for type hints in common Scanpy usage. IPython should use Jedi to create autocompletions since this summer, but they forgot to reenable it. I sent them an issue to do so, ipython/ipython#11503 and a fix in ipython/ipython#11506. Jedi supports type hints, so with `c.Completer.use_jedi = True` now or by default in a month, people will profit from them. Furthermore, people are using scanpy in applications and scripts, not just in notebooks. When you use an IDE (or install the jedi extension in EMACS) you should profit from it. 2. The Jupyter shift-tab help being hard to read in the presence of type hints is what I consider a bug. I reported it in ipython/ipython#11504 and fixed it in ipython/ipython#11505. 3. The numpy is on it (see [here](https://github.com/numpy/numpy-stubs)) and will probably integrate it once there needs to be no Python 2 compat. e.g. scikit-learn waits for numpy: scikit-learn/scikit-learn#11170. I see your concern about entry hurdles, but I don’t agree. It’s super easy. `Union` is “or”, `Optional` is “or `None`”. If there’s questions, they can be answered. (or people click on the links in the docs and read like one sentence of explanation). 4. If you want we can change how all that is rendered. `Union[a, b]` could be done as ``` :class:`a` or :class:`b` ``` But it’s really not hard…. Honestly I think the `Callable[…]` is much better than the textual description that was there before: Until it was there, people (including me when i was writing that annotation) had to dive into the code to figure out what function signature is *really* expected there. Now they have to be able to parse what that `Callable[[a,b], c]` there means. If they have never encountered it before, they can click on it, read one sentence of explanation and know that `a` and `b` are parameters and `c` the return type. Done in",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-440619581:936,stub,stubs,936,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-440619581,1,['stub'],['stubs']
Testability,"Hi! Sorry for the very late reply! But yes, this function is assuming the data is log-transformed before ranking genes. That's the typical workflow. It originally had a parameter to check for this, but then we decided to simplify and remove it (#519). There was some brief discussions here about adding an attribute when pp.log1p is run to handle non-transformed data, but I don't think was ever implemented. Might be worth revisiting though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/673#issuecomment-528510773:82,log,log-transformed,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/673#issuecomment-528510773,1,['log'],['log-transformed']
Testability,"Hi! not sure why the two tests failed, I don't think it's related to my edits",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1511#issuecomment-738690458:25,test,tests,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511#issuecomment-738690458,1,['test'],['tests']
Testability,"Hi!. Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more!. Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/26#issuecomment-312654301:80,log,log,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26#issuecomment-312654301,2,['log'],"['log', 'log-transform']"
Testability,"Hi, . Actually that's not what I've experienced - if you compare with default rank_genes_groups test you get genes with positive **and** negative logFC, which means that the test reports both upregulated and downregulated genes in that comparison, but again, it's not symmetric - please try on a test dataset for yourself.. Also if I take lists produced by A vs B comparison and B vs A and filter the genes by a common adjusted p-value cutoff (0.05 let's say) I would get lists of different sizes, so all of that makes me think that the tests are not symmetric/two-sided.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/919#issuecomment-554364259:96,test,test,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/919#issuecomment-554364259,5,"['log', 'test']","['logFC', 'test', 'tests']"
Testability,"Hi, . Thanks for the quick reply!. I'm attaching the output for `combined_bbknn.obs['scNym']`:. ![Screenshot 2021-03-01 at 11 09 39](https://user-images.githubusercontent.com/3297906/109489440-ca187300-7a7e-11eb-943d-270c0273c3fc.png). This is really weird. When I tested it on my macbook I created a new environment and the problem persisted. However, there I downgraded to `scanpy==1.6` as well, the problem persisted, but the `NA`s weren't there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701#issuecomment-787867150:265,test,tested,265,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701#issuecomment-787867150,1,['test'],['tested']
Testability,"Hi, ; I tested your fix and it works! ; ```; scanpy==1.4.5.2.dev6+gfa408dc7 anndata==0.7.1 ; umap==0.3.10 numpy==1.17.4 scipy==1.3.1 ; pandas==0.25.2 scikit-learn==0.21.3 ; statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1; ```; BTW:; `matplotlib==3.1.3`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-586333599:8,test,tested,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-586333599,1,['test'],['tested']
Testability,"Hi, ; Thank you very much for such a detailed explanation. It really helps. I've two more questions: . 1). Can we do this gene subsetting with Logistic regression (where no multiple testing correction is involved)? . 2). Since you nicely pointed out sc.tl_rank_genes_groups doesn't tell about the contribution of genes in the clustering- are there tools that can be integrated with ScanPy to do this job? (for example, diffxpy or MAST). I'm really interested in the differential gene testing to predict the markers (from a gene subset used for clustering). . I shall be grateful if you can suggest a method.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/748#issuecomment-515114575:143,Log,Logistic,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748#issuecomment-515114575,3,"['Log', 'test']","['Logistic', 'testing']"
Testability,"Hi, @ShobiStassen.; As @falexwolf said, i tested the memory usage in the step where you have the problem.; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/cluster_1m_neurons.ipynb; The peak usage is around 121 GB, but it should still be possible to run with 126 GB RAM. Maybe another process took some serious amount of memory?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/511#issuecomment-470255319:42,test,tested,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-470255319,2,"['benchmark', 'test']","['benchmarks', 'tested']"
Testability,"Hi, @awnimo , sorry for the delay.; It seems that this PR breaks test_harmony_timeseries.py. I get ; ```; E ValueError: 'time_points' column does not contain Categorical data. ../../external/tl/_harmony_timeseries.py:140: ValueError; ```; On master the test works fine.; Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1248#issuecomment-702660644:253,test,test,253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248#issuecomment-702660644,1,['test'],['test']
Testability,"Hi, @eroell, I understand what you're saying. You're referring to tests with signed test statistics, like t-tests and Wilcoxon tests. You mentioned that larger scores typically correspond to lower p-values, and conversely, scores further from 0 also tend to have lower p-values. However, I am currently confused about what the positive and negative values of these scores represent. Previously, I believed that positive scores indicated upregulation and negative scores indicated downregulation, but recent results have shown me that this viewpoint is incorrect.; ![image](https://github.com/scverse/scanpy/assets/103617127/5f7d7b5b-939d-4ffe-8822-b68b59ac354f)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246:66,test,tests,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246,4,['test'],"['test', 'tests']"
Testability,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by ; `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`; and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/26#issuecomment-312650646:290,log,log,290,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26#issuecomment-312650646,3,['log'],['log']
Testability,"Hi, I just wanted to bring this back up again because I've been logging some of the issue's I've encountered. It seems we're at a bit of a philosophical divide, so perhaps it's best for me to just register which use cases I have that AnnData / scanpy are personally causing me friction:. Instead of pasting all errors, I'm just going to paste code blocks I wish worked. Note, these are actual use cases I have regularly encountered. **1. Cannot pass AnnData to numpy or sklearn operators**. ```python; import scanpy as sc; import numpy as np; import pandas as pd; import matplotlib.pyplot as plt; from sklearn import decomposition, cluster. data = np.random.normal(size=(100,10)); adata = sc.AnnData(data). # All of the following raise errors; np.sqrt(adata); adata[:, adata.var_names[0:3]] - adata[:, adata.var_names[3:6]]. adata.obsm['X_PCA'] = decomposition.PCA(2).fit_transform(adata); ```; To answer the question above, I think it should return the whole AnnData object, like how DataFrames return themselves. I don't know if we think it should ""update"" the original AnnData. I'm also confused by how this results in a performance decrease? If I do `adata = np.sqrt(adata)` then isn't this the same footprint as modifying inplace? If I do `adata_sq = np.sqrt(adata)` then my intention is to duplicate the adata object. In this case, it is my intention to create a duplicate object, and I would like AnnData to respect this intention. ; **2. Requirement to use .var_vector or .obs_vector for single columns**; ```python; # This works as expected; adata[:, adata.var_names[0:3]]. # I wish this did as well.; adata[:, adata.var_names[0]]; ```; **3. .var_vector doesn't return a Series**. ```python; pdata = pd.DataFrame(data); # Returns series; pdata[0]. # Returns ndarray; adata.var_vector[0]; ```. **4. Clusters as categories creates confusing scatterplots**; ```python; sc.pp.neighbors(adata); sc.tl.leiden(adata). plt.scatter(adata.obs['leiden'], adata.X[:,0]); ```; Produces the following plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-607952458:64,log,logging,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-607952458,1,['log'],['logging']
Testability,"Hi, It's not available in scanpy at the moment, but I wrote a wrapper for it via `rpy2` and `anndata2ri` which is available here:; https://github.com/normjam/benchmark/blob/master/normbench/methods/ad2seurat.py",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-590009483:158,benchmark,benchmark,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-590009483,1,['benchmark'],['benchmark']
Testability,"Hi, can you please create an issue with a minimal reproducible example?. Alternatively please add a unit test that will trigger your newly added branch. You’ll be able to see if that worked when this comment goes away:. > ![grafik](https://github.com/user-attachments/assets/46daf9ee-93c4-4576-bbcd-c1b17c090e0d). Lastly, please follow the [pre-commit instructions](https://results.pre-commit.ci/run/github/80342493/1726160235.3-pI6xDsREqRW19ZysrYpg):. > ```pytb; > src/scanpy/preprocessing/_pca.py:268:13: E722 Do not use bare `except`; > |; > 266 | try:; > 267 | pca_.partial_fit(chunk); > 268 | except:; > | ^^^^^^ E722; > 269 | continue; > |; > ```; > ; > Found 1 error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3227#issuecomment-2371113084:105,test,test,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227#issuecomment-2371113084,1,['test'],['test']
Testability,"Hi, did any one ever end up testing Densmap for scRNA ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1619#issuecomment-1906223696:28,test,testing,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1619#issuecomment-1906223696,1,['test'],['testing']
Testability,"Hi, everything is OK with the benchmarks, `regress_out` would fail if called with variables that doesn’t exist. The reason these are named differently is here: https://github.com/scverse/scanpy/blob/ad657edfb52e9957b9a93b3a16fc8a87852f3f09/benchmarks/benchmarks/_utils.py#L27-L31. I did that to be able to run benchmarks benchmarks on multiple data sets with the same code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110#issuecomment-2185859889:30,benchmark,benchmarks,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110#issuecomment-2185859889,5,['benchmark'],['benchmarks']
Testability,"Hi, for `method='wilcoxon'` this is [Wilcoxon rank-sum test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test), and the scores are U_1 from methods in in the link. Higher absolute value of score -> lower p-value (more evidence the levels of expression between groups are different), higher score indicates higher expression, lower score -> lower expression.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1688#issuecomment-784969965:55,test,test,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1688#issuecomment-784969965,1,['test'],['test']
Testability,"Hi, looks great!. Ignore the tool, I think it’s a bit broken. I need to figure out what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that wi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:550,test,tests,550,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412,7,"['assert', 'test']","['assert', 'assertions', 'test', 'tests']"
Testability,"Hi, same confusion here.; According to: https://github.com/scverse/scanpy/issues/969#issuecomment-629667682; If I set `flavor ='cell_ranger'`, dose it mean I should not use `sc.pp.log1p(adata)` to ensure use the ""library size normalized counts""(not log)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1545#issuecomment-1501448104:249,log,log,249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545#issuecomment-1501448104,1,['log'],['log']
Testability,"Hi, sorry for the late response... > 1. Can we infer from such an analysis how much a pathway is upregulated? (e.g. by calculating the FC of the mean?) . It would be great to conclude for example, that Pathway X is 30% more active, in condition Y. I think so. Historically, this function has been used to score cell cycle and, in that case, one can say that cells are in a specific state *because* of a different distribution of signatures. This is generally true. I have myself used the score to underline cells with activated/depleted pathways. Also, I have used gene lists from KEGG or Reactome to score single cells. IMHO, once you have those values you can perform any statistical test on their distributions to tell if there's a difference in activation of a certain pathway.; There may be better ways to do this, but it's a start. > 2. How does in your opinion class-imbalance affect the analysis? For example, Condition A has 10 samples, while for Condition B,C.. I only have 3 each?. As @giovp pointed out, it should be ok, as long as you have enough cells to estimate the distributions. > 3. I am happy to provide the code for the density distributions to visualise the results of the gene-set-score function. What I usually do is to calculate the `embedding_density` for signatures, so that it's easy to visualize them on my embeddings (I usually cut values into quartiles).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1629#issuecomment-781323134:686,test,test,686,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1629#issuecomment-781323134,1,['test'],['test']
Testability,"Hi, thank you for the report. However, you deleted. > Put a minimal reproducible example that reproduces the bug in the code block below. Please do that, so we can create a regression test from it:. ```py; import numpy as np; import scanpy as sc; ad = AnnData(np.array([...])); sc.tl.rank_genes_groups(ad) # this line crashes without the fix; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1061#issuecomment-588270826:184,test,test,184,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061#issuecomment-588270826,1,['test'],['test']
Testability,"Hi, thanks again for your interest in GLM-PCA. We welcome its inclusion in scanpy, but some caveats are that it is about 10x slower than PCA and we are still working to improve its numerical stability and ability to handle sparse data matrices. . With that in mind, we have put together an implementation of [Pearson and deviance residuals](https://github.com/kstreet13/scry/blob/master/R/nullResiduals.R) as an approximation to GLM-PCA via the [scry R package](https://github.com/kstreet13/scry). These residuals, based on binomial and poisson approximation to multinomial, can be computed in closed form so they are computationally as fast as log-transforming. The sctransform method uses a negative binomial likelihood which doesn't have a closed form solution and is more complicated to implement (although we do recomment it from a statistical validity standpoint). . In addition to the null residuals, the scry package has an implementation of [feature selection via deviance](https://github.com/kstreet13/scry/blob/master/R/featureSelection.R), which may also be of interest as an alternative to highly variable genes. This is also a closed form computation. Both the feature selection and null residuals functions allow adjusting for categorical batch labels. I do hope to implement both of these in python eventually but it's pretty far down my to-do list. Given the functions are fairly simple, I welcome anyone to go ahead and copy them into python if they find it potentially useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-593125190:645,log,log-transforming,645,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-593125190,1,['log'],['log-transforming']
Testability,"Hi, thanks for your interest in scanpy!. I’ll try to comment on your observations here with your code example:. ```; import scanpy as sc; import numpy as np; ### Loading and preprocessing data; adata = sc.datasets.pbmc3k_processed(). ### Defining scale function; def mean_var(X, axis=0):; mean = np.mean(X, axis=axis, dtype=np.float64); mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); var = mean_sq - mean**2; # enforce R convention (unbiased estimator) for variance; var *= X.shape[axis] / (X.shape[axis] - 1); return mean, var; ```. As a first note of caution, in your code your function actually modifies the original data matrix, of the scanpy object - which is used again later in the snippet.; → We should create a copy of `X`. Else the code overwrites this object, and ends up comparing an object with itself, while simply using two names for it (this caused your `==` comparisons to evaluate as `True`, but is not what you intend to test).; ```; def my_scale_function(X, clip=False):; # need to make a copy of X; Y = X.copy(); mean, var = mean_var(Y, axis=0); Y -= mean; std = np.sqrt(var); #std[std == 0] = 1; Y /= std; if clip:; Y = np.clip(X, -10, 10); return np.matrix(Y); ```. As a second note of caution, floating point numbers should not be compared with the `==` operator (see for example [here](https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/)). → A more common way would be to use e.g. `np.allclose()` for this purpose. ```; ### Scanpy scale vs my_scale_function. print(""Rescaled with my_scale_function:""); mtx_rescaled = my_scale_function(adata.X). print(""Do a numpy check for closeness of floats:""); print(np.allclose(adata.X, mtx_rescaled)); ```. ```; Do a numpy check for closeness of floats:; False; ```. You can see that this test actually fails. This is because not all genes appear scaled, and your function now actually is doing that.; ```; adata.X.var(0); ```. ```; array([0.9996213 , 0.97964925, 0.29805112, ..., ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2629#issuecomment-1708220273:956,test,test,956,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629#issuecomment-1708220273,1,['test'],['test']
Testability,"Hi, that certainly seems like an improvement! I took the liberty to split out two bugs: #3168 and #3169. We had a similar fix #2875, which is hidden behind a `ctrl_as_ref` flag. I think since that fix is not yet released, we should rename the flag and unify both fixes behind it. Could you please; 1. check if issue #3169 is already fixed by installing scanpy’s git version and setting `ctrl_as_ref=True`; 2. Our backwards compatibility means that changes to the scoring need to be optional. This is why `tests/test_score_genes.py::test_score_with_reference` is failing here, and that’s what `ctrl_as_ref` is for. 	So since that option is not yet released and in order to fix the test, we should probably change that option to incorporate both improvements. We can rename it to reflect the two things it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3167#issuecomment-2252216712:505,test,tests,505,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167#issuecomment-2252216712,2,['test'],"['test', 'tests']"
Testability,"Hi, yes, i will start adding tests. ; And i think it can be useful but only if you have time for it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651#issuecomment-520006052:29,test,tests,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-520006052,1,['test'],['tests']
Testability,"Hi,. Currently using covariates in `sc.tl.rank_genes_groups()` is not implemented. In the Wilcoxon and t-test versions this is also not possible. However, in logistic regression this could be added. As a coarse approximation you could correct for batch using `sc.pp.combat()` and then use the corrected data instead of `adata.raw` (which is the default) to calculate marker genes. However, generally I would not recommend performing statistical analysis on batch-corrected data for other tests. Regarding your `anndata2ri` error... you could also check `adata.var` columns to see if any are categorical, but numeric.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/691#issuecomment-502549720:105,test,test,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691#issuecomment-502549720,3,"['log', 'test']","['logistic', 'test', 'tests']"
Testability,"Hi,. I just made a test and it seems that it is indeed a problem of non-sparse matrix. How can I render the matrix sparse again from one that is dense? Is there something similar to the `adata.X.todense()` command?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/641#issuecomment-491768644:19,test,test,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/641#issuecomment-491768644,1,['test'],['test']
Testability,"Hi,. I wonder whether you have a gene with constant expression value in there... that sounds like it might break the regression step. Otherwise, I would argue that subsetting to highly variable genes for regressing out a covariate is completely fine. In the end you are probably regressing out a covariate to improve the embedding. That is anyway only done on the highly variable genes, so other genes won't affect that. The only thing that might not be ideal is that you don't have the ""corrected"" data (data after regressing out your covariate) for plotting gene expression values, as you probably don't want to do any testing on the corrected data anyway. Still... it should be possible to do this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/667#issuecomment-497027543:621,test,testing,621,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/667#issuecomment-497027543,1,['test'],['testing']
Testability,"Hi,. I've tried to reproduce this with scanpy 1.4.3+80.g740c557 on the pbmc68k_reduced dataset and it works for me. I did the following:. ```; adata = sc.datasets.pbmc68k_reduced() ; sc.pp.filter_cells(adata, min_counts=10) ; sc.pp.filter_genes(adata, min_cells=5) ; sc.pp.normalize_per_cell(adata) ; sc.pp.log1p(adata); sc.tl.rank_genes_groups(adata, groupby='bulk_labels', groups=['CD56+ NK', 'Dendritic', 'CD34+'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); ```. The `sc.tl.rank_genes_groups()` call is taken more or less from your example. Could you check that this works for you, and otherwise provide a minimal reproducible example that I could test?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/706#issuecomment-505335006:702,test,test,702,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706#issuecomment-505335006,1,['test'],['test']
Testability,"Hi,. Thank you for your prompt reply and suggestions. I checked the `adata.obs[""n_counts]` and `adata.X` comparing them among the different tests and they are actually identical.; I also identified why there was a stochastic effect in the jitter plots inside the violin plots.; It is due to the `numpy` random seed; indeed, if you call `numpy.random.seed(N)` before calling the `scanpy.pl.violin` function, you obtain the same violin plots.; Notice that you have to call it before every call of `scanpy.pl.violin`.; It seems that the seed is reset somewhere in the code. Best wishes,; Simone",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/977#issuecomment-573112548:140,test,tests,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/977#issuecomment-573112548,1,['test'],['tests']
Testability,"Hi,. Thank you so much for the prompt response. I was able to make the comparisons following your method. As you suggested, I am going to try using MAST or limma for DEG testing in the future. Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447417086:170,test,testing,170,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447417086,1,['test'],['testing']
Testability,"Hi,. This can be done by subsetting your dataset to the cluster you're interested in and then using the `.obs` column where you store your condition information to do the differential testing. Something like this might work (note i didn't check for typos):. ```; WT_Donuts_clust1 = WT_Donuts[WT_Donuts.obs.leiden.isin(['1'])]; sc.tl.rank_genes_groups(WT_Donuts_clust1, 'condition', method='t-test', groups=['mut'], reference='ctrl', key_added='mut_up_ctrl_down'); sc.pl.rank_genes_groups(WT_Donuts_clust1, n_genes=5, key='mut_up_ctrl_down'); ```. This code makes the assumption that you have `adata.obs['condition']` which stores the categories `'mut'` and `'ctrl'`, and that you are interested in adata.obs['leiden'] == '1'`. Change these values to match your data.; In the above code you will get the top 5 genes that are up-regulated in `'mut'` compared to `'ctrl'`. If you want the up-regulated genes in `'ctrl'` compared to `'mut'`, just switch around the keywords above. There are of course better, more sensitive tests for differential expression than a t-test, but if you just want a quick top 5... then this should be fine. Also note that your use of `use_raw=False` may be dangerous. You should probably be doing a t-test on log-normalized data (not batch corrected, or scaled data, or data where any covariates were regressed out). The t-test assumes normally distributed data, which is approximated by log-normalization.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1035#issuecomment-583749392:184,test,testing,184,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035#issuecomment-583749392,8,"['log', 'test']","['log-normalization', 'log-normalized', 'test', 'testing', 'tests']"
Testability,"Hi,. We get this error without swapping axes:. The code is ; ```; genes = [""DES"", ""CD34"", ""COL1A1""]; sc.pl.stacked_violin(adata, genes, groupby = ""leiden_0.1"", ); ```; The error is ; ```; IndexError Traceback (most recent call last); <ipython-input-35-8f09494e5255> in <module>; ----> 1 sc.pl.stacked_violin(adata, genes, groupby = ""leiden_0.1""). ~/anaconda3/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); 929 axs_list.append(ax); 930 ax = sns.violinplot('variable', y='value', data=df, inner=None, order=order,; --> 931 orient='vertical', scale=scale, ax=ax, color=row_colors[idx], **kwds); 932 ; 933 if stripplot:. IndexError: list index out of range; ```. However, I would still consider the addition because in many cases where the amount of genes is considerable, if the user wants the genes to be in the rows, `swap_axes = True` should be necessary, and they would not be able to color the violins according to the clusters of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/465#issuecomment-461450618:459,log,log,459,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/465#issuecomment-461450618,1,['log'],['log']
Testability,"Hi,. You are correct that DE testing should be performed on raw or normalized data, but not on batch-corrected data. `sc.tl.rank_genes_groups()` doesn't let you include covariates, but there are plenty of methods that do. You could look into `diffxpy` for this, which is also based on AnnData and is easily integrated into a scanpy script. Otherwise, I have a case study for a best practices workflow, which uses MAST. You could reuse code from there as well. You can find the case study [here](https://www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/669#issuecomment-497118928:29,test,testing,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/669#issuecomment-497118928,1,['test'],['testing']
Testability,"Hi,. You could just create a new `.obs` variable with the two groups and the perform `sc.tl.rank_genes_groups()` over this variable. For example, you could do something like this:. ```; adata.obs['groups'] = ['group 1' if int(i) < 9 else 'group 2' for i in adata.obs['louvain']]; sc.tl.rank_genes_groups(adata, groupby='groups', key_added='group_DE_results'); ```. as there are only two groups the top-ranked genes for either groups will be the up-regulated genes in that group (and down-regulated in the other group) that are most differentially expressed between the groups. . You should however note that `rank_genes_groups` is not a particularly sensitive test for differential gene expression. While it is good for a quick exploratory analysis, other tools like limma or MAST may give you more DEG results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447140464:660,test,test,660,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447140464,1,['test'],['test']
Testability,"Hi,. `sc.tl.rank_genes_groups()` treats each gene as an independent variable in the test. Thus, the only difference if you were to subset the genes would be that the multiple testing correction would be over fewer genes. You can also do that manually by looking at the `adata.uns['rank_genes']['pvals'][CLUSTER_ID]` and doing the multiple-testing correction yourself over the gene set you care about. However, the p-values of this test are inflated anyway, and therefore they should be used with caution. You should be able to extract your test results of interest by doing something along the lines of this:; ```; CLUST_ID = 0; gene_list = ['Gabrg1', 'Ntrk1', 'Htr1a', 'Plaur', 'Il31ra', 'Gabrg3', 'P2rx3', 'Oprk1', 'P2ry1', 'Cnih3']; gene_mask = [gene in gene_list for gene in adata.uns['rank_genes']['names'][CLUST_ID]]; results = adata.uns['rank_genes']['pvals'][CLUST_ID][gene_mask]; ```. Then you need to perform multiple testing correction over those p-values. And that would be the result you would get from a subsetting. However, multiple-testing over only those values, assumes you will not use the other gene results for anything. If you use the other gene results for something else, then you should just use the results of `sc.tl.rank_genes_groups()` as it is. Also note that `sc.tl.rank_genes_groups()` doesn't really tell you the contribution of genes to the clustering, but it just tells you what genes are characteristic of a cluster in the output. Those aren't the same things. For example, one gene could have been responsible for partitioning the data into 2 parts, but then after subclustering those 2 parts it may not show up as a marker gene in the `sc.tl.rank_genes_groups` results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/748#issuecomment-515061065:84,test,test,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748#issuecomment-515061065,7,['test'],"['test', 'testing']"
Testability,"Hi,. thanks for you interest in scanpy!. Does this issue still persist for you?; If yes, is it possible to extend your example so that I can test it too, to see what might cause the computation to fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2472#issuecomment-1718993973:141,test,test,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472#issuecomment-1718993973,1,['test'],['test']
Testability,"Hi,. thanks for your interest in scanpy!. Regarding your question on ordering, and test statistic scores vs p-values:. 1. The structured array is [ordered according to scores](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.rank_genes_groups.html#scanpy.tl.rank_genes_groups), not the p-values. 2. For tests with a signed test statistic (for example the t-test and the wilcoxon test), a ‘larger’ score does necessarily correspond to a lower p-value: rather, a score ‘further away from 0’ corresponds to lower p-value. Hence as currently the output stored in `adata.uns['rank_genes_groups']` is ordered according to scores, this does not mean it is ordered according to p-values. To the part where you mention you went into the code: My best guess is you refer to [this computation](https://github.com/scverse/scanpy/blob/1df92d61f00cec83b2ab2feb9c977cfcda84ebc0/scanpy/tools/_rank_genes_groups.py#L290). Here, considering the absolute value is used to get the two tails of the distribution when using the survival function (`stats.distribution.sf`). Generally if you’re interested in the Wilcoxon computation and the normal approximation used here, you can check [this](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test) for a start. This also introduces the relation between the scores and the p-value. Hope this helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2586#issuecomment-1717970663:83,test,test,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586#issuecomment-1717970663,5,['test'],"['test', 'tests']"
Testability,"Hi,; I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`?. Something like this:; ```; adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0); sc.pp.regress_out(adata, genes_of_interest); ```; If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:; ```; adata_tmp = adata.copy(); sc.pp.scale(adata_tmp); adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0); sc.pp.regress_out(adata, genes_of_interest); ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/492#issuecomment-465046253:769,test,tested,769,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492#issuecomment-465046253,1,['test'],['tested']
Testability,"Hi,; Thank you so much! It worked this time! I got a lot ""Keyerror"" before, but I tried your tested code, it worked perfectly! ; I really appreciate it!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1035#issuecomment-585508877:93,test,tested,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035#issuecomment-585508877,1,['test'],['tested']
Testability,"Hi,; could you please try ; ```; sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata); ```; As highly_variable_genes expects logarithmized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-445038953:127,log,logarithmized,127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-445038953,1,['log'],['logarithmized']
Testability,"Hi. Maybe I can help a little as well. Typically batch correction or data integration methods would be used to obtain good clustering of the data, however once differential testing is performed it is still unclear whether the corrected data can or should be used (no batch correction method is perfect and may overcorrect). The standard strategy would be to correct for batch, and any other covariates that you are not interested in for the clustering process. Once you have the clusters, it is standard practice to go back to the raw data and use a differential testing algorithm that allows you to account for batch and other technical covariates in the model (e.g. MAST).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/168#issuecomment-395726806:173,test,testing,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/168#issuecomment-395726806,2,['test'],['testing']
Testability,"Hi. This is unlikely to be a scanpy issue. You probably don’t have enough memory or there’s some problem with your Jupyter configuration. But in any case, we need more information to tell which one it is. Please share the logs that `jupyter lab` created, especially any stack traces around “kernel died, restarting”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2675#issuecomment-1750301889:222,log,logs,222,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675#issuecomment-1750301889,1,['log'],['logs']
Testability,"Hm, I am a bit lost wrt to the checks failing @giovp ; the doc build doesn't show any logs and travis fails because of black complaining about scanpy/tools/_sim.py and some version checking problem. None of this seems related to my PR 🤔",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1811#issuecomment-827726391:86,log,logs,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1811#issuecomment-827726391,1,['log'],['logs']
Testability,"Hm, I've wanted to add a PAGA notebook to the tests and I'm struggling to get it to run on travis. The tests run through for me on a MacBook and on a remote linux machine, but travis seems even to be able to produce differently-shaped output images: https://travis-ci.org/theislab/scanpy/jobs/450416143. My current suspicion is that networkx does something strange as it really only affects the graph plot... I'll investigate further, but if you've seen this already, a hint would be very welcome! 🙂",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-435650013:46,test,tests,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-435650013,2,['test'],['tests']
Testability,"Hm, strange, the notebook is in the tests... I also just ran it through myself, manually, everything got me exactly the same results as available online: my versions are; ```; scanpy==1.3.7+86.g2c80c7a anndata==0.6.17+1.ga0cd0c6 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ```. Could it be that you're using an older anndata or scanpy or something? I think I added the notebook to the tests around Scanpy 1.3 or so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/445#issuecomment-457346216:36,test,tests,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445#issuecomment-457346216,2,['test'],['tests']
Testability,"Hm, the tests work for me. And I never set up a specific environment. Obviously, they also run through on Travis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-432352461:8,test,tests,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-432352461,1,['test'],['tests']
Testability,"Hm, there’s something messed up with the test runner. It fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:41,test,test,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,12,['test'],"['test', 'tests']"
Testability,"Hm, yes it's nice that things are simpler now, but the point of the script before was to use the fast installation of the conda binaries... . Before your commit: 3 min 46 s test time (https://travis-ci.org/theislab/scanpy/builds/454438531?utm_source=github_status&utm_medium=notification). After your commit: 6 min 46 s test time (https://travis-ci.org/theislab/scanpy/builds/454487170?utm_source=github_status&utm_medium=notification). While the 3 min 46 s are way too long, there is still a good chance that you realize that your commit broke everything. After almost 7 min, you're almost always doing something else already. I also feel kind of bad about travis's servers. ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/360#issuecomment-439746463:173,test,test,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/360#issuecomment-439746463,2,['test'],['test']
Testability,"Hmm, I also consistently get a slightly different result for computing the mean between numpy and numba (I think it's one floating point step). When you were seeing differences, did they show up as different with `np.allclose`? If they did, I think we can go with adding a small reference test that checks with `np.testing.assert_almost_equal`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1890#issuecomment-866651210:289,test,test,289,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890#issuecomment-866651210,2,['test'],"['test', 'testing']"
Testability,"Hmm, I think it's more complicated than that. First, cell type labels may not come from clustering. Even if it's the case, the design of Louvain does not rely on univariate mean difference between groups due to the distance metrics used in kNN graph, which take all genes into account at once. . Besides, I believe that how cell types are defined e.g. by biologist's manually annotation of each cell, Louvain, bulk comparison etc. doesn't really make the null hypothesis invalid. t-test just tests if the means are the same or not. Regarding false positives with random clustering, that's why we have Bonferroni, no? But this is now a different story about p-values and multiple testing correction in general. So it's not our duty to solve it in rank_genes_group function. I'd rather prefer reporting a p-value (or maybe t-stat) and letting the user decide how valid/useful it is for his/her research instead of not outputting it with the consideration of the chance that it's not valid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-425375105:482,test,test,482,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-425375105,3,['test'],"['test', 'testing', 'tests']"
Testability,"Hmm, I'm having trouble reproducing using the same release. Could be an issue with an underlying library? I'm using a slightly newer scipy. <details>; <summary> My environment </summary>. ```; -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; IPython 7.21.0; PIL 8.1.0; anndata 0.7.5; backcall 0.2.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; ipython_genutils 0.2.0; jedi 0.17.2; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; llvmlite 0.35.0; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; numba 0.52.0; numexpr 2.7.2; numpy 1.20.1; packaging 20.9; pandas 1.2.2; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0.7.0; pygments 2.8.1; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.1; scipy 1.6.1; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; storemagic NA; tables 3.6.1; traitlets 5.0.5; wcwidth 0.2.5; -----; Python 3.8.5 (default, Sep 4 2020, 02:22:02) [Clang 10.0.0 ]; macOS-10.15.7-x86_64-i386-64bit; 16 logical CPU cores, i386; -----; Session information updated at 2021-03-20 16:27; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1749#issuecomment-803253215:1018,log,logical,1018,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749#issuecomment-803253215,1,['log'],['logical']
Testability,"Hmm, I’m pretty happy with my self-documented test code:. ```py; def test_deferred_imports(imported_modules):; slow_to_import = {; 'umap', # neighbors, tl.umap; 'seaborn', # plotting; 'sklearn.metrics', # neighbors; 'scipy.stats', # tools._embedding_density; 'networkx', # diffmap, paga, plotting._utils; # TODO: 'matplotlib.pyplot',; # TODO (maybe): 'numba',; }; falsely_imported = slow_to_import & imported_modules; > assert not falsely_imported; E AssertionError: assert not {'scipy.stats'}; ```. Do you think this could be clearer?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/797#issuecomment-537474116:46,test,test,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797#issuecomment-537474116,4,"['Assert', 'assert', 'test']","['AssertionError', 'assert', 'test']"
Testability,"Hmm, seems like `PCA` with `svd_solver='arpack'` works differently in sklearn 1.5 and flips the coordinates in some tests:. https://github.com/scikit-learn/scikit-learn/issues/28826. E.g. this used to work, now it doesn’t. ```py; from __future__ import annotations. import numpy as np; from sklearn.decomposition import PCA. data = np.asarray([[-1, 2, 0], [3, 4, 0], [1, 2, 0]]).T; expected = np.array(; [[-1.579575e-15, 1.490712], [-2.44949, -0.745356], [2.44949, -0.745356]],; dtype=np.float32,; ). pca = PCA(n_components=2, svd_solver=""arpack"", random_state=np.random.RandomState(0)); transformed = pca.fit_transform(data).astype(np.float32); np.testing.assert_almost_equal(transformed, expected, decimal=5); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3047#issuecomment-2098389353:116,test,tests,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047#issuecomment-2098389353,2,['test'],"['testing', 'tests']"
Testability,"Hmm, you're right. I think it must have been the that the ordering of cells in the `adata` object was also non-random. We had this quite a bit in the benchmarking data integration project while plotting batch. In several methods (e.g., scanorama), individual batch anndata objects are concatenated to generate the final output, which results in batch-ordered anndata objects. . Maybe instead of just having `sort_order=False` it would be better to have randomized ordering for plotting categorical variables? Unless it is an ordered categorical I guess.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1588#issuecomment-760249638:150,benchmark,benchmarking,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1588#issuecomment-760249638,1,['benchmark'],['benchmarking']
Testability,"Hmm... you are right, that should also create an error by the above logic. It does look like this check is done for the case that `adata.n_vars < n_comps` here:; https://github.com/theislab/scanpy/blob/be1a0555252cfd97b9d00f51dc5fbab462588da0/scanpy/preprocessing/_simple.py#L472-L477. I'm not sure why that wasn't also done for `n_obs`. @Koncopd you made this fix at the time... any reason for not also checking `adata.n_obs` in the same way? Could quickly add a check for `adata.n_obs` unless there is a reason not to @ivirshup, @flying-sheep?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1051#issuecomment-586494795:68,log,logic,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051#issuecomment-586494795,1,['log'],['logic']
Testability,"Hmmm, you got it to successfully run? The last thing I had posted was failures in testing (see above)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-367706813:82,test,testing,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-367706813,1,['test'],['testing']
Testability,"How about an empty `DataFrame` instead of `None`? I think I prefer `len(results) == 0` to `results is None`. Also, I need to look into the arguments to `gprofiler` a bit more before this is ready to merge. I'd also like to add tests, but probably ones that are optional. Does `scanpy` have a preferred way of adding tests that don't run by default?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467#issuecomment-464278846:227,test,tests,227,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-464278846,2,['test'],['tests']
Testability,How are you building the package and running the tests? Are you working with a clone of the repo?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048#issuecomment-969078321:49,test,tests,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048#issuecomment-969078321,1,['test'],['tests']
Testability,"How can one get a DEG table with a pts column for each cluster? So that for each group there would be 4 columns: 'names', 'logfoldchanges', 'pvals_adj' and 'pts'?. Manual sorting from 2 files is not quite optimal:; ```; sc.tl.rank_genes_groups(adata, 'cell_types', method='wilcoxon', pts=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names; degs_by_cluster = pd.DataFrame({group + '_' + key[:14]: result[key][group]; for group in groups for key in ['names', 'logfoldchanges', 'pvals_adj']}); degs_by_cluster.to_csv(""DEG_adata_cell_types_pct_to_sort.csv""); pts=pd.DataFrame(adata.uns['rank_genes_groups']['pts']); pts.to_csv(""pts_adata.csv""); ```. Could you help with a more efficient way to do that? ; @fidelram @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1455#issuecomment-1066545407:123,log,logfoldchanges,123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455#issuecomment-1066545407,2,['log'],['logfoldchanges']
Testability,"How did you installed scanpy?. Try:. conda install --file requirements.txt. this may install all the right versions of the packages that you need. On Thu, Oct 4, 2018 at 2:26 AM ar-baya <notifications@github.com> wrote:. > Hi, I am reproducing this tutorial; > https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb; >; > the line sc.pp.neighbors(adata) produces the following error:; >; > Inconsistency detected by ld.so: dl-version.c: 205:; > _dl_check_map_versions: Assertion `needed != NULL' failed!; >; > Ubuntu 18.04; > Python 3.6.6; >; > scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4; > scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; >; > Can you help me? Thank You; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/280>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1Sgm2UxCRL2y2-EGlah7YmtIrmmeks5uhVXGgaJpZM4XHKo6>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-426896350:513,Assert,Assertion,513,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-426896350,1,['Assert'],['Assertion']
Testability,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console; $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no; Numba function called from a non-threadsafe context. Try installing `tbb`.; Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads.; - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):; File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper; File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _; File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper; File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get; File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task; File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task; File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks; File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", li",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3335#issuecomment-2457625478:342,test,test,342,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335#issuecomment-2457625478,2,['test'],"['test', 'tests']"
Testability,"Huh, I don't think the tests are checking what I thought they were. . 1. It doesn't look like you can have an AnnData object with a Dask array, what am I doing wrong here?. ```python; from anndata import AnnData; import numpy as np; import dask.array as da; from scipy.sparse import csr_matrix. X_total = [[1, 0], [3, 0], [5, 6]]. adata = AnnData(np.array(X_total), dtype='float32'); print(type(adata.X) # is a numpy matrix, as expected. adata = AnnData(csr_matrix(X_total), dtype='float32'); print(type(adata.X) # is a sparse matrix, as expected. adata = AnnData(da.from_array(X_total), dtype='float32'); print(type(adata.X) # is a numpy array NOT a dask array, not what I expected; ```. 2. The change I made to `_normalize_data()` changed coercion of `counts`, not `X`. When I stepped through this private function, it seemed like things were working the way I'd expected, but there's a lot of other stuff happening before & afterwards in `normalize_total()` which I haven't looked at much. What combinations of inputs to `_normalize_data()` need to be supported?; * numpjy `X`, numpy `counts`; * dask `X`, dask `counts` ; * csr_matrix `X`, csr_matrix `counts` . Combinations?; * numpjy `X`, dask `counts`; * dask `X`, numpy `counts`; * numpjy `X`, csr_matrix `counts`; * csr_matrix `X`, numpy `counts`; * dask `X`, csr_matrix `counts`; * csr_matrix `X`, dask `counts`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1663#issuecomment-781880180:23,test,tests,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1663#issuecomment-781880180,1,['test'],['tests']
Testability,"Huh, it looks like pandas does not have the option for doing a stable sort here, so maybe we should change the test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1584#issuecomment-759955470:111,test,test,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1584#issuecomment-759955470,1,['test'],['test']
Testability,"I actually had not set that attribute. But I just tested it now. ```; sc.settings.n_jobs = 15; sc.pp.neighbors(adata_B, n_neighbors=100, n_pcs=11); ```. OR. ```; sc.settings.n_jobs = 15; with parallel_backend('threading', n_jobs=15):; sc.pp.neighbors(adata_B, n_neighbors=100, n_pcs=11); ```. and in either case it only uses one cpu and takes the same amount of time as above.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/913#issuecomment-552997835:50,test,tested,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/913#issuecomment-552997835,1,['test'],['tested']
Testability,"I added a scalar dataset to the `scanpy/tests/_data/10x_data/1.2.0/multiple_genomes.h5` file in the last commit. Diff between the h5ls of old vs new files:. ```diff; @@ -6,6 +6,7 @@; /another_genome/genes Dataset {343/4681}; /another_genome/indices Dataset {12/8192}; /another_genome/indptr Dataset {13/8192}; +/another_genome/scalar_dataset Dataset {SCALAR}; /another_genome/shape Dataset {2/16384}; /hg19_chr21 Group; /hg19_chr21/barcodes Dataset {12/3640}; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2344#issuecomment-1267397231:40,test,tests,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344#issuecomment-1267397231,1,['test'],['tests']
Testability,I added a test and a release node,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2589#issuecomment-1666905237:10,test,test,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589#issuecomment-1666905237,1,['test'],['test']
Testability,I added a test that fails on master,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2546#issuecomment-1625353939:10,test,test,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2546#issuecomment-1625353939,1,['test'],['test']
Testability,"I added helper functions. I am working on the tests.; Apparently there's a test https://github.com/theislab/scanpy/blob/fc24dfc62c049a0d0c9cc491d4647d03b52bfb10/scanpy/tests/test_rank_genes_groups_logreg.py#L22; that fails locally in my machine.; It is because after `rank_genes_groups` categories are naturally sorted. I don't think this is due to my changes, but let me know how can I help. I am unsure why it is failing on Travis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-479539907:46,test,tests,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-479539907,3,['test'],"['test', 'tests']"
Testability,I added tests for both louvain and leiden with restrict parameter. Please review the test code to be sure it is clear and working.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-479587681:8,test,tests,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-479587681,2,['test'],"['test', 'tests']"
Testability,I added two tests in `scanpy/tests/test_embedding_density.py`... one of them just to test if the plotting functions run. Should this have been placed in a different file?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/543#issuecomment-476406754:12,test,tests,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-476406754,3,['test'],"['test', 'tests']"
Testability,I added unit tests and reformated the code.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/812#issuecomment-537955879:13,test,tests,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812#issuecomment-537955879,1,['test'],['tests']
Testability,"I addressed some of the points in your review already and will finish latest on Monday :). > > tests that check if combinations of input arguments lead to expected output (in terms of returned shapes/columns/...) and don't break the function; > > tests that check if warnings/errors are raised for ""common mistakes"" (inappropriate data, nonsense input argument combinations..); > ; > yes both makes sense, it would also be useful to come up with a dummy example for which the actual output could be tested against. This is done in seurat_v3 for instance, but in that case it's kind of straightforward because the ""expected"" is the output computed with original implementation (and as you catched in #1732 it's still might not be enough smile ).; > another random thing that comes to mind re this specific case is to make sure that indexing etc. is consistent and robust, as you seem to have to sort and resort a fair bit in the hvg implementation. Sounds good, thanks for the input! I will prepare some tests early next week.; ; > on another note, I was thinking if it makes sense to also release a short tutorial together with the PR (that would be on theislab/scanpy_tutorials) ? I think that for a lot of people the term ""pearson residuals"" could be alienating, and so they'd rather stick to `normalize_total` for comfort (but they shouldn't!). So maybe just something easy like pearson res norm + umap and hvg plots ? curious to hear what you and the others @ivirshup @LuckyMD think about it. I think that would be really nice - I'd very happy prepare to some examples if everyone agrees that this would be useful to have :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-797689998:95,test,tests,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-797689998,4,['test'],"['tested', 'tests']"
Testability,"I agree and had also noticed it. Double logs make no sense. It should be the log2 basis. @a-munoz-rojas, as you implemented this, would you make PR to fix it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-470311545:40,log,logs,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470311545,1,['log'],['logs']
Testability,"I agree with @LuckyMD about the points regarding covariates. . With respect to two group comparisons without confounding, rank-sum tests have less statitical power than t-tests (https://stats.stackexchange.com/questions/130562/why-is-the-asymptotic-relative-efficiency-of-the-wilcoxon-test-3-pi-compared), disclaimer I haven't checked this proof, I think this is a standard statistics result though, this is also discussed here https://stats.stackexchange.com/questions/121852/how-to-choose-between-t-test-or-non-parametric-test-e-g-wilcoxon-in-small-sampl. I havent run simulations to check how big the influence of the difference in power is on the kind of data we encounter. However, as also pointed out by the second link, violations of the distributional assumptions for t-test impact these results and these violations will be major on scRNAseq. Intuitively I would therefore tend to rank-sum tests. With respect to [diffxpy](https://github.com/theislab/diffxpy): We can account for other noise models in the two-group comparisons by performing model fitting, tutorial [here](https://github.com/theislab/diffxpy_tutorials/blob/master/diffxpy_tutorials/test/single/wald_test.ipynb). The bioarxiv will hopefully be up in the next few weeks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447874358:131,test,tests,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447874358,7,['test'],"['test', 'test-', 'test-or-non-parametric-test-e-g-wilcoxon-in-small-sampl', 'tests']"
Testability,"I agree with malte that there's so much more ML out there that just adding a function cause it can be quickly implemented can be risky.; however if we're not the ones to try then who else should. so what if we test the leiden_multiplex in comparison to seurat's WNN on the tutorial data, and decide then? I would be surprised if we didn't find a set of params for leiden_multiplex that allows to replicate the seurat clustering results. also comes to mind similarity network fusion (implemented for citeseq in the citefuse package). prob a project of its own sake tbh. ; happy to help with this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1818#issuecomment-857832028:210,test,test,210,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818#issuecomment-857832028,1,['test'],['test']
Testability,"I agree, I've been trying to reduce the dataset and save it as 10x_h5 format again but it seems to be more complicated than I thought. I think it would be best to have an 10x_h5 format so to also use it for the read function test. Also, yes will only keep the lowres image",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1024#issuecomment-586196692:225,test,test,225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024#issuecomment-586196692,1,['test'],['test']
Testability,"I also just found this: https://docs.pytest.org/en/stable/pythonpath.html#import-modes. > `importlib`: new in pytest-6.0, this mode uses importlib to import test modules.; > […]; > makes test modules non-importable by each other.; > […]; > ; > **We intend to make importlib the default in future releases.**",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1528#issuecomment-741748332:157,test,test,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528#issuecomment-741748332,2,['test'],['test']
Testability,"I am also getting the error `RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion)` when running `sc.pp.highly_variable_genes(adata, min_mean=1.7, max_mean=5, min_disp=0.5, flavor='seurat')` on log scale data in the adata.X slot with mean=0 and max=16.336065. Any ideas?. Update: I just noticed that my adata.X contains a numpy array instead of a sparse matrix. Perhaps that's the issue? Will try updating to a sparse matrix and will report back",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-718294561:74,log,log,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-718294561,3,['log'],['log']
Testability,"I am also getting the error when running. sc.pp.neighbors(). AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. I tried pip uninstall numba and pip install numba==0.52.0 and numba==0.51.0, but nothing works. I had umap-learn 0.4.6, and updating it resolved the issue for me:; conda install -c conda-forge umap-learn",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799#issuecomment-867004309:61,Assert,AssertionError,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799#issuecomment-867004309,1,['Assert'],['AssertionError']
Testability,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python; colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]; test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames); test = test.stack(level=1).reset_index(); test[""group""] = test[""group""].astype(""int""); test.sort_values('group', inplace=True). test; ```; I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1530#issuecomment-1236487688:149,log,logreg,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530#issuecomment-1236487688,14,"['log', 'test']","['logfoldchange', 'logistic', 'logreg', 'test']"
Testability,"I am experiencing a similar issue with a dataset I am using. This runs fine:; ```; variable_genes_min_mean = 0.01; variable_genes_max_mean = 5; variable_genes_min_disp = 0.5. sc.pp.filter_genes_dispersion(adata_gex, ; min_mean=variable_genes_min_mean, ; max_mean=variable_genes_max_mean, ; min_disp=variable_genes_min_disp,; flavor='seurat',; log = True); ```. But this:; ```; variable_genes_min_mean = 0.01; variable_genes_max_mean = 5; variable_genes_min_disp = 0.5. sc.pp.highly_variable_genes(adata_gex, ; min_mean=variable_genes_min_mean, ; max_mean=variable_genes_max_mean, ; min_disp=variable_genes_min_disp,; flavor = 'seurat') ; ```. Throws the following error: ; ```; /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scipy/sparse/data.py:135: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: overflow encountered in log; dispersion = np.log(dispersion); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-71-69d6424effb2> in <module>; 3 max_mean=variable_genes_max_mean,; 4 min_disp=variable_genes_min_disp,; ----> 5 flavor = 'seurat') . /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preproces",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026:343,log,log,343,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026,1,['log'],['log']
Testability,I am not sure what king of test. I don't want to add another `save_and_compare_images` test because plots seem to depend on the system at least sometimes (i have 3 failing plotting tests locally but they run fine here).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1942#issuecomment-878118310:27,test,test,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1942#issuecomment-878118310,3,['test'],"['test', 'tests']"
Testability,"I am running Python 3.6.0. The following is the output of running just the snippet above:. > File ""test.py"", line 13, in <module>; print(ViewArgs(None, ""a"")); TypeError: __new__() missing 1 required positional argument: 'keys'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/734#issuecomment-509615807:99,test,test,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734#issuecomment-509615807,1,['test'],['test']
Testability,"I am using the latest M1 macbook pro with python 3.10.3. For some reason if you clone the repository then compile it works in python 3.9+; I cannot explain why the release tarball has issues. As per some other documentation, it is because [tp_print has been removed from type objects for python 3.9+.](https://docs.python.org/3/c-api/typeobj.html) See below. So, if you clone the repository using git and then install it works! (I am sure there is an explanation). ```; test@mac ~/PythonPackages/forceatlas2$ git pull; Already up to date.; test@mac ~/PythonPackages/forceatlas2$ pip3 install . --user; Processing /Users/test/PythonPackages/forceatlas2; Preparing metadata (setup.py) ... done; Requirement already satisfied: numpy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.21.5); Requirement already satisfied: scipy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.8.0); Requirement already satisfied: tqdm in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (4.63.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... done; Created wheel for fa2: filename=fa2-0.3.5-cp310-cp310-macosx_12_0_x86_64.whl size=155419 sha256=23d907bfec5df0e9d0d522865d1c288b1f8894134bd61b6c5a02467128dfd102; Stored in directory: /private/var/folders/0s/67yn6b6n3lx4882xx_86ps2m0000gp/T/pip-ephem-wheel-cache-i69s_t3j/wheels/51/1c/a5/5a9ef4f0bc9387d300190bc15adbb98dbda9d90c6da9c2da04; Successfully built fa2; Installing collected packages: fa2; Successfully installed fa2-0.3.5 ; test@mac ~/PythonPackages/forceatlas2$; ```. However, if you try to install the release version you get an error:. ```; test@mac ~/PythonPackages$ wget https://github.com/bhargavchippada/forceatlas2/archive/refs/tags/v0.3.5.tar.gz; --2022-03-24 02:54:21-- https://github.com/bhargavchippada/forceatlas2/archive/refs/tags/v0.3.5.tar.gz; Resolving github.com (github.com)... 140.82.114.3; Connecting to github.com (github.com)|140.82.114.3|:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:470,test,test,470,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,6,['test'],['test']
Testability,I answered that back then already. - https://github.com/scverse/scanpy/pull/2235#discussion_r850302669; - https://github.com/scverse/scanpy/pull/2235#discussion_r850304636. This PR has exactly the scope necessary to separate test utils and tests. The only thing that I can think of to add to those answers is that the repeated code for all the data fixtures is necessary to make editors understand them. A more dynamic way to make all those fixtures breaks ctrl/cmd-clicking fixtures.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235#issuecomment-1597183580:225,test,test,225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1597183580,2,['test'],"['test', 'tests']"
Testability,I believe numba will always throw a warning if some part of the requested compilation failed. We could add tests for compilation based on this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/462#issuecomment-461279367:107,test,tests,107,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/462#issuecomment-461279367,1,['test'],['tests']
Testability,"I can add the changes you suggested but. >since if there was a bug in how `filter_rank_genes_groups` sets those values this test would still pass. this is not a test of `filter_rank_genes_groups`, we have a separate test for this. Do you think we need to double check this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1942#issuecomment-879832703:124,test,test,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1942#issuecomment-879832703,3,['test'],['test']
Testability,"I can confirm this as a working workaround. Thank you @michalk8 . > @pati-ni; > I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy.; > Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1298#issuecomment-662450011:261,test,tested,261,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298#issuecomment-662450011,1,['test'],['tested']
Testability,"I can get the data by skipping the spatial plot. . If I run this in a fresh IPython session I get the attached plot. ```; import scanpy; from matplotlib import pyplot; from scanpy.tests.test_embedding_plots import HERE; from scanpy.plotting._tools import scatterplots; adata = scanpy.read_visium(HERE / ""_data"" / ""visium_data"" / ""1.0.0""); adata.obs = adata.obs.astype({'array_row': 'str'}); data_points, components = scatterplots._get_data_points(adata, ""spatial"", None, None, None); pyplot.scatter(data_points[0][:, 0], data_points[0][:, 1]); pyplot.savefig(""visium.png""). ```; ![visium](https://user-images.githubusercontent.com/975038/141928846-993b0fc9-33ad-4edf-b0b3-44b56274494e.png). If I call scanpy.pl.spatial before I call pyplot.scatter I get the black plot, so it's probably some default isn't right.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048#issuecomment-969888153:180,test,tests,180,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048#issuecomment-969888153,1,['test'],['tests']
Testability,"I can reproduce this bug on my machine as well. I can supply additional information or context if needed, and I can test fixes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2322143716:116,test,test,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2322143716,1,['test'],['test']
Testability,I can test tomorrow,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2276255849:6,test,test,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2276255849,1,['test'],['test']
Testability,I can understand your line of reasoning @a-munoz-rojas. But is it not also dangerous to allow a user an interpretation which may be incorrect? I think outputting logFC values is great... I just have issues with calling the other output P-values. It is at the very least contentious whether they are measures of significance.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-425737907:162,log,logFC,162,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-425737907,1,['log'],['logFC']
Testability,"I checked the new tests locally, can't work out why they're not running in the CI here- hopefully it's obvious to you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-728104293:18,test,tests,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-728104293,1,['test'],['tests']
Testability,"I completely agree. It should simply go in the `test` extra. @tomwhite, would you do that? It might that the tests don't run through on Travis for some reason and then, I guess, it would be great if you could look into it (would for sure be a problem that would pop elsewhere, too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/439#issuecomment-460071018:48,test,test,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-460071018,2,['test'],"['test', 'tests']"
Testability,"I could probably be convinced to include `radius_neighbors`. I'd mainly need a test case. My initial opposition was that (1) it's a pretty trivial implementation and (2) without a real example I'm not sure if it's missing any obvious edge cases. For n-rings, I think that walking some steps from each node generalizes beyond graph construction, and might be reasonable to have as a separate method. I also haven't seen any recommendations about how to weigh the edges, which I think is pretty important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-707610846:79,test,test,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-707610846,1,['test'],['test']
Testability,"I created a PR to this branch to add GPU support for :; *`tl.rank_gene_groups` with method='logreg'; *`tl.embedding_density`; *`correlation_matrix`; *`diffmap`; I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow.; The default pca solver for device GPU is now ""auto""; I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy.; ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1189986399:92,log,logreg,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-1189986399,2,['log'],['logreg']
Testability,"I definitely don't define the consensus, but I normally prefer FDR correction. It makes a bit more sense to me to correct for a false discovery rate, rather than a test-based error, if you are only interested in the rejected null hypotheses. . They also test for FDR control in a [recent comparison of differential testing methods](http://www.nature.com/doifinder/10.1038/nmeth.4612).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/289#issuecomment-428239213:164,test,test-based,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289#issuecomment-428239213,3,['test'],"['test', 'test-based', 'testing']"
Testability,"I didn't change any defaults I think. Test fails in rename_category of pandas in pbmc, not sure it's related.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/640#issuecomment-495574383:38,Test,Test,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/640#issuecomment-495574383,1,['Test'],['Test']
Testability,I didn't know about `testing.setup()` I will take a look. Seems very promising.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-435785931:21,test,testing,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-435785931,1,['test'],['testing']
Testability,I don't know what is happening with the new matplotlib but I had to increase the tolerance for the image comparison in order for the tests to pass. Locally I noticed small differences in the margins and axis labels. Also I noticed that running a single test is different than running several tests at once. This probably has to do with some internal matplotlib parameters that are modified. . At least the tests are passing now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-426281432:133,test,tests,133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-426281432,4,['test'],"['test', 'tests']"
Testability,I don't know what makes the tests fail with dask in utils,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3017#issuecomment-2131272074:28,test,tests,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017#issuecomment-2131272074,1,['test'],['tests']
Testability,I don't know why the tests related to violin plots fail. I assume that it has to do with different libraries that produce slightly different shapes. But without access to the images generated during the testing would be difficult to say.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/228#issuecomment-411070568:21,test,tests,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/228#issuecomment-411070568,2,['test'],"['testing', 'tests']"
Testability,I don't think we need to test against 3.8 until a stable release is out. I'm thinking we can just drop that from travis and merge?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/704#issuecomment-506145082:25,test,test,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704#issuecomment-506145082,1,['test'],['test']
Testability,"I don't think you'll be able to do this with the tracksplot. Were you looking for something more like a volcano plot?. I've used something like this snipped (using `hvplots`) for these:. ```python; import hvplot.pandas. def plot_volcano(dedf):; dedf = dedf.copy(); dedf = dedf[dedf[""pvals""].notnull()]; dedf.loc[dedf[""logfoldchanges""] == np.inf, ""logfoldchanges""] = 10; dedf.loc[dedf[""logfoldchanges""] == -np.inf, ""logfoldchanges""] = -10; return dedf.hvplot.scatter(; ""logfoldchanges"",; ""pvals"",; xlim=(dedf[""logfoldchanges""][dedf[""logfoldchanges""].abs() != np.inf].min(), dedf[""logfoldchanges""][dedf[""logfoldchanges""].abs() != np.inf].max()),; ylim=(dedf[""pvals""][dedf[""pvals""].abs() != np.inf].min(), dedf[""pvals""][dedf[""pvals""].abs() != np.inf].max() + .5),; hover_cols=list(dedf.columns),; logy=True,; flip_yaxis=True; ). plot_volcano(sc.get.rank_genes_groups(adata, ...)); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1778#issuecomment-814594367:318,log,logfoldchanges,318,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1778#issuecomment-814594367,10,['log'],"['logfoldchanges', 'logy']"
Testability,"I downloaded the github source archive at the 1.8.2 tag. The build process applies a few patches viewable [here](https://salsa.debian.org/med-team/python-scanpy/-/tree/master/debian/patches). One is a small change to some R code, and the other is I marked several more tests as needs internet because the Debian builds in an environment without network access and those ultimately tried to download something. (And it's really unclear if we can legally redistributed the 10x pbmc3k dataset.). The Debian build file is (here)[https://salsa.debian.org/med-team/python-scanpy/-/blob/master/debian/rules] though mostly it lets you see what tests I was skipping because of missing dependencies. Also if I set a color like in_tissue, or array_row the data shows up. I can paste the full build log if you'd like but this is the dependencies installed and the environment variables. . ```; Build-Origin: Debian; Build-Architecture: amd64; Build-Date: Sun, 14 Nov 2021 20:11:26 +0000; Build-Path: /<<PKGBUILDDIR>>; Installed-Build-Depends:; adduser (= 3.118),; adwaita-icon-theme (= 41.0-1),; autoconf (= 2.71-2),; automake (= 1:1.16.5-1),; autopoint (= 0.21-4),; autotools-dev (= 20180224.1+nmu1),; base-files (= 12),; base-passwd (= 3.5.52),; bash (= 5.1-3.1),; binutils (= 2.37-8),; binutils-common (= 2.37-8),; binutils-x86-64-linux-gnu (= 2.37-8),; blt (= 2.5.3+dfsg-4.1),; bsdextrautils (= 2.37.2-4),; bsdutils (= 1:2.37.2-4),; build-essential (= 12.9),; bzip2 (= 1.0.8-4),; ca-certificates (= 20211016),; coreutils (= 8.32-4.1),; cpp (= 4:11.2.0-2),; cpp-11 (= 11.2.0-10),; dash (= 0.5.11+git20210903+057cd650a4ed-3),; dbus (= 1.12.20-3),; dbus-bin (= 1.12.20-3),; dbus-daemon (= 1.12.20-3),; dbus-session-bus-common (= 1.12.20-3),; dbus-system-bus-common (= 1.12.20-3),; dbus-user-session (= 1.12.20-3),; dconf-gsettings-backend (= 0.40.0-2),; dconf-service (= 0.40.0-2),; debconf (= 1.5.79),; debhelper (= 13.5.2),; debianutils (= 5.5-1),; dh-autoreconf (= 20),; dh-python (= 5.20211105),; dh-strip-no",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616:269,test,tests,269,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616,3,"['log', 'test']","['log', 'tests']"
Testability,"I encountered the same problem, when I created a small artificial `AnnData` with a single gene in `gene_list` for some unit test. Here is my analysis of the problem:. In this line; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L182; `control_genes` was actually empty, hence the index error.; The reason for the empty `control_genes` genes is; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L173; `control_genes` contained some genes before (in my artificial case only one), but they are removed here, since the genes in `control_genes` also appeared in `gene_list`. I think this is where the bug resides:; I assume `control_genes` should not contain genes from `gene_list` in the first place. Hence, this line; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L167; would need to be changed/complemented:; An additional filter for not being a gene in `gene_list` should fix this issue, if I understand this code correctly. That being said, I suppose that this issue appears rather rarely in the realistically sized datasets. I assume, that the probability of *accidentally* picking genes from `gene_list` as `control_genes` decreases with increasing number of genes.; At least I have not encountered this exception in my experimental datasets.; Furthermore, this issue does not make the result *wrong*, as far as I understand the algorithm, because the control genes are selected randomly anyway.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2153#issuecomment-1910410846:124,test,test,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153#issuecomment-1910410846,1,['test'],['test']
Testability,"I feel like it's a bit of a weird include anyways. What would you call it?. ------------. Btw, some of the matplotlib tests are being flaky with the size of the plot generated. Not really sure what's up with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2087#issuecomment-998071678:118,test,tests,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2087#issuecomment-998071678,1,['test'],['tests']
Testability,"I figured it out. I forgot that I should (or at least, I think I should?) set `adata_sub.raw = adata.sub`. Adding this step before running a new embedding and clustering seemed to have fixed my issue. I guess a follow-up question would be is this an acceptable approach? I stored my full data set in `raw` after log-normalizing my data (so, `adata.raw = adata`) during initial preprocessing. Since `adata_sub` is just a subset of `adata`, I am guessing it is ok to set `adata_sub.raw = adata.sub`?. Apologies for opening this issue based on what was an oversight on my part.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2007#issuecomment-931566526:312,log,log-normalizing,312,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2007#issuecomment-931566526,1,['log'],['log-normalizing']
Testability,I fixed the bug: https://github.com/theislab/scanpy/commit/15593d532fbaa696bf1ea328d1991d31b334e175. . And I'll immediately make a new release and put a warning on the webpage... @Koncopd: Thank you for adding the tests!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/393#issuecomment-446373823:214,test,tests,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446373823,1,['test'],['tests']
Testability,"I forgot to mention, additionally the same code executes with no problem with older versions of the packages. I've tested it on anndata = 0.8.0 and scanpy 1.9.3 and it executes fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3102#issuecomment-2154843905:115,test,tested,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102#issuecomment-2154843905,1,['test'],['tested']
Testability,"I found the same problem in `sc.pl.dotplot`, but i found in `\scanpy\plotting\_anndata.py` 2236th line：; ```; if dendrogram_key not in adata.uns:; from ..tools._dendrogram import dendrogram. logg.warning(; f""dendrogram data not found (using key={dendrogram_key}). ""; ""Running `sc.tl.dendrogram` with default parameters. For fine ""; ""tuning it is recommended to run `sc.tl.dendrogram` independently.""; ); dendrogram(adata, groupby, key_added=dendrogram_key); ```; `dendrogram` is not add `var_names`, and i fixed it in my source code. ------; anndata 0.7.8; scanpy 1.9.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1549#issuecomment-1298339775:191,log,logg,191,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549#issuecomment-1298339775,1,['log'],['logg']
Testability,"I found the testing in the [original R implementation](https://github.com/willtownes/scrna2019/blob/master/util/functions.R) of the deviances, and then mirrored it in [my implementation](https://github.com/theislab/scanpy/pull/1765). Glad to hear there seems to be potential for something analogous here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-874842313:12,test,testing,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-874842313,1,['test'],['testing']
Testability,"I found this problem too. Now logFC is still calculated in this way, that I am not satisfied with. When we are talking about average fold change of gene expression, the fold change of non-loged average expression is expected. In this way people get an intuitive feeling about how many times a gene is expressed compared with another group. **So the expm() step must be done before the mean() step.** Swap this order not only changes the logFC vaule, but also loses the biological meaning and doesn't make any sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/864#issuecomment-1109443073:30,log,logFC,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/864#issuecomment-1109443073,3,['log'],"['logFC', 'loged']"
Testability,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2037449650:10,test,test,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2037449650,7,"['log', 'test']","['logs', 'test', 'tests']"
Testability,"I guess both distance and connectivities matrices are full, and in order to get a sparse matrix, they apply a cutoff. I guess that that cutoff is a hard cutoff on distances, and a softer cutoff on connectivities. From some tests I've done for a particular project, in some datasets there are differences between distances and connectivities, and for others aren't. We'll have to wait to see the answer.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1984#issuecomment-920706904:223,test,tests,223,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1984#issuecomment-920706904,1,['test'],['tests']
Testability,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-470456611:314,test,test,314,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470456611,5,"['log', 'test']","['log', 'test']"
Testability,I had a go a making these changes but I didn't have time to get the tests working locally so there is a fair chance I broke something in the process,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2921#issuecomment-2083598014:68,test,tests,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2921#issuecomment-2083598014,1,['test'],['tests']
Testability,"I had a look at scanpy's [setup file](https://github.com/theislab/scanpy/blob/master/setup.py) `setup.py` and realised that running. ```bash; pip install -e .; pip install "".[dev]""; ```. does neither install all packages used within Scanpy's code base nor packages required for documentation or testing. IMO, these packages should be installed in a _developer installation_ as they are all part of the development cycle. Adding a file `requirements-dev.txt` including all needed packages would be an option to allow for an easy _developer installation_ via. ```bash; pip install -e .; pip install -r requirements-dev.txt; ```. Any thoughts on this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1419#issuecomment-703124876:295,test,testing,295,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1419#issuecomment-703124876,1,['test'],['testing']
Testability,"I had a same issue. My environment is; ```; windows10; python3.8.8 (conda env); ```. scanpy installation ; `conda install -c conda-forge -c bioconda scanpy`. It looks work well on command prompt, but it wasn't work on jupyterlab(3.0). To solve this, I just installed all packages using pip, not conda.; here is my install procedure. ```; conda create -n test python=3.8; pip install ipykernel; pip install jupyterlab; pip install scanpy; pip install python-igraph; pip install leidenalg; pip install fa2; ```. I tired a lot of install and environment combination, but always there was a problem with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541:354,test,test,354,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541,1,['test'],['test']
Testability,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py; import anndata2ri; import logging. import rpy2.rinterface_lib.callbacks as rcb; import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR); ro.pandas2ri.activate(); anndata2ri.activate(). %load_ext rpy2.ipython; ```; Convert adata_p and adata_g to R objects. ```r; ro.globalenv['r_adata_p'] = adata_p; ro.globalenv['r_adata_g'] = adata_g; ```. ```r; %%R -w 800 -h 400 -u px. library(Seurat); library(viridis); library(viridisLite); library(ggplot2); library(cowplot). df_poor= data.frame(; total_counts = colData(r_adata_p)$total_counts,; n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,; pct_counts_mt = colData(r_adata_p)$pct_counts_mt; ). df_good= data.frame(; total_counts = colData(r_adata_g)$total_counts,; n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,; pct_counts_mt = colData(r_adata_g)$pct_counts_mt; ). #head(df); # Create a scatter plot using ggplot2; p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +; geom_point() +; scale_color_viridis() +; labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +; theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +; geom_point() +; scale_color_viridis() +; labs(title = ""good (after outlier and mitochrondrial gene removal)"") +; theme_minimal(). p2 + g2; ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1258#issuecomment-1853651085:153,log,logging,153,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258#issuecomment-1853651085,3,['log'],"['logger', 'logging']"
Testability,"I had to fix a few issues, if you want you can check it out: 66e64b40870035c3ee869e3baf34cf7110508d85. - I unified the parameter order with `louvain`; - I actually import it in `sc.tl`; - I added it to the docs here: https://scanpy.readthedocs.io/en/latest/api/#clustering-and-trajectory-inference; - I added a test; - I fixed the references (you had typos there: 2018 instead of 18 and a missing “L”); - You did this:. ```py; partition_kwargs['weights'] = None; if use_weights:; weights = np.array(g.es['weight']).astype(np.float64); # “weights” is never used then; ```. But I assume you meant this. Am I correct?. ```py; if use_weights:; partition_kwargs['weights'] = np.array(g.es['weight']).astype(np.float64); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/361#issuecomment-439331820:311,test,test,311,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/361#issuecomment-439331820,1,['test'],['test']
Testability,"I had to use the pbmc3k dataset for testing, as the error doesn't occur on blobs or pbmc68k_reduced. To test I need sufficient genes that have 0 variance in a subset of the cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/824#issuecomment-530426113:36,test,testing,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824#issuecomment-530426113,2,['test'],"['test', 'testing']"
Testability,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files.; With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error.; I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be?; The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step.; Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128:872,test,test,872,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128,2,['test'],['test']
Testability,"I have an AnnData object whose .X matrix has been transformed by size factor division, +1 and log. Subsequent ```sc.pp.highly_variable_genes(dataset, flavor='cell_ranger', n_top_genes=1000)``` yields the ```ValueError: Bin edges must be unique: ... You can drop duplicate edges by setting the 'duplicates' kwarg``` error discussed above. Transformation to a sparse matrix did not alleviate the error, and neither did any other solutions suggested. Edit: **However!** While I could not get ```flavor='cell_ranger'``` to work on the data I normalised myself, ```flavor='seurat'``` has worked okay. Therefore, I recommend people also encountering this error to stick with this second flavour, because as I understand it they utilise a similar methodology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-751495201:94,log,log,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-751495201,1,['log'],['log']
Testability,"I have gotten fairly different clustering results when using `svd_solver='arpack'` in all but 1 case actually. The biological interpretation is still roughly the same, but the depth of subclustering you can do does differ. Based on a preliminary test, using arpack for all `sc.pp.pca()` calls does improve the reproducibility, although clustering results still differ (tested on Fedora 25 and Fedora 28, e.g. cluster sizes change by 100-200 cells). I can show you the differences when you're around next if you like. This is definitely a discussion for a different thread though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/455#issuecomment-474334322:246,test,test,246,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-474334322,2,['test'],"['test', 'tested']"
Testability,"I have log normalised the data and have filtered out the genes. . I have : ; 1. adata.var[adata.var[""n_cells""]==np.nan] - result is 0.; 2. np.isinf(adata.X.todense()).sum() - result is 0. Data I'm using is GSE158055. Link : https://drive.google.com/file/d/1TXDJqOvFkJxbcm2u2-_bM5RBdTOqv56w/view?usp=sharing",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2193#issuecomment-1079813917:7,log,log,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193#issuecomment-1079813917,1,['log'],['log']
Testability,I have not set the precision to float64 manually anywhere. It may however be the case that ComBat batch correction automatically uses float64. I will test and let you know.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/324#issuecomment-433383722:150,test,test,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324#issuecomment-433383722,1,['test'],['test']
Testability,"I have removed issue from the pull request by the testing tool, now the tools showed me duplications, which are mostly from other code and 1-2 from my code. Please have a look into it. It's my first pull request and its taking too much time :(. Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-493836759:50,test,testing,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493836759,1,['test'],['testing']
Testability,"I have several plotting functions that allow to compare any two categorical columns in `.obs` to achieve similar output but never found the time to integrate them into scanpy. Is really quite some effort to add proper tests, documentation and code standards. I will be happy to share the code if other people is willing to help. . One problem with the stacked bar plot is that with lot of samples it is difficult to compare the fractions. To solve this I had used the dot plot with good results, see for example a comparison of the `louvain` clusters and the `bulk labels` annotation from `sc.datasets.pbmc68k_reduced()`:. ![image](https://user-images.githubusercontent.com/4964309/104466204-3e718280-55b5-11eb-9b87-ac3860af7979.png). and . ![image](https://user-images.githubusercontent.com/4964309/104466234-49c4ae00-55b5-11eb-92c8-45140de9e107.png). The dot plot also computes enrichment with respect to random expectations and sorts the rows and columns.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1573#issuecomment-759496093:218,test,tests,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1573#issuecomment-759496093,1,['test'],['tests']
Testability,"I have something that might be related:. ```python; ad = ad[ad.obs['cell type'] != 'nan'].copy(); assert np.all(ad.obs['cell type'] != 'nan'); sc.utils.sanitize_anndata(ad); assert np.all(ad.obs['cell type'] != 'nan'); ```. This fails in the second assert:. ```python; AssertionError Traceback (most recent call last); <ipython-input-103-2f44e51fdcae> in <module>; 8 assert np.all(ad.obs['cell type'] != 'nan'); 9 sc.utils.sanitize_anndata(ad); ---> 10 assert np.all(ad.obs['cell type'] != 'nan'); 11 ; 12 . AssertionError: ; ```. It's really black magic, any ideas?. PS: `nan`s are really string, not proper NaNs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/166#issuecomment-491099687:98,assert,assert,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166#issuecomment-491099687,7,"['Assert', 'assert']","['AssertionError', 'assert']"
Testability,"I have written a couple of functions to match clusters and marker genes. The simplest case is just a table of overlap score. Alternatively, I know someone who has used the Jaccard Index and enrichment tests. The other functions I wrote calculate average z-scores of marker genes in clusters (not sure if this is similar to `score_genes` or not. I could paste the functions in here if you like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/290#issuecomment-428240965:201,test,tests,201,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290#issuecomment-428240965,1,['test'],['tests']
Testability,"I have written a function to do this... I could add it to scanpy. But for the moment, this is it:. ```; def marker_gene_expression(anndata, marker_dict, gene_symbol_key=None, partition_key='louvain_r1'):; """"""A function go get mean z-score expressions of marker genes; # ; # Inputs:; # anndata - An AnnData object containing the data set and a partition; # marker_dict - A dictionary with cell-type markers. The markers should be stores as anndata.var_names or ; # an anndata.var field with the key given by the gene_symbol_key input; # gene_symbol_key - The key for the anndata.var field with gene IDs or names that correspond to the marker ; # genes; # partition_key - The key for the anndata.obs field where the cluster IDs are stored. The default is; # 'louvain_r1' """""". #Test inputs; if partition_key not in anndata.obs.columns.values:; print('KeyError: The partition key was not found in the passed AnnData object.'); print(' Have you done the clustering? If so, please tell pass the cluster IDs with the AnnData object!'); raise. if (gene_symbol_key != None) and (gene_symbol_key not in anndata.var.columns.values):; print('KeyError: The provided gene symbol key was not found in the passed AnnData object.'); print(' Check that your cell type markers are given in a format that your anndata object knows!'); raise; . if gene_symbol_key:; gene_ids = anndata.var[gene_symbol_key]; else:; gene_ids = anndata.var_names. clusters = anndata.obs[partition_key].cat.categories; n_clust = len(clusters); marker_exp = pd.DataFrame(columns=clusters); marker_exp['cell_type'] = pd.Series({}, dtype='str'); marker_names = []; ; z_scores = sc.pp.scale(anndata, copy=True). i = 0; for group in marker_dict:; # Find the corresponding columns and get their mean expression in the cluster; for gene in marker_dict[group]:; ens_idx = np.in1d(gene_ids, gene) #Note there may be multiple mappings; if np.sum(ens_idx) == 0:; continue; else:; z_scores.obs[ens_idx[0]] = z_scores.X[:,ens_idx].mean(1) #works for both s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/181#issuecomment-400238103:775,Test,Test,775,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/181#issuecomment-400238103,1,['Test'],['Test']
Testability,"I have yet to install the most latest `scanpy` and I do not have CPUs to test for this specific case, but I had some issue of reproducing `leiden` results from `scanpy` from a published paper, and found that running `leiden` 10 times (per `n_iteration` option) resolved any discrepancy. Wonder whether it adds to the discussion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2014#issuecomment-946665831:73,test,test,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2014#issuecomment-946665831,1,['test'],['test']
Testability,"I haven't benchmarked against scanpy, only against `scipy.stats.mannwhitneyu` (which at this point can handle arrays, I know it couldn't before). On my laptop (an 8-core Intel MacBook Pro) it's about a 10x speedup. But with more cores it can be a lot more. Even without parallelization, you can get some improvement by just using `numba.njit` on some of the internal bits (e.g. `tiecorrect`). Of course, your code has a lot of options that I didn't bother with, because I didn't need them. Some of them might be harder to JIT than others.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2060#issuecomment-981723859:10,benchmark,benchmarked,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2060#issuecomment-981723859,1,['benchmark'],['benchmarked']
Testability,"I haven't performed an in-depth benchmark comparison. But results from a single run of modularity detection on an example (a [Facebook graph](http://konect.uni-koblenz.de/networks/facebook-wosn-links)) is sufficiently revealing I think:; ```; Running Leiden 0.7.0.post1+71.g14ba1e4.dirty; Running igraph 0.8.0; Read graph (n=63731,m=817035), starting community detection.; leidenalg: t=8.048258741036989, m=0.6175825273363675; igraph community_leiden: t=1.159165252931416, m=0.6298702028415605; ```; This is only a relatively small graph, and the difference is likely to be even bigger for larger graphs. Perhaps the `igraph` Leiden algorithm can indeed be the default, with `leidenalg` being an optional choice or something?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-586969791:32,benchmark,benchmark,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053#issuecomment-586969791,1,['benchmark'],['benchmark']
Testability,"I haven't tried `read_direct ` yet but, in my opinion, it is not that helpful when we are reading the full array in memory without any type conversions. But i will check it of course. Now it seems like the problem in the recursion as reading simple files with pre-specified paths is faster and takes less memory.; Also, it can be that the problem is somewhere in the step of transforming dictionary to AnnData, but i don't see where for now. I'll check a few things, prepare readable benchmarks next week and we can have a call about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/303#issuecomment-441478499:484,benchmark,benchmarks,484,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/303#issuecomment-441478499,1,['benchmark'],['benchmarks']
Testability,I haven't used np.allclose for comparison but if I remember correctly (it was a while ago) the differences were around 4th or 5th decimal point. I will write a test using np.allclose against a reference and run it on different machines to see how it looks. I will post here the results.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1890#issuecomment-867445206:160,test,test,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890#issuecomment-867445206,1,['test'],['test']
Testability,"I hope that soon I can add some figures into the documentation and add further test. ; . > Am 23.07.2018 um 23:12 schrieb Alex Wolf <notifications@github.com>:; > ; > OK, merged this into master on the command line after fixing plotting/anndata.py, where some changes would have otherwise been reversed...; > ; > Thank you very much, Fidel! Really cool!; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/207#issuecomment-407332243:79,test,test,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/207#issuecomment-407332243,1,['test'],['test']
Testability,"I input pip show scipy I get:. Name: scipy; Version: 1.4.1; Summary: SciPy: Scientific Library for Python; Home-page: https://www.scipy.org; Author: None; Author-email: None; License: BSD; Location: /home/ubuntu/.local/lib/python3.6/site-packages; Requires: numpy; Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata; You are using pip version 18.0, however version 20.2b1 is available.; You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:; Name: scanpy; Version: 1.5.1; Summary: Single-Cell Analysis in Python.; Home-page: http://github.com/theislab/scanpy; Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrés R. Muñoz-Rojas; Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de; License: BSD; Location: /home/ubuntu/.local/lib/python3.6/site-packages; Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata; Required-by: ; You are using pip version 18.0, however version 20.2b1 is available.; You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user; when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252#issuecomment-635681942:1799,log,logging,1799,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252#issuecomment-635681942,1,['log'],['logging']
Testability,I just add the versions I used:; ```python; sc.logging.print_versions(). scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/536#issuecomment-474301705:47,log,logging,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536#issuecomment-474301705,1,['log'],['logging']
Testability,"I just found out that raw was already log transformed. Now I fixed it and nanmin seems a bit too conservative, any ideas?. ![image](https://user-images.githubusercontent.com/1140359/56463105-ea177f80-639b-11e9-80d3-f96463734634.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/614#issuecomment-485188655:38,log,log,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/614#issuecomment-485188655,1,['log'],['log']
Testability,"I just increased the noise in the testdata. With this, the assertion fails with the wrong number of noise barcodes.; The original test data was to ""clean"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2190#issuecomment-1082217533:34,test,testdata,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190#issuecomment-1082217533,3,"['assert', 'test']","['assertion', 'test', 'testdata']"
Testability,"I just noticed I forgot to answer to your point about multiple-testing-correction. Multiple testing correction deals with the effect that obtaining any false positives become more likely with repeated tests. However, it does not deal with bias. Bias is however present in the test given that the correct null hypothesis should assume some genes are different between groups, and not that all genes are equal. This comes back to the observation that some genes will be always be different between groups in random data, given that clustering defines the groups over which we test. And as for louvain using whole transcriptome similarities rather than individual gene similarities... these are related. If you defined groups by differences of whole transcriptomes, this necesitates individual genes having different means. The correct p-value would be the output of a permutation test. . Could discuss this offline if you like @gokceneraslan. I'm preparing a manuscript which makes a point of this... if I am wrong, please convince me of this soon ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-425737634:63,test,testing-correction,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-425737634,6,['test'],"['test', 'testing', 'testing-correction', 'tests']"
Testability,"I just stumbled upon a similar bug using SciKit Learn. It's not ScanPy, but this issue is the only result Google returned when I looked up my error. Here's my crash log:. ```; Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV); Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110; Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11; Termination Reason: Namespace SIGNAL, Code 0xb; Terminating Process: exc handler [0]. VM Regions Near 0x110:; --> ; __TEXT 000000010ddfb000-000000010ddfd000 [ 8K] r-x/rwx SM=COW /usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:; crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread; 0 libdispatch.dylib 	0x00007fff4fb578e1 _dispatch_root_queue_push + 108; 1 libBLAS.dylib 	0x00007fff24844c9a rowMajorTranspose + 546; 2 libBLAS.dylib 	0x00007fff24844a65 cblas_dgemv + 757; 3 multiarray.cpython-36m-darwin.so	0x00000001104e3f86 gemv + 182; 4 multiarray.cpython-36m-darwin.so	0x00000001104e3527 cblas_matrixproduct + 2807; 5 multiarray.cpython-36m-darwin.so	0x00000001104a9b27 PyArray_MatrixProduct2 + 215; 6 multiarray.cpython-36m-darwin.so	0x00000001104aeabf array_matrixproduct + 191; 7 org.python.python 	0x000000010de4712e _PyCFunction_FastCallDict + 463; 8 org.python.python 	0x000000010dead0e6 call_function + 491; 9 org.python.python 	0x000000010dea5621 _PyEval_EvalFrameDefault + 1659; 10 org.python.python 	0x000000010dead866 _PyEval_EvalCodeWithName + 1747; ```. It's not very useful as it's the same as the OP's, but it might help shifting the blame to a common dependency of SciKit Learn and ScanPy (like BLAS having an issue with macOS' Grand Central Dispatch).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/182#issuecomment-408848214:165,log,log,165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182#issuecomment-408848214,1,['log'],['log']
Testability,"I just tested this out... The idea was that if `sc.pp.pca()` has the parameter `use_highly_variable` that be extension `sc.tl.umap()`, `sc.tl.tsne()`, and `sc.tl.draw_graph()` would also be based only on highly variable genes. That however doesn't seem to be the case. When I subset my anndata object to only highly variable genes I get a different result than when I just run it with `sc.pp.pca(adata, use_highly_variable=True)`. The `sc.pl.pca()` is the same, but `sc.pl.diffmap` seems somehow inverted, and umap, tsne, and draw_graph are all slightly different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/284#issuecomment-432836664:7,test,tested,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/284#issuecomment-432836664,1,['test'],['tested']
Testability,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```; gene1 = 'XXX'; gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &; (adata.raw[:,'{}'.format(gene2)].X.todense() > 0); ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/490#issuecomment-587473372:244,log,log,244,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-587473372,1,['log'],['log']
Testability,"I like the thought... for exactly the reason you brought up, I recommended storing log-normalized data in `adata.raw` in my best practices workflow. That way DE analysis and plotting is done on that data type rather than raw counts. I have been working with `adata.layers['counts']` for count data and don't keep filtered out cells/genes (easy to recreate anyway).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-819683830:83,log,log-normalized,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-819683830,1,['log'],['log-normalized']
Testability,"I like this idea, but think it could be expanded on a bit. I think there are benefits to approaching this through logging. Some advantages of doing this through logging:. * Global record. If a copy is made or an AnnData split, you could figure out which object came from where.; * Control over level of detail. What kind of information is recorded can be customized. Maybe the user wants provenance, but maybe they want performance information. What if tracking was done through logging? Here's a couple quick examples of what I mean:. <details>. <summary>Simple example. Logs `anndata` used, function called, time elapsed </summary>. ```python; from anndata import AnnData; from datetime import datetime; from functools import wraps; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(func):; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; call_start_record = dict(call_id=call_id, called_func=func.__name__); if type(args[0]) is AnnData:; call_start_record[""adata_id""] = id(args[0]); logger.msg(""call"", **call_start_record). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(called_func=func.__name__, elapsed=dt); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 cal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:114,log,logging,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273,6,"['Log', 'log']","['Logs', 'logged', 'logger', 'logging']"
Testability,I like your suggestions. Especially the `filter_rank_genes_groups` use makes a lot of sense to me. The one thing I would suggest to take into account is that some of these filtering steps can be done before significance testing and therefore you would not have to perform multiple testing correction on the filtered out genes. This may be quite useful to some. That precludes filtering on p-value though. It also makes a case for filtering already in `rank_genes_groups` rather than in `sc.get`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1529#issuecomment-738766770:220,test,testing,220,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529#issuecomment-738766770,2,['test'],['testing']
Testability,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`?. Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148:36,test,test,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148,8,['test'],"['test', 'testing', 'tests']"
Testability,I looked at a few genes and it looks like I'm getting pretty similar residuals compared to the R implementation. Something weird is going on with the genes in the last couple images so I'm currently trying to figure that before generating more thorough benchmarks. (I clip negative values to zero to preserve sparsity structure). ![image](https://user-images.githubusercontent.com/16548075/107794002-c4dfc800-6d0b-11eb-8c69-eca5963a2cc4.png); ![image](https://user-images.githubusercontent.com/16548075/107794217-02445580-6d0c-11eb-9c12-a1fce473a69a.png); ![image](https://user-images.githubusercontent.com/16548075/107794044-d1642080-6d0b-11eb-9659-bd72e7a9aa99.png); ![image](https://user-images.githubusercontent.com/16548075/107794308-23a54180-6d0c-11eb-8b2e-59bb479b09af.png),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1643#issuecomment-778299582:253,benchmark,benchmarks,253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1643#issuecomment-778299582,1,['benchmark'],['benchmarks']
Testability,"I looked at it a while ago (for one test dataset, probably), and got the impression that `louvain` was faster. That said, they're both very fast. I would note that solutions from either can be pretty unstable, frequently depending on size of the community. @LuckyMD When you say heavy tailed, are you thinking of the unweighted KNN graph case or both?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-483207692:36,test,test,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-483207692,1,['test'],['test']
Testability,"I looked into that, but I'm not sure it actually makes this any less complicated. The issue is getting the `tqdm` thing to update, and requests would need all of the same logic to do that as far as I can tell. Plus, at that point it's copying from stack overflow vs. copying from python's stdlib. You'd think this would be a convenience function somewhere. Or you'd think that `urlretrieve` could take a `Request` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1344#issuecomment-666336406:171,log,logic,171,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344#issuecomment-666336406,1,['log'],['logic']
Testability,I merged it and moved it into `rtools`. There is a reexport so that you should be able to call it using `sc.rtools.mnn_concatenate` where `sc` is `scanpy.api`. Could you test whether this works?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-384126068:170,test,test,170,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-384126068,1,['test'],['test']
Testability,I modified the code to reintroduce `chunked` but I confess I haven't tested it because I've never been able to get it to work. I think there might be other issues with that functionality...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/191#issuecomment-403244826:69,test,tested,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191#issuecomment-403244826,1,['test'],['tested']
Testability,"I must also mention that upon reading in the data:; - running `adata.uns['log1p']` returns `{}`;; - setting `adata.uns['log1p'][""base""] = None` after reading doesn't help.; - running `del adata.uns['log1p']` solves the problem. Visual inspection of expression values in `adata.X` seem to not be log-transformed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1333#issuecomment-1210570611:295,log,log-transformed,295,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333#issuecomment-1210570611,1,['log'],['log-transformed']
Testability,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback.; ```; TypeErrorTraceback (most recent call last); <ipython-input-963-f4f784156b06> in <module>; ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 285 If `show==False` a `matplotlib.Axis` or a list of it.; 286 """"""; --> 287 return plot_scatter(adata, 'umap', **kwargs); 288 ; 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 202 _data_points[:, 0], _data_points[:, 1],; 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,; --> 204 **kwargs,; 205 ); 206 . ~/.virtualenvs/intel_default/lib/python3",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/555#issuecomment-483342652:573,test,test,573,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555#issuecomment-483342652,4,['test'],['test']
Testability,I noticed that matplotlib v. 3 is being installed in travis. This may be the reason why some tests not related to the changes are now failing. I am updating my matplotlib version to update de tests.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-425947033:93,test,tests,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-425947033,2,['test'],['tests']
Testability,"I noticed, however, that the tests pass even when removing the `if stripplot:` part. Any idea on why this is happening and how to prevent it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-694832160:29,test,tests,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-694832160,1,['test'],['tests']
Testability,I pushed to your branch. It failed yesterday while Github was having issues. The test should pass.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1541518384:81,test,test,81,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1541518384,1,['test'],['test']
Testability,"I reckon that's a fair consideration. In the end we don't use `sc.tl.rank_genes_groups()` for complex DE tests that require this amount of detail, but instead for marker gene calculations where it's mainly about ranking genes. It would be interesting to see the error of the approximation though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-471500111:105,test,tests,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471500111,1,['test'],['tests']
Testability,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that); ```; ... WARNING: did not find DISPLAY variable needed for interactive plotting; --> try ssh with `-X` or `-Y`; setting `sett.savefigs = True`; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/16#issuecomment-298663054:403,log,logs,403,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16#issuecomment-298663054,1,['log'],['logs']
Testability,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-470239225:30,log,logs,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470239225,5,"['log', 'test']","['log-fold', 'log-normalized', 'log-scale', 'logs', 'test']"
Testability,"I see no reason why the possibility shouldn't exist to run the weighted version on the full graph. I'm still curious about the quality of the outcome though. Using protein-protein interaction data, I've noticed that similarity scores perform worse than using network neighbourhoods based on cutoffs to cluster data (this does not have to be the case for scRNA-seq of course). In the latter case you require cells to be each others nearest neighbours to create dense network regions, rather than highly similar transcriptomes based on one calculation of similarity. I would have thought the cutoff approach is more robust to changing similarity metrics as well. It's definitely worth testing this though. Maybe I'm just too skeptical of similarity metrics over all. @fidelram do you have labels on your data where you could verify the quality of those two partitions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-416161676:683,test,testing,683,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/240#issuecomment-416161676,1,['test'],['testing']
Testability,"I see your point, no problem. krumsiek11 dataset does not actually cause inconsistencies float32/float64 (without/with the fix). I suspect this is because it has fewer decimal digits and fewer genes so does not accumulate enough imprecision.; Paul15 data behaves as reported before, so I used that one instead. Hope this is fine!. As previously the test passes with the fix but not without it on the two machines I tested.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1890#issuecomment-873623806:349,test,test,349,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890#issuecomment-873623806,2,['test'],"['test', 'tested']"
Testability,"I see, [densmap](https://umap-learn.readthedocs.io/en/latest/densmap_demo.html). Hmm, I think that `method='densmap'` and `method_kwds={...}` would be a better API for us (which would then be translated into `densmap=True, densmap_kwds=method_kwds`). This also needs tests and a release note. Also we probably should just remove the umap 0.4 compatibility code, what do you think @ivirshup?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2684#issuecomment-1764564449:267,test,tests,267,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2684#issuecomment-1764564449,1,['test'],['tests']
Testability,"I simplified this quite a bit. I decided against blocking this on an upstream `anndata` helper for multiple reasons:. 1. we test on older anndata versions that won’t have that parameter immediately; 2. needs some designing, e.g. the API should be able to do “use `ceil(shape[0] / 2)` as chunk size for dim 0, and `-1` (=full size) for dim 1”; 3. it would make no sense for the non-dask array types, should we still add it for them?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3162#issuecomment-2250061054:124,test,test,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162#issuecomment-2250061054,1,['test'],['test']
Testability,"I started to test also with 3.8, but sadly there’s a bug in scipy: scipy/scipy#10354",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/704#issuecomment-505415647:13,test,test,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704#issuecomment-505415647,1,['test'],['test']
Testability,"I submitted both the exact changes suggested by @flying-sheep and . normalize = matplotlib.colors.Normalize(vmin=kwds.get('vmin'), vmax=kwds.get('vmax')); colors = [cmap(normalize(value)) for value in mean_flat]. as a second submission, trying to pass the tests. But it looks like the tests are failing for some other reason outside of the anndata.py file (only file modified in my commit). . I don't think the tests are failing from the changes made here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/390#issuecomment-446061532:256,test,tests,256,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/390#issuecomment-446061532,3,['test'],['tests']
Testability,"I support the idea of tidying up plotting arguments. I think there are mainly two problems. 1) the high number of plotting arguments 2) lack of reusability of plotting ""styles"". . Chaining looks really cool and improves 1). Also, it logically partitions the plotting arguments. However, it doesn't solve 2). In other words, if we plot two figures, we'll need to copy the entire thing, and it'll be very verbose:. ```python; sc.pl.umap(adata, color='clusters').scatter_outline(width=0.1); .legend(loc='on data', outline=1); .add_edges(color='black', width=0.1). sc.pl.umap(adata2, color='fluffy').scatter_outline(width=0.1); .legend(loc='on data', outline=1); .add_edges(color='black', width=0.1); ```. One thing that comes to mind for reusability is to store the result of the chain somewhere and, well, reuse it:. ```python; style = sc.pl.styles.scatter_outline(width=0.1); .legend(loc='on data', outline=1); .add_edges(color='black', width=0.1). # using simple arguments, similar to https://stat.ethz.ch/R-manual/R-devel/library/nlme/html/lmeControl.html; sc.pl.umap(adata, color='clusters', style=style); sc.pl.umap(adata2, color='fluffy', style=style). # using context managers, similar to https://seaborn.pydata.org/tutorial/aesthetics.html#temporarily-setting-figure-style; with style:; sc.pl.umap(adata, color='clusters'); sc.pl.umap(adata2, color='fluffy'). # overriding an existing style object; with style.legend(fontsize=12):; sc.pl.umap(adata, color='clusters'); sc.pl.umap(adata2, color='fluffy'). # or use predefined styles (?); with sc.pl.style('malte'):; sc.pl.umap(adata, color='clusters'); sc.pl.umap(adata2, color='fluffy'). ```. WDYT?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/956#issuecomment-567321810:233,log,logically,233,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/956#issuecomment-567321810,1,['log'],['logically']
Testability,"I tentatively added a benchmark that runs just on `_get_mean_var`. Locally I don’t see any difference though, what’s wrong? Too small data? Numba not set up with correct number of threads?. /edit: also I think the machine is not sufficiently tuned. The original run (before I added the `mean_var` benchmarks) said “No changes in benchmarks.”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3015#issuecomment-2066327499:22,benchmark,benchmark,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3015#issuecomment-2066327499,3,['benchmark'],"['benchmark', 'benchmarks']"
Testability,"I tested myself and obtained exactly the same results. :). You probably don't have the FA2 package installed, that's why your graph look different... :). I'm merging this! Awesome work!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-487797746:2,test,tested,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-487797746,1,['test'],['tested']
Testability,"I tested the code, now it is possible to calculate more components for the tSNE embedding method",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/461#issuecomment-460703629:2,test,tested,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/461#issuecomment-460703629,1,['test'],['tested']
Testability,"I tested this in a couple of machine and the pipeline works fine there. However, I just re-installed `leidenalg` and this is now resolved! . Thanks a lot for the feedback.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1410#issuecomment-689637466:2,test,tested,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1410#issuecomment-689637466,1,['test'],['tested']
Testability,I tested this. 🙂,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/927#issuecomment-556003335:2,test,tested,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/927#issuecomment-556003335,1,['test'],['tested']
Testability,"I think I'll leave codecov to a separate PR, since this immediately improves test reporting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1564#issuecomment-754438743:77,test,test,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1564#issuecomment-754438743,1,['test'],['test']
Testability,"I think `adata.obsm` could make sense, but `adata.uns` would maybe be a bit too messy given the unstructured nature and the assumptions and tests that would have to be added.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1189#issuecomment-621466673:140,test,tests,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189#issuecomment-621466673,1,['test'],['tests']
Testability,I think it is more or less complete.; Here are the tutorials; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/Ingest-realistic.ipynb; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/Ingest-simple.ipynb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651#issuecomment-519155566:104,benchmark,benchmarks,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-519155566,2,['benchmark'],['benchmarks']
Testability,I think it just needs a test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2280#issuecomment-1592923701:24,test,test,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2280#issuecomment-1592923701,1,['test'],['test']
Testability,I think it makes sense. I will open a new PR cause I'll have to change the test as well.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1149#issuecomment-628521440:75,test,test,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1149#issuecomment-628521440,1,['test'],['test']
Testability,"I think it's normally just the string `""euclidean""`, but you can just test what is stored in `.uns['neighbors']['params']['metric']` after running `sc.pp.neighbors()` on some test data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1201#issuecomment-658658158:70,test,test,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201#issuecomment-658658158,2,['test'],['test']
Testability,"I think maybe i found a solution to solve this problem.; Maybe this problem is caused by the version of scikit—misc，when you use pip install --user scikit-misc or pip install scikit-misc，the system will install scikit-misc==0.1.4.; so,i try to install another verion of scikit-misc,you can use install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1.; In addition, this line of command needs to be used when python is greater than or equal to 3.8.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497:313,test,test,313,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497,1,['test'],['test']
Testability,"I think separating static analysis from running the tests is the way to go (in #841 I added black checking as a separate step.). Also mypy is very strict, so we might have to fix *a lot*.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/839#issuecomment-531489355:52,test,tests,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839#issuecomment-531489355,1,['test'],['tests']
Testability,"I think the current approach - a very simple interface as in `scanpy/tools/phate.py` and a bunch of others is the easiest way to go for the developer. So, I'd say we make a submodule `.ext` with the `.tools`, `.plotting`, `.preprocessing` substructure in it. We move things like `phate.py` into `scanpy/ext/tools`. We maintain backwards compat by still reexporting it in `scanpy.api`. The canonical way of calling these extension will be by importing `import scanpy.ext as sce` and people can use that extension namespace and call everything in the same way that they are used to. Users can look up extension tools on docs site like [this](https://scanpy.readthedocs.io/en/latest/api/index.html). It will also be clear to users that these extensions will require installing additional packages, which don't come with the default scanpy. Of course, all of this needs none of the ""extension mechanisms"" mentioned above. But people really don't want to write actual ""scanpy extensions""; they want to write their own packages and have them interface with scanpy so that convenient calls are enabled without the need to adapt to new conventions. For the scanpy users, the cool things is that a large number of tools can be quickly tested out. If you don't mind, @fidelram and @flying-sheep, @Koncopd would go along and make this modest change.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/271#issuecomment-431634492:1226,test,tested,1226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271#issuecomment-431634492,1,['test'],['tested']
Testability,"I think the plotting parameter would make a lot of sense. We should take a few things into account though when determining defaults here.; 1. Not all methods have log fold changes (`'logreg'` for example); 2. Ordering based on log FC will be different than based on the scoring (lowly expressed genes will typically have higher logFC). I'm not sure how meaningful the plot would then be...; 3. We initially didn't have any fold changes or p-values at all, partially because the marker gene DE test setup is ill-defined. You test gene in two groups where the groups are defined based on the genes you test... that will generate inflated p-values. Hence it might be a good idea to only consider the test as a way to order genes rather than a robust statistical test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1152#issuecomment-610607335:163,log,log,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152#issuecomment-610607335,9,"['log', 'test']","['log', 'logFC', 'logreg', 'test']"
Testability,"I think the problem is the option `sort_order` which is True by default for; numerical data. This changes the ordering of the dots and thus it messes; up with your own sizes. Setting `sort_order=False` should fix the problem. On Tue, Feb 12, 2019 at 6:07 AM Andreas <notifications@github.com> wrote:. > I'm trying to use an array for the size argument to my umap/scatterplot; > with the following code; >; > import scanpy.api as sc; > import numpy as np; > sc.settings.figdir = ""testdir""; > sc.settings.file_format_figs = ""png""; > sc.logging.print_versions(); >; > With these libraries; > scanpy==1.3.7 anndata==0.6.16 numpy==1.16.1 scipy==1.2.0 pandas==0.23.4; > scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; >; > Running the following code bit. I use some dummy variable for size.; >; > somedata = sc.datasets.paul15(); > sc.pp.pca(somedata); > sc.pp.neighbors(somedata, n_neighbors=4, n_pcs=20); > sc.tl.umap(somedata, spread=1, min_dist=0.1, random_state=42); > sc.tl.leiden(somedata, resolution=0.5, random_state=42); > z = np.abs(somedata.obsm['X_pca'][:,0])**1; > sc.pl.umap(somedata, color=['1110007C09Rik'], size=z, cmap='viridis', save='continuous_expr.png'); > sc.pl.umap(somedata, color=['leiden'], size=z, cmap='viridis', save='group_value.png'); >; > I get the following two figure as output; > [image: umapcontinuous_expr]; > <https://user-images.githubusercontent.com/715716/52612879-951a3300-2e59-11e9-9dad-a8afc60a4b54.png>; > [image: umapgroup_value]; > <https://user-images.githubusercontent.com/715716/52612880-95b2c980-2e59-11e9-9a44-81dd84e3274d.png>; >; > I would expect to see a similar size allocation/distribution but they are; > very different. I Could not really find a cause for this looking at the; > scatter plot function so it might be somewhere deeper.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/478>, or ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/478#issuecomment-462722152:479,test,testdir,479,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/478#issuecomment-462722152,2,"['log', 'test']","['logging', 'testdir']"
Testability,"I think this is an important conversation to have not just for imputation, but also for other analysis methods like visualization and batch effect correction. Every algorithm makes some assumptions and biases, and it is possible to misinterpret for misuse almost any machine learning algorithm. . For example, t-SNE, often used for visualization, is also used as dimensionality reduction for clustering. However, most clustering algorithms assume that global distances in a dataset are relevant. This assumption is broken with t-SNE, as evidenced by the inconsistency of t-SNE embeddings on the same data and inability for t-SNE to capture some global trends in a dataset (especially with continuous data, leading to the popularity of graph-based visualizations). . On top of this, each clustering algorithm makes assumptions that data is in fact distributed in clusters, but this is often not the case in single cell data. I agree that it's important to warn users about the limitations of imputation methods, and make them aware that their decision on which algorithm to run can affect their output. However, it seems to me that this conversation could be much broader in scope. We don't currently have a system for unified benchmarking and standardization of single cell analysis methods, so all approaches should be used with some caution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189#issuecomment-413591251:1226,benchmark,benchmarking,1226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189#issuecomment-413591251,1,['benchmark'],['benchmarking']
Testability,"I think this is orthogonal to that. The idea with having a separate argument for how we merge the results from different batches would mean factoring out the merge logic from each flavor and having it be a stand alone operation. It would also change the API here, since we wouldn't be adding a new `flavor`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2792#issuecomment-1892297913:164,log,logic,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1892297913,1,['log'],['logic']
Testability,"I think this looks pretty good. One thing we had discussed was moving out the merge logic for multiple batches from being specified by `flavor` to being specified by a different argument, maybe `merge_flavor` or `batch_flavor`. Have you thought about/ looked into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2792#issuecomment-1892277383:84,log,logic,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1892277383,1,['log'],['logic']
Testability,"I think this would be more appropriate in `anndata`. Since it's not an on disk format, maybe it the function could be called something like `from_starfish`?. * This would also need tests, so some kind of example data.; * Why the differences between this and [starfish's `save_anndata` method](https://spacetx-starfish.readthedocs.io/en/latest/_modules/starfish/core/expression_matrix/expression_matrix.html#ExpressionMatrix.save_anndata)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1362#issuecomment-671720357:181,test,tests,181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1362#issuecomment-671720357,1,['test'],['tests']
Testability,"I think umap works on the connectivities matrix generated from `sc.pp.neighbors`. I guess you can test this by omitting `sc.pp.neighbors` before running umap. Or just running umap after your step 2 and look at the difference. >Yes, my batches have very similar (if not the same) cell type composition. In that case it would make sense for both bbknn and combat to work quite well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666#issuecomment-496866953:98,test,test,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496866953,1,['test'],['test']
Testability,"I think we can merge this for now. I will add other tests I think next week. There is something I don't understand: For the docs, I see that an image is presented together with the API documentation. E.g. [api.pl.dotplot](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.dotplot.html) But I don't see how is this image is referred in the function description. How does this work?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/207#issuecomment-405917660:52,test,tests,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/207#issuecomment-405917660,1,['test'],['tests']
Testability,"I think we can work without this particular fix, we probably only need to update the test data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1669#issuecomment-799447066:85,test,test,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669#issuecomment-799447066,1,['test'],['test']
Testability,"I think you are using a view of the anndata object, rather than the object with that method of subsetting. That shouldn't be related to the issue, but if you want to work with the subset, I would use `.copy()` at the end. Also, does this give you the number of cells and genes as intended? I typically put a `:` for the genes to get something like `adata[cell_filter,:].copy()`. Not sure if that's necessary though. So I think the issue is the `foldchanges[global_indices]` that has values that you can't input into `np.log2`. That can be `NaN` or negative values. A fold change is something like `(average expression in condition 1)/(average expression in condition 2)` if expression values can be negative, then one of those values can be negative, giving a negative fold change. I would guess that these testing frameworks don't play well with negative values. . It is likely that this only pops up now, as the average expression value for the e.g., ""not cluster 3"" data is now negative, where before it wasn't as there was different data to average over. If this is the issue, I'm not entirely sure what to do about this... fold changes aren't defined for such a case. I would either:; 1. rescale the data to be between two non-negative values.; 2. Set all negative values to 0. You could take the code in the `sc.tl.rank_genes_groups()` function and calculate the fold changes for your genes step by step to see if this is the problem. I assume that it is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/653#issuecomment-494347969:807,test,testing,807,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494347969,1,['test'],['testing']
Testability,"I think you might be using an out of date version of scanpy. Try updating that. If that fails, please show your version info by running `sc.logging.print_versions()` and pasting the result here. Probable duplicate of: #781",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1139#issuecomment-608251007:140,log,logging,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1139#issuecomment-608251007,1,['log'],['logging']
Testability,"I think you're all good. Taking another look at the function I believe I had actually tried to completely replace the whole thing (since the logic is fairly convoluted), which ended up breaking functions that relied on the convoluted parts. I think ultimately the whole function should be replaced, ideally using `sc.get._get_obs_rep`. At that point we can rename the argument and make it more widely available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2179#issuecomment-1081877491:141,log,logic,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1081877491,1,['log'],['logic']
Testability,"I took about 20 minutes on it, but couldn't figure out how to add more annotations. I've got interactive versions with hover over, but log scale is bugged in those libraries... I believe the bins that are the darkest shade in the minimum cluster size for the unweighted graph actually correspond to a minimum cluster size of 1 cell. Megakaryocytes were detected as a distinct cluster every time that k was 10 in the unweighted case, but no other times. I think that when we make a call on ""this is a kind of cell"" from unsupervised clustering, those results should be robust. That is, if there's strong signal in the data and your clustering algorithm can pick up that signal, good clusters shouldn't change much if you vary the parameters a little. If you can pick any parameters from a wide range and get results that are pretty consistent, that seems like good data and a good method to me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-488191694:135,log,log,135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-488191694,1,['log'],['log']
Testability,"I tried to improve the ticklabel location which now looks like this. Also, I added a parameter to turn on the labels. ```PYTHON; sc.pl.stacked_violin(adata,marker_genes,groupby='louvain',log=False, yticklabels=True, row_palette='muted'); ```; ![image](https://user-images.githubusercontent.com/4964309/89010208-6a05f680-d30e-11ea-995b-bd5b1a673c51.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1342#issuecomment-666974308:187,log,log,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1342#issuecomment-666974308,1,['log'],['log']
Testability,"I updated release notes and added a test for this specific case. I did not write many tests before, so I looked at the other tests and tried to stick to what I saw there. I noted something unexpected when writing the test: When used `np.mean` and `np.var(.., ddof=1)` to compare against the test failed because some of the variances were off. The current version of the test uses `sc.pp._utils._get_mean_var()` (thats what `highly_variable_genes()` uses internally...), and does not fail.. Is it ok to use that instead? Is it expected that numpy and `_get_mean_var()` are slightly different here?. Test code with numpy ground truth:; ```; def test_seurat_v3_mean_var_output_with_batchkey_vs_numpy():; pbmc = sc.datasets.pbmc3k(); pbmc.var_names_make_unique(); n_cells = pbmc.shape[0]; batch = np.zeros((n_cells), dtype=int); batch[1500:] = 1; pbmc.obs[""batch""] = batch. true_mean = np.mean(pbmc.X.toarray(), axis=0); true_var = np.var(pbmc.X.toarray(), axis=0, ddof=1). result_df = sc.pp.highly_variable_genes(; pbmc, batch_key='batch', flavor='seurat_v3', n_top_genes=4000, inplace=False; ); np.testing.assert_allclose(true_mean, result_df['means'], rtol=2e-05, atol=2e-05); np.testing.assert_allclose(true_var, result_df['variances'], rtol=2e-05, atol=2e-05); ```; Test output:; ```; E AssertionError: ; E Not equal to tolerance rtol=2e-05, atol=2e-05; E ; E Mismatched elements: 172 / 32738 (0.525%); E Max absolute difference: 0.01117667; E Max relative difference: 0.00013328; E x: array([0., 0., 0., ..., 0., 0., 0.], dtype=float32); E y: array([0., 0., 0., ..., 0., 0., 0.]). tests/test_highly_variable_genes.py:279: AssertionError; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1732#issuecomment-797052072:36,test,test,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732#issuecomment-797052072,13,"['Assert', 'Test', 'test']","['AssertionError', 'Test', 'test', 'testing', 'tests']"
Testability,I used the 68k pbmc dataset from 10x genomics for the large dataset. Jupyter notebook with residuals:; [benchmarks_PR1066_residuals.ipynb.zip](https://github.com/theislab/scanpy/files/4234730/benchmarks_PR1066_residuals.ipynb.zip). The memory and timing benchmarks:; ![large](https://user-images.githubusercontent.com/16548075/75012333-97cd4200-5436-11ea-883a-94512bac16a4.png); ![small](https://user-images.githubusercontent.com/16548075/75012334-97cd4200-5436-11ea-9393-696a00b884f8.png),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589529166:254,benchmark,benchmarks,254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-589529166,1,['benchmark'],['benchmarks']
Testability,"I want to second this issue!! I just spent many hours digging into the source code to figure out why `filter_rank_genes_groups` was filtering out genes that reported really high fold changes from `rank_genes_groups`, only to discover the discrepancy in the fold change calculation. Here is an example of how confusing this inconsistency can be:. - I run `rank_genes_groups` and see that many marker genes have high log2 fold changes in `adata.uns['rank_genes_groups']['logfoldchanges'][<cluster_string>]`. For example, gene X has a fold change of -27.720167.; - Then, I run `filter_rank_genes_groups` -- and none of these genes with high negative fold changes are retained; - There are two issues here: one is that negative fold changes don't get retained at all. [This is the issue I notice first, and report in #1325]. I fix that in my fork of the repo (solution below), but STILL these genes are removed when filtering for a min absolute fold change of 1.5 (0.58 on log scale)... ?!; - This boils down to the inconsistency in fold change calculation. Mean expression of gene X within my cluster of interest is 0, and outside it is 0.1997576. `np.log2((0 + 1e-9)/(0.1997576 + 1e-9)) = -27.720167`, as reported originally by `rank_genes_groups`. As a user, I completely expect this gene to pass my threshold. `filter_rank_genes_groups`, however, calculates fold change as `np.log2(np.exp(0)/np.exp(0.199758)) = -0.288189`, which does NOT pass my fold change threshold, thus it gets filtered out. All this happens silently of course [the only number I have seen is a whopping fold change of -27] leaving me utterly confused. I'm not sure which is more correct (though -27 seems pretty inflated to me given the raw numbers), but it would make a lot more sense for it to at least be consistent, especially so that `filter_rank_genes_groups` could give expected results. p.s. Here is my fix to retain downregulated genes in `filter_rank_genes_groups`: update the third condition to `(np.absolute(np.log2(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/863#issuecomment-661497061:469,log,logfoldchanges,469,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/863#issuecomment-661497061,2,['log'],"['log', 'logfoldchanges']"
Testability,"I was able to set up a dev environment with a little work. I think it works? Ran into some other issues though. <details>; <summary> Roughly what I ran </summary>. ```sh; mamba create -yn ""numba-0.55.0rc1-pip"" -c conda-forge python=3.10 pip; conda activate numba-0.55.0rc1-pip; pip install ""numba== 0.55.0rc1-pip""; pip install flit_core setuptools_scm; cd ~/github/anndata; pip install -e "".[dev,doc,test]""; cd ~/github/scanpy; pip install -e --no-build-isolation "".[dev,doc,test]""; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911:400,test,test,400,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911,2,['test'],['test']
Testability,"I was also investigating how `leiden` got `use_weights=True` by default, and noticed the lack of discussion. Seems like it just sorta happened when `leiden` got added #361?. I think it'd be pretty different from clustering on the embedding, because the embedding has constraints based on things like minimum distance two points can be from each other, and the number of dimensions it's embedded in. On the binarized KNN-graph, I think we've actually talked about this before (#240). I personally think using a weighted graph makes more sense. For example, say you have a cell type of which occurs 15 times in your dataset, but you've set k to 30. With a binarized graph there will be a less clear signal that this is a distinct cell-type. From a slightly more empirical/ anecdotal perspective, on a couple datasets I tested, total degree of the generated graph was sub-linear (looked log-ish) w.r.t. `k` for the weighted umap graph. Here's using one of the bone marrow donors from the hca immune census (y-axis is log scaled so you can still see the total weighted degree increase):. ![image](https://user-images.githubusercontent.com/8238804/56469005-400d2580-6477-11e9-98f1-b9dfe70bd1d7.png). To me, this suggested a stable representation of the dataset was being found. As a connected point, in my experience clustering results seems fairly robust to `k` for weighted graphs above a low threshold (I think dataset dependent, but 30-60 range). Using an unweighted graph, there is a much stronger dependence on `k` and some smaller clusters seem less stable (show up in a smaller proportion of clustering solutions from a parameter space).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-485242638:817,test,tested,817,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-485242638,3,"['log', 'test']","['log', 'log-ish', 'tested']"
Testability,"I was just about to ask about the chunking along genes - you read my mind @falexwolf. I think it might be possible to do a multi-dimensional adaptation of the scipy.stats code you linked to, and still do the math with sparse matrices, similar to how we implemented the t-tests. This way we could possibly avoid the chunking (it might help with readability of the code). Would this be worth pursuing?. I'll give this a quick try, but I am a little limited in bandwidth. I'll let you know soon if it would be best to get some help from @Koncopd (if they have time!)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-427489214:271,test,tests,271,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-427489214,1,['test'],['tests']
Testability,"I was looking at the scanpy function to compute the mean and variance an noticed that it had some comments inside, pointing to performance issues. Thus, I looked for an alternative method, found the sklearn sparse function and then tested it in an artificially large matrix. Otherwise, I did not have any trouble with the current implementation. The floating point precision is higher in the sklearn method, thus I suppose this is not an issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/163#issuecomment-392049026:232,test,tested,232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163#issuecomment-392049026,1,['test'],['tested']
Testability,"I was looking at the tests, and something made me think. If `use_raw=False` is given, we use a diverging colormap on purpose, right? Like this:. ![image](https://user-images.githubusercontent.com/1140359/53746250-cb523d80-3e6e-11e9-8952-5c5e93afaf13.png). Now with the new standardization option, values are squashed between 0 and 1 but the color scale is still diverging:. ![image](https://user-images.githubusercontent.com/1140359/53746542-65b28100-3e6f-11e9-9297-e4352c8befc0.png). @fidelram Do you think that's ok, or should we switch back to viridis when `standard_scale` is given, regardless of `use_raw` state?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/512#issuecomment-469314623:21,test,tests,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512#issuecomment-469314623,1,['test'],['tests']
Testability,"I was thinking about these in the context of of feature selection, where you may want a principled cutoff for inclusion. From looking at this in one visium datasets and one single cell dataset. It looks like expected value for any gene with a high morans I were quite low. This was not the case for Geary's C on the umap connectivity with single cell data. Here are some plots around this. Values from permuting the order are in blue, measured values are in black. This only shows the genes which were in the 95th percentile of scores. I inverted the values of gearys C so it was easier to compare with morans I. The x-axis is score between 0 and 1, the y axis is gene rank. It's pretty clear there is much greater dispersion of expected value for Geary's C. <details>; <summary> Morans I UMAP connectivity </summary>. ![image](https://user-images.githubusercontent.com/8238804/112266866-bac8c600-8cc8-11eb-96bc-922256b7e52e.png). </details>. <details>; <summary> Geary's C UMAP connectivity </summary>. ![image](https://user-images.githubusercontent.com/8238804/112266847-b3092180-8cc8-11eb-8e1a-56b26c6bfe23.png). </details>. <details>; <summary> Morans I spatial connectivity </summary>. ![image](https://user-images.githubusercontent.com/8238804/112269342-5b6cb500-8ccc-11eb-8339-b0b9512a5081.png). </details>. <details>; <summary> Geary's C spatial connectivity </summary>. ![image](https://user-images.githubusercontent.com/8238804/112266893-c5835b00-8cc8-11eb-931e-0169ccc0471f.png). </details>. Comparing distribution of scores for the single cell PBMC data:. ![image](https://user-images.githubusercontent.com/8238804/112268036-76d6c080-8cca-11eb-8d0d-a22c1e11ff7c.png). My current thinking is that Gearys C is more sensitive to sparse features, and may be more in need of significance testing. I think this is not as visible for visium data since features are less sparse.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-805564864:1795,test,testing,1795,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698#issuecomment-805564864,1,['test'],['testing']
Testability,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>; <summary> Example output: </summary>. ```; -----; IPython 7.16.1; scanpy 1.5.2.dev38+g6728bdab; sinfo 0.3.1; -----; IPython 7.16.1; PIL 7.2.0; anndata 0.7.5.dev0+g58886f0.d20200729; asciitree NA; backcall 0.2.0; cffi 1.14.0; cloudpickle 1.5.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dask 2.21.0; dateutil 2.8.1; decorator 4.4.2; fasteners NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.2; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.33.0; louvain 0.7.0; matplotlib 3.3.0; monotonic NA; mpl_toolkits NA; msgpack 1.0.0; natsort 7.0.1; numba 0.50.1; numcodecs 0.6.4; numexpr 2.7.1; numpy 1.19.0; packaging 20.4; pandas 1.0.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.7.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.5.2.dev38+g6728bdab; scipy 1.5.1; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.23.1; sphinxcontrib NA; storemagic NA; tables 3.6.1; tblib 1.6.0; texttable 1.6.2; tlz 0.10.0; toolz 0.10.0; traitlets 4.3.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zarr 2.4.0; -----; Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]; macOS-10.15.6-x86_64-i386-64bit; 16 logical CPU cores, i386; -----; Session information updated at 2020-07-30 19:28; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1343#issuecomment-666257831:1488,log,logical,1488,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343#issuecomment-666257831,1,['log'],['logical']
Testability,"I was wondering if using the initial `total_counts` versus the post-filtering `total_counts` really matter that much. In the end we typically only filter out genes that have very few counts, so that the difference between the initial and post-filtering `total_counts` should be minimal. Principally using pre-filtering values is probably more logical, although I'm not sure it really changes anything. I wonder how hard it would be to put scran's size factor calculation into python... that might be a good HiWi project.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/429#issuecomment-460629186:343,log,logical,343,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/429#issuecomment-460629186,1,['log'],['logical']
Testability,"I welcome @VolkerBergen ideas about plot scatter. I have used the scvelo version of scatter and works quite well and always thought that we could integrate this. Our comprehensive collection of tests related to embeddings should facilitate the recreation of the current functionality using a scatter module. As @flying-sheep points out we have a mess with respect to `pl.scatter` and `pl.embeddings` and would be great to unify the code. Currently, `pl.scatter` is used to plot two genes or any two variables like in `sc.pl.highly_variable_genes`. `pl.embedding` takes x,y (and z if 3D) from `.obsm` while adjusting color and size depending on given parameters. When I started working on the plotting functions I didn't touch `pl.scatter` which remains quite convoluted and hard to follow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/617#issuecomment-554257192:194,test,tests,194,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554257192,1,['test'],['tests']
Testability,"I went over all the places where we use the `array_type` fixture and thought about your idea to use `@pytest.mark.parametrize` and I came around to it for this case:. For **unfinished** features, it’s great. Everwhere we can’t say “we fully support this” and gradually build in support, we should use it. It has its disadvantages:. - `@pytest.mark.parametrize(""array_type"", ARRAY_TYPES)` is so long that in practice, it’s hard to see the difference to something like this: `@pytest.mark.parametrize(""array_type"", ARRAY_TYPES_XYZ)`. 	E.g. I don’t like seeing; 	; 	```py; 	@pytest.mark.parametrize(""array_type"", ARRAY_TYPES); 	@pytest.mark.parametrize(""dtype"", [""float32"", ""int64""]); 	```. 	4 times in `test_normalize_total`. If the 3rd test had a different list of values in one of the params, it would be near impossible to see. - Fixtures can depend on other fixtures, but can’t easily have a parameter matrix without that. (`pytest.fixture(params=...)` only accepts a single list of parameters, we’d have to manually use `product` in there for a matrix). That’s why I didn’t go away from a fixture in `test_pca.py`. I therefore propose that we use `@pytest.mark.parametrize` for. - things that aren’t heavily reused; - things we don’t fully support. and fixtures for everything where there’s ~3 or more test functions using the same list of parameter values.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2696#issuecomment-1781361678:735,test,test,735,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2696#issuecomment-1781361678,2,['test'],['test']
Testability,"I will check. Meanwhile, I realized that some errors were introduced in the latest plotting functions, thus I started working in a list of tests to avoid those problems in the future.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/204#issuecomment-405303780:139,test,tests,139,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/204#issuecomment-405303780,1,['test'],['tests']
Testability,"I will take a look later to see how we can integrate better the visualizations, the tests and the documentation. I will put back `kwds` also. . Have you consider adding another dataset to the repository? This will be good for showing examples.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/207#issuecomment-405505301:84,test,tests,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/207#issuecomment-405505301,1,['test'],['tests']
Testability,"I will take a look. On Fri, Jan 11, 2019 at 6:08 PM Andreas <notifications@github.com> wrote:. > Hi thinks for the answer and thanks for the link on the test data and; > visualization, I will try to use that going forward.; >; > I will cook up a non working example if needed, however just looking at; > the code; > https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L302; > there is missing return statements for a few of the plotting functions in; > the _rank_genes_groups_plot unless I missed something they will then not; > return an axes?; >; > The heatmap; > <https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L1044>; > function itself return an axis but there is no return statement from the; > _rank_genes_groups_plot.; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/419#issuecomment-453587853>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1aJAKobdjZYdCil5CcJ3vJz8h-2nks5vCMUmgaJpZM4Z4pAD>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/419#issuecomment-453606922:153,test,test,153,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419#issuecomment-453606922,1,['test'],['test']
Testability,I wonder why the tests are not working now?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-696687023:17,test,tests,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-696687023,1,['test'],['tests']
Testability,"I would definitely recommend using the `sc.logging.print_versions` function for a more complete listing of dependencies, which does include `pynndescent`. That said, I'm not against adding it to the more compact version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1613#issuecomment-768656224:43,log,logging,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1613#issuecomment-768656224,1,['log'],['logging']
Testability,"I would say there is a more general problem. You should be able to expect that `sc.tl.rank_genes_groups(adata)` and then `sc.pl.rank_genes_groups(adata)` always works. However, if adata is subsetted to HVGs and then `sc.tl.rank_genes_groups()` is run with the default of use_raw=True, then you can get genes as top ranked markers which are not in the adata.X subset. Thus, `sc.pl.rank_genes_groups()` or `sc.pl.rank_genes_groups_violin()` will fail as the gene in `adata.uns['rank_genes_groups']['name']` is not found in adata.var_names. This occurs as the plotting is done on adata.X and not adata.raw.X. I've tested this when using the gene_symbols parameter, but it feels like it should also happen when just using regular var_names.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/210#issuecomment-407082502:611,test,tested,611,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/210#issuecomment-407082502,1,['test'],['tested']
Testability,"I would say this is not a scanpy question.; It is not clear what do you mean by correlation of a categorical variable with multiple categories and a continuous variable. ; If you have a binary categorical variable, you can calculate Point Biserial Correlation, but for a multicategorical variable you would have to discretize your continuous variable and calculate Chi-squared test. You can also try ANOVA. If you think you know what variables are dependent and independent you can use logistic regression and look at its coefficients or try ANCOVA.; some additional information with examples; https://datascience.stackexchange.com/questions/893/how-to-get-correlation-between-two-categorical-variable-and-a-categorical-variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1845#issuecomment-848101984:377,test,test,377,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1845#issuecomment-848101984,2,"['log', 'test']","['logistic', 'test']"
Testability,I would suggest `scanpy\[test\]` . Works with BASH and ZSH.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1441#issuecomment-703314166:25,test,test,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441#issuecomment-703314166,1,['test'],['test']
Testability,I'd appreciate a quick review from @fidelram or @flying-sheep on this. It'd be nice to get this soon since the tests failing are blocking the merging of other PRs.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1090#issuecomment-596377120:111,test,tests,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090#issuecomment-596377120,1,['test'],['tests']
Testability,"I'd be interested in hearing what this might break. While I was checking to see if the euclidean distance implementation here got different results than the sklearn one, my (fairly cursory) tests at the repl passed the `np.allclose` test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/245#issuecomment-416827079:190,test,tests,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/245#issuecomment-416827079,2,['test'],"['test', 'tests']"
Testability,"I'd be up for all of the numbered ones. IIRC, I had some issues with the trailing whitespace/ end of file fixers and some binary files/ csvs in the test suite. I'm a bit worried about false positives with `check-large-files`, but so long as it's easy to allow certain things (e.g. intentionally added test data) it should be fine. In terms of breaking these things down into small tasks/ PRs how about: (1), (2, 3), (4, 5)?. `prettier` looks a bit heavy and like it's targeting a lot of stuff we don't use, so you'd have to make a good case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-842799143:148,test,test,148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-842799143,2,['test'],['test']
Testability,"I'd have to think about the naming scheme, since its something I've been going back and forth on recently. I'm playing around with these semantic a bit over in my [mantis](https://github.com/ivirshup/mantis) repo, but I don't think I'm ready to make a call on which one I like best. Right now I'm split between following [plyexperiment](https://github.com/sa-lee/plyexperiment) and `xarray`. I think I'd like to keep them as separate functions, since the `calculate_qc_metrics` function already has about as complicated a relationship as I'd want with parameter values and return type. How about these keep their current name for now, but we don't export these functions beyond `_qc.py`? This will let me play around with their naming scheme and the usefulness a bit more, while scanpy gets the faster, more thorough tests and improved `calculate_qc_metrics`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/615#issuecomment-487265939:817,test,tests,817,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/615#issuecomment-487265939,1,['test'],['tests']
Testability,"I'd like to add this function plus tests to scanpy. I think I'll leave out `n_rings` argument and the `radius_neighbors` functions until there are clear use-cases. I would recommend just having a copy of the code in spatial-tools, which can be deduplicated later.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-707603083:35,test,tests,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-707603083,1,['test'],['tests']
Testability,"I'll keep the focused PRs in mind. The new control flow seems reasonbale. I was unfamiliar with the `@singledispatch` decorator, so it was not directly self explanatory for me. I expected infinity loops and unreachable code, but it turned out to be correct (:. `inf` is there for the sparse case `zero_center=False` and a gene with zero variance but finite mean. Here is the example (slightly modified from the new `tests/test_scaling.py`), with the four cases for genes `(mean==0,mean!=0) x (var==0,var!=0)`:; ```; X = csr_matrix([[-1,2,0,0],[1,2,4,0],[0,2,2,0]]); X = sc.pp.scale(Xtest, copy=True, zero_center=False); X; ```; If `std[std == 0] = eps` (`eps!=0`) is only in the dense path, I get: `array([[-1., inf, 0., 0.], [ 1., inf, 2., 0.], [ 0., inf, 1., 0.]])`; if `std[std == 0] = 1` is before the sparse/dense split, I get: `array([[-1., 2., 0., 0.], [ 1., 2., 2., 0.], [ 0., 2., 1., 0.]])`; if `std[std == 0] = 1e-12` is before the sparse/dense split, I get: `array([[-1., 2.e+12, 0., 0.], [ 1., 2.e+12, 2., 0.], [ 0., 2.e+12, 1., 0.]])`. This suggests, that `0/0` in a sparse setting remains `0` (I guess thats what you see); it makes sense for an efficient sparse matrix implementation, as the `0` is not even represented in the sparse data, so scaling with anything is optimized away. If it were not, it should probably yield `nan` and not `0`.; But if you have something finite with zero variance, you get an explicit `<finite>/0=inf`. [This IS an edge case, and probably never the case in real expression data, but still the behaviour should be consistent and well defined.]; Now, if you have the statement `std[std == 0] = eps` before the sparse/dense split, the `inf` is caught in both cases. The change from `eps=1e-12` to `eps=1` only makes the values keep their original values without zero centering, instead of having these values multiplied by the arbitrary `1e12`. I read the intent for this behaviour into the Note in the docs ""Variables (genes) that do not display any variat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1160#issuecomment-622613221:416,test,tests,416,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1160#issuecomment-622613221,1,['test'],['tests']
Testability,"I'll take a look at this to make sure I've not messed up in writing this wrapper (I'm actually doing some more testing myself for production use right now). . But you should know that what we've done here is mirror some of the internals of scrublet, but using Scanpy functions. Scrublet should be supplied with raw counts, but does do its own normalisations internally before doing the actual doublet prediction, which is what we're doing here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1957#issuecomment-889126422:111,test,testing,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957#issuecomment-889126422,1,['test'],['testing']
Testability,"I'll work a little bit with this branch for a couple of days to test it out myself, I might also push little changes to it. I'm super happy to merge after these tests. :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-424803869:64,test,test,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-424803869,2,['test'],"['test', 'tests']"
Testability,"I'm a little confused about the question. `normalize_total` does try to modify the data inplace:. ```python; adata = sc.AnnData(np.arange(16).reshape((4, 4))); a = adata.X; sc.pp.normalize_total(adata); assert a is adata.X; ```. In general, we try to make most operations in place for efficiency. This should allow people to work with datasets that fit uncomfortably in memory, which might not be an option if a copy was made. Your screenshot does show some weirdness in the anndata constructor where a copy get's made, which there are more details on here: https://github.com/theislab/anndata/issues/129. Basically there's a line in the constructor where:. ```python; adata.X = X.astype(dtype=dtype); ```. where `dtype` defaults to float32. This is something we'd like to remove, but it was troublesome when last attempted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1415#issuecomment-694688826:203,assert,assert,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1415#issuecomment-694688826,1,['assert'],['assert']
Testability,"I'm actually testing and tweaking someone else's code that was written a while ago. I assume they used; `import scanpy.api as sc` because it was appropriate then. I personally resolved my issue by downgrading versions, I just wanted to bring this up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397#issuecomment-683807774:13,test,testing,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397#issuecomment-683807774,1,['test'],['testing']
Testability,"I'm also a bit confused about how the CLR is applied. In the CITE-seq paper, I think it was done within a cell (over proteins), then I think they had switched to within a protein (over cells), and now in Seurat v4 it appears to be back to within a cell. Any per cell normalization is a bit tricky because the panels will differ between datasets as well as the titration of antibodies used. The simplest thing to me seems to be a simple log transformation combined with per protein scaling, as values between proteins are not comparable to begin with. We have some additional thoughts in the appendix of our totalVI paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1469#issuecomment-729339290:436,log,log,436,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469#issuecomment-729339290,1,['log'],['log']
Testability,I'm also not sure why the test is failing -- it works interactively locally for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1182#issuecomment-618699783:26,test,test,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182#issuecomment-618699783,1,['test'],['test']
Testability,"I'm also suddenly having this problem with ""ValueError: Length of values (1) does not match length of index()"" for certain Scanpy functions like `sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac')` and numpy functions `adata.obs['log_counts'] = np.log(adata.obs['n_counts'])`. The error is not due to a problem with my adata file because it reproduces with datasets that were previously error-free.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-944874522:258,log,log,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-944874522,1,['log'],['log']
Testability,I'm as puzzled as you are... We've been discussing this a bit here: #549 . I didn't really change anything of note when Travis started failing. And I have no idea why the test would result in a `1.0`. Do you know if there are any instructions on how to rebuild the test environment in conda? Is it just python 3.5 and scanpy from github?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/580#issuecomment-478620980:171,test,test,171,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478620980,2,['test'],['test']
Testability,I'm confused too. The documentation says that flavor ='seurat' or flavor ='cell_ranger' needs logarithmic data. Why the data is transformed back out of logspace using X=np.expm1(X) if flavor='seurat' ? Doesn't this do nothing if expm1(log1p(X))?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1545#issuecomment-1222015647:94,log,logarithmic,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545#issuecomment-1222015647,2,['log'],"['logarithmic', 'logspace']"
Testability,"I'm getting the same error using the CellBender tutorial output. Attaching the file to make it easier to reproduce. [tiny_10x_pbmc_filtered.h5.zip](https://github.com/scverse/scanpy/files/8766499/tiny_10x_pbmc_filtered.h5.zip). `sc.logging.print_versions()`. ```; -----; anndata 0.7.8; scanpy 1.9.1; -----; PIL 9.0.1; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; doubletdetection 4.2; entrypoints 0.4; executing 0.8.3; google NA; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; ipykernel 6.10.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; mudata 0.1.1; muon 0.1.2; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.2; organize_metadata NA; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.28; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2022.1; scikits NA; scipy 1.8.0; seaborn 0.11.2; session_info 1.0.0; setuptools 62.0.0; setuptools_scm NA; six 1.16.0; sklearn 1.0.2; stack_data 0.2.0; statsmodels 0.13.2; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.63.1; traitlets 5.1.1; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 8.2.0; jupyter_client 7.1.2; jupyter_core 4.9.2; notebook 6.4.10; -----; Python 3.9.11 (main, Mar 28 2022, 10:10:35) [GCC 7.5.0]; Linux-4.15.0-142-generic-x86_64-with-glibc2.27; -----; Session information updated at 2022-05-24 15:05; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2203#issuecomment-1136479284:232,log,logging,232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1136479284,1,['log'],['logging']
Testability,"I'm having some trouble debugging whatever is going wrong with the notebook tests here. I get the same results if I run `pytest` on my machine, but don't get a failure if I run the code manually. Additionally, I don't get an error (the `abort`) if I *only* run the notebook tests (`pytest -k ""test_pbmc3k""`). Pretty sure the error is happening on the call to louvain in the notebook tests – an `assert False` fails the tests, one after gives current result – but I can't reproduce the abort interactively. Any idea what's going on/ how I can get a more helpful error message here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248#issuecomment-419695136:76,test,tests,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248#issuecomment-419695136,5,"['assert', 'test']","['assert', 'tests']"
Testability,"I'm not comfortable with doing an absolute switch without significant testing. I would want a few frequent contributors (Fidel, Sergei, Goecken?) to try it out, try and break it, and make sure we could get things done. I also still have concerns about the limitations of what flit can distribute, and would like to hear other's thoughts on this. If a `setuptools` based workflow can happen, then I don't think these steps are necessarily blocking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-760622794:70,test,testing,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-760622794,1,['test'],['testing']
Testability,"I'm not completely sure this doesn't break anything, but the regression tests pass. The internal code is very similar, so I'm not too worried about these changes. It does look like it's (very) slightly slower. Running this a thousand times for pbmc68k dataset took ~2.3% longer (about 1.4 ms per run) than the previous version. That said, we're very inefficient about mean and variance calculation, so I think that's a better place to optimize. Edit: I've force pushed to fix some minor formatting issues (trailing white space, blank line, typo) that I didn't think deserved it's own commit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/621#issuecomment-487260802:72,test,tests,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/621#issuecomment-487260802,1,['test'],['tests']
Testability,"I'm not super familiar with this code, I had no idea a pie chart could even be used here. @falexwolf or @fidelram may be able to say more here. A few points:. * This should have a regression test, similar to [these](https://github.com/theislab/scanpy/blob/c255fa10fb75f607780ed7d9afc6683cbcecc38e/scanpy/tests/test_plotting.py#L742-L774); * Could you give some more details about the benchmark? 14 seconds seems far too slow for that plot. Also, is that plotting right? The pie charts all look the same.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1123#issuecomment-604224882:191,test,test,191,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123#issuecomment-604224882,3,"['benchmark', 'test']","['benchmark', 'test', 'tests']"
Testability,I'm not sure I totally trust that generated test data to be reproducible across scipy versions. Could you use one of the small example datasets modified in a deterministic way instead? Something like `sc.datasets.krumsiek11()`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1890#issuecomment-871135647:44,test,test,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890#issuecomment-871135647,1,['test'],['test']
Testability,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof; >; > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode; * Changing organization of tests; * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922:303,test,testing,303,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922,5,['test'],"['test', 'testing', 'tests']"
Testability,I'm not sure the benefits from using mypy would outweigh the pain in using unstable numpy type-stubs,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/839#issuecomment-531642595:95,stub,stubs,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839#issuecomment-531642595,1,['stub'],['stubs']
Testability,"I'm sure it will be... Just having network issues atm, so server storage is too slow to do anything. Can't really test this atm I'm afraid :/.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/614#issuecomment-486205965:114,test,test,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/614#issuecomment-486205965,1,['test'],['test']
Testability,"I'm wondering if it would be possible to make a gradient descent based version of COMBAT or similar. It would involve some level of benchmarking, but presumably you would be able to get past the memory issue by streaming data in batches, letting the final weights and correction being informed by the whole data while not needing all of it in memory at once. Could possibly implement with a pytorch backend.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1977#issuecomment-1949231015:132,benchmark,benchmarking,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977#issuecomment-1949231015,1,['benchmark'],['benchmarking']
Testability,I've added a test in https://github.com/theislab/scanpy/pull/1654/commits/189354eb0074140e3f2204d09b02aaa912d13934,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1654#issuecomment-781473683:13,test,test,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1654#issuecomment-781473683,1,['test'],['test']
Testability,"I've added the test mentioned above and checked on two machines (MacOS and CentOS) with the same results. ; The differences in output are after 5th decimal point, the test:; - passes np.allclose both with and without the fix (master branch vs this PR); - passes np.array_equal only with the fix (this PR); Hence, I've kept only the np.array_equal test. This series of tests uses _create_sparse_nan_matrix, so I had to set the np.random.seed to make the test reproducible and agree with the reference.; The reference is stored in tests/_data/ as a pkl file, as I've noticed that there were some analogous files stored there for other tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1890#issuecomment-869646597:15,test,test,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890#issuecomment-869646597,7,['test'],"['test', 'tests']"
Testability,"I've been able to get the tests to pass on a different machine (this one running linux). I can get rid of most of the discrepancies between plots between the two machines by replacing:. ```python; mpl.use(""agg""); ```. with. ```python; from matplotlib.testing import setup; setup(); ```. However violin plots still get a large RMS value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-434538616:26,test,tests,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-434538616,2,['test'],"['testing', 'tests']"
Testability,"I've been using a rough python implementation of Chris McGinnis's MULTIseq demuxing code for all my multiplexed experiments. This algorithm has been incorporated into Seurat as an alternative to their default `HTODemux` function. This [recent preprint](https://www.biorxiv.org/content/10.1101/2020.11.16.384222v1) suggests it's one of the better algorithms for sample demultiplexing. I recently put my implementation on GitHub here: https://github.com/wflynny/multiseq-py. Is there interest in including this in `scanpy.external` in addition to solo? If so, I can invest effort into cleaning up the implementation, adding tests, etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-758885784:622,test,tests,622,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-758885784,1,['test'],['tests']
Testability,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:; ```; import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'); adata.raw=adata.copy() #data to save; sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should; adata=adata.raw.to_adata(); sc.pp.log1p(adata); ##>>> no warning; ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:; ```; import scanpy as sc. ## same as above; adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'); adata.raw=adata.copy() #data to save; sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw; ### saving object, reading, testing again; ### Doesnt work; adata.write_h5ad(tmp+'scanpy_test.h5ad'); adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'); adata=adata.raw.to_adata(); sc.pp.log1p(adata); ###>>>WARNING: adata.X seems to be already log-transformed.; ```. I'm on scanpy 1.9.1 if it matters",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1333#issuecomment-1209486748:304,log,logaritmize,304,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333#issuecomment-1209486748,6,"['Test', 'log', 'test']","['Test', 'log-transformed', 'logaritmize', 'testing']"
Testability,"I've made a few changes:. ## Numba bug. First, the reason that you were getting different issues with floats is that there's a numba bug where the generated parallelized code is completely wrong. I ran into this with gearys_c too, so I've just done a similar thing. It seems to be triggered by having a `np.sum` in a `prange` loop, plus some minor other things. You can check the linked comment info for more details. I believe calculation of `z2ss` in the outer loop was triggering this bug, so I've just moved this into the inner function. Since we're not doing iterations anymore this shouldn't be a performance issue. ## Argument order. So, one bigger organizational change I made is to have consistent argument orders for the elements of a sparse matrix. Basically, always use the same order for positional arguments between functions, otherwise it's very easy to introduce bugs. ## Minor things. * I've modified one of the `morans_i` tests to check that if you pass a dense matrix and a sparse matrix of the same data, you should get the same results.; * I've removed the use of an intermediate array in `_morans_i_vec_W`, since you can just accumulated directly to `inum`.; * Fixed up typing, removed unused exports",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1740#issuecomment-802562555:940,test,tests,940,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1740#issuecomment-802562555,1,['test'],['tests']
Testability,"I've managed to fix this up a bit. Missing (or masked - for `groups`) values in categorical arrays are now always plotted on bottom and use a default color. For spatial plots this default color is transparent. This has led to some code simplification. Surprisingly, this didn't break any tests locally, so a bunch of new tests are probably needed. Continuous values are still a little weird. Right now the points don't show up on embedding plots, and mess up all the colors for spatial plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1356#issuecomment-674738421:288,test,tests,288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356#issuecomment-674738421,2,['test'],['tests']
Testability,"I've managed to mostly fix this with only a slightly hacky change to AnnData (no longer requiring X to have a view type defined when making a copy). However the `normalize_per_cell` test still fails, as it seems like the matrix isn't actually being modified. I think it's because the reference to the dask array on [this line](https://github.com/theislab/scanpy/blob/610a955f025f5f17328865926a9341a55553e081/scanpy/preprocessing/_simple.py#L667) becomes a copy when assigned to. I've asked about this behaviour, and if it might change or throw a warning in https://github.com/dask/dask/issues/5199",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/733#issuecomment-517226549:182,test,test,182,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/733#issuecomment-517226549,1,['test'],['test']
Testability,"I've noticed this behavior too. Here's a couple examples:. ```python; # First, using a standard test dataset; In [1]: %load_ext memory_profiler . In [2]: import scanpy as sc . In [3]: adatas = [] . In [4]: adatas_backed = [] . In [5]: for i in range(10): ; ...: %memit adatas.append(sc.read(""data/pbmc3k_raw.h5ad"")) ; ...: ; peak memory: 223.52 MiB, increment: 48.47 MiB; peak memory: 275.66 MiB, increment: 52.14 MiB; peak memory: 319.36 MiB, increment: 43.71 MiB; peak memory: 361.41 MiB, increment: 42.04 MiB; peak memory: 403.64 MiB, increment: 42.24 MiB; peak memory: 446.02 MiB, increment: 42.37 MiB; peak memory: 488.57 MiB, increment: 42.56 MiB; peak memory: 530.31 MiB, increment: 41.74 MiB; peak memory: 573.53 MiB, increment: 43.21 MiB; peak memory: 615.81 MiB, increment: 42.29 MiB. In [6]: for i in range(10): ; ...: %memit adatas_backed.append(sc.read(""data/pbmc3k_raw.h5ad"", backed=""r"")) ; ...: ; peak memory: 658.04 MiB, increment: 42.07 MiB; peak memory: 700.22 MiB, increment: 42.19 MiB; peak memory: 742.49 MiB, increment: 42.27 MiB; peak memory: 784.62 MiB, increment: 42.14 MiB; peak memory: 827.00 MiB, increment: 42.38 MiB; peak memory: 869.21 MiB, increment: 42.21 MiB; peak memory: 911.36 MiB, increment: 42.14 MiB; peak memory: 953.34 MiB, increment: 41.98 MiB; peak memory: 996.37 MiB, increment: 43.03 MiB; peak memory: 1038.57 MiB, increment: 42.20 MiB. In [7]: %memit ; peak memory: 1038.62 MiB, increment: -0.09 MiB. In [8]: sc.__version__ ; Out[8]: '1.3.7+59.ge0d2ea6'; ```. Using a larger dataset:. ```python; # In a new session:; In [4]: %memit adata = sc.read(""tmp_bm.h5ad"") ; peak memory: 2975.57 MiB, increment: 2799.25 MiB. # In another session:; In [4]: %memit adata_backed = sc.read(""tmp_bm.h5ad"", backed=""r"") ; peak memory: 2969.57 MiB, increment: 2794.57 MiB; ```. While making those examples I got a range of results, though what I've posted are the ones I saw most often. It's enough to make me think there's something strange going on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/434#issuecomment-456037752:96,test,test,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434#issuecomment-456037752,1,['test'],['test']
Testability,"I've punted on this issue for getting the expression atlas downloader added. I think it'd be worth changing the default data directory at the same time as dealing with configuration more generally, so related breaking changes can happen together. I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. [Everett](https://everett.readthedocs.io/en/latest/index.html) seems nice, but maybe a little immature. I like the ability to use context managers (making testing easier) and the auto documentation features. Generally, I think there should be a longer planning discussion about how configuration works. But that could be multiple issues. For example:. * Could we not change global state for plotting? We could shift over to using the `pyplot.rc_context` manager internally.; * What's the appropriate way to set logging level? It seems to keep changing and breaking things; * What's the appropriate precedence for config setting? I'd think `set in session > environment variable > config file > defaults`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932:565,test,testing,565,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932,2,"['log', 'test']","['logging', 'testing']"
Testability,"I've ran into this before (`sc.read_10x_mtx()` has the same default of course). One possible issue with defaulting to `gex_only=False` is that someone might accidentally run a 'regular pipeline' with multi-modal data, e.g. log-normalizing RNA+protein+cell hashing counts together without first subsetting the adata based on `.var[""feature_types""]`. By contrast, anyone who know they have multi-modal data would hopefully notice the missing the data with `gex_only=True`. Either way, logging warnings sounds good.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1949#issuecomment-879247652:223,log,log-normalizing,223,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949#issuecomment-879247652,2,['log'],"['log-normalizing', 'logging']"
Testability,"I've tested this quite a bit in the past 5 days and am merging it into master. In essence, it's a superficial change.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/406#issuecomment-450768851:5,test,tested,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406#issuecomment-450768851,1,['test'],['tested']
Testability,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh; isaac@Mimir:~/github/scanpy ‹master›; $ pytest --version; pytest 6.1.2; isaac@Mimir:~/github/scanpy ‹master›; $ pytest -n 6 --import-mode=importlib; ...; ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================; ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1528#issuecomment-742213296:79,test,tests,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528#issuecomment-742213296,10,['test'],"['test', 'testing', 'tests']"
Testability,"I've update the code to ; - test that the file is actually a tiff image; - automatically add the path to the image to `adata.uns['spatial'][library_id]['metadata']['tissue_image_path']`. It's looking for a tiff or jpeg file with the name `""image""` or `library_id""_image""`. This should cover most cases hopefully?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-734405082:28,test,test,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-734405082,1,['test'],['test']
Testability,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-733605592:106,test,test,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-733605592,4,['test'],['test']
Testability,ILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47114,test,tests,47114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,ILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbo,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48406,test,tests,48406,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"If I catch your point the function prototype would then be. ```; def pca_loadings(; adata: AnnData,; components: Union[str, Sequence[int], None] = None,; include_lowest: bool = True,; n_points: Union[int, None] = None,; show: Optional[bool] = None,; save: Union[str, bool, None] = None,; ):; ```. Then . ```; if n_points is None and adata.n_vars < 30:; n_points = adata.n_vars; elif n_points is None:; n_points = 30. ## should we also prevent user from plotting more than adata.n_vars?. else:; n_points = min(n_points, adata.n_vars); ```; ; considering the tests, I don't see what you expect (sorry, I'm quite new to collaborative work on github):; looking at test_rankings in test_plottings.py, the test should look like; sc.pl.pca(pbmc, n_points=10); save_and_compare_images(""pca_loadings_with_10_points""). but what will it compare to?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2061#issuecomment-985389044:557,test,tests,557,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2061#issuecomment-985389044,2,['test'],"['test', 'tests']"
Testability,"If a linter flexible enough to enforce this existed, it would be great. The test should definitely exist, something in our code requires the docstrings to have that format, I just forgot which part. (But in any case it guarantees consistent formatting so that’s nice). #1492 should fix that test to ignore blank lines for the time being. Also isn’t it cool that it points exactly to the problematic line?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1484#issuecomment-725978155:76,test,test,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484#issuecomment-725978155,2,['test'],['test']
Testability,"If it passes the tests I'm sure it works, feel free to pull it in.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1199#issuecomment-826288598:17,test,tests,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199#issuecomment-826288598,1,['test'],['tests']
Testability,"If p-values are regarded as a valuable output rather than just the ranks, it might be worth recomputing as thresholding would ease the multiple testing burden. I guess that's the idea behind the `min_pCells` parameter request.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471664988:144,test,testing,144,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471664988,1,['test'],['testing']
Testability,"If we can cleanly switch to the igraph implementation for modularity with weights, it could make sense for that to be the default. Any chance you could point me to some benchmarks on performance? An initial test looks very impressive!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-586696126:169,benchmark,benchmarks,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053#issuecomment-586696126,2,"['benchmark', 'test']","['benchmarks', 'test']"
Testability,"If you @a-munoz-rojas would give it another try, using a multi-dimensional chunked implementation along the current implementation and the comment above, then that would be very cool! If you don't have bandwidth for that, could you pass this on to @Koncopd, who might have bandwidth? It would be nice to clean up the whole module (in particular, split up the long code chunks into three functions `_t_test()`, `_wilcoxon()`, `_logreg()`). I also made the tests work again; I guess they failed as the current implementation and scipy are handling ties a little different; the results for scores were exactly the same up to the position of a single gene. . Please make a new PR for any of this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-427484452:455,test,tests,455,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-427484452,1,['test'],['tests']
Testability,"If you have to regress out covariates, maybe you could do it after log transformation? I'm not 100% sure about this approach either though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2110#issuecomment-1103608129:67,log,log,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110#issuecomment-1103608129,1,['log'],['log']
Testability,"If your implementation already uses scanpy, the best is to keep it in your repository and we can link to it from scanpy (see https://scanpy.readthedocs.io/en/stable/ecosystem.html). I did some work on HTOs in the past and for me what worked best was to fit a gaussian mixture but I had not followed the new methods. Something that helped was to visualize the results as follows (each row a different barcode, x axis = log HTO):. ![image](https://user-images.githubusercontent.com/4964309/104469555-edfc2400-55b8-11eb-9f47-580395b255a7.png). If you are interested I can share the code with you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-759510507:418,log,log,418,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-759510507,1,['log'],['log']
Testability,Image files did not match.`; * Some missing function from scipy; * Missing pynndescent; * 3 or 4 more unique ones. <details>; <summary> </summary>. ```python; FAILED scanpy/get/get.py::scanpy.get.get.obs_df; FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_metrics.py::test_consistency[morans_i-allclose] - AssertionError: ; FAILED scanpy/tests/test_paga.py::test_paga_plots[-paga] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:1245,test,tests,1245,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['test'],['tests']
Testability,"ImplicitModificationWarning; 8 from ._core.merge import concat; 9 from ._core.raw import Raw. ~\.conda\envs\NewPy38\lib\site-packages\anndata\_core\anndata.py in <module>; 15 from typing import Tuple, List # Generic; 16 ; ---> 17 import h5py; 18 from natsort import natsorted; 19 import numpy as np. ~\.conda\envs\NewPy38\lib\site-packages\h5py\__init__.py in <module>; 31 raise; 32 ; ---> 33 from . import version; 34 ; 35 if version.hdf5_version_tuple != version.hdf5_built_version_tuple:. ~\.conda\envs\NewPy38\lib\site-packages\h5py\version.py in <module>; 13 ; 14 from collections import namedtuple; ---> 15 from . import h5 as _h5; 16 import sys; 17 import numpy. h5py\h5.pyx in init h5py.h5(). ImportError: DLL load failed while importing defs; ````; Step4: I do `!pip uninstall h5py` and `conda install -c conda-forge pytables h5py`, then; ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_14912/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 4 ; 5 if not within_flit(): # see function docstring on why this is there; ----> 6 from ._utils import check_versions; 7 ; 8 check_versions(). ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\__init__.py in <module>; 27 from .. import logging as logg; 28 ; ---> 29 from .compute.is_constant import is_constant; 30 ; 31 . ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\compute\is_constant.py in <module>; 3 ; 4 import numpy as np; ----> 5 from numba import njit; 6 from scipy import sparse; 7 . ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in <module>; 198 ; 199 _ensure_llvm(); --> 200 _ensure_critical_d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:5748,log,logging,5748,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841,1,['log'],['logging']
Testability,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/549#issuecomment-478933342:257,assert,assert,257,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478933342,3,"['assert', 'test']","['assert', 'testing']"
Testability,"In my opinion, we'll likely move away from logging everything. Isaac built this in so that one can conveniently visualize things in seaborn; I added the switch to turn it off so that the basic tutorial of v1.5 doesn't lead to a completely cluttered AnnData object. But, I guess, we all agree that this here isn't the final solution. 😄",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1226#issuecomment-630023263:43,log,logging,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1226#issuecomment-630023263,1,['log'],['logging']
Testability,"In scanpy 1.10, the line referenced is:. * https://github.com/scverse/scanpy/blob/214e05bdc54df61c520dc563ab39b7780e6d3358/scanpy/preprocessing/_highly_variable_genes.py#L226. But in 1.9.8 the line is:. * https://github.com/scverse/scanpy/blob/6da39f128ecf78cf572f453ee2865d1b901715f3/scanpy/preprocessing/_highly_variable_genes.py#L226. So, to me it seems like the warning would require running an older version of the code. . Can you demonstrate that in a session where `sc.__version__ == ""1.10.0""` you get this warning and show that here? Something like:. ```python; import scanpy as sc; sc.pp.highly_variable_genes(sc.pp.pbmc3k_processed()); sc.logging.print_versions(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2967#issuecomment-2034397517:649,log,logging,649,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2967#issuecomment-2034397517,1,['log'],['logging']
Testability,"In the main code, they have just filtered the gene names and they haven't done anything with the logFC, thus they get left out. I have written the code which can take care of this, please do let me know if I can push this or not.; Besides this, the logFC can be negative but still they are equally significant as that of positive, so can we use **abs** so that the genes for which logFC < -threshold, also holds??",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1446#issuecomment-1759598407:97,log,logFC,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446#issuecomment-1759598407,3,['log'],['logFC']
Testability,In the tests that I have the heatmap seems to be ok. See https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Visualize-marker-genes-using-heatmap. Do you think that the problem occurs when lot of cells/genes are plotted?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/637#issuecomment-517276810:7,test,tests,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-517276810,1,['test'],['tests']
Testability,Indeed the tests have been modified and now `testing.setup` is being used. Thanks for the tip. You can close this issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-453920643:11,test,tests,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-453920643,2,['test'],"['testing', 'tests']"
Testability,"Indeed, ~3-7x faster for me & of course quite a bit more memory efficient (quickly checked with scalene). Tests keep working (for `seurat_v3`/`seurat_v3_paper` somewhat tight numeric comparison with Seurat results), nice.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3017#issuecomment-2122484190:106,Test,Tests,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017#issuecomment-2122484190,1,['Test'],['Tests']
Testability,"Interesting ideas. I actually didn't notice scanpy has no logging implemented - this would indeed be useful and could already solve half the problem indeed. However, I doubt the best way to go about this would be post hoc with decorators etc, but rather intrinsically throughout the various API functions. Regardless of logging, I still think that having something which is intrinsically attached to the object would have the advantage of knowing the exact set of operations solely from the h5ad file/AnnData object itself. Don't know if people are actually out there are also sharing these or not but it could be useful from that perspective too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/472#issuecomment-464492356:58,log,logging,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464492356,2,['log'],['logging']
Testability,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>; <summary> me trying </summary>. ```python; isaac@Mimir:~/tmp/genomic-features-docs; $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy; [ ... ]; isaac@Mimir:~/tmp/genomic-features-docs; $ conda activate test-2978 ; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help.; [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""); Out[4]: <Version('0.9.0')>. In [5]: quit(); (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ pip install -U anndata; Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0); Collecting anndata; Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB); [ ... ]; Downloading anndata-0.10.6-py3-none-any.whl (122 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00; Downloading array_api_compat-1.6-py3-none-any.whl (36 kB); Installing collected packages: array-api-compat, anndata; Attempting uninstall: anndata; Found existing installation: anndata 0.9.0; Uninstalling anndata-0.9.0:; Successfully uninstalled anndata-0.9.0; Successfully installed anndata-0.10.6 array-api-compat-1.6; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ conda list | grep anndata; anndata 0.10.6 pypi_0 pypi; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""); Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757:203,test,test-,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757,5,['test'],['test-']
Testability,"Is because we changed dot edge the defaults shortly before the release. Time to add a test for this. I will make a fix but meanwhile you can trigger the dynamic coloring by setting `dot_edge_color` and `dot_edge_lw` as `None`:. ```PYTHON; sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True)\; .style(color_on='square', dot_edge_color=None, dot_edge_lw=None).show(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1210#issuecomment-682371282:86,test,test,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210#issuecomment-682371282,1,['test'],['test']
Testability,"Is it generally a good idea to output P-values for marker gene identification? As the null model is not valid for this setup, P-values are not really a measure of significance, but should only serve to order genes. I can see the point of outputting log fold changes, but outputting P-values may be misleading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-425353186:249,log,log,249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-425353186,1,['log'],['log']
Testability,"Is that in embedding? I had thought we'd removed all that. There shouldn't be any special meaning to strings starting with `X_` anyways, it's just a convention. I'd like to give this a review, but I'd need to see that tests are passing. Do you know why travis isn't running on this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105#issuecomment-600684687:218,test,tests,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105#issuecomment-600684687,1,['test'],['tests']
Testability,"It doesn't matter for the topic of this discussion indeed. I reckon line 201 is the cause. If you want to solve this as scipy does, you will probably have to test for 0 variance and then assign a `-Inf` score, which defaults to a p-value of 0. I wonder if you get spurious marker gene results then though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/620#issuecomment-486600972:158,test,test,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/620#issuecomment-486600972,1,['test'],['test']
Testability,"It happened many times on centos os I am using and I have been pulling at my hair. Finally what solved my issue is reinstalling traitlets to 5.9.0, which is apparently critical to operations in jupyter notebook. Reading the output logs of the crashed sessions really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2359#issuecomment-1551035497:231,log,logs,231,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359#issuecomment-1551035497,1,['log'],['logs']
Testability,"It is said that ""Be reminded that it is not advised to use the corrected data matrices for differential expression testing."" in scanpy document (http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.mnn_correct.html) when execute MNN correction. However, Haghverdi Laleh (the one who presents MNN correction strategy, https://www.nature.com/articles/nbt.4091) says ""MNN correction improves differential expression analyses, After batch correction is performed, the corrected expression values can be used in routine downstream analyses such as clustering prior to differential gene expression identification"" in his Nature Biotech paper. So, I am a little confused. We have compared some corrections methods, such as regress_out, combat, MNN and MultiCCA (used by seurat), the results show that MNN and CCA have a better effect than regress_out and combat.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/168#issuecomment-395615173:115,test,testing,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/168#issuecomment-395615173,1,['test'],['testing']
Testability,"It is working fine for me and is part of the testing. Which version do you; have? maybe you need to use `n_panels_per_row`. On Thu, Dec 6, 2018 at 3:55 AM Alex Wolf <notifications@github.com> wrote:. > Hm, the code; > <https://github.com/theislab/scanpy/blob/21adc0c9a31fb1eebb16579aa4f41700bc939aa2/scanpy/plotting/tools/__init__.py#L180-L188>; > for this looks fine: do you have less than 5 groups?; >; > n_panels_x = min(n_panels_per_row, len(group_names)); >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/389#issuecomment-444730523>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1du-PES9h_EXgZVonUcbuvlvFKdWks5u2IcsgaJpZM4ZCXJs>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/389#issuecomment-444820105:45,test,testing,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/389#issuecomment-444820105,1,['test'],['testing']
Testability,It looks like all of the tests that failed have to do with ingest functionality and are thus unrelated to this PR. The same ones failed on the PR after this one as well. Let me know what I can do to fix this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027#issuecomment-955073297:25,test,tests,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027#issuecomment-955073297,1,['test'],['tests']
Testability,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2231#issuecomment-1140780018:24,Assert,AssertionError,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1140780018,2,"['Assert', 'test']","['AssertionError', 'tests']"
Testability,"It looks like the underlying issue (`np.zeros` was being called with a heterogeneous `shape` tuple) has been marked to be resolved in the next numba release. We could implement a workaround here where we force the dtype, though numba does have a pretty fast release cadence. @fkoegel, if we implemented a fix here would you be able to test it for us on master branches?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/843#issuecomment-532086499:335,test,test,335,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843#issuecomment-532086499,1,['test'],['test']
Testability,"It looks like those warning are being raised from `scipy.stats.distributions.t.sf`. . This was also happening in the tests, but there's already a bunch of warnings in the tests so we didn't see it. ~~I believe we didn't get this warning from the older code because of these lines:~~. ```python; dof[np.isnan(dof)] = 0		; pvals = stats.t.sf(abs(scores), dof)*2 # *2 because of two-tailed t-test; ```. I don't think it's the above lines anymore, since the replacing the `ttest_ind_from_stats` call with the following still throws the warning:. ```python; df, denom = stats.stats._unequal_var_ttest_denom(; v1=var_group, n1=ns_group, v2=var_rest, n2=ns_rest; ); df[np.isnan(df)] = 0; scores, pvals = stats.stats._ttest_ind_from_stats(; mean_group, mean_rest, denom, df; ); ```. Other than that, potential solutions include:. * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them); * Revert change (would bring back issue of genes with variance of 0); * Wrap the t-test with something like `np.errstate` to hide the warning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/629#issuecomment-488907170:117,test,tests,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-488907170,4,['test'],"['test', 'tests']"
Testability,"It makes sense to use AND logic, because the function keeps genes that satisfy all three conditions. ; 1) Fraction of cells inside the cluster expressing the gene must be greater than `min_in_group_fraction`; 2) Fractions of cells outside the cluster expressing the gene must be less than `max_out_group_fraction`; 3) Fold change must be greater than `min_fold_change`. But there are remaining issues (calculation of fold change and using the absolute value of the fold change) in this function that needs to be updated #863",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1213#issuecomment-629970781:26,log,logic,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213#issuecomment-629970781,1,['log'],['logic']
Testability,It seems like I run into segfaults with the csc implementation. I could not reproduce these with on my PC. I run the tests a lot of times. Since the csr-kernel seems to be working and csr is anyway better for row-based subsets I would propose that we transform the `csc` into a `csr` and than return that for `mask_obs`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2015068347:117,test,tests,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2942#issuecomment-2015068347,1,['test'],['tests']
Testability,"It seems to be a stalled build in CI. Something to do with a URL request... if the tests run through on your end, everything should be fine. Do they?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/343#issuecomment-436045072:83,test,tests,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/343#issuecomment-436045072,1,['test'],['tests']
Testability,"It should definitely run through with these resources, and I and many other people ran it already. @Koncopd, could you check whether everything behaves still normally? I don't know how we can test this, but I also can't see who we might have broken it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/511#issuecomment-469641352:192,test,test,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-469641352,1,['test'],['test']
Testability,It started to go wrong with ff26149 and all I changed there was that I moved the `if inplace:` statement up to the user tests instead of down to where the outputs were written. Is python 3.5 somehow sensitive to whitespace after if statements? I found a whitespace after the `if inplace: `... maybe that's it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/549#issuecomment-478395193:120,test,tests,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478395193,1,['test'],['tests']
Testability,"It would be good to have an open issue here for why we pin matplotlib to a lower version. If I try upgrading it, I get a few failures in the tests for heat maps as well as 3d plotting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/787#issuecomment-532125401:141,test,tests,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787#issuecomment-532125401,1,['test'],['tests']
Testability,"It would've succeeded anyways, it just wasn't testing the right thing",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/494#issuecomment-465924110:46,test,testing,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/494#issuecomment-465924110,1,['test'],['testing']
Testability,"It'd be great have a test for this to catch such bugs next time, like checking the range of the scores.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1335#issuecomment-665417204:21,test,test,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335#issuecomment-665417204,1,['test'],['test']
Testability,"It'll take a little doing, but it's certainly do-able. Something like this should do it:. ```python; import numpy as np; from functools import reduce. def concat(arrays: ""list[np.recarray]""):; names = arrays[0].dtype.names; dtypes = [dict(a.dtype.descr) for a in arrays]; assert all(arrays[0].dtype.names == a.dtype.names for a in arrays[1:]), ""All arrays should have same names""; ; offset = 0; out_dtypes = {}; for k in names:; out_dtype = reduce(np.result_type, (dtype[k] for dtype in dtypes)); out_dtypes[k] = (out_dtype, offset); offset += out_dtype.alignment. out_recarray = np.recarray(sum(map(len, arrays)), dtype=out_dtypes) ; np.concatenate(arrays, out=out_recarray); ; return out_recarray; ```. Maybe the solution should happen upstream though. . Do we concatenate recarrays often?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/753#issuecomment-522930652:272,assert,assert,272,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/753#issuecomment-522930652,1,['assert'],['assert']
Testability,"It's a hard to be sure without a reproducible example (e.g., we'd need to be able to make an `AnnData` object that could trigger this issue), but I suspect some categories in your batch and covariates are completely confounded. Here's an example that would also trigger this:. ```python; import scanpy as sc; import pandas as pd. blobs = sc.datasets.blobs(); blobs.obs[""blobs""] = pd.Categorical(blobs.obs[""blobs""]); blobs.obs[""cov""] = pd.Categorical(blobs.obs[""blobs""] == ""0""). sc.pp.combat(blobs, ""blobs"", covariates=[""cov""]); # LinAlgError: Singular matrix; ```. <details>; <summary> Full traceback </summary>. ```pytb; ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <ipython-input-13-5685c001369c> in <module>; ----> 1 sc.pp.combat(blobs, ""blobs"", covariates=[""cov""]). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 204 # standardize across genes using a pooled variance estimator; 205 logg.info(""Standardizing Data across genes.\n""); --> 206 s_data, design, var_pooled, stand_mean = _standardize_data(model, data, key); 207 ; 208 # fitting the parameters on the standardized data. ~/github/scanpy/scanpy/preprocessing/_combat.py in _standardize_data(model, data, batch_key); 102 ; 103 # compute pooled variance estimator; --> 104 B_hat = np.dot(np.dot(la.inv(np.dot(design.T, design)), design.T), data.T); 105 grand_mean = np.dot((n_batches / n_array).T, B_hat[:n_batch, :]); 106 var_pooled = (data - np.dot(design, B_hat).T) ** 2. <__array_function__ internals> in inv(*args, **kwargs). /usr/local/lib/python3.8/site-packages/numpy/linalg/linalg.py in inv(a); 544 signature = 'D->D' if isComplexType(t) else 'd->d'; 545 extobj = get_linalg_error_extobj(_raise_linalgerror_singular); --> 546 ainv = _umath_linalg.inv(a, signature=signature, extobj=extobj); 547 return wrap(ainv.astype(result_t, copy=False)); 548 . /usr/local/lib/python3.8/site-packages/numpy/linalg/linalg.p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1606#issuecomment-766480303:1011,log,logg,1011,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1606#issuecomment-766480303,1,['log'],['logg']
Testability,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1469#issuecomment-725916572:566,log,log,566,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469#issuecomment-725916572,1,['log'],['log']
Testability,It's not clear to me why these `test_10x` tests are failing here and not on master -- there shouldn't be anything in this diff that affects those tests.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1003#issuecomment-577253898:42,test,tests,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1003#issuecomment-577253898,2,['test'],['tests']
Testability,"Its an issue with numba. See here https://github.com/jmschrei/apricot/blob/98693788ca315ceceeb2eb0f4ce8526f40e0049b/README.md. *Update* Quoting from the REAME above. > If you get an error that looks like; > ; > Inconsistency detected by ld.so: dl-version.c: 224: _dl_check_map_versions: Assertion `needed != NULL' failed!; > ; > or a segmentation fault when importing apricot for the first time then you should try reinstalling numba through conda using; > ; > conda install numba.; > ; > or; > ; > pip install numba==0.39.0; > ; > The issue appears to be with the most recent verson of numba, v0.40.0. Downgrading to numba v0.39.0 should solve the issue. ; > . That means numba should be frozen to v0.39.0 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-427364460:287,Assert,Assertion,287,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-427364460,1,['Assert'],['Assertion']
Testability,"It’s both bullshit that that numpy/numpy#2776 is unfixed since 2012 and Python doesn’t have instance checks for collections without testing for all the mixed-in methods. What we mostly want to test for is if something is iterable and/or indexable. For “sized iterable”, this is possible via `isinstance(x, cabc.Collection)`, but everything more complex has all those mixin methods that are checked for …. At least what we have now is better than `isinstance(x, list)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/839#issuecomment-531701000:132,test,testing,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839#issuecomment-531701000,2,['test'],"['test', 'testing']"
Testability,"It’s connected because the paga tests don’t `copy` the objects and therefore run sequentially, but I can extract it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235#issuecomment-1598722003:32,test,tests,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1598722003,1,['test'],['tests']
Testability,"It’s needed when you modify the `AnnData` object afterwards. The above slices it twice, and only then copies it, because slicing isn’t a modification. So what’s happening is:. ```py; adata_orig = AnnData(...). adata_sliced_view = adata_orig[..., :]; assert adata_sliced_view.is_view; adata_sliced_copy = adata_sliced_view[..., :].copy(); assert not adata_sliced_copy.is_view. do_modify(adata_sliced_copy); ```. The slicing could also have been done in one operation. ```py; adata = adata_orig[(adata.obs[""n_genes_by_count""] < 2500) & (adata.obs[""pct_counts_mt""] < 5), :].copy(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3073#issuecomment-2180456998:250,assert,assert,250,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073#issuecomment-2180456998,2,['assert'],['assert']
Testability,It’s using `__orig_doc__` so the line should be correct. `assert lines[0]` just asserts that the first line is non-empty. `any(broken)` checks if there’s under-indented lines.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1492#issuecomment-726004959:58,assert,assert,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492#issuecomment-726004959,2,['assert'],"['assert', 'asserts']"
Testability,"I’d advise to use the R package. The score is still off and I didn’t figure out why. Sorry. /edit: it works now. I’d like to have a good toy example for the tests that actually has a batch effect, then I’d merge this",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/364#issuecomment-453448469:157,test,tests,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/364#issuecomment-453448469,1,['test'],['tests']
Testability,"I’m doing all the tests @ivirshup proposed. If my explanations to the questions I left open are sufficient, I’ll merge this! :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/676#issuecomment-498701054:18,test,tests,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-498701054,1,['test'],['tests']
Testability,"I’m not a fan of duplicating things. We already install optional requirements via the list of extras here:. https://github.com/theislab/scanpy/blob/f428848ece1d7a4794090eb70a34a3b8f1953dee/.travis.yml#L8. so we should simply add them to the `test` extra:. https://github.com/theislab/scanpy/blob/f428848ece1d7a4794090eb70a34a3b8f1953dee/setup.py#L35. or add more extras (e.g. `dask=['dask[array]'],`) and add them to the list of extras to be installed in .travis.yml",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/439#issuecomment-457915041:242,test,test,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-457915041,1,['test'],['test']
Testability,"I’m talking about unit test. please add one here. You can just add one or more parameter sets to the list, and the test will create a file at `scanpy/tests/figures/master_{id}.png`.; Just copy that file to `scanpy/tests/_images/` and commit it together with the added test. https://github.com/scverse/scanpy/blob/9c6996f374370a7d50768c634e76e50173d22839/scanpy/tests/test_plotting.py#L973-L1082. if you need help, please tell us!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631074929:23,test,test,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631074929,6,['test'],"['test', 'tests']"
Testability,Just a follow up here. I found the code from the Zheng et al. paper:. It appears they do calculate dispersion as var/mean but on the library size normalized counts (not log). https://github.com/10XGenomics/single-cell-3prime-paper/blob/265433ebf858c7fdcab759ca9f36b5e0241ceece/pbmc68k_analysis/util.R#L122-L135,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/969#issuecomment-629667682:169,log,log,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/969#issuecomment-629667682,1,['log'],['log']
Testability,"Just a heads up, I would like to run a few benchmarks on this before merging.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/844#issuecomment-532173941:43,benchmark,benchmarks,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844#issuecomment-532173941,1,['benchmark'],['benchmarks']
Testability,"Just a heads up, it looks like Pandas 1.3.3 might break things again, was experiencing errors that I was able to resolve by downgrading. I can create a new issue if you'd like. Error below so you can determine if this is the same issue or not:; ```; adata.obs['log_counts'] = np.log(adata.obs['n_counts']); File ""/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py"", line 3612, in __setitem__; self._set_item(key, value); File ""/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py"", line 3784, in _set_item; value = self._sanitize_column(value); File ""/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py"", line 4509, in _sanitize_column; com.require_length_match(value, self.index); File ""/opt/conda/lib/python3.8/site-packages/pandas/core/common.py"", line 531, in require_length_match; raise ValueError(; ValueError: Length of values (1) does not match length of index (38978); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1918#issuecomment-925478453:279,log,log,279,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1918#issuecomment-925478453,1,['log'],['log']
Testability,"Just a quick comment... Benjamini-Hochberg correction is usually the standard for multiple-testing correction in differential expression testing. Not sure if you want to take it into account, but I thought I should mention it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/289#issuecomment-428010274:91,test,testing,91,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289#issuecomment-428010274,2,['test'],['testing']
Testability,"Just added a test and changed the behaviour of scale a little more.; The case of zero variance was until now replace with an arbitrary tiny variance, which arbitrarily blew up the scaled value and made it completely meaningless `scale[scale == 0] = 1e-12`.; Now I put instead `scale[scale == 0] = 1`. This yields the same result for `zero_center == True`: all values set to `0`, anyway (but with less arbitrary magic numbers and maybe less rounding errors). But if `zero_zenter == False`, unscalable values are untouched. This only affected the dense codepath where zero-centering was done afterwards anyway due to the original bug. Therefore this is no code breaking change.; But I also moved this statement before the sparse check to have consistent handling of sparse and dense data. Before that the sparse path wrote infs in the values (unchecked divison by zero) - this is a potentially code breaking change, but it only leads to the behaviour already stated in the documentation. I personally think that code relying on this undocumented behaviour should be rewritten, anyway...; In the new test I explicitly check for this behaviour to make it well defined.; Similar for integer datatypes (resulted in an error), they are now converted to floating point for scaling and return a copy. BTW: In order to make the tests run in my conda environment, I had to remove every reference to compare_images from matplotlib.testing.compare. There seems to be a version conflict in the version checking... It always gave errors like the following:; `________________ ERROR collecting scanpy/tests/test_plotting.py ________________; scanpy/tests/test_plotting.py:16: in <module>; from matplotlib.testing.compare import compare_images; ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:240: in <module>; _update_converter(); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:222: in _update_converter; mpl._get_executable_info(""gs""); ~/.conda/envs/cus",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330:13,test,test,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330,1,['test'],['test']
Testability,Just changed the argument a little and added a test. Will be out soon!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1821#issuecomment-1084806101:47,test,test,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1821#issuecomment-1084806101,1,['test'],['test']
Testability,"Just checked on this example; ```; adata = sc.AnnData(np.array([[1, 2],[-1, 2]])); adata.write_loom('test.loom'); adata = sc.read('test.loom', sparse=True); ```; and it looks fine, with retaining the negative value, for both sparse and non-sparse read-in.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/712#issuecomment-505890739:101,test,test,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/712#issuecomment-505890739,2,['test'],['test']
Testability,"Just checked using this dockerfile, works flawlessly:. ```dockerfile; FROM continuumio/miniconda. RUN conda install python=3.8; RUN pip install flit>=3.1; RUN git clone https://github.com/theislab/scanpy.git; WORKDIR /scanpy; # Go to the mainline-pip branch if it hasn’t been merged into master yet; RUN git checkout mainline-pip || true; RUN FLIT_ROOT_INSTALL=1 flit install -s --dep=develop # Make development install of scanpy; # Make sure the dist-info folder has a plus in its name; RUN SCANPY_VERSION=$(python -c 'from importlib.metadata import version; print(version(""scanpy""))') && \; echo $SCANPY_VERSION | grep '+' &&; test -d /opt/conda/lib/python3.8/site-packages/scanpy-$SCANPY_VERSION.dist-info; # Install project that depends on scanpy; RUN pip install scvelo; # Make sure it’s still a dev install; RUN test -L /opt/conda/lib/python3.8/site-packages/scanpy; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1702#issuecomment-788200617:629,test,test,629,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702#issuecomment-788200617,2,['test'],['test']
Testability,"Just load any data, e.g. pbmc3k, then do `sc.pp.calculate_qc_metrics(adata, percent_top=[])` which gives the following: (this is on v1.3.7, haven't tested on earlier versions). ```; In [5]: sc.pp.calculate_qc_metrics(adata, percent_top=[]) ; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-385-66af52bcd3f3> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata, percent_top=[]). ~/miniconda2/envs/py3/lib/python3.6/site-packages/scanpy/preprocessing/qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, inplace); 70 obs_metrics[""log1p_total_{expr_type}""] = np.log1p(; 71 obs_metrics[""total_{expr_type}""]); ---> 72 proportions = top_segment_proportions(X, percent_top); 73 # Since there are local loop variables, formatting must occur in their scope; 74 # Probably worth looking into a python3.5 compatable way to make this better. ~/miniconda2/envs/py3/lib/python3.6/site-packages/scanpy/preprocessing/qc.py in top_segment_proportions(mtx, ns); 182 if not isspmatrix_csr(mtx):; 183 mtx = csr_matrix(mtx); --> 184 return top_segment_proportions_sparse_csr(mtx.data, mtx.indptr, ns); 185 else:; 186 return top_segment_proportions_dense(mtx, ns). IndexError: index -1 is out of bounds for axis 0 with size 0; ```. Not sure if there are other impacts, but I think perhaps basically one just need to check `percent_top` before calling `top_segment_proportions()` at line 72.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/421#issuecomment-453896450:148,test,tested,148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421#issuecomment-453896450,1,['test'],['tested']
Testability,"Just my 2cents: ; I made really good experiences with Github actions.; * I find them easy to set-up and they run many (20-40?) jobs in parallel. ; * Really good integration with Github (e.g. upload to PyPI on release) ; * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1358#issuecomment-674834154:230,test,testing,230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358#issuecomment-674834154,3,['test'],"['test', 'testing']"
Testability,"Just opened a PR to fix this. Quoting from the PR (#1069):. > Note that if you wish to modify the figure in the same jupyter notebook cell in which the plotting function is called, you should set show=False:. ```; fig,ax = sc.pl.dotplot(adata,var_names,show=False); ax.set_xlabel('test'); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/979#issuecomment-589863225:281,test,test,281,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/979#issuecomment-589863225,1,['test'],['test']
Testability,"Just re run it, [tests passed](https://travis-ci.org/github/theislab/scanpy/builds/663089197?utm_medium=notification&utm_source=github_status); No sure why it does not appear on github",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105#issuecomment-600685036:17,test,tests,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105#issuecomment-600685036,1,['test'],['tests']
Testability,"Just tested, works perfectly with the main command. Brilliant job @flying-sheep!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/281#issuecomment-484503926:5,test,tested,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281#issuecomment-484503926,1,['test'],['tested']
Testability,"Just took a look at pbmc3k, your logging still has fractions of a second in there. This logging does not capture times with that accuracy anymore. I tried updating `datetime` in case that's secretly responsible, as you seem to use it internally for time tracking. It was not secretly responsible, the timing discrepancy and lack of deep persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/746#issuecomment-514115289:33,log,logging,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746#issuecomment-514115289,2,['log'],['logging']
Testability,Just wanted to bring this question back up - it would be great if we could get fold changes and p-values returned from the relevant methods for differential testing in scanpy. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/159#issuecomment-420329092:157,test,testing,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159#issuecomment-420329092,1,['test'],['testing']
Testability,"Kinda related, I was about to open an issue on the memory usage of this function. The current implementation can double the memory usage of a program, I believe due to intermediate arrays in the current code. I'd come up with a slower but fewer allocation method for dense arrays (which could probably be sped up with a little `numba`):. ```python; def lessalloc_dense(X):; mean = X.mean(axis=0); mean_sq = np.apply_along_axis(lambda x: np.square(x).mean(), 0, X); var = (mean_sq - mean**2) * ((X.shape[0]/(X.shape[0]-1))); return mean, var; ```. And looked at memory usage using [`memory_profiler`](https://github.com/pythonprofilers/memory_profiler/releases), including @fidelram 's method:. ![mean_var_memory](https://user-images.githubusercontent.com/8238804/40597918-eacd8764-6287-11e8-98ff-017e697b350d.png). [Full script for benchmark here.](https://gist.github.com/ivirshup/a6facfa1ace5b356ea2d18ff3ffe0cb9)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/163#issuecomment-392421567:832,benchmark,benchmark,832,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163#issuecomment-392421567,1,['benchmark'],['benchmark']
Testability,LED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_violin_without_raw - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_path - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[pca] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-float32-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[spatial] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_dimension_broadcasting - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_marker_broadcasting - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:45428,test,tests,45428,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,LED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_violin - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_binary_scatter - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plottin,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49943,test,tests,49943,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,LED scanpy/tests/test_plotting.py::test_scatterplots[pca_multiple_markers_multiple_colors-fn7] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_marker_with_dimensions-fn8] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[3dprojection-fn2] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap-fn14] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_markers_with_dimensions-fn9] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_one_marker-fn5] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca-fn0] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_with_fonts-fn1] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_markers_colors_with_dimensions-fn10] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class ',MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:53491,test,tests,53491,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"LGTM! . Don't worry about the test failures, those are due to a networkx update changing how plots look, which we'll deal with.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1950#issuecomment-887218018:30,test,test,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1950#issuecomment-887218018,1,['test'],['test']
Testability,"Let me check if dot sizes work now. Also, I still have another function I would like to add, which probably requires less work. Just some marker gene overlap test that takes a dictionary as input. Could you give til next week Wednesday for that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/543#issuecomment-475592847:158,test,test,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-475592847,1,['test'],['test']
Testability,"Let's please test this thoroughly, I'm not sure about how stable fold change estimates are in base 2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/931#issuecomment-558659047:13,test,test,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/931#issuecomment-558659047,1,['test'],['test']
Testability,"Looking at the commits page I can see that the tests has been failing for some days already. . First was a problem with a notebook test (test_pbmc3k) that seems innocuous but should be addressed. This is related to release 1.4.3 (https://github.com/theislab/scanpy/commit/85acb6c8949d43d08a26437dceab4fa5db79e246). The commits are unrelated to the failing test so I assume that some dependency was updated . However, after this commit https://github.com/theislab/scanpy/commit/115d635bf950354509053d976b90c1db518bcffe more errors are found. But again, I don't see any relevant changes that will cause the problems. One of the errors is that statsmodels is using a deprecated module from scipy.misc:. ```; > from scipy.misc import factorial; E ImportError: cannot import name 'factorial'; ../../../virtualenv/python3.6.7/lib/python3.6/site-packages/statsmodels/distributions/edgeworth.py:7: ImportError; ```. This was introduced after scipy 1.3 was recently updated (https://github.com/statsmodels/statsmodels/issues/5759). It seems that currently, the only solution is to install statsmodels directly from the master branch. Or downgrade scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166:47,test,tests,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166,3,['test'],"['test', 'tests']"
Testability,"Looks good! Remaining questions:. - The plan is to add the Visium reading function to `anndata`, right?; - You’re repeating yourself with the docs: `doc_scatter_basic` (and therefore `doc_scatter_embedding`) and the docstring of `pl.spatial` both contain similar text for the same parameters. If you want to reorder them, you could do something fancy (like slicing doc_scatter_embedding) or just mention the parameter names in the free text, something like:. ```restructuredtext; Scatter plot in spatial coordinates. Use the parameter `img_key` to see the microscopy image in the background.; Use `crop_coord`, `alpha_img`, and `bw` to control how it is displayed,; and `scale_spot` to control the size of the Visium spots plotted on top.; ```. - Is it possible to derive the amount of cropping? Then we could extend the `crop_coord` parameter to this:. ```py; Union[; Iterable[Literal['left', 'l', 'right', 'r', 'top', 't', 'bottom', 'b']],; Tuple[int, int, int, int], # l, r, t, b; ]; ```. - Maybe it makes sense to add some test data and a test plot? (very low res of course)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1012#issuecomment-578688703:1027,test,test,1027,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1012#issuecomment-578688703,2,['test'],['test']
Testability,"Looks great! I wasn't aware of this high-dimensional version of a t-test in Scipy, which seems to be as efficient as the current implementation. I only investigated thoroughly for Wilcoxon rank and found that Scipy doesn't have a scalable version to offer. But yes, this will get merged after 1.4.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/621#issuecomment-487019494:68,test,test,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/621#issuecomment-487019494,1,['test'],['test']
Testability,Looks great! Let's wait for the tests to complete and merge!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/539#issuecomment-474326729:32,test,tests,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539#issuecomment-474326729,1,['test'],['tests']
Testability,"Looks great! Optimally we’d add a test image like the bottom one in https://github.com/theislab/scanpy/pull/794#issuecomment-523515331, but I’d be up for merging this as-is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/794#issuecomment-524364576:34,test,test,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794#issuecomment-524364576,1,['test'],['test']
Testability,Looks like the tests passed! @fidelram,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1432#issuecomment-700952241:15,test,tests,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432#issuecomment-700952241,1,['test'],['tests']
Testability,"Looks like this is not available for python yet ([docs](https://docs.microsoft.com/en-us/azure/devops/pipelines/test/codecoverage-for-pullrequests?view=azure-devops#prerequisites)). > While you can collect and publish code coverage results for many different languages using Azure Pipelines, the code coverage for pull requests feature discussed in this document is currently available only for .NET and .NET core projects using the Visual Studio code coverage results format (file extension .coverage). Support for other languages and coverage formats will be added in future milestones.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1576#issuecomment-758366276:112,test,test,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1576#issuecomment-758366276,1,['test'],['test']
Testability,"Looks like this not working with `multi_panel` would be introduced by #1422. At the moment my matplotlib tests are being flaky, so I may have some trouble fixing this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2051#issuecomment-993445505:105,test,tests,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2051#issuecomment-993445505,1,['test'],['tests']
Testability,"Looks simple enough! Please deduplicate the tests though, they have too many identical lines.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3042#issuecomment-2092792623:44,test,tests,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042#issuecomment-2092792623,1,['test'],['tests']
Testability,"Looks very good to me, thank you very much!. Would you mind adding an option to select for the correction type that defaults to 'benjamini-hochberg' and can be set to 'bonferroni'?. In the best of all world's, you'd also extend the tests for rank_genes_groups so that the p values are tested and not messed up by pull requests in the future. We want people to get the same p values again and again. And as the whole module sort of involves a lot of custom code as the scipy alternatives are not there for mult-dimensional and sparse data, it's easy to mess this up in the future. Thank you so much for the awesome addition @a-munoz-rojas , I'll add you both to the Scanpy author list and to the release notes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/289#issuecomment-429445105:232,test,tests,232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289#issuecomment-429445105,2,['test'],"['tested', 'tests']"
Testability,Made the `.size` change and added a test. Not entirely sure I have done the test correctly so let me know if that needs adjusting.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2231#issuecomment-1118266184:36,test,test,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1118266184,2,['test'],['test']
Testability,Makes sense that backwards compatibility has to take priority. Integer check will work for most cases (at least it checks if it's still count data). The only exception I can think of is for CPM/size factor normalized data where it would fail (although usually you'd do log-transformation after you normalize otherwise). I can't think of a better method atm either way.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/172#issuecomment-398761924:269,log,log-transformation,269,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/172#issuecomment-398761924,1,['log'],['log-transformation']
Testability,"Malte, don't you have `pytest` installed locally? Debugging using all these `added prints` etc. commits doesn't help maintain a clean git history. :wink:. Is it possible that there is any ambiguity regarding floating point precision? It's a bit hard for me to debug this. In case you don't have python 3.5 installed. Simply do `conda create -n py35 python=3.5`. Calling `pytest scanpy/tests/marker_gene_overlap.py` should rapidly reveal what's going on. Or simply debugging this in a notebook. Thank you and sorry that this causes trouble!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/583#issuecomment-479387950:385,test,tests,385,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-479387950,1,['test'],['tests']
Testability,"Matplotlib 3.4 has dropped 3.6 support. Since matplotlib is our most painful dependency (reliably causes test failures when it updates), it's a great time to drop 3.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1697#issuecomment-809011473:105,test,test,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697#issuecomment-809011473,1,['test'],['test']
Testability,"Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=426) self.state.lifted = (); [428](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=427) self.state.lifted_from = None; --> [429](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=428) return self._compile_bytecode(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:497, in CompilerBase._compile_bytecode(self); [493](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=492) """"""; [494](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=493) Populate and run pipeline for bytecode input; [495](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=494) """"""; [496](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=495) assert self.state.func_ir is None; --> [497](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=496) return self._compile_core(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:476, in CompilerBase._compile_core(self); [474](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=473) self.state.status.fail_reason = e; [475](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=474) if is_final_pipeline:; --> [476](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=475) raise e; [477](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=476) else:; [478](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=477) raise CompilerError(""All available pipelines exhausted""). File D:\Users\xiang",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:20470,assert,assert,20470,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['assert'],['assert']
Testability,"Mmh, very strange. Graph abstraction will be in the next Scanpy release and is not stable yet... Are you simply running the [minimal example](https://github.com/theislab/graph_abstraction/blob/master/minimal_examples/minimal_examples.ipynb)? Maybe reread and reload your data? At some point a few months ago, the format for AnnData files changed. Also, the master branch on Github doesn't have all tests on all notebooks yet, I'd recommend to wait until the release that is scheduled for the next week. Cheers,; alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/40#issuecomment-333528844:398,test,tests,398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40#issuecomment-333528844,1,['test'],['tests']
Testability,"More comprehensive test, similar to the current AnnData slicing tests (no use of external data). Each try/except block will (currently) fail on its last assertion. ```; import sys, traceback; import numpy as np; import scanpy.api as sc. adata = sc.AnnData(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])). # integer indexing; print(""\n>>> integer indexing, obs first""); try:; assert adata[0:2, :][:, 0:2].X.tolist() == [[1,2], [4,5]]; assert adata[0, 0].X.tolist() == 1; assert adata[0:1, 0:1].X.tolist() == 1; assert adata[0, :][:, 0].X.tolist() == 1. except Exception as e:; traceback.print_exc(file=sys.stdout). print(""\n>>> integer indexing, vars first""); try:; assert adata[:, 0:2][0:2, :].X.tolist() == [[1,2], [4,5]]; assert adata[0, 0].X.tolist() == 1; assert adata[0:1, 0:1].X.tolist() == 1; assert adata[:, 0][0, :].X.tolist() == 1. except Exception as e:; traceback.print_exc(file=sys.stdout). # boolean indexing; print(""\n>>> boolean indexing, obs first""); try:; obs_selector = np.zeros(len(adata.obs), dtype=bool); vars_selector = np.zeros(len(adata.var), dtype=bool). obs_selector[:] = [True, True, False]; vars_selector[:] = [True, True, False]; assert adata[obs_selector, :][:, vars_selector].X.tolist() == [[1,2], [4,5]]. obs_selector[:] = [True, False, False]; vars_selector[:] = [True, False, False]; assert adata[obs_selector, :][:, vars_selector].X.tolist() == 1. except Exception as e:; traceback.print_exc(file=sys.stdout). print(""\n>>> boolean indexing, vars first""); try:; obs_selector = np.zeros(len(adata.obs), dtype=bool); vars_selector = np.zeros(len(adata.var), dtype=bool). obs_selector[:] = [True, True, False]; vars_selector[:] = [True, True, False]; assert adata[:, vars_selector][obs_selector, :].X.tolist() == [[1,2], [4,5]]. obs_selector[:] = [True, False, False]; vars_selector[:] = [True, False, False]; assert adata[:, vars_selector][obs_selector, :].X.tolist() == 1. except Exception as e:; traceback.print_exc(file=sys.stdout); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/332#issuecomment-434005191:19,test,test,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332#issuecomment-434005191,15,"['assert', 'test']","['assert', 'assertion', 'test', 'tests']"
Testability,"Most of the time? There is an issue with fairly old CPUs (no AVX2, so like >5 years), but that was the last I saw. My guess is that there are more reproducibility issues on windows than linux, likely because it is tested less. I would like to confirm that it's UMAP and not the PCA though. After that could be worth checking the threading (e.g. reduce to one thread, though I thought UMAP should be as reproducible as possible w.r.t. threading by default).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2114#issuecomment-1016712689:214,test,tested,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1016712689,1,['test'],['tested']
Testability,"Most things?. - pandas has https://github.com/pandas-dev/pandas/tree/main/pandas/_testing; - numpy has https://github.com/numpy/numpy/tree/main/numpy/testing. It also literally has `_private.py` which is awesome since I came up with that on the fly!. They both have `__init__.py` files in their `tests` directory for which I can forgive them since they probably didn’t know about `--import-mode=importlib` (or it didn’t exist) when they created their test suites. They probably ran into some problem about test files having identical names and hacked their way around it. But we can do better since we know better: `--import-mode=importlib` just fixes problems like that, no caveats.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090388986:150,test,testing,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090388986,4,['test'],"['test', 'testing', 'tests']"
Testability,My impression has been that doing the densifying scale transform didn't seem to show performance improvements in a number of benchmarks. This is also the workflow used in [sc-best-practices](https://www.sc-best-practices.org/preprocessing_visualization/normalization.html). @Zethson do you have a good citation for this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034405597:125,benchmark,benchmarks,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034405597,1,['benchmark'],['benchmarks']
Testability,"My point is: The paper suggests that the reason for the zero inflation idea might be the log-transform, so we should offer a better path from counts to distances. Our current path is to go via normally distributed “expression” values which can be used to calculate distances. Something like fold changes, i.e. what we currently do by log-transforming (because `log(count) = foldchange`):. > counts (→ normalization) → expressions (→ normalization) (→ embedding) → distances → analyses. We use PCA as a latent space embedding here for efficiency purposes but it’s not required, we could calculate distances directly from expressions.; One alternative is to stay with (possibly bias-normalized) counts, and create our latent space from those directly using a suitable model (like GLM-PCA):. > counts (→ normalization) → embedding → distances → analyses. The other alternative is to offer something like SCTransform and stay with our original path, bu better. ---. All of this is of course only super important if the log transform turns out to be maximally problematic (which the amount of successful data analyses using it doesn’t suggest), but I think offering alternatives will definitely be very beneficial!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-592503518:89,log,log-transform,89,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-592503518,4,['log'],"['log', 'log-transform', 'log-transforming']"
Testability,"My priority are intuitive semantics so people can add or bump dependencies without 100% understanding the algorithm of the minimum dependency script. So I can think of options:. 1. Each version must be fully specified (`>=1.2.0`, not `>=1.2`). The script installs exactly the specified minimum version. Implementation: Would be quickly done now, just check the job run and change `matplotlib>=3.6` to `matplotlib>=3.6.3` and so on. Effect: whenever we bump something, we probably need to bump more things, which might sometimes be painful. The minimum versions will be more accurate, as we know that the exact versions specified successfully run out test suite. 4. We maintain a list of all dependencies we have together with data about which version segment denotes the patch version (i.e. for semver it’s the third, for calendar ver, it’s nothing), then modify versions based on that knowledge (e.g. semver `>=1.2.3` → `>=1.2.3, <1.3`). Implementation: Each newly added dependency needs to be added to that list. Effect: This would be basically a more powerful (able to specify minimum patch) and obvious version of what you’re doing now (explicit data instead of the presence of a patch version indicating if something is semver or not). In both versions, there’s no hidden semantics in `>=1.2` that would distinguish it from `>=1.2.0`, which is what I’m after. What does your experience while implementing this so far say to these? Any other ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1943497240:650,test,test,650,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1943497240,1,['test'],['test']
Testability,"My questions from #929 don’t apply since you don’t use numba here. Except for “What's the performance difference here”:. It’s not too bad, but we should use base 2 for everything that isn’t the natural logarithm: log2 can be calculated much faster on regular hardware due to binary storage.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/931#issuecomment-558143591:202,log,logarithm,202,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/931#issuecomment-558143591,1,['log'],['logarithm']
Testability,"My thinking on this right now is that:. * The code for masking logic (pre this PR) is kind of a mess; * This PR doesn't make the code nicer. But the performance benefit is quite good, and for sure the operation `X[mask_obs, :] = scale_rv` is something we don't want to do with sparse matrices. I also think we could get even faster, plus a bit cleaner if we instead modified scale array to use something like what I suggest [here](https://github.com/scipy/scipy/issues/20169#issuecomment-1973335172) to accept a `row_mask` argument:. ```python; from scipy import sparse; import numpy as np; from operator import mul, truediv. def broadcast_csr_by_vec(X, vec, op, axis):; if axis == 0:; new_data = op(X.data, np.repeat(vec, np.diff(X.indptr))); elif axis == 1:; new_data = op(X.data, vec.take(X.indices, mode=""clip"")); return X._with_data(new_data); ```. Which *I think* would be something like:. ```python; def broadcast_csr_by_vec(X, vec, op, axis, row_mask: None | np.ndarray):; if row_mask is not None:; vec = np.where(row_mask, vec, 1); if axis == 0:; new_data = op(X.data, np.repeat(vec, np.diff(X.indptr))); elif axis == 1:; new_data = op(X.data, vec.take(X.indices, mode=""clip"")); return X._with_data(new_data); ```. Or, since we're doing numba already we could do just write out the operation with a check to see if we're on a masked row (which *should* be even faster since we're not allocating anything extra). I think either of these solutions would be simpler since we do the masking all in one place, and don't have to have a second update step.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2024951345:63,log,logic,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2942#issuecomment-2024951345,1,['log'],['logic']
Testability,"NaN is a special floating point sentinel value, meaning ""Not a Number."" In general, Python prefers raising an exception to returning NaN, so things like sqrt(-1) and log(0.0) will generally raise instead of returning NaN. However, you may get this value back from some other library. From v0.24, you actually can. [Pandas](http://net-informations.com/ds/pd/default.htm) introduces Nullable Integer Data Types which allows integers to coexist with NaNs. You need to say what you want to do with nans. You can either drop those rows (df.dropna()) or replace nans with something else (0 for instance: df.fillna(0)). My suggestion would be to specifically try to identify this problem (why are you getting this particular NaN), and then write some code to provide a replacement. Also, even at the lastest versions of pandas if the column is object type you would have to convert into float first, something like:. `df['column_name'].astype(np.float).astype(""Int32"")`. NB: You have to go through numpy float first and then to nullable Int32, for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1259#issuecomment-799095321:166,log,log,166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259#issuecomment-799095321,1,['log'],['log']
Testability,"Never mind, just turned off the problem option for the purpose of the tests :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1659#issuecomment-781357674:70,test,tests,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1659#issuecomment-781357674,1,['test'],['tests']
Testability,"Nevermind... it turns out I had changed the parameter before, but not rerun it apparently... I reproduced it setting `log=True`. My bad...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/246#issuecomment-416572288:118,log,log,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/246#issuecomment-416572288,1,['log'],['log']
Testability,"Nice catch - agree on all points regarding inconsistency, the causing sections & the solution with @jlause. Made the PR implementing the ""half-pseudocode"" and added tests which catch your described unexpected behavior for all `flavor`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1867#issuecomment-1814616200:165,test,tests,165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867#issuecomment-1814616200,1,['test'],['tests']
Testability,"Nice! Can you please explain your rationale for why they shouldn’t a) be normal tools and b) saved into the AnnData object?. ```py; sc.tl.gearys_c(pbmc, layer=""logcounts""); to_plot = pbmc.var_names[np.argsort(pbmc.var.gearys_c)[:4]]; ```. Sure, adding more and more features is a good point to think about the API, I’d just like to hear why all current analysis tools belong into `tl` and these two don’t!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-553322915:160,log,logcounts,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-553322915,1,['log'],['logcounts']
Testability,"Nice! Tests should also be run by Travis, shouldn't they? Or have we missed out on demanding dependencies and your tests won't run through for that reason? If so, please point me to it and I'll make sure that Travis actually runs the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/439#issuecomment-456635443:6,Test,Tests,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-456635443,3,"['Test', 'test']","['Tests', 'tests']"
Testability,No idea about the error in the performance test. @flying-sheep ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/945#issuecomment-561423626:43,test,test,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/945#issuecomment-561423626,1,['test'],['test']
Testability,No idea why the unrelated plot tests fail.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1942#issuecomment-877144170:31,test,tests,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1942#issuecomment-877144170,1,['test'],['tests']
Testability,No longer getting errors on plotting tests. Was this being actively worked on? I think it's ready to close otherwise.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-453901572:37,test,tests,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-453901572,1,['test'],['tests']
Testability,"No matter what it returns, it definitely shouldn't make stuff fail. I think that `downsample_counts` was returning integers before the most recent PR as well. iirc, I made `downsample_counts` use integers because a) numba was failing inference unless I was explicit about integers and b) downsampling counts only makes sense for integer valued numbers. At the time I couldn't see a reason to convert the output to a different type. I figure that `log1p` should be able to take an integer valued expression matrix. However, I tried to implement that and ended up adding a lot of flow control to an already flow control heavy function, which got ugly:. <details>; <summary> 🍝 </summary>. ```python; def log1p(data, copy=False, chunked=False, chunk_size=None):; """"""Logarithmize the data matrix. Computes `X = log(X + 1)`, where `log` denotes the natural logarithm. Parameters; ----------; data : :class:`~anndata.AnnData`, `np.ndarray`, `sp.sparse`; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; copy : `bool`, optional (default: `False`); If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""; if copy:; if not isinstance(data, AnnData):; data = data.astype(np.floating); data = data.copy(); elif not isinstance(data, AnnData) and np.issubdtype(data.dtype, np.integer):; raise TypeError(""Cannot perform inplace log1p on integer array""). def _log1p(X):; if issparse(X):; np.log1p(X.data, out=X.data); else:; np.log1p(X, out=X). return X. if isinstance(data, AnnData):; if not np.issubdtype(data.X.dtype, np.floating):; data.X = data.X.astype(np.floating, copy=False); if chunked:; for chunk, start, end in data.chunked_X(chunk_size):; data.X[start:end] = _log1p(chunk); else:; _log1p(data.X); else:; _log1p(data). return data if copy else None; ```. </details>. I'll give that another shot, and open a PR. On the return type of `downsample_coun",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239:762,Log,Logarithmize,762,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239,4,"['Log', 'log']","['Logarithmize', 'log', 'logarithm']"
Testability,No problem - is there a standard input dataset you use for testing? Otherwise I can just use one I have on-hand.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364154163:59,test,testing,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364154163,1,['test'],['testing']
Testability,"No problem, I'll change it to your preferred style. I don't think it's a problem to add the chunking but I'll need to test it for sparse matrices. Just to clarify, what I meant by ""more functional style"" is something like this:. ```; processed_data = raw_data.log1p().normalize(options...).some_other_method(options...); ```. That is, it allows a [functional programming](https://en.wikipedia.org/wiki/Functional_programming) style. Similar to libraries like `scikit-learn` (e.g. `fit()` returns `self` so you can immediately call another method) or `keras` (see the [functional API guide](https://keras.io/getting-started/functional-api-guide/). But as you say, that might be a dramatic change in coding style for your library. I find it can lead to simpler code but that's a personal preference. The above examples are notable because they allow both functional and declarative styles of coding, depending on the user.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/191#issuecomment-403242179:118,test,test,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191#issuecomment-403242179,1,['test'],['test']
Testability,"No problem. . To give you a quick example with some of the inbuilt datasets:. ```; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); adata_sub = adata[adata.obs.bulk_labels.isin(['Dendritic'])]; sc.tl.rank_genes_groups(adata_sub, 'phase', method='t-test', groups=['G1'], reference='S', key_added='g1_upreg') ; sc.pl.rank_genes_groups(adata_sub, key='g1_upreg'); ```. This version actually works and was tested... just to rule out issues with the code I put above.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1035#issuecomment-584271804:259,test,test,259,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035#issuecomment-584271804,2,['test'],"['test', 'tested']"
Testability,No problem. I think increasing the test coverage should be prioritised to make scanpy more robust.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/114#issuecomment-378183576:35,test,test,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/114#issuecomment-378183576,1,['test'],['test']
Testability,"No problem. Maybe something we should consider comes from my attempt to use; plotly with the scatter functions output (probably for bokeh is similar).; Plotly has a function to convert a matplotlib fig object to plotly.; However, for this to work the figure object (the one returned by; pyplot.figure()) has to be returned. Currently, only the axes object are; returned. Thus, we should consider returning the fig object instead of the; axis or add this separately not to break any other code. On Wed, Sep 26, 2018 at 7:33 PM Alex Wolf <notifications@github.com> wrote:. > I'll work a little bit with this branch for a couple of days to test it; > out myself, I might also push little changes to it. I'm super happy to; > merge after these tests. 😄; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/244#issuecomment-424803869>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1afq5UYTS8faVtwGlqyLCpKCIgQkks5ue7pWgaJpZM4WNj5_>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-424844986:637,test,test,637,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-424844986,2,['test'],"['test', 'tests']"
Testability,"No, each of '1' and '2' is tested against the ""rest"" of the data, that is the union of '2' & '3' in the first, and the union of '1' and '3' in the second case. `groups` merely subsets which groups to look at, the default is to look at all, where 'all' will be equivalent to `['1', '2', '3']`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/278#issuecomment-427037743:27,test,tested,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/278#issuecomment-427037743,1,['test'],['tested']
Testability,"No, i see the same test failures on the PR unrelated to plotting. No, i haven't looked yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020492061:19,test,test,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020492061,1,['test'],['test']
Testability,"No, it currently doesn't. Instead it uses the `scores`... usually some ""differential z-score"" that goes into the t-test. We will extend differential testing in the future.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/159#issuecomment-390656402:115,test,test,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159#issuecomment-390656402,2,['test'],"['test', 'testing']"
Testability,"No, looks good and we test the QC metrics.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/462#issuecomment-464624309:22,test,test,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/462#issuecomment-464624309,1,['test'],['test']
Testability,"No, there aren't any references. It's most easy to understand from this: https://github.com/theislab/scanpy/blob/662f66a4c2bc9a254990792f570cc971a444c575/scanpy/tools/_rank_genes_groups.py#L191. We had quite some material before (@tcallies, where did it go?), but we're now moving away from it and will set a different default test in the future.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/365#issuecomment-474304007:327,test,test,327,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365#issuecomment-474304007,1,['test'],['test']
Testability,"Nope, I don't think we can work around this. If the fix is not right, could someone take the tests that are included here and fix them ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1669#issuecomment-800046083:93,test,tests,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669#issuecomment-800046083,1,['test'],['tests']
Testability,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1306#issuecomment-662072716:31,log,login,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306#issuecomment-662072716,2,['log'],"['log', 'login']"
Testability,"Not exactly sure how to test this - it's not that the axis is misordered, it's that we were not informing the violin plot of this ordering. I am not sure if there is a way to access the underlying data of a plot...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3196#issuecomment-2269833379:24,test,test,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196#issuecomment-2269833379,1,['test'],['test']
Testability,Not sure what kind of test to add for this...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/403#issuecomment-453966774:22,test,test,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-453966774,1,['test'],['test']
Testability,"Not sure what the best way of posting this is, but I'll just paste it for now:. Function to score clusters using multiple cell-type markers; ```; #Define cluster score for all markers; def evaluate_partition(anndata, marker_dict, gene_symbol_key=None, partition_key='louvain_r1'):; # Inputs:; # anndata - An AnnData object containing the data set and a partition; # marker_dict - A dictionary with cell-type markers. The markers should be stores as anndata.var_names or ; # an anndata.var field with the key given by the gene_symbol_key input; # gene_symbol_key - The key for the anndata.var field with gene IDs or names that correspond to the marker ; # genes; # partition_key - The key for the anndata.obs field where the cluster IDs are stored. The default is; # 'louvain_r1' . #Test inputs; if partition_key not in anndata.obs.columns.values:; print('KeyError: The partition key was not found in the passed AnnData object.'); print(' Have you done the clustering? If so, please tell pass the cluster IDs with the AnnData object!'); raise. if (gene_symbol_key != None) and (gene_symbol_key not in anndata.var.columns.values):; print('KeyError: The provided gene symbol key was not found in the passed AnnData object.'); print(' Check that your cell type markers are given in a format that your anndata object knows!'); raise; . if gene_symbol_key:; gene_ids = anndata.var[gene_symbol_key]; else:; gene_ids = anndata.var_names. clusters = np.unique(anndata.obs[partition_key]); n_clust = len(clusters); n_groups = len(marker_dict); ; marker_res = np.zeros((n_groups, n_clust)); z_scores = sc.pp.scale(anndata, copy=True). i = 0; for group in marker_dict:; # Find the corresponding columns and get their mean expression in the cluster; j = 0; for clust in clusters:; cluster_cells = np.in1d(z_scores.obs[partition_key], clust); marker_genes = np.in1d(gene_ids, marker_dict[group]); marker_res[i,j] = z_scores.X[np.ix_(cluster_cells,marker_genes)].mean(); j += 1; i+=1. variances = np.nanvar(marker_re",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/290#issuecomment-428502782:782,Test,Test,782,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290#issuecomment-428502782,1,['Test'],['Test']
Testability,"Not sure what's going on here, but it sounds like your environment. Could you post your version info with `sc.logging.print_versions()`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1143#issuecomment-608192740:110,log,logging,110,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143#issuecomment-608192740,1,['log'],['logging']
Testability,"Not sure what's up with Travis... the tests pass on my machine, and they were passing on Travis the whole time... my last commit hasn't really changed anything that would cause this fail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/549#issuecomment-478161476:38,test,tests,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478161476,1,['test'],['tests']
Testability,"Not sure what's up with the test - is it flaky? If not, I can look into it. maybe https://github.com/scverse/scanpy/pull/2889/commits/4bc1c48bee697bc520720723bf3033dd621544fe?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2923#issuecomment-2003908465:28,test,test,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2923#issuecomment-2003908465,1,['test'],['test']
Testability,NotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacke,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2322,Assert,AssertionError,2322,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Assert'],['AssertionError']
Testability,"Notebook tests: there is only one there in the tests, see https://github.com/theislab/scanpy/tree/master/scanpy/tests/notebooks. I run all other linked examples notebooks run manually... So this is not really an option for you, I'd say. I think I can add two important further notebooks very soon so that almost all of the functionality is covered. `setup.py`: yes, definitely, `louvain-igraph>=0.6` is fine! no one should use an earlier version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248#issuecomment-419283151:9,test,tests,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248#issuecomment-419283151,3,['test'],['tests']
Testability,"Nothing should be hardcoded `np.float32`, but it might be that some functions still do that from an early time, where, for instance, scikit-learn's PCA was silently transforming to `float64` (and Scanpy silently transformed back etc.). Nothing should change the dtype that the user wants, except, for instance, when we logarithmize an integer matrix etc. Here, there should be a default `dtype='float32'` parameter. [PS: In algorithms that inherently are unstable and would profit more from higher precision, one could think about increasing precision.]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475999342:319,log,logarithmize,319,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475999342,1,['log'],['logarithmize']
Testability,"Now seurat performs DE analysis using alternative tests including MAST and DESeq2 in a convinent way, such as FindMarkers(pbmc, ident.1 = ""CD14+ Mono"", ident.2 = ""FCGR3A+ Mono"", test.use = ""MAST""). So I hope that Scanpy could interated more methods too, such as diffxpy in this way:; sc.tl.rank_gene_groups(adata, method='diffxpy' or 'MAST'). Here is the hyperlink of DE analysis in Seurat:. https://satijalab.org/seurat/v3.0/de_vignette.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-529105173:50,test,tests,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-529105173,2,['test'],"['test', 'tests']"
Testability,Now that tests are passing I will replace the outdated doc images.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1309#issuecomment-656592229:9,test,tests,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309#issuecomment-656592229,1,['test'],['tests']
Testability,OK! Tests should pass now too,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2870#issuecomment-1954676453:4,Test,Tests,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2870#issuecomment-1954676453,1,['Test'],['Tests']
Testability,"OK! Thanks! @fidelram Should we simply regenerate all images using `matplotlib.testing.setup()`, which seems to be the most stable way to go and in the future restrict ourselves to that? I guess this is closer to a reliable test setup for all the images than the current solution via `mpl.use(""agg"")`. Also the name suggests that matplotlib does it this way. But you did some research at the time when introducing the first tests, right?. Thanks for the comment on the PAGA notebook, too, @ivirshup. I'll make sure that I didn't hard-code anything into the plotting functions that might collide with anything else happening on travis... but it's astonishing... In the meanwhile I work-around with a data-base test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-435729565:79,test,testing,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-435729565,4,['test'],"['test', 'testing', 'tests']"
Testability,"OK, I'll add the tests myself. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/289#issuecomment-430649606:17,test,tests,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289#issuecomment-430649606,1,['test'],['tests']
Testability,"OK, my changes in 426f028708cdd203b7d97d48eb558e695090da82 didn’t make the tests break!. Do we currently not use the plotting test results?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/369#issuecomment-441216129:75,test,tests,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369#issuecomment-441216129,2,['test'],"['test', 'tests']"
Testability,"OK, one more change. The log functions now all return the current time and have the optional parameter `time: datetime`. If you pass something there, the time will be logged:. ```py; start = log.info('foo'); # do stuff; log.hint('bar', time=start) # --> bar (00:00:02); ```. You can customize where the time ends up via `log.*('blah {time_passed}: blub', time=...)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/676#issuecomment-499002256:25,log,log,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499002256,5,['log'],"['log', 'logged']"
Testability,"OK, reproducible with smaller test data:. ```py; adata_file = cache.mkdir(""rank_gene_groups_violin"") / ""test_adata.h5ad""; if not Path(adata_file).exists():; ssl._create_default_https_context = ssl._create_unverified_context; urllib.request.urlretrieve(; ""https://apps-01.i-med.ac.at/resources/tmp/toy_adata.h5ad"", adata_file; ); adata_full = sc.read_h5ad(adata_file); adata = ad.concat([; adata[adata.obs.cell_type == 'Naive CD4+ T cells'][:4, :4],; adata[adata.obs.cell_type == 'Naive CD8+ T cells'][:4, :4],; ], merge='unique'); adata.write(data_path / 't-cells.h5ad'); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2258#issuecomment-1658188074:30,test,test,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258#issuecomment-1658188074,1,['test'],['test']
Testability,"OK, since Isaac has no time, I guess we add more tests in a follow-up PR if necessary",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2776#issuecomment-1857829967:49,test,tests,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2776#issuecomment-1857829967,1,['test'],['tests']
Testability,"OK, that’s weird: Now there’s a bunch of `ImageComparisonFailure`s in the minimal tests job. are they unrelated? A fluke?. https://dev.azure.com/scverse/scanpy/_build/results?buildId=5487&view=logs&j=50ff7263-9206-5a84-1219-938c9ee7fde7&t=2e49bd34-47bd-5a56-3183-6247e293d44d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2836#issuecomment-1915065037:82,test,tests,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2836#issuecomment-1915065037,2,"['log', 'test']","['logs', 'tests']"
Testability,"OK, this is absolutely great, thank you for actually doing the benchmarks! :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/303#issuecomment-443549085:63,benchmark,benchmarks,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/303#issuecomment-443549085,1,['benchmark'],['benchmarks']
Testability,"OK, this should be mostly it. Maybe some cleanup, but no major changes. Test failures are all the server for `ebi_expression_atlas` breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1910279573:72,Test,Test,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1910279573,1,['Test'],['Test']
Testability,"OK, very interesting! Can we have a video call on this? I'd be very interested in seeing a few benchmarks. . At first sight, I'd say it shouldn't be that as the problem also appears when there are no ""deep"" recursions. I'd have thought that it could be this line that brings considerable performance gain (I sent you the reference in an email some time ago):. https://github.com/cmap/cmapPy/blob/7a2e18030f713865e8038bc7351e5ca44d061205/cmapPy/pandasGEXpress/parse_gctx.py#L332-L333. To get away from the recursions and to use `read_direct`, one needs to start exploiting the naming conventions in the `.h5ad` files. As these has have converged since about a year ago, it's save to do it, along with a table that explains the file format and provides an official reference. Right now, the only reference on the file format is [this](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/info_h5ad.md), which is ridiculous. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/303#issuecomment-441476938:95,benchmark,benchmarks,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/303#issuecomment-441476938,1,['benchmark'],['benchmarks']
Testability,OK. I initially thought that PCA is such a fast step that much logging is not needed. But you're right. :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/623#issuecomment-487026385:63,log,logging,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/623#issuecomment-487026385,1,['log'],['logging']
Testability,OR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60745,test,tests,60745,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,OR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62548,test,tests,62548,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,OR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62224,test,tests,62224,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,ORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pyt,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64104,test,testing,64104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,OS: Windows 10; Python version: 3.7.7; sc.logging.print_versions() gives; scanpy==1.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.4 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1246#issuecomment-633439038:42,log,logging,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246#issuecomment-633439038,1,['log'],['logging']
Testability,"Oh, I also added tests for example dataset loading since checking they worked manually was a pain. These won't run by default (they take a while, and can fail for network access reasons), but will run with `pytest --internet-tests`. Note that `test_burczynski06` will fail until this get's rebased on master. Thoughts?. Also travis failed this for `scanpy/tests/test_marker_gene_overlap.py` failing an assertion on the first time around, but passed when I triggered a new build. Not sure what's up with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/573#issuecomment-478414881:17,test,tests,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478414881,4,"['assert', 'test']","['assertion', 'tests']"
Testability,"Oh, I had assumed the test failures were related. Any idea what's up with those?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020439130:22,test,test,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020439130,1,['test'],['test']
Testability,"Oh, I specifically meant `tests` not `{package}/tests`. Though looking through the pandas test it does look like there are fewer internal imports than I recall.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090414562:26,test,tests,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090414562,3,['test'],"['test', 'tests']"
Testability,"Oh, I think I misunderstood earlier when you said:. > I just think that you should probably also add the top-level function to the qc.py file in preprocessing.; ; I wasn't sure if you meant move `calculate_qc_metrics` to `qc.py` or add `top_proportions` and `top_segment_proportions` to the preprocessing module. If you're not asking for that, I'm not sure if they're important enough to go there. I use `top_proportions` to make a `plotScater` kind of plot, but that's about it. Otherwise, I think this might be good for now. I was thinking I'd update the tutorial to use this function after the PR is merged. Once that's done, is there a script to update the tests under `notebooks` or is that done manually?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/316#issuecomment-433771528:661,test,tests,661,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316#issuecomment-433771528,1,['test'],['tests']
Testability,"Oh, and one more thing. It would be great if the test for the batched version could check it was equivalent to computing the doublets separately. E.g. <details>; <summary> modified `test_scrublet_batched` </summary>. ```python; def test_scrublet_batched():; """"""; Test that Scrublet run works with batched data. Check that scrublet runs and detects some doublets.; """"""; pytest.importorskip(""scrublet""). adata = sc.datasets.pbmc3k(); adata.obs['batch'] = 1350 * ['a'] + 1350 * ['b']; split = [adata[adata.obs[""batch""] == x].copy() for x in (""a"", ""b"")]. sce.pp.scrublet(adata, use_approx_neighbors=False, batch_key='batch'). # replace assertions by conditions; assert ""predicted_doublet"" in adata.obs.columns; assert ""doublet_score"" in adata.obs.columns. assert adata.obs[""predicted_doublet""].any(), ""Expect some doublets to be identified""; assert (; 'batches' in adata.uns['scrublet'].keys(); ), ""Expect .uns to contain batch info"". # Check that results are independent; for s in split:; sce.pp.scrublet(s, use_approx_neighbors=False); merged = sc.concat(split). pd.testing.assert_frame_equal(adata.obs[merged.obs.columns], merged.obs); ```. </details>. --------. For the docs, I think you might need to merge from master to get them to build. Sphinx has been acting up a lot recently.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1965#issuecomment-1075220656:49,test,test,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965#issuecomment-1075220656,8,"['Test', 'assert', 'test']","['Test', 'assert', 'assertions', 'test', 'testing']"
Testability,"Oh, no need to do this, I've already got this working a bit more generically (also supports `obsm`) with tests. Just wasn't sure about how to do the keys.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1308#issuecomment-654812288:105,test,tests,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1308#issuecomment-654812288,1,['test'],['tests']
Testability,"Oh, thanks! Sorry for the long downtime, the whole family was sick... I'm going through the PR now. The tests question was actually targeted towards @davidsebfischer, but thanks anyways! The comparison question was also targeted to @davidsebfischer, @tcallies. But if you do it, @andrea-tango, awesome!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471327039:104,test,tests,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471327039,1,['test'],['tests']
Testability,"Oh, that's wonderful and exactly what I had hoped pip on the travis server would do! :smile: You mentioned that you might look into it at some point. I just didn't notice the ; ```; cache: pip; ```; line in the commit... Great that you figured this out! Test times now are really nice, in particular, as I can easily speed them up further... So cool! :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/360#issuecomment-439837732:254,Test,Test,254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/360#issuecomment-439837732,1,['Test'],['Test']
Testability,"Oh, wow, sorry! I completely missed your comment here!. > What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? . What I was thinking: if it's a string get the array from `obsm`, if it's an array, check that it's shape is right, then use the array directly. > It is possible to do something like this. That looks great, thanks!. > I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning. For sure! I was waiting on this actually, just managed to miss any notifications about it. Sorry again about that!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-754420131:464,test,tests,464,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-754420131,1,['test'],['tests']
Testability,"Ok @RubenVanEsch we have to assume that this is a windows problem then. I think we will try to set up a test job and hopefully this catches the problem, although will likely catch others. What happens without a `random_state` set?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034479245:104,test,test,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034479245,1,['test'],['test']
Testability,"Ok this should be good to go @ivirshup , I've incorporated the suggestion from @fidelram , thanks @mvdbeek for first attempt and tests!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1669#issuecomment-826764814:129,test,tests,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669#issuecomment-826764814,1,['test'],['tests']
Testability,"Ok, I found a workaround by subsetting the dataset to 100 obs and 100 vars and writing it back to file with this R package 😅 ; https://bioconductor.org/packages/release/bioc/html/DropletUtils.html . . This dataset now works for both `read_visium` and `pl.spatial` tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1048#issuecomment-586269616:264,test,tests,264,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1048#issuecomment-586269616,1,['test'],['tests']
Testability,"Ok, I ran the test and was successful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-586343222:14,test,test,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-586343222,1,['test'],['test']
Testability,"Ok, good to read that it wasn't log-transformed!. @Koncopd, could you quickly implement these simple changes? Before continuing to work on the UMAP? These simple changes are for 1.4.1, the UMAP will be for 1.5. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-478391082:32,log,log-transformed,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-478391082,1,['log'],['log-transformed']
Testability,"Ok, now the tests are actually passing again, everything is in the three commits prior and including this one: https://github.com/theislab/scanpy/commit/d889faf9a58d8981c0783584b3f333680fc161ce",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-427485305:12,test,tests,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-427485305,1,['test'],['tests']
Testability,"Ok, thank you! Maybe I just didn't find them. If so, please point me to them. Merging this in the meanwhile, you can add the tests in a new PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/594#issuecomment-481653813:125,test,tests,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/594#issuecomment-481653813,1,['test'],['tests']
Testability,"Ok, while trying to implement what I've suggested, I realized I made a mistake and it won't work - I can't specify different markers per 1 call of `ax.scatter`. I don't think the speed is a major issue, since the above example is an extreme case (255 categories). Currently, I don't have any trick up my sleeve on how to speed it up. I've also tried including the regression test, but I can't seem to produce an expected figure. I have the default parameters + 40 dpi as it's in `test_plotting.py`, but the plots that I save are always larger for some reason (tried running it from CLI as well, saving the result from the test case [both options failed]). I've tried whether this is related specifically to the pie chart - it isn't - plotting it without still produces larger plots. @ivirshup any idea what I'm doing wrong?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1123#issuecomment-605284449:375,test,test,375,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123#issuecomment-605284449,2,['test'],['test']
Testability,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users.; - plot function moved to scanpy/external/pl.py as scrublet_score_distribution().; - functions linked via 'See also' sections.; - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-727953553:187,log,logic,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-727953553,2,"['log', 'test']","['logic', 'tests']"
Testability,"Okay, test added!. Couldn't test for use_approx_neighbors since we know from the above that one version of that breaks the CI. Also, 'stdev_doublet_rate' rate seems to have no impact, but I'm fairly sure it's passed correctly, so I'm going to blame the Scrublet code itself.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1659#issuecomment-782141395:6,test,test,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1659#issuecomment-782141395,2,['test'],['test']
Testability,"Okay... I have no idea what else I can do... . I put print statements into the tests and saw that the assignment of names of the `adata.uns['rank_genes_groups']['names']` recarrays is not in the expected order when the tests fail. That's why I put in explicit names into the test data and started testing by these names. For some reason the tests fail when I take the print statements out, but they pass when the print statements are in there... so I can't even look at why they are failing anymore... I may continue to play with this when I have some more time tonight, but I need to focus on some other things atm. If you have any ideas @flying-sheep @ivirshup @falexwolf, I'd be super keen to hear them. Should I just leave print statements in the tests so that it's super verbose when tests fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/583#issuecomment-478954628:79,test,tests,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-478954628,7,['test'],"['test', 'testing', 'tests']"
Testability,"On the other hand, the tests are in the source distribution, including test data, blowing up scanpy’s size to 6MB. I usually put tests next to the package and don’t deliver them to users. We should probably start doing that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/995#issuecomment-574584113:23,test,tests,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995#issuecomment-574584113,3,['test'],"['test', 'tests']"
Testability,"One comprehensive benchmark is [this one](https://ieeexplore.ieee.org/document/8388285/) by Zhang et al (not so up-to-date anymore, though). It'd be nice to establish a ""live"" benchmark repository and compare all methods in a transparent, comprehensive and up-to-date way.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189#issuecomment-404781382:18,benchmark,benchmark,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189#issuecomment-404781382,2,['benchmark'],['benchmark']
Testability,"One important thing: pip supports self-depending. I’ve written dep lists like. ```toml; [project]; name = 'myproj'. [project.optional-dependencies]; # myproj’s exported testing tools depend on those:; testing = ['pytest-postgresql']; # to run our package’s tests, we need:; test = ['pytest', 'myproj[testing]']; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295:169,test,testing,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295,5,['test'],"['test', 'testing', 'tests']"
Testability,"One last thing, could you exclude the test data files from any automatic formatting? I guess it's good to know that new lines at the end of files doesn't matter, but I'd prefer to keep those files exactly as they were written by `spaceranger`/ `zarr`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1848#issuecomment-848593645:38,test,test,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1848#issuecomment-848593645,1,['test'],['test']
Testability,"One of the shortcomings of scanpy's default DE testing is that p-values (or FDR) of a few genes are very significant (equal 0 or approximately 0 in some datasets), then it's impossible to execute -log transformation, even there is only one 0. The volcano plot will be not beautiful because of the high significance.; @falexwolf",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-551419621:47,test,testing,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-551419621,2,"['log', 'test']","['log', 'testing']"
Testability,"Only the tests that fail on master also fail here, so this is fine and can be merged",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/161#issuecomment-391988495:9,test,tests,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/161#issuecomment-391988495,1,['test'],['tests']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; $ git checkout 1.7.x; $ git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; $ git cherry-pick -m1 5fc12f4a918e21f0c57937b787d52040db046f01; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; $ git commit -am 'Backport PR #1587: Attach failing plots to CI results'; ```. 4. Push to a named branch :. ```; git push YOURFORK 1.7.x:auto-backport-of-pr-1587-on-1.7.x; ```. 5. Create a PR against branch 1.7.x, I would have named this PR:. > ""Backport PR #1587 on branch 1.7.x"". And apply the correct labels and milestones. Congratulation you did some good work ! Hopefully your backport PR will be tested by the continuous integration and merged soon!. If these instruction are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1587#issuecomment-787808128:860,test,tested,860,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1587#issuecomment-787808128,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; $ git checkout 1.7.x; $ git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; $ git cherry-pick -m1 ce508c4084e8df272163f4e17136386cfaec2605; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; $ git commit -am 'Backport PR #1768: Fix correlation plot test for new version of matplotlib'; ```. 4. Push to a named branch :. ```; git push YOURFORK 1.7.x:auto-backport-of-pr-1768-on-1.7.x; ```. 5. Create a PR against branch 1.7.x, I would have named this PR:. > ""Backport PR #1768 on branch 1.7.x"". And apply the correct labels and milestones. Congratulation you did some good work ! Hopefully your backport PR will be tested by the continuous integration and merged soon!. If these instruction are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1768#issuecomment-809014499:516,test,test,516,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768#issuecomment-809014499,2,['test'],"['test', 'tested']"
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; $ git checkout 1.7.x; $ git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; $ git cherry-pick -m1 f7279f6342f1e4a340bae2a8d345c1c43b2097bb; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; $ git commit -am 'Backport PR #1679: enables highly_variable_genes_seurat_v3 to accept pseudocounts'; ```. 4. Push to a named branch :. ```; git push YOURFORK 1.7.x:auto-backport-of-pr-1679-on-1.7.x; ```. 5. Create a PR against branch 1.7.x, I would have named this PR:. > ""Backport PR #1679 on branch 1.7.x"". And apply the correct labels and milestones. Congratulation you did some good work ! Hopefully your backport PR will be tested by the continuous integration and merged soon!. If these instruction are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1679#issuecomment-814587648:888,test,tested,888,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1679#issuecomment-814587648,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.10.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 5c0e89e99dc2461c654c549435a73f547f3573ce; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #3339: Add PYI lints'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.10.x:auto-backport-of-pr-3339-on-1.10.x; ```. 5. Create a PR against branch 1.10.x, I would have named this PR:. > ""Backport PR #3339 on branch 1.10.x (Add PYI lints)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3339#issuecomment-2457653625:856,test,tested,856,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3339#issuecomment-2457653625,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.10.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 5d5d873b1fb0353089569f85580b43437df9c6cd; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #3104: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.10.x:auto-backport-of-pr-3104-on-1.10.x; ```. 5. Create a PR against branch 1.10.x, I would have named this PR:. > ""Backport PR #3104 on branch 1.10.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3104#issuecomment-2160085624:904,test,tested,904,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3104#issuecomment-2160085624,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.10.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 8d046ff37e024ae88eadfb22ea8fd142a6b95aa1; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #3093: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.10.x:auto-backport-of-pr-3093-on-1.10.x; ```. 5. Create a PR against branch 1.10.x, I would have named this PR:. > ""Backport PR #3093 on branch 1.10.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3093#issuecomment-2146729991:904,test,tested,904,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3093#issuecomment-2146729991,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 05dcf68f32ce255447ea804de55babefb3c47c92; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2753: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2753-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2753 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2753#issuecomment-1809942763:899,test,tested,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2753#issuecomment-1809942763,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 330a099ffe76286f0f047387701af7e9fd58831a; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2838: Fix pytest 8 compat'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2838-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2838 on branch 1.9.x (Fix pytest 8 compat)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2838#issuecomment-1923260036:863,test,tested,863,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2838#issuecomment-1923260036,2,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 47664d83a7bc47756356b907e5719076ab187361; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2784: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2784-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2784 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2784#issuecomment-1862463379:899,test,tested,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2784#issuecomment-1862463379,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 4f4b1c3a655546d981360bcce625d354a4291385; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2811: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2811-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2811 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2811#issuecomment-1893536608:899,test,tested,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2811#issuecomment-1893536608,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 585f58c9e4dd82dd7809a831538c4e230b008818; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2841: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2841-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2841 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2841#issuecomment-1929072209:899,test,tested,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2841#issuecomment-1929072209,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 5ccce795b19a5aa59a6b1f1c3552884ed6fc94d1; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2544: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2544-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2544 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2544#issuecomment-1619899808:899,test,tested,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2544#issuecomment-1619899808,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 86dc4d5d96eb7547833e7805ea2f7d603bd3ba2d; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2779: Fix anndata warnings'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2779-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2779 on branch 1.9.x (Fix anndata warnings)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2779#issuecomment-1858121974:865,test,tested,865,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2779#issuecomment-1858121974,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 95206dc54c8bb0d9d478f09f47dff9477a5c58c4; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2704: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2704-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2704 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2704#issuecomment-1776676386:899,test,tested,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2704#issuecomment-1776676386,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 b23229f9bfc95ff90a5d6393b4d53d062190d5bb; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2732: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2732-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2732 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2732#issuecomment-1795950835:899,test,tested,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2732#issuecomment-1795950835,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 bf5f27aa9e968de6e73fc7abb46a89084ddf6880; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2831: Prepare 1.9.8, stop ignoring citation errors'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2831-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2831 on branch 1.9.x (Prepare 1.9.8, stop ignoring citation errors)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2831#issuecomment-1911960423:913,test,tested,913,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2831#issuecomment-1911960423,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 c2f706b35d52a5e21ccf84f1cd299b0dadf49668; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2716: Add missing link targets'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2716-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2716 on branch 1.9.x (Add missing link targets)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2716#issuecomment-1780921886:873,test,tested,873,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2716#issuecomment-1780921886,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 c410cd123f5487f25c08b421c8d06da50551ff73; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2799: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2799-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2799 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2799#issuecomment-1882962300:899,test,tested,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2799#issuecomment-1882962300,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 e5d41d4aa58a925f0fa5cfcf580cb975167a71c9; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2235: Separate test utils from tests'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2235-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2235 on branch 1.9.x (Separate test utils from tests)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870:499,test,test,499,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870,5,['test'],"['test', 'tested', 'tests']"
Testability,PES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72626,test,testing,72626,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,PES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66563,test,testing,66563,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,PES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66881,test,testing,66881,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,PES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspac,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69340,test,testing,69340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,PES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62793,test,tests,62793,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,PES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63448,test,testing,63448,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,PPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61490,test,testing,61490,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,PPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/wo,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74430,test,tests,74430,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"PPS: I see that I'm getting test failures with some github automatic tests, with none of the failures clearly coming from the code I edited -- do you know what is going on here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-902986463:28,test,test,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-902986463,2,['test'],"['test', 'tests']"
Testability,"PS: You don't need a test for this... it would require installing phate on travis and this would take time... Also, the interface is trivial. You should simply link to your package within the docs to redirect people for bugs and more info.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/136#issuecomment-385960220:21,test,test,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136#issuecomment-385960220,1,['test'],['test']
Testability,"Part of why I would like this to be in `sklearn` is that it lessens our responsibility to maintain it, and simplifies our code. I think it'll be easiest to do this sooner, rather than later, since these things have a tendency to lose momentum. For sklearn submission, I don't think you'd have to implement any classes. Your solution would just be what happened if someone passed a sparse matrix and `solver=""arpack""` to `PCA.fit`, like what https://github.com/scikit-learn/scikit-learn/pull/12841 does. Does this make it more appealing? If not, would you mind if I opened a PR to sklearn with this code (crediting you, of course)?. ----------------. About this PR, could you add tests for:. * The variance and variance explained entries being correct; * Explicit and implicit centering returning equivalent results. After that and the code reorganization I mentioned above, this should be about ready to merge.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-593822877:679,test,tests,679,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-593822877,1,['test'],['tests']
Testability,"Perf measurements for the use case of running the HVG tests on my machine (not very accurate, and not very reminiscent of how users use it). Tests get a bit slower, real world gets faster. - scanpy master:. ```console; $ git switch master; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:54,test,tests,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266,6,"['Test', 'test']","['Tests', 'test', 'tests']"
Testability,"Phil, thanks for this! I'm slowly finding time again to deal with these things. I looked through it and it's a very nice solution. I'll test it these days and merge it into master. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/38#issuecomment-335447670:136,test,test,136,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/38#issuecomment-335447670,1,['test'],['test']
Testability,"Please adapt the corresponding test to:. ```; @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); def test_scale(flavor):; adata = pbmc68k_reduced(); adata.X = adata.raw.X; v = adata[:, 0 : adata.shape[1] // 2]; # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; assert v.is_view; with pytest.warns(Warning, match=""view""):; sc.pp.scale(v, flavor=flavor); assert not v.is_view; assert_allclose(v.X.var(axis=0), np.ones(v.shape[1]), atol=0.01); assert_allclose(v.X.mean(axis=0), np.zeros(v.shape[1]), atol=0.00001); ```. It fails for me with `FAILED scanpy/tests/test_preprocessing.py::test_scale[use_fastpp] - numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267:31,test,test,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267,4,"['assert', 'test']","['assert', 'test', 'tests']"
Testability,"Please add the relevant part of `jupyter lab`’s log. If it’s a SEGFAULT, please reproduce with the [`PYTHONFAULTHANDLER`](https://docs.python.org/3/using/cmdline.html#envvar-PYTHONFAULTHANDLER) env variable set to a non-empty string to get a traceback",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2840#issuecomment-1929143068:48,log,log,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2840#issuecomment-1929143068,1,['log'],['log']
Testability,"Please go ahead!. On Tue, Feb 12, 2019 at 6:41 PM Philipp A. <notifications@github.com> wrote:. > Ah, sorry for being in the way here with the unrelated logging changes.; > Alex is currently a bit ill I learned, which is why he probably didn’t do; > it yet. I didn’t have time to review the whole thing, but if y’all want I; > can do that too; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/425#issuecomment-462858876>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1RE9LYK4sL6sLFd586y_cpEBQKxwks5vMvzRgaJpZM4Z-M3d>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/425#issuecomment-463080680:153,log,logging,153,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-463080680,1,['log'],['logging']
Testability,"Possible TODO:. - normalize_pearson_residuals_pca. @ivirshup I reverted the change in a6290ee9e0d1baf0e3483118aa552b6f6dcf02c0 where you changed. ```diff; -X_pca = np.zeros((X.shape[0], n_comps), X.dtype); +X_pca = np.zeros((adata_comp.shape[0], n_comps), adata.X.dtype); ```. the commit message is “Fix up pca tests”, but that change doesn’t seem to impact tests and it takes properties from several different object without reasoning.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2272#issuecomment-1807755523:311,test,tests,311,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2272#issuecomment-1807755523,2,['test'],['tests']
Testability,Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:22: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:52: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: no,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:8647,test,test,8647,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['test'],['test']
Testability,Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:52: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:26: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:11270,test,test,11270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['test'],['test']
Testability,"Question for this, what heuristics have you tried? My guess would be that `min(distances_between_points) / 3` should be fine for an upper bound. Second, I think this logic is a little convoluted, and I don't know that `library_id` will always be associated with visium only. Would a better check be for `[""metadata""][""software_version""]` or something like that?. It might help for me to know what exactly you're planning on putting in the `""spatial""` entry.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-738578221:166,log,logic,166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-738578221,1,['log'],['logic']
Testability,"Quick question to you @ivirshup, can't we simply replace all the `adata_neighbors` stuff with `scanpy.datasets.pbmc68k_reduced`? It already has the neighbor graph etc. in it and is smaller, that is, would speed up tests considerably.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/581#issuecomment-479418054:214,test,tests,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479418054,1,['test'],['tests']
Testability,R scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65504,test,tests,65504,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,R scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportErr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69585,test,tests,69585,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,RAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.para,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66069,test,tests,66069,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,RAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68362,test,testing,68362,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,ROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60906,test,tests,60906,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,ROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - Imp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68770,test,tests,68770,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,ROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportErr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64848,test,tests,64848,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,RROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3724,test,tests,3724,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['test'],['tests']
Testability,RROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - Im,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61892,test,tests,61892,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,RROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportErro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69098,test,tests,69098,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,RROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_grou,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72211,test,tests,72211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,RROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64353,test,tests,64353,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"Re: quotes: Yes, the difference is that escape sequences work in double quoted strings. So for me a double quoted string in otherwise single quoted TOML means “pay attention, this one has special stuff in it”. Re: Build: The problem is that. 1. we’re installing louvain and it; 2. [doesn’t have a Python 3.9 wheel](https://pypi.org/project/louvain/#files), which causes us to download the sdist,; 3. [Sets `2to3=True` in setup.py](https://github.com/vtraag/louvain-igraph/blob/0.7.0/setup.py#L827-L828), for which [setuptools has removed support](https://setuptools.pypa.io/en/latest/history.html#v58-0-0). I think the best course of action would be to just port louvain to Python 3 only, and until then make sure our build environment as setuptools 57 installed. See https://github.com/vtraag/louvain-igraph/issues/57. Or we can deactivate louvain tests, skip installing it in the tests, and let people who need it deal with that. Or we ask @vtraag to upload Python 3.9 and 3.10 wheels, then we kicked the problem back two releases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2042#issuecomment-967619897:849,test,tests,849,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2042#issuecomment-967619897,2,['test'],['tests']
Testability,"Re: testing externals, I've tried my best to just test the way it interfaces with scanpy. i.e., if MAGIC silently fails to return the correct output, scanpy tests would pass so long as the output is the right type / shape. If MAGIC throws an error when run from scanpy, this might be something you would like to address (i.e. by contacting the relevant external developer) regardless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/988#issuecomment-573589189:4,test,testing,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/988#issuecomment-573589189,3,['test'],"['test', 'testing', 'tests']"
Testability,"Regarding Pearson vs. deviance residuals @adamgayoso: we looked into in in detail for the second version of the manuscript (just posted to bioRxiv: https://www.biorxiv.org/content/10.1101/2020.12.01.405886v2.full.pdf). Our conclusion is that deviance residuals don't work here at all because they -- unlike Pearson residuals -- show a very strong mean-variance relationship. Here, see an excerpt from Figure S2:. ![Screenshot from 2021-04-28 09-29-02](https://user-images.githubusercontent.com/8970231/116365322-6f449300-a805-11eb-8458-0bbf2aceb23a.png). I was surprised by that because I fully expected that deviance and Pearson residuals would be very similar and we'd see no qualitative difference between them. But this wasn't the case. See also a new benchmark in Figure 5. > I was using GLM-PCA as a generic example, but I then realized that coincidentally in the GLM-PCA paper they describe a fast analytical approximation using deviance residuals, which is not compared to in the analytical Pearson residuals manuscript (and again highlights the potential role of peer-review IMO). Re peer review -- as I already mentioned, none of the actual reviewers asked us about deviance residuals ;-) So thanks a lot for voicing these concerns here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-828228025:756,benchmark,benchmark,756,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-828228025,1,['benchmark'],['benchmark']
Testability,"Regarding running CI with minimal optional deps, I’d say we could change this line:. https://github.com/scverse/scanpy/blob/86e2a35c1df2b61772e5f898bfcd11abb8d9fb2c/.azure-pipelines.yml#L46. … to be parametric like `pip install .[dev,test$(test_extras))]`, and run things once with `test_extras=''` and once with `test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'`. we’d probably have to make a lot of tests optional with `@skipif(not find_spec('thing'), ...)` though, and of course remove some things from the `test` extra",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088710180:234,test,test,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088710180,3,['test'],"['test', 'tests']"
Testability,Reminder: Check Benchmarks,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3284#issuecomment-2435684966:16,Benchmark,Benchmarks,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3284#issuecomment-2435684966,1,['Benchmark'],['Benchmarks']
Testability,SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65585,test,testing,65585,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,S_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69840,test,tests,69840,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,S_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.pa,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61975,test,testing,61975,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,S_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/worksp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69181,test,testing,69181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,S_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65751,test,tests,65751,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"Same error here...any ideas?. ```; -----; anndata 0.8.0; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; anndata 0.8.0; anndata2ri 0.0.0; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; backports NA; beta_ufunc NA; binom_ufunc NA; bs4 4.10.0; cached_property 1.5.2; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.02.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.10.0; entrypoints 0.4; fsspec 2022.02.0; get_version 3.5.4; h5py 3.6.0; igraph 0.9.9; ipykernel 6.9.1; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; markupsafe 2.1.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.0; numpy 1.21.5; packaging 21.3; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.27; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.7; pytz 2021.3; pytz_deprecation_shim NA; rpy2 3.4.2; scanpy 1.8.2; scipy 1.7.3; seaborn 0.11.2; setuptools 59.8.0; sinfo 0.3.1; sip NA; six 1.16.0; sklearn 1.0.2; soupsieve 2.3.1; sphinxcontrib NA; spyder 5.2.2; spyder_kernels 2.2.1; spydercustomize NA; statsmodels 0.13.2; storemagic NA; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tlz 0.11.2; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; tzlocal NA; wcwidth 0.2.5; wurlitzer 3.0.2; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 7.32.0; jupyter_client 7.1.2; jupyter_core 4.9.2; -----; Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]; Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid; 16 logical CPU cores, x86_64; -----; Session information updated at 2022-04-20 18:16; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2239#issuecomment-1104127300:1879,log,logical,1879,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1104127300,1,['log'],['logical']
Testability,Same issue here. Using `pip` +pyhton3.7 and not conda to install from pypi. Is there a way to resolve it without installing using conda?. Logs:. ```; [dilawars@chamcham scanpy_exp]$ python planaria.py ; /home1/dilawars/.local/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses; import imp; scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1 ; ... storing 'clusters' as categorical; computing tSNE; using data matrix X directly; using the 'MulticoreTSNE' package by Ulyanov (2017); finished (0:02:53.98); saving figure to file ./figures/tsne_full.pdf; computing neighbors; using data matrix X directly; Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed!; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-427357518:138,Log,Logs,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-427357518,2,"['Assert', 'Log']","['Assertion', 'Logs']"
Testability,"Scanpy does have logging implemented (examples: [neighbors](https://github.com/theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/neighbors/__init__.py#L84), [highly variable genes](https://github.com/theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/preprocessing/_highly_variable_genes.py#L81)), but it's not that widely used. I think this is because it has to be implemented manually in the code (not sure if this is what you mean by ""intrinsic""?), which makes it take some effort to implement and not all contributors are aware of. I think using a decorator would be nice for abstracting out the process. This would have benefits of consistency of usage by making it easy, consistency of logged messages, and separation of concerns between computation and tracking. I also think you'd be able to know the exact set of operations from this approach. Assuming all top level functions have been wrapped with a decorator like the one I presented above, this code:. ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""); ```. Should result in a set of (psuedo-)records like:. ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""read_10x_h5"", ""args"": {""filename"": ""./10x_run/outs/filtered_gene_matrix.h5""}, ""returned_adata"": id(1)}; {""call"": ""normalize_per_cell"", ""args"": {""counts_per_cell_after"": 1000}, ""adata_id"": id(1)}; {""call"": ""log1p"", ""adata_id"": id(1)}; {""call"": ""pca"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```. It's pretty trivial to go through these logs and figure out what happened to the AnnData, and made accessible through helper functions. Maybe they'd look like `sc.logging.get_operations(adata_id=id(adata))` or `sc.logging.get_operations(written_to=""./cache/01_simple_process.h5ad"")`. There could also b",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063:17,log,logging,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063,2,['log'],"['logged', 'logging']"
Testability,Scanpy precisely reproduces Seurat's output as outlined in the first tutorial. You can also feed in logarithmized data by passing the parameter `log=True`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/188#issuecomment-402090857:100,log,logarithmized,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188#issuecomment-402090857,2,['log'],"['log', 'logarithmized']"
Testability,"Second step: reverted things that were logged at a level equal or higher than 4 to `debug`. a37efc71876f1cd9ace1165d7f774e390d30343d. The only thing that remains is to reformat the time output, which now displays many useless digits after the seconds comma [and fix all other places in which similar things happened].",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/684#issuecomment-500211162:39,log,logged,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684#issuecomment-500211162,1,['log'],['logged']
Testability,See #2682 for a putative fix. Might need a unit test though.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2681#issuecomment-1757749996:48,test,test,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681#issuecomment-1757749996,1,['test'],['test']
Testability,"See my last comment. After fixing the colormaps in this PR, I didn’t update the images, but the tests still pass. What’s up with that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/369#issuecomment-441571449:96,test,tests,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369#issuecomment-441571449,1,['test'],['tests']
Testability,Seems it works properly; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/log1p_test.ipynb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/191#issuecomment-403512265:67,benchmark,benchmarks,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191#issuecomment-403512265,1,['benchmark'],['benchmarks']
Testability,"Seems like some shell shenanigans. For some reason you passed `'scanpy` as a first parameter instead of the whole thing as a string. In any case, I either need someone to confirm that the fix works, or better, a reproducible example that we can derive a test case from.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3028#issuecomment-2089789779:254,test,test,254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028#issuecomment-2089789779,1,['test'],['test']
Testability,Seems like we don’t have a benchmark for the clipping. Should we add one?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3100#issuecomment-2173601937:27,benchmark,benchmark,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100#issuecomment-2173601937,1,['benchmark'],['benchmark']
Testability,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/511#issuecomment-470050466:18,test,tested,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-470050466,1,['test'],['tested']
Testability,"Should be possible to turn the y ticks legends on. But I just tested it and didn't work. I will try to fix it. The syntax is:; ```PYTHON; sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True).style(yticklabels=True,row_palette='muted').show(); ```. `style` needs to be used to tune the graphical parameters to avoid overcrowding the parameters list. But I am open to have a discussion on what the users think is best. Documentation is here: https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.DotPlot.style.html#scanpy.pl.DotPlot.style",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1321#issuecomment-666170536:62,test,tested,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321#issuecomment-666170536,1,['test'],['tested']
Testability,"Should probably figure out what's happening with these tests. @flying-sheep, has this been happening for other PRs?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1014#issuecomment-580247580:55,test,tests,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1014#issuecomment-580247580,1,['test'],['tests']
Testability,Since this is an overflow any data set with 1000's of cells I can use for this? I think it is Windows specific crash and how python implements sqrt() on windows which probably is a wrapper of the native math library in C. I may be wrong. So will the regression test work in this case?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1061#issuecomment-588274013:261,test,test,261,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061#issuecomment-588274013,1,['test'],['test']
Testability,"Since we can’t test this without your help, could you check if passing your own RNG here makes it work?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2275985402:15,test,test,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2275985402,1,['test'],['test']
Testability,"Since we don't know when a release of `pynndescent` will go out, I think it's fine to keep this a little hacky for now. I think it can be less hacky than now doing something like this:. ```python; from_init = pynndescent.NNDescent(train, n_neighbors=15, init_graph=indices); from_init._rp_forest = rp_forest; query_indices_init, query_distances_init = from_scratch.query(test); ```. Once a release of pynndescent comes out we can support doing it the proper way. . I'd say it's up to you whether you want to have the kinda hacky solution or not. I definitely don't want UMAP to be pinned to below 0.5 when we release 1.7 proper, and it would be good for ingest to work with UMAP 0.5. The only downside I see to the kinda hacky solution as an intermediate is that you're fixing it twice. I don't think it'll be hard to go from this to the clean version however. -------------------------. I haven't looked into what needs to happen for the UMAP embedding transfer stuff to work. Is that pretty straight forward?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1589#issuecomment-762553133:371,test,test,371,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1589#issuecomment-762553133,1,['test'],['test']
Testability,"So I just reproduced this error for `sc.pp.log1p()` using my own data after using the `sc.pp.downsample_counts()` function. It might have to do with that?. i noticed that `sc.pp.downsample_counts()` returns `np.int64` rather than `np.float64` I reckon that's what the log transformation is complaining about. If I add the line:; ```; adata.X = adata.X.astype(np.float64); ```; after the downsampling call, it works again. Maybe add that to `sc.pp.log1p()`? Or change `sc.pp.downsample_counts()` to return `np.float64`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475709600:268,log,log,268,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475709600,1,['log'],['log']
Testability,"So actually, I run a test on a fresh docker image (with this [Dockerfile](https://gist.github.com/pwl/005c781cbe19f5e961b59366f738caaf)) and it still fails to install scanpy with the same error. I had some success with changing the default python encoding to utf-8 as shown in the Dockerfile but it only works when calling python3 directly and not for pip3. However, it worked with python2. I guess python3 is not supported by scanpy, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43#issuecomment-343252579:21,test,test,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43#issuecomment-343252579,1,['test'],['test']
Testability,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668:185,log,log,185,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668,1,['log'],['log']
Testability,"So for a fix, we’d simply need to change. https://github.com/scverse/scanpy/blob/414092f68b4b40aa99153556377c32839b392636/scanpy/preprocessing/_highly_variable_genes.py#L197-L199. into. ```py; X = X.copy(); if 'log1p' in adata.uns_keys() and adata.uns['log1p'].get('base') is not None:; X *= np.log(adata.uns['log1p']['base']); np.expm1(X, out=X); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2668#issuecomment-1766402734:295,log,log,295,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668#issuecomment-1766402734,1,['log'],['log']
Testability,"So it looks like we definitely started downloading the rc for numpy relecently: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6661&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=22c10d56-3e3b-5f98-5bc6-b33384a21306 (from last week or something, downloading 1.26.4) vs https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=efb91c47-e839-5730-ecc5-cc752bc791b5 (downloading the 2.0 rc)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2112322713:150,log,logs,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2112322713,2,['log'],['logs']
Testability,"So it will only work on non-negative expression values without any pre-process?; I guess that make sense, thank you for the reply. The version of the package:. scanpy==1.4.6 anndata==0.7.1 umap==0.4.0 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. The AnnData objects were all read through same commands without any modification. sc.read_10x_h5(filepath, gex_only=False). the dataset I used to test them are:. https://support.10xgenomics.com/single-cell-vdj/datasets/2.2.0/vdj_v1_hs_nsclc_5gex; https://support.10xgenomics.com/single-cell-gene-expression/datasets/3.0.0/pbmc_10k_protein_v3; https://support.10xgenomics.com/single-cell-gene-expression/datasets/3.0.0/malt_10k_protein_v3. It appears to me that it only works on the v2 nsclc h5 data. I was trying to merge the three data sets and run through SAM to compare with the result of BBKNN, didn't work. So I tried to run each of them individually in the loop. I guess it won't work on CITESeq data without other processing?. I tried removed all the antibody read counts from adata.X and ran it once, still got same error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1157#issuecomment-614976989:457,test,test,457,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157#issuecomment-614976989,1,['test'],['test']
Testability,"So one small update here -- it works like a charm for categorical variables, but not for continuous variables.; e.g.; > sc.pl.umap(testData, save = fileName, color='CCL5',s=50,frameon=False,legend_loc = None). Still gives something like a legend:; ![image](https://user-images.githubusercontent.com/10536275/99786010-40234a80-2b1e-11eb-83ab-77c9341dab05.png). Presumably this is because the color strip on the right is not actually a legend in the underlying matplotlib?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1502#issuecomment-731065768:131,test,testData,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502#issuecomment-731065768,1,['test'],['testData']
Testability,"So the reason you didn't get this before, would be that if you do a `sc.tl.rank_genes_groups()` call with default parameters, you compare the expression in one cluster with the expression in the rest of the dataset. The ""rest of the dataset"" has changed, so you could now get -ve average expression for genes in the ""rest of the dataset"". This will likely create -ve fold changes, which cannot be logged and probably give you `NaN`. This is hiding a signal that is actually there, and not because the gene is not actually differentially expressed. > I did a rescale of my data to 10 again but unfortunately the same warning is happening!; What do you mean by this?. Turning negative values to 0, doesn't mean you lose the data. You have some expression space, of which 0 is a valid number. The question is really what does a negative expression value mean after MAGIC? Is it just a confidence of the gene not being expressed? Then putting it to zero makes sense. Again... if you ignore this, you will just ignore particular genes which are likely differentially expression, because MAGIC has rescaled the expression values in the ""rest of the dataset"" to a negative value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/653#issuecomment-494353628:397,log,logged,397,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494353628,1,['log'],['logged']
Testability,"So we've just put out a release of 1.7.0rc1, and will be releasing it proper soon.; I'm looking at making a 1.6.1 release where the only change is pinning umap, but there are some CI issues (largely tests failing due to Matplotlib outputs changing slightly).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1579#issuecomment-760014261:199,test,tests,199,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579#issuecomment-760014261,1,['test'],['tests']
Testability,"So you should easily be able to see that the null hypothesis is not valid by the distribution of p-values for all genes in one rank_genes_groups test. If it is valid, this distribution should be uniform. In that case it's only a multiple testing problem... I would guarantee you that it's not uniform though. Cell type labels from expression-independent sources should not have the same confounding effect. However, I would bet you can trace back all biological annotations of cell types back to expression.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-425395345:145,test,test,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-425395345,2,['test'],"['test', 'testing']"
Testability,"So, I'm not too surprised to see this, since I don't think much of the distributed stuff has good testing, and I'm not too familiar with it. I believe the `AnnData` constructor is converting the array. You can get around this by assigning X to be a dask array, e.g.:. ```python; a = ad.AnnData(np.ones((1000, 100))); a.X = da.from_array(a.X); type(a.X); # dask.array.core.Array; ```. Better support for dask arrays would be a great feature request and series of additions to anndata. I think this is the endemic numeric python problem of ""these things are all like arrays, so can kinda use the same API, but in practice every type needs to be special cased"". > but there's a lot of other stuff happening before & afterwards in normalize_total() which I haven't looked at much. Yeah, I think this function has built up some cruft. I've opened a PR to streamline this #1667, but will need to check with people more familiar with the code. The private method should handle all of the computation, while the outer wrapper will do more argument handling/ getting data out of the `AnnData`/ assigning it back. > What combinations of inputs to _normalize_data() need to be supported. I believe `counts` should always be generated from `X`, so we don't need to worry about the combinations of types.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1663#issuecomment-782803190:98,test,testing,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1663#issuecomment-782803190,1,['test'],['testing']
Testability,"So, bumping pandas to above 2.0 fixes most of the plotting tests. Almost all the differences were in ordering, and frequently where the ordering would change, but the dendrogram being displayed would not. It's not immediately obvious to me which piece of code is the problem, so I am going to temporarily bump the required pandas version and come back to it after resolving the other remaining issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1903981693:59,test,tests,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1903981693,1,['test'],['tests']
Testability,"So, that dataset is used pretty extensively in the tests, and especially around plotting (plus it's actually shipped with the library). I don't think we're likely to modify it, given that it's used so heavily as a reference. What do you need it for, and could you use `pbmc3k_processed` for that purpose?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1762#issuecomment-807908934:51,test,tests,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1762#issuecomment-807908934,1,['test'],['tests']
Testability,"So, we could also not early load `scanpy.testing._pytest` or load `pytest-cov` first?. I would like to keep the `xdist` support and use a similar interface.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2874#issuecomment-1956920175:41,test,testing,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2874#issuecomment-1956920175,1,['test'],['testing']
Testability,"So, without any evidence, I think it should be fine. The reason I had put an error in the first place is that the typical behavior is to pass log normalized data to this HVG function, and I didn't want people to run this incorrectly. I think another solution would be to just throw a UserWarning, though in a way I like the idea of having an argument that disables the `check_nonnegative_integer()`. I think I would call it `enforce_counts_seurat_v3` though. You might also consider bypassing the check if the flag is set, because it can be slowish for large datasets.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1642#issuecomment-776841793:142,log,log,142,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1642#issuecomment-776841793,1,['log'],['log']
Testability,Solution here is `adata.obs.index = adata.obs.index.astype(str)`. Should be called by default if this assertionerror is raised.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/747#issuecomment-1242183366:102,assert,assertionerror,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747#issuecomment-1242183366,1,['assert'],['assertionerror']
Testability,"Solved same problem for me as well. . For the record, the output of `sc.logging.print_versions()` in my conda environment is: . `scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.2 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/948#issuecomment-571371654:72,log,logging,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948#issuecomment-571371654,1,['log'],['logging']
Testability,"Some notes from a brief discussion with Sergei. 1. make helper functions for each method so that level of indentation and length is decreased; 2. replace lists `rankings_gene_...` by DataFrame; 3. think about simplifying the wilcoxon implementation, compare with scipy stats implementation and potentially update the test; 4. investigate how the logreg implementation behaves for different choices of reference groups",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/723#issuecomment-526079225:317,test,test,317,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/723#issuecomment-526079225,2,"['log', 'test']","['logreg', 'test']"
Testability,Some of the tests fail for reasons unrelated to the PR (`test_preprocessing`). Locally all tests pass for me. Any ideas?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/661#issuecomment-495233581:12,test,tests,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495233581,2,['test'],['tests']
Testability,"Some small benchmarks for 32 cores with `CSR.shape=(196943, 20867)`:; | axis |old|new|; |------|-----|------|; |minor|804 ms|96 ms|; |major|520 ms|40 ms|",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3015#issuecomment-2066134612:11,benchmark,benchmarks,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3015#issuecomment-2066134612,1,['benchmark'],['benchmarks']
Testability,"Some tests are still failing, but not because of `uns/spatial`. They all throw errors along these lines:; ```; assert 'Error: Image files did not match.\n RMS Value: 15.114361035293829\n; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105#issuecomment-600196432:5,test,tests,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105#issuecomment-600196432,2,"['assert', 'test']","['assert', 'tests']"
Testability,Some things on pancreas dataset; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/ingest_pancreas.ipynb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651#issuecomment-527675546:75,benchmark,benchmarks,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-527675546,1,['benchmark'],['benchmarks']
Testability,"Somehow, updating anndata fixes the PCA test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1915626230:40,test,test,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1915626230,1,['test'],['test']
Testability,"Something like this should work. Note, this is not tested. ```pytb; target_cells = 5000. adatas = [adata[adata.obs[cluster_key].isin(clust)] for clust in adata.obs[cluster_key].cat.categories]. for dat in adatas:; if dat.n_obs > target_cells:; sc.pp.subsample(dat, n_obs=target_cells). adata_downsampled = adatas[0].concatenate(*adatas[1:]); ```. Hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/987#issuecomment-574063629:51,test,tested,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/987#issuecomment-574063629,1,['test'],['tested']
Testability,Something went wrong ... Please have a look at my logs. It seem that the branch you are trying to backport to does not exists.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1628#issuecomment-781794583:50,log,logs,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1628#issuecomment-781794583,1,['log'],['logs']
