quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,filename,wiki,url,total_similar,target_keywords,target_matched_words
Deployability," *outData;. OSStatus st =; SecKeychainItemCopyContent(2, ptr, ptr, length, &outData);. st = SecKeychainItemCopyContent(2, ptr, ptr, length, &outData);; // warn: release data before another call to the allocator. if (st == noErr); SecKeychainItemFreeContent(ptr, outData);; }. void test() {; SecKeychainItemRef itemRef = 0;; SecKeychainAttributeInfo *info = 0;; SecItemClass *itemClass = 0;; SecKeychainAttributeList *attrList = 0;; UInt32 *length = 0;; void *outData = 0;. OSStatus st =; SecKeychainItemCopyAttributesAndData(itemRef, info,; itemClass, &attrList,; length, &outData);. SecKeychainItemFreeContent(attrList, outData);; // warn: deallocator doesn't match the allocator; }. osx.cocoa.AtSync; (ObjC); Check for nil pointers used as mutexes for @synchronized. void test(id x) {; if (!x); @synchronized(x) {} // warn: nil value used as mutex; }. void test() {; id y;; @synchronized(y) {} // warn: uninitialized value used as mutex; }. osx.cocoa.ClassRelease; (ObjC); Check for sending retain, release, or ; autorelease directly to a class. @interface MyClass : NSObject; @end. void test(void) {; [MyClass release]; // warn; }. osx.cocoa.Dealloc; (ObjC); Warn about Objective-C classes that lack a correct implementation; of -dealloc. @interface MyObject : NSObject {; id _myproperty;; }; @end. @implementation MyObject // warn: lacks 'dealloc'; @end. @interface MyObject : NSObject {}; @property(assign) id myproperty;; @end. @implementation MyObject // warn: does not send 'dealloc' to super; - (void)dealloc {; self.myproperty = 0;; }; @end. @interface MyObject : NSObject {; id _myproperty;; }; @property(retain) id myproperty;; @end. @implementation MyObject; @synthesize myproperty = _myproperty;; // warn: var was retained but wasn't released; - (void)dealloc {; [super dealloc];; }; @end. @interface MyObject : NSObject {; id _myproperty;; }; @property(assign) id myproperty;; @end. @implementation MyObject; @synthesize myproperty = _myproperty;; // warn: var wasn't retained but was ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/available_checks.html:14925,release,release,14925,interpreter/llvm-project/clang/www/analyzer/available_checks.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/available_checks.html,1,['release'],['release']
Deployability," -- Many operator p.d.f. and function components now show; a more intuitive natural representation of their contents (these changes are mostly in the; respective p.d.f.s, but are most relevant in the context of a workspace). New object factory interface to workspace to facilitate script driven model definition; A object factory has been added to RooFit to simplify the process of creating p.d.f.; and function expressions consisting of multiple objects. The factory has two goals:; the first is to provide a back-end for higher level factories and tools to process; the creation of objects. The second is to provide a simple end-user language to; populate a RooWorkspace with function and p.d.f. objects. For the latter purpose the object creation language is executed through the factory() method; of a workspace object. RooWorkspace w(""w"") ;; RooAbsArg* arg = w.factory(""expression_goes_here"") ;. Basic Syntax; The rules at its simplest level are as follows. Expressions with square brackets create variables (discrete and continuous). ""m[-10,10]"" - Creates a RooRealVar named 'm' with range [-10,10]; ""m[5,-10,10]"" - Idem, but with initial value 5; ""m[5]"" - Creates a constant RooRealVar with name 'm' and value 5. ""tagCat[Lep,Kao,NT1,NT2]"" -- Creates a RooCategory with name tagCat and labeled states Lep,Kao,NT1,NT2; ""b0flav[B0=1,B0bar=-1]"" -- Creates a RooCategory with name b0flav and states B0 and B0bar with explicit index assignments. Expressions with parentheses create RooAbsArg function objects of any type. ""RooGaussian::g(x,m,s)"" -- Create a RooGaussian named g with variables x,m,s; This expression maps 1-1 to a createArg() call. ""Gaussian::g(x,m,s)"" -- Idem. The 'Roo' prefix on any class may be omitted. ""Gaussian(x,m,s)"" -- Create a RooGaussian with an automatically assigned name with variables x,m,s. Expressions with curly brackets creates RooArgSets or RooArgLists ""{x,y,z}"". Compound expressions; The real power of this language is that all these expressions may be nested t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:18863,continuous,continuous,18863,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,1,['continuous'],['continuous']
Deployability," --Wno-error=<value> - If set don't error out on the specified warning type.; =unknown - If set, unknown format options are only warned about.; This can be used to enable formatting, even if the; configuration contains unknown (newer) options.; Use with caution, as this might lead to dramatically; differing format depending on an option being; supported or not.; --assume-filename=<string> - Set filename used to determine the language and to find; .clang-format file.; Only used when reading from stdin.; If this is not passed, the .clang-format file is searched; relative to the current working directory when reading stdin.; Unrecognized filenames are treated as C++.; supported:; CSharp: .cs; Java: .java; JavaScript: .mjs .js .ts; Json: .json; Objective-C: .m .mm; Proto: .proto .protodevel; TableGen: .td; TextProto: .textpb .pb.txt .textproto .asciipb; Verilog: .sv .svh .v .vh; --cursor=<uint> - The position of the cursor when invoking; clang-format from an editor integration; --dry-run - If set, do not actually make the formatting changes; --dump-config - Dump configuration options to stdout and exit.; Can be used with -style option.; --fallback-style=<string> - The name of the predefined style used as a; fallback in case clang-format is invoked with; -style=file, but can not find the .clang-format; file to use. Defaults to 'LLVM'.; Use -fallback-style=none to skip formatting.; --ferror-limit=<uint> - Set the maximum number of clang-format errors to emit; before stopping (0 = no limit).; Used only with --dry-run or -n; --files=<filename> - A file containing a list of files to process, one per line.; -i - Inplace edit <file>s, if specified.; --length=<uint> - Format a range of this length (in bytes).; Multiple ranges can be formatted by specifying; several -offset and -length pairs.; When only a single -offset is specified without; -length, clang-format will format up to the end; of the file.; Can only be used with one input file.; --lines=<string> - <start line>:<end ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst:1980,integrat,integration,1980,interpreter/llvm-project/clang/docs/ClangFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst,2,"['configurat', 'integrat']","['configuration', 'integration']"
Deployability," --config Release --target libcef_dll_wrapper; ~~~. 5. Before compiling ROOT, `set CEF_ROOT=C:\Soft\cef` variable. ## Using plain CEF in ROOT batch mode on Linux. Default CEF builds, provided by [https://cef-builds.spotifycdn.com/index.html](https://cef-builds.spotifycdn.com/index.html), do; not include support of Ozone framework, which the only support headless mode in CEF. To run ROOT in headless (or batch) made with such CEF distribution,; one can use `Xvfb` server. Most simple way is to use `xvfb-run` utility like:. ~~~; $ xvfb-run --server-args='-screen 0, 1024x768x16' root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. Or run `Xvfb` before starting ROOT:. ~~~; $ Xvfb :99 &; $ export DISPLAY=:99; $ root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. ## Compile CEF with ozone support. Since March 2019 one can compile [CEF without X11](https://bitbucket.org/chromiumembedded/cef/issues/2296/), but such builds not provided.; Therefore to be able to use real headless mode in CEF, one should compile it from sources.; On [CEF build tutorial](https://bitbucket.org/chromiumembedded/cef/wiki/AutomatedBuildSetup.md) one can find complete compilation documentation.; Several Ubuntu distributions are supported by CEF, all others may require extra work. Once all depndencies are installed,; CEF with ozone support can be compiled with following commands:. ~~~; $ export GN_DEFINES=""is_official_build=true use_sysroot=true use_allocator=none symbol_level=1 is_cfi=false use_thin_lto=false use_ozone=true""; $ python automate-git.py --download-dir=/home/user/cef --branch=4638 --minimal-distrib --client-distrib --force-clean --x64-build --build-target=cefsimple; ~~~. With little luck one get prepared tarballs in `/home/user/cef/chromium/src/cef/binary_distrib`.; Just install it in the same way as described before in this document.; ROOT will automatically detect that CEF build with `ozone` support and will use it for both interactive and headless modes. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md:3616,install,installed,3616,gui/cefdisplay/Readme.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md,2,['install'],"['install', 'installed']"
Deployability," . TMVA. TMVA version 4.1.0 is included in this root release. The most; important new feature is the support for simulataneous classification ; of multiple output classes for several multi-variate methods. ; A lot of effort went into consolidation of the software,; i.e. method performance and robustness, and framework; stability. The changes with respect to ROOT 5.27 / TMVA 4.0.7 are; in detail:. Framework. Multi-class support. The support of multiple; output classes (i.e., more than a single background and signal; class) has been enabled for these methods: MLP (NN), BDTG,; FDA.; The multiclass; functionality can be enabled with the Factory option; ""AnalysisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:53,release,release,53,tmva/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html,1,['release'],['release']
Deployability," . TMVA; ; This version corresponds to TMVA version 3.9.5.; ; . New; reference page for configuration options The; page is automatically generated for each new release. Next to; the classifiers also exist information links for hints to; improve the classifier performance (click on the ""i""; button). Many thanks to Zhiyi Liu (Fraser U) for suggesting; this.; ; Methods:. BDT: New Decision Tree Pruning algorithm: Cost; Complexity Pruning a la CART. Written by Doug Schouten; (Fraser U.). It replaces the old CostComplexity and; CostComplexity2 algorithms.; . BDT: New no splitting option (choosable with; NCuts<0) that finds best split point by first sorting the; events for each variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:88,configurat,configuration,88,tmva/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html,2,"['configurat', 'release']","['configuration', 'release']"
Deployability," .. _BreakAfterJavaFieldAnnotations:. **BreakAfterJavaFieldAnnotations** (``Boolean``) :versionbadge:`clang-format 3.8` :ref:`¶ <BreakAfterJavaFieldAnnotations>`; Break after each annotation on a field in Java files. .. code-block:: java. true: false:; @Partial vs. @Partial @Mock DataLoad loader;; @Mock; DataLoad loader;. .. _BreakArrays:. **BreakArrays** (``Boolean``) :versionbadge:`clang-format 16` :ref:`¶ <BreakArrays>`; If ``true``, clang-format will always break after a Json array ``[``; otherwise it will scan until the closing ``]`` to determine if it should; add newlines between elements (prettier compatible). .. note::. This is currently only for formatting JSON. .. code-block:: c++. true: false:; [ vs. [1, 2, 3, 4]; 1,; 2,; 3,; 4; ]. .. _BreakBeforeBinaryOperators:. **BreakBeforeBinaryOperators** (``BinaryOperatorStyle``) :versionbadge:`clang-format 3.6` :ref:`¶ <BreakBeforeBinaryOperators>`; The way to wrap binary operators. Possible values:. * ``BOS_None`` (in configuration: ``None``); Break after operators. .. code-block:: c++. LooooooooooongType loooooooooooooooooooooongVariable =; someLooooooooooooooooongFunction();. bool value = aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa +; aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa ==; aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa &&; aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa >; ccccccccccccccccccccccccccccccccccccccccc;. * ``BOS_NonAssignment`` (in configuration: ``NonAssignment``); Break before operators that aren't assignments. .. code-block:: c++. LooooooooooongType loooooooooooooooooooooongVariable =; someLooooooooooooooooongFunction();. bool value = aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa; + aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa; == aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa; && aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa; > ccccccccccccccccccccccccccccccccccccccccc;. * ``BOS_All`` (in configuration: ``All``); Break before operators. .. code-block:: c++. LooooooooooongType loooooooooooooooooooooongVariable",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:46230,configurat,configuration,46230,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," .. code-block:: c++. unsigned bf : 2;. * ``BFCS_None`` (in configuration: ``None``); Add no space around the ``:`` (except when needed for; ``AlignConsecutiveBitFields``). .. code-block:: c++. unsigned bf:2;. * ``BFCS_Before`` (in configuration: ``Before``); Add space before the ``:`` only. .. code-block:: c++. unsigned bf :2;. * ``BFCS_After`` (in configuration: ``After``); Add space after the ``:`` only (space may be added before if; needed for ``AlignConsecutiveBitFields``). .. code-block:: c++. unsigned bf: 2;. .. _BraceWrapping:. **BraceWrapping** (``BraceWrappingFlags``) :versionbadge:`clang-format 3.8` :ref:`¶ <BraceWrapping>`; Control of individual brace wrapping cases. If ``BreakBeforeBraces`` is set to ``BS_Custom``, use this to specify how; each individual brace case should be handled. Otherwise, this is ignored. .. code-block:: yaml. # Example of usage:; BreakBeforeBraces: Custom; BraceWrapping:; AfterEnum: true; AfterStruct: false; SplitEmptyFunction: false. Nested configuration flags:. Precise control over the wrapping of braces. .. code-block:: c++. # Should be declared this way:; BreakBeforeBraces: Custom; BraceWrapping:; AfterClass: true. * ``bool AfterCaseLabel`` Wrap case labels. .. code-block:: c++. false: true:; switch (foo) { vs. switch (foo) {; case 1: { case 1:; bar(); {; break; bar();; } break;; default: { }; plop(); default:; } {; } plop();; }; }. * ``bool AfterClass`` Wrap class definitions. .. code-block:: c++. true:; class foo; {};. false:; class foo {};. * ``BraceWrappingAfterControlStatementStyle AfterControlStatement``; Wrap control statements (``if``/``for``/``while``/``switch``/..). Possible values:. * ``BWACS_Never`` (in configuration: ``Never``); Never wrap braces after a control statement. .. code-block:: c++. if (foo()) {; } else {; }; for (int i = 0; i < 10; ++i) {; }. * ``BWACS_MultiLine`` (in configuration: ``MultiLine``); Only wrap braces after a multi-line control statement. .. code-block:: c++. if (foo && bar &&; baz); {; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:38757,configurat,configuration,38757,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," // to the same file; ```. Importing will append the volume to the current TGeoManager or will; create one:. ``` {.cpp}; TGeoManager *geom = new TGeoManager(""myGeom"", """");; TGeoVolume *top = geom->MakeBox(...);; geom->SetTopVolume(top);; //name of volume or key (depending on export usage); TGeoVolume *module1 = TGeoVolume::Import(""file.root"", ""MOD1"");; TGeoVolume *module2 = TGeoVolume::Import(""file.root"", ""MOD2"");; top->AddNode(module1, 1, new TGeoTranslation(0,0,100));; top->AddNode(module2, 1, new TGeoTranslation(0,0,-100));; // One should close oneself the geometry; geom->CloseGeometry();; ```. ### GDML. Few lines above word GDML was used. GDML stands for **G**eometry; **D**escription **M**arkup **L**anguage. It is an application-independent; geometry description format based on XML. It is mainly used for geometry; interchange between ROOT and Geant4 framework. More details about this; project can be found http://gdml.web.cern.ch. This feature; (importing/exporting from/to gdml file format) is disabled by default in; ROOT installation. To enable this feature add `--enable-gdml` option to; `./configure` script call. ## Navigation Algorithms. This section will describe the main methods and algorithms used for; implementing the navigation features within the geometrical modeller.; This includes navigation queries at shape level, global geometrical; queries and optimization mechanisms. ### Finding the State Corresponding to a Location (x,y,z). For reminder, a geometry state is a ‘touchable' object in the geometry; hierarchy. It is represented by a path like: **/TOP\_1/A\_1/B\_3/C\_1**,; where **B\_3** for instance is a copy of volume **B** positioned inside; volume **A**. A state is always associated to a transformation matrix; **M** of the touchable with respect to the global reference frame; (obtained by piling-up all local transformations of nodes in the branch; with respect to their containers). The current state and the; corresponding global matrix are updated wh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:154421,install,installation,154421,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['install'],['installation']
Deployability," // to the same file; ~~~. Importing will append the volume to the current TGeoManager or will; create one:. ~~~{.cpp}; TGeoManager *geom = new TGeoManager(""myGeom"", """");; TGeoVolume *top = geom->MakeBox(...);; geom->SetTopVolume(top);; //name of volume or key (depending on export usage); TGeoVolume *module1 = TGeoVolume::Import(""file.root"", ""MOD1"");; TGeoVolume *module2 = TGeoVolume::Import(""file.root"", ""MOD2"");; top->AddNode(module1, 1, new TGeoTranslation(0,0,100));; top->AddNode(module2, 1, new TGeoTranslation(0,0,-100));; // One should close oneself the geometry; geom->CloseGeometry();; ~~~. \anchor GP06a; ### GDML. Few lines above word GDML was used. GDML stands for Geometry; Description Markup Language. It is an application-independent; geometry description format based on XML. It is mainly used for geometry; interchange between %ROOT and Geant4 framework. More details about this; project can be found http://gdml.web.cern.ch. This feature; (importing/exporting from/to gdml file format) is disabled by default in; %ROOT installation. To enable this feature add `--enable-gdml` option to; `./configure` script call. \anchor GP07; ## Navigation Algorithms. This section will describe the main methods and algorithms used for; implementing the navigation features within the geometrical modeller.; This includes navigation queries at shape level, global geometrical; queries and optimization mechanisms. \anchor GP07a; ### Finding the State Corresponding to a Location (x,y,z). For reminder, a geometry state is a ‘touchable' object in the geometry; hierarchy. It is represented by a path like: `/TOP\_1/A\_1/B\_3/C\_1`,; where `B\_3` for instance is a copy of volume `B` positioned inside; volume `A`. A state is always associated to a transformation matrix; `M` of the touchable with respect to the global reference frame; (obtained by piling-up all local transformations of nodes in the branch; with respect to their containers). The current state and the; corresponding global m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:114958,install,installation,114958,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['install'],['installation']
Deployability," 0; %tmp5 = load double* %tmp4, align 8, !tbaa !4; %idxprom7 = sext i32 %i.01718 to i64; %tmp10 = getelementptr inbounds %struct.anon* %tmp3, i64 %idxprom7, i32 0; %tmp11 = load double* %tmp10, align 8, !tbaa !4; %cmp12 = fcmp ogt double %tmp5, %tmp11; br i1 %cmp12, label %if.then, label %for.inc. if.then: ; preds = %for.body; %i.017 = trunc i64 %indvar to i32; br label %for.inc. for.inc: ; preds = %for.body, %if.then; %i.01719 = phi i32 [ %i.01718, %for.body ], [ %i.017, %if.then ]; %indvar.next = add i64 %indvar, 1; %exitcond = icmp eq i64 %indvar.next, %tmp22; br i1 %exitcond, label %for.cond.for.end_crit_edge, label %for.body. It is good that we hoisted the reloads of numf2's, and Y out of the loop and; sunk the store to winner out. However, this is awful on several levels: the conditional truncate in the loop; (-indvars at fault? why can't we completely promote the IV to i64?). Beyond that, we have a partially redundant load in the loop: if ""winner"" (aka ; %i.01718) isn't updated, we reload Y[winner].y the next time through the loop.; Similarly, the addressing that feeds it (including the sext) is redundant. In; the end we get this generated assembly:. LBB0_2: ## %for.body; ## =>This Inner Loop Header: Depth=1; 	movsd	(%rdi), %xmm0; 	movslq	%edx, %r8; 	shlq	$4, %r8; 	ucomisd	(%rcx,%r8), %xmm0; 	jbe	LBB0_4; 	movl	%esi, %edx; LBB0_4: ## %for.inc; 	addq	$16, %rdi; 	incq	%rsi; 	cmpq	%rsi, %rax; 	jne	LBB0_2. All things considered this isn't too bad, but we shouldn't need the movslq or; the shlq instruction, or the load folded into ucomisd every time through the; loop. On an x86-specific topic, if the loop can't be restructure, the movl should be a; cmov. //===---------------------------------------------------------------------===//. [STORE SINKING]. GCC PR37810 is an interesting case where we should sink load/store reload; into the if block and outside the loop, so we don't reload/store it on the; non-call path. for () {; *P += 1;; if (); call();; else; ...; ->; tm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:31247,update,updated,31247,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['update'],['updated']
Deployability," 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vm/vscnt(0). - If CU wavefront execution; mode, omit.; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store ato",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:364016,release,released,364016,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['released']
Deployability," :program:`clang-format` is integrated into `CLion <https://www.jetbrains; .com/clion/>`_ as an alternative code formatter. CLion turns it on; automatically when there is a ``.clang-format`` file under the project root.; Code style rules are applied as you type, including indentation,; auto-completion, code generation, and refactorings. :program:`clang-format` can also be enabled without a ``.clang-format`` file.; In this case, CLion prompts you to create one based on the current IDE settings; or the default LLVM style. Visual Studio Integration; =========================. Download the latest Visual Studio extension from the `alpha build site; <https://llvm.org/builds/>`_. The default key-binding is Ctrl-R,Ctrl-F. Visual Studio Code Integration; ==============================. Get the latest Visual Studio Code extension from the `Visual Studio Marketplace <https://marketplace.visualstudio.com/items?itemName=xaver.clang-format>`_. The default key-binding is Alt-Shift-F. Git integration; ===============. The script `clang/tools/clang-format/git-clang-format` can be used to; format just the lines touched in git commits:. .. code-block:: console. % git clang-format -h; usage: git clang-format [OPTIONS] [<commit>] [<commit>|--staged] [--] [<file>...]. If zero or one commits are given, run clang-format on all lines that differ; between the working directory and <commit>, which defaults to HEAD. Changes are; only applied to the working directory, or in the stage/index. Examples:; To format staged changes, i.e everything that's been `git add`ed:; git clang-format. To also format everything touched in the most recent commit:; git clang-format HEAD~1. If you're on a branch off main, to format everything touched on your branch:; git clang-format main. If two commits are given (requires --diff), run clang-format on all lines in the; second <commit> that differ from the first <commit>. The following git-config settings set the default of the corresponding option:; clangFormat.bi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst:10175,integrat,integration,10175,interpreter/llvm-project/clang/docs/ClangFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst,1,['integrat'],['integration']
Deployability," :ref:`statepoint-example GC<statepoint_example_gc>` strategy in; certain aspects like:. * Base-pointers of interior pointers are not explicitly; tracked and reported. * A different format is used for encoding stack maps. * Safe-point polls are only needed before loop-back edges; and before tail-calls (not needed at function-entry). Custom GC Strategies; ====================. If none of the built in GC strategy descriptions met your needs above, you will; need to define a custom GCStrategy and possibly, a custom LLVM pass to perform; lowering. Your best example of where to start defining a custom GCStrategy; would be to look at one of the built in strategies. You may be able to structure this additional code as a loadable plugin library.; Loadable plugins are sufficient if all you need is to enable a different; combination of built in functionality, but if you need to provide a custom; lowering pass, you will need to build a patched version of LLVM. If you think; you need a patched build, please ask for advice on llvm-dev. There may be an; easy way we can extend the support to make it work for your use case without; requiring a custom build. Collector Requirements; ----------------------. You should be able to leverage any existing collector library that includes the following elements:. #. A memory allocator which exposes an allocation function your compiled; code can call. #. A binary format for the stack map. A stack map describes the location; of references at a safepoint and is used by precise collectors to identify; references within a stack frame on the machine stack. Note that collectors; which conservatively scan the stack don't require such a structure. #. A stack crawler to discover functions on the call stack, and enumerate the; references listed in the stack map for each call site. #. A mechanism for identifying references in global locations (e.g. global; variables). #. If you collector requires them, an LLVM IR implementation of your collectors; load a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:22165,patch,patched,22165,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['patch'],['patched']
Deployability," :versionbadge:`clang-format 3.3` :ref:`¶ <AllowAllParametersOfDeclarationOnNextLine>`; If the function declaration doesn't fit on a line,; allow putting all parameters of a function declaration onto; the next line even if ``BinPackParameters`` is ``false``. .. code-block:: c++. true:; void myFunction(; int a, int b, int c, int d, int e);. false:; void myFunction(int a,; int b,; int c,; int d,; int e);. .. _AllowBreakBeforeNoexceptSpecifier:. **AllowBreakBeforeNoexceptSpecifier** (``BreakBeforeNoexceptSpecifierStyle``) :versionbadge:`clang-format 18` :ref:`¶ <AllowBreakBeforeNoexceptSpecifier>`; Controls if there could be a line break before a ``noexcept`` specifier. Possible values:. * ``BBNSS_Never`` (in configuration: ``Never``); No line break allowed. .. code-block:: c++. void foo(int arg1,; double arg2) noexcept;. void bar(int arg1, double arg2) noexcept(; noexcept(baz(arg1)) &&; noexcept(baz(arg2)));. * ``BBNSS_OnlyWithParen`` (in configuration: ``OnlyWithParen``); For a simple ``noexcept`` there is no line break allowed, but when we; have a condition it is. .. code-block:: c++. void foo(int arg1,; double arg2) noexcept;. void bar(int arg1, double arg2); noexcept(noexcept(baz(arg1)) &&; noexcept(baz(arg2)));. * ``BBNSS_Always`` (in configuration: ``Always``); Line breaks are allowed. But note that because of the associated; penalties ``clang-format`` often prefers not to break before the; ``noexcept``. .. code-block:: c++. void foo(int arg1,; double arg2) noexcept;. void bar(int arg1, double arg2); noexcept(noexcept(baz(arg1)) &&; noexcept(baz(arg2)));. .. _AllowShortBlocksOnASingleLine:. **AllowShortBlocksOnASingleLine** (``ShortBlockStyle``) :versionbadge:`clang-format 3.5` :ref:`¶ <AllowShortBlocksOnASingleLine>`; Dependent on the value, ``while (true) { continue; }`` can be put on a; single line. Possible values:. * ``SBS_Never`` (in configuration: ``Never``); Never merge blocks into a single line. .. code-block:: c++. while (true) {; }; while (true) {; co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:26114,configurat,configuration,26114,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," :versionbadge:`clang-format 9` :ref:`¶ <TypenameMacros>`; A vector of macros that should be interpreted as type declarations; instead of as function calls. These are expected to be macros of the form:. .. code-block:: c++. STACK_OF(...). In the .clang-format configuration file, this can be configured like:. .. code-block:: yaml. TypenameMacros: ['STACK_OF', 'LIST']. For example: OpenSSL STACK_OF, BSD LIST_ENTRY. .. _UseCRLF:. **UseCRLF** (``Boolean``) :versionbadge:`clang-format 10` :ref:`¶ <UseCRLF>`; This option is **deprecated**. See ``LF`` and ``CRLF`` of ``LineEnding``. .. _UseTab:. **UseTab** (``UseTabStyle``) :versionbadge:`clang-format 3.7` :ref:`¶ <UseTab>`; The way to use tab characters in the resulting file. Possible values:. * ``UT_Never`` (in configuration: ``Never``); Never use tab. * ``UT_ForIndentation`` (in configuration: ``ForIndentation``); Use tabs only for indentation. * ``UT_ForContinuationAndIndentation`` (in configuration: ``ForContinuationAndIndentation``); Fill all leading whitespace with tabs, and use spaces for alignment that; appears within a line (e.g. consecutive assignments and declarations). * ``UT_AlignWithSpaces`` (in configuration: ``AlignWithSpaces``); Use tabs for line continuation and indentation, and spaces for; alignment. * ``UT_Always`` (in configuration: ``Always``); Use tabs whenever we need to fill whitespace that spans at least from; one tab stop to the next one. .. _VerilogBreakBetweenInstancePorts:. **VerilogBreakBetweenInstancePorts** (``Boolean``) :versionbadge:`clang-format 17` :ref:`¶ <VerilogBreakBetweenInstancePorts>`; For Verilog, put each port on its own line in module instantiations. .. code-block:: c++. true:; ffnand ff1(.q(),; .qbar(out1),; .clear(in1),; .preset(in2));. false:; ffnand ff1(.q(), .qbar(out1), .clear(in1), .preset(in2));. .. _WhitespaceSensitiveMacros:. **WhitespaceSensitiveMacros** (``List of Strings``) :versionbadge:`clang-format 11` :ref:`¶ <WhitespaceSensitiveMacros>`; A vector of macros w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:132291,configurat,configuration,132291,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," ; Wigner coefficient functions:; ; double wigner_3j(int ja, int jb, int jc, int ma, int mb, int mc);; double wigner_6j(int ja, int jb, int jc, int jd, int je, int jf);; double wigner_9j(int ja, int jb, int jc, int jd, int je, int jf, int jg, int jh, int ji);; . New statistical function: non-central chisquare probability; density function; ; double noncentral_chisquared_pdf(double x, double r, double lambda);; ; It is implemented using Bessel functions or hypergeometric function; ; New classes VavilovAccurate and VavilovFast,; derived from the abstract base class Vavilov,; provide pdf, cdf and quantile functions for the Vavilov distribution,; based on the algorithms of CERNLIB (G116 and G115, respectively).; The classes VavilovAccuratePdf,; VavilovAccurateCdf and VavilovAccurateQuantile; implement the IParametricFunctionOneDim interface; for easier use in fit problems. . Unuran. Use new version 1.7.2 ; Add new class TUnuranSampler implementing the; ROOT::Math::DistSampler interface for one dimensional; continuous and discrete distributions and for mult-dimensional ones; . Foam. Add new class TFoamSampler implementing the; ROOT::Math::DistSampler interface for generating random; numbers according to any one or multi-dim distributions using Foam.; ; All the TFoam options can be controlled via the; ROOT::Math::DistSamplerOptions class, which can be passed; as input to the virtual ROOT::Math::DistSampler::Init(..); function.; . GenVector. Add some missing copy constructor and assignment operators to; fix compilation issue observed with LLVM (Clang). Minuit. Fix a bug when using at the same time TMinuit or TFitter with; the new TMinuitMinimizer class. See bug 72909.; . Minuit2. Fix the returned error from the Minimizer class for fixed and; constant parameters. Now is set explicitly to zero.; ; Fix a problem in re-defining fixed parameters as variable; ones. Before it was not possible to release them.; ; Fix a problem in the number of function calls when running MnHesse; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v528/index.html:9114,continuous,continuous,9114,math/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v528/index.html,1,['continuous'],['continuous']
Deployability," <hash>,; i32 <condition-id>,; ptr <mcdc-temp-addr>,; i1 <bool-value>). Overview:; """""""""""""""""". The '``llvm.instrprof.mcdc.condbitmap.update``' intrinsic is used to track; MC/DC condition evaluation for each condition in a boolean expression. Arguments:; """""""""""""""""""". The first argument is a pointer to a global variable containing the; name of the entity being instrumented. This should generally be the; (mangled) function name for a set of counters. The second argument is a hash value that can be used by the consumer; of the profile data to detect changes to the instrumented source. The third argument is an ID of a condition to track. This value is used as a; bit index into the condition bitmap. The fourth argument is the address of the condition bitmap. The fifth argument is the boolean value representing the evaluation of the; condition (true or false). Semantics:; """""""""""""""""""". This intrinsic represents the update of a condition bitmap that is local to a; function and will cause the ``-instrprof`` pass to generate the code to; instrument the control flow around each condition in a boolean expression. The; ID of each condition corresponds to a bit index in the condition bitmap which; is set based on the evaluation of the condition. '``llvm.instrprof.mcdc.tvbitmap.update``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.instrprof.mcdc.tvbitmap.update(ptr <name>, i64 <hash>,; i32 <bitmap-bytes>); i32 <bitmap-index>,; ptr <mcdc-temp-addr>). Overview:; """""""""""""""""". The '``llvm.instrprof.mcdc.tvbitmap.update``' intrinsic is used to track MC/DC; test vector execution after each boolean expression has been fully executed.; The overall value of the condition bitmap, after it has been successively; updated using the '``llvm.instrprof.mcdc.condbitmap.update``' intrinsic with; the true or false evaluation of each condition, uniquely identifies an executed; MC/DC test vector and is used as a bit index into the global test vecto",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:534422,update,update,534422,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['update'],['update']
Deployability," <https://github.com/orgs/llvm/projects/3>`_; to see the list of bugs that are being considered for the release. #. Review each bug and first check if it has been fixed in main. If it has, update; its status to ""Needs Pull Request"", and create a pull request for the fix; using the /cherry-pick or /branch comments if this has not been done already. #. If a bug has been fixed and has a pull request created for backporting it,; then update its status to ""Needs Review"" and notify a knowledgeable reviewer.; Usually you will want to notify the person who approved the patch in Phabricator,; but you may use your best judgement on who a good reviewer would be. Once; you have identified the reviewer(s), assign the issue to them and mention; them (i.e @username) in a comment and ask them if the patch is safe to backport.; You should also review the bug yourself to ensure that it meets the requirements; for committing to the release branch. #. Once a bug has been reviewed, add the release:reviewed label and update the; issue's status to ""Needs Merge"". Check the pull request associated with the; issue. If all the tests pass, then the pull request can be merged. If not,; then add a comment on the issue asking someone to take a look at the failures. #. Once the pull request has been merged push it to the official release branch; with the script ``llvm/utils/git/sync-release-repo.sh``. Then add a comment to the issue stating that the fix has been merged along with; the git hashes from the release branch. Add the release:merged label to the issue; and close it. Release Patch Rules; -------------------. Below are the rules regarding patching the release branch:. #. Patches applied to the release branch may only be applied by the release; manager, the official release testers or the code owners with approval from; the release manager. #. Release managers are encouraged, but not required, to get approval from code; owners before approving patches. If there is no code owner or the code ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:11857,release,release,11857,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,2,"['release', 'update']","['release', 'update']"
Deployability," =================================. Introduction; ============. This document contains information about successfully releasing LLVM ---; including sub-projects: e.g., ``clang`` and ``compiler-rt`` --- to the public.; It is the Release Manager's responsibility to ensure that a high quality build; of LLVM is released. If you're looking for the document on how to test the release candidates and; create the binary packages, please refer to the :doc:`ReleaseProcess` instead. .. _timeline:. Release Timeline; ================. LLVM is released on a time based schedule --- with major releases roughly; every 6 months. In between major releases there may be dot releases.; The release manager will determine if and when to make a dot release based; on feedback from the community. Typically, dot releases should be made if; there are large number of bug-fixes in the stable branch or a critical bug; has been discovered that affects a large number of users. Unless otherwise stated, dot releases will follow the same procedure as; major releases. Annual Release Schedule; -----------------------. Here is the annual release schedule for LLVM. This is meant to be a; guide, and release managers are not required to follow this exactly.; Releases should be tagged on Tuesdays. =============================== =========================; Release Approx. Date; =============================== =========================; *release branch: even releases* *4th Tue in January*; *release branch: odd releases* *4th Tue in July*; X.1.0-rc1 3 days after branch.; X.1.0-rc2 2 weeks after branch.; X.1.0-rc3 4 weeks after branch; **X.1.0-final** **6 weeks after branch**; **X.1.1** **8 weeks after branch**; **X.1.2** **10 weeks after branch**; **X.1.3** **12 weeks after branch**; **X.1.4** **14 weeks after branch**; **X.1.5** **16 weeks after branch**; **X.1.6 (if necessary)** **18 weeks after branch**; =============================== =========================. Release Process Summary; -----------------------.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:1055,release,releases,1055,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,2,['release'],['releases']
Deployability," @runtime(); call void (i64, i32, ...) @llvm.experimental.stackmap(i64 77, i32 8,; ptr %ptr); %val = load i64, ptr %ptr; %add = add i64 %val, 3; ret i64 %add. May require one byte of nop-padding:. .. code-block:: none. 0x00 callq _runtime; 0x05 nop <--- stack map address; 0x06 movq (%rdi), %rax; 0x07 addq $3, %rax; 0x0a popq %rdx; 0x0b ret <---- end of 8-byte shadow. Now, if the runtime needs to invalidate the compiled code, it may; patch 8 bytes of code at the stack map's address at follows:. .. code-block:: none. 0x00 callq _runtime; 0x05 movl $0xffff, %rax <--- patched code at stack map address; 0x0a callq *%rax <---- end of 8-byte shadow. This way, after the normal call to the runtime returns, the code will; execute a patched call to a special entry point that can rebuild a; stack frame from the values located by the stack map. '``llvm.experimental.patchpoint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.patchpoint.void(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...); declare i64; @llvm.experimental.patchpoint.i64(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.patchpoint.*``' intrinsics creates a function; call to the specified ``<target>`` and records the location of specified; values in the stack map. Operands:; """""""""""""""""". The first operand is an ID, the second operand is the number of bytes; reserved for the patchable region, the third operand is the target; address of a function (optionally null), and the fourth operand; specifies how many of the following variable operands are considered; function call arguments. The remaining variable number of operands are; the ``live values`` for which locations will be recorded in the stack; map. Semantics:; """""""""""""""""""". The patch point intrinsic generates a stack map. It also emits a; function call to the address specified by ``<target>`` if the address; is not a constant nul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:7475,patch,patchpoint,7475,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['patch'],['patchpoint']
Deployability," A PCH file can then be used as a prefix header when a ``-include-pch``; option is passed to ``clang``:. .. code-block:: console. $ clang -include-pch test.h.pch test.c -o test. The ``clang`` driver will check if the PCH file ``test.h.pch`` is; available; if so, the contents of ``test.h`` (and the files it includes); will be processed from the PCH file. Otherwise, Clang will report an error. .. note::. Clang does *not* automatically use PCH files for headers that are directly; included within a source file or indirectly via :option:`-include`.; For example:. .. code-block:: console. $ clang -x c-header test.h -o test.h.pch; $ cat test.c; #include ""test.h""; $ clang test.c -o test. In this example, ``clang`` will not automatically use the PCH file for; ``test.h`` since ``test.h`` was included directly in the source file and not; specified on the command line using ``-include-pch``. Relocatable PCH Files; ^^^^^^^^^^^^^^^^^^^^^. It is sometimes necessary to build a precompiled header from headers; that are not yet in their final, installed locations. For example, one; might build a precompiled header within the build tree that is then; meant to be installed alongside the headers. Clang permits the creation; of ""relocatable"" precompiled headers, which are built with a given path; (into the build directory) and can later be used from an installed; location. To build a relocatable precompiled header, place your headers into a; subdirectory whose structure mimics the installed location. For example,; if you want to build a precompiled header for the header ``mylib.h``; that will be installed into ``/usr/include``, create a subdirectory; ``build/usr/include`` and place the header ``mylib.h`` into that; subdirectory. If ``mylib.h`` depends on other headers, then they can be; stored within ``build/usr/include`` in a way that mimics the installed; location. Building a relocatable precompiled header requires two additional; arguments. First, pass the ``--relocatable-pch`` flag t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:47976,install,installed,47976,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['install'],['installed']
Deployability," A few developers in the community have dedicated time to validate the release; candidates and volunteered to be the official release testers for each; architecture. These will be the ones testing, generating and uploading the official binaries; to the server, and will be the minimum tests *necessary* for the release to; proceed. This will obviously not cover all OSs and distributions, so additional community; validation is important. However, if community input is not reached before the; release is out, all bugs reported will have to go on the next stable release. The official release managers are:. * Even releases: Tom Stellard (tstellar@redhat.com); * Odd releases: Tobias Hieta (tobias@hieta.se). The official release testers are volunteered from the community and have; consistently validated and released binaries for their targets/OSs. To contact; them, you should post on the `Discourse forums (Project; Infrastructure - Release Testers). <https://discourse.llvm.org/c/infrastructure/release-testers/66>`_. The official testers list is in the file ``RELEASE_TESTERS.TXT``, in the ``LLVM``; repository. Community Testing; -----------------. Once all testing has been completed and appropriate bugs filed, the release; candidate tarballs are put on the website and the LLVM community is notified. We ask that all LLVM developers test the release in any the following ways:. #. Download ``llvm-X.Y``, ``llvm-test-X.Y``, and the appropriate ``clang``; binary. Build LLVM. Run ``make check`` and the full LLVM test suite (``make; TEST=nightly report``). #. Download ``llvm-X.Y``, ``llvm-test-X.Y``, and the ``clang`` sources. Compile; everything. Run ``make check`` and the full LLVM test suite (``make; TEST=nightly report``). #. Download ``llvm-X.Y``, ``llvm-test-X.Y``, and the appropriate ``clang``; binary. Build whole programs with it (ex. Chromium, Firefox, Apache) for; your platform. #. Download ``llvm-X.Y``, ``llvm-test-X.Y``, and the appropriate ``clang``; binary. Build *your* ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:7813,release,release-testers,7813,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['release'],['release-testers']
Deployability," ABI alignment of types; the layout of structs and; unions and the value returned by the alignof operator remain the same. This option can be overridden on a case-by-case basis by putting an explicit; “aligned” alignment on a struct, union, or typedef. For example:. .. code-block:: console. #include <immintrin.h>; // Make an aligned typedef of the AVX-512 16-int vector type.; typedef __v16si __aligned_v16si __attribute__((aligned(64)));. void initialize_vector(__aligned_v16si *v) {; // The compiler may assume that ‘v’ is 64-byte aligned, regardless of the; // value of -fmax-type-align.; }. .. option:: -faddrsig, -fno-addrsig. Controls whether Clang emits an address-significance table into the object; file. Address-significance tables allow linkers to implement `safe ICF; <https://research.google.com/pubs/archive/36912.pdf>`_ without the false; positives that can result from other implementation techniques such as; relocation scanning. Address-significance tables are enabled by default; on ELF targets when using the integrated assembler. This flag currently; only has an effect on ELF targets. .. option:: -f[no]-unique-internal-linkage-names. Controls whether Clang emits a unique (best-effort) symbol name for internal; linkage symbols. When this option is set, compiler hashes the main source; file path from the command line and appends it to all internal symbols. If a; program contains multiple objects compiled with the same command-line source; file path, the symbols are not guaranteed to be unique. This option is; particularly useful in attributing profile information to the correct; function when multiple functions with the same private linkage name exist; in the binary. It should be noted that this option cannot guarantee uniqueness and the; following is an example where it is not unique when two modules contain; symbols with the same private linkage name:. .. code-block:: console. $ cd $P/foo && clang -c -funique-internal-linkage-names name_conflict.c; $ cd $P/ba",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:87053,integrat,integrated,87053,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['integrat'],['integrated']
Deployability," A[0]+A[1]+A[2]+A[3];; }. Instead we get this:. _f32: ## @f32; 	pshufd	$1, %xmm0, %xmm1 ## xmm1 = xmm0[1,0,0,0]; 	addss	%xmm0, %xmm1; 	pshufd	$3, %xmm0, %xmm2 ## xmm2 = xmm0[3,0,0,0]; 	movhlps	%xmm0, %xmm0 ## xmm0 = xmm0[1,1]; 	movaps	%xmm0, %xmm3; 	addss	%xmm1, %xmm3; 	movdqa	%xmm2, %xmm0; 	addss	%xmm3, %xmm0; 	ret. Also, there are cases where some simple local SLP would improve codegen a bit.; compiling this:. _Complex float f32(_Complex float A, _Complex float B) {; return A+B;; }. into:. _f32: ## @f32; 	movdqa	%xmm0, %xmm2; 	addss	%xmm1, %xmm2; 	pshufd	$1, %xmm1, %xmm1 ## xmm1 = xmm1[1,0,0,0]; 	pshufd	$1, %xmm0, %xmm3 ## xmm3 = xmm0[1,0,0,0]; 	addss	%xmm1, %xmm3; 	movaps	%xmm2, %xmm0; 	unpcklps	%xmm3, %xmm0 ## xmm0 = xmm0[0],xmm3[0],xmm0[1],xmm3[1]; 	ret. seems silly when it could just be one addps. //===---------------------------------------------------------------------===//. Expand libm rounding functions inline: Significant speedups possible.; http://gcc.gnu.org/ml/gcc-patches/2006-10/msg00909.html. //===---------------------------------------------------------------------===//. When compiled with unsafemath enabled, ""main"" should enable SSE DAZ mode and; other fast SSE modes. //===---------------------------------------------------------------------===//. Think about doing i64 math in SSE regs on x86-32. //===---------------------------------------------------------------------===//. This testcase should have no SSE instructions in it, and only one load from; a constant pool:. double %test3(bool %B) {; %C = select bool %B, double 123.412, double 523.01123123; ret double %C; }. Currently, the select is being lowered, which prevents the dag combiner from; turning 'select (load CPI1), (load CPI2)' -> 'load (select CPI1, CPI2)'. The pattern isel got this one right. //===---------------------------------------------------------------------===//. Lower memcpy / memset to a series of SSE 128 bit move instructions when it's; feasible. //===------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:2071,patch,patches,2071,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,1,['patch'],['patches']
Deployability," Analysis Facility is; simply a matter of starting a certain number of CernVM virtual machines; that will become part of your PROOF cluster. CernVM uses; contextualization to specialize each virtual machine to be either a head; node or a worker node. The Virtual Analysis Facility comes with many preconfigured things:. - a HTCondor cluster capable of running PROOF on Demand. - certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only av",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:1317,release,releases,1317,proof/doc/confman/DeployVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md,1,['release'],['releases']
Deployability," AnotherBranch; cd ../../projects/libcxx; git checkout AnotherBranch. .. _workflow-mono-branching:. Monorepo Variant; ^^^^^^^^^^^^^^^^. Regular Git commands are sufficient, because everything is in a single; repository:. To update the repository to tip of trunk::. git pull. To create a new branch::. git checkout -b MyBranch. To switch branches::. git checkout AnotherBranch. Bisecting; ---------. Assuming a developer is looking for a bug in clang (or lld, or lldb, ...). Currently; ^^^^^^^^^. SVN does not have builtin bisection support, but the single revision across; sub-projects makes it possible to script around. Using the existing Git read-only view of the repositories, it is possible to use; the native Git bisection script over the llvm repository, and use some scripting; to synchronize the clang repository to match the llvm revision. .. _workflow-mono-bisecting:. Monorepo Variant; ^^^^^^^^^^^^^^^^. Bisecting on the monorepo is straightforward, and very similar to the above,; except that the bisection script does not need to include the; `git submodule update` step. The same example, finding which commit introduces a regression where clang-3.9; crashes but not clang-3.8 passes, will look like::. git bisect start releases/3.9.x releases/3.8.x; git bisect run ./bisect_script.sh. With the `bisect_script.sh` script being::. #!/bin/sh; cd $BUILD_DIR. ninja clang || exit 125 # an exit code of 125 asks ""git bisect""; # to ""skip"" the current commit. ./bin/clang some_crash_test.cpp. Also, since the monorepo handles commits update across multiple projects, you're; less like to encounter a build failure where a commit change an API in LLVM and; another later one ""fixes"" the build in clang. Moving Local Branches to the Monorepo; =====================================. Suppose you have been developing against the existing LLVM git; mirrors. You have one or more git branches that you want to migrate; to the ""final monorepo"". The simplest way to migrate such branches is with the;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:19388,update,update,19388,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['update'],['update']
Deployability," B physics. ; MULTIDIMENSIONAL MODELS. rf301_composition.C - Multi-dimensional p.d.f.s through composition, e.g. substituting a p.d.f parameter with a function that depends on other observables; rf302_utilfuncs.C - Utility functions classes available for use in tailoring; rf303_conditional.C - Use of tailored p.d.f as conditional p.d.fs.s; rf304_uncorrprod.C - Simple uncorrelated multi-dimensional p.d.f.s; rf305_condcorrprod.C - Multi-dimensional p.d.f.s with conditional p.d.fs in product; rf306_condpereventerrors.C - Complete example with use of conditional p.d.f. with per-event errors; rf307_fullpereventerrors.C -Complete example with use of full p.d.f. with per-event errors; rf308_normintegration2d.C - Examples on normalization of p.d.f.s in more than one dimension; rf309_ndimplot.C - Making 2 and 3 dimensional plots of p.d.f.s and datasets; rf310_sliceplot.C -Projecting p.d.f and data slices in discrete observables; rf311_rangeplot.C -Projecting p.d.f and data ranges in continuous observables; rf312_multirangefit.C - Performing fits in multiple (disjoint) ranges in one or more dimensions; rf313_paramranges.C - Working with parameterized ranges to define non-rectangular regions; rf314_paramfitrange.C - Working with parameterized ranges in a fit.; rf315_projectpdf.C - Marginizalization of multi-dimensional p.d.f.s through integration; rf316_llratioplot.C - Using the likelihood ratio technique to construct a signal enhanced 1-D projection of a multi-dimensional p.d.f.; ; DATA AND CATEGORIES. rf401_importttreethx.C -Overview of advanced option for importing data from ROOT TTree and THx histograms; rf402_datahandling.C - Tools for manipulation of (un)binned datasets; rf403_weightedevts.C - Using weights in unbinned datasets; rf404_categories.C - Working with RooCategory objects to describe discrete variables; rf405_realtocatfuncs.C - Demonstration of real-->discrete mapping functions; rf406_cattocatfuncs.C - Demonstration of discrete-->discrete (invertable) functions;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:3036,continuous,continuous,3036,roofit/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html,1,['continuous'],['continuous']
Deployability," BPF_LD) which are used to access packet data.; Register R6 is an implicit input that must contain pointer to sk_buff.; Register R0 is an implicit output which contains the data fetched; from the packet. Registers R1-R5 are scratch registers and must not; be used to store the data across BPF_ABS | BPF_LD or BPF_IND | BPF_LD; instructions. These instructions have implicit program exit condition; as well. When eBPF program is trying to access the data beyond; the packet boundary, the interpreter will abort the execution of the program. BPF_IND | BPF_W | BPF_LD is equivalent to:; R0 = ntohl(\*(u32 \*) (((struct sk_buff \*) R6)->data + src_reg + imm32)). eBPF maps; ^^^^^^^^^. eBPF maps are provided for sharing data between kernel and user-space.; Currently implemented types are hash and array, with potential extension to; support bloom filters, radix trees, etc. A map is defined by its type,; maximum number of elements, key size and value size in bytes. eBPF syscall; supports create, update, find and delete functions on maps. Function calls; ^^^^^^^^^^^^^^. Function call arguments are passed using up to five registers (R1 - R5).; The return value is passed in a dedicated register (R0). Four additional; registers (R6 - R9) are callee-saved, and the values in these registers; are preserved within kernel functions. R0 - R5 are scratch registers within; kernel functions, and eBPF programs must therefor store/restore values in; these registers if needed across function calls. The stack can be accessed; using the read-only frame pointer R10. eBPF registers map 1:1 to hardware; registers on x86_64 and other 64-bit architectures. For example, x86_64; in-kernel JIT maps them as. ::. R0 - rax; R1 - rdi; R2 - rsi; R3 - rdx; R4 - rcx; R5 - r8; R6 - rbx; R7 - r13; R8 - r14; R9 - r15; R10 - rbp. since x86_64 ABI mandates rdi, rsi, rdx, rcx, r8, r9 for argument passing; and rbx, r12 - r15 are callee saved. Program start; ^^^^^^^^^^^^^. An eBPF program receives a single argument and co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:106811,update,update,106811,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['update'],['update']
Deployability," Brian Bockelman, UNL,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Raphael Isemann, Chalmers Univ. of Tech.,\; Vladimir Ilievski, GSOC 2017,\; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Saurav Shekhar, GSOC 2017,\; Xavier Valls Pla, UJI, CERN/SFT,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, CERN/SFT, \; Zhe Zhang, UNL. ## Important Notice. The default compression algorithm used when writing ROOT files has been updated to use LZ4 in particular to improve read (decompression) performance. You can change this default for each file through (for example) the `TFile constructor` or `TFile::SetCompressionAlgorithm`. It should be noted that ROOT files written with LZ4 compression can not be read with older release of ROOT. Support for LZ4 was however back-ported to the patch branches of previous releases and the following tags (and later release in the same patch series) can read ROOT files written with LZ4 compression:. * v5.34/38; * v6.08/06 [not yet released]; * v6.10/08; * v6.12/02. ## Removed interfaces. ## Core Libraries; - Optimize away redundant deserialization of template specializations. This reduces the memory footprint for hsimple by around 30% while improving the runtime performance for various cases by around 15%.; - When ROOT is signaled with a SIGUSR2 (i.e. on Linux and MacOS X) it will now print a backtrace.; - Move RStringView.h to ROOT/RStringView.hxx and always include ROOT/RStringView.hxx instead of RStringView.h for backward compatibility; - In `TClingCallFunc`, support r-value reference parameters. This paves the way for the corresponding support in PyROOT (implemented now in the latest Cppyy).; - Included the new TSequentialEx",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:1411,release,release,1411,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,1,['release'],['release']
Deployability," CORS on Apache web server, hosting ROOT files, one should add following lines to `.htaccess` file:. <IfModule mod_headers.c>; <FilesMatch ""\.root"">; Header set Access-Control-Allow-Origin ""*""; Header set Access-Control-Allow-Headers ""range""; Header set Access-Control-Expose-Headers ""content-range,content-length,accept-ranges""; Header set Access-Control-Allow-Methods ""GET""; </FilesMatch>; </IfModule>. More details about configuring of CORS headers can be found [here](https://developer.mozilla.org/en/http_access_control). Alternative - enable CORS requests in the browser. It can be easily done with [CORS Everywhere plugin](https://addons.mozilla.org/de/firefox/addon/cors-everywhere/) for the Firefox browser or [Allow CORS plugin](https://chrome.google.com/webstore/detail/allow-control-allow-origi/nlfbmbojpeacfghkpbjhddihlkkiljbi?hl=en) for the Chrome browser. Next solution - install JSROOT on the server hosting ROOT files. In such configuration JSROOT does not issue CORS requests, therefore server and browsers can be used with their default settings. A simplified variant of such solution - copy only the top index.htm file from JSROOT package and specify the full path to `modules/gui.mjs` script like:. ```javascript; <script type=""module"">; import { openFile, draw } from 'https://root.cern/js/latest/modules/gui.mjs';; // ...; </script>; ```. In the main `<div>` element one can specify many custom parameters like one do it in URL string:. ```html; <div id=""simpleGUI"" path=""files/path"" files=""userfile1.root;subdir/usefile2.root"">; loading scripts ...; </div>; ```. ## Reading local ROOT files. JSROOT can read files from local file system using HTML5 FileReader functionality.; Main limitation here - user should interactively select files for reading.; There is button __""...""__ on the main JSROOT page, which starts file selection dialog.; If valid ROOT file is selected, JSROOT will be able to normally read content of such file. ## JSROOT with THttpServer. THttpServer provi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:28733,configurat,configuration,28733,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['configurat'],['configuration']
Deployability," Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsRea",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:4704,integrat,integration,4704,roofit/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html,1,['integrat'],['integration']
Deployability," Clang; **Debug** None Yes Yes Developers of LLVM; **RelWithDebInfo** For Speed Yes No Users that also need Debug; **MinSizeRel** For Size No No When disk space matters; =========================== ============= ========== ========== ==========================. * Optimizations make LLVM/Clang run faster, but can be an impediment for; step-by-step debugging.; * Builds with debug information can use a lot of RAM and disk space and is; usually slower to run. You can improve RAM usage by using ``lld``, see; the :ref:`LLVM_USE_LINKER <llvm_use_linker>` option.; * Assertions are internal checks to help you find bugs. They typically slow; down LLVM and Clang when enabled, but can be useful during development.; You can manually set :ref:`LLVM_ENABLE_ASSERTIONS <llvm_enable_assertions>`; to override the default from `CMAKE_BUILD_TYPE`. If you are using an IDE such as Visual Studio or Xcode, you should use; the IDE settings to set the build type. **CMAKE_INSTALL_PREFIX**:PATH; Path where LLVM will be installed when the ""install"" target is built. **CMAKE_{C,CXX}_FLAGS**:STRING; Extra flags to use when compiling C and C++ source files respectively. **CMAKE_{C,CXX}_COMPILER**:STRING; Specify the C and C++ compilers to use. If you have multiple; compilers installed, CMake might not default to the one you wish to; use. .. _Frequently Used LLVM-related variables:. Frequently Used LLVM-related variables; --------------------------------------. The default configuration may not match your requirements. Here are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. *",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:8384,install,installed,8384,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,2,['install'],"['install', 'installed']"
Deployability, Constructor checking in new-expression; Unknown. 2103; CD5; Lvalue-to-rvalue conversion is irrelevant in odr-use of a reference; Yes. 2104; CD4; Internal-linkage constexpr references and ODR requirements; Unknown. 2105; open; When do the arguments for a parameter pack end?; Not resolved. 2106; CD4; Unclear restrictions on use of function-type template arguments; Unknown. 2107; CD4; Lifetime of temporaries for default arguments in array copying; Unknown. 2108; drafting; Conversions to non-class prvalues in reference initialization; Not resolved. 2109; CD4; Value dependence underspecified; Unknown. 2110; drafting; Overload resolution for base class conversion and reference/non-reference; Not resolved. 2111; NAD; Array temporaries in reference binding; Unknown. 2112; CD5; new auto{x}; Unknown. 2113; CD4; Incompete specification of types for declarators; Unknown. 2114; CD3; Missing description of incompatibility from aggregate NSDMIs; Unknown. 2115; drafting; Order of implicit destruction vs release of automatic storage; Not resolved. 2116; C++17; Direct or copy initialization for omitted aggregate initializers; Unknown. 2117; drafting; Explicit specializations and constexpr function templates; Not resolved. 2118; open; Stateful metaprogramming via friend injection; Not resolved. 2119; NAD; Disambiguation of multi-level covariant return type; Unknown. 2120; CD4; Array as first non-static data member in standard-layout class; Clang 7. 2121; CD6; More flexible lambda syntax; Unknown. 2122; CD4; Glvalues of void type; Unknown. 2123; open; Omitted constant initialization of local static variables; Not resolved. 2124; CD4; Signature of constructor template; Unknown. 2125; NAD; Copy elision and comma operator; Unknown. 2126; C++20; Lifetime-extended temporaries in constant expressions; Clang 12. 2127; drafting; Partial specialization and nullptr; Not resolved. 2128; drafting; Imprecise rule for reference member initializer; Not resolved. 2129; CD4; Non-object prvalues and con,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:143999,release,release,143999,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,1,['release'],['release']
Deployability," Cortex-M4.; Multilib can also choose between libraries for the same architecture based on; other options. For example if the user specifies ``-fno-exceptions`` then a; toolchain could select libraries built without exception support, thereby; reducing the size of the resulting binary. Design; ======. Clang supports GCC's ``-print-multi-lib`` and ``-print-multi-directory``; options. These are described in; `GCC Developer Options <https://gcc.gnu.org/onlinedocs/gcc-12.2.0/gcc/Developer-Options.html>`_. There are two ways to configure multilib in Clang: hard-coded or via a; configuration file. Hard-coded Multilib; ===================. The available libraries can be hard-coded in Clang. Typically this is done; using the ``MultilibBuilder`` interface in; ``clang/include/clang/Driver/MultilibBuilder.h``.; There are many examples of this in ``lib/Driver/ToolChains/Gnu.cpp``.; The remainder of this document will not focus on this type of multilib. EXPERIMENTAL Multilib via configuration file; ============================================. Some Clang toolchains support loading multilib configuration from a; ``multilib.yaml`` configuration file. A ``multilib.yaml`` configuration file specifies which multilib variants are; available, their relative location, what compilation options were used to build; them, and the criteria by which they are selected. Multilib processing; ===================. Clang goes through the following steps to use multilib from a configuration; file:. #. Normalize command line options. Clang can accept the same; information via different options - for example,; ``--target=arm-none-eabi -march=armv7-m`` and; ``--target=armv7m-none-eabi`` are equivalent.; Clang normalizes the command line before passing them to the multilib system.; To see what flags are emitted for a given set of command line options, use; the ``-print-multi-flags-experimental`` command line option; along with the rest of the options you want to use.; #. Load ``multilib.yaml`` from sysr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst:1920,configurat,configuration,1920,interpreter/llvm-project/clang/docs/Multilib.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst,1,['configurat'],['configuration']
Deployability, DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT webassembly-resource-headers). install(; FILES ${x86_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT x86-resource-headers). if(NOT CLANG_ENABLE_HLSL); set(EXCLUDE_HLSL EXCLUDE_FROM_ALL); endif(). install(; FILES ${hlsl_h}; DESTINATION ${header_install_dir}; ${EXCLUDE_HLSL}; COMPONENT hlsl-resource-headers). install(; FILES ${hlsl_subdir_files}; DESTINATION ${header_install_dir}/hlsl; ${EXCLUDE_HLSL}; COMPONENT hlsl-resource-headers). install(; FILES ${opencl_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT opencl-resource-headers). install(; FILES ${openmp_wrapper_files}; DESTINATION ${header_install_dir}/openmp_wrappers; EXCLUDE_FROM_ALL; COMPONENT openmp-resource-headers). install(; FILES ${openmp_wrapper_files}; DESTINATION ${header_install_dir}/openmp_wrappers; EXCLUDE_FROM_ALL; COMPONENT openmp-resource-headers). install(; FILES ${utility_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT utility-resource-headers). install(; FILES ${windows_only_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT windows-resource-headers); #############################################################. if (NOT LLVM_ENABLE_IDE); add_llvm_install_targets(install-clang-resource-headers; DEPENDS clang-resource-headers; COMPONENT clang-resource-headers). add_llvm_install_targets(install-core-resource-headers; DEPENDS core-resource-headers; COMPONENT core-resource-headers); add_llvm_install_targets(install-arm-common-resource-headers; DEPENDS arm-common-resource-headers; COMPONENT arm-common-resource-headers); add_llvm_install_targets(install-arm-resource-headers; DEPENDS arm-resource-headers; COMPONENT arm-resource-headers); add_llvm_install_targets(install-aarch64-resource-headers; DEPENDS aarch64-resource-headers; COMPONENT aarch64-resource-headers); add_llvm_install_targets(install-cuda-resource-headers; DEPENDS cuda-resource-headers; ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt:16282,install,install,16282,interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,1,['install'],['install']
Deployability," Discourse forums`_ describing; your target and how it follows all the requirements and what work has been; done and will need to be done to accommodate the official target requirements.; Make sure to expose any and all controversial issues, changes needed in the; base code, table gen, etc.; 3. Once the response is positive, the LLVM community can start reviewing the; actual patches (but they can be prepared before, to support the RFC). Create; a sequence of N patches, numbered '1/N' to 'N/N' (make sure N is an actual; number, not the letter 'N'), that completes the basic structure of the target.; 4. The initial patch should add documentation, code owners and triple support in; clang and LLVM. The following patches add TableGen infrastructure to describe; the target and lower instructions to assembly. The final patch must show that; the target can lower correctly with extensive LIT tests (IR to MIR, MIR to; ASM, etc).; 5. Some patches may be approved before others, but only after *all* patches are; approved that the whole set can be merged in one go. This is to guarantee; that all changes are good as a single block.; 6. After the initial merge, the target community can stop numbering patches and; start working asynchronously on the target to complete support. They should; still seek review from those who helped them in the initial phase, to make; sure the progress is still consistent.; 7. Once all official requirements have been fulfilled (as above), the code owner; should request the target to be enabled by default by sending another RFC to; the `LLVM Discourse forums`_. Adding an Established Project To the LLVM Monorepo; --------------------------------------------------. The `LLVM monorepo <https://github.com/llvm/llvm-project>`_ is the centerpoint; of development in the LLVM world, and has all of the primary LLVM components,; including the LLVM optimizer and code generators, Clang, LLDB, etc. `Monorepos; in general <https://en.wikipedia.org/wiki/Monorepo>`_ are g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:44235,patch,patches,44235,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,2,['patch'],['patches']
Deployability," DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:3564,install,install,3564,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,2,['install'],['install']
Deployability," EXISTS ""${FREETYPE_INCLUDE_DIR}/ft2build.h""); message(ERROR ""Can't find ft2build.h in ${FREETYPE_INCLUDE_DIR}""); endif(). if(NOT EXISTS ""${ZLIB_INCLUDE_DIR}/zlib.h""); message(ERROR ""Can't find zlib.h in ${ZLIB_INCLUDE_DIR}""); endif(). INCLUDE_DIRECTORIES(${FREETYPE_INCLUDE_DIR} ${ZLIB_INCLUDE_DIR}). set (LIB_DESTINATION ""${CMAKE_INSTALL_PREFIX}/lib${LIB_SUFFIX}""). FILE(GLOB H_FILES ""*.h""). SET(SRC_FILES; libpng/png.c libpng/pngmem.c libpng/pngrio.c libpng/pngset.c libpng/pngwio.c libpng/pngwutil.c; libpng/pngerror.c libpng/pngpread.c libpng/pngrtran.c libpng/pngtest.c libpng/pngwrite.c; libpng/pngget.c libpng/pngread.c libpng/pngrutil.c libpng/pngtrans.c libpng/pngwtran.c; libjpeg/jcapimin.c libjpeg/jcapistd.c libjpeg/jccoefct.c libjpeg/jccolor.c libjpeg/jcdctmgr.c libjpeg/jchuff.c libjpeg/jcinit.c; libjpeg/jcmainct.c libjpeg/jcmarker.c libjpeg/jcmaster.c libjpeg/jcomapi.c libjpeg/jcparam.c libjpeg/jcphuff.c libjpeg/jcprepct.c; libjpeg/jcsample.c libjpeg/jctrans.c libjpeg/jdapimin.c libjpeg/jdapistd.c libjpeg/jdatadst.c libjpeg/jdatasrc.c libjpeg/jdcoefct.c; libjpeg/jdcolor.c libjpeg/transupp.c libjpeg/jaricom.c libjpeg/jdarith.c libjpeg/jcarith.c libjpeg/jddctmgr.c libjpeg/jdhuff.c; libjpeg/jdinput.c libjpeg/jdmainct.c libjpeg/jdmarker.c libjpeg/jdmaster.c libjpeg/jdmerge.c libjpeg/jdpostct.c libjpeg/jdsample.c; libjpeg/jdtrans.c libjpeg/jerror.c libjpeg/jfdctflt.c libjpeg/jfdctfst.c libjpeg/jfdctint.c libjpeg/jidctflt.c libjpeg/jidctfst.c; libjpeg/jidctint.c libjpeg/jmemmgr.c libjpeg/jmemnobs.c libjpeg/jquant1.c libjpeg/jquant2.c libjpeg/jutils.c; libungif/dgif_lib.c libungif/egif_lib.c libungif/gif_err.c libungif/gifalloc.c libungif/gif_hash.c afterbase.c ascmap.c asfont.c; asimage.c asstorage.c asvisual.c blender.c bmp.c char2uni.c; export.c import.c transform.c ungif.c xcf.c ximage.c xpm.c draw.c; imencdec.c scanline.c; afterrootpngwrite.c; ). ADD_LIBRARY(${LIB_NAME} STATIC ${H_FILES} ${SRC_FILES}). install(TARGETS ${LIB_NAME} DESTINATION ${LIB_DESTINATION}); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/asimage/src/libAfterImage/CMakeLists.txt:2971,install,install,2971,graf2d/asimage/src/libAfterImage/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/asimage/src/libAfterImage/CMakeLists.txt,1,['install'],['install']
Deployability," Foundation sponsors the server and; provides limited support, but there is only so much it can do. Volunteers are not sysadmins themselves, but compiler engineers that happen; to know a thing or two about hosting servers. We also don't have 24/7 support,; and we sometimes wake up to see that continuous integration is broken because; the SVN server is either down or unresponsive. We should take advantage of one of the services out there (GitHub, GitLab,; and BitBucket, among others) that offer better service (24/7 stability, disk; space, Git server, code browsing, forking facilities, etc) for free. Why Git?; --------. Many new coders nowadays start with Git, and a lot of people have never used; SVN, CVS, or anything else. Websites like GitHub have changed the landscape; of open source contributions, reducing the cost of first contribution and; fostering collaboration. Git is also the version control many LLVM developers use. Despite the; sources being stored in a SVN server, these developers are already using Git; through the Git-SVN integration. Git allows you to:. * Commit, squash, merge, and fork locally without touching the remote server.; * Maintain local branches, enabling multiple threads of development.; * Collaborate on these branches (e.g. through your own fork of llvm on GitHub).; * Inspect the repository history (blame, log, bisect) without Internet access.; * Maintain remote forks and branches on Git hosting services and; integrate back to the main repository. In addition, because Git seems to be replacing many OSS projects' version; control systems, there are many tools that are built over Git.; Future tooling may support Git first (if not only). Why GitHub?; -----------. GitHub, like GitLab and BitBucket, provides free code hosting for open source; projects. Any of these could replace the code-hosting infrastructure that we; have today. These services also have a dedicated team to monitor, migrate, improve and; distribute the contents of the repositor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:2492,integrat,integration,2492,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['integrat'],['integration']
Deployability," GNU LESSER GENERAL PUBLIC LICENSE; Version 2.1, February 1999. Copyright (C) 1991, 1999 Free Software Foundation, Inc.; 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA; Everyone is permitted to copy and distribute verbatim copies; of this license document, but changing it is not allowed. [This is the first released version of the Lesser GPL. It also counts; as the successor of the GNU Library Public License, version 2, hence; the version number 2.1.]. Preamble. The licenses for most software are designed to take away your; freedom to share and change it. By contrast, the GNU General Public; Licenses are intended to guarantee your freedom to share and change; free software--to make sure the software is free for all its users. This license, the Lesser General Public License, applies to some; specially designated software packages--typically libraries--of the; Free Software Foundation and other authors who decide to use it. You; can use it too, but we suggest you first think carefully about whether; this license or the ordinary General Public License is the better; strategy to use in any particular case, based on the explanations below. When we speak of free software, we are referring to freedom of use,; not price. Our General Public Licenses are designed to make sure that; you have the freedom to distribute copies of free software (and charge; for this service if you wish); that you receive source code or can get; it if you want it; that you can change the software and use pieces of; it in new free programs; and that you are informed that you can do; these things. To protect your rights, we need to make restrictions that forbid; distributors to deny you these rights or to ask you to surrender these; rights. These restrictions translate to certain responsibilities for; you if you distribute copies of the library or if you modify it. For example, if you distribute copies of the library, whether gratis; or for a fee, you must give the recipients all the rights tha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/LGPL2_1.txt:316,release,released,316,LGPL2_1.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/LGPL2_1.txt,1,['release'],['released']
Deployability," However, sometimes it can; negatively impact the performance because two-address code is more restrictive; when it comes to scheduling. Unfortunately, liveout information is currently unavailable during DAG combine; time. 2) Consider spliting a indexed load / store into a pair of add/sub + load/store; to solve #1 (in TwoAddressInstructionPass.cpp). 3) Enhance LSR to generate more opportunities for indexed ops. 4) Once we added support for multiple result patterns, write indexed loads; patterns instead of C++ instruction selection code. 5) Use VLDM / VSTM to emulate indexed FP load / store. //===---------------------------------------------------------------------===//. Implement support for some more tricky ways to materialize immediates. For; example, to get 0xffff8000, we can use:. mov r9, #&3f8000; sub r9, r9, #&400000. //===---------------------------------------------------------------------===//. We sometimes generate multiple add / sub instructions to update sp in prologue; and epilogue if the inc / dec value is too large to fit in a single immediate; operand. In some cases, perhaps it might be better to load the value from a; constantpool instead. //===---------------------------------------------------------------------===//. GCC generates significantly better code for this function. int foo(int StackPtr, unsigned char *Line, unsigned char *Stack, int LineLen) {; int i = 0;. if (StackPtr != 0) {; while (StackPtr != 0 && i < (((LineLen) < (32768))? (LineLen) : (32768))); Line[i++] = Stack[--StackPtr];; if (LineLen > 32768); {; while (StackPtr != 0 && i < LineLen); {; i++;; --StackPtr;; }; }; }; return StackPtr;; }. //===---------------------------------------------------------------------===//. This should compile to the mlas instruction:; int mlas(int x, int y, int z) { return ((x * y + z) < 0) ? 7 : 13; }. //===---------------------------------------------------------------------===//. At some point, we should triage these to see if they still apply to us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:9553,update,update,9553,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,1,['update'],['update']
Deployability," IDE build folder separate from the; Ninja build folder. This prevents the two build systems from negatively; interacting with each other. Once the ``compile_commands.json`` file has been created by Ninja, you can; use that compilation database with Clang Tooling. One caveat is that because; there are indirect settings obtained through the environment variables,; you may need to run any Clang Tooling executables through a command prompt; window created for use with Visual Studio as described above. An; alternative, e.g. for using the Visual Studio debugger on a Clang Tooling; executable, is to ensure that the environment variables are also visible; to the debugger settings. This can be done locally in Visual Studio's; debugger configuration locally or globally by launching the Visual Studio; IDE from a suitable command-prompt window. Using Clang Tools; =================. After you completed the previous steps, you are ready to run clang tools. If; you have a recent clang installed, you should have ``clang-check`` in; ``$PATH``. Try to run it on any ``.cpp`` file inside the LLVM source tree:. .. code-block:: console. $ clang-check tools/clang/lib/Tooling/CompilationDatabase.cpp. If you're using vim, it's convenient to have clang-check integrated. Put; this into your ``.vimrc``:. ::. function! ClangCheckImpl(cmd); if &autowrite | wall | endif; echo ""Running "" . a:cmd . "" ...""; let l:output = system(a:cmd); cexpr l:output; cwindow; let w:quickfix_title = a:cmd; if v:shell_error != 0; cc; endif; let g:clang_check_last_cmd = a:cmd; endfunction. function! ClangCheck(); let l:filename = expand('%'); if l:filename =~ '\.\(cpp\|cxx\|cc\|c\)$'; call ClangCheckImpl(""clang-check "" . l:filename); elseif exists(""g:clang_check_last_cmd""); call ClangCheckImpl(g:clang_check_last_cmd); else; echo ""Can't detect file's compilation arguments and no previous clang-check invocation!""; endif; endfunction. nmap <silent> <F5> :call ClangCheck()<CR><CR>. When editing a .cpp/.cxx/.cc/.c file, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HowToSetupToolingForLLVM.rst:4649,install,installed,4649,interpreter/llvm-project/clang/docs/HowToSetupToolingForLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HowToSetupToolingForLLVM.rst,1,['install'],['installed']
Deployability," IDE support.; * Make sure that ``children()`` visits all of the subexpressions. This is; important for a number of features (e.g., IDE support, C++ variadic; templates). If you have sub-types, you'll also need to visit those; sub-types in ``RecursiveASTVisitor``.; * Add printing support (``StmtPrinter.cpp``) for your expression.; * Add profiling support (``StmtProfile.cpp``) for your AST node, noting the; distinguishing (non-source location) characteristics of an instance of; your expression. Omitting this step will lead to hard-to-diagnose; failures regarding matching of template declarations.; * Add serialization support (``ASTReaderStmt.cpp``, ``ASTWriterStmt.cpp``); for your AST node. #. Teach semantic analysis to build your AST node. At this point, you can wire; up your ``Sema::BuildXXX`` function to actually create your AST. A few; things to check at this point:. * If your expression can construct a new C++ class or return a new; Objective-C object, be sure to update and then call; ``Sema::MaybeBindToTemporary`` for your just-created AST node to be sure; that the object gets properly destructed. An easy way to test this is to; return a C++ class with a private destructor: semantic analysis should; flag an error here with the attempt to call the destructor.; * Inspect the generated AST by printing it using ``clang -cc1 -ast-print``,; to make sure you're capturing all of the important information about how; the AST was written.; * Inspect the generated AST under ``clang -cc1 -ast-dump`` to verify that; all of the types in the generated AST line up the way you want them.; Remember that clients of the AST should never have to ""think"" to; understand what's going on. For example, all implicit conversions should; show up explicitly in the AST.; * Write tests that use your expression as a subexpression of other,; well-known expressions. Can you call a function using your expression as; an argument? Can you use the ternary operator?. #. Teach code generation to create ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:149595,update,update,149595,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['update'],['update']
Deployability," If **you are a new contributor**, please start with the :doc:`GettingStarted`; page. This page is geared for existing contributors moving from the; legacy configure/make system. If you are really anxious about getting a functional LLVM build, go to the; `Quick start`_ section. If you are a CMake novice, start with `Basic CMake usage`_; and then go back to the `Quick start`_ section once you know what you are doing. The; `Options and variables`_ section is a reference for customizing your build. If; you already have experience with CMake, this is the recommended starting point. This page is geared towards users of the LLVM CMake build. If you're looking for; information about modifying the LLVM CMake build system you may want to see the; :doc:`CMakePrimer` page. It has a basic overview of the CMake language. .. _Quick start:. Quick start; ===========. We use here the command-line, non-interactive CMake interface. #. `Download <http://www.cmake.org/cmake/resources/software.html>`_ and install; CMake. Version 3.20.0 is the minimum required. #. Open a shell. Your development tools must be reachable from this shell; through the PATH environment variable. #. Create a build directory. Building LLVM in the source; directory is not supported. cd to this directory:. .. code-block:: console. $ mkdir mybuilddir; $ cd mybuilddir. #. Execute this command in the shell replacing `path/to/llvm/source/root` with; the path to the root of your LLVM source tree:. .. code-block:: console. $ cmake path/to/llvm/source/root. CMake will detect your development environment, perform a series of tests, and; generate the files required for building LLVM. CMake will use default values; for all build parameters. See the `Options and variables`_ section for; a list of build parameters that you can modify. This can fail if CMake can't detect your toolset, or if it thinks that the; environment is not sane enough. In this case, make sure that the toolset that; you intend to use is the only one reachab",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:1339,install,install,1339,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['install'],['install']
Deployability," If this happens, please consult the documentation of [fitTo()](https://root.cern/doc/v626/classRooAbsPdf.html#a5f79f16f4a26a19c9e66fb5c080f59c5) to check which of the [free functions in the `RooFit` namespace](https://root.cern/doc/v626/group__CmdArgs.html) you need to use to achieve the desired configuration. **Example** of an error that is now caught at compile time: confusing the [RooAbsPdf::fitTo()]() function signature with the one of [TH1::Fit()](https://root.cern/doc/v626/classTH1.html#a63eb028df86bc86c8e20c989eb23fb2a) and passing the fit range name as a string literal:. ```C++; pdf.fitTo(*data, ""r""); // ERROR!; // Will not compile anymore, as `""r""` is not a recognized command and will be ignored!; // Instead, to restrict to a range called ""r"", use:; pdf.fitTo(*data, RooFit::Range(""r""));; ```. ## TMVA. ### SOFIE : Code generation for fast inference of Deep Learning models. ROOT/TMVA SOFIE (“System for Optimized Fast Inference code Emit”) is a new package introduced in this release that generates C++ functions easily invokable for the fast inference of trained neural network models. It takes ONNX model files as inputs and produces C++ header files that can be included and utilized in a “plug-and-go” style.; This is a new development and it is currently still in experimental stage. From ROOT command line, or in a ROOT macro you can use this code for parsing a model in ONNX file format; and generate C++ code that can be used to evaluate the model:. ```; using namespace TMVA::Experimental;; SOFIE::RModelParser_ONNX parser;; SOFIE::RModel model = parser.Parse(“./example_model.onnx”);; model.Generate();; model.OutputGenerated(“./example_output.hxx”);; ```; And an C++ header file will be generated. In addition also a text file, `example_output.dat` will be also generated. This file will contain the model weight values that will be used to initialize the model.; A full example for parsing an ONNX input file is given by the tutorial [`TMVA_SOFIE_ONNX.C`](https://root",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:32613,release,release,32613,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['release'],['release']
Deployability," If you are interested in fixing a bug please comment on it to; let people know you are working on it. Then try to reproduce and fix the bug with upstream LLVM. Start by building; LLVM from source as described in :doc:`GettingStarted` and; use the built binaries to reproduce the failure described in the bug. Use; a debug build (`-DCMAKE_BUILD_TYPE=Debug`) or a build with assertions; (`-DLLVM_ENABLE_ASSERTIONS=On`, enabled for Debug builds). Reporting a Security Issue; --------------------------. There is a separate process to submit security-related bugs, see :ref:`report-security-issue`. Bigger Pieces of Work; ---------------------; In case you are interested in taking on a bigger piece of work, a list of; interesting projects is maintained at the `LLVM's Open Projects page`_. In case; you are interested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:1971,patch,patch,1971,interpreter/llvm-project/llvm/docs/Contributing.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst,1,['patch'],['patch']
Deployability," Improved the ``alpha.unix.Stream`` checker by modeling more functions; ``fputs``, ``fputc``, ``fgets``, ``fgetc``, ``fdopen``, ``ungetc``, ``fflush``,; ``getdelim``, ``getline`` and no not recognize alternative; ``fopen`` and ``tmpfile`` implementations.; (`#78693 <https://github.com/llvm/llvm-project/pull/78693>`_,; `#76776 <https://github.com/llvm/llvm-project/pull/76776>`_,; `#74296 <https://github.com/llvm/llvm-project/pull/74296>`_,; `#73335 <https://github.com/llvm/llvm-project/pull/73335>`_,; `#72627 <https://github.com/llvm/llvm-project/pull/72627>`_,; `#71518 <https://github.com/llvm/llvm-project/pull/71518>`_,; `#72016 <https://github.com/llvm/llvm-project/pull/72016>`_,; `#70540 <https://github.com/llvm/llvm-project/pull/70540>`_,; `#73638 <https://github.com/llvm/llvm-project/pull/73638>`_,; `#77331 <https://github.com/llvm/llvm-project/pull/77331>`_). - The ``alpha.security.taint.TaintPropagation`` checker no longer propagates; taint on ``strlen`` and ``strnlen`` calls, unless these are marked; explicitly propagators in the user-provided taint configuration file.; This removal empirically reduces the number of false positive reports.; Read the PR for the details.; (`#66086 <https://github.com/llvm/llvm-project/pull/66086>`_). - Other taint-related improvements.; (`#66358 <https://github.com/llvm/llvm-project/pull/66358>`_,; `#66074 <https://github.com/llvm/llvm-project/pull/66074>`_,; `#66358 <https://github.com/llvm/llvm-project/pull/66358>`_). - Checkers can query constraint bounds to improve diagnostic messages.; (`#74141 <https://github.com/llvm/llvm-project/pull/74141>`_). - Improved the generated initializers for modules. Now the calls to initialize; functions from imported module units can be omitted if the initialize; function is known to be empty.; (`#56794 <https://github.com/llvm/llvm-project/issues/56794>`_). - Clang now allow to export declarations within linkage-specification.; (`#71347 <https://github.com/llvm/llvm-project/issues/71347>`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:75602,configurat,configuration,75602,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['configurat'],['configuration']
Deployability," In this case he needs to provide the function object as a class deriving from the; `ROOT::Math::IParametricGradFunctionMultiDim` interface.; Note that the wrapper class `ROOT::Math::WrappedMultiTF1` implements also the gradient interface, using internally `TF1::GradientPar`,; which is based on numerical differentiation, apart for the case of linear functions (i.e. when `TF1::IsLinear()` is `true`).; The parameter derivatives of the model function can be useful to some minimization algorithms, such as Fumili.; However, in general is better to leave the minimization algorithm (e.g. Minuit) to compute the needed derivatives using its own customised; numerical differentiation algorithm.; In order to not provide to the fitter the parameter derivatives, we explicitly passed in `Fitter::SetFunction` a `false` value. ### Fit Configuration. The configuration of the fit is done via the `ROOT::Fit::FitConfig` class and its contained `ROOT::Fit::ParameterSettings` class.; These are the possible allowed fit configurations:. - setting the initial values of the parameters;; - setting the parameter step sizes;; - setting eventual parameter bounds;; - setting the minimizer library and the particular algorithm to use;; - setting different minimization options (print level, tolerance, max iterations, etc...); - setting the type of parameter errors to compute (parabolic error, Minos errors, re-normalize errors using fitted chi2 values). The initial parameter values can be set directly in the input model function object.; However, for setting parameter bounds and step sizes to values different than the automatically computed ones, one needs to use the `ROOT::Fit::ParameterSetting` class.; This example code will set the lower/upper bounds for the first parameter and a lower bound for the second parameter. ``` {.cpp}; fitter.SetFunction( fitFunction, false);; fitter.Config().ParSettings(0).SetLimits(0,1.E6);; fitter.Config().ParSettings(2).SetLowerLimit(0);; ```. Note that a `ROOT::Fit::P",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:38414,configurat,configurations,38414,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['configurat'],['configurations']
Deployability," L; comprised of one incomplete composite location description SL, then the; incomplete composite location storage LS that SL specifies is updated to; append a new part P. P specifies the location description PL and has a; bit size of S scaled by 8 (the byte size). L is left on the stack. * Otherwise, a location description L comprised of one incomplete; composite location description SL is pushed on the stack. An incomplete composite location storage LS is created with a single; part P. P specifies the location description PL and has a bit size of S; scaled by 8 (the byte size). SL specifies LS with a bit offset of 0. * Otherwise, the DWARF expression is ill-formed. *Many compilers store a single variable in sets of registers or store a; variable partially in memory and partially in registers.* ``DW_OP_piece``; *provides a way of describing where a part of a variable is located.*. *If a non-0 byte displacement is required, the* ``DW_OP_LLVM_offset``; *operation can be used to update the location description before using it as; the part location description of a* ``DW_OP_piece`` *operation.*. *The evaluation rules for the* ``DW_OP_piece`` *operation allow it to be; compatible with the DWARF Version 5 definition.*. .. note::. Since these extensions allow location descriptions to be entries on the; stack, a simpler operation to create composite location descriptions could; be defined. For example, just one operation that specifies how many parts,; and pops pairs of stack entries for the part size and location; description. Not only would this be a simpler operation and avoid the; complexities of incomplete composite location descriptions, but it may; also have a smaller encoding in practice. However, the desire for; compatibility with DWARF Version 5 is likely a stronger consideration. 2. ``DW_OP_bit_piece``. ``DW_OP_bit_piece`` has two operands. The first is an unsigned LEB128; integer that represents the part bit size S. The second is an unsigned; LEB128 integer that",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:135612,update,update,135612,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['update'],['update']
Deployability," LLVM, A 2019 LLVM Developers' Meeting Presentation: https://youtu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good reviewer.; * Split your patch into multiple smaller patches that build on each other. The; smaller your patch is, the higher the probability that somebody will take a quick; look at it. When doing this, it is helpful to add ""[N/M]"" (for 1 <= N <= M) to; the title of each patch in the series, so it is clear that there is an order; and what that order is. Developers should participate in code reviews as both reviewers and; authors. If someone is kind enough to review your code, you should return the; favor for someone else. Note that anyone is welcome to review and give feedback; on a patch, but appr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:11693,patch,patch,11693,interpreter/llvm-project/llvm/docs/CodeReview.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst,1,['patch'],['patch']
Deployability," Lowers to a call to `objc_loadWeak <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtime-objc-loadweak>`_. '``llvm.objc.loadWeakRetained``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.loadWeakRetained(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_loadWeakRetained <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtime-objc-loadweakretained>`_. '``llvm.objc.moveWeak``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare void @llvm.objc.moveWeak(ptr, ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_moveWeak <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#void-objc-moveweak-id-dest-id-src>`_. '``llvm.objc.release``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare void @llvm.objc.release(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_release <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#void-objc-release-id-value>`_. '``llvm.objc.retain``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.retain(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_retain <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtime-objc-retain>`_. '``llvm.objc.retainAutorelease``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.retainAutorelease(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_retainAutorelease <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtime-objc-retainautorelease>`_. '``llvm.objc.retainAutoreleaseReturnValue``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.retainAutoreleaseReturnValue(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_retainAutoreleaseReturnValue <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtime-objc-retainautoreleasereturnvalue>`_. '``llvm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:969753,release,release-id-value,969753,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['release'],['release-id-value']
Deployability," Manual; Status of ObjectiveC[++]. Get Involved. Latest News; Cling goes public; July 25th, 2011; Cling was officially announced to the Clang community Read more. New website launched; July 1st, 2011; Welcome to the new website of the project. Read more; Useful Links. CERN. Download & Build Instructions; This page is shows how to download and build the project cling as a standalone C++ interpreter in few steps; If you want to download and build cling within ROOT please follow the tutorial here; Build; Unix systems; Prerequisites; See Getting Started with the LLVM System - Requirements. Note also that Python is needed for running the test suite. Get it at: http://www.python.org/download; . Checkout LLVM:; svn co http://llvm.org/svn/llvm-project/llvm/trunk llvm/src. Checkout Clang:; cd llvm/src/tools/; svn co http://llvm.org/svn/llvm-project/cfe/trunk clang. Checkout Cling (next to clang):; svn co http://root.cern.ch/svn/root/branches/dev/cling cling. Allow Cling to hook into LLVM's build system:; cat tools/cling/patches/*.diff | patch -p0. Configure in your build folder (preferably out of the source code). For example:; cd ../../obj; ../src/configure --prefix=Where\to\be\installed\. Now compile and install:; make && make install. The executables could be found in your installation folder.; ; Using Visual Studio; Prerequisites; Subversion client - http://subversion.tigris.org/getting.html; cmake - http://www.cmake.org/cmake/resources/software.html; Python - http://www.python.org/download/; GnuWin32 Tools - http://getgnuwin32.sourceforge.net/; Visual Studio - VS Express should work as well. Checkout LLVM; svn co http://llvm.org/svn/llvm-project/llvm/trunk llvm/src/. Checkout Clang; cd llvm\src\tools\; svn co http://llvm.org/svn/llvm-project/cfe/trunk clang. Checkout Cling (next to Clang); ; svn co http://root.cern.ch/svn/root/branches/dev/cling cling. Allow Cling to hook into LLVM's build system: apply the two patches located in the cling\patches folder.; . Open up cma",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/old/download.html:1211,patch,patches,1211,interpreter/cling/www/old/download.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/old/download.html,1,['patch'],['patches']
Deployability," Minuit2. The Minuit2 library is a new object-oriented implementation, written in C++, of the popular MINUIT minimization package.; These new version provides basically all the functionality present in the old Fortran version,; with almost equivalent numerical accuracy and computational performances.; Furthermore, it contains new functionality, like the possibility to set single side parameter limits or; the FUMILI algorithm, which is an optimized method for least square and log likelihood minimizations.; The package has been originally developed by M. Winkler and F. James.; More information on the new C++ version can be found on the; MINUIT Web Site. Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention (function names starting with capital letters) and the classes have been moved inside the namespace ROOT::Minuit2.; In addition, the %ROOT distribution contains classes needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements the interface; ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2. An example of using this interface is; the %ROOT tutorial tutorials/fit/NumericalMinimization.C or; the Minuit2 test program testMinimize.cxx. A standalone version of Minuit2 (independent of %ROOT) can be downloaded from here. It does not contain the %ROOT interface and it is therefore totally independent of external packages and can be simply build using the configure script and then make. Example tests are provided in the directory test/MnSim and test/MnTutorial and they can be built with the make check command. The Minuit2 User Guide provides all the information needed for using directly (without add-on packages like %ROOT) Minuit2. References. F. James, Fortran MINUIT Refer",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.html:1071,integrat,integrate,1071,math/minuit2/doc/Minuit2.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.html,1,['integrat'],['integrate']
Deployability," Mutex m1 ACQUIRED_BEFORE(m2);. void foo() {; m2.Lock();; m1.Lock(); // Warning! m2 must be acquired after m1.; m1.Unlock();; m2.Unlock();; }. CAPABILITY(<string>); --------------------. *Previously*: ``LOCKABLE``. ``CAPABILITY`` is an attribute on classes, which specifies that objects of the; class can be used as a capability. The string argument specifies the kind of; capability in error messages, e.g. ``""mutex""``. See the ``Container`` example; given above, or the ``Mutex`` class in :ref:`mutexheader`. SCOPED_CAPABILITY; -----------------. *Previously*: ``SCOPED_LOCKABLE``. ``SCOPED_CAPABILITY`` is an attribute on classes that implement RAII-style; locking, in which a capability is acquired in the constructor, and released in; the destructor. Such classes require special handling because the constructor; and destructor refer to the capability via different names; see the; ``MutexLocker`` class in :ref:`mutexheader`, below. Scoped capabilities are treated as capabilities that are implicitly acquired; on construction and released on destruction. They are associated with; the set of (regular) capabilities named in thread safety attributes on the; constructor or function returning them by value (using C++17 guaranteed copy; elision). Acquire-type attributes on other member functions are treated as; applying to that set of associated capabilities, while ``RELEASE`` implies that; a function releases all associated capabilities in whatever mode they're held. TRY_ACQUIRE(<bool>, ...), TRY_ACQUIRE_SHARED(<bool>, ...); ---------------------------------------------------------. *Previously:* ``EXCLUSIVE_TRYLOCK_FUNCTION``, ``SHARED_TRYLOCK_FUNCTION``. These are attributes on a function or method that tries to acquire the given; capability, and returns a boolean value indicating success or failure.; The first argument must be ``true`` or ``false``, to specify which return value; indicates success, and the remaining arguments are interpreted in the same way; as ``ACQUIRE``. Se",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:13663,release,released,13663,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['release'],['released']
Deployability," N2401; Unknown. ; N2359; No. ; N2546; Unknown. N2580; Unknown. ; N2640; Unknown. ; N2755; Unknown. Preprocessor line numbers unspecified; N2322. Partial; The line number associated with a macro invocation is not the line; number of the first character of the macro name in the invocation.; Additionally, Clang may not associate the line number of a pp-directive; with the first # token. As these are recommended practices; and not normative requirements, Clang's behavior is still conforming.; . deprecated attribute; N2334; Clang 9. Attributes. ; N2335; Clang 9. ; N2554; Clang 9. Defining new types in offsetof; N2350; Yes. fallthrough attribute; N2408; Clang 9. Two's complement sign representation; N2412; Clang 14. Adding the u8 character prefix; N2418; Clang 15. Remove support for function definitions with identifier lists; N2432; Clang 15. *_IS_IEC_60559 feature test macros; N2379; Unknown. Floating-point negation and conversion; N2416; Unknown. Annex F.8 update for implementation extensions and rounding; N2384; Unknown. _Bool definitions for true and false; N2393; Subsumed by N2935. [[nodiscard(""should have a reason"")]]; N2448; Clang 10. Allowing unnamed parameters in function definitions; N2480; Clang 11. Free positioning of labels inside compound statements; N2508; Clang 18. Clarification request for C17 example of undefined behavior; N2517; No. Querying attribute support; N2553; Clang 9. Binary literals; N2549; Clang 9. Allow duplicate attributes; N2557; Clang 13. Character encoding of diagnostic text; N2563; Yes. What we think we reserve; N2572; Partial. Remove mixed wide string literal concatenation; N2594; Clang 9. Update to IEC 60559:2020; N2600; Unknown. Compatibility of Pointers to Arrays with Qualifiers; N2607. Partial; Much of the proposal is implemented, but Clang lacks pedantic diagnostics; in C17 and earlier regarding use of incompatible pointer types as an; extension. Further, Clang does not properly compute the correct result; type for the ?: operator",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_status.html:8441,update,update,8441,interpreter/llvm-project/clang/www/c_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_status.html,1,['update'],['update']
Deployability," Naumann,A. and Moneta,L. and Russo,P.},; title = {{Cling} -- The New Interactive Interpreter for {ROOT} 6}},; journal = {Journal of Physics: Conference Series},; year = 2012,; month = {dec},; volume = {396},; number = {5},; pages = {052071},; doi = {10.1088/1742-6596/396/5/052071},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/396/5/052071/pdf},; publisher = {{IOP} Publishing}; }; ```. Developers' Corner; ==================; [Cling's latest doxygen documentation](http://cling.web.cern.ch/cling/doxygen/). Contributions; -------------; Every contribution is considered a donation and its copyright and any other; related rights become exclusive ownership of the person who merged the code or; in any other case the main developers of the ""Cling Project"". We warmly welcome external contributions to the Cling! By providing code,; you agree to transfer your copyright on the code to the ""Cling project"".; Of course you will be duly credited and your name will appear on the; contributors page, the release notes, and in the [CREDITS file](CREDITS.txt); shipped with every binary and source distribution. The copyright transfer is; necessary for us to be able to effectively defend the project in case of; litigation. License; -------; Please see our [LICENSE](LICENSE.TXT). Releases; --------; Our release steps to follow when cutting a new release:; 1. Update [release notes](docs/ReleaseNotes.md); 2. Remove `~dev` suffix from [VERSION](VERSION); 3. Add a new entry in the news section of our [website](www/news.html); 4. Commit the changes.; 5. `git tag -a v0.x -m ""Tagging release v0.x""`; 6. Tag `cling-patches` of `clang.git`:; `git tag -a cling-v0.x -m ""Tagging clang for cling v0.x""`; 7. Create a draft release in github and copy the contents of the release notes.; 8. Wait for green builds.; 9. Upload binaries to github (Travis should do this automatically).; 10. Publish the tag and announce it on the mailing list.; 11. Increment the current version and append `~dev`.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md:4039,release,release,4039,interpreter/cling/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md,7,"['patch', 'release']","['patches', 'release']"
Deployability," Neg, Exp, Sqrt, Reciprocal; - Add, Sum, Mul, Div; - Reshape, Flatten, Transpose; - Squeeze, Unsqueeze, Slice; - Concat, Reduce; - Identity; - Shape; - Custom; - Error; - Log. #### SOFIE Keras Parser; - The Swish Activation function is now supported in the SOFIE Keras parser. ## 2D Graphics Libraries. - Introduce `TAxis::ChangeLabelByValue` to set custom label defined by axis value. It works also; when axis zooming changes and position and index of correspondent axis label changes as well.; `TAxis::ChangeLabel` method to change axis label by index works as before. - Introduce `TCanvas::SaveAll` method. Allows to store several pads at once into different image file formats.; File name can include printf qualifier to code pad number. Also allows to store all pads in single PDF; or single ROOT file. Significantly improves performance when creating many image files using web graphics. - Introduce `TCanvas::UpdateAsync` method. In case of web-based canvas triggers update of the canvas on the client side,; but does not wait that real update is completed. Avoids blocking of caller thread.; Have to be used if called from other web-based widget to avoid logical dead-locks.; In case of normal canvas just canvas->Update() is performed. - The Delaunay triangles (used by TGraph2D) were computed by the external package `triangle.c`; included in the ROOT distribution. This package had several issues:; - It was not maintained anymore.; - Its license was not compatible with LGPL; This code is now replaced by the [CDT package](https://github.com/artem-ogre/CDT) which is; properly maintained and has a license (MLP) compatible with LGPL. It will appear in 6.03.02. ## Machine Learning integration. - ROOT now offers functionality to extract batches of events out of a dataset for use in common ML training workflows. For example, one can generate PyTorch tensors from a TTree. The functionality is available through the `RBatchGenerator` class and can be seamlessly integrated in user code, f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md:19953,update,update,19953,README/ReleaseNotes/v630/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md,2,['update'],['update']
Deployability," Nonetheless, it is sometimes useful to be able to force an object to be; released at a precise time, even if that object does not appear to be used.; This is likely to be uncommon enough that the syntactic weight of explicitly; requesting these semantics will not be burdensome, and may even make the code; clearer. .. _arc.misc:. Miscellaneous; =============. .. _arc.misc.special_methods:. Special methods; ---------------. .. _arc.misc.special_methods.retain:. Memory management methods; ^^^^^^^^^^^^^^^^^^^^^^^^^. A program is ill-formed if it contains a method definition, message send, or; ``@selector`` expression for any of the following selectors:. * ``autorelease``; * ``release``; * ``retain``; * ``retainCount``. .. admonition:: Rationale. ``retainCount`` is banned because ARC robs it of consistent semantics. The; others were banned after weighing three options for how to deal with message; sends:. **Honoring** them would work out very poorly if a programmer naively or; accidentally tried to incorporate code written for manual retain/release code; into an ARC program. At best, such code would do twice as much work as; necessary; quite frequently, however, ARC and the explicit code would both; try to balance the same retain, leading to crashes. The cost is losing the; ability to perform ""unrooted"" retains, i.e. retains not logically; corresponding to a strong reference in the object graph. **Ignoring** them would badly violate user expectations about their code.; While it *would* make it easier to develop code simultaneously for ARC and; non-ARC, there is very little reason to do so except for certain library; developers. ARC and non-ARC translation units share an execution model and; can seamlessly interoperate. Within a translation unit, a developer who; faithfully maintains their code in non-ARC mode is suffering all the; restrictions of ARC for zero benefit, while a developer who isn't testing the; non-ARC mode is likely to be unpleasantly surprised if they try",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:85649,release,release,85649,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['release']
Deployability," OR NOT CMAKE_Fortran_COMPILER); list(APPEND MAN_PATT_EXCL PATTERN h2root.1 EXCLUDE); list(APPEND MAN_PATT_EXCL PATTERN g2root.1 EXCLUDE); endif(); install(DIRECTORY man/ DESTINATION ${CMAKE_INSTALL_MANDIR} ${DIR_PERMISSIONS} ${MAN_PATT_EXCL}); install(DIRECTORY tutorials/ DESTINATION ${CMAKE_INSTALL_TUTDIR} ${DIR_PERMISSIONS} COMPONENT tests); install(FILES; cmake/modules/RootMacros.cmake; cmake/modules/RootTestDriver.cmake; DESTINATION ${CMAKE_INSTALL_CMAKEDIR}); install(FILES; ""cmake/modules/FindVdt.cmake""; DESTINATION ""${CMAKE_INSTALL_CMAKEDIR}/modules""); endif(). #---Add configuration files for kernel and jupyter----------------------------------------------; # Make sure the Jupyter ROOT C++ kernel runs with the same Python version as ROOT; set(root_jupyter_dir notebook); set(root_jupyter_config jupyter_notebook_config.py); configure_file(etc/${root_jupyter_dir}/${root_jupyter_config}.in etc/${root_jupyter_dir}/${root_jupyter_config}); install(FILES ${CMAKE_BINARY_DIR}/etc/${root_jupyter_dir}/${root_jupyter_config} DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}/${root_jupyter_dir}). set(root_kernel_dir ${root_jupyter_dir}/kernels/root); set(root_kernel_file kernel.json); configure_file(etc/${root_kernel_dir}/${root_kernel_file}.in etc/${root_kernel_dir}/${root_kernel_file}); install(FILES ${CMAKE_BINARY_DIR}/etc/${root_kernel_dir}/${root_kernel_file} DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}/${root_kernel_dir}). #---install clad header files-------------------------------------------------------------------; if(clad); install(DIRECTORY ${CMAKE_BINARY_DIR}/etc/cling/plugins/; DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}/cling/plugins); endif(). #---Set flag for PyROOT tests that are expected to fail; if(pyroot); set(PYTESTS_WILLFAIL WILLFAIL); endif(). #---Configure Testing using CTest----------------------------------------------------------------; configure_file(${CMAKE_SOURCE_DIR}/cmake/modules/CTestCustom.cmake ${CMAKE_BINARY_DIR} COPYONLY); if(testing); include(RootCTest",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt:26970,install,install,26970,CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt,1,['install'],['install']
Deployability," OSObject subclasses.; The attribute indicates that the caller should not change the retain; count of the returned object. Example. class MyClass {; OSObject *f;; LIBKERN_RETURNS_NOT_RETAINED OSObject *myFieldGetter();; }. // Note that the annotation only has to be applied to the function declaration.; OSObject * MyClass::myFieldGetter() {; return f;; }. Attribute 'os_consumed'; Similarly to ns_consumed attribute,; os_consumed (accessed through LIBKERN_CONSUMED) attribute,; applied to a parameter,; indicates that the call to the function consumes the parameter:; the callee should either release it or store it and release it in the destructor,; while the caller should assume one is subtracted from the reference count; after the call. IOReturn addToList(LIBKERN_CONSUMED IOPMinformee *newInformee);. Attribute 'os_consumes_this'; Similarly to ns_consumes_self,; the os_consumes_self attribute indicates that the method call; consumes the implicit this argument: the caller; should assume one was subtracted from the reference count of the object; after the call, and the callee has on obligation to either; release the argument, or store it and eventually release it in the; destructor. void addThisToList(OSArray *givenList) LIBKERN_CONSUMES_THIS;. Out Parameters. A function can also return an object to a caller by a means of an out parameter; (a pointer-to-OSObject-pointer is passed, and a callee writes a pointer to an; object into an argument).; Currently the analyzer does not track unannotated out; parameters by default, but with annotations we distinguish four separate cases:. 1. Non-retained out parameters, identified using; LIBKERN_RETURNS_NOT_RETAINED applied to parameters, e.g.:. void getterViaOutParam(LIBKERN_RETURNS_NOT_RETAINED OSObject **obj). Such functions write a non-retained object into an out parameter, and the; caller has no further obligations.; 2. Retained out parameters,; identified using LIBKERN_RETURNS_RETAINED:. void getterViaOutParam(LIBKERN_RETURNS_NOT",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html:17096,release,release,17096,interpreter/llvm-project/clang/www/analyzer/annotations.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html,2,['release'],['release']
Deployability," Objective-C pointer types, block pointer types, and; :when-revised:`[beginning Apple 8.0, LLVM 3.8]` :revision:`BPTRs declared; within` ``extern ""BCPL""`` blocks. For now, it is sensible to version this document by the releases of its sole; implementation (and its host project), clang. ""LLVM X.Y"" refers to an; open-source release of clang from the LLVM project. ""Apple X.Y"" refers to an; Apple-provided release of the Apple LLVM Compiler. Other organizations that; prepare their own, separately-versioned clang releases and wish to maintain; similar information in this document should send requests to cfe-dev. If a change decreases the expressiveness of the language, for example by; imposing a new restriction, this should be taken as an oversight in the; original specification and something to be avoided in all versions. Such; changes are generally to be avoided. .. _arc.general:. General; =======. Automatic Reference Counting implements automatic memory management for; Objective-C objects and blocks, freeing the programmer from the need to; explicitly insert retains and releases. It does not provide a cycle collector;; users must explicitly manage the lifetime of their objects, breaking cycles; manually or with weak or unsafe references. ARC may be explicitly enabled with the compiler flag ``-fobjc-arc``. It may; also be explicitly disabled with the compiler flag ``-fno-objc-arc``. The last; of these two flags appearing on the compile line ""wins"". If ARC is enabled, ``__has_feature(objc_arc)`` will expand to 1 in the; preprocessor. For more information about ``__has_feature``, see the; :ref:`language extensions <langext-__has_feature-__has_extension>` document. .. _arc.objects:. Retainable object pointers; ==========================. This section describes retainable object pointers, their basic operations, and; the restrictions imposed on their use under ARC. Note in particular that it; covers the rules for pointer *values* (patterns of bits indicating the location; o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:8930,release,releases,8930,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['releases']
Deployability," Process Summary; -----------------------. * Announce release schedule to the LLVM community and update the website. Do; this at least 3 weeks before the -rc1 release. * Create release branch and begin release process. * Send out release candidate sources for first round of testing. Testing lasts; 6 weeks. During the first round of testing, any regressions found should be; fixed. Patches are merged from mainline into the release branch. Also, all; features need to be completed during this time. Any features not completed at; the end of the first round of testing will be removed or disabled for the; release. * Generate and send out the second release candidate sources. Only *critical*; bugs found during this testing phase will be fixed. Any bugs introduced by; merged patches will be fixed. If so a third round of testing is needed. * The release notes are updated. * Finally, release!. * Announce bug fix release schedule to the LLVM community and update the website. * Do bug-fix releases every two weeks until X.1.5 or X.1.6 (if necessary). Release Process; ===============. .. contents::; :local:. Release Administrative Tasks; ----------------------------. This section describes a few administrative tasks that need to be done for the; release process to begin. Specifically, it involves:. * Updating version numbers,. * Creating the release branch, and. * Tagging release candidates for the release team to begin testing. Create Release Branch; ^^^^^^^^^^^^^^^^^^^^^. Branch the Git trunk using the following procedure:. #. Remind developers that the release branching is imminent and to refrain from; committing patches that might break the build. E.g., new features, large; patches for works in progress, an overhaul of the type system, an exciting; new TableGen feature, etc. #. Verify that the current git trunk is in decent shape by; examining nightly tester and buildbot results. #. Bump the version in trunk to N.0.0git and tag the commit with llvmorg-N-init.; If ``X`` is the v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:3019,release,releases,3019,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['release'],['releases']
Deployability," PyPy with pyproject.toml; * ``std::string`` not converterd to ``str`` on function returns; * Cover more use cases where C string memory can be managed; * Automatic memory management of converted python functions; * Added pyinstaller hooks (https://stackoverflow.com/questions/64406727); * Support for enums in pseudo-constructors of aggregates; * Fixes for overloaded/split-access protected members in cross-inheritance; * Support for deep, mixed, hierarchies for multi-cross-inheritance; * Added tp_iter method to low level views. 2020-11-06: 1.8.6; -----------------. * Fix preprocessor macro of CPyCppyy header for Windows/MSVC. 2020-10-31: 1.8.5; -----------------. * Fix leaks when using vector iterators on Py3/Linux. 2020-10-10: 1.8.4; -----------------. * ``std::string`` globals/data members no longer automatically converted to ``str``; * New methods for std::string to allow ``str`` interchangability; * Added a ``decode`` method to ``std::string``; * Add pythonized ``__contains__`` to ``std::set``; * Fix constructor generation for aggregates with static data; * Fix performance bug when using implicit conversions; * Fix memory overwrite when parsing during sorting of methods; * PyPy pip install again falls back to setup.py install. 2020-09-21: 1.8.3; -----------------. * Add initializer constructors for PODs and aggregates; * Use actual underlying type for enums, where possible; * Enum values remain instances of their type; * Expose enum underlying type name as ``__underlying`` and ``__ctype__``; * Strictly follow C++ enum scoping rules; * Same enum in transparent scope refers to same type; * More detailed enum ``repr()`` printing, where possible; * Fix for (extern) explicit template instantiations in namespaces; * Throw objects from an std::tuple a life line; * Global pythonizors now always run on all classes; * Simplified iteraton over STL-like containers defining ``begin()``/``end()``. 2020-09-08: 1.8.2; -----------------. * Add ``cppyy.set_debug()`` to enable debu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:10127,install,install,10127,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,1,['install'],['install']
Deployability," Replace low resolution images with bigger ones more suited for modern screens. ## Build System and Configuration. - ROOT can now be built against an externally built llvm and clang (llvm can be used unpatched, clang still require ROOT specific patches). The options are builtin_llvm and builtin_clang both defaulting to ON.; - Update RConfigure.h with R__HAS__VDT if the package is found/builtin; - CMake exported targets now have the `INTERFACE_INCLUDE_DIRECTORIES` property set ([ROOT-8062](https://sft.its.cern.ch/jira/browse/ROOT-8062)).; - The `-fPIC` compile flag is no longer propagated to dependent projects via `CMAKE_CXX_FLAGS` ([ROOT-9212](https://sft.its.cern.ch/jira/browse/ROOT-9212)).; - Several builtins have updated versions:; - OpenSSL was updated from 1.0.2d to 1.0.2.o (latest lts release, [ROOT-9359](https://sft.its.cern.ch/jira/browse/ROOT-9359)); - Davix was updated from 0.6.4 to 0.6.7 (support for OpenSSL 1.1, [ROOT-9353](https://sft.its.cern.ch/jira/browse/ROOT-9353)); - Vdt has been updated from 0.3.9 to 0.4.1 (includes new atan function); - XRootd has been updated from 4.6.1 to 4.8.2 (for GCC 8.x support); - Builtin TBB can now be used on Windows; - xxHash and LZ4 have been separated so that a system version of LZ4 can be used even if it does not include xxHash headers ([ROOT-9099](https://sft.its.cern.ch/jira/browse/ROOT-9099)); - In addition, several updates have been made to fix minor build system issues, such as not checking for external packages if their builtin is turned off, or checking for packages even when the respective option is disabled ([ROOT-8806](https://sft.its.cern.ch/jira/browse/ROOT-8806), [ROOT-9190](https://sft.its.cern.ch/jira/browse/ROOT-9190), [ROOT-9315](https://sft.its.cern.ch/jira/browse/ROOT-9315), [ROOT-9385](https://sft.its.cern.ch/jira/browse/ROOT-9385)).; - The `python3` option to CMake has been removed ([ROOT-9033](https://sft.its.cern.ch/jira/browse/ROOT-9033), [ROOT-9143](https://sft.its.cern.ch/jira/browse/ROOT-9",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:18555,update,updated,18555,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,1,['update'],['updated']
Deployability," Should there be other entries here?; ); list(REMOVE_DUPLICATES LLVM_CONFIG_LIBRARY_DIRS). set(LLVM_CONFIG_BINARY_DIR ""${LLVM_BINARY_DIR}""); set(LLVM_CONFIG_CMAKE_DIR ""${CMAKE_CURRENT_SOURCE_DIR}""); set(LLVM_CONFIG_TOOLS_BINARY_DIR ""${LLVM_TOOLS_BINARY_DIR}""). # Generate a default location for lit; if (LLVM_BUILD_UTILS); if (CMAKE_HOST_WIN32 AND NOT CYGWIN); set(LLVM_CONFIG_DEFAULT_EXTERNAL_LIT ""${LLVM_CONFIG_TOOLS_BINARY_DIR}/llvm-lit.py""); else(); set(LLVM_CONFIG_DEFAULT_EXTERNAL_LIT ""${LLVM_CONFIG_TOOLS_BINARY_DIR}/llvm-lit""); endif(); endif(). if (LLVM_LINK_LLVM_DYLIB); set(LLVM_CONFIG_LINK_LLVM_DYLIB; ""set(LLVM_LINK_LLVM_DYLIB ${LLVM_LINK_LLVM_DYLIB})""); endif(). # We need to use the full path to the LLVM Exports file to make sure we get the; # one from the build tree. This is due to our cmake files being split between; # this source dir and the binary dir in the build tree configuration and the; # LLVM_CONFIG_CMAKE_DIR being the source directory. In contrast in the install; # tree, both the generated LLVMExports.cmake file and the rest of the cmake; # source files are put in the same cmake directory.; set(LLVM_CONFIG_EXPORTS ""${LLVM_EXPORTS};${LLVM_EXPORTS_BUILDTREE_ONLY}""); set(LLVM_CONFIG_INCLUDE_EXPORTS ""include(\""${LLVM_EXPORTS_FILE}\"")""); set(llvm_config_include_buildtree_only_exports; ""include(\""${LLVM_BUILDTREEONLY_EXPORTS_FILE}\"")""); configure_file(; LLVMConfig.cmake.in; ${llvm_cmake_builddir}/LLVMConfig.cmake; @ONLY); set(llvm_config_include_buildtree_only_exports). # For compatibility with projects that include(LLVMConfig); # via CMAKE_MODULE_PATH, place API modules next to it.; # Copy without source permissions because the source could be read-only,; # but we need to write into the copied folder.; # This should be removed in the future.; file(COPY .; DESTINATION ${llvm_cmake_builddir}; NO_SOURCE_PERMISSIONS; FILES_MATCHING PATTERN *.cmake; PATTERN CMakeFiles EXCLUDE; PATTERN llvm-driver-template.cpp.in; ). #; # Generate LLVMConfig.cmake for the inst",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/cmake/modules/CMakeLists.txt:3570,install,install,3570,interpreter/llvm-project/llvm/cmake/modules/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/cmake/modules/CMakeLists.txt,1,['install'],['install']
Deployability," T> requires C<T> struct Foo {... template <typename T> requires C<T> void bar(T t) {... template <typename T> void bar(T t) requires C<T> {... // Not fitting, one possible example:; template <typename LongName>; requires C<LongName>; struct Foo {... template <typename LongName>; requires C<LongName>; void bar(LongName ln) {. template <typename LongName>; void bar(LongName ln); requires C<LongName> {. .. _RequiresExpressionIndentation:. **RequiresExpressionIndentation** (``RequiresExpressionIndentationKind``) :versionbadge:`clang-format 16` :ref:`¶ <RequiresExpressionIndentation>`; The indentation used for requires expression bodies. Possible values:. * ``REI_OuterScope`` (in configuration: ``OuterScope``); Align requires expression body relative to the indentation level of the; outer scope the requires expression resides in.; This is the default. .. code-block:: c++. template <typename T>; concept C = requires(T t) {; ...; }. * ``REI_Keyword`` (in configuration: ``Keyword``); Align requires expression body relative to the ``requires`` keyword. .. code-block:: c++. template <typename T>; concept C = requires(T t) {; ...; }. .. _SeparateDefinitionBlocks:. **SeparateDefinitionBlocks** (``SeparateDefinitionStyle``) :versionbadge:`clang-format 14` :ref:`¶ <SeparateDefinitionBlocks>`; Specifies the use of empty lines to separate definition blocks, including; classes, structs, enums, and functions. .. code-block:: c++. Never v.s. Always; #include <cstring> #include <cstring>; struct Foo {; int a, b, c; struct Foo {; }; int a, b, c;; namespace Ns { };; class Bar {; public: namespace Ns {; struct Foobar { class Bar {; int a; public:; int b; struct Foobar {; }; int a;; private: int b;; int t; };; int method1() {; // ... private:; } int t;; enum List {; ITEM1, int method1() {; ITEM2 // ...; }; }; template<typename T>; int method2(T x) { enum List {; // ... ITEM1,; } ITEM2; int i, j, k; };; int method3(int par) {; // ... template<typename T>; } int method2(T x) {; }; // ...; c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:106696,configurat,configuration,106696,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," TGLRnrCtx. Add support for several color-sets (class TGLColorSet -; each defines colors for background, foreground, outline, markup and; for outlines of selected and highlighted objects. This also allows for independent changing of background color and; outline mode in the GL viewer - the e key now toggles between; dark / light background. New class TGLAnnotation - it allows display of; annotation-text on top of displayed objects. The annotation can be created from the TGLViewer editor; (""Guides"" tab). After that it can be dragged around the screen, edited; or closed. TGLAxisPainter - reimplemented to completely separate; label and tick-mark positioning code from the rendering itself. TGLSAViewer - when exporting an image properly take into; account image extension if it was typed by the user. TGLFont now uses the same font-naming scheme as the rest; of ROOT (had to specify font-file names before). Overlay-object management has been improved. Allow clipping object to be fixed by user - until now it was updated; on every redraw. See TGLViewer::SetClipAutoUpdate(). Eve. TEveElement - add context-menu functions allowing the; source-object to be printed, dumped or exported to CINT. TEveTrack - added flag for locking of current; track-points - the track will not be re-extrapolated automatically; even when the extrapolation parameters are changed. TEveTrack - removed ALICE specific ImportXyzz(); functions for loading of kinematics, hits and clusters associated with; a track. These were calling macros that were not available in ROOT. Several improvements in rendering of coordinate axes; in TEveCaloLego and TEveProjectionAxes. New class TEveJetCone for display of circular and; elliptic jet-cones clipped to the calorimeter's inner surface. Add support for extraction of composite-shape tesselations. A new; class TEveGeoPolyShape has been introduced to make this; tesselation serializable. See example; in tutorials/eve/csgdemo.C. Generalize representation of EVE-window title-ba",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v524/index.html:3710,update,updated,3710,graf3d/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v524/index.html,1,['update'],['updated']
Deployability," Tests are identified by the test suite they are contained within, and the; relative path inside that suite. Note that the relative path may not refer to; an actual file on disk; some test formats (such as *GoogleTest*) define; ""virtual tests"" which have a path that contains both the path to the actual; test file and a subpath to identify the virtual test. .. _local-configuration-files:. LOCAL CONFIGURATION FILES; ~~~~~~~~~~~~~~~~~~~~~~~~~. When :program:`lit` loads a subdirectory in a test suite, it instantiates a; local test configuration by cloning the configuration for the parent directory; --- the root of this configuration chain will always be a test suite. Once the; test configuration is cloned :program:`lit` checks for a *lit.local.cfg* file; in the subdirectory. If present, this file will be loaded and can be used to; specialize the configuration for each individual directory. This facility can; be used to define subdirectories of optional tests, or to change other; configuration parameters --- for example, to change the test format, or the; suffixes which identify test files. SUBSTITUTIONS; ~~~~~~~~~~~~~. :program:`lit` allows patterns to be substituted inside RUN commands. It also; provides the following base set of substitutions, which are defined in; TestRunner.py:. ======================= ==============; Macro Substitution; ======================= ==============; %s source path (path to the file currently being run); %S source dir (directory of the file currently being run); %p same as %S; %{pathsep} path separator; %{fs-src-root} root component of file system paths pointing to the LLVM checkout; %{fs-tmp-root} root component of file system paths pointing to the test's temporary directory; %{fs-sep} file system path separator; %t temporary file name unique to the test; %basename_t The last path component of %t but without the ``.tmp`` extension; %T parent directory of %t (not unique, deprecated, do not use); %% %; %/s %s but ``\`` is replaced by ``/``;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:18820,configurat,configuration,18820,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['configurat'],['configuration']
Deployability," The default configuration files are searched for in the same directories; following the rules described in the next paragraphs. Loading default; configuration files can be disabled entirely via passing; the ``--no-default-config`` flag. First, the algorithm searches for a configuration file named; ``<triple>-<driver>.cfg`` where `triple` is the triple for the target being; built for, and `driver` is the name of the currently used driver. The algorithm; first attempts to use the canonical name for the driver used, then falls back; to the one found in the executable name. The following canonical driver names are used:. - ``clang`` for the ``gcc`` driver (used to compile C programs); - ``clang++`` for the ``gxx`` driver (used to compile C++ programs); - ``clang-cpp`` for the ``cpp`` driver (pure preprocessor); - ``clang-cl`` for the ``cl`` driver; - ``flang`` for the ``flang`` driver; - ``clang-dxc`` for the ``dxc`` driver. For example, when calling ``x86_64-pc-linux-gnu-clang-g++``,; the driver will first attempt to use the configuration file named::. x86_64-pc-linux-gnu-clang++.cfg. If this file is not found, it will attempt to use the name found; in the executable instead::. x86_64-pc-linux-gnu-clang-g++.cfg. Note that options such as ``--driver-mode=``, ``--target=``, ``-m32`` affect; the search algorithm. For example, the aforementioned executable called with; ``-m32`` argument will instead search for::. i386-pc-linux-gnu-clang++.cfg. If none of the aforementioned files are found, the driver will instead search; for separate driver and target configuration files and attempt to load both.; The former is named ``<driver>.cfg`` while the latter is named; ``<triple>.cfg``. Similarly to the previous variants, the canonical driver name; will be preferred, and the compiler will fall back to the actual name. For example, ``x86_64-pc-linux-gnu-clang-g++`` will attempt to load two; configuration files named respectively::. clang++.cfg; x86_64-pc-linux-gnu.cfg. with fallback",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:32981,configurat,configuration,32981,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['configurat'],['configuration']
Deployability," The following git-config settings set the default of the corresponding option:; clangFormat.binary; clangFormat.commit; clangFormat.extensions; clangFormat.style. positional arguments:; <commit> revision from which to compute the diff; <file>... if specified, only consider differences in these files. optional arguments:; -h, --help show this help message and exit; --binary BINARY path to clang-format; --commit COMMIT default commit to use if none is specified; --diff print a diff instead of applying the changes; --diffstat print a diffstat instead of applying the changes; --extensions EXTENSIONS; comma-separated list of file extensions to format, excluding the period and case-insensitive; -f, --force allow changes to unstaged files; -p, --patch select hunks interactively; -q, --quiet print less information; --staged, --cached format lines in the stage instead of the working dir; --style STYLE passed to clang-format; -v, --verbose print extra information. Script for patch reformatting; =============================. The python script `clang/tools/clang-format/clang-format-diff.py` parses the; output of a unified diff and reformats all contained lines with; :program:`clang-format`. .. code-block:: console. usage: clang-format-diff.py [-h] [-i] [-p NUM] [-regex PATTERN] [-iregex PATTERN] [-sort-includes] [-v] [-style STYLE]; [-fallback-style FALLBACK_STYLE] [-binary BINARY]. This script reads input from a unified diff and reformats all the changed; lines. This is useful to reformat all the lines touched by a specific patch.; Example usage for git/svn users:. git diff -U0 --no-color --relative HEAD^ | clang-format-diff.py -p1 -i; svn diff --diff-cmd=diff -x-U0 | clang-format-diff.py -i. It should be noted that the filename contained in the diff is used unmodified; to determine the source file to update. Users calling this script directly; should be careful to ensure that the path in the diff is correct relative to the; current working directory. optional arguments:; -h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst:12073,patch,patch,12073,interpreter/llvm-project/clang/docs/ClangFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst,1,['patch'],['patch']
Deployability," There are also several; interesting techniques to try and mitigate these challenges and make hardening; the results of loads viable in at least some cases. However, we generally; expect to fall back when unprofitable from hardening the loaded value to the; next approach of hardening the address itself. ###### Loads folded into data-invariant operations can be hardened after the operation. The first key to making this feasible is to recognize that many operations on; x86 are ""data-invariant"". That is, they have no (known) observable behavior; differences due to the particular input data. These instructions are often used; when implementing cryptographic primitives dealing with private key data; because they are not believed to provide any side-channels. Similarly, we can; defer hardening until after them as they will not in-and-of-themselves; introduce a speculative execution side-channel. This results in code sequences; that look like:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; orl %eax, %edi; ```. While an addition happens to the loaded (potentially secret) value, that; doesn't leak any data and we then immediately harden it. ###### Hardening of loaded values deferred down the data-invariant expression graph. We can generalize the previous idea and sink the hardening down the expression; graph across as many data-invariant operations as desirable. This can use very; conservative rules for whether something is data-invariant. The primary goal; should be to handle multiple loads with a single hardening instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and ne",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:25777,update,update,25777,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['update'],['update']
Deployability," They; also have default options set to dead strip shared libs that don't resolve; any symbols (equivalent to the MacOS X build changes described above). Core Libraries; TClonesArray. Introduce TClonesArray::ConstructedAt which; always returns an already constructed object. If the slot is being used for the; first time, it calls the default constructor otherwise it returns the object as; is (unless a string is passed as the 2nd argument to the function in which case,; it also calls Clear(second_argument) on the object).; This allows to replace code like:. for (int i = 0; i < ev->Ntracks; i++) {; new(a[i]) TTrack(x,y,z,...);; ...; ...; }; ...; a.Delete(); // or a.Clear(""C""). with the simpler and more efficient:. for (int i = 0; i < ev->Ntracks; i++) {; TTrack *track = (TTrack*)a.ConstructedAt(i);; track->Set(x,y,z,....);; ...; ...; }; ...; a.Clear();. even in case where the TTrack class allocates memory. TClonesArray: update ExpandCreateFast to also reset the non-used slots; so that calling Clear (which does too much) is no longer necessary; when using ExpandCreateFast. New Thread Pool class. A first version of TThreadPool class has been introduced.; This class implements a Thread Pool pattern.; So far it supports only one type of queue - FIFO. Thread library. Reduces risk of internal dead lock by using a private internal lock to protect the internals of TThread, rather than using TThread::Lock. New header TThreadSlots.h to centralize and formalize the use of the TThread local memory slots amongst the ROOT packages. Global Variables. The global values gPad, gVirtualX, gInterpreter, gDirectory and gFile; are now all accessed via a static function of their respective class. The; access is made transparent via a CPP macro.; The access is now also made transparent from the CINT and python prompt.; gPad, gVirtualX and gInterpreter are now accessible even when their value; is zero and they now properly support tab completion.; See the important note in the I/O section on gD",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v532/index.html:2278,update,update,2278,core/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v532/index.html,1,['update'],['update']
Deployability," This approach can be made to scale to arbitrarily deep hierarchies. The; trick is that you arrange the enum values so that they correspond to a; preorder traversal of the class hierarchy tree. With that arrangement, all; subclass tests can be done with two comparisons as shown above. If you just; list the class hierarchy like a list of bullet points, you'll get the; ordering right::. | Shape; | Square; | SpecialSquare; | OtherSpecialSquare; | Circle. A Bug to be Aware Of; --------------------. The example just given opens the door to bugs where the ``classof``\s are; not updated to match the ``Kind`` enum when adding (or removing) classes to; (from) the hierarchy. Continuing the example above, suppose we add a ``SomewhatSpecialSquare`` as; a subclass of ``Square``, and update the ``ShapeKind`` enum like so:. .. code-block:: c++. enum ShapeKind {; SK_Square,; SK_SpecialSquare,; SK_OtherSpecialSquare,; + SK_SomewhatSpecialSquare,; SK_Circle; }. Now, suppose that we forget to update ``Square::classof()``, so it still; looks like:. .. code-block:: c++. static bool classof(const Shape *S) {; // BUG: Returns false when S->getKind() == SK_SomewhatSpecialSquare,; // even though SomewhatSpecialSquare ""is a"" Square.; return S->getKind() >= SK_Square &&; S->getKind() <= SK_OtherSpecialSquare;; }. As the comment indicates, this code contains a bug. A straightforward and; non-clever way to avoid this is to introduce an explicit ``SK_LastSquare``; entry in the enum when adding the first subclass(es). For example, we could; rewrite the example at the beginning of `Concrete Bases and Deeper; Hierarchies`_ as:. .. code-block:: c++. enum ShapeKind {; SK_Square,; + SK_SpecialSquare,; + SK_OtherSpecialSquare,; + SK_LastSquare,; SK_Circle; }; ...; // Square::classof(); - static bool classof(const Shape *S) {; - return S->getKind() == SK_Square;; - }; + static bool classof(const Shape *S) {; + return S->getKind() >= SK_Square &&; + S->getKind() <= SK_LastSquare;; + }. Then, adding new su",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst:9448,update,update,9448,interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst,1,['update'],['update']
Deployability," This is unexpected, because one would expect that if two numbers are considered exactly equal, they would also be considered equal within any range.; Therefore, the behavior of `TMath::AreEqualAbs()` was changed to return always `true` if the `==` comparison would return `true`. ## RooFit Libraries. ### Changes in RooFormulaVar and RooGenericPdf. The TFormula-based RooFit classes `RooFormulaVar` and `RooGenericPdf` change a bit their behavior to be more consistent:. 1. No matter which variables you pass to the constructor, only the variables that the formula depends on are registered as value servers.; 2. Similarly, the `dependents()` method of RooFormulaVar and RooGenericPdf will only return the list of actual value servers. ### Removal of the RooGenFunction and RooMultiGenFunction classes. The `RooGenFunction` was only a lightweight adaptor that exports a RooAbsReal as a `ROOT::Math::IGenFunction`.; The same can be easily achieved with the generic `ROOT::Math::Functor1D`, so in the spirit of not duplicating interfaces, the `RooGenFunction` is removed in this release. Here is an example that shows how to replace it in the unlikely case you were using it:. ```C++; RooArgSet normSet{x}; // normalization set. // Old way 1: create a RooGenFunction:; RooGenFunction func1{pdf, x, {}, normSet};. // Old way 2: use `RooAbsReal::iGenFunction()`:; std::unique_ptr<ROOT::Math::IGenFunction> func2{; pdf.iGenFunction(x, normSet); };. // How to do it now:; RooFunctor functor{pdf, x, {}, normSet};; ROOT::Math::Functor1D func3{functor};; // Functor1D takes by reference, so the RooFunctor also needs to stay alive.; ```. For the same reason, the `RooMultiGenFunction` class that implements a multidimensional `ROOT::Math::IMultiGenFunction` is removed too.; It can easily be replaced by a `ROOT::Math::Functor`:. ```C++; RooFunctor functor{pdf, observables, {}, normSet};; ROOT::Math::Functor func4{functor, static_cast<unsigned int>(functor.nObs())};; // Functor takes by reference, so the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md:11934,release,release,11934,README/ReleaseNotes/v630/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md,1,['release'],['release']
Deployability," This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric integrals; For p.d.f.s with numeric integrals that remain difficult or very time consuming,; a new persistent caching technique is now available that allows to precalculate; these integrals and store their values for future use. This technique works transparently; for any p.d.f. stored in a RooWorkspace. One can store numeric integral values for problems with zero, one or two floating parameters.; In the first case, the value is simply stored. In cases with one or two floating parameters; a grid (histogram) of integral values is stored, which are interpolated to return inte",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5966,integrat,integration,5966,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,1,['integrat'],['integration']
Deployability," This section; includes best practices and some recommendations as to how to achieve; that end. The goal; In 2020, the monorepo had just under 35 thousand commits. This works; out to an average of 4 commits per hour. Already, we can see that a; builder must cycle in less than 15 minutes to have a hope of being; useful. However, those commits are not uniformly distributed. They; tend to cluster strongly during US working hours. Looking at a couple; of recent (Nov 2021) working days, we routinely see ~10 commits per; hour during peek times, with occasional spikes as high as ~15 commits; per hour. Thus, as a rule of thumb, we should plan for our builder to; complete ~10-15 builds an hour. Resource Appropriately; At 10-15 builds per hour, we need to complete a new build on average every; 4 to 6 minutes. For anything except the fastest of hardware/build configs,; this is going to be well beyond the ability of a single machine. In buildbot; terms, we likely going to need multiple workers to build requests in parallel; under a single builder configuration. For some rough back of the envelope; numbers, if your build config takes e.g. 30 minutes, you will need something; on the order of 5-8 workers. If your build config takes ~2 hours, you'll; need something on the order of 20-30 workers. The rest of this section; focuses on how to reduce cycle times. Restrict what you build and test; Think hard about why you're setting up a bot, and restrict your build; configuration as much as you can. Basic functionality is probably; already covered by other bots, and you don't need to duplicate that; testing. You only need to be building and testing the *unique* parts; of the configuration. (e.g. For a multi-stage clang builder, you probably; don't need to be enabling every target or building all the various utilities.). It can sometimes be worthwhile splitting a single builder into two or more,; if you have multiple distinct purposes for the same builder. As an example,; if you want to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:9041,configurat,configuration,9041,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['configurat'],['configuration']
Deployability," This specification describes ARC as performing specific ``retain`` and; ``release`` operations on retainable object pointers at specific; points during the execution of a program. These operations make up a; non-contiguous subsequence of the computation history of the program.; The portion of this sequence for a particular retainable object; pointer for which a specific function execution is directly; responsible is the :arc-term:`formal local retain history` of the; object pointer. The corresponding actual sequence executed is the; `dynamic local retain history`. However, under certain circumstances, ARC is permitted to re-order and; eliminate operations in a manner which may alter the overall; computation history beyond what is permitted by the general ""as if""; rule of C/C++ and the :ref:`restrictions <arc.objects.retains>` on; the implementation of ``retain`` and ``release``. .. admonition:: Rationale. Specifically, ARC is sometimes permitted to optimize ``release``; operations in ways which might cause an object to be deallocated; before it would otherwise be. Without this, it would be almost; impossible to eliminate any ``retain``/``release`` pairs. For; example, consider the following code:. .. code-block:: objc. id x = _ivar;; [x foo];. If we were not permitted in any event to shorten the lifetime of the; object in ``x``, then we would not be able to eliminate this retain; and release unless we could prove that the message send could not; modify ``_ivar`` (or deallocate ``self``). Since message sends are; opaque to the optimizer, this is not possible, and so ARC's hands; would be almost completely tied. ARC makes no guarantees about the execution of a computation history; which contains undefined behavior. In particular, ARC makes no; guarantees in the presence of race conditions. ARC may assume that any retainable object pointers it receives or; generates are instantaneously valid from that point until a point; which, by the concurrency model of the host la",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:76653,release,release,76653,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['release']
Deployability," U : Def->uses()) {; MemoryAccess *MA = cast<MemoryAccess>(Use.getUser());; if (auto *MU = cast_of_null<MemoryUse>MA) {; // Process MemoryUse as needed.; }; else {; // Process MemoryDef or MemoryPhi as needed. // As a user can come up twice, as an optimized access and defining; // access, keep a visited list. // Check transitive uses as needed; checkUses (MA); // use a worklist for an iterative algorithm; }; }; }. An example of similar traversals can be found in the DeadStoreElimination pass. Invalidation and updating; -------------------------. Because ``MemorySSA`` keeps track of LLVM IR, it needs to be updated whenever; the IR is updated. ""Update"", in this case, includes the addition, deletion, and; motion of ``Instructions``. The update API is being made on an as-needed basis.; If you'd like examples, ``GVNHoist`` and ``LICM`` are users of ``MemorySSA``\ s; update API.; Note that adding new ``MemoryDef``\ s (by calling ``insertDef``) can be a; time-consuming update, if the new access triggers many ``MemoryPhi`` insertions and; renaming (optimization invalidation) of many ``MemoryAccesses``\ es. Phi placement; ^^^^^^^^^^^^^. ``MemorySSA`` only places ``MemoryPhi``\ s where they're actually; needed. That is, it is a pruned SSA form, like LLVM's SSA form. For; example, consider:. .. code-block:: llvm. define void @foo() {; entry:; %p1 = alloca i8; %p2 = alloca i8; %p3 = alloca i8; ; 1 = MemoryDef(liveOnEntry); store i8 0, ptr %p3; br label %while.cond. while.cond:; ; 3 = MemoryPhi({%0,1},{if.end,2}); br i1 undef, label %if.then, label %if.else. if.then:; br label %if.end. if.else:; br label %if.end. if.end:; ; MemoryUse(1); %1 = load i8, ptr %p1; ; 2 = MemoryDef(3); store i8 2, ptr %p2; ; MemoryUse(1); %2 = load i8, ptr %p3; br label %while.cond; }. Because we removed the stores from ``if.then`` and ``if.else``, a ``MemoryPhi``; for ``if.end`` would be pointless, so we don't place one. So, if you need to; place a ``MemoryDef`` in ``if.then`` or ``if.else``, you'll ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:14533,update,update,14533,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['update'],['update']
Deployability," Unlock() RELEASE();. // Release/unlock a shared mutex.; void ReaderUnlock() RELEASE_SHARED();. // Generic unlock, can unlock exclusive and shared mutexes.; void GenericUnlock() RELEASE_GENERIC();. // Try to acquire the mutex. Returns true on success, and false on failure.; bool TryLock() TRY_ACQUIRE(true);. // Try to acquire the mutex for read operations.; bool ReaderTryLock() TRY_ACQUIRE_SHARED(true);. // Assert that this mutex is currently held by the calling thread.; void AssertHeld() ASSERT_CAPABILITY(this);. // Assert that is mutex is currently held for read operations.; void AssertReaderHeld() ASSERT_SHARED_CAPABILITY(this);. // For negative capabilities.; const Mutex& operator!() const { return *this; }; };. // Tag types for selecting a constructor.; struct adopt_lock_t {} inline constexpr adopt_lock = {};; struct defer_lock_t {} inline constexpr defer_lock = {};; struct shared_lock_t {} inline constexpr shared_lock = {};. // MutexLocker is an RAII class that acquires a mutex in its constructor, and; // releases it in its destructor.; class SCOPED_CAPABILITY MutexLocker {; private:; Mutex* mut;; bool locked;. public:; // Acquire mu, implicitly acquire *this and associate it with mu.; MutexLocker(Mutex *mu) ACQUIRE(mu) : mut(mu), locked(true) {; mu->Lock();; }. // Assume mu is held, implicitly acquire *this and associate it with mu.; MutexLocker(Mutex *mu, adopt_lock_t) REQUIRES(mu) : mut(mu), locked(true) {}. // Acquire mu in shared mode, implicitly acquire *this and associate it with mu.; MutexLocker(Mutex *mu, shared_lock_t) ACQUIRE_SHARED(mu) : mut(mu), locked(true) {; mu->ReaderLock();; }. // Assume mu is held in shared mode, implicitly acquire *this and associate it with mu.; MutexLocker(Mutex *mu, adopt_lock_t, shared_lock_t) REQUIRES_SHARED(mu); : mut(mu), locked(true) {}. // Assume mu is not held, implicitly acquire *this and associate it with mu.; MutexLocker(Mutex *mu, defer_lock_t) EXCLUDES(mu) : mut(mu), locked(false) {}. // Same as constructors, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:29062,release,releases,29062,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['release'],['releases']
Deployability," Update Documentation; ^^^^^^^^^^^^^^^^^^^^. Review the documentation in the release branch and ensure that it is up; to date. The ""Release Notes"" must be updated to reflect new features, bug; fixes, new known issues, and changes in the list of supported platforms.; The ""Getting Started Guide"" should be updated to reflect the new release; version number tag available from Subversion and changes in basic system; requirements. .. _tag:. Tag the LLVM Final Release; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Tag the final release sources:. ::. $ git tag -sa llvmorg-X.Y.Z; $ git push https://github.com/llvm/llvm-project.git llvmorg-X.Y.Z. Update the LLVM Website; ^^^^^^^^^^^^^^^^^^^^^^^. The website must be updated before the release announcement is sent out. Here; is what to do:. #. Check out the ``www-releases`` module from GitHub. #. Create a new sub-directory ``X.Y.Z`` in the releases directory. #. Copy and commit the ``llvm/docs`` and ``LICENSE.txt`` files into this new; directory. #. Update the ``releases/download.html`` file with links to the release; binaries on GitHub. #. Update the ``releases/index.html`` with the new release and link to release; documentation. #. After you push the changes to the www-releases repo, someone with admin; access must login to prereleases-origin.llvm.org and manually pull the new; changes into /data/www-releases/. This is where the website is served from. #. Finally checkout the llvm-www repo and update the main page; (``index.html`` and sidebar) to point to the new release and release; announcement. Announce the Release; ^^^^^^^^^^^^^^^^^^^^. Create a new post in the `Announce Category <https://discourse.llvm.org/c/announce>`_; once all the release tasks are complete. For X.1.0 releases, make sure to include a; link to the release notes in the post. For X.1.1+ releases, generate a changelog; using this command and add it to the post. ::. $ git log --format=""- %aN: [%s (%h)](https://github.com/llvm/llvm-project/commit/%H)"" llvmorg-X.1.N-1..llvmor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:14898,release,releases,14898,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['release'],['releases']
Deployability," Value *CallExprAST::codegen() {; // Look up the name in the global module table.; Function *CalleeF = getFunction(Callee);. ... Function *FunctionAST::codegen() {; // Transfer ownership of the prototype to the FunctionProtos map, but keep a; // reference to it for use below.; auto &P = *Proto;; FunctionProtos[Proto->getName()] = std::move(Proto);; Function *TheFunction = getFunction(P.getName());; if (!TheFunction); return nullptr;. To enable this, we'll start by adding a new global, ``FunctionProtos``, that; holds the most recent prototype for each function. We'll also add a convenience; method, ``getFunction()``, to replace calls to ``TheModule->getFunction()``.; Our convenience method searches ``TheModule`` for an existing function; declaration, falling back to generating a new declaration from FunctionProtos if; it doesn't find one. In ``CallExprAST::codegen()`` we just need to replace the; call to ``TheModule->getFunction()``. In ``FunctionAST::codegen()`` we need to; update the FunctionProtos map first, then call ``getFunction()``. With this; done, we can always obtain a function declaration in the current module for any; previously declared function. We also need to update HandleDefinition and HandleExtern:. .. code-block:: c++. static void HandleDefinition() {; if (auto FnAST = ParseDefinition()) {; if (auto *FnIR = FnAST->codegen()) {; fprintf(stderr, ""Read function definition:"");; FnIR->print(errs());; fprintf(stderr, ""\n"");; ExitOnErr(TheJIT->addModule(; ThreadSafeModule(std::move(TheModule), std::move(TheContext))));; InitializeModuleAndPassManager();; }; } else {; // Skip token for error recovery.; getNextToken();; }; }. static void HandleExtern() {; if (auto ProtoAST = ParseExtern()) {; if (auto *FnIR = ProtoAST->codegen()) {; fprintf(stderr, ""Read extern: "");; FnIR->print(errs());; fprintf(stderr, ""\n"");; FunctionProtos[ProtoAST->getName()] = std::move(ProtoAST);; }; } else {; // Skip token for error recovery.; getNextToken();; }; }. In HandleDefinit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:19707,update,update,19707,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['update'],['update']
Deployability," Vasilev (Princeton University) explains how Cling enables interactivity in C++, and illustrates the type introspection mechanism provided by the interpreter.; * - `Introducing Cling, a C++ Interpreter Based on Clang/LLVM <https://www.youtube.com/watch?v=f9Xfh8pv3Fs>`_; - *Axel Naumann* 2012 Googletechtalks; - Axel Naumann (CERN) discusses Cling’s most relevant features: abstract syntax tree (AST) production, wrapped functions, global initialization of a function, delay expression evaluation at runtime, and dynamic scopes.; * - `Creating Cling, an interactive interpreter interface <https://www.youtube.com/watch?v=BjmGOMJWeAo>`_; - *Axel Naumann* 2010 LLVM Developers’ meeting; - This presentation introduces Cling, an ahead-of-time compiler that extends C++ for ease of use as an interpreter.; . ; .. list-table:: Demos, tutorials, Cling’s ecosystem:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Cling integration | CLion <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_; - 2022.2 Version; - CLion uses Cling to integrate the `Quick Documentation <https://www.jetbrains.com/help/clion/2022.2/viewing-inline-documentation.html>`_ popup by allowing you to view the value of the expressions evaluated at compile time.; * - `Interactive C++ for Data Science <https://www.youtube.com/watch?v=23E0S3miWB0&t=2716s>`_; - *Vassil Vassilev* 2021 CppCon (The C++ Conference); - In this video, the author discusses how Cling enables interactive C++ for Data Science projects. ; * - `Cling -- Beyond Just Interpreting C++ <https://blog.llvm.org/posts/2021-03-25-cling-beyond-just-interpreting-cpp/>`_; - *Vassil Vassilev* 2021 The LLVM Project Blog; - This blog page discusses how Cling enables template Instantiation on demand, language interoperability on demand, interpreter/compiler as a service, plugins extension.; * - `TinySpec-Cling <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_; - Noah Weninger 2020; - A tiny C++ live-coded ove",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:2030,integrat,integration,2030,interpreter/cling/docs/chapters/references.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst,1,['integrat'],['integration']
Deployability," Villanueva, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Alexandra Dobrescu, CERN/SFT,\; Giulio Eulisse, CERN/ALICE,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Stephan Hageboeck, CERN/SFT,\; Jan Knedlik, GSI,\; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Alja Mrak-Tadel, UCSD/CMS,\; Axel Naumann, CERN/SFT,\; Vincenzo Eduardo Padulano, Bicocca/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Henry Schreiner, Princeton,\; Oksana Shadura, Nebraska,\; Simon Spies, GSI,\; Yuka Takahashi, Princeton and CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Matevz Tadel, UCSD/CMS,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas,\; Zhe Zhang, Nebraska,\; Stefan Wunsch, CERN/SFT. ## Deprecation and Removal. ### Deprecated packages. The Virtual Monte Carlo (VMC) interfaces have been deprecated for this release; and will be removed in a future release. It is no longer built by default, but; can still be enabled with the option `-Dvmc=ON` in the CMake configuration phase.; A standalone version of VMC is being developed at [https://github.com/vmc-project/vmc](https://github.com/vmc-project/vmc); to replace the deprecated version in ROOT. ### Removed packages. Support for the following optional components of ROOT has been removed:. * afdsmgrd (Dataset manager for PROOF-based analysis facilities); * bonjour (Avahi/Bonjour/Zeroconf); * castor (CERN Advanced STORage manager); * geocad (OpenCascade); * globus (Globus authentication); * hdfs (Hadoop Distributed File System); * krb5 (Kerberos 5 authentication); * ldap (OpenLDAP authentication); * memstat (legacy memory statistics utility); * qt, qtgsi, qtroot (Qt4-based GUI components); * rfio (Remote File IO for CASTOR); * table (libTable contrib library). In addition, the following deprecated parts of ROOT components have been; removed:. * PROOF's PQ2 module; * `THttpServer::ExecuteHttp()` and `THttpServer::SubmitHttp` from `THttpServer`. ### Other ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:1554,configurat,configuration,1554,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,1,['configurat'],['configuration']
Deployability," We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:35891,update,update,35891,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['update'],['update']
Deployability," When transparent volumes appeared in the model, one could use `produceRenderOrder()` function; to correctly set rendering order. It should be used as:. ```javascript; import { produceRenderOrder } from './path_to_jsroot/modules/geom/TGeoPainter.mjs';; produceRenderOrder(scene, camera.position, 'box');; ```. Following methods can be applied: ""box"", ""pnt"", ""size"", ""ray"" and ""dflt"". See more info in draw options description for TGeo classes. Here is [running example](https://root.cern/js/latest/api.htm#custom_html_geometry) and [source code](https://github.com/root-project/jsroot/blob/master/demo/tgeo_build.htm). ### Custom user class. There is [code example](https://github.com/root-project/jsroot/tree/master/demo/custom) how custom user class can be implemented.; It shows usage of different draw options for the class and ability to access sub-elements of the object using specialized `expand` function. ### Use with Node.js. To install latest JSROOT release, just do:. ```bash; [shell] npm install jsroot; ```. To use in the Node.js scripts, one should add following line:. ```javascript; import { httpRequest, makeSVG } from 'jsroot';; ```. Using JSROOT functionality, one can open binary ROOT files (local and remote), parse ROOT JSON,; create SVG output. For example, to create SVG image with lego plot, one should do:. ```javascript; import { openFile, makeSVG } from 'jsroot';; import { writeFileSync } from 'fs';. let file = await openFile(""https://root.cern/js/files/hsimple.root"");; let obj = await file.readObject(""hpx;1"");; let svg = await makeSVG({ object: obj, option: ""lego2"", width: 1200, height: 800 });; writeFileSync(""lego2.svg"", svg);; ```. It is also possible to convert any JavaScript object into ROOT JSON string, using `toJSON()` function. Like:. ```javascript; import { toJSON, openFile, makeSVG } from 'jsroot';; import { writeFileSync } from 'fs';. let file = await openFile(""https://root.cern/js/files/hsimple.root"");; let obj = await file.readObject(""hpx;1"");; l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:44455,install,install,44455,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['install'],['install']
Deployability," You can also expand; the unit test to see the details:. .. image:: Phabricator_premerge_unit_tests.png. Opting Out; ^^^^^^^^^^. In case you want to opt-out entirely of pre-merge testing, add yourself to the; `OPT OUT project <https://reviews.llvm.org/project/view/83/>`_. If you decide; to opt-out, please let us know why, so we might be able to improve in the future. Operational Details; ^^^^^^^^^^^^^^^^^^^. The code responsible for running the pre-merge flow can be found in the `external; repository <https://github.com/google/llvm-premerge-checks>`_. For enhancement; ideas and most bugs, please file an issue on said repository. For immediate; operational problems, the point of contact is; `Mikhail Goncharov <mailto:goncharo@google.com>`_. Background on the pre-merge infrastructure can be found in `this 2020 DevMeeting; talk <https://llvm.org/devmtg/2020-09/slides/Goncharov-Pre-merge_checks.pdf>`_. Committing a change; -------------------. Once a patch has been reviewed and approved on Phabricator it can then be; committed to trunk. If you do not have commit access, someone has to; commit the change for you (with attribution). It is sufficient to add; a comment to the approved review indicating you cannot commit the patch; yourself. If you have commit access, there are multiple workflows to commit the; change. Whichever method you follow it is recommended that your commit message; ends with the line:. ::. Differential Revision: <URL>. where ``<URL>`` is the URL for the code review, starting with; ``https://reviews.llvm.org/``. This allows people reading the version history to see the review for; context. This also allows Phabricator to detect the commit, close the; review, and add a link from the review to the commit. Note that if you use the Arcanist tool the ``Differential Revision`` line will; be added automatically. If you don't want to use Arcanist, you can add the; ``Differential Revision`` line (as the last line) to the commit message; yourself. Using the Arca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst:13208,patch,patch,13208,interpreter/llvm-project/llvm/docs/Phabricator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst,1,['patch'],['patch']
Deployability," \; 	-- \; 	-DLLVM_TARGETS_TO_BUILD=Native -DCMAKE_BUILD_TYPE=Release \; 	-DBOOTSTRAP_CMAKE_BUILD_TYPE=Release \; 	-DCLANG_ENABLE_BOOTSTRAP=ON -DCLANG_BOOTSTRAP_TARGETS=""install-clang;install-clang-resource-headers""; 	; This will produce a new image ``clang-debian10:staging`` from the latest; upstream revision.; After the image is built you can run bash inside a container based on your image; like this:. .. code-block:: bash. docker run -ti clang-debian10:staging bash. Now you can run bash commands as you normally would:. .. code-block:: bash. root@80f351b51825:/# clang -v; clang version 5.0.0 (trunk 305064); Target: x86_64-unknown-linux-gnu; Thread model: posix; InstalledDir: /bin; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8.4; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9.2; Selected GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Candidate multilib: .;@m64; Selected multilib: .;@m64. Which image should I choose?; ============================; We currently provide two images: Debian10-based and nvidia-cuda-based. They; differ in the base image that they use, i.e. they have a different set of; preinstalled binaries. Debian8 is very minimal, nvidia-cuda is larger, but has; preinstalled CUDA libraries and allows to access a GPU, installed on your; machine. If you need a minimal linux distribution with only clang and libstdc++ included,; you should try Debian10-based image. If you want to use CUDA libraries and have access to a GPU on your machine,; you should choose nvidia-cuda-based image and use `nvidia-docker; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker container that is running the built; image. If you have a different use-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:5477,install,installation,5477,interpreter/llvm-project/llvm/docs/Docker.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst,1,['install'],['installation']
Deployability," _BreakBeforeTernaryOperators:. **BreakBeforeTernaryOperators** (``Boolean``) :versionbadge:`clang-format 3.7` :ref:`¶ <BreakBeforeTernaryOperators>`; If ``true``, ternary operators will be placed after line breaks. .. code-block:: c++. true:; veryVeryVeryVeryVeryVeryVeryVeryVeryVeryVeryLongDescription; ? firstValue; : SecondValueVeryVeryVeryVeryLong;. false:; veryVeryVeryVeryVeryVeryVeryVeryVeryVeryVeryLongDescription ?; firstValue :; SecondValueVeryVeryVeryVeryLong;. .. _BreakConstructorInitializers:. **BreakConstructorInitializers** (``BreakConstructorInitializersStyle``) :versionbadge:`clang-format 5` :ref:`¶ <BreakConstructorInitializers>`; The break constructor initializers style to use. Possible values:. * ``BCIS_BeforeColon`` (in configuration: ``BeforeColon``); Break constructor initializers before the colon and after the commas. .. code-block:: c++. Constructor(); : initializer1(),; initializer2(). * ``BCIS_BeforeComma`` (in configuration: ``BeforeComma``); Break constructor initializers before the colon and commas, and align; the commas with the colon. .. code-block:: c++. Constructor(); : initializer1(); , initializer2(). * ``BCIS_AfterColon`` (in configuration: ``AfterColon``); Break constructor initializers after the colon and commas. .. code-block:: c++. Constructor() :; initializer1(),; initializer2(). .. _BreakInheritanceList:. **BreakInheritanceList** (``BreakInheritanceListStyle``) :versionbadge:`clang-format 7` :ref:`¶ <BreakInheritanceList>`; The inheritance list style to use. Possible values:. * ``BILS_BeforeColon`` (in configuration: ``BeforeColon``); Break inheritance list before the colon and after the commas. .. code-block:: c++. class Foo; : Base1,; Base2; {};. * ``BILS_BeforeComma`` (in configuration: ``BeforeComma``); Break inheritance list before the colon and commas, and align; the commas with the colon. .. code-block:: c++. class Foo; : Base1; , Base2; {};. * ``BILS_AfterColon`` (in configuration: ``AfterColon``); Break inheritance li",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:54550,configurat,configuration,54550,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," __block int x;; return ^(){ return x; }();; }. By an accident of implementation, GCC and llvm-gcc unintentionally always; zero initialized __block variables. However, any program which depends; on this behavior is relying on unspecified compiler behavior. Programs must; explicitly initialize all local block variables before they are used, as with; other local variables.; Clang does not zero initialize local block variables, and programs which rely; on such behavior will most likely break when built with Clang. Inline assembly. In general, Clang is highly compatible with the GCC inline assembly; extensions, allowing the same set of constraints, modifiers and operands as GCC; inline assembly.; On targets that use the integrated assembler (such as most X86 targets),; inline assembly is run through the integrated assembler instead of your system; assembler (which is most commonly ""gas"", the GNU assembler). The LLVM; integrated assembler is extremely compatible with GAS, but there are a couple of; minor places where it is more picky, particularly due to outright GAS bugs.; One specific example is that the assembler rejects ambiguous X86 instructions; that don't have suffixes. For example:. asm(""add %al, (%rax)"");; asm(""addw $4, (%rax)"");; asm(""add $4, (%rax)"");. Both clang and GAS accept the first instruction: because the first; instruction uses the 8-bit %al register as an operand, it is clear that; it is an 8-bit add. The second instruction is accepted by both because the ""w""; suffix indicates that it is a 16-bit add. The last instruction is accepted by; GAS even though there is nothing that specifies the size of the instruction (and; the assembler randomly picks a 32-bit add). Because it is ambiguous, Clang; rejects the instruction with this error message:. <inline asm>:3:1: error: ambiguous instructions require an explicit suffix (could be 'addb', 'addw', 'addl', or 'addq'); add $4, (%rax); ^. To fix this compatibility issue, add an explicit suffix to the instructio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/compatibility.html:7665,integrat,integrated,7665,interpreter/llvm-project/clang/www/compatibility.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/compatibility.html,1,['integrat'],['integrated']
Deployability," _phabricator-request-review-web:. Requesting a review via the web interface; -----------------------------------------. The tool to create and review patches in Phabricator is called; *Differential*. Note that you can upload patches created through git, but using `arc` on the; command line (see previous section) is preferred: it adds more metadata to; Phabricator which are useful for the pre-merge testing system and for; propagating attribution on commits when someone else has to push it for you. To make reviews easier, please always include **as much context as; possible** with your diff! Don't worry, Phabricator; will automatically send a diff with a smaller context in the review; email, but having the full file in the web interface will help the; reviewer understand your code. To get a full diff, use one of the following commands (or just use Arcanist; to upload your patch):. * ``git show HEAD -U999999 > mypatch.patch``; * ``git diff -U999999 @{u} > mypatch.patch``; * ``git diff HEAD~1 -U999999 > mypatch.patch``. Before uploading your patch, please make sure it is formatted properly, as; described in :ref:`How to Submit a Patch <format patches>`. To upload a new patch:. * Click *Differential*.; * Click *+ Create Diff*.; * Paste the text diff or browse to the patch file. Leave this first Repository; field blank. (We'll fill in the Repository later, when sending the review.); Click *Create Diff*.; * Leave the drop down on *Create a new Revision...* and click *Continue*.; * Enter a descriptive title and summary. The title and summary are usually; in the form of a :ref:`commit message <commit messages>`.; * Add reviewers (see below for advice). (If you set the Repository field; correctly, llvm-commits or cfe-commits will be subscribed automatically;; otherwise, you will have to manually subscribe them.); * In the Repository field, enter ""rG LLVM Github Monorepo"".; * Click *Save*. To submit an updated patch:. * Click *Differential*.; * Click *+ Create Diff*.; * Paste",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst:3403,patch,patch,3403,interpreter/llvm-project/llvm/docs/Phabricator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst,1,['patch'],['patch']
Deployability," `ROOT::Math::AdaptiveIntegratorMultiDim` |; | `ROOT::Math::IntegratorMultiDim::kVEGAS` | `ROOT::Math:::GSLMCIntegrator` |; | `ROOT::Math::IntegratorMultiDim::kMISER` | `ROOT::Math:::GSLMCIntegrator` |; | `ROOT::Math::IntegratorMultiDim::kPLAIN` | `ROOT::Math:::GSLMCIntegrator` |. The control parameters for the integration algorithms can be specified using the; `ROOT::Math::IntegratorMultiDimOptions` class. Static methods are provided to change the default values.; It is possible to print the list of default control parameters using the `ROOT::Math::IntegratorMultiDimOptions::Print` function.; Example:; ```{.cpp}; ROOT::Math::IntegratorMultiDimOptions opt;; opt.Print();; Integrator Type : ADAPTIVE; Absolute tolerance : 1e-09; Relative tolerance : 1e-09; Workspace size : 100000; (max) function calls : 100000; ```; Depending on the algorithm, some of the control parameters might have no effect. #### `ROOT::Math::AdaptiveIntegratorMultiDim`. This class implements an adaptive quadrature integration method for multi dimensional functions. It is described in this paper; *Genz, A.A. Malik, An adaptive algorithm for numerical integration over an N-dimensional rectangular region, J. Comput. Appl. Math. 6 (1980) 295-302*.; It is part of the *MathCore* library.; The user can control the relative and absolute tolerance and the maximum allowed number of function evaluation. #### `ROOT::Math::GSLMCIntegrator`. It is a class for performing numerical integration of a multidimensional function. It uses the numerical integration algorithms of GSL, which reimplements the algorithms used; in the QUADPACK, a numerical integration package written in Fortran. Plain MC, MISER and VEGAS integration algorithms are supported for integration over finite (hypercubic) ranges.; For a detail description of the GSL methods visit the GSL users guide.; Specific configuration options (documented in the GSL user guide) for the `ROOT::Math::GSLMCIntegration` can be set directly in the class, or when usin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:61228,integrat,integration,61228,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['integrat'],['integration']
Deployability," ``-DLIBUNWIND_USE_COMPILER_RT=OFF``. We use the MS runtime. The CMake files will need to be edited to prevent them adding GNU specific libraries to the link line. Building libc++abi:; -------------------. * ``-DLIBCXXABI_ENABLE_SHARED=OFF``; * ``-DLIBCXXABI_ENABLE_STATIC=ON``; * ``-DLIBCXX_ENABLE_SHARED=ON'``; * ``-DLIBCXX_ENABLE_STATIC_ABI_LIBRARY=ON``. To break the symbol dependency between libc++abi and libc++ we; build libc++abi as a static library and then statically link it; into the libc++ DLL. This necessitates setting the CMake file; to ensure that the visibility macros (which expand to dllexport/import); are expanded as they will be needed when creating the final libc++; DLL later, see: https://reviews.llvm.org/D90021. * ``-DLIBCXXABI_LIBCXX_INCLUDES=<path to libcxx>/include``. Where to find the libc++ headers. Building libc++:; ----------------. * ``-DLIBCXX_ENABLE_SHARED=ON``; * ``-DLIBCXX_ENABLE_STATIC=OFF``. We build libc++ as a DLL and statically link libc++abi into it. * ``-DLIBCXX_INSTALL_HEADERS=ON``. Install the headers. * ``-DLIBCXX_USE_COMPILER_RT=OFF``. We use the MS runtime. * ``-DLIBCXX_HAS_WIN32_THREAD_API=ON``. Windows Itanium does not offer a POSIX-like layer over WIN32. * ``-DLIBCXX_ENABLE_STATIC_ABI_LIBRARY=ON``; * ``-DLIBCXX_CXX_ABI=libcxxabi``; * ``-DLIBCXX_CXX_ABI_INCLUDE_PATHS=<libcxxabi src path>/include``; * ``-DLIBCXX_CXX_ABI_LIBRARY_PATH=<libcxxabi build path>/lib``. Use the static libc++abi library built earlier. * ``-DLIBCXX_NO_VCRUNTIME=ON``. Remove any dependency on the VC runtime - we need libc++abi to supply the C++ runtime. * ``-DCMAKE_C_FLAGS=<path to installed unwind.lib>``. As we are statically linking against libcxxabi we need to link; against the unwind import library to resolve unwind references; from the libcxxabi objects. * ``-DCMAKE_C_FLAGS+=' -UCLOCK_REALTIME'``. Prevent the inclusion of sys/time that MS doesn't provide. Notes:; ------. An example build recipe is available here: https://reviews.llvm.org/D88124; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildWindowsItaniumPrograms.rst:6492,install,installed,6492,interpreter/llvm-project/llvm/docs/HowToBuildWindowsItaniumPrograms.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildWindowsItaniumPrograms.rst,1,['install'],['installed']
Deployability," ``-fno-exceptions`` then a; toolchain could select libraries built without exception support, thereby; reducing the size of the resulting binary. Design; ======. Clang supports GCC's ``-print-multi-lib`` and ``-print-multi-directory``; options. These are described in; `GCC Developer Options <https://gcc.gnu.org/onlinedocs/gcc-12.2.0/gcc/Developer-Options.html>`_. There are two ways to configure multilib in Clang: hard-coded or via a; configuration file. Hard-coded Multilib; ===================. The available libraries can be hard-coded in Clang. Typically this is done; using the ``MultilibBuilder`` interface in; ``clang/include/clang/Driver/MultilibBuilder.h``.; There are many examples of this in ``lib/Driver/ToolChains/Gnu.cpp``.; The remainder of this document will not focus on this type of multilib. EXPERIMENTAL Multilib via configuration file; ============================================. Some Clang toolchains support loading multilib configuration from a; ``multilib.yaml`` configuration file. A ``multilib.yaml`` configuration file specifies which multilib variants are; available, their relative location, what compilation options were used to build; them, and the criteria by which they are selected. Multilib processing; ===================. Clang goes through the following steps to use multilib from a configuration; file:. #. Normalize command line options. Clang can accept the same; information via different options - for example,; ``--target=arm-none-eabi -march=armv7-m`` and; ``--target=armv7m-none-eabi`` are equivalent.; Clang normalizes the command line before passing them to the multilib system.; To see what flags are emitted for a given set of command line options, use; the ``-print-multi-flags-experimental`` command line option; along with the rest of the options you want to use.; #. Load ``multilib.yaml`` from sysroot.; #. Generate additional flags. ``multilib.yaml`` contains a ``Mappings`` section,; which specifies how to generate additional flags bas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst:2073,configurat,configuration,2073,interpreter/llvm-project/clang/docs/Multilib.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst,1,['configurat'],['configuration']
Deployability," ``DW_AT_frame_base`` *attribute of the debugger; information entry corresponding to the current subprogram can be computed; using a location list expression, in some cases this would require an; extensive location list because the values of the registers used in; computing the CFA change during a subprogram execution. If the call frame; information is present, then it already encodes such changes, and it is; space efficient to reference that using the* ``DW_OP_call_frame_cfa``; *operation.*. 6. ``DW_OP_fbreg``. ``DW_OP_fbreg`` has a single signed LEB128 integer operand that represents a; byte displacement B. The location description L for the *frame base* of the current subprogram is; obtained from the ``DW_AT_frame_base`` attribute of the debugger information; entry corresponding to the current subprogram as described in; :ref:`amdgpu-dwarf-low-level-information`. The location description L is updated as if the ``DW_OP_LLVM_offset_uconst; B`` operation was applied. The updated L is pushed on the stack. 7. ``DW_OP_breg0``, ``DW_OP_breg1``, ..., ``DW_OP_breg31``. The ``DW_OP_breg<N>`` operations encode the numbers of up to 32 registers,; numbered from 0 through 31, inclusive. The register number R corresponds to; the N in the operation name. They have a single signed LEB128 integer operand that represents a byte; displacement B. The address space identifier AS is defined as the one corresponding to the; target architecture specific default address space. The address size S is defined as the address bit size of the target; architecture specific address space corresponding to AS. The contents of the register specified by R are retrieved as if a; ``DW_OP_regval_type R, DR`` operation was performed where DR is the offset; of a hypothetical debug information entry in the current compilation unit; for an unsigned integral base type of size S bits. B is added and the least; significant S bits are treated as an unsigned value to be used as an address; A. They push a locatio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:115199,update,updated,115199,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['update'],['updated']
Deployability," ``DW_OP_piece``, except that any part created; has the bit size S, and the location description PL of any created part is; updated as if the ``DW_OP_constu B; DW_OP_LLVM_bit_offset`` operations were; applied. ``DW_OP_bit_piece`` *is used instead of* ``DW_OP_piece`` *when the piece to; be assembled is not byte-sized or is not at the start of the part location; description.*. *If a computed bit displacement is required, the* ``DW_OP_LLVM_bit_offset``; *operation can be used to update the location description before using it as; the part location description of a* ``DW_OP_bit_piece`` *operation.*. .. note::. The bit offset operand is not needed as ``DW_OP_LLVM_bit_offset`` can be; used on the part's location description. 3. ``DW_OP_LLVM_piece_end`` *New*. If the top stack entry is not a location description L comprised of one; incomplete composite location description SL, then the DWARF expression is; ill-formed. Otherwise, the incomplete composite location storage LS specified by SL is; updated to be a complete composite location description with the same parts. 4. ``DW_OP_LLVM_extend`` *New*. ``DW_OP_LLVM_extend`` has two operands. The first is an unsigned LEB128; integer that represents the element bit size S. The second is an unsigned; LEB128 integer that represents a count C. It pops one stack entry that must be a location description and is treated; as the part location description PL. A location description L comprised of one complete composite location; description SL is pushed on the stack. A complete composite location storage LS is created with C identical parts; P. Each P specifies PL and has a bit size of S. SL specifies LS with a bit offset of 0. The DWARF expression is ill-formed if the element bit size or count are 0. 5. ``DW_OP_LLVM_select_bit_piece`` *New*. ``DW_OP_LLVM_select_bit_piece`` has two operands. The first is an unsigned; LEB128 integer that represents the element bit size S. The second is an; unsigned LEB128 integer that represents a count ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:137685,update,updated,137685,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['update'],['updated']
Deployability," ``LLVM_HOST_TRIPLE`` specifies the triple of the system; that the cross built LLVM is going to run on - the flag is named based; on the autoconf build/host/target nomenclature. (This flag implicitly sets; other defaults, such as ``LLVM_DEFAULT_TARGET_TRIPLE``.). If you're compiling with GCC, you can use architecture options for your target,; and the compiler driver will detect everything that it needs:. * ``-DCMAKE_CXX_FLAGS='-march=armv7-a -mcpu=cortex-a9 -mfloat-abi=hard'``. However, if you're using Clang, the driver might not be up-to-date with your; specific Linux distribution, version or GCC layout, so you'll need to fudge. In addition to the ones above, you'll also need:. * ``--target=arm-linux-gnueabihf`` or whatever is the triple of your cross GCC.; * ``'--sysroot=/usr/arm-linux-gnueabihf'``, ``'--sysroot=/opt/gcc/arm-linux-gnueabihf'``; or whatever is the location of your GCC's sysroot (where /lib, /bin etc are).; * Appropriate use of ``-I`` and ``-L``, depending on how the cross GCC is installed,; and where are the libraries and headers. You may also want to set the ``LLVM_NATIVE_TOOL_DIR`` option - pointing; at a directory with prebuilt LLVM tools (``llvm-tblgen``, ``clang-tblgen``; etc) for the build host, allowing you to them reuse them if available.; E.g. ``-DLLVM_NATIVE_TOOL_DIR=<path-to-native-llvm-build>/bin``.; If the option isn't set (or the directory doesn't contain all needed tools),; the LLVM cross build will automatically launch a nested build to build the; tools that are required. The CXX flags define the target, cpu (which in this case; defaults to ``fpu=VFP3`` with NEON), and forcing the hard-float ABI. If you're; using Clang as a cross-compiler, you will *also* have to set ``--sysroot``; to make sure it picks the correct linker. When using Clang, it's important that you choose the triple to be *identical*; to the GCC triple and the sysroot. This will make it easier for Clang to; find the correct tools and include headers. But that won't m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToCrossCompileLLVM.rst:2627,install,installed,2627,interpreter/llvm-project/llvm/docs/HowToCrossCompileLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToCrossCompileLLVM.rst,1,['install'],['installed']
Deployability," ``__block`` variables did not implicitly retain during capture. ``__block`` variables of retainable object owner type are moved off the stack; by initializing the heap copy with the result of moving from the stack copy. With the exception of retains done as part of initializing a ``__strong``; parameter variable or reading a ``__weak`` variable, whenever these semantics; call for retaining a value of block-pointer type, it has the effect of a; ``Block_copy``. The optimizer may remove such copies when it sees that the; result is used only as an argument to a call. When a block pointer type is converted to a non-block pointer type (such as; ``id``), ``Block_copy`` is called. This is necessary because a block allocated; on the stack won't get copied to the heap when the non-block pointer escapes.; A block pointer is implicitly converted to ``id`` when it is passed to a; function as a variadic argument. .. _arc.misc.exceptions:. Exceptions; ----------. By default in Objective C, ARC is not exception-safe for normal releases:. * It does not end the lifetime of ``__strong`` variables when their scopes are; abnormally terminated by an exception.; * It does not perform releases which would occur at the end of a; full-expression if that full-expression throws an exception. A program may be compiled with the option ``-fobjc-arc-exceptions`` in order to; enable these, or with the option ``-fno-objc-arc-exceptions`` to explicitly; disable them, with the last such argument ""winning"". .. admonition:: Rationale. The standard Cocoa convention is that exceptions signal programmer error and; are not intended to be recovered from. Making code exceptions-safe by; default would impose severe runtime and code size penalties on code that; typically does not actually care about exceptions safety. Therefore,; ARC-generated code leaks by default on exceptions, which is just fine if the; process is going to be immediately terminated anyway. Programs which do care; about recovering from except",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:97751,release,releases,97751,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['releases']
Deployability," ``float`` -> ``const long long&`` conversion; * Capture python exception message string in PyException from callbacks; * Thread safety in enum lookups. 2021-03-22: 1.9.5; -----------------. * Do not regulate direct smart pointers (many to one can lead to double deletion); * Use pkg_resources of ``CPyCppyy``, if available, to find the API include path. 2021-03-17: 1.9.4; -----------------. * Fix for installing into a directory that has a space in the name; * Fix empty collection printing through Cling on 64b Windows; * Fix accidental shadowing of derived class typedefs by same names in base; * Streamlined templated function lookups in namespaces; * Fix edge cases when decomposing std::function template arguments; * Enable multi-cross inheritance with non-C++ python bases; * Support Bound C++ functions as template argument; * Python functions as template arguments from ``__annotations__`` or ``__cpp_name__``; * Removed functions/apis deprecated in py3.9; * Improved support for older pip and different installation layouts. 2021-02-15: 1.9.3; -----------------. * Wheels for Linux now follow manylinux2014; * Enable direct calls of base class' methods in Python cross-overrides; * cppyy.bind_object can now re-cast types, incl. Python cross-derived ones; * Python cross-derived objects send to (and owned by) C++ retain Python state; * Ignore, for symbol lookups, libraries that can not be reloaded; * Use PathCanonicalize when resolving paths on Windows; * Add more ways of finding the backend library; * Improve error reporting when failed to find the backend library; * Workaround for mixing std::endl in JIT-ed and compiled code on Windows 32b; * Fixed a subtle crash that arises when an invalid ``using`` is the last method; * Filter -fno-plt (coming from anaconda builds; not understood by Cling); * Fixed memory leak in generic base ``__str__``. 2021-01-05: 1.9.2; -----------------. * Added ``cppyy.types`` module for exposing cppyy builtin types; * Improve numpy integration with",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:7628,install,installation,7628,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,1,['install'],['installation']
Deployability," ``live values`` will have their location recorded, which; could be a register, stack location, or constant. A special calling; convention has been introduced for use with stack maps, anyregcc,; which forces the arguments to be loaded into registers but allows; those register to be dynamically allocated. These argument registers; will have their register locations recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a call to the target address on the; supported targets. If the call target is constant null, then there is; no minimum requirement. A zero-byte null target patchpoint is; valid. The runtime may patch the code emitted for the patch point, including; the call sequence and nops. However, the runtime may not assume; anything about the code LLVM emits within the reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:10393,patch,patching,10393,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['patch'],['patching']
Deployability," ``standard``.; * ``16`` - Forces ``_Float16`` operations to be emitted without using excess; precision arithmetic. .. option:: -fcx-limited-range:. This option enables the naive mathematical formulas for complex division and; multiplication with no NaN checking of results. The default is; ``-fno-cx-limited-range``, but this option is enabled by the ``-ffast-math``; option. .. option:: -fcx-fortran-rules:. This option enables the naive mathematical formulas for complex; multiplication and enables application of Smith's algorithm for complex; division. See SMITH, R. L. Algorithm 116: Complex division. Commun.; ACM 5, 8 (1962). The default is ``-fno-cx-fortran-rules``. .. _floating-point-environment:. Accessing the floating point environment; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; Many targets allow floating point operations to be configured to control things; such as how inexact results should be rounded and how exceptional conditions; should be handled. This configuration is called the floating point environment.; C and C++ restrict access to the floating point environment by default, and the; compiler is allowed to assume that all operations are performed in the default; environment. When code is compiled in this default mode, operations that depend; on the environment (such as floating-point arithmetic and `FLT_ROUNDS`) may have; undefined behavior if the dynamic environment is not the default environment; for; example, `FLT_ROUNDS` may or may not simply return its default value for the target; instead of reading the dynamic environment, and floating-point operations may be; optimized as if the dynamic environment were the default. Similarly, it is undefined; behavior to change the floating point environment in this default mode, for example; by calling the `fesetround` function.; C provides two pragmas to allow code to dynamically modify the floating point environment:. - ``#pragma STDC FENV_ACCESS ON`` allows dynamic changes to the entire floating; point envir",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:69226,configurat,configuration,69226,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['configurat'],['configuration']
Deployability," ``ttyname``, ``ttyname_r``, ``wctomb``, ``wcwidth``. Default sinks:; ``printf``, ``setproctitle``, ``system``, ``popen``, ``execl``, ``execle``,; ``execlp``, ``execv``, ``execvp``, ``execvP``, ``execve``, ``dlopen``,; ``memcpy``, ``memmove``, ``strncpy``, ``strndup``, ``malloc``, ``calloc``,; ``alloca``, ``memccpy``, ``realloc``, ``bcopy``. Please note that there are no built-in filter functions. One can configure their own taint sources, sinks, and propagation rules by; providing a configuration file via checker option; ``alpha.security.taint.TaintPropagation:Config``. The configuration file is in; `YAML <http://llvm.org/docs/YamlIO.html#introduction-to-yaml>`_ format. The; taint-related options defined in the config file extend but do not override the; built-in sources, rules, sinks. The format of the external taint configuration; file is not stable, and could change without any notice even in a non-backward; compatible way. For a more detailed description of configuration options, please see the; :doc:`user-docs/TaintAnalysisConfiguration`. For an example see; :ref:`clangsa-taint-configuration-example`. **Configuration**. * `Config` Specifies the name of the YAML configuration file. The user can; define their own taint sources and sinks. **Related Guidelines**. * `CWE Data Neutralization Issues; <https://cwe.mitre.org/data/definitions/137.html>`_; * `SEI Cert STR02-C. Sanitize data passed to complex subsystems; <https://wiki.sei.cmu.edu/confluence/display/c/STR02-C.+Sanitize+data+passed+to+complex+subsystems>`_; * `SEI Cert ENV33-C. Do not call system(); <https://wiki.sei.cmu.edu/confluence/pages/viewpage.action?pageId=87152177>`_; * `ENV03-C. Sanitize the environment when invoking external programs; <https://wiki.sei.cmu.edu/confluence/display/c/ENV03-C.+Sanitize+the+environment+when+invoking+external+programs>`_. **Limitations**. * The taintedness property is not propagated through function calls which are; unknown (or too complex) to the analyzer, unless there",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:73266,configurat,configuration,73266,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['configurat'],['configuration']
Deployability," a better style, improved index and several new chapters; (since 2002). **Bertrand Bellenot** has been developing and maintaining the Win32GDK; version of ROOT. Bertrand has also many other contributions like the; nice RootShower example (since 2001). **Valeriy Onoutchin** has been working on several ROOT packages, in; particular the graphics sub-system for Windows and the GUI Builder; (since 2000). **Gerri Ganis** has been working on the authentication procedures to; be used by the root daemons and the PROOF system (since 2002). **Maarten Ballintijn** (MIT) is one of the main developers of the; PROOF sub-system (since 1995). **Valeri Fine** (now at BNL) ported ROOT to Windows and contributed; largely to the 3-D graphics. He is currently working on the Qt layer; of ROOT (since 1995). **Victor Perevoztchikov** (BNL) worked on key elements of the I/O; system, in particular the improved support for STL collections; (1997-2001). **Nenad Buncic** developed the HTML documentation generation system; and integrated the X3D viewer inside ROOT (1995-1997). **Suzanne Panacek** was the author of the first version of this User's; Guide and very active in preparing tutorials and giving lectures about; ROOT (1999-2002). **Axel Naumann** has been developing further the HTML Reference Guide; and helps in porting ROOT under Windows (cygwin/gcc implementation); (since 2000). **Anna Kreshuk** has developed the Linear Fitter and Robust Fitter; classes as well as many functions in TMath, TF1, TGraph (since 2005). **Richard Maunder** has contributed to the GL viewer classes (since; 2004). **Timur Pocheptsov** has contributed to the GL viewer classes and GL; in pad classes (since 2004). **Sergei Linev** has developed the XML driver and the TSQLFile classes; (since 2003). **Stefan Roiser** has been contributing to the reflex and cintex; packages (since 2005). **Lorenzo Moneta** has been contributing the MathCore, MathMore,; Smatrix & Minuit2 packages (since 2005). **Wim Lavrijsen** is the a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Preface.md:3562,integrat,integrated,3562,documentation/users-guide/Preface.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Preface.md,1,['integrat'],['integrated']
Deployability," a shell on your local computer!; pod://dberzano@cloud-gw-213.to.infn.it [~] >. This shell runs on your local computer and it has the environment; properly set up. PoD and PROOF workflow; ----------------------. > The following operations are valid inside the `vaf-enter` environment. ### Start your PoD server. With PROOF on Demand, each user has the control of its own personal; PROOF cluster. The first thing to do is to start the PoD server and the; PROOF master like this:. vafctl --start. A successful output will be similar to:. ** Starting remote PoD server on dberzano@cloud-gw-213.to.infn.it:/cvmfs/sft.cern.ch/lcg/external/PoD/3.12/x86_64-slc5-gcc41-python24-boost1.53; ** Server is started. Use ""pod-info -sd"" to check the status of the server. ### Request and wait for workers. Now the server is started but you don't have any worker available. To; request for `<n>` workers, do:. vafreq <n>. To check how many workers became available for use:. pod-info -n. To continuously update the check (`Ctrl-C` to terminate):. vafcount. Example of output:. Updating every 5 seconds. Press Ctrl-C to stop monitoring...; [20130411-172235] 0; [20130411-172240] 0; [20130411-172245] 12; [20130411-172250] 12; ... To execute a command after a certain number of workers is available (in; the example we wait for 5 workers then start ROOT):. vafwait 5 && root -l. > Workers take some time before becoming available. Also, it is possible; > that not all the requested workers will be satisfied. ### Start ROOT and use PROOF. When you are satisfied with the available number of active workers, you; may start your PROOF analysis. Start ROOT, and from its prompt connect; to PROOF like this:. root [0] TProof::Open(""pod://"");. Example of output:. Starting master: opening connection ...; Starting master: OK; Opening connections to workers: OK (12 workers); Setting up worker servers: OK (12 workers); PROOF set to parallel mode (12 workers). ### Stop or restart your PoD cluster. At the end of your session",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:11129,continuous,continuously,11129,proof/doc/confman/UsingVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md,2,"['continuous', 'update']","['continuously', 'update']"
Deployability," actual; coordinates of the points around the contour, suitable for plotting with; a graphics routine or by hand (using MnPlot, see [api:plot]). The points; are given in counter-clockwise order around the contour. Only one; contour is calculated per command, and the level is; $\displaystyle F_{\mathrm{min}} + \mbox{up}$. where $\mbox{up}$; is the return value of FCNBase::up() specified by the user (usually 1.0; by default). The number of points to be calculated is chosen by the user; (default is 20). As a by-product, $\mbox{CONTOURS}$ provides the; $\mbox{MINOS}$ errors of the two parameters in question, since these; are just the extreme points of the contour (use the; MnContours::contour(...) method in order to get the points of the; contour and the ones of the $\mbox{MINOS}$ errors).; MnContours::operator() returns a; std::vector$<$std::pair$<$double,double$> >$ of (x,y) points. Using; MnPlot::operator() will generate a text graphics plot in the terminal. # M installation #. ## M releases ##. To follow the current release process the user is referred to the M; homepage @bib-C++MINUIT. M was re–implemented in from 2002–2004, but the functionality is largely; compatible with the one of the version. The usage is different in the; sense that the re–write from to was done by its signification and not; literally (with minor exceptions). Applications such as; $\mbox{MIGRAD}$ have a corresponding class MnMigrad, M ""commands""; became classes or methods of classes according to their purpose. Users; familiar with the version of M , who have not yet used releases from the; version, should however read this manual, in order to adapt to the; changes as well as to discover the new features and easier ways of using; old features. ## Install M using autoconf/make ##. For each release of M a tar.gz file is provided for downloading from the; M homepage @bib-C++MINUIT. For non-UNIX platforms please refer to the M; homepage. The necessary steps to follow are:. 1. download the tar.gz b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:21350,release,releases,21350,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['release'],['releases']
Deployability," add ``-fxray-instrument`` to the list of flags; passed to Clang when building a binary. Note that we need to link with Clang as; well to get the XRay runtime linked in appropriately. For building ``llc`` with; XRay, we do something similar below for our LLVM build:. ::. $ mkdir -p llvm-build && cd llvm-build; # Assume that the LLVM sources are at ../llvm; $ cmake -GNinja ../llvm -DCMAKE_BUILD_TYPE=Release \; -DCMAKE_C_FLAGS_RELEASE=""-fxray-instrument"" -DCMAKE_CXX_FLAGS=""-fxray-instrument"" \; # Once this finishes, we should build llc; $ ninja llc. To verify that we have an XRay instrumented binary, we can use ``objdump`` to; look for the ``xray_instr_map`` section. ::. $ objdump -h -j xray_instr_map ./bin/llc; ./bin/llc: file format elf64-x86-64. Sections:; Idx Name Size VMA LMA File off Algn; 14 xray_instr_map 00002fc0 00000000041516c6 00000000041516c6 03d516c6 2**0; CONTENTS, ALLOC, LOAD, READONLY, DATA. Getting Traces; --------------. By default, XRay does not write out the trace files or patch the application; before main starts. If we run ``llc`` it should work like a normally built; binary. If we want to get a full trace of the application's operations (of the; functions we do end up instrumenting with XRay) then we need to enable XRay; at application start. To do this, XRay checks the ``XRAY_OPTIONS`` environment; variable. ::. # The following doesn't create an XRay trace by default.; $ ./bin/llc input.ll. # We need to set the XRAY_OPTIONS to enable some features.; $ XRAY_OPTIONS=""patch_premain=true xray_mode=xray-basic verbosity=1"" ./bin/llc input.ll; ==69819==XRay: Log file in 'xray-log.llc.m35qPB'. At this point we now have an XRay trace we can start analysing. The ``llvm-xray`` Tool; ----------------------. Having a trace then allows us to do basic accounting of the functions that were; instrumented, and how much time we're spending in parts of the code. To make; sense of this data, we use the ``llvm-xray`` tool which has a few subcommands; to help us und",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:1594,patch,patch,1594,interpreter/llvm-project/llvm/docs/XRayExample.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst,1,['patch'],['patch']
Deployability," add_llvm_install_targets(install-llvm-libraries; DEPENDS llvm-libraries; COMPONENT llvm-libraries); endif(). get_property(LLVM_LIBS GLOBAL PROPERTY LLVM_LIBS); if(LLVM_LIBS); list(REMOVE_DUPLICATES LLVM_LIBS); foreach(lib ${LLVM_LIBS}); add_dependencies(llvm-libraries ${lib}); if (NOT LLVM_ENABLE_IDE); add_dependencies(install-llvm-libraries install-${lib}); add_dependencies(install-llvm-libraries-stripped install-${lib}-stripped); endif(); endforeach(); endif(); endif(). # This must be at the end of the LLVM root CMakeLists file because it must run; # after all targets are created.; llvm_distribution_add_targets(); process_llvm_pass_plugins(GEN_CONFIG); include(CoverageReport). # This allows us to deploy the Universal CRT DLLs by passing -DCMAKE_INSTALL_UCRT_LIBRARIES=ON to CMake; if (MSVC AND CMAKE_HOST_SYSTEM_NAME STREQUAL ""Windows"" AND CMAKE_INSTALL_UCRT_LIBRARIES); include(InstallRequiredSystemLibraries); endif(). if (LLVM_INCLUDE_BENCHMARKS); # Override benchmark defaults so that when the library itself is updated these; # modifications are not lost.; set(BENCHMARK_ENABLE_TESTING OFF CACHE BOOL ""Disable benchmark testing"" FORCE); set(BENCHMARK_ENABLE_EXCEPTIONS OFF CACHE BOOL ""Disable benchmark exceptions"" FORCE); set(BENCHMARK_ENABLE_INSTALL OFF CACHE BOOL ""Don't install benchmark"" FORCE); set(BENCHMARK_DOWNLOAD_DEPENDENCIES OFF CACHE BOOL ""Don't download dependencies"" FORCE); set(BENCHMARK_ENABLE_GTEST_TESTS OFF CACHE BOOL ""Disable Google Test in benchmark"" FORCE); set(BENCHMARK_ENABLE_WERROR ${LLVM_ENABLE_WERROR} CACHE BOOL; ""Handle -Werror for Google Benchmark based on LLVM_ENABLE_WERROR"" FORCE); # Since LLVM requires C++11 it is safe to assume that std::regex is available.; set(HAVE_STD_REGEX ON CACHE BOOL ""OK"" FORCE); add_subdirectory(${LLVM_THIRD_PARTY_DIR}/benchmark; ${CMAKE_CURRENT_BINARY_DIR}/third-party/benchmark); add_subdirectory(benchmarks); endif(). if (LLVM_INCLUDE_UTILS AND LLVM_INCLUDE_TOOLS); add_subdirectory(utils/llvm-locstats); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:54061,update,updated,54061,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,2,"['install', 'update']","['install', 'updated']"
Deployability," after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:359161,release,release,359161,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability," all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windows{{.*}}``; to match any Windows target triple). | ``REQUIRES`` enables the test if all expressions are true.; | ``UNSUPPORTED`` disables the test if any expression is true.; | ``XFAIL`` expects the test to fail if any expression is true. As a special case, ``XFAIL: *`` is expected to fail everywhere. .. code-block:: llvm. ; This test is disabled when ru",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:20461,configurat,configuration,20461,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['configurat'],['configuration']
Deployability," an HypoTestInverterResult class. The result is a SimpleInterval, which via the method UpperLimit returns to the user the upper limit value. The HypoTestInverter implements various option for performing the scan. HypoTestInverter::RunFixedScan will scan using a fixed grid the parameter of interest. HypoTestInverter::RunAutoScan will perform an automatic scan to find optimally the curve and it will stop when the desired precision is obtained.; The confidence level value at a given point can also be done via HypoTestInverter::RunOnePoint.; The class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been called).; The estimated error due to the MC toys statistics from the HybridCalculator is propagated into the limits obtained from the HypoTestResult; A new tutorial rs801_HypoTestInverter.C has been added in the tutorials/roostats directory to show the usage of this class. New class BayesianCalculator. New class for calculating Bayesian interval using numerical integration. It implements the IntervalCalculator interface and returns as result a SimpleInterval. . The BayesianCalculator::GetInterval() method returns a SimpleInterval which contains the lower and upper value of the bayesian interval obtained from the posterior probability for the given confidence level.; The class return also the posterior pdf (BayesianCalculator::GetPosteriorPdf()) obtained from integrating (marginalizing) on the nuisance parameters.; It works currently only for one-dimensional problems by relying on RooFit for performing analytical or numerical integration.; A plot of the posterior and the desired interval can be obtained using BayesianCalculator::GetPosteriorPlot().; A new tutorial rs701_BayesianCalculator.C has been added in the tutorials/roostats directory to show the usage of this class. MCMCCalculator. Add possibility to specify the prior function in the constructor of the class to have a signature similar to the BayesianCalculator c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:16009,integrat,integration,16009,roofit/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html,1,['integrat'],['integration']
Deployability," an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:219125,release,release,219125,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability," an extension of the functionality provided by the \ref MathCore. The; current set includes classes and functions for:. * \ref SpecFunc, with all the major functions (Bessel functions, Legendre polynomial, etc..); * \ref StatFunc, Mathematical functions used in statistics such as probability density; functions, cumulative distributions functions and their inverse (quantiles).; * Numerical algorithms:; * \ref Integration; * \ref MCIntegration; * \ref Deriv; * \ref RootFinders; * \ref Min1D; * \ref MultiMin; * \ref Interpolation; * \ref FuncApprox, based on Chebyshev polynomials; * \ref Random. The mathematical functions are implemented as a set of free functions in the namespace \em; ROOT::Math. The naming used for the special functions is the same proposed for the C++; standard (see C++ standard extension [proposal document](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1687.pdf)).; The MathMore library is implemented wrapping in C++ the GNU Scientific Library; ([GSL](http://www.gnu.org/software/gsl)). To build MathMore you need to have first GSL; installed somewhere in your system. A version of GSL larger or equal 1.8 is required. A tar; file of GSL can be downloaded from the [GSL Web site](http://www.gnu.org/software/gsl/#downloading),; or (for version 1.8) from [here](http://seal.web.cern.ch/seal/MathLibs/gsl-1.8.tar.gz).; Windows binaries, compiled using Visual Studio 7.1 can be downloaded from; [this location](http://seal.web.cern.ch/seal/MathLibs/GSL-1.8.zip). MathMore (and its %ROOT CINT dictionary) can be built within %ROOT whenever a GSL library; is found in the system. Optionally the GSL library and header file location can be specified; in the %ROOT configure script with _configure --with-gsl-incdir=... --with-gsl-libdir=..._; MathMore links with the GSL static libraries. On some platform (like Linux x86-64) GSL; needs to be compiled with the option _--with-pic_.; The source code of MathMore is distributed under the GNU General Public License; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/doc/index.md:1318,install,installed,1318,math/mathmore/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/doc/index.md,1,['install'],['installed']
Deployability," an unbalanced; release followed by a ""balancing"" retain. .. _arc.optimization.liveness:. Object liveness; ---------------. ARC may not allow a retainable object ``X`` to be deallocated at a; time ``T`` in a computation history if:. * ``X`` is the value stored in a ``__strong`` object ``S`` with; :ref:`precise lifetime semantics <arc.optimization.precise>`, or. * ``X`` is the value stored in a ``__strong`` object ``S`` with; imprecise lifetime semantics and, at some point after ``T`` but; before the next store to ``S``, the computation history features a; load from ``S`` and in some way depends on the value loaded, or. * ``X`` is a value described as being released at the end of the; current full-expression and, at some point after ``T`` but before; the end of the full-expression, the computation history depends; on that value. .. admonition:: Rationale. The intent of the second rule is to say that objects held in normal; ``__strong`` local variables may be released as soon as the value in; the variable is no longer being used: either the variable stops; being used completely or a new value is stored in the variable. The intent of the third rule is to say that return values may be; released after they've been used. A computation history depends on a pointer value ``P`` if it:. * performs a pointer comparison with ``P``,; * loads from ``P``,; * stores to ``P``,; * depends on a pointer value ``Q`` derived via pointer arithmetic; from ``P`` (including an instance-variable or field access), or; * depends on a pointer value ``Q`` loaded from ``P``. Dependency applies only to values derived directly or indirectly from; a particular expression result and does not occur merely because a; separate pointer value dynamically aliases ``P``. Furthermore, this; dependency is not carried by values that are stored to objects. .. admonition:: Rationale. The restrictions on dependency are intended to make this analysis; feasible by an optimizer with only incomplete information about ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:79547,release,released,79547,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['released']
Deployability," and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package manager of your distro, you can install the; packages required by CPT to build RPM bundles. For a Red Hat based distro; (which uses ```yum``` package manager), you can use the following command; (also performed automatically by CPT):; ```sh; sudo yum update; sudo yum install git gcc gcc-c++ rpm-build python; ```. #### Mac OS X; Mac OS X provides a sane environement for CPT to build Apple Disk Images; (DMG Installers). On older versions of Mac OS, you need to update XCode to; get the latest version of Clang supporting c++11 features. A great package; manager for Mac OS X is [Macports]. It is recommended that you use the; packages provided by Macports for running CPT (or any other tool if that; is the case) rather than the ones which come pre-installed with Mac OS.; Assuming that you have Macports installed on your Mac, you can use the; following command to install the requisite packages (also done automatically; by CPT):; [Macports]:http://www.macports.org/; ```sh; sudo port -v selfupdate; sudo port install git g++ python; ```. ### Usage; ```sh; cd tools/packaging/; ```. ```; usage: cpt.py [-h] [-c] [--current-dev CURRENT_DEV]; [--last-stable LAST_STABLE] [--tarball-tag TARBALL_TAG]; [--deb-tag DEB_TAG] [--rpm-tag RPM_TAG] [--nsis-tag NSIS_TAG]; [--dmg-tag DMG_TAG] [--with-llvm-url WITH_LLVM_URL]; [--with-clang-url WITH_CLANG_URL]; [--with-cling-url WITH_CLING_URL] [--no-test]; [--create-dev-env CREATE_DEV_ENV] [--with-workdir WITH_WORKDIR]; [--make-proper MAKE_PROPER]. Cling Packaging Tool. optional arguments:; -h, --help show this help message and exit; -c, --check-requirements; Check if packages required by the script are installed; --current-dev CURRENT_DEV; Package the latest development snapshot in one of; these formats: tar | deb | nsis | rpm | dmg | pkg; --last-stable LAST_STABLE; Package the last stable snapshot in one of the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:6016,install,installed,6016,interpreter/cling/tools/packaging/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md,2,['install'],"['install', 'installed']"
Deployability," and TAnnotation classes; 20. Implement moving and resizing of subpads; 21. Implement zooming in the TASImage; 22. Let configure position and direction of camera for TGeo, let create URL for that; 23. Support labels rotation for simple axis in geometry; 24. Support many orthographic cameras with overlayed grid/labels; 25. Support InstancedMesh for TGeo drawing, let show really large geometries; 26. Implement 'inject=path/script_name.js' url option to inject scripts without emulating of v6; 27. Exclude 'HEAD' http request when reading ROOT file, all necessary info can be get from first real HTTP request; 28. Provide makeImage function for generation of svg, png and jpeg images in batch and interactively (#257); 29. Implement interactive zoom shifting when middle-mouse button down or single-touch moving; 30. Several improvements for touch devices or devices with small displays; 31. Remove settings.FrameNDC, use Style.fPadLeft/Right/Top/BottomMargin values instead; 32. Fix - rescan sumw2 when update TH1; 33. Fix - correct placing for TLegend header; 34. Fix - correctly align sub/super scripts in complex TLatex; 35. Fix - correctly set visibility level for geo drawing (#258); 36. Fix - use more factor for number of nodes in geo drawing (#258). ## Changes in 7.3.4; 1. Fix - failure in normal_cdf calculation; 2. Fix - check in TTree::Draw for null buffer; 3. Fix - do not rise exception in treeProcess; 4. Fix - RH1 zero line drawing only when required; 5. Fix - do not allow move float browser too far left/top. ## Changes in 7.3.2; 1. Fix - undefined graph in TGraphPainter; 2. Fix - error in showing info in the geo painter; 3. Fix - stack limitation with Math.min.apply in tree draw. ## Changes in 7.3.1; 1. Fix - TGeo update in the TWebCanvas; 2. Fix - several tutorials with three.js modules loading; 3. Fix - redraw pad when change text align attributes; 4. Fix - pad ranges for TWebCanvas, handle log2 scales; 5. Fix - support candle and violin options when creating string dr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:14232,update,update,14232,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['update'],['update']
Deployability," and build LLVM and Clang:. * ``cd llvm-project``; * ``cmake -S llvm -B build -G <generator> [options]``. Some common build system generators are:. * ``Ninja`` --- for generating `Ninja <https://ninja-build.org>`_; build files. Most llvm developers use Ninja.; * ``Unix Makefiles`` --- for generating make-compatible parallel makefiles.; * ``Visual Studio`` --- for generating Visual Studio projects and; solutions.; * ``Xcode`` --- for generating Xcode projects. * See the `CMake docs; <https://cmake.org/cmake/help/latest/manual/cmake-generators.7.html>`_; for a more comprehensive list. Some common options:. * ``-DLLVM_ENABLE_PROJECTS='...'`` --- semicolon-separated list of the LLVM; subprojects you'd like to additionally build. Can include any of: clang,; clang-tools-extra, lldb, lld, polly, or cross-project-tests. For example, to build LLVM, Clang, and LLD, use; ``-DLLVM_ENABLE_PROJECTS=""clang;lld""``. * ``-DCMAKE_INSTALL_PREFIX=directory`` --- Specify for *directory* the full; pathname of where you want the LLVM tools and libraries to be installed; (default ``/usr/local``). * ``-DCMAKE_BUILD_TYPE=type`` --- Controls optimization level and debug; information of the build. Valid options for *type* are ``Debug``,; ``Release``, ``RelWithDebInfo``, and ``MinSizeRel``. For more detailed; information see :ref:`CMAKE_BUILD_TYPE <cmake_build_type>`. * ``-DLLVM_ENABLE_ASSERTIONS=ON`` --- Compile with assertion checks enabled; (default is ON for Debug builds, OFF for all other build types). * ``-DLLVM_USE_LINKER=lld`` --- Link with the `lld linker`_, assuming it; is installed on your system. This can dramatically speed up link times; if the default linker is slow. * ``-DLLVM_PARALLEL_{COMPILE,LINK}_JOBS=N`` --- Limit the number of; compile/link jobs running in parallel at the same time. This is; especially important for linking since linking can use lots of memory. If; you run into memory issues building LLVM, try setting this to limit the; maximum number of compile/link jobs ru",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:2858,install,installed,2858,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['install'],['installed']
Deployability," and ensure that it is up; to date. The ""Release Notes"" must be updated to reflect new features, bug; fixes, new known issues, and changes in the list of supported platforms.; The ""Getting Started Guide"" should be updated to reflect the new release; version number tag available from Subversion and changes in basic system; requirements. .. _tag:. Tag the LLVM Final Release; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Tag the final release sources:. ::. $ git tag -sa llvmorg-X.Y.Z; $ git push https://github.com/llvm/llvm-project.git llvmorg-X.Y.Z. Update the LLVM Website; ^^^^^^^^^^^^^^^^^^^^^^^. The website must be updated before the release announcement is sent out. Here; is what to do:. #. Check out the ``www-releases`` module from GitHub. #. Create a new sub-directory ``X.Y.Z`` in the releases directory. #. Copy and commit the ``llvm/docs`` and ``LICENSE.txt`` files into this new; directory. #. Update the ``releases/download.html`` file with links to the release; binaries on GitHub. #. Update the ``releases/index.html`` with the new release and link to release; documentation. #. After you push the changes to the www-releases repo, someone with admin; access must login to prereleases-origin.llvm.org and manually pull the new; changes into /data/www-releases/. This is where the website is served from. #. Finally checkout the llvm-www repo and update the main page; (``index.html`` and sidebar) to point to the new release and release; announcement. Announce the Release; ^^^^^^^^^^^^^^^^^^^^. Create a new post in the `Announce Category <https://discourse.llvm.org/c/announce>`_; once all the release tasks are complete. For X.1.0 releases, make sure to include a; link to the release notes in the post. For X.1.1+ releases, generate a changelog; using this command and add it to the post. ::. $ git log --format=""- %aN: [%s (%h)](https://github.com/llvm/llvm-project/commit/%H)"" llvmorg-X.1.N-1..llvmorg-X.1.N. Once the release has been announced add a link to the announcement on the llvm; hom",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:14991,release,releases,14991,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['release'],['releases']
Deployability," approach:; * It is not preventing any particular side-channel from working. This is; important as there are an unknown number of potential side channels and we; expect to continue discovering more. Instead, it prevents the observation of; secret data in the first place.; * It accumulates the predicate state, protecting even in the face of nested; *correctly* predicted control flows.; * It passes this predicate state across function boundaries to provide; [interprocedural protection](#interprocedural-checking).; * When hardening the address of a load, it uses a *destructive* or; *non-reversible* modification of the address to prevent an attacker from; reversing the check using attacker-controlled inputs.; * It does not completely block speculative execution, and merely prevents; *mis*-speculated paths from leaking secrets from memory (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/H",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:6166,update,updates,6166,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['update'],['updates']
Deployability," approaches have typically been seen as a ; tradeoff between performance and portability. On a deeper level, however, ; there are two reasons that optimal system performance may be obtained by a; system somewhere in between these two extremes: Dynamic application ; behavior and social constraints. From a technical perspective, pure static compilation cannot ever give ; optimal performance in all cases, because applications have varying dynamic; behavior that the static compiler cannot take into consideration. Even ; compilers that support profile guided optimization generate poor code in ; the real world, because using such optimization tunes that application ; to one particular usage pattern, whereas real programs (as opposed to ; benchmarks) often have several different usage patterns. On a social level, static compilation is a very shortsighted solution to ; the performance problem. Instruction set architectures (ISAs) continuously ; evolve, and each implementation of an ISA (a processor) must choose a set ; of tradeoffs that make sense in the market context that it is designed for. ; With every new processor introduced, the vendor faces two fundamental ; problems: First, there is a lag time between when a processor is introduced ; to when compilers generate quality code for the architecture. Secondly, ; even when compilers catch up to the new architecture there is often a large ; body of legacy code that was compiled for previous generations and will ; not or can not be upgraded. Thus a large percentage of code running on a ; processor may be compiled quite sub-optimally for the current ; characteristics of the dynamic execution environment. For these reasons, LLVM has been designed from the beginning as a long-term ; solution to these problems. Its design allows the large body of platform ; independent, static, program optimizations currently in compilers to be ; reused unchanged in their current form. It also provides important static ; type information to ena",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-04-16-DynamicCompilation.txt:1783,continuous,continuously,1783,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-04-16-DynamicCompilation.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-04-16-DynamicCompilation.txt,1,['continuous'],['continuously']
Deployability," are already using the module):. .. code-block:: console. % mount -t binfmt_misc none /proc/sys/fs/binfmt_misc; % echo ':llvm:M::BC::/path/to/lli:' > /proc/sys/fs/binfmt_misc/register; % chmod u+x hello.bc (if needed); % ./hello.bc. This allows you to execute LLVM bitcode files directly. On Debian, you can also; use this command instead of the 'echo' command above:. .. code-block:: console. % sudo update-binfmts --install llvm /path/to/lli --magic 'BC'. .. _Program Layout:; .. _general layout:. Directory Layout; ================. One useful source of information about the LLVM source base is the LLVM `doxygen; <http://www.doxygen.org/>`_ documentation available at; `<https://llvm.org/doxygen/>`_. The following is a brief introduction to code; layout:. ``llvm/cmake``; --------------; Generates system build files. ``llvm/cmake/modules``; Build configuration for llvm user defined options. Checks compiler version and; linker flags. ``llvm/cmake/platforms``; Toolchain configuration for Android NDK, iOS systems and non-Windows hosts to; target MSVC. ``llvm/examples``; -----------------. - Some simple examples showing how to use LLVM as a compiler for a custom; language - including lowering, optimization, and code generation. - Kaleidoscope Tutorial: Kaleidoscope language tutorial run through the; implementation of a nice little compiler for a non-trivial language; including a hand-written lexer, parser, AST, as well as code generation; support using LLVM- both static (ahead of time) and various approaches to; Just In Time (JIT) compilation.; `Kaleidoscope Tutorial for complete beginner; <https://llvm.org/docs/tutorial/MyFirstLanguageFrontend/index.html>`_. - BuildingAJIT: Examples of the `BuildingAJIT tutorial; <https://llvm.org/docs/tutorial/BuildingAJIT1.html>`_ that shows how LLVM’s; ORC JIT APIs interact with other parts of LLVM. It also, teaches how to; recombine them to build a custom JIT that is suited to your use-case. ``llvm/include``; ----------------. Public he",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:34334,configurat,configuration,34334,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['configurat'],['configuration']
Deployability," are only; intended for use with ``conda-build``.; In particular, the corresponding run-time is installed (for use through rpath; when building), but not set up.; That is, the conda compilers are added to ``PATH`` but not their libraries; to ``LD_LIBRARY_PATH`` (Mac, Linux; ``PATH`` for both on MS Windows).; Thus, you get the conda compilers and your system libraries mixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PREFIX/lib``.; Note that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been modified, which can can lead to parsing problems if; your system C library does not support C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard with pip; ---------------------. The C++20 standard is the default on all systems as of release 3.0.1 (both; PyPI and conda-forge); it is C++17 for older releases.; When installing from PyPI using ``pip``, you can control the standard; selection by setting the ``STDCXX`` envar to '20', '17', or '14' (for Linux,; the backend does not need to be recompiled) for the 3.x releases; '17', '14',; or '11' for the 2.x releases.; Note that the build will automatically lower your choice if the compiler used; does not support a newer standard. Install from source; -------------------; .. _installation_from_source:. To build an existing release from source, tell ``pip`` to not download any; binary wheels.; Build-time only dependencies are ``cmake`` (for general build), ``python``; (obviously, but also for LLVM), and a modern C++ compiler (one that supports; at least C++14).; Use the envar ``STD",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:4648,install,install,4648,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,3,['install'],['install']
Deployability," are taken to be the token contents.; 3. If the `XDG_RUNTIME_DIR` environment variable is set, then take the token from the contents of `$XDG_RUNTIME_DIR/bt_u$ID`(this additional location is intended to provide improved security for shared login environments as `$XDG_RUNTIME_DIR` is defined to be user-specific as opposed to a system-wide directory.).; 4. Otherwise, take the token from `/tmp/bt_u$ID`. ## GUI Libraries. ### RBrowser improvements. - central factory methods to handle browsing, editing and drawing of different classes; - simple possibility to extend RBrowser on user-defined classes; - support of web-based geometry viewer; - better support of TTree drawing; - server-side handling of code editor and image viewer widgets; - rbrowser content is fully recovered when web-browser is reloaded; - load of widgets code only when really required (shorter startup time for RBrowser). ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ## JavaScript ROOT. ### Major JSROOT update to version 6. - update all used libraries `d3.js`, `three.js`, `MathJax.js`, openui5; - change to Promise based interface for all async methods, remove call-back arguments; - change scripts names, core scripts name now `JSRoot.core.js`; - unify function/methods naming conventions, many changes in method names; - provide central code loader via `JSROOT.require`, supporting 4 different loading engines; - many nice features and many bug fixes; see JSROOT v6 release notes. ## Tutorials. ## Class Reference Guide. ## Build, Configuration and Testing Infrastructure. - a new cmake variable, `CMAKE_INSTALL_PYTHONDIR`, has been added: it allows customization of the installation directory of ROOT's python modules; - the developer build option `asserts` is introduced to enable/disable asserts via the `NDEBUG` C/CXX flag. Asserts are always enabled for `CMAKE_BUILD_TYPE=Debug` and `dev=ON`. The previous behavior of the builds set via the `CMAKE_BUILD_TYPE` variable has not changed.; - `CMAKE_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:27370,update,update,27370,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['update'],['update']
Deployability," are useful during development, it is often more useful to; refer to optimization remarks post-compilation, typically during performance; analysis. For that, LLVM can serialize the remarks produced for each compilation unit to; a file that can be consumed later. By default, the format of the serialized remarks is :ref:`YAML; <yamlremarks>`, and it can be accompanied by a :ref:`section <remarkssection>`; in the object files to easily retrieve it. :doc:`llc <CommandGuide/llc>` and :doc:`opt <CommandGuide/opt>` support the; following options:. ``Basic options``. .. option:: -pass-remarks-output=<filename>. Enables the serialization of remarks to a file specified in <filename>. By default, the output is serialized to :ref:`YAML <yamlremarks>`. .. option:: -pass-remarks-format=<format>. Specifies the output format of the serialized remarks. Supported formats:. * :ref:`yaml <yamlremarks>` (default); * :ref:`yaml-strtab <yamlstrtabremarks>`; * :ref:`bitstream <bitstreamremarks>`. ``Content configuration``. .. option:: -pass-remarks-filter=<regex>. Only passes whose name match the given (POSIX) regular expression will be; serialized to the final output. .. option:: -pass-remarks-with-hotness. With PGO, include profile count in optimization remarks. .. option:: -pass-remarks-hotness-threshold. The minimum profile count required for an optimization remark to be; emitted. Other tools that support remarks:. :program:`llvm-lto`. .. option:: -lto-pass-remarks-output=<filename>; .. option:: -lto-pass-remarks-filter=<regex>; .. option:: -lto-pass-remarks-format=<format>; .. option:: -lto-pass-remarks-with-hotness; .. option:: -lto-pass-remarks-hotness-threshold. :program:`gold-plugin` and :program:`lld`. .. option:: -opt-remarks-filename=<filename>; .. option:: -opt-remarks-filter=<regex>; .. option:: -opt-remarks-format=<format>; .. option:: -opt-remarks-with-hotness. Serialization modes; ===================. There are two modes available for serializing remarks:. ``Separate``. In ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst:2958,configurat,configuration,2958,interpreter/llvm-project/llvm/docs/Remarks.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst,1,['configurat'],['configuration']
Deployability," are; neither persistent for the same loop through transformations nor; necessarily unique to just one loop. '``llvm.loop.disable_nonforced``'; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This metadata disables all optional loop transformations unless; explicitly instructed using other transformation metadata such as; ``llvm.loop.unroll.enable``. That is, no heuristic will try to determine; whether a transformation is profitable. The purpose is to avoid that the; loop is transformed to a different loop before an explicitly requested; (forced) transformation is applied. For instance, loop fusion can make; other transformations impossible. Mandatory loop canonicalizations such; as loop rotation are still applied. It is recommended to use this metadata in addition to any llvm.loop.*; transformation directive. Also, any loop should have at most one; directive applied to it (and a sequence of transformations built using; followup-attributes). Otherwise, which transformation will be applied; depends on implementation details such as the pass pipeline order. See :ref:`transformation-metadata` for details. '``llvm.loop.vectorize``' and '``llvm.loop.interleave``'; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Metadata prefixed with ``llvm.loop.vectorize`` or ``llvm.loop.interleave`` are; used to control per-loop vectorization and interleaving parameters such as; vectorization width and interleave count. These metadata should be used in; conjunction with ``llvm.loop`` loop identification metadata. The; ``llvm.loop.vectorize`` and ``llvm.loop.interleave`` metadata are only; optimization hints and the optimizer will only interleave and vectorize loops if; it believes it is safe to do so. The ``llvm.loop.parallel_accesses`` metadata; which contains information about loop-carried memory dependencies can be helpful; in determining the safety of these transformations. '``llvm.loop.interleave.count``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This metadata suggests an ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:295936,pipeline,pipeline,295936,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['pipeline'],['pipeline']
Deployability," arr = [ 1, 2, 3 ]; vs. var arr = [1, 2, 3];; f({a : 1, b : 2, c : 3}); f({a: 1, b: 2, c: 3});. .. _SpacesInLineCommentPrefix:. **SpacesInLineCommentPrefix** (``SpacesInLineComment``) :versionbadge:`clang-format 13` :ref:`¶ <SpacesInLineCommentPrefix>`; How many spaces are allowed at the start of a line comment. To disable the; maximum set it to ``-1``, apart from that the maximum takes precedence; over the minimum. .. code-block:: c++. Minimum = 1; Maximum = -1; // One space is forced. // but more spaces are possible. Minimum = 0; Maximum = 0; //Forces to start every comment directly after the slashes. Note that in line comment sections the relative indent of the subsequent; lines is kept, that means the following:. .. code-block:: c++. before: after:; Minimum: 1; //if (b) { // if (b) {; // return true; // return true;; //} // }. Maximum: 0; /// List: ///List:; /// - Foo /// - Foo; /// - Bar /// - Bar. This option has only effect if ``ReflowComments`` is set to ``true``. Nested configuration flags:. Control of spaces within a single line comment. * ``unsigned Minimum`` The minimum number of spaces at the start of the comment. * ``unsigned Maximum`` The maximum number of spaces at the start of the comment. .. _SpacesInParens:. **SpacesInParens** (``SpacesInParensStyle``) :versionbadge:`clang-format 17` :ref:`¶ <SpacesInParens>`; Defines in which cases spaces will be inserted after ``(`` and before; ``)``. Possible values:. * ``SIPO_Never`` (in configuration: ``Never``); Never put a space in parentheses. .. code-block:: c++. void f() {; if(true) {; f();; }; }. * ``SIPO_Custom`` (in configuration: ``Custom``); Configure each individual space in parentheses in; `SpacesInParensOptions`. .. _SpacesInParensOptions:. **SpacesInParensOptions** (``SpacesInParensCustom``) :versionbadge:`clang-format 17` :ref:`¶ <SpacesInParensOptions>`; Control of individual spaces in parentheses. If ``SpacesInParens`` is set to ``Custom``, use this to specify; how each individual space in par",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:125774,configurat,configuration,125774,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," as separate efforts to integrate LLVM development with local practices. It is the responsibility of each sub-community to care about their own parts; and the intersection of that with the core tier and other peripheral parts. There are three main groups of code that fit in this category:; * Code that is making its way into LLVM, via the `experimental <https://llvm.org/docs/DeveloperPolicy.html#introducing-new-components-into-llvm>`_; roadmap or similar efforts.; * Code that is making its way out of LLVM, via deprecation, replacement or; bit-rot, and will be removed if the sub-community that cares about it; cannot maintain it.; * Code that isn't meant to be in LLVM core and can coexist with the code in; the core tier (and others in the peripheral tier) long term, without causing; breakages or disturbances. What is covered; ---------------. The peripheral tier is composed of:; * Experimental targets and options that haven't been enable by default yet.; * Main repository projects that don't get released or regularly tested.; * Legacy tools and scripts that aren't used in upstream validation.; * Alternative build systems (ex. GN, Bazel) and related infrastructure.; * Tools support (ex. gdb scripts, editor configuration, helper scripts). Requirements; ------------. Code in this tier must:; * Have a clear benefit for residing in the main repository, catering to an; active sub-community (upstream or downstream).; * Be actively maintained by such sub-community and have its problems addressed; in a timely manner. Code in this tier must **not**:; * Break or invalidate core tier code or infrastructure. If that happens; accidentally, reverting functionality and working on the issues offline; is the only acceptable course of action.; * Negatively affect development of core tier code, with the sub-community; involved responsible for making changes to address specific concerns.; * Negatively affect other peripheral tier code, with the sub-communities; involved tasked to resolve th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:4480,release,released,4480,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst,1,['release'],['released']
Deployability," attributes - to proxy requests to the relevant; ""config owner"" in a timely manner. Most issues with a buildbot should be addressed directly with a bot owner; via email. Please CC `Galina Kistanova <mailto:gkistanova@gmail.com>`_. Steps To Add Builder To LLVM Buildbot; =====================================; Volunteers can provide their build machines to work as build workers to; public LLVM Buildbot. Here are the steps you can follow to do so:. #. Check the existing build configurations to make sure the one you are; interested in is not covered yet or gets built on your computer much; faster than on the existing one. We prefer faster builds so developers; will get feedback sooner after changes get committed. #. The computer you will be registering with the LLVM buildbot; infrastructure should have all dependencies installed and be able to; build your configuration successfully. Please check what degree; of parallelism (-j param) would give the fastest build. You can build; multiple configurations on one computer. #. Install buildbot-worker (currently we are using buildbot version 2.8.4).; This specific version can be installed using ``pip``, with a command such; as ``pip3 install buildbot-worker==2.8.4``. #. Create a designated user account, your buildbot-worker will be running under,; and set appropriate permissions. #. Choose the buildbot-worker root directory (all builds will be placed under; it), buildbot-worker access name and password the build master will be using; to authenticate your buildbot-worker. #. Create a buildbot-worker in context of that buildbot-worker account. Point it; to the **lab.llvm.org** port **9994** (see `Buildbot documentation,; Creating a worker; <http://docs.buildbot.net/current/tutorial/firstrun.html#creating-a-worker>`_; for more details) by running the following command:. .. code-block:: bash. $ buildbot-worker create-worker <buildbot-worker-root-directory> \; lab.llvm.org:9994 \; <buildbot-worker-access-name> \; <buildbot-worker-ac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:2989,configurat,configurations,2989,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['configurat'],['configurations']
Deployability," avoid bias. Those two datasets; can be built aside and then given to the network, or can be built from; a standard expression. By default, half of the events are put in both; datasets. ``` {.cpp}; // a more complex 4:8:1 network; // the ptsumf branch is used as weigh;; // default event lists are explicit; TMultiLayerPerceptron network(""m,pt,acol,acopl:8:type"",""pt"",tree,; ""Entry$%2"",""Entry$/2"");; ```. The method `TMultiLayerPerceptron::SetLearningMethod()` defines the; learning method. Learning methods are:. ```; TMultiLayerPerceptron::kStochastic,; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS // default; ```. The training can start with; `TMultiLayerPerceptron::Train(Int_t nepoch,Option_t* options).` The; first argument is the number of epochs while option is a string that; can contain ""`text`"" (simple text output), ""`graph`"" (evaluating; graphical training curves), ""`update` `=` `X`"" (step for the; text/graph output update) or ""`+`"" (will skip the randomization and; start from the previous values). All combinations are available. ``` {.cpp}; network.Train(1000,""text,graph,update=10""); // full output every; // 10 epochs; network.Train(100,""text,+""); // 100 more epochs; //starts with existing weights; ```. The weights can be saved to a file (`DumpWeights`) and then reloaded; (`LoadWeights`) to a new compatible network. The output can also be; evaluated (`Evaluate`) for a given output neuron and an array of; double input parameters or the network can be exported (`Export`) as a; standalone code. Up to now, this is only as a C++ or PYTHON class, but; other languages could be implemented. ### Examples. An example of how to use **`TMultiLayerPerceptron`** is the macro; `mlpHiggs.C` in \$ROOTSYS/tutorials. Using some standard simulated; information that could have been obtained at `LEP`, a neural network; is build, which can make the d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:76798,update,update,76798,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,2,['update'],['update']
Deployability," back to source line locations. .. code-block:: console. $ clang++ -O2 -gline-tables-only code.cc -o code. 2. Run the executable under a sampling profiler. The specific profiler; you use does not really matter, as long as its output can be converted; into the format that the LLVM optimizer understands. Currently, there; exists a conversion tool for the Linux Perf profiler; (https://perf.wiki.kernel.org/), so these examples assume that you; are using Linux Perf to profile your code. .. code-block:: console. $ perf record -b ./code. Note the use of the ``-b`` flag. This tells Perf to use the Last Branch; Record (LBR) to record call chains. While this is not strictly required,; it provides better call information, which improves the accuracy of; the profile data. 3. Convert the collected profile data to LLVM's sample profile format.; This is currently supported via the AutoFDO converter ``create_llvm_prof``.; It is available at https://github.com/google/autofdo. Once built and; installed, you can convert the ``perf.data`` file to LLVM using; the command:. .. code-block:: console. $ create_llvm_prof --binary=./code --out=code.prof. This will read ``perf.data`` and the binary file ``./code`` and emit; the profile data in ``code.prof``. Note that if you ran ``perf``; without the ``-b`` flag, you need to use ``--use_lbr=false`` when; calling ``create_llvm_prof``. Alternatively, the LLVM tool ``llvm-profgen`` can also be used to generate; the LLVM sample profile:. .. code-block:: console. $ llvm-profgen --binary=./code --output=code.prof--perfdata=perf.data. 4. Build the code again using the collected profile. This step feeds; the profile back to the optimizers. This should result in a binary; that executes faster than the original one. Note that you are not; required to build the code with the exact same arguments that you; used in the first step. The only requirement is that you build the code; with ``-gline-tables-only`` and ``-fprofile-sample-use``. .. code-block:: conso",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:93979,install,installed,93979,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['install'],['installed']
Deployability," backslash to ""escape""; a special character, which is the convention used by GNU Make. The -MV; option tells Clang to put double-quotes around the entire filename, which; is the convention used by NMake and Jom. .. option:: -femit-dwarf-unwind=<value>. When to emit DWARF unwind (EH frame) info. This is a Mach-O-specific option. Valid values are:. * ``no-compact-unwind`` - Only emit DWARF unwind when compact unwind encodings; aren't available. This is the default for arm64.; * ``always`` - Always emit DWARF unwind regardless.; * ``default`` - Use the platform-specific default (``always`` for all; non-arm64-platforms). ``no-compact-unwind`` is a performance optimization -- Clang will emit smaller; object files that are more quickly processed by the linker. This may cause; binary compatibility issues on older x86_64 targets, however, so use it with; caution. .. _configuration-files:. Configuration files; -------------------. Configuration files group command-line options and allow all of them to be; specified just by referencing the configuration file. They may be used, for; example, to collect options required to tune compilation for particular; target, such as ``-L``, ``-I``, ``-l``, ``--sysroot``, codegen options, etc. Configuration files can be either specified on the command line or loaded; from default locations. If both variants are present, the default configuration; files are loaded first. The command line option ``--config=`` can be used to specify explicit; configuration files in a Clang invocation. If the option is used multiple times,; all specified files are loaded, in order. For example:. ::. clang --config=/home/user/cfgs/testing.txt; clang --config=debug.cfg --config=runtimes.cfg. If the provided argument contains a directory separator, it is considered as; a file path, and options are read from that file. Otherwise the argument is; treated as a file name and is searched for sequentially in the directories:. - user directory,; - system directory,; - th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:30663,configurat,configuration,30663,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['configurat'],['configuration']
Deployability," bar(const std::unique_ptr<int> &x);. void foo(std::unique_ptr<int> &x) {; int *a = x.get(); // (a, 0, direct): &AbstractStorageRegion; *a = 1; // (AbstractStorageRegion, 0, direct): 1 S32b; int *b = new int;; *b = 2; // (SymRegion{conj_$0<int *>}, 0 ,direct): 2 S32b; x.reset(b); // Checker map: x -> SymRegion{conj_$0<int *>}; bar(x); // 'a' doesn't escape (the pointer was unique), 'b' does.; clang_analyzer_eval(*a == 1); // Making this true is up to the checker.; clang_analyzer_eval(*b == 2); // Making this unknown is up to the checker.; }. The checker doesn't totally need to ensure that ``*a == 1`` passes - even though the; pointer was unique, it could theoretically have ``.get()``-ed above and the code; could of course break the uniqueness invariant (though we'd probably want it).; The checker can say that ""even if ``*a`` did escape, it was not because it was; stuffed directly into bar()"". The checker's direct responsibility, however, is to solve the ``*b == 2`` thing; (which is in fact the problem we're dealing with in this patch - escaping the; storage region of the object). So we're talking about one more operation over the program state (scanning; reachable symbols and regions) that cannot work without checker support. We can probably add a new callback ""checkReachableSymbols"" to solve this. This; is in fact also related to the dead symbols problem (we're scanning for live; symbols in the store and in the checkers separately, but we need to do so; simultaneously with a single worklist). Hmm, in fact this sounds like a good; idea; we can replace checkLiveSymbols with checkReachableSymbols. Or we could just have ghost member variables, and no checker support required at; all. For ghost member variables, the relation with their parent region (which; would be their superregion) is actually useful, the mutability of their contents; is expressed naturally, and the store automagically sees reachable symbols, live; symbols, escapes, invalidations, whatever. > In my vi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst:12988,patch,patch,12988,interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,1,['patch'],['patch']
Deployability," be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; the surrounding code to prove that the flags are not in fact alive or being; used. Typically, it has been set by some other instruction which just happens; to set the flags register (much like ours!) with no actual dependency. In those; cases, it is safe to directly insert these instructions. Alternatively we may; be able to move them earlier to avoid clobbering the used value. However, this may ultimately be impossible. In that case, we need to preserve; the flags around these instructions:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; pushfq; orq %rax, %rcx # Mask the pointer if misspeculating.; orq %rax, %rdx # Mask the index if misspeculating.; popfq; movl (%rcx,%rdx), %edi; ```. Using the `pushf` and `popf` instructions saves the flags register around our; inserted code, but comes at a high cost. First, we must store the flags to the; stack and reload them. Second, this causes the stack pointer to be adjusted; dynamically, requiring a frame pointer be used for referring to temporaries; spilled to the stack, etc. On newer x86 processors we can use the `lahf` and `sahf` instructions to save; all of the flags besides the overflow flag in a register rather than on the; stack. We can then use `seto` and `add` to save and restore the overflow flag; in a register. Combined, this will save and restore flags in the same manner as; above but using two registers rather than the stack. That is still very; expensive if slightly less expensive than `pushf` and `popf` in most cases. #####",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:32464,update,update,32464,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['update'],['update']
Deployability," be built in such a way that; they will always be treated as being ""system frameworks"", even if they are not; present in a system framework directory. This can be useful to system; framework developers who want to be able to test building other applications; with development builds of their framework, including the manner in which the; compiler changes warning behavior for system headers. Framework developers can opt-in to this mechanism by creating a; ""``.system_framework``"" file at the top-level of their framework. That is, the; framework should have contents like:. .. code-block:: none. .../TestFramework.framework; .../TestFramework.framework/.system_framework; .../TestFramework.framework/Headers; .../TestFramework.framework/Headers/TestFramework.h; ... Clang will treat the presence of this file as an indicator that the framework; should be treated as a system framework, regardless of how it was found in the; framework search path. For consistency, we recommend that such files never be; included in installed versions of the framework. Checks for Standard Language Features; =====================================. The ``__has_feature`` macro can be used to query if certain standard language; features are enabled. The ``__has_extension`` macro can be used to query if; language features are available as an extension when compiling for a standard; which does not provide them. The features which can be tested are listed here. Since Clang 3.4, the C++ SD-6 feature test macros are also supported.; These are macros with names of the form ``__cpp_<feature_name>``, and are; intended to be a portable way to query the supported features of the compiler.; See `the C++ status page <https://clang.llvm.org/cxx_status.html#ts>`_ for; information on the version of SD-6 supported by each Clang release, and the; macros provided by that revision of the recommendations. C++98; -----. The features listed below are part of the C++98 standard. These features are; enabled by default when com",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:38553,install,installed,38553,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['install'],['installed']
Deployability," be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if that person hasn't done so yet. Note that, if a reviewer has requested a particular community member to review,; and after a week that community member has yet to respond, feel free to ping; the patch (which literally means submitting a comment on the patch with the; word, ""Ping.""), or alternatively, ask the original reviewer for further; suggestions. If it is likely that others will want to review a recently-posted patch,; especially if there might be objections, but no one else has done so yet, it is; also polite to provide a qualified approval (e.g., ""LGTM, but please wait for a; couple of days in case others wish to review""). If approval is received very; quickly, a patch author may also elect to wait before committing (and this is; certainly considered polite for non-trivial patches). Especially given the; global nature of our community, this waiting time should be at least 24 hours.; Please also be mindful of weekends and major holidays. Our goal is to ensure community consensus around design decisions and; significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is to be reasonably sure that such; consensus exists. If you're not familiar enough with the community to know,; then you shouldn't be providing final approval to commit. A reviewer providing; final approval should have commit access to the LLVM project. Every patch should be reviewed by at least one technical expert in the areas of; the project affected by the change. Splitting Requests and Conditional Acceptance; ---------------------------------------------. Reviewers may request certain aspects of a patch to be broken out into separate; patches for independ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:7924,patch,patch,7924,interpreter/llvm-project/llvm/docs/CodeReview.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst,2,['patch'],"['patch', 'patches']"
Deployability," be used in the; compiler environment of your choice. The main difference with respect; the Module.mk build is that the build is done out of the source tree,; which allows several build configurations in parallel (debug,; non-debug, optional components, etc.).  The main advantage; with respect the standard build system is that for the Windows platform; it does not require the installaton of CygWin.; Here are the basic instructions: . mkdir <builddir>   # create a empty directory in which CMake will put temporary and binary files; cd <builddir>; cmake [options] <rootsources> # by default it will generate a Makefile (or NMake file on Windows); make [options] # you can use any standard make options (e.g. -jN); make install # installation to the source tree by default, use CMAKE_INSTALL_PREFIX to change it. The CMake options and parameters can be viewed using the ccmake utility (cmake-gui for Windows). Here is a quick summary of them:. -DCMAKE_INSTALL_PREFIX=<installdir> # installation prefix; -Dxxxx=ON -Dyyyy=OFF # Optional ROOT components (e.g. tmva, mathcode, gdml, etc.); -DGIF_INCLUDE_DIR=/usr/include # Specify locations for external libraries and packages; -DGIF_LIBRARY=/usr/lib64/libgif.so ; -G <generator name> # E.g. ""XCode"", ""Eclipse CDT4 - Unix Makefiles"", ""Visual Studio 9 2008",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v530/index.html:5354,install,installdir,5354,core/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v530/index.html,2,['install'],"['installation', 'installdir']"
Deployability," before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:220326,release,release,220326,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability," between vector memory operations of different wavefronts. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L1 caches use an L2 cache shared by all SAs on the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each L1 quadrant of a single SA accesses a different L2 channel. Each L1; quadrant has a separate request queue per L2 channel. Therefore, the vector; and scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different SAs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0) & vscnt(0)`` is; required to ensure synchronization between vector memory operations of; different SAs. It ensures a previous vector memory operation has completed; before executing a subsequent vector memory and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence.; * On GFX10.3 and GFX11 a memory attached last level (MALL) cache exists for GPU memory.; The MALL cache is fully coherent with GPU memory and has no impact on system; coherence. All agents (GPU and CPU) access GPU memory through the MALL cache. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between k",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:339524,release,release,339524,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability," break;; }; }; } while (--i);; return true;; } catch (...) {; handleError();; return false;; }; }. void foo(bool b); {; if (b) {; baz(2);; } else {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_Custom`` (in configuration: ``Custom``); Configure each individual brace in ``BraceWrapping``. .. _BreakBeforeConceptDeclarations:. **BreakBeforeConceptDeclarations** (``BreakBeforeConceptDeclarationsStyle``) :versionbadge:`clang-format 12` :ref:`¶ <BreakBeforeConceptDeclarations>`; The concept declaration style to use. Possible values:. * ``BBCDS_Never`` (in configuration: ``Never``); Keep the template declaration line together with ``concept``. .. code-block:: c++. template <typename T> concept C = ...;. * ``BBCDS_Allowed`` (in configuration: ``Allowed``); Breaking between template declaration and ``concept`` is allowed. The; actual behavior depends on the content and line breaking rules and; penalties. * ``BBCDS_Always`` (in configuration: ``Always``); Always break before ``concept``, putting it in the line after the; template declaration. .. code-block:: c++. template <typename T>; concept C = ...;. .. _BreakBeforeInlineASMColon:. **BreakBeforeInlineASMColon** (``BreakBeforeInlineASMColonStyle``) :versionbadge:`clang-format 16` :ref:`¶ <BreakBeforeInlineASMColon>`; The inline ASM colon style to use. Possible values:. * ``BBIAS_Never`` (in configuration: ``Never``); No break before inline ASM colon. .. code-block:: c++. asm volatile(""string"", : : val);. * ``BBIAS_OnlyMultiline`` (in configuration: ``OnlyMultiline``); Break before inline ASM colon if the line length is longer than column; limit. .. code-block:: c++. asm volatile(""string"", : : val);; asm(""cmoveq %1, %2, %[result]""; : [result] ""=r""(result); : ""r""(test), ""r""(new), ""[result]""(old));. * ``BBIAS_Always`` (in configuration: ``Always``); Always break before inline ASM colon. .. code-block:: c++. asm volatile(""string"",; :; : val);. .. _BreakBeforeTernaryOperators:. **BreakBeforeTernaryOperators",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:52616,configurat,configuration,52616,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," build with assertions; (`-DLLVM_ENABLE_ASSERTIONS=On`, enabled for Debug builds). Reporting a Security Issue; --------------------------. There is a separate process to submit security-related bugs, see :ref:`report-security-issue`. Bigger Pieces of Work; ---------------------; In case you are interested in taking on a bigger piece of work, a list of; interesting projects is maintained at the `LLVM's Open Projects page`_. In case; you are interested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:2327,patch,patches,2327,interpreter/llvm-project/llvm/docs/Contributing.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst,1,['patch'],['patches']
Deployability," but break before function definitions, ``catch``, and; ``else``. .. code-block:: c++. namespace N {; enum E {; E1,; E2,; };. class C {; public:; C();; };. bool baz(int i); {; try {; do {; switch (i) {; case 1: {; foobar();; break;; }; default: {; break;; }; }; } while (--i);; return true;; }; catch (...) {; handleError();; return false;; }; }. void foo(bool b); {; if (b) {; baz(2);; }; else {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_Allman`` (in configuration: ``Allman``); Always break before braces. .. code-block:: c++. namespace N; {; enum E; {; E1,; E2,; };. class C; {; public:; C();; };. bool baz(int i); {; try; {; do; {; switch (i); {; case 1:; {; foobar();; break;; }; default:; {; break;; }; }; } while (--i);; return true;; }; catch (...); {; handleError();; return false;; }; }. void foo(bool b); {; if (b); {; baz(2);; }; else; {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_Whitesmiths`` (in configuration: ``Whitesmiths``); Like ``Allman`` but always indent braces and line up code with braces. .. code-block:: c++. namespace N; {; enum E; {; E1,; E2,; };. class C; {; public:; C();; };. bool baz(int i); {; try; {; do; {; switch (i); {; case 1:; {; foobar();; break;; }; default:; {; break;; }; }; } while (--i);; return true;; }; catch (...); {; handleError();; return false;; }; }. void foo(bool b); {; if (b); {; baz(2);; }; else; {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_GNU`` (in configuration: ``GNU``); Always break before braces and add an extra level of indentation to; braces of control statements, not to those of class, function; or other definitions. .. code-block:: c++. namespace N; {; enum E; {; E1,; E2,; };. class C; {; public:; C();; };. bool baz(int i); {; try; {; do; {; switch (i); {; case 1:; {; foobar();; break;; }; default:; {; break;; }; }; }; while (--i);; return true;; }; catch (...); {; handleError();; return false;; }; }. void foo(bool b); {; if (b); {; baz(2);; }; e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:50281,configurat,configuration,50281,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," can be replaced using the Root.StacktraceScript resource.; Numerous minor bug fixes... New module editline ; The new module editline enhances the prompt, giving type and syntax feedback using e.g. colors.; Class names are highlighted blue when typed, indicating that it is known to ROOT.; Matching parenthesis pairs are highlighted green when typed, or when the cursor is moved to a bracket. This works for () {} and [] brackets.; Any mismatched brackets (those without a matching partner) will be highlighted red when typed or when the cursor is moved to the bracket.; Tab completion output is colored magenta to differentiate between tab completion output and user input.; All of the colors are configurable in the .rootrc file.; They can be specified as #rgb or #rrggbb or color names:; black, red, green, yellow, blue, magenta, cyan or white.; They can be followed by an optional bold (alias light) or underlined.; Rint.ReverseColor allows to quickly toggle between the default ""light on dark"" (yes) instead of ""dark on light"" (no), depending on the terminal background.; An example configuration would be:. Rint.TypeColor: blue; Rint.BracketColor: bold green; Rint.BadBracketColor: underlined red; Rint.TabColor: magenta; Rint.PromptColor: black; Rint.ReverseColor: no. The enhanced prompt is available on all platforms with [n]curses, including Linux, Solaris and MacOS; the bold and underline options are available also for black and white terminals. You can export (or setenv) TERM=xterm-256color for nicer colors.; With editline comes also an improved terminal input handler.; It supports e.g. ^O (Ctrl-o) to replay the history: suppose you have entered. ...; root [3] i = func(); root [4] i += 12; root [5] printf(""i is %d\n"", i). You now want to re-run these three lines.; As always, you press the up cursor three times to see. root [6] i = func(). and now press ^O (Ctrl-o) to run the line, and prepare the next line:. root [6] i = func()^O; root [7] i += 12^O; root [8] printf(""i is %d\",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v526/index.html:2337,toggle,toggle,2337,core/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v526/index.html,1,['toggle'],['toggle']
Deployability," can control the relative and absolute tolerance and the maximum allowed number of function evaluation. #### `ROOT::Math::GSLMCIntegrator`. It is a class for performing numerical integration of a multidimensional function. It uses the numerical integration algorithms of GSL, which reimplements the algorithms used; in the QUADPACK, a numerical integration package written in Fortran. Plain MC, MISER and VEGAS integration algorithms are supported for integration over finite (hypercubic) ranges.; For a detail description of the GSL methods visit the GSL users guide.; Specific configuration options (documented in the GSL user guide) for the `ROOT::Math::GSLMCIntegration` can be set directly in the class, or when using it via the `ROOT::Math::IntegratorMultiDim`; interface, can be defined using the `ROOT::Math::IntegratorMultiDimOptions`. ## Function Derivation. There are in ROOT only two classes to perform numerical derivation. One of them is in the MathCore library while the other is in the MathMore wrapping an integration function from the GSL library.; * RichardsonDerivator: Implements the Richardson method for numerical integration. It can calculate up to the third derivative of a function.; * GSLDerivator of *MathMore* based on GSL. ## Numerical Minimization. The algorithms provided by ROOT for numerical integration are implemented following the hierarchy shown in the next image. The left branch of classes are used for one dimensional minimization, while; the right one is used for multidimensional minimization. In the case of multidimensional minimization we have also the classes `TMinuitMinimizer` implemented using `TMinuit`, `TFumiliMinimizer`; implemented using `TFumili` for least square or likelihood minimizations.; We encourage the use of the GSL algorithms for one dimensional minimization and `Minuit2` (or the old version`Minuit`) for multi dimensional minimization. ![Numerical Minimization classes](pictures/Minimization.png). ### One-Dimensional Minimization. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:62533,integrat,integration,62533,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['integrat'],['integration']
Deployability," candidates, on the previous release. You should:. * Download the previous release sources from; https://llvm.org/releases/download.html. * Run the test-release.sh script on ``final`` mode (change ``-rc 1`` to; ``-final``). * Once all three stages are done, it'll test the final stage. * Using the ``Phase3/Release+Asserts/llvmCore-MAJ.MIN-final.install`` base,; run the test-suite. If the final phase's ``make check-all`` failed, it's a good idea to also test; the intermediate stages by going on the obj directory and running; ``make check-all`` to find if there's at least one stage that passes (helps; when reducing the error for bug report purposes). .. _release-process:. Release Process; ===============. .. contents::; :local:. When the Release Manager sends you the release candidate, download all sources,; unzip on the same directory (there will be sym-links from the appropriate places; to them), and run the release test as above. You should:. * Download the current candidate sources from where the release manager points; you (ex. https://llvm.org/pre-releases/3.3/rc1/). * Repeat the steps above with ``-rc 1``, ``-rc 2`` etc modes and run the; test-suite the same way. * Compare the results, report all errors on Bugzilla and publish the binary blob; where the release manager can grab it. Once the release manages announces that the latest candidate is the good one,; you have to pack the ``Release`` (no Asserts) install directory on ``Phase3``; and that will be the official binary. * Rename (or link) ``clang+llvm-REL-ARCH-ENV`` to the .install directory. * Tar that into the same name with ``.tar.gz`` extension from outside the; directory. * Make it available for the release manager to download. .. _bug-reporting:. Bug Reporting Process; =====================. .. contents::; :local:. If you found regressions or failures when comparing a release candidate with the; previous release, follow the rules below:. * Critical bugs on compilation should be fixed as soon as possible",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst:6000,release,release,6000,interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,1,['release'],['release']
Deployability," capability to access data that is protected by ``mu``. Similarly,; calling ``mu.Unlock()`` releases that capability. A thread may hold a capability either *exclusively* or *shared*. An exclusive; capability can be held by only one thread at a time, while a shared capability; can be held by many threads at the same time. This mechanism enforces a; multiple-reader, single-writer pattern. Write operations to protected data; require exclusive access, while read operations require only shared access. At any given moment during program execution, a thread holds a specific set of; capabilities (e.g. the set of mutexes that it has locked.) These act like keys; or tokens that allow the thread to access a given resource. Just like physical; security keys, a thread cannot make copy of a capability, nor can it destroy; one. A thread can only release a capability to another thread, or acquire one; from another thread. The annotations are deliberately agnostic about the; exact mechanism used to acquire and release capabilities; it assumes that the; underlying implementation (e.g. the Mutex implementation) does the handoff in; an appropriate manner. The set of capabilities that are actually held by a given thread at a given; point in program execution is a run-time concept. The static analysis works; by calculating an approximation of that set, called the *capability; environment*. The capability environment is calculated for every program point,; and describes the set of capabilities that are statically known to be held, or; not held, at that particular point. This environment is a conservative; approximation of the full set of capabilities that will actually held by a; thread at run-time. Reference Guide; ===============. The thread safety analysis uses attributes to declare threading constraints.; Attributes must be attached to named declarations, such as classes, methods,; and data members. Users are *strongly advised* to define macros for the various; attributes; example def",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:5201,release,release,5201,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['release'],['release']
Deployability," cfe-commits will be subscribed automatically;; otherwise, you will have to manually subscribe them.); * In the Repository field, enter ""rG LLVM Github Monorepo"".; * Click *Save*. To submit an updated patch:. * Click *Differential*.; * Click *+ Create Diff*.; * Paste the updated diff or browse to the updated patch file. Click *Create Diff*.; * Select the review you want to from the *Attach To* dropdown and click; *Continue*.; * Leave the Repository field blank. (We previously filled out the Repository; for the review request.); * Add comments about the changes in the new diff. Click *Save*. Choosing reviewers: You typically pick one or two people as initial reviewers.; This choice is not crucial, because you are merely suggesting and not requiring; them to participate. Many people will see the email notification on cfe-commits; or llvm-commits, and if the subject line suggests the patch is something they; should look at, they will. .. _creating-a-patch-series:. Creating a patch series; -----------------------. Chaining reviews together requires some manual work. There are two ways to do it; (these are also described `here <https://moz-conduit.readthedocs.io/en/latest/arcanist-user.html#series-of-commits>`_; along with some screenshots of what to expect). .. _using-the-web-interface:. Using the web interface; ^^^^^^^^^^^^^^^^^^^^^^^. This assumes that you've already created a Phabricator review for each commit,; using `arc` or the web interface. * Go to what will be the last review in the series (the most recent).; * Click ""Edit Related Revisions"" then ""Edit Parent Revisions"".; * This will open a dialog where you will enter the patch number of the parent patch; (or patches). The patch number is of the form D<number> and you can find it by; looking at the URL for the review e.g. reviews.llvm/org/D12345.; * Click ""Save Parent Revisions"" after entering them.; * You should now see a ""Stack"" tab in the ""Revision Contents"" section of the web; interface, showing the parent ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst:5147,patch,patch,5147,interpreter/llvm-project/llvm/docs/Phabricator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst,1,['patch'],['patch']
Deployability," change is required as `DIAssignID`; attachments are automatically merged if `combineMetadata` is called. One way or; another, the `DIAssignID` attachments must be merged such that new store; becomes linked to all the `llvm.dbg.assign` intrinsics that the merged stores; were linked to. This can be achieved simply by calling a helper function; `Instruction::mergeDIAssignID`. **Inlining** stores: As stores are inlined we generate `llvm.dbg.assign`; intrinsics and `DIAssignID` attachments as if the stores represent source; assignments, just like the in frontend. This isn’t perfect, as stores may have; been moved, modified or deleted before inlining, but it does at least keep the; information about the variable correct within the non-inlined scope. **Splitting** stores: SROA and passes that split stores treat `llvm.dbg.assign`; intrinsics similarly to `llvm.dbg.declare` intrinsics. Clone the; `llvm.dbg.assign` intrinsics linked to the store, update the FragmentInfo in; the `ValueExpression`, and give the split stores (and cloned intrinsics) new; `DIAssignID` attachments each. In other words, treat the split stores as; separate assignments. For partial DSE (e.g. shortening a memset), we do the; same except that `llvm.dbg.assign` for the dead fragment gets an `Undef`; `Address`. **Promoting** allocas and store/loads: `llvm.dbg.assign` intrinsics implicitly; describe joined values in memory locations at CFG joins, but this is not; necessarily the case after promoting (or partially promoting) the; variable. Passes that promote variables are responsible for inserting; `llvm.dbg.assign` intrinsics after the resultant PHIs generated during; promotion. `mem2reg` already has to do this (with `llvm.dbg.value`) for; `llvm.dbg.declare`s. Where a store has no linked intrinsic, the store is; assumed to represent an assignment for variables stored at the destination; address. #### Debug intrinsic updates. **Moving** a debug intrinsic: avoid moving `llvm.dbg.assign` intrinsics where; p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:7481,update,update,7481,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md,1,['update'],['update']
Deployability," changing this line in the source file:. ``` {.cpp}; ClassDef(TEvent,0);; ```. If you want to prevent the generation of `Streamer()`, see the section; ""Adding a Class with a Shared Library"". ### Dictionaries for STL. Usually, headers are passed to rootcling at the command line. To generate; a dictionary for a class from the STL, e.g. **std::vector\<MyClass\>**, you would normally pass the header defining; **MyClass** and **std::vector**. The latter is a compiler specific; header and cannot be passed to rootcling directly. Instead, create a; little header file that includes both headers, and pass that to; rootcling. Often ROOT knows where **MyClass** and the templated class (e.g. vector); are defined, for example because the files got **\#included**. Knowing; these header files ROOT can automatically generate the dictionary for; any template combination (e.g. **vector\<myClass\>**) when it is needed,; by generating files starting with **AutoDict\***. You can toggle this; feature on or off at the ROOT prompt by executing **.autodict**. ## Adding a Class with a Shared Library. \index{adding a class!shared library}; **Step 1:** Define your own class in `SClass.h` and implement it in; `SClass.cxx`. You must provide a default constructor or an I/O; constructor for your class. See the ""The Default Constructor"" paragraph; in this chapter. ``` {.cpp}; #include <iostream.h>; #include ""TObject.h""; class SClass : public TObject {; private:; Float_t fX; //x position in centimeters; Float_t fY; //y position in centimeters; Int_t fTempValue; //! temporary state value; public:; SClass() { fX = fY = -1; }; void Print() const;; void SetX(float x) { fX = x; }; void SetY(float y) { fY = y; }. ClassDef(SClass, 1); };; ```. **Step 2:** Add a call to the `ClassDef` macro to at the end of the class; definition (in the `SClass.h` file). `ClassDef(SClass,1)`. Add a call to; the `ClassImp` macro in the implementation file (`SClass.cxx`):; `ClassImp(SClass)`. ``` {.cpp}; // SClass.cxx:; #includ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md:19307,toggle,toggle,19307,documentation/users-guide/AddingaClass.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md,1,['toggle'],['toggle']
Deployability," chisquared fits $\mbox{up = 1}$, and; for negative log likelihood, $\mbox{up = 0.5}$. ### $\mbox{FCN}$ function with gradient ###. By default first derivatives are calculated numerically by M . In case; the user wants to supply their own gradient calculator (e.g. analytical; derivatives), they need to implement the FCNGradientBase interface. ![](figures/fcngradientbase.png). The size of the output vector is the same as of the input one. The same; is true for the position of the elements (first derivative of the; function with respect to the $n_\mathrm{th}$ variable has index $n$ in; the output vector). ## M parameters ##. Interaction with the parameters of the function are essential both for M; and the user. Different interfaces are provided, depending on the level; of interaction. ### Minimal required interface ###. Starting values of parameters and uncertainties can be provided to M by; the user via std::vector$<$double$>$ vector containers. Any interaction; with the parameters before minimization (fix, release, limits, etc.) is; not possible then. Optionally if the user wants to provide starting values for the; covariance, they have to provide the values in a std::vector$<$double$>$; vector container stored in upper triangular packed storage format (see; [api:covariance]). ### MnUserParameters ###. A more functional interface to the user parameters is provided through M; via the class MnUserParameters. The user can add parameters giving them; a name and starting values. More information can be found in; [api:parameters]. ### MnUserCovariance ###. The user can (optionally) provide a covariance matrix as input using the; class MnUserCovariance. More information can be found in; [api:covariance]. ### MnUserParameterState ###. The MnUserParameterState contains the parameters (MnUserParameters) and; covariance (MnUserCovariance). The MnUserParameterState has to main; purposes:. - It can be used as input to minimization. - The result of the minimization is transformed ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:30648,release,release,30648,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['release'],['release']
Deployability," class. In addition, in order to have a common entry point, interfaces classes for these numerical algorithms have been; included.; These interfaces are as well implemented by classes using the GSL library and located in the MathMore library. The library can be loaded automatically using the ROOT plug-in manager.; In detail, the new classes containing implementations present previously in TF1 are:. ; GaussIntegrator and GaussLegendreIntegrator for numerical integration of one-dimensional functions. The first class uses Gaussian 8 and 16 point quadrature approximation, it provides the translation of the CERNLIB algorithm; DGAUSS by Sigfried Kolbig, and it is used by the TF1::Integral method. The second one uses the Gauss Legendre quadrature formula. It is used by the TF1::IntegralFast method.; These classes implement both the same virtual interface as the adaptive integration methods provided by the MathMore library. They can all be created and used easily via the common class ROOT::Math::IntegratorOneDim providing the interfaces for numerical integration.; New template methods have been also included in the common Integration class in order to be able to integrate automatically any C++ callable object. ROOT::Math::RichardsonDerivator implementing numerical derivation using the Richardson's extrapolation formula (use 2 derivative estimates to compute a third, more accurate estimation). This is used by the TD1::Derivative method. ; BrentRootFinder for finding the root of one-dimensional function using the Brent algorithm. The class inherits from a virtual interface, which is also implemented by the MathMore root finder methods. The user can instantiate, via the common ROOT::Math::RootFinder class, all the various root finder algorithms. The BrentRootFinder class is used by TF1::GetX . ; A similar class, BrentMinimizer1D, provides the possibility to find the minimum of one-dimensional functions using the Brent algorithm. This class is used by TF1::GetMinimum or TF1::Ge",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v520/index.html:7300,integrat,integration,7300,math/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v520/index.html,1,['integrat'],['integration']
Deployability," click on the names ontop to select a tab. Inheritance; This chart shows the inheritance hierarchy for the current class. Arrows point to; base classes. You can click the classes to get to their reference page. Inherited Members; The second chart shows a list of all members of all base classes. You can see at what; level they are defined or at what level they are defined. Members that are accessible; (public) have a green background, protected ones have a yellow background, and private; members have a red background. Members with a dark gray background are re-implemented; or hidden by a derived class. Includes; The Includes chart shows which files are indirectly included by including the class's; header. Most headers will #include some files, so by #including that header you also; #include the #included files, and so on. A illegible chart often means you should; read a bit on the C++ trick known as ""forward declaration"". Including too many headers; has some nasty consequences, like compile time, additional dependencies, etc. Libraries; Each class is assumed to be in a library. That library might depend on other libraries.; The fourth chart shows the dependencies of these libraries. You will need to link against; all of these if you write your own program. Member Function Documentation; Each function should be documented by the developer of the class. The documentation can; contain HTML, pictures, and example code. It should explain what the function does,; what it expects as parameters, what it returns, and what can make it fail. Short functions; can have their source displayed. You can click on the function name to jump to a; colored version of the function's source.  . Author: Axel Naumann; Last update: 2007-01-12; Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. This page has been hand crafted. If you have any comments or suggestions about the page layout send a mail to ROOT support, or contact the developers with any questions or problems regarding ROOT. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/etc/html/HELP.html:8631,update,update,8631,etc/html/HELP.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/etc/html/HELP.html,1,['update'],['update']
Deployability," code from the; GSL library, wich is provided in the *MathMore* library of ROOT. The interface to use is the same as above. We have now the possibility to specify a different integration algorithm in the constructor of the `ROOT::Math::GSLIntegrator` class.; ```{.cpp}; // create the adaptive integrator with the 51 point rule; ROOT::Math::GSLIntegrator ig(ROOT::Math::Integration::kADAPTIVE, ROOT::Math::Integration::kGAUSS51);; ig.SetRelTolerance(1.E-6); // set relative tolerance; ig.SetAbsTolerance(1.E-6); // set absoulte tolerance; ```. The algorithm is controlled by the given absolute and relative tolerance. The iterations are continued until the following condition is satisfied; $$; absErr <= max ( epsAbs, epsRel * Integral); $$; Where *absErr* is an estimate of the absolute error (it can be retrieved with `GSLIntegrator::Error()`) and *Integral* is the estimate of the function integral; (it can be obtained with `GSLIntegrator::Result()`). The possible integration algorithm types to use with the GSLIntegrator are the following. More information is provided in the `GSL` users documentation.; * `ROOT::Math::Integration::kNONADAPTIVE` : based on `gsl_integration_qng`. It is a non-adaptive procedure which uses fixed Gauss-Kronrod-Patterson abscissae; to sample the integrand at a maximum of 87 points. It is provided for fast integration of smooth functions.; * `ROOT::Math::Integration::kADAPTIVE`: based on `gsl_integration_qag`. It is an adaptiva Gauss-Kronrod integration algorithm, the integration region is divided into subintervals, and on each; iteration the subinterval with the largest estimated error is bisected. It is possible to specify the integration rule as an extra enumeration parameter. The possible rules are; * `Integration::kGAUSS15` : 15 points Gauss-Konrod rule (value = 1); * `Integration::kGAUSS21` : 21 points Gauss-Konrod rule (value = 2); * `Integration::kGAUSS31` : 31 points Gauss-Konrod rule (value = 3); * `Integration::kGAUSS41` : 41 points Gauss-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:56063,integrat,integration,56063,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['integrat'],['integration']
Deployability," code. It's distinctive enough that character sequences that look like the start; or end of a markup element should rarely if ever appear incidentally in logging; text. It's specifically intended not to require sanitizing plain text, such as; the HTML/XML requirement to replace ``<`` with ``&lt;`` and the like. :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` includes a symbolizing; filter via its ``--filter-markup`` option. Also, LLVM utilites emit stack; traces as markup when the ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` environment; variable is set. Scope and assumptions; =====================. A symbolizing filter implementation will be independent both of the target; operating system and machine architecture where the logs are generated and of; the host operating system and machine architecture where the filter runs. This format assumes that the symbolizing filter processes intact whole lines. If; long lines might be split during some stage of a logging pipeline, they must be; reassembled to restore the original line breaks before feeding lines into the; symbolizing filter. Most markup elements must appear entirely on a single line; (often with other text before and/or after the markup element). There are some; markup elements that are specified to span lines, with line breaks in the middle; of the element. Even in those cases, the filter is not expected to handle line; breaks in arbitrary places inside a markup element, but only inside certain; fields. This format assumes that the symbolizing filter processes a coherent stream of; log lines from a single process address space context. If a logging stream; interleaves log lines from more than one process, these must be collated into; separate per-process log streams and each stream processed by a separate; instance of the symbolizing filter. Because the kernel and user processes use; disjoint address regions in most operating systems, a single user process; address space plus the kernel address space can be treate",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:2380,pipeline,pipeline,2380,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,1,['pipeline'],['pipeline']
Deployability," coding style. <string> can be:; 1. A preset: LLVM, GNU, Google, Chromium, Microsoft,; Mozilla, WebKit.; 2. 'file' to load style configuration from a; .clang-format file in one of the parent directories; of the source file (for stdin, see --assume-filename).; If no .clang-format file is found, falls back to; --fallback-style.; --style=file is the default.; 3. 'file:<format_file_path>' to explicitly specify; the configuration file.; 4. ""{key: value, ...}"" to set specific parameters, e.g.:; --style=""{BasedOnStyle: llvm, IndentWidth: 8}""; --verbose - If set, shows the list of processed files. Generic Options:. --help - Display available options (--help-hidden for more); --help-list - Display list of available options (--help-list-hidden for more); --version - Display the version of this program. .. END_FORMAT_HELP. When the desired code formatting style is different from the available options,; the style can be customized using the ``-style=""{key: value, ...}""`` option or; by putting your style configuration in the ``.clang-format`` or ``_clang-format``; file in your project's directory and using ``clang-format -style=file``. An easy way to create the ``.clang-format`` file is:. .. code-block:: console. clang-format -style=llvm -dump-config > .clang-format. Available style options are described in :doc:`ClangFormatStyleOptions`. .clang-format-ignore; ====================. You can create ``.clang-format-ignore`` files to make ``clang-format`` ignore; certain files. A ``.clang-format-ignore`` file consists of patterns of file path; names. It has the following format:. * A blank line is skipped.; * Leading and trailing spaces of a line are trimmed.; * A line starting with a hash (``#``) is a comment.; * A non-comment line is a single pattern.; * The slash (``/``) is used as the directory separator.; * A pattern is relative to the directory of the ``.clang-format-ignore`` file; (or the root directory if the pattern starts with a slash). Patterns; containing drive names (e.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst:4748,configurat,configuration,4748,interpreter/llvm-project/clang/docs/ClangFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst,1,['configurat'],['configuration']
Deployability," command line. RelWithDebInfo. These builds are useful when debugging. They generate optimized binaries with; debug information. CMakes default optimization level is -O2. This can be; configured by setting the ``CMAKE_CXX_FLAGS_RELWITHDEBINFO`` variable on the; CMake command line. Once you have LLVM configured, you can build it by entering the *OBJ_ROOT*; directory and issuing the following command:. .. code-block:: console. % make. If the build fails, please `check here`_ to see if you are using a version of; GCC that is known not to compile LLVM. If you have multiple processors in your machine, you may wish to use some of the; parallel build options provided by GNU Make. For example, you could use the; command:. .. code-block:: console. % make -j2. There are several special targets which are useful when working with the LLVM; source code:. ``make clean``. Removes all files generated by the build. This includes object files,; generated C/C++ files, libraries, and executables. ``make install``. Installs LLVM header files, libraries, tools, and documentation in a hierarchy; under ``$PREFIX``, specified with ``CMAKE_INSTALL_PREFIX``, which; defaults to ``/usr/local``. ``make docs-llvm-html``. If configured with ``-DLLVM_ENABLE_SPHINX=On``, this will generate a directory; at ``OBJ_ROOT/docs/html`` which contains the HTML formatted documentation. Cross-Compiling LLVM; --------------------. It is possible to cross-compile LLVM itself. That is, you can create LLVM; executables and libraries to be hosted on a platform different from the platform; where they are built (a Canadian Cross build). To generate build files for; cross-compiling CMake provides a variable ``CMAKE_TOOLCHAIN_FILE`` which can; define compiler flags and variables used during the CMake test operations. The result of such a build is executables that are not runnable on the build; host but can be executed on the target. As an example the following CMake; invocation can generate build files targeting iOS. T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:30291,install,install,30291,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['install'],['install']
Deployability," configure access restriction in THttpServer. ### Configure fastcgi with Apache2. Since Apache version 2.4 FastCGI is directly supported - there is no need to compile and install external modules any more.; One only need to enable `mod_proxy` and `mod_proxy_fcgi` modules and add following line to **Apache2** configuration file:. ```; ProxyPass ""/root.app/"" ""fcgi://localhost:9000/"" enablereuse=on; ```. More information can be found in [FastCGI proxy docu](https://httpd.apache.org/docs/2.4/mod/mod_proxy_fcgi.html).; After restarting apache server one should be able to open address: `http://apache_host_name/root.app/`.; There are many ways to configure user authentication in Apache. Example of digest auth for FastCGI server:. ```; <Location ""/root.app/"">; AuthType Digest; AuthName ""root""; AuthDigestDomain ""/root.app/"" ""root""; AuthDigestProvider file; AuthUserFile ""/srv/auth/auth.txt""; Require valid-user; </Location>; ```. ### Configure fastcgi with lighttpd. An example of configuration file for **lighttpd** server is:. ```; server.modules += ( ""mod_fastcgi"" ); fastcgi.server = (; ""/root.app"" =>; (( ""host"" => ""192.168.1.11"",; ""port"" => 9000,; ""check-local"" => ""disable"",; ""docroot"" => ""/""; )); ); ```. Be aware, that with *lighttpd* one should specify IP address of the host, where ROOT application is running. Address of the ROOT application will be following: `http://lighttpd_host_name/root.app/`. Example of authorization configuration for FastCGI connection:. auth.require = ( ""/root.app"" => (; ""method"" => ""digest"",; ""realm"" => ""root"",; ""require"" => ""valid-user""; ) ). ## Integration with existing applications. In many practical cases no change of existing code is required. Opened files (and all objects inside), existing canvas and histograms are automatically scanned by the server and will be available to the users. If necessary, any object can be registered directly to the server with a [THttpServer::Register()](https://root.cern/doc/master/classTHttpServer.html#a73658da",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:11967,configurat,configuration,11967,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['configurat'],['configuration']
Deployability," construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_BUILD*, *LLVM_ENABLE_PROJECTS*,; *LLVM_ENABLE_RUNTIMES*, *LLVM_BUILD_LLVM_DYLIB*, and *LLVM_LINK_LLVM_DYLIB*. **LLVM_ENABLE_RUNTIMES**:STRING; When building a distribution that includes LLVM runtime projects (i.e. libcxx,; compiler-rt, libcxxabi, libunwind...), it is important to build those projects; with the just-built compiler. **LLVM_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of LLVM build system; components to install. All LLVM-based tools are components, as well as most; of the libraries and runtimes. Component names match the names of the build; system targets. **LLVM_DISTRIBUTIONS**:STRING; This variable can be set to a semi-colon separated list of distributions. See; the :ref:`Multi-distribution configurations` section above for details on this; and other CMake variables to configure multiple distributions. **LLVM_RUNTIME_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of runtime library; components. This is used in conjunction with *LLVM_ENABLE_RUNTIMES* to specify; components of runtime libraries that you want to include in your distribution.; Just like with *LLVM_DISTRIBUTION_COMPONENTS*, component names match the names; of the build system targets. **LLVM_DYLIB_COMPONENTS**:STRING; This variable can be set to a semi-colon separated name of LLVM library; components. LLVM library components are either library names with the LLVM; prefix removed (i.e. Support, Demangle...), LLVM target names, or special; purpose component names. The special purpose component names are:. #. ``all`` - All LLVM available component libraries; #. ``Native`` - The LLVM target for the Native system; #. ``AllTargetsAsmParsers`` - All the included target ASM parsers libraries; #. ``AllTargetsDescs`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:11894,configurat,configurations,11894,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['configurat'],['configurations']
Deployability," constructed to be Objective-C objects regardless of; whether the Objective-C runtime is operational in the program or; not. Blocks using automatic (stack) memory are objects and may be; messaged, although they may not be assigned into ``__weak`` locations; if garbage collection is enabled. Within a Block literal expression within a method definition; references to instance variables are also imported into the lexical; scope of the compound statement. These variables are implicitly; qualified as references from self, and so self is imported as a const; copy. The net effect is that instance variables can be mutated. The :block-term:`Block_copy` operator retains all objects held in; variables of automatic storage referenced within the Block expression; (or form strong references if running under garbage collection).; Object variables of ``__block`` storage type are assumed to hold; normal pointers with no provision for retain and release messages. Foundation defines (and supplies) ``-copy`` and ``-release`` methods for; Blocks. In the Objective-C and Objective-C++ languages, we allow the; ``__weak`` specifier for ``__block`` variables of object type. If; garbage collection is not enabled, this qualifier causes these; variables to be kept without retain messages being sent. This; knowingly leads to dangling pointers if the Block (or a copy) outlives; the lifetime of this object. In garbage collected environments, the ``__weak`` variable is set to; nil when the object it references is collected, as long as the; ``__block`` variable resides in the heap (either by default or via; ``Block_copy()``). The initial Apple implementation does in fact; start ``__block`` variables on the stack and migrate them to the heap; only as a result of a ``Block_copy()`` operation. It is a runtime error to attempt to assign a reference to a; stack-based Block into any storage marked ``__weak``, including; ``__weak`` ``__block`` variables. C++ Extensions; ==============. Block literal expres",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:10041,release,release,10041,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['release'],['release']
Deployability," consumed by instructions.; It delegates the management of processor resource units and resource groups to a; resource manager. The resource manager is responsible for selecting resource; units that are consumed by instructions. For example, if an instruction; consumes 1cy of a resource group, the resource manager selects one of the; available units from the group; by default, the resource manager uses a; round-robin selector to guarantee that resource usage is uniformly distributed; between all units of a group. :program:`llvm-mca`'s scheduler internally groups instructions into three sets:. * WaitSet: a set of instructions whose operands are not ready.; * ReadySet: a set of instructions ready to execute.; * IssuedSet: a set of instructions executing. Depending on the operands availability, instructions that are dispatched to the; scheduler are either placed into the WaitSet or into the ReadySet. Every cycle, the scheduler checks if instructions can be moved from the WaitSet; to the ReadySet, and if instructions from the ReadySet can be issued to the; underlying pipelines. The algorithm prioritizes older instructions over younger; instructions. Write-Back and Retire Stage; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Issued instructions are moved from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculati",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:38509,pipeline,pipelines,38509,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['pipeline'],['pipelines']
Deployability," contained within each object, rather than; scattered through the program in the form of global variables. - Objects may come and go, but the basic structure of the program; remains relatively static, increases opportunity for reuse of; design. ## Installing ROOT; \index{install ROOT}. To install ROOT you have the choice to; download the binaries or the source. The source is quicker to transfer; since it is only \~22 MB, but you will need to compile and link it. The; binaries compiled with no debug information range from \~35 MB to \~45; MB depending on the target platform. The installation and building of ROOT is described in Appendix A:; Install and Build ROOT. You can download the binaries, or the source.; The GNU g++ compiler on most UNIX platforms can compile ROOT. Before downloading a binary version make sure your machine contains the; right run-time environment. In most cases it is not possible to run a; version compiled with, e.g., gcc4.0 on a platform where only gcc 3.2 is; installed. In such cases you'll have to install ROOT from source. ROOT is currently running on the following platforms: supported; platforms. - `GNU/Linux x86-32 (IA32) and x86-64 (AMD64)(GCC,Intel/icc,; Portland/PGCC,KAI/KCC)`. - `Intel Itanium (IA64) GNU/Linux (GCC, Intel/ecc, SGI/CC) `. - `FreeBSD and OpenBSD (GCC)`. - `GNU/Hurd (GCC)`. - `HP HP-UX 10.x (IA32) and 11 (IA64) (HP CC, aCC, GCC)`. - `IBM AIX 4.1 (xlC compiler, GCC)`. - `Sun Solaris for SPARC (SUN C++ compiler, GCC) `. - `Sun Solaris for x86 (SUN C++ compiler, KAI/KCC)`. - `Compaq Alpha (GCC, KAI/KCC, DEC/CXX)`. - `SGI Irix 32 and 64 bits (GCC, KAI/KCC, SGI C++ compiler) `. - `Windows >= 95 (Microsoft Visual C++ compiler, Cygwin/GCC) `. - `MacOS X PPC, x86-32, x86-64 (GCC, Intel/ICC, IBM/xl)`. - `PowerPC with GNU/Linux and GCC, Debian v2`. - `PowerPC64 with GNU/Linux and GCC`. - `ARM with GNU/Linux and GCC`. - `LynxOS`. ## The Organization of the ROOT Framework. Now after we know in abstract terms what the ROOT framework i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:9505,install,installed,9505,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['install'],['installed']
Deployability," contents::; :local:; :depth: 2. Abstract; ========. The intended audience of this document is developers of language frontends; targeting LLVM IR. This document is home to a collection of tips on how to; generate IR that optimizes well. IR Best Practices; =================. As with any optimizer, LLVM has its strengths and weaknesses. In some cases,; surprisingly small changes in the source IR can have a large effect on the; generated code. Beyond the specific items on the list below, it's worth noting that the most; mature frontend for LLVM is Clang. As a result, the further your IR gets from; what Clang might emit, the less likely it is to be effectively optimized. It; can often be useful to write a quick C program with the semantics you're trying; to model and see what decisions Clang's IRGen makes about what IR to emit.; Studying Clang's CodeGen directory can also be a good source of ideas. Note; that Clang and LLVM are explicitly version locked so you'll need to make sure; you're using a Clang built from the same git revision or release as the LLVM; library you're using. As always, it's *strongly* recommended that you track; tip of tree development, particularly during bring up of a new project. The Basics; ^^^^^^^^^^^. #. Make sure that your Modules contain both a data layout specification and; target triple. Without these pieces, non of the target specific optimization; will be enabled. This can have a major effect on the generated code quality. #. For each function or global emitted, use the most private linkage type; possible (private, internal or linkonce_odr preferably). Doing so will; make LLVM's inter-procedural optimizations much more effective. #. Avoid high in-degree basic blocks (e.g. basic blocks with dozens or hundreds; of predecessors). Among other issues, the register allocator is known to; perform badly with confronted with such structures. The only exception to; this guidance is that a unified return block with high in-degree is fine. Use of a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:1170,release,release,1170,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['release'],['release']
Deployability," created. Since this dot-product; example utilized only floating point registers, the JFPuPRF was responsible for; creating the 900 mappings. However, we see that the pipeline only used a; maximum of 35 of 72 available register slots at any given time. We can conclude; that the floating point PRF was the only register file used for the example, and; that it was never resource constrained. The register file statistics are; displayed by using the command option ``-all-stats`` or; ``-register-file-stats``. In this example, we can conclude that the IPC is mostly limited by data; dependencies, and not by resource pressure. Instruction Flow; ^^^^^^^^^^^^^^^^; This section describes the instruction flow through the default pipeline of; :program:`llvm-mca`, as well as the functional units involved in the process. The default pipeline implements the following sequence of stages used to; process instructions. * Dispatch (Instruction is dispatched to the schedulers).; * Issue (Instruction is issued to the processor pipelines).; * Write Back (Instruction is executed, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipeline implements the following sequence of stages:; * InOrderIssue (Instruction is issued to the processor pipelines).; * Retire (Instruction is retired; writes are architecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not modeled. Performance bottlenecks in the frontend are not; diagnosed. Also, :program:`llvm-mca` does not model branch prediction. Instruction Dispatch; """"""""""""""""""""""""""""""""""""""""; During the dispatch stage, instructions are picked in program order from a; queue of already decoded instructions, and dispatched in groups to the; simulated hardware schedulers. The size of a dispatch group depends on the availability of the simulated; hardwa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:34200,pipeline,pipelines,34200,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['pipeline'],['pipelines']
Deployability," cross-compiler, meaning that; one set of programs can compile to all targets by setting the ``-target``; option. That makes it a lot easier for programmers wishing to compile to; different platforms and architectures, and for compiler developers that; only have to maintain one build system, and for OS distributions, that; need only one set of main packages. But, as is true to any cross-compiler, and given the complexity of; different architectures, OS's and options, it's not always easy finding; the headers, libraries or binutils to generate target specific code.; So you'll need special options to help Clang understand what target; you're compiling to, where your tools are, etc. Another problem is that compilers come with standard libraries only (like; ``compiler-rt``, ``libcxx``, ``libgcc``, ``libm``, etc), so you'll have to; find and make available to the build system, every other library required; to build your software, that is specific to your target. It's not enough to; have your host's libraries installed. Finally, not all toolchains are the same, and consequently, not every Clang; option will work magically. Some options, like ``--sysroot`` (which; effectively changes the logical root for headers and libraries), assume; all your binaries and libraries are in the same directory, which may not; true when your cross-compiler was installed by the distribution's package; management. So, for each specific case, you may use more than one; option, and in most cases, you'll end up setting include paths (``-I``) and; library paths (``-L``) manually. To sum up, different toolchains can:; * be host/target specific or more flexible; * be in a single directory, or spread out across your system; * have different sets of libraries and headers by default; * need special options, which your build system won't be able to figure; out by itself. General Cross-Compilation Options in Clang; ==========================================. Target Triple; -------------. The basic option",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CrossCompilation.rst:2515,install,installed,2515,interpreter/llvm-project/clang/docs/CrossCompilation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CrossCompilation.rst,1,['install'],['installed']
Deployability," current iterator; - **But not** inserting/deleting before/at the current iterator position. With a debug build (with assertions), the legacy iterators will check that the collection is not mutated. In a release build, elements might be skipped or be iterated twice. #### Moving away from the slower iterators; The legacy iterators have been flagged with a special deprecation macro that can be used help the user use the recommended ROOT interface. Defining one of the [deprecation macros](#preprocessor-deprecation-macros) (either in a single translation unit or in the build system), and creating a legacy iterator will trigger a compiler warning such as:; ```; <path>/RooChebychev.cxx:66:34: warning: 'createIterator' is deprecated: There is a superior alternative: begin(), end() and range-based for loops. [-Wdeprecated-declarations]; TIterator* coefIter = coefList.createIterator() ;; ^; 1 warning generated.; ```. ## TMVA. This release provides a consolidation and several fixes of the new machine learning tools provided in TMVA such as the Deep Learning module.; The method `TMVA::Types::kDL` should be used now for building Deep Learning architecture in TMVA, while `TMVA::Types::kDNN` is now deprecated. `TMVA::Types::kDL` provides all the functionality of `TMVA::Types::kDNN`, i.e building fully connected dense layer, but in addition supports building convolutional and recurrent neural network architectures.; These release contains improvements in the `MethodDL` such as:; - fix droput support for dense layer; - add protection to avoid returning NaN in the cross-entropy loss function. In addition we have :. - New `TMVA::Executor` class to control the multi-thread running of TMVA. By default now MT running will be enabled only when `ROOT::EnabledImplicitMT()` is called. But we can take the control of the threads by using `TMVA::gConfig().EnableMT(...)` and `TMVA::gConfig().DisableMT()`. ### PyMVA; - add support when using the Tensorflow backend in Keras to control the number o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:17184,release,release,17184,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,1,['release'],['release']
Deployability," data = foo3();. data = data + 42;; return data;; }. --- main.c ---; #include <stdio.h>; #include ""a.h"". void foo4(void) {; printf(""Hi\n"");; }. int main() {; return foo1();; }. To compile, run:. .. code-block:: console. % clang -flto -c a.c -o a.o # <-- a.o is LLVM bitcode file; % clang -c main.c -o main.o # <-- main.o is native object file; % clang -flto a.o main.o -o main # <-- standard link command with -flto. * In this example, the linker recognizes that ``foo2()`` is an externally; visible symbol defined in LLVM bitcode file. The linker completes its usual; symbol resolution pass and finds that ``foo2()`` is not used; anywhere. This information is used by the LLVM optimizer and it; removes ``foo2()``. * As soon as ``foo2()`` is removed, the optimizer recognizes that condition ``i; < 0`` is always false, which means ``foo3()`` is never used. Hence, the; optimizer also removes ``foo3()``. * And this in turn, enables linker to remove ``foo4()``. This example illustrates the advantage of tight integration with the; linker. Here, the optimizer can not remove ``foo3()`` without the linker's; input. Alternative Approaches; ----------------------. **Compiler driver invokes link time optimizer separately.**; In this model the link time optimizer is not able to take advantage of; information collected during the linker's normal symbol resolution phase.; In the above example, the optimizer can not remove ``foo2()`` without the; linker's input because it is externally visible. This in turn prohibits the; optimizer from removing ``foo3()``. **Use separate tool to collect symbol information from all object files.**; In this model, a new, separate, tool or library replicates the linker's; capability to collect information for link time optimization. Not only is; this code duplication difficult to justify, but it also has several other; disadvantages. For example, the linking semantics and the features provided; by the linker on various platform are not unique. This means, thi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:3093,integrat,integration,3093,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['integrat'],['integration']
Deployability," definition return type breaking style to use. This; option is **deprecated** and is retained for backwards compatibility. Possible values:. * ``DRTBS_None`` (in configuration: ``None``); Break after return type automatically.; ``PenaltyReturnTypeOnItsOwnLine`` is taken into account. * ``DRTBS_All`` (in configuration: ``All``); Always break after the return type. * ``DRTBS_TopLevel`` (in configuration: ``TopLevel``); Always break after the return types of top-level functions. .. _AlwaysBreakAfterReturnType:. **AlwaysBreakAfterReturnType** (``ReturnTypeBreakingStyle``) :versionbadge:`clang-format 3.8` :ref:`¶ <AlwaysBreakAfterReturnType>`; The function declaration return type breaking style to use. Possible values:. * ``RTBS_None`` (in configuration: ``None``); Break after return type automatically.; ``PenaltyReturnTypeOnItsOwnLine`` is taken into account. .. code-block:: c++. class A {; int f() { return 0; };; };; int f();; int f() { return 1; }. * ``RTBS_All`` (in configuration: ``All``); Always break after the return type. .. code-block:: c++. class A {; int; f() {; return 0;; };; };; int; f();; int; f() {; return 1;; }. * ``RTBS_TopLevel`` (in configuration: ``TopLevel``); Always break after the return types of top-level functions. .. code-block:: c++. class A {; int f() { return 0; };; };; int; f();; int; f() {; return 1;; }. * ``RTBS_AllDefinitions`` (in configuration: ``AllDefinitions``); Always break after the return type of function definitions. .. code-block:: c++. class A {; int; f() {; return 0;; };; };; int f();; int; f() {; return 1;; }. * ``RTBS_TopLevelDefinitions`` (in configuration: ``TopLevelDefinitions``); Always break after the return type of top-level definitions. .. code-block:: c++. class A {; int f() { return 0; };; };; int f();; int; f() {; return 1;; }. .. _AlwaysBreakBeforeMultilineStrings:. **AlwaysBreakBeforeMultilineStrings** (``Boolean``) :versionbadge:`clang-format 3.4` :ref:`¶ <AlwaysBreakBeforeMultilineStrings>`; If ``true``, always",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:33365,configurat,configuration,33365,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," deprecated and will be switched to read-only mode in October; 2023, for new code contributions use :ref:`GitHub Pull Requests <github-reviews>`.; This section contains old information that needs to be updated. * When performing the code review for the change, please add any applicable; ""vendors"" group to the review for their awareness. The purpose of these; groups is to give vendors early notice that potentially disruptive changes; are being considered but have not yet been accepted. Vendors can give early; testing feedback on the changes to alert us to unacceptable breakages. The; current list of vendor groups is:. * `Clang vendors <https://reviews.llvm.org/project/members/113/>`_; * `libc++ vendors <https://reviews.llvm.org/project/members/109/>`_. People interested in joining the vendors group can do so by clicking the; ""Join Project"" link on the vendor's ""Members"" page in Phabricator. * When committing the change to the repository, add appropriate information; about the potentially breaking changes to the ``Potentially Breaking Changes``; section of the project's release notes. The release note should have; information about what the change is, what is potentially disruptive about; it, as well as any code examples, links, and motivation that is appropriate; to share with users. This helps users to learn about potential issues with; upgrading to that release. * After the change has been committed to the repository, the potentially; disruptive changes described in the release notes should be posted to the; `Announcements <https://discourse.llvm.org/c/announce/>`_ channel on; Discourse. The post should be tagged with the ``potentially-breaking`` label; and a label specific to the project (such as ``clang``, ``llvm``, etc). This; is another mechanism by which we can give pre-release notice to users about; potentially disruptive changes. It is a lower-traffic alternative to the; joining ""vendors"" group. To automatically be notified of new announcements; with the ``po",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:6598,release,release,6598,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['release'],['release']
Deployability," derived pointer. By default RewriteStatepointsForGC passes in ``0xABCDEF00`` as the statepoint; ID and ``0`` as the number of patchable bytes to the newly constructed; ``gc.statepoint``. These values can be configured on a per-callsite; basis using the attributes ``""statepoint-id""`` and; ``""statepoint-num-patch-bytes""``. If a call site is marked with a; ``""statepoint-id""`` function attribute and its value is a positive; integer (represented as a string), then that value is used as the ID; of the newly constructed ``gc.statepoint``. If a call site is marked; with a ``""statepoint-num-patch-bytes""`` function attribute and its; value is a positive integer, then that value is used as the 'num patch; bytes' parameter of the newly constructed ``gc.statepoint``. The; ``""statepoint-id""`` and ``""statepoint-num-patch-bytes""`` attributes; are not propagated to the ``gc.statepoint`` call or invoke if they; could be successfully parsed. In practice, RewriteStatepointsForGC should be run much later in the pass; pipeline, after most optimization is already done. This helps to improve; the quality of the generated code when compiled with garbage collection support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memcpy and memmove operations:; GC leaf lowering and GC parseable lowering. If a call is explicitly marked with; ""gc-leaf-function"" attribute the call is lowered to a GC leaf call to; '``__llvm_memcpy_element_unordered_atomic_*``' or; '``__llvm_memmove_element_unordered_atomic_*``' symbol. Such a call can not; take a safepoint. Otherwise, the call is made G",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:29061,pipeline,pipeline,29061,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['pipeline'],['pipeline']
Deployability," described later.; Instructions are available on this; website on how to use open source builds of the analyzer as a replacement for; the one bundled with Xcode.; Using scan-build directly; If you wish to use scan-build with your iPhone project, keep the; following things in mind:. Analyze your project in the Debug configuration, either by setting; this as your configuration with Xcode or by passing -configuration; Debug to xcodebuild.; Analyze your project using the Simulator as your base SDK. It is; possible to analyze your code when targeting the device, but this is much; easier to do when using Xcode's Build and Analyze feature.; Check that your code signing SDK is set to the simulator SDK as well, and make sure this option is set to Don't Code Sign. Note that you can most of this without actually modifying your project. For; example, if your application targets iPhoneOS 2.2, you could run; scan-build in the following manner from the command line:. $ scan-build xcodebuild -configuration Debug -sdk iphonesimulator2.2. Alternatively, if your application targets iPhoneOS 3.0:. $ scan-build xcodebuild -configuration Debug -sdk iphonesimulator3.0. Gotcha: using the right compiler; Recall that scan-build analyzes your project by using a compiler to; compile the project and clang to analyze your project. The script uses; simple heuristics to determine which compiler should be used (it defaults to; clang on Darwin and gcc on other platforms). When analyzing; iPhone projects, scan-build may pick the wrong compiler than the one; Xcode would use to build your project. For example, this could be because; multiple versions of a compiler may be installed on your system, especially if; you are developing for the iPhone.; When compiling your application to run on the simulator, it is important that scan-build; finds the correct version of gcc/clang. Otherwise, you may see strange build; errors that only happen when you run scan-build. scan-build provides the --use-cc and --use-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/scan-build.html:9544,configurat,configuration,9544,interpreter/llvm-project/clang/www/analyzer/scan-build.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/scan-build.html,1,['configurat'],['configuration']
Deployability," development, e.g. libstdc++; and binutils. The interface to run the build is ``build_docker_image.sh`` script. It accepts a; list of LLVM repositories to checkout and arguments for CMake invocation. If you want to write your own docker image, start with an ``example/`` subfolder.; It provides an incomplete Dockerfile with (very few) FIXMEs explaining the steps; you need to take in order to make your Dockerfiles functional. Usage; =====; The ``llvm/utils/build_docker_image.sh`` script provides a rather high degree of; control on how to run the build. It allows you to specify the projects to; checkout from git and provide a list of CMake arguments to use during when; building LLVM inside docker container. Here's a very simple example of getting a docker image with clang binary,; compiled by the system compiler in the debian10 image:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Note that a build like that doesn't use a 2-stage build process that; you probably want for clang. Running a 2-stage build is a little more intricate,; this command will do that:. .. code-block:: bash. # Run a 2-stage build.; # LLVM_TARGETS_TO_BUILD=Native is to reduce stage1 compile time.; # Options, starting with BOOTSTRAP_* are passed to stage2 cmake invocation.; ./build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i stage2-install-clang -i stage2-install-clang-resource-headers \; 	-- \; 	-DLLVM_TARGETS_TO_BUILD=Native -DCMAKE_BUILD_TYPE=Release \; 	-DBOOTSTRAP_CMAKE_BUILD_TYPE=Release \; 	-DCLANG_ENABLE_BOOTSTRAP=ON -DCLANG_BOOTSTRAP_TARGETS=""install-clang;install-clang-resource-headers""; 	; This will produce a new image ``clang-debian10:staging`` from the latest; upstream revision.; After the image is built you can run ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:3851,install,install-clang,3851,interpreter/llvm-project/llvm/docs/Docker.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst,2,['install'],"['install-clang', 'install-clang-resource-headers']"
Deployability," directory. This is where tests will be run and temporary output files; placed. **environment** A dictionary representing the environment to use when executing; tests in the suite. **standalone_tests** When true, mark a directory with tests expected to be run; standalone. Test discovery is disabled for that directory. *lit.suffixes* and; *lit.excludes* must be empty when this variable is true. **suffixes** For **lit** test formats which scan directories for tests, this; variable is a list of suffixes to identify test files. Used by: *ShTest*. **substitutions** For **lit** test formats which substitute variables into a test; script, the list of substitutions to perform. Used by: *ShTest*. **unsupported** Mark an unsupported directory, all tests within it will be; reported as unsupported. Used by: *ShTest*. **parent** The parent configuration, this is the config object for the directory; containing the test suite, or None. **root** The root configuration. This is the top-most :program:`lit` configuration in; the project. **pipefail** Normally a test using a shell pipe fails if any of the commands; on the pipe fail. If this is not desired, setting this variable to false; makes the test fail only if the last command in the pipe fails. **available_features** A set of features that can be used in `XFAIL`,; `REQUIRES`, and `UNSUPPORTED` directives. TEST DISCOVERY; ~~~~~~~~~~~~~~. Once test suites are located, :program:`lit` recursively traverses the source; directory (following *test_source_root*) looking for tests. When :program:`lit`; enters a sub-directory, it first checks to see if a nested test suite is; defined in that directory. If so, it loads that test suite recursively,; otherwise it instantiates a local test config for the directory (see; :ref:`local-configuration-files`). Tests are identified by the test suite they are contained within, and the; relative path inside that suite. Note that the relative path may not refer to; an actual file on disk; some test forma",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:17027,configurat,configuration,17027,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['configurat'],['configuration']
Deployability," displayed objects should be updated.; 4. Implement 'opt' and 'opts' URL parameters for main page.; 5. Show progress with scripts loading in the browser window; 6. When one appends ""+"" to the filename, its content read completely with first I/O operation.; 7. Implement JS custom streamer for TCanvas, restore aspect ratio when drawing; 8. Major redesign of drawing classes. Resize and update of TCanvas are implemented.; All major draw functions working with HTML element id as first argument.; 9. Extract 3D drawings into separate JSRoot3DPainter.js script; 10. Use newest three.min.js (r68) for 3D drawings, solves problem with Firefox.; 11. Introduce generic list of draw functions for all supported classes.; 12. Add possibility to 'expand' normal objects in the hierarchy browser.; For instance, this gives access to single elements of canvas,; when whole canvas cannot be drawn.; 13. Correct usage of colors map, provided with TCanvas.; 14. Introduce JSROOT.redraw() function which is capable to create or update object drawing.; 15. In main index.htm page browser can be disabled (nobrowser parameter) and; page can be used to display only specified items from the file; 16. Add support of TPolyMarker3D in binary I/O. ### September 2014; 1. First try to handle resize of the browser,; for the moment works only with collapsible layout; 2. Also first try to interactively move separation line between; browser and drawing field.; 3. Small fix of minor ticks drawing on the axis; 4. Introduce display class for MDI drawing. Provide two implementations -; 'collapsible' for old kind and 'tabs' for new kinds.; 5. Adjust size of color palette drawing when labels would take more place as provided.; 6. Add correct filling of statistic for TProfile,; fix small problem with underflow/overflow bins.; 7. Provide way to select display kind ('collapsible', 'tabs') in the simple GUI.; 8. Implement 'grid' display, one could specify any number of division like; 'grid 3x3' or 'grid 4x2'.; 9. MDI disp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:71719,update,update,71719,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['update'],['update']
Deployability," do not follow the; project how the C API is changing and evolving. .. _toolchain:. Updating Toolchain Requirements; -------------------------------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM can be painful for those building LLVM; therefore, it; will only be done through the following process:. * It is a general goal to support LLVM and GCC versions from the last 3 years; at a minimum. This time-based guideline is not strict: we may support much; older compilers, or decide to support fewer versions. * An RFC is sent to the `LLVM Discourse forums`_. - Detail upsides of the version increase (e.g. which newer C++ language or; library features LLVM should use; avoid miscompiles in particular compiler; versions, etc).; - Detail downsides on important platforms (e.g. Ubuntu LTS status). * Once the RFC reaches consensus, update the CMake toolchain version checks as; well as the :doc:`getting started<GettingStarted>` guide. This provides a; softer transition path for developers compiling LLVM, because the; error can be turned into a warning using a CMake flag. This is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:34795,update,update,34795,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['update'],['update']
Deployability," do not; have any doc in them. With a direct link to the GitHub source file the dependency between source; code and json is now more obvious.; - Document how to remove shadow of `TPave`, as it was not evident (only explanations were hidden here and there in the forum).; - Improve the `SetFillColorAlpha` documentation.; - Simplify some graphics examples: arrow.C, crown.C, diamond.C and ellipse.C.; - Fix a typo in the documentation of `TGraph::SetHighlight` in `TGraph.cxx`.; - Change the marker style in the tutorial `df014_CSVDataSource`.; - Remove useless settings in the tutorial `scatter.C`.; - Fix the tutorial `h1analysisTreeReader.C`.; - Fix doxygen formatting in `TGNumberEntry.cxx`.; - Avoid the CDT documentation to appear in the reference guide.; - Remove last references to the old ROOT `drupal` website. ## Build, Configuration and Testing Infrastructure. Release v6.32.00 is the first one integrated and tested entirely through the new GitHub based build system. ## Bugs and Issues fixed in this release. More than 200 items were addressed for this release. The full list is:. * [[#15621](https://github.com/root-project/root/issues/15621)] - Buffer overflow in TBranch::Init; * [[#15610](https://github.com/root-project/root/issues/15610)] - Memory leak in TTree __getattr__ pythonization; * [[#15590](https://github.com/root-project/root/issues/15590)] - Infinite recursion in TFile::Open; * [[#15460](https://github.com/root-project/root/issues/15460)] - TEnum::GetEnum(""B"")->GetUnderlyingType() does not following typedefs; * [[#15413](https://github.com/root-project/root/issues/15413)] - Fails to build with cuDNN version 9; * [[#15406](https://github.com/root-project/root/issues/15406)] - `TEnum::GetEnum` does not seem to see 'through' using statements.; * [[#15399](https://github.com/root-project/root/issues/15399)] - Memory leak with jitted nodes if the execution is never triggered; * [[#15396](https://github.com/root-project/root/issues/15396)] - [TMVA] Pymva test (K",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:24777,release,release,24777,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['release'],['release']
Deployability," done for arguments that are only; stored to (returning the value instead), but does not currently. This case; would be best handled when and if LLVM starts supporting multiple return values; from functions. ``block-placement``: Profile Guided Basic Block Placement; ---------------------------------------------------------. This pass is a very simple profile guided basic block placement algorithm. The; idea is to put frequently executed blocks together at the start of the function; and hopefully increase the number of fall-through conditional branches. If; there is no profile information for a particular function, this pass basically; orders blocks in depth-first order. ``break-crit-edges``: Break critical edges in CFG; -------------------------------------------------. Break all of the critical edges in the CFG by inserting a dummy basic block.; It may be ""required"" by passes that cannot deal with critical edges. This; transformation obviously invalidates the CFG, but can update forward dominator; (set, immediate dominators, tree, and frontier) information. ``codegenprepare``: Optimize for code generation; ------------------------------------------------. This pass munges the code in the input function to better prepare it for; SelectionDAG-based code generation. This works around limitations in its; basic-block-at-a-time approach. It should eventually be removed. ``constmerge``: Merge Duplicate Global Constants; ------------------------------------------------. Merges duplicate global constants together into a single constant that is; shared. This is useful because some passes (i.e., TraceValues) insert a lot of; string constants into the program, regardless of whether or not an existing; string is available. .. _passes-dce:. ``dce``: Dead Code Elimination; ------------------------------. Dead code elimination is similar to dead instruction elimination, but it; rechecks instructions that were used by removed instructions to see if they; are newly dead. ``deadargeli",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:14300,update,update,14300,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['update'],['update']
Deployability," double %iftmp; }. This is a trivial case for mem2reg, since there are no redefinitions of; the variable. The point of showing this is to calm your tension about; inserting such blatant inefficiencies :). After the rest of the optimizers run, we get:. .. code-block:: llvm. define double @fib(double %x) {; entry:; %cmptmp = fcmp ult double %x, 3.000000e+00; %booltmp = uitofp i1 %cmptmp to double; %ifcond = fcmp ueq double %booltmp, 0.000000e+00; br i1 %ifcond, label %else, label %ifcont. else:; %subtmp = fsub double %x, 1.000000e+00; %calltmp = call double @fib(double %subtmp); %subtmp5 = fsub double %x, 2.000000e+00; %calltmp6 = call double @fib(double %subtmp5); %addtmp = fadd double %calltmp, %calltmp6; ret double %addtmp. ifcont:; ret double 1.000000e+00; }. Here we see that the simplifycfg pass decided to clone the return; instruction into the end of the 'else' block. This allowed it to; eliminate some branches and the PHI node. Now that all symbol table references are updated to use stack variables,; we'll add the assignment operator. New Assignment Operator; =======================. With our current framework, adding a new assignment operator is really; simple. We will parse it just like any other binary operator, but handle; it internally (instead of allowing the user to define it). The first; step is to set a precedence:. .. code-block:: c++. int main() {; // Install standard binary operators.; // 1 is lowest precedence.; BinopPrecedence['='] = 2;; BinopPrecedence['<'] = 10;; BinopPrecedence['+'] = 20;; BinopPrecedence['-'] = 20;. Now that the parser knows the precedence of the binary operator, it; takes care of all the parsing and AST generation. We just need to; implement codegen for the assignment operator. This looks like:. .. code-block:: c++. Value *BinaryExprAST::codegen() {; // Special case '=' because we don't want to emit the LHS as an expression.; if (Op == '=') {; // This assume we're building without RTTI because LLVM builds that way by; // defau",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:20004,update,updated,20004,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['update'],['updated']
Deployability," draw options:; - ""RX"" and ""RY"" for TGraph to reverse axis; - ""noopt"" for TGraph to disable drawing optimization; - ""CPN"" for TCanvas to create color palette from N last colors; - ""line"" for TGraph2D; * New features:; - support LZ4 compression; - tooltips and zooming in TGraphPolar drawings; - TPavesText with multiple underlying paves; - implement all fill styles; - draw borders for TWbox; - draw all objects from TList/TObjArray as they appear in list of primitives; - let enable/disable highlight of extra objects in geometry viewer; - draw axis labels on both sides when pad.fTick[x/y] > 1; - make drawing of TCanvas with many primitives smoother; - add fOptTitle, fOptLogx/y/z fields in JSROOT.gStyle; * Behavior changes:; - disable automatic frame adjustment, can be enabled with ""&adjframe"" parameter in URL; - when drawing TH2/TH3 scatter plots, always generate same ""random"" pattern; - use barwidth/baroffset parameters in lego plots; * Bug fixes:; - use same number of points to draw lines and markers on the TGraph; - correctly draw filled TArrow endings; - let combine ""L"" or ""C"" TGraph draw option with others; - correct positioning of custom axis labels; - correctly toggle lin/log axes in lego plot; - let correctly change marker attributes interactively ; - monitoring mode in draw.htm page; - zooming in colz palette; - support both 9.x and 10.x jsdom version in Node.js (#149); - draw axis main line with appropriate attributes (#150); - use axis color when drawing grids lines (#150); - when set pad logx/logy, reset existing user ranges in pad; - avoid too deep calling stack when drawing many graphs or histos (#154); - correctly (re)draw tooltips on canvas with many subpads. ## Code Examples. - New graphics tutorial AtlasExample.C illustrating the ATLAS style.; - New TLazyDS tutorial added tdf015_LazyDataSource.C.; - Show how to inspect a `TCutFlowReport` object. ## Class Reference Guide. - Replace low resolution images with bigger ones more suited for modern screens. ##",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:16805,toggle,toggle,16805,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,1,['toggle'],['toggle']
Deployability," drawing; in a new filename. - *Print*: popup a dialog to print the current canvas drawing. - *Quit ROOT*: exit the ROOT session. ![](pictures/0300000B.png). #### Edit Menu. There is only one active menu entry in the Edit menu. The others menu; entries will be implemented and will become active in the near future. - *Clear:* delete all objects in the canvas; or in the selected pad according to the selected entry in the; submenu. #### View Menu. - *Editor*: toggles the view of the editor. If it is selected; activates and shows up the editor on the left side of the canvas; window. According to the selected object, the editor loads the; corresponding user interface for easy change of the object's; attributes. - *Toolbar*: toggles the view of the toolbar. If it is selected; activates and shows up the toolbar. It contains buttons for easy; and fast access to most frequently used commands and for graphics; primitive drawing. Tool tips are provided for helping users. - *Status Bar*: toggles the view of the status bar. If it is; selected, the status bar below the canvas window shows up. There; the identification of the objects is displayed when moving the; mouse (such as the object's name, the object's type, its; coordinates, etc.). - *Colors*: creates a new canvas showing the color palette. - *Markers*: creates a new canvas showing the various marker styles. - *Iconify*: create the canvas window icon, does not close the; canvas. - *View With...*: If the last selected pad contains a 3-d structure,; a new canvas is created with a 3-D picture according to the; selection made from the cascaded menu: X3D or OpenGL. The 3-D; image can be interactively rotated, zoomed in wire-frame, solid,; hidden line or stereo mode. ![](pictures/0300000C.png). #### Options Menu. - *Auto Resize Canvas*: turns auto-resize of the canvas *on/off*:. - *on* - the canvas fits to the window when changing the window; size;; - *off* - the canvas stays fixed when changing the window size. - *Resize Canvas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md:8996,toggle,toggles,8996,documentation/users-guide/GettingStarted.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md,1,['toggle'],['toggles']
Deployability," dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that go on that branch, with the exception that we will fix an unintentional; C API break that will keep the release consistent with both the previous and; next release. * Testing: Patches to the C API are expected to come with tests just like any; other patch. * Including new things into the API: If an LLVM subcomponent has a C API already; included, then expanding that C API is acceptable. Adding C API for; subcomponents that don't currently have one needs to be discussed on the; `LLVM Discourse forums`_ for design and maintainability feedback prior to implementation. * Documentation: Any changes to the C API are required to be documented in the; release notes so that it's clear to external users who do not follow the; project how the C API is changing and evolving. .. _toolchain:. Updating Toolchain Requirements; -------------------------------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM can be painful for those building LLVM; therefore, it; will only be done through the following process:. * It is a general goal to support LLVM and GCC versions from the las",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:33373,patch,patch,33373,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['patch'],['patch']
Deployability," due to importing all C++ Modules at startup; we see overhead which depends on the number of preloaded modules. For; ROOT it is between 40-60 MB depending on the concrete configuration.; When the workload increases we notice that the overall memory performance; decreases in number of cases.; * Execution times -- likewise we have an execution overhead. For ; workflows which take ms the slowdown can be 2x. Increasing of the work; to seconds shows 50-60% slowdowns. The performance is dependent on many factors such as configuration of ROOT and; workflow. You can read more at our Intel IPCC-ROOT Showcase presentation; here (pp 25-33)[[8]]. #### Loading C++ Modules on Demand. In long term, we should optimize the preloading of modules to be a no-op and; avoid recursive behavior based on identifier lookup callbacks. Unfortunately,; at the moment the loading of C++ modules on demand shows significantly better; performance results. You can visit our continuous performance monitoring tool where we compare; the performance of ROOT against ROOT with a PCH [[9]].; *Note: if you get error 400, clean your cache or open a private browser session.*. ## How to use; C++ Modules in ROOT are default since v6.20 (Unix) and v6.22 (OSX). Enjoy. To disable C++ Modules in ROOT use `-Druntime_cxxmodules=Off`. ## Citing ROOT's C++ Modules; ```latex; % Peer-Reviewed Publication; %; % 22nd International Conference on Computing in High Energy and Nuclear Physics (CHEP); % 8-14 October, 2016, San Francisco, USA; %; @inproceedings{Vassilev_ROOTModules,; author = {Vassilev,V.},; title = {{Optimizing ROOT's Performance Using C++ Modules}},; journal = {Journal of Physics: Conference Series},; year = 2017,; month = {oct},; volume = {898},; number = {7},; pages = {072023},; doi = {10.1088/1742-6596/898/7/072023},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/898/7/072023/pdf},; publisher = {{IOP} Publishing}; }; ```; ; # Acknowledgement. We would like to thank the ROOT team. We would like ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:19158,continuous,continuous,19158,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['continuous'],['continuous']
Deployability," during the; code review stage and do not pollute the main branch. Our goal with pre-merge testing is to report most true problems while strongly; minimizing the number of false positive reports. Our goal is that problems; reported are always actionable. If you notice a false positive, please report; it so that we can identify the cause. If you notice issues or have an idea on how to improve pre-merge checks, please; `create a new issue <https://github.com/google/llvm-premerge-checks/issues/new>`_; or give a ❤️ to an existing one. Requirements; ^^^^^^^^^^^^. To get a patch on Phabricator tested, the build server must be able to apply the; patch to the checked out git repository. Please make sure that either:. * You set a git hash as ``sourceControlBaseRevision`` in Phabricator which is; available on the GitHub repository,; * **or** you define the dependencies of your patch in Phabricator,; * **or** your patch can be applied to the main branch. Only then can the build server apply the patch locally and run the builds and; tests. Accessing build results; ^^^^^^^^^^^^^^^^^^^^^^^; Phabricator will automatically trigger a build for every new patch you upload or; modify. Phabricator shows the build results at the top of the entry. Clicking on; the links (in the red box) will show more details:. .. image:: Phabricator_premerge_results.png. The CI will compile and run tests, run clang-format and clang-tidy on lines; changed. If a unit test failed, this is shown below the build status. You can also expand; the unit test to see the details:. .. image:: Phabricator_premerge_unit_tests.png. Opting Out; ^^^^^^^^^^. In case you want to opt-out entirely of pre-merge testing, add yourself to the; `OPT OUT project <https://reviews.llvm.org/project/view/83/>`_. If you decide; to opt-out, please let us know why, so we might be able to improve in the future. Operational Details; ^^^^^^^^^^^^^^^^^^^. The code responsible for running the pre-merge flow can be found in the `external; repo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst:11745,patch,patch,11745,interpreter/llvm-project/llvm/docs/Phabricator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst,1,['patch'],['patch']
Deployability," elements which are not zero; - Add `Reverse` helepr: return copy of reversed RVec.; - Add `Sort` helper: return copy of vector with elements sorted in ascending order (also according to a user defined predicate); - Add `Take` helper which can:; - return elements of a RVec at given indices.; - return first elements or last elements of an RVec.; - Add `Where` helper which can:; - return the elements of v1 if the condition c is true and v2 if the condition c is false.; - return the elements of v1 if the condition c is true and sets the value v2 if the condition c is false.; - return the elements of v2 if the condition c is false and sets the value v1 if the condition c is true.; - return a vector with the value v2 if the condition c is false and sets the value v1 if the condition c is true. ## RooFit Libraries; - Add value printer for RooAbsArg and daughters.; - Add a Python version for the majority of the Tutorials. ## TMVA Library. ### Deep Learning. This release contains several fixes and improvement for the `MethodDL`. The `MethodDL` is also now the recommended class to use for Deep Learning in TMVA and is replacing the previous existing; `MethodDNN`, which is still available, but it has a limited functionality and it supports only dense layer. The new features of `MethodDL` are:. - Support training and evaluation of Convolutional layer on GPU; - Several ML optimizers are now included and they can be used in addition to SGD. These are ADAM (the new default), ADAGRAD,; RMSPROP, ADADELTA. A new option, *Optimizer* has been added in the option string used to define the training strategy options.; - Add support for regression in MethodDL; - Use single precision (float) types as the fundamental type for the neural network architecture. Double precision could be enabled, but it will require recompiling TMVA. ; - Support inference (network evaluation) in batch mode in addition to single event. Batch mode evaluation is now the default when used within the `TMVA::Factory` ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md:13115,release,release,13115,README/ReleaseNotes/v616/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md,1,['release'],['release']
Deployability," emit a stack smashing; protector. This attribute causes a strong heuristic to be used when; determining if a function needs stack protectors. The strong heuristic; will enable protectors for functions with:. - Arrays of any size and type; - Aggregates containing an array of any size and type.; - Calls to alloca().; - Local variables that have had their address taken. Variables that are identified as requiring a protector will be arranged; on the stack such that they are adjacent to the stack protector guard.; The specific layout rules are:. #. Large arrays and structures containing large arrays; (``>= ssp-buffer-size``) are closest to the stack protector.; #. Small arrays and structures containing small arrays; (``< ssp-buffer-size``) are 2nd closest to the protector.; #. Variables that have had their address taken are 3rd closest to the; protector. This overrides the ``ssp`` function attribute. If a function with an ``sspstrong`` attribute is inlined into a calling; function which has an ``ssp`` attribute, the calling function's attribute; will be upgraded to ``sspstrong``. ``sspreq``; This attribute indicates that the function should *always* emit a stack; smashing protector. This overrides the ``ssp`` and ``sspstrong`` function; attributes. Variables that are identified as requiring a protector will be arranged; on the stack such that they are adjacent to the stack protector guard.; The specific layout rules are:. #. Large arrays and structures containing large arrays; (``>= ssp-buffer-size``) are closest to the stack protector.; #. Small arrays and structures containing small arrays; (``< ssp-buffer-size``) are 2nd closest to the protector.; #. Variables that have had their address taken are 3rd closest to the; protector. If a function with an ``sspreq`` attribute is inlined into a calling; function which has an ``ssp`` or ``sspstrong`` attribute, the calling; function's attribute will be upgraded to ``sspreq``. ``strictfp``; This attribute indicates that the fu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:104708,upgrade,upgraded,104708,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['upgrade'],['upgraded']
Deployability," enabled by default for Darwin (Apple platform) targets. Deprecated Compiler Flags; -------------------------. Modified Compiler Flags; -----------------------. * ``-Woverriding-t-option`` is renamed to ``-Woverriding-option``.; * ``-Winterrupt-service-routine`` is renamed to ``-Wexcessive-regsave`` as a generalization; * ``-frewrite-includes`` now guards the original #include directives with; ``__CLANG_REWRITTEN_INCLUDES``, and ``__CLANG_REWRITTEN_SYSTEM_INCLUDES`` as; appropriate.; * Introducing a new default calling convention for ``-fdefault-calling-conv``:; ``rtdcall``. This new default CC only works for M68k and will use the new; ``m68k_rtdcc`` CC on every functions that are not variadic. The ``-mrtd``; driver/frontend flag has the same effect when targeting M68k.; * ``-fvisibility-global-new-delete-hidden`` is now a deprecated spelling of; ``-fvisibility-global-new-delete=force-hidden`` (``-fvisibility-global-new-delete=``; is new in this release).; * ``-fprofile-update`` is enabled for ``-fprofile-generate``. Removed Compiler Flags; -------------------------. * ``-enable-trivial-auto-var-init-zero-knowing-it-will-be-removed-from-clang`` has been removed.; It has not been needed to enable ``-ftrivial-auto-var-init=zero`` since Clang 16. Attribute Changes in Clang; --------------------------; - On X86, a warning is now emitted if a function with ``__attribute__((no_caller_saved_registers))``; calls a function without ``__attribute__((no_caller_saved_registers))``, and is not compiled with; ``-mgeneral-regs-only``; - On X86, a function with ``__attribute__((interrupt))`` can now call a function without; ``__attribute__((no_caller_saved_registers))`` provided that it is compiled with ``-mgeneral-regs-only``. - When a non-variadic function is decorated with the ``format`` attribute,; Clang now checks that the format string would match the function's parameters'; types after default argument promotion. As a result, it's no longer an; automatic diagnostic to use par",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:19021,update,update,19021,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['update'],['update']
Deployability," enabled individually; using the ``-fxray-instrumentation-bundle=`` flag. For example if you only wanted to; instrument function entry and custom points you could specify:. ::. clang -fxray-instrument -fxray-instrumentation-bundle=function-entry,custom ... This will omit the other sled types entirely, reducing the binary size. You can also; instrument just a sampled subset of functions using instrumentation groups.; For example, to instrument only a quarter of available functions invoke:. ::. clang -fxray-instrument -fxray-function-groups=4. A subset will be chosen arbitrarily based on a hash of the function name. To sample a; different subset you can specify ``-fxray-selected-function-group=`` with a group number; in the range of 0 to ``xray-function-groups`` - 1. Together these options could be used; to produce multiple binaries with different instrumented subsets. If all you need is; runtime control over which functions are being traced at any given time it is better; to selectively patch and unpatch the individual functions you need using the XRay; Runtime Library's ``__xray_patch_function()`` method. Future Work; ===========. There are a number of ongoing efforts for expanding the toolset building around; the XRay instrumentation system. Trace Analysis Tools; --------------------. - Work is in progress to integrate with or develop tools to visualize findings; from an XRay trace. Particularly, the ``stack`` tool is being expanded to; output formats that allow graphing and exploring the duration of time in each; call stack.; - With a large instrumented binary, the size of generated XRay traces can; quickly become unwieldy. We are working on integrating pruning techniques and; heuristics for the analysis tools to sift through the traces and surface only; relevant information. More Platforms; --------------. We're looking forward to contributions to port XRay to more architectures and; operating systems. .. References... .. _`XRay whitepaper`: http://research.google",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:14112,patch,patch,14112,interpreter/llvm-project/llvm/docs/XRay.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst,1,['patch'],['patch']
Deployability," endforeach(). foreach(LibexecFile ${LibexecFiles}); add_custom_command(OUTPUT ${CMAKE_BINARY_DIR}/libexec/${LibexecFile}; COMMAND ${CMAKE_COMMAND} -E make_directory; ${CMAKE_BINARY_DIR}/libexec; COMMAND ${CMAKE_COMMAND} -E copy; ${CMAKE_CURRENT_SOURCE_DIR}/libexec/${LibexecFile}; ${CMAKE_BINARY_DIR}/libexec/; DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/libexec/${LibexecFile}); list(APPEND Depends ${CMAKE_BINARY_DIR}/libexec/${LibexecFile}); install(PROGRAMS libexec/${LibexecFile}; DESTINATION ""${CMAKE_INSTALL_LIBEXECDIR}""; COMPONENT scan-build); endforeach(). foreach(ManPage ${ManPages}); add_custom_command(OUTPUT ""${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_MANDIR}/man1/${ManPage}""; COMMAND ${CMAKE_COMMAND} -E make_directory; ""${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_MANDIR}/man1""; COMMAND ${CMAKE_COMMAND} -E copy; ""${CMAKE_CURRENT_SOURCE_DIR}/man/${ManPage}""; ""${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_MANDIR}/man1/""; DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/man/${ManPage}); list(APPEND Depends ""${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_MANDIR}/man1/${ManPage}""); install(FILES man/${ManPage}; DESTINATION ""${CMAKE_INSTALL_MANDIR}/man1""; COMPONENT scan-build); endforeach(). foreach(ShareFile ${ShareFiles}); add_custom_command(OUTPUT ${CMAKE_BINARY_DIR}/share/scan-build/${ShareFile}; COMMAND ${CMAKE_COMMAND} -E make_directory; ${CMAKE_BINARY_DIR}/share/scan-build; COMMAND ${CMAKE_COMMAND} -E copy; ${CMAKE_CURRENT_SOURCE_DIR}/share/scan-build/${ShareFile}; ${CMAKE_BINARY_DIR}/share/scan-build/; DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/share/scan-build/${ShareFile}); list(APPEND Depends ${CMAKE_BINARY_DIR}/share/scan-build/${ShareFile}); install(FILES share/scan-build/${ShareFile}; DESTINATION ""${CMAKE_INSTALL_DATADIR}/scan-build""; COMPONENT scan-build); endforeach(). add_custom_target(scan-build ALL DEPENDS ${Depends}); set_target_properties(scan-build PROPERTIES FOLDER ""Misc""). if(NOT LLVM_ENABLE_IDE); add_llvm_install_targets(""install-scan-build""; DEPENDS scan-build; COMPONENT scan-build); endif(); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build/CMakeLists.txt:2607,install,install,2607,interpreter/llvm-project/clang/tools/scan-build/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build/CMakeLists.txt,2,['install'],"['install', 'install-scan-build']"
Deployability," example on; how to use this class. New statistical functions ROOT::Math::landau_quantile (inverse of landau cumulative distribution); translated from RANLAN and; ROOT::Math::landau_quantile_c.; ; New statistical functions; ROOT::Math::negative_binomial_pdf and the cumulative distributions; ROOT::Math::negative_binomial_cdf and ROOT::Math::negative_binomial_cdf_c.; ; New special functions: sine and cosine integral, translated by; B. List from CERNLIB:; ROOT::Math::sinint and ROOT::Math::cosint. New classes ROOT::Math::IOptions and; ROOT::Math::GenAlgoOptions for dealing in general with the; options for the numerical algorithm. The first one is the interface; for the second and defines the setting and retrieval of generic pair; of (name,value) options.; They are used for defining possible extra; options for the minimizer, integration and sampler options.; ; Integration classes:; ; Fix a bug in the templated method setting the integrand; function; Use now IntegrationOneDim::kADAPTIVESINGULAR as default method for the 1D; integration; Add the method IntegrationOneDim::kLEGENDRE based on; the GaussLegendreIntegrator class. ; Implement also for the GaussIntegrator and; GaussLegendreIntegrator the undefined and semi-undefined integral; using a function transformation as it is done in the GSLIntegrator; Fix a bug in IntegratorOneDim::SetAbsTolerance; New class ROOT::Math::IntegratorOptions which can be passed to; all integrator allowing the user to give options to the class and in; particular default value. Via the support for extra options (with; the class ROOT::Math::IOptions generic (string,value); options can be used in the base class to define specific options for; the implementations. For example for the MCIntegrator class,; specific options can now be passed to VEGAS or MISER.; . Improve the root finder and 1D minimization classes (BrentRootFinder; and BrentMinimizer1D) by fixing a bug in the Brent method (see rev. 32544); and adding possibility to pass the tolerance",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v528/index.html:5365,integrat,integration,5365,math/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v528/index.html,1,['integrat'],['integration']
Deployability," exclude really-install from main target; set_target_properties(${NEXT_CLANG_STAGE} PROPERTIES _EP_really-install_EXCLUDE_FROM_MAIN On); ExternalProject_Add_Step(${NEXT_CLANG_STAGE} really-install; COMMAND ${CMAKE_COMMAND} --build <BINARY_DIR> --target install; COMMENT ""Performing install step for '${NEXT_CLANG_STAGE}'""; DEPENDEES build; USES_TERMINAL 1; ); ExternalProject_Add_StepTargets(${NEXT_CLANG_STAGE} really-install); add_custom_target(${NEXT_CLANG_STAGE}-install DEPENDS ${NEXT_CLANG_STAGE}-really-install). if(NOT CLANG_BOOTSTRAP_TARGETS); set(CLANG_BOOTSTRAP_TARGETS check-llvm check-clang check-all); endif(); foreach(target ${CLANG_BOOTSTRAP_TARGETS}); # Install targets have side effects, so we always want to execute them.; # ""install"" is reserved by CMake and can't be used as a step name for; # ExternalProject_Add_Step, so we can match against ""^install-"" instead of; # ""^install"" to get a tighter match. CMake's installation scripts already; # skip up-to-date files, so there's no behavior change if you install to the; # same destination multiple times.; if(target MATCHES ""^install-""); set(step_always ON); else(); set(step_always OFF); endif(). ExternalProject_Add_Step(${NEXT_CLANG_STAGE} ${target}; COMMAND ${CMAKE_COMMAND} --build <BINARY_DIR> --target ${target}; COMMENT ""Performing ${target} for '${NEXT_CLANG_STAGE}'""; DEPENDEES configure; ALWAYS ${step_always}; EXCLUDE_FROM_MAIN ON; USES_TERMINAL 1; ). if(target MATCHES ""^stage[0-9]*""); add_custom_target(${target} DEPENDS ${NEXT_CLANG_STAGE}-${target}); endif(). ExternalProject_Add_StepTargets(${NEXT_CLANG_STAGE} ${target}); endforeach(); endif(). if (CLANG_BOLT_INSTRUMENT AND NOT LLVM_BUILD_INSTRUMENTED); set(CLANG_PATH ${LLVM_RUNTIME_OUTPUT_INTDIR}/clang); set(CLANG_INSTRUMENTED ${CLANG_PATH}-bolt.inst); set(BOLT_FDATA ${CMAKE_CURRENT_BINARY_DIR}/utils/perf-training/prof.fdata). # Instrument clang with BOLT; add_custom_target(clang-instrumented; DEPENDS ${CLANG_INSTRUMENTED}; ); add_custom_command(OUTPUT ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt:29886,install,installation,29886,interpreter/llvm-project/clang/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt,2,['install'],"['install', 'installation']"
Deployability," executable built for each tool (in; ``$(LLVM_OBJ_ROOT)/bin``). This ensures that :program:`lit` does; not invoke any stray LLVM tools in the user's path during testing. Each RUN line is executed on its own, distinct from other lines unless; its last character is ``\``. This continuation character causes the RUN; line to be concatenated with the next one. In this way you can build up; long pipelines of commands without making huge line lengths. The lines; ending in ``\`` are concatenated until a RUN line that doesn't end in; ``\`` is found. This concatenated set of RUN lines then constitutes one; execution. :program:`lit` will substitute variables and arrange for the pipeline; to be executed. If any process in the pipeline fails, the entire line (and; test case) fails too. Below is an example of legal RUN lines in a ``.ll`` file:. .. code-block:: llvm. ; RUN: llvm-as < %s | llvm-dis > %t1; ; RUN: llvm-dis < %s.bc-13 > %t2; ; RUN: diff %t1 %t2. As with a Unix shell, the RUN lines permit pipelines and I/O; redirection to be used. There are some quoting rules that you must pay attention to when writing; your RUN lines. In general nothing needs to be quoted. :program:`lit` won't; strip off any quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating ass",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:10163,pipeline,pipelines,10163,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['pipeline'],['pipelines']
Deployability," execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If not TgSplit execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_inv and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:319025,release,released,319025,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['released']
Deployability," execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If not TgSplit execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:268512,release,released,268512,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['released']
Deployability," expression transformations; N2846; Unknown. Contradiction about INFINITY macro; N2848; Unknown. Require exact-width integer type interfaces; N2872; Yes. @, $, and ‘ in the source/execution character set; N2701; Yes. Quantum exponent of NaN (version 2); N2754; Unknown. The noreturn attribute; N2764; Clang 15. *_HAS_SUBNORM==0 implies what?; N2797; Yes. Disambiguate the storage class of some compound literals; N2819; Unknown. Add annotations for unreachable control flow v2; N2826; Clang 17. Unicode Sequences More Than 21 Bits are a Constraint Violation r0; N2828; Clang 3.6. Identifier Syntax using Unicode Standard Annex 31; N2836; Clang 15. No function declarators without prototypes; N2841; Clang 15. Remove default argument promotions for _FloatN types; N2844; No. Revised Suggestions of Change for Numerically Equal/Equivalent; N2847; Yes. 5.2.4.2.2 Cleanup, Again Again (N2806 update); N2879; Yes. char8_t: A type for UTF-8 characters and strings; N2653; No. Clarification for max exponent macros-update; N2882; Unknown. Consistent, Warningless, and Intuitive Initialization with {}. ; N2900; Clang 17. ; N3011; Clang 17. Not-so-magic: typeof. ; N2927; Clang 16. ; N2930; Clang 16. Type annex tgmath narrowing macros with integer args v2; N2931; Unknown. Revise spelling of keywords v7; N2934; Clang 17. Make false and true first-class language features v8; N2935; Clang 15. Properly define blocks as part of the grammar v3; N2937; Yes. Annex X (replacing Annex H) for IEC 60559 interchange; N2601; No. Indeterminate Values and Trap Representations; N2861; Yes. Remove ATOMIC_VAR_INIT v2; N2886; Clang 17. Require exact-width integer type interfaces v2; N2888; Yes. Wording Change for Variably-Modified Types; N2992; Yes. Identifier syntax fixes; N2939; Clang 15. Remove trigraphs??!; N2940; Clang 18. Improved normal enumerations; N3029; Unknown. Relax requirements for va_start; N2975; Clang 16. Enhanced enumerations; N3030; Unknown. Freestanding C and IEC 60559 conformance scope reduc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_status.html:11853,update,update,11853,interpreter/llvm-project/clang/www/c_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_status.html,1,['update'],['update']
Deployability," fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructionselect`. .. _progress-fastisel:. FastISel Replacement; --------------------. For the initial FastISel replacement, we intend to fallback to SelectionDAG on; selection failures. Currently, compile-time of the fast pipeline is within 1.5x of FastISel.; We're optimistic we can get to within 1.1/1.2x, but beating FastISel will be; challenging given the multi-pass approach.; Still, supporting all IR (via a complete legalizer) and avoiding the fallback; to SelectionDAG in the worst case should enable better amortized performance; than SelectionDAG+FastISel. ``NOTE``:; We considered never having a fallback to SelectionDAG, instead deciding early; whether a given function is supported by GlobalISel or not. The decision would; be based on :ref:`milegalizer` queries.; We abandoned that for two reasons:; a) on IR inputs, we'd need to basically simulate the :ref:`irtranslator`;; b) to be robust against unforeseen failures and to enable iterative; improvements.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:2528,pipeline,pipeline,2528,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,1,['pipeline'],['pipeline']
Deployability," fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:279354,release,release-fence-paired-atomic,279354,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release-fence-paired-atomic']
Deployability," files opened even further. Update hadd and TFileMerger so that they prefix all their information message; with their names (when running hadd, the TFileMerger message are prefixed by hadd):. $ hadd -v 0 -f output.root input1.root input2.root; $ hadd -v 1 -f output.root input1.root input2.root; hadd merged 2 input files in output.root.; $ hadd -v 2 -f output.root input1.root input2.root; hadd target file: output.root; hadd Source file 1: input1.root; hadd Source file 2: input2.root; hadd Target path: output.root:/. Introduce non-static version of TFile::Cp allows the copy of; an existing TFile object. Introduce new explicit interface for providing reseting; capability after a merge. If a class has a method with; the name and signature:. void ResetAfterMerge(TFileMergeInfo*);. it will be used by a TMemFile to reset its objects after; a merge operation has been done. If this method does not exist, the TClass will use; a method with the name and signature:. void Reset(Optiont_t *);. TClass now provides a quick access to these merging; function via TClass::GetResetAfterMerge. The wrapper function; is automatically created by rootcint and can be installed; via TClass::SetResetAfterMerge. The wrapper function should have; the signature/type ROOT::ResetAfterMergeFunc_t:. void (*)(void *thisobj, TFileMergeInfo*);. ResetAfterMerge functions were added to the following classes:; TDirectoryFile, TMemFile, TTree, TChain, TBranch, TBranchElement,; TBranchClones, TBranchObject and TBranchRef. Avoid leaking the inner object in a container like vector<vector<MyClass*> > ; and vector<vector<MyClass*> *> . Put in place the infrastructure to optimize the I/O writes in the same way we optimized the I/O reads. Add the function TBuffer::AutoExpand to centralize the automatic; buffer extension policy. This enable the ability to tweak it later; (for example instead of always doubling the size, increasing by; only at most 2Mb or take hints from the number of entries already; in a TBasket). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html:8916,install,installed,8916,io/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html,1,['install'],['installed']
Deployability," fitter class, ROOT::Fit::Fitter is used now to implement the fit functionality of the Hist library (i.e. TH1::Fit, TGraph::Fit/; ; The Fitter class has been changed to retain a pointer to the Minimizer and Objective function of the last fit. The objective function depends on a reference to the data and the model function, therefore the objective function pointer is valid as far the data and the model function are maintained alive.; ; The library provides the implementation of standard objective function like the Chi2 function, the Poisson likelihood function (for binned likelihood fits) and the loh likelihood function (for unbinned fits). These standard objective functions can be created with or without gradient functionality. In the first case the minimization will be performed using the gradient provided by the function. These functions can also be used in specialized fitting methods like Fumili or the GSL non-linear least square.; . MathCore. Fixed a bug in setting the VEGAS integration mode in the GSLMCIntegrator class.; . Fumili. Add implementation of Minimizer interface using TFumili.; ; Minuit. In TMinuitMinimizer: do not delete the contained TMinuit reference, but maintain it alive, and accessible outside as gMinuit. It can then be used after fitting, for example for drawing contour plots. Add also support for Scan and Contour plots.; ; TLinearMinimizer: add support for robust fitting; . Minuit2. Add support to perform parallel minimization using a thread for each gradient calculation with openMP. In the ROOT environment the Minuit2 library can be built using openMP ( -fopenmp compilation flag for gcc) if the environment variables USE_PARALLEL_MINUIT2 and USE_OPENMP are set.; In the Minuit2 standalone built libraries (using autoconf) support for openMP is automatically enabled, whenever the compiler supports it (for example for gcc version >= 4.2). Some small changes have been applied in Minuit2 to make it thread safe. For example, when transforming from in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v522/index.html:2660,integrat,integration,2660,math/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v522/index.html,1,['integrat'],['integration']
Deployability," flag.; This is not supported on every platform. Atomics library; ---------------. If your program makes use of atomic operations and the compiler is not able; to lower them all directly to machine instructions (because there either is; no known suitable machine instruction or the operand is not known to be; suitably aligned), a call to a runtime library ``__atomic_*`` function; will be generated. A runtime library containing these atomics functions is; necessary for such programs. compiler-rt (LLVM); ^^^^^^^^^^^^^^^^^^. compiler-rt contains an implementation of an atomics library. libatomic (GNU); ^^^^^^^^^^^^^^^. libgcc_s does not provide an implementation of an atomics library. Instead,; `GCC's libatomic library <https://gcc.gnu.org/wiki/Atomic/GCCMM>`_ can be; used to supply these when using libgcc_s. .. note::. Clang does not currently automatically link against libatomic when using; libgcc_s. You may need to manually add ``-latomic`` to support this; configuration when using non-native atomic operations (if you see link errors; referring to ``__atomic_*`` functions). Unwind library; --------------. The unwind library provides a family of ``_Unwind_*`` functions implementing; the language-neutral stack unwinding portion of the Itanium C++ ABI; (`Level I <https://itanium-cxx-abi.github.io/cxx-abi/abi-eh.html#base-abi>`_).; It is a dependency of the C++ ABI library, and sometimes is a dependency; of other runtimes. libunwind (LLVM); ^^^^^^^^^^^^^^^^. LLVM's unwinder library is part of the llvm-project git repository. To; build it, pass ``-DLLVM_ENABLE_RUNTIMES=libunwind`` to the cmake invocation. If using libc++abi, you may need to configure it to use libunwind; rather than libgcc_s by passing ``-DLIBCXXABI_USE_LLVM_UNWINDER=YES``; to ``cmake``. If libc++abi is configured to use some version of; libunwind, that library will be implicitly linked into binaries that; link to libc++abi. libgcc_s (GNU); ^^^^^^^^^^^^^^. libgcc_s has an integrated unwinder, and does not",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Toolchain.rst:8146,configurat,configuration,8146,interpreter/llvm-project/clang/docs/Toolchain.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Toolchain.rst,1,['configurat'],['configuration']
Deployability," flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These conditional move instructions are known to not be predicted on any x86; processors, making them immune to misprediction that could reintroduce the; vulnerability. When we insert the conditional moves, the code ends up looking; like the following:; ```; # %bb.0: # %entry; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; testl %edi, %edi; jne .LBB0_1; # %bb.2: # %then1; cmovneq %r8, %rax # Conditionally update predicate state.; testl %esi, %esi; jne .LBB0_1; # %bb.3: # %then2; cmovneq %r8, %rax # Conditionally update predicate state.; testl %edx, %edx; je .LBB0_4; .LBB0_1:; cmoveq %r8, %rax # Conditionally update predicate state.; popq %rax; retq; .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; ...; ```. Here we create the ""empty"" or ""correct execution"" predicate state by zeroing; `%rax`, and we create a constant ""incorrect execution"" predicate value by; putting `-1` into `%r8`. Then, along each edge coming out of a conditional; branch we do a conditional move that in a correct execution will be a no-op,; but if misspeculated, will replace the `%rax` with the value of `%r8`.; Misspeculating any one of the three predicates will cause `%rax` to hold the; ""incorrect execution"" value from `%r8` as we preserve incoming values when; execution is correct rather than overwriting it. We now have a value in `%rax` in each basic block that indicates if at some; point previously a predicate was mispredicted. And we have arranged for that; value to be particularly effective when used below to harden loads. ##### Indirect Call, Branch, and Return Predicates. There is no analogous flag to use when tracing indirect calls, branches, and; returns. The pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:16971,update,update,16971,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['update'],['update']
Deployability," flags, disabling optimization and enabling debug information, only; for specific libraries or source files you actually need to debug. 14. Test LLVM in Visual Studio:. You can run LLVM tests by merely building the project ""check-all"". The test; results will be shown in the VS output window. Once the build succeeds, you; have verified a working LLVM development environment!. You should not see any unexpected failures, but will see many unsupported; tests and expected failures:. ::. 114>Testing Time: 1124.66s; 114> Skipped : 39; 114> Unsupported : 21649; 114> Passed : 51615; 114> Expectedly Failed: 93; ========== Build: 114 succeeded, 0 failed, 321 up-to-date, 0 skipped ==========``. Alternatives to manual installation; ===================================; Instead of the steps above, to simplify the installation procedure you can use; `Chocolatey <https://chocolatey.org/>`_ as package manager.; After the `installation <https://chocolatey.org/install>`_ of Chocolatey,; run these commands in an admin shell to install the required tools:. .. code-block:: bat. choco install -y git cmake python3; pip3 install psutil. There is also a Windows; `Dockerfile <https://github.com/llvm/llvm-zorg/blob/main/buildbot/google/docker/windows-base-vscode2019/Dockerfile>`_; with the entire build tool chain. This can be used to test the build with a; tool chain different from your host installation or to create build servers. Next steps; ==========; 1. Read the documentation.; 2. Seriously, read the documentation.; 3. Remember that you were warned twice about reading the documentation. Test LLVM on the command line:; ------------------------------; The LLVM tests can be run by changing directory to the llvm source; directory and running:. .. code-block:: bat. c:\llvm> python ..\build\Release\bin\llvm-lit.py llvm\test. This example assumes that Python is in your PATH variable, which would be; after **Add Python to the PATH** was selected during Python installation.; If you had opened a comm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst:8246,install,install,8246,interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,2,['install'],['install']
Deployability," following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. GFX940, GFX941; - wavefront - generic buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store. store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc0=1; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:307497,release,released,307497,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['released']
Deployability," following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcn",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:221618,release,release,221618,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['release'],['release']
Deployability," for your pass. The :ref:`Hello World; <writing-an-llvm-pass-basiccode>` example uses the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` class for its implementation, but we did; not discuss why or when this should occur. Here we talk about the classes; available, from the most general to the most specific. When choosing a superclass for your ``Pass``, you should choose the **most; specific** class possible, while still being able to meet the requirements; listed. This gives the LLVM Pass Infrastructure information necessary to; optimize how passes are run, so that the resultant compiler isn't unnecessarily; slow. The ``ImmutablePass`` class; ---------------------------. The most plain and boring type of pass is the ""`ImmutablePass; <https://llvm.org/doxygen/classllvm_1_1ImmutablePass.html>`_"" class. This pass; type is used for passes that do not have to be run, do not change state, and; never need to be updated. This is not a normal type of transformation or; analysis, but can provide information about the current compiler configuration. Although this pass class is very infrequently used, it is important for; providing information about the current target machine being compiled for, and; other static information that can affect the various transformations. ``ImmutablePass``\ es never invalidate other transformations, are never; invalidated, and are never ""run"". .. _writing-an-llvm-pass-ModulePass:. The ``ModulePass`` class; ------------------------. The `ModulePass <https://llvm.org/doxygen/classllvm_1_1ModulePass.html>`_ class; is the most general of all superclasses that you can use. Deriving from; ``ModulePass`` indicates that your pass uses the entire program as a unit,; referring to function bodies in no predictable order, or adding and removing; functions. Because nothing is known about the behavior of ``ModulePass``; subclasses, no optimization can be done for their execution. A module pass can use function level passes (e.g. dominators) using the;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:12275,configurat,configuration,12275,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['configurat'],['configuration']
Deployability," for; the one bundled with Xcode.; Using scan-build directly; If you wish to use scan-build with your iPhone project, keep the; following things in mind:. Analyze your project in the Debug configuration, either by setting; this as your configuration with Xcode or by passing -configuration; Debug to xcodebuild.; Analyze your project using the Simulator as your base SDK. It is; possible to analyze your code when targeting the device, but this is much; easier to do when using Xcode's Build and Analyze feature.; Check that your code signing SDK is set to the simulator SDK as well, and make sure this option is set to Don't Code Sign. Note that you can most of this without actually modifying your project. For; example, if your application targets iPhoneOS 2.2, you could run; scan-build in the following manner from the command line:. $ scan-build xcodebuild -configuration Debug -sdk iphonesimulator2.2. Alternatively, if your application targets iPhoneOS 3.0:. $ scan-build xcodebuild -configuration Debug -sdk iphonesimulator3.0. Gotcha: using the right compiler; Recall that scan-build analyzes your project by using a compiler to; compile the project and clang to analyze your project. The script uses; simple heuristics to determine which compiler should be used (it defaults to; clang on Darwin and gcc on other platforms). When analyzing; iPhone projects, scan-build may pick the wrong compiler than the one; Xcode would use to build your project. For example, this could be because; multiple versions of a compiler may be installed on your system, especially if; you are developing for the iPhone.; When compiling your application to run on the simulator, it is important that scan-build; finds the correct version of gcc/clang. Otherwise, you may see strange build; errors that only happen when you run scan-build. scan-build provides the --use-cc and --use-c++; options to hardwire which compiler scan-build should use for building your code.; Note that although you are chiefly intere",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/scan-build.html:9672,configurat,configuration,9672,interpreter/llvm-project/clang/www/analyzer/scan-build.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/scan-build.html,1,['configurat'],['configuration']
Deployability," function coverage is usually the least granular while; branch coverage (with MC/DC) is the most granular. 100% branch coverage for a; function implies 100% region coverage for a function. The project-wide totals; for each statistic are listed in the summary. Format compatibility guarantees; ===============================. * There are no backwards or forwards compatibility guarantees for the raw; profile format. Raw profiles may be dependent on the specific compiler; revision used to generate them. It's inadvisable to store raw profiles for; long periods of time. * Tools must retain **backwards** compatibility with indexed profile formats.; These formats are not forwards-compatible: i.e, a tool which uses format; version X will not be able to understand format version (X+k). * Tools must also retain **backwards** compatibility with the format of the; coverage mappings emitted into instrumented binaries. These formats are not; forwards-compatible. * The JSON coverage export format has a (major, minor, patch) version triple.; Only a major version increment indicates a backwards-incompatible change. A; minor version increment is for added functionality, and patch version; increments are for bugfixes. Impact of llvm optimizations on coverage reports; ================================================. llvm optimizations (such as inlining or CFG simplification) should have no; impact on coverage report quality. This is due to the fact that the mapping; from source regions to profile counters is immutable, and is generated before; the llvm optimizer kicks in. The optimizer can't prove that profile counter; instrumentation is safe to delete (because it's not: it affects the profile the; program emits), and so leaves it alone. Note that this coverage feature does not rely on information that can degrade; during the course of optimization, such as debug info line tables. Using the profiling runtime without static initializers; =================================================",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst:14411,patch,patch,14411,interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,1,['patch'],['patch']
Deployability," function pass; would have access to. To get access to an outer level IR analysis, you can; call. .. code-block:: c++. const auto &MAMProxy =; AM.getResult<ModuleAnalysisManagerCGSCCProxy>(InitialC, CG);; FooAnalysisResult *AR = MAMProxy.getCachedResult<FooAnalysis>(M);. Asking for a cached and immutable outer level IR analysis works via; ``getCachedResult()``, but getting direct access to an outer level IR analysis; manager to compute an outer level IR analysis is not allowed. This is for a; couple reasons. The first reason is that running analyses across outer level IR in inner level; IR passes can result in quadratic compile time behavior. For example, a module; analysis often scans every function and allowing function passes to run a module; analysis may cause us to scan functions a quadratic number of times. If passes; could keep outer level analyses up to date rather than computing them on demand; this wouldn't be an issue, but that would be a lot of work to ensure every pass; updates all outer level analyses, and so far this hasn't been necessary and; there isn't infrastructure for this (aside from function analyses in loop passes; as described below). Self-updating analyses that gracefully degrade also handle; this problem (e.g. GlobalsAA), but they run into the issue of having to be; manually recomputed somewhere in the optimization pipeline if we want precision,; and they block potential future concurrency. The second reason is to keep in mind potential future pass concurrency, for; example parallelizing function passes over different functions in a CGSCC or; module. Since passes can ask for a cached analysis result, allowing passes to; trigger outer level analysis computation could result in non-determinism if; concurrency was supported. A related limitation is that outer level IR analyses; that are used must be immutable, or else they could be invalidated by changes to; inner level IR. Outer analyses unused by inner passes can and often will be; invalidat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst:9369,update,updates,9369,interpreter/llvm-project/llvm/docs/NewPassManager.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst,1,['update'],['updates']
Deployability," function` passing the `async context` as the one of its arguments; argument. The `resume function` can restore its (the caller's) `async context`; by applying a `context projection function` that is provided by the frontend as; a parameter to the `llvm.coro.suspend.async` intrinsic. .. code-block:: c. // For example:; struct async_context {; struct async_context *caller_context;; ...; }. char *context_projection_function(struct async_context *callee_ctxt) {; return callee_ctxt->caller_context;; }. .. code-block:: llvm. %resume_func_ptr = call ptr @llvm.coro.async.resume(); call {ptr, ptr, ptr} (ptr, ptr, ...) @llvm.coro.suspend.async(; ptr %resume_func_ptr,; ptr %context_projection_function. The frontend should provide a `async function pointer` struct associated with; each async coroutine by `llvm.coro.id.async`'s argument. The initial size and; alignment of the `async context` must be provided as arguments to the; `llvm.coro.id.async` intrinsic. Lowering will update the size entry with the; coroutine frame requirements. The frontend is responsible for allocating the; memory for the `async context` but can use the `async function pointer` struct; to obtain the required size. .. code-block:: c. struct async_function_pointer {; uint32_t relative_function_pointer_to_async_impl;; uint32_t context_size;; }. Lowering will split an async coroutine into a ramp function and one resume; function per suspend point. How control-flow is passed between caller, suspension point, and back to; resume function is left up to the frontend. The suspend point takes a function and its arguments. The function is intended; to model the transfer to the callee function. It will be tail called by; lowering and therefore must have the same signature and calling convention as; the async coroutine. .. code-block:: llvm. call {ptr, ptr, ptr} (ptr, ptr, ...) @llvm.coro.suspend.async(; ptr %resume_func_ptr,; ptr %context_projection_function,; ptr %suspend_function,; ptr %arg1, ptr %arg2, i8 %arg3)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:9650,update,update,9650,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['update'],['update']
Deployability," has not been done already. #. If a bug has been fixed and has a pull request created for backporting it,; then update its status to ""Needs Review"" and notify a knowledgeable reviewer.; Usually you will want to notify the person who approved the patch in Phabricator,; but you may use your best judgement on who a good reviewer would be. Once; you have identified the reviewer(s), assign the issue to them and mention; them (i.e @username) in a comment and ask them if the patch is safe to backport.; You should also review the bug yourself to ensure that it meets the requirements; for committing to the release branch. #. Once a bug has been reviewed, add the release:reviewed label and update the; issue's status to ""Needs Merge"". Check the pull request associated with the; issue. If all the tests pass, then the pull request can be merged. If not,; then add a comment on the issue asking someone to take a look at the failures. #. Once the pull request has been merged push it to the official release branch; with the script ``llvm/utils/git/sync-release-repo.sh``. Then add a comment to the issue stating that the fix has been merged along with; the git hashes from the release branch. Add the release:merged label to the issue; and close it. Release Patch Rules; -------------------. Below are the rules regarding patching the release branch:. #. Patches applied to the release branch may only be applied by the release; manager, the official release testers or the code owners with approval from; the release manager. #. Release managers are encouraged, but not required, to get approval from code; owners before approving patches. If there is no code owner or the code owner; is unreachable then release managers can ask approval from patch reviewers or; other developers active in that area. #. *Before RC1* Patches should be limited to bug fixes, important optimization; improvements, or completion of features that were started before the branch; was created. As with all phases, release ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:12193,release,release,12193,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,2,['release'],"['release', 'release-repo']"
Deployability," has shown us there is no point in partitioning to more than; one variable. It simply generates more IR, and optimizations still; have to query something to disambiguate further anyway. As a result, LLVM partitions to one variable. Precision in practice; ^^^^^^^^^^^^^^^^^^^^^. In practice, there are implementation details in LLVM that also affect the; results' precision provided by ``MemorySSA``. For example, AliasAnalysis has various; caps, or restrictions on looking through phis which can affect what ``MemorySSA``; can infer. Changes made by different passes may make MemorySSA either ""overly; optimized"" (it can provide a more accurate result than if it were recomputed; from scratch), or ""under optimized"" (it could infer more if it were recomputed).; This can lead to challenges to reproduced results in isolation with a single pass; when the result relies on the state acquired by ``MemorySSA`` due to being updated by; multiple subsequent passes.; Passes that use and update ``MemorySSA`` should do so through the APIs provided by the; ``MemorySSAUpdater``, or through calls on the Walker.; Direct optimizations to ``MemorySSA`` are not permitted.; There is currently a single, narrowly scoped exception where DSE (DeadStoreElimination); updates an optimized access of a store, after a traversal that guarantees the; optimization is correct. This is solely allowed due to the traversals and inferences; being beyond what ``MemorySSA`` does and them being ""free"" (i.e. DSE does them anyway).; This exception is set under a flag (""-dse-optimize-memoryssa"") and can be disabled to; help reproduce optimizations in isolation. LLVM Developers Meeting presentations; -------------------------------------. - `2016 LLVM Developers' Meeting: G. Burgess - MemorySSA in Five Minutes <https://www.youtube.com/watch?v=bdxWmryoHak>`_.; - `2020 LLVM Developers' Meeting: S. Baziotis & S. Moll - Finding Your Way Around the LLVM Dependence Analysis Zoo <https://www.youtube.com/watch?v=1e5y6WDbXCQ>`_; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:19204,update,update,19204,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,2,['update'],"['update', 'updates']"
Deployability," have been moved out from the MathCore library in a new library, libGenVector. The library contains as well the CINT dictionary including main instantiations for the template classes. For this release the instantiation of some extra methods, in particular of the class ROOT::Math::TRansform3D have been added in the dictionary library.; Due to a CINT limitation, the dictionary for explicit template constructors of the Rotation classes, taking as input any other type; of rotation are missing. Therefore code like the following one will now work in CINT (or Python):. ROOT::Math::Rotation3D r;; ROOT::Math::EulerAngles eulerRot(r);. A possible solution is to use the operator=:. ROOT::Math::EulerAngles eulerRot; eulerRot = r;. In addition the setter methods for the 2D,3D and 4D vector classes have been extended following a suggestion by G. Raven. Functions like SetX instead of returning a void return now a reference to the vector class itself (*this).; Detailed description of the current GenVector release can be found at this location. SMatrix; Fix a bug discovered by Harals Soleng in the addition of two matrix expressions. Remove also some compilation warning found on Windows when compiling matrices instantiated using float types.; Detailed description of the current SMatrix release can be found at this location. Minuit; Two new classes have been added:; ; TMinuitMinimizer: implementation of the ROOT::Math::Minimizer interface with TMinuit. This class is used for example by the new Fitter class.; TLinearMinimizer: implementation of the ROOT::Math::Minimizer interface with the TLinearFitter.; ; In addition, the method TLinearFitter::SetBasisFunction(TObjArray * f) has been added to set directly the linear terms of the fit function. Minuit2. Various fixes have been applied to different problems discovered mainly by a test program from Alfio Lazzaro. In detail:; . Fix a bug in MnMinos which was setting wrong initial values when the parameters were limited.; This was resulting",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v520/index.html:12038,release,release,12038,math/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v520/index.html,1,['release'],['release']
Deployability," higher; pointer bits for other purposes.; * May require changes in the OS kernels (e.g. Linux seems to dislike; tagged pointers passed from address space:; https://www.kernel.org/doc/Documentation/arm64/tagged-pointers.txt).; * **Does not require redzones to detect buffer overflows**,; but the buffer overflow detection is probabilistic, with roughly; `1/(2**TS)` chance of missing a bug (6.25% or 0.39% with 4 and 8-bit TS; respectively).; * **Does not require quarantine to detect heap-use-after-free,; or stack-use-after-return**.; The detection is similarly probabilistic. The memory overhead of HWASAN is expected to be much smaller; than that of AddressSanitizer:; `1/TG` extra memory for the shadow; and some overhead due to `TG`-aligning all objects. Supported architectures; =======================; HWASAN relies on `Address Tagging`_ which is only available on AArch64.; For other 64-bit architectures it is possible to remove the address tags; before every load and store by compiler instrumentation, but this variant; will have limited deployability since not all of the code is; typically instrumented. On x86_64, HWASAN utilizes page aliasing to place tags in userspace address; bits. Currently only heap tagging is supported. The page aliases rely on; shared memory, which will cause heap memory to be shared between processes if; the application calls ``fork()``. Therefore x86_64 is really only safe for; applications that do not fork. HWASAN does not currently support 32-bit architectures since they do not; support `Address Tagging`_ and the address space is too constrained to easily; implement page aliasing. Related Work; ============; * `SPARC ADI`_ implements a similar tool mostly in hardware.; * `Effective and Efficient Memory Protection Using Dynamic Tainting`_ discusses; similar approaches (""lock & key"").; * `Watchdog`_ discussed a heavier, but still somewhat similar; ""lock & key"" approach.; * *TODO: add more ""related work"" links. Suggestions are welcome.*. .. _W",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst:10684,deploy,deployability,10684,interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,1,['deploy'],['deployability']
Deployability," horizontal direction (like gridiNx1); - [vert121](https://root.cern//js/latest/api.htm#url_syntax_veritcal_layout) - 3 frames sorted in vertical direction, second frame divided on two sub-frames; - [horiz32_12](https://root.cern//js/latest/api.htm#url_syntax_horizontal_layout) - 2 horizontal frames with 3 and 2 subframes, and 1/3 and 2/3 as relative size. When specifying `files`, `items` or `opts` parameters, array of strings could be provided like `files=['file1.root','file2.root']`. One could skip quotes when specifying elements names `items=[file1.root/hpx,file2.root/hpy]` or `opts=['',colz]`. As item name, URL to existing image can be provided like `item=img:http://server/image.png`. Such image will be just inserted in the existing layout. One could specify option `""scale""` to automatically scale image to available space. Many examples of URL string usage can be found on [JSROOT API examples](https://root.cern/js/latest/api.htm) page. One can very easy integrate JSROOT graphic into arbitrary HTML pages using a __iframe__ tag:. ```html; <iframe width=""700"" height=""400""; src=""https://root.cern/js/latest/?nobrowser&file=https://root.cern/js/files/hsimple.root&item=hpxpy&opt=colz"">; </iframe>; ```. ## Supported ROOT classes by JSROOT. List of supported classes and draw options:. - TH1 : [hist](https://root.cern/js/latest/examples.htm#th1),; [p](https://root.cern/js/latest/examples.htm#th1_p),; [p0](https://root.cern/js/latest/examples.htm#th1_p0),; [*](https://root.cern/js/latest/examples.htm#th1_star),; [l](https://root.cern/js/latest/examples.htm#th1_l),; [lf2](https://root.cern/js/latest/examples.htm#th1_lf2),; [a](https://root.cern/js/latest/examples.htm#th1_a),; [e](https://root.cern/js/latest/examples.htm#th1_e),; [e0](https://root.cern/js/latest/examples.htm#th1_e0),; [e1](https://root.cern/js/latest/examples.htm#th1_e1),; [e1x0](https://root.cern/js/latest/examples.htm#th1_e1x0),; [e3](https://root.cern/js/latest/examples.htm#th1_e3),; [e4](https://root.cer",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:5652,integrat,integrate,5652,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['integrat'],['integrate']
Deployability," i.e. use; ``@property (readonly)`` instead of ``@property(readonly)``. .. _ObjCSpaceBeforeProtocolList:. **ObjCSpaceBeforeProtocolList** (``Boolean``) :versionbadge:`clang-format 3.7` :ref:`¶ <ObjCSpaceBeforeProtocolList>`; Add a space in front of an Objective-C protocol list, i.e. use; ``Foo <Protocol>`` instead of ``Foo<Protocol>``. .. _PPIndentWidth:. **PPIndentWidth** (``Integer``) :versionbadge:`clang-format 13` :ref:`¶ <PPIndentWidth>`; The number of columns to use for indentation of preprocessor statements.; When set to -1 (default) ``IndentWidth`` is used also for preprocessor; statements. .. code-block:: c++. PPIndentWidth: 1. #ifdef __linux__; # define FOO; #else; # define BAR; #endif. .. _PackConstructorInitializers:. **PackConstructorInitializers** (``PackConstructorInitializersStyle``) :versionbadge:`clang-format 14` :ref:`¶ <PackConstructorInitializers>`; The pack constructor initializers style to use. Possible values:. * ``PCIS_Never`` (in configuration: ``Never``); Always put each constructor initializer on its own line. .. code-block:: c++. Constructor(); : a(),; b(). * ``PCIS_BinPack`` (in configuration: ``BinPack``); Bin-pack constructor initializers. .. code-block:: c++. Constructor(); : aaaaaaaaaaaaaaaaaaaa(), bbbbbbbbbbbbbbbbbbbb(),; cccccccccccccccccccc(). * ``PCIS_CurrentLine`` (in configuration: ``CurrentLine``); Put all constructor initializers on the current line if they fit.; Otherwise, put each one on its own line. .. code-block:: c++. Constructor() : a(), b(). Constructor(); : aaaaaaaaaaaaaaaaaaaa(),; bbbbbbbbbbbbbbbbbbbb(),; ddddddddddddd(). * ``PCIS_NextLine`` (in configuration: ``NextLine``); Same as ``PCIS_CurrentLine`` except that if all constructor initializers; do not fit on the current line, try to fit them on the next line. .. code-block:: c++. Constructor() : a(), b(). Constructor(); : aaaaaaaaaaaaaaaaaaaa(), bbbbbbbbbbbbbbbbbbbb(), ddddddddddddd(). Constructor(); : aaaaaaaaaaaaaaaaaaaa(),; bbbbbbbbbbbbbbbbbbbb(),; ccccccccccc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:92202,configurat,configuration,92202,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," i.e., a module that is not nested within an enclosing module. The ``exhaustive`` attribute specifies that the list of macros in the *config-macros-declaration* is exhaustive, meaning that no other macro definition is intended to have an effect on the API of that module. .. note::. The ``exhaustive`` attribute implies that any macro definitions; for macros not listed as configuration macros should be ignored; completely when building the module. As an optimization, the; compiler could reduce the number of unique module variants by not; considering these non-configuration macros. This optimization is not; yet implemented in Clang. A translation unit shall not import the same module under different definitions of the configuration macros. .. note::. Clang implements a weak form of this requirement: the definitions; used for configuration macros are fixed based on the definitions; provided by the command line. If an import occurs and the definition; of any configuration macro has changed, the compiler will produce a; warning (under the control of ``-Wconfig-macros``). **Example:** A logging library might provide different API (e.g., in the form of different definitions for a logging macro) based on the ``NDEBUG`` macro setting:. .. parsed-literal::. module MyLogger {; umbrella header ""MyLogger.h""; config_macros [exhaustive] NDEBUG; }. Conflict declarations; ~~~~~~~~~~~~~~~~~~~~~; A *conflict-declaration* describes a case where the presence of two different modules in the same translation unit is likely to cause a problem. For example, two modules may provide similar-but-incompatible functionality. .. parsed-literal::. *conflict-declaration*:; ``conflict`` *module-id* ',' *string-literal*. The *module-id* of the *conflict-declaration* specifies the module with which the enclosing module conflicts. The specified module shall not have been imported in the translation unit when the enclosing module is imported. The *string-literal* provides a message to be provided as part ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:47816,configurat,configuration,47816,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['configurat'],['configuration']
Deployability," if supported by the RooFit object.; You can use the CUDA mode by passing `""cuda""` to the `BatchMode()` command argument:; ```C++; model.fitTo(data); // not using the batch mode; model.fitTo(data, RooFit::BatchMode(true)); // using the BatchMode on CPU (RooFit::BatchMode(""cpu"") is equivalent); model.fitTo(data, RooFit::BatchMode(""cuda"")); // using the new CUDA backend; ```. The `RooBatchCompute` backend now also supports ROOT's implicit multithreading (similar to RDataFrame), which can be enabled as follows:; ```C++; ROOT::EnableImplicitMT(nThreads);; ```. For more information, please have a look at this [contribution to the ACAT 2021 conference](https://indico.cern.ch/event/855454/contributions/4596763/) or consult the [RooBatchComupte README](https://github.com/root-project/root/tree/v6-26-00-patches/roofit/batchcompute).; The README also describes how to enable BatchMode support for your own PDFs. ### Parallel calculation of likelihood gradients during fitting; This release features two new optional RooFit libraries: `RooFit::MultiProcess` and `RooFit::TestStatistics`.; To activate both, build with `-Droofit_multiprocess=ON`. The `RooFit::TestStatistics` namespace contains a major refactoring of the `RooAbsTestStatistic`-`RooAbsOptTestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;; 2. calculation/evaluation/optimization based classes on the other hand. The main selling point of using `RooFit::TestStatistics` from a performance point of view is the implementation of the `RooFit::MultiProcess` based `LikelihoodGradientJob` calculator class.; To use it to perform a ""migrad"" fit (using Minuit2), one should create a `RooMinimizer` using a new constructor with a `RooAbsL` likelihood parameter as follows:. ```c++; using RooFit::TestStatistics::RooAbsL;; using RooFit::TestStatistics::buildLikelihood;. RooAbsPdf* pdf = ...; // build a pdf; RooAbsData* data = ...; // get some data. std::shared_ptr<RooAbsL> likelihood = buildLikel",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:16506,release,release,16506,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['release'],['release']
Deployability," in a comment and ask them if the patch is safe to backport.; You should also review the bug yourself to ensure that it meets the requirements; for committing to the release branch. #. Once a bug has been reviewed, add the release:reviewed label and update the; issue's status to ""Needs Merge"". Check the pull request associated with the; issue. If all the tests pass, then the pull request can be merged. If not,; then add a comment on the issue asking someone to take a look at the failures. #. Once the pull request has been merged push it to the official release branch; with the script ``llvm/utils/git/sync-release-repo.sh``. Then add a comment to the issue stating that the fix has been merged along with; the git hashes from the release branch. Add the release:merged label to the issue; and close it. Release Patch Rules; -------------------. Below are the rules regarding patching the release branch:. #. Patches applied to the release branch may only be applied by the release; manager, the official release testers or the code owners with approval from; the release manager. #. Release managers are encouraged, but not required, to get approval from code; owners before approving patches. If there is no code owner or the code owner; is unreachable then release managers can ask approval from patch reviewers or; other developers active in that area. #. *Before RC1* Patches should be limited to bug fixes, important optimization; improvements, or completion of features that were started before the branch; was created. As with all phases, release managers and code owners can reject; patches that are deemed too invasive. #. *Before RC2* Patches should be limited to bug fixes or backend specific; improvements that are determined to be very safe. #. *Before RC3/Final Major Release* Patches should be limited to critical; bugs or regressions. #. *Bug fix releases* Patches should be limited to bug fixes or very safe; and critical performance improvements. Patches must maintain both A",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:12572,release,release,12572,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,4,['release'],['release']
Deployability," in bulk. New targets need the same level of support as other; *core* parts of the compiler, so they are covered in the *core tier* of our; :doc:`support policy<SupportPolicy>`. We have found that landing large pieces of new code and then trying to fix; emergent problems in-tree is problematic for a variety of reasons. For these; reasons, new targets are *always* added as *experimental* until they can be; proven stable, and later moved to non-experimental. The differences between both classes are:. * Experimental targets are not built by default (they need to be explicitly; enabled at CMake time). * Test failures, bugs, and build breakages that only appear when the; experimental target is enabled, caused by changes unrelated to the target, are; the responsibility of the community behind the target to fix. The basic rules for a back-end to be upstreamed in **experimental** mode are:. * Every target must have a :ref:`code owner<code owners>`. The `CODE_OWNERS.TXT`; file has to be updated as part of the first merge. The code owner makes sure; that changes to the target get reviewed and steers the overall effort. * There must be an active community behind the target. This community; will help maintain the target by providing buildbots, fixing; bugs, answering the LLVM community's questions and making sure the new; target doesn't break any of the other targets, or generic code. This; behavior is expected to continue throughout the lifetime of the; target's code. * The code must be free of contentious issues, for example, large; changes in how the IR behaves or should be formed by the front-ends,; unless agreed by the majority of the community via refactoring of the; (:doc:`IR standard<LangRef>`) **before** the merge of the new target changes,; following the :ref:`IR backwards compatibility`. * The code conforms to all of the policies laid out in this developer policy; document, including license, patent, and coding standards. * The target should have either reasonable do",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:39902,update,updated,39902,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['update'],['updated']
Deployability," in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:9184,pipeline,pipeline,9184,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['pipeline'],['pipeline']
Deployability," in order. For example:. ::. clang --config=/home/user/cfgs/testing.txt; clang --config=debug.cfg --config=runtimes.cfg. If the provided argument contains a directory separator, it is considered as; a file path, and options are read from that file. Otherwise the argument is; treated as a file name and is searched for sequentially in the directories:. - user directory,; - system directory,; - the directory where Clang executable resides. Both user and system directories for configuration files are specified during; clang build using CMake parameters, ``CLANG_CONFIG_FILE_USER_DIR`` and; ``CLANG_CONFIG_FILE_SYSTEM_DIR`` respectively. The first file found is used.; It is an error if the required file cannot be found. The default configuration files are searched for in the same directories; following the rules described in the next paragraphs. Loading default; configuration files can be disabled entirely via passing; the ``--no-default-config`` flag. First, the algorithm searches for a configuration file named; ``<triple>-<driver>.cfg`` where `triple` is the triple for the target being; built for, and `driver` is the name of the currently used driver. The algorithm; first attempts to use the canonical name for the driver used, then falls back; to the one found in the executable name. The following canonical driver names are used:. - ``clang`` for the ``gcc`` driver (used to compile C programs); - ``clang++`` for the ``gxx`` driver (used to compile C++ programs); - ``clang-cpp`` for the ``cpp`` driver (pure preprocessor); - ``clang-cl`` for the ``cl`` driver; - ``flang`` for the ``flang`` driver; - ``clang-dxc`` for the ``dxc`` driver. For example, when calling ``x86_64-pc-linux-gnu-clang-g++``,; the driver will first attempt to use the configuration file named::. x86_64-pc-linux-gnu-clang++.cfg. If this file is not found, it will attempt to use the name found; in the executable instead::. x86_64-pc-linux-gnu-clang-g++.cfg. Note that options such as ``--driver-mode=``, ``-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:32216,configurat,configuration,32216,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['configurat'],['configuration']
Deployability," in practice a functions returning an out-parameter usually also return a return code, and then an out parameter may or may not be written, which conditionally depends on the exit code, e.g.:. bool maybeCreateObject(LIBKERN_RETURNS_RETAINED OSObject **obj);. For such functions, the usual semantics is that an object is written into on ""success"", and not written into on ""failure"".; For LIBKERN_RETURNS_RETAINED we assume the following definition of; success:; For functions returning OSReturn or IOReturn; (any typedef to kern_return_t) success is defined as having an output of zero (kIOReturnSuccess is zero).; For all others, success is non-zero (e.g. non-nullptr for pointers); 3. Retained out parameters on zero return; The annotation LIBKERN_RETURNS_RETAINED_ON_ZERO states; that a retained object is written into if and only if the function returns a zero value:. bool OSUnserializeXML(void *data, LIBKERN_RETURNS_RETAINED_ON_ZERO OSString **errString);. Then the caller has to release an object if the function has returned zero.; 4. Retained out parameters on non-zero return; Similarly, LIBKERN_RETURNS_RETAINED_ON_NONZERO specifies that a; retained object is written into the parameter if and only if the function has; returned a non-zero value.; Note that for non-retained out parameters conditionals do not matter, as the; caller has no obligations regardless of whether an object is written into or; not. Custom Assertion Handlers. The analyzer exploits code assertions by pruning off paths where the; assertion condition is false. The idea is capture any program invariants; specified in the assertion that the developer may know but is not immediately; apparent in the code itself. In this way assertions make implicit assumptions; explicit in the code, which not only makes the analyzer more accurate when; finding bugs, but can help others better able to understand your code as well.; It can also help remove certain kinds of analyzer false positives by pruning off; false paths.;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html:19156,release,release,19156,interpreter/llvm-project/clang/www/analyzer/annotations.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html,1,['release'],['release']
Deployability," in the Clang source code. The specific IDs for an address space do not; have to match between the AST and the IR. Typically in the AST address space; numbers represent logical segments while in the IR they represent physical; segments.; Therefore, machines with flat memory segments can map all AST address space; numbers to the same physical segment ID or skip address space attribute; completely while generating the IR. However, if the address space information; is needed by the IR passes e.g. to improve alias analysis, it is recommended; to keep it and only lower to reflect physical memory segments in the late; machine passes. The mapping between logical and target address spaces is; specified in the Clang's source code. .. _cxx_for_opencl_impl:. C++ for OpenCL Implementation Status; ====================================. Clang implements language versions 1.0 and 2021 published in `the official; release of C++ for OpenCL Documentation; <https://github.com/KhronosGroup/OpenCL-Docs/releases/tag/cxxforopencl-docrev2021.12>`_. Limited support of experimental C++ libraries is described in the :ref:`experimental features <opencl_experimenal>`. GitHub issues for this functionality are typically prefixed; with '[C++4OpenCL]' - click `here; <https://github.com/llvm/llvm-project/issues?q=is%3Aissue+is%3Aopen+%5BC%2B%2B4OpenCL%5D>`__; to view the full bug list. Missing features or with limited support; ----------------------------------------. - Support of C++ for OpenCL 2021 is currently in experimental phase. Refer to; :ref:`OpenCL 3.0 status <opencl_300>` for details of common missing; functionality from OpenCL 3.0. - IR generation for non-trivial global destructors is incomplete (See:; `PR48047 <https://llvm.org/PR48047>`_). - Support of `destructors with non-default address spaces; <https://www.khronos.org/opencl/assets/CXX_for_OpenCL.html#_construction_initialization_and_destruction>`_; is incomplete (See: `D109609 <https://reviews.llvm.org/D109609>`_). .. _opencl_300:.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenCLSupport.rst:13198,release,releases,13198,interpreter/llvm-project/clang/docs/OpenCLSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenCLSupport.rst,1,['release'],['releases']
Deployability," in the XRay runtime. The default implementation of the XRay runtime will enable XRay instrumentation; before ``main`` starts, which works for applications that have a short; lifetime. This implementation also records all function entry and exit events; which may result in a lot of records in the resulting trace. Also by default the filename of the XRay trace is ``xray-log.XXXXXX`` where the; ``XXXXXX`` part is randomly generated. These options can be controlled through the ``XRAY_OPTIONS`` environment; variable, where we list down the options and their defaults below. +-------------------+-----------------+---------------+------------------------+; | Option | Type | Default | Description |; +===================+=================+===============+========================+; | patch_premain | ``bool`` | ``false`` | Whether to patch |; | | | | instrumentation points |; | | | | before main. |; +-------------------+-----------------+---------------+------------------------+; | xray_mode | ``const char*`` | ``""""`` | Default mode to |; | | | | install and initialize |; | | | | before ``main``. |; +-------------------+-----------------+---------------+------------------------+; | xray_logfile_base | ``const char*`` | ``xray-log.`` | Filename base for the |; | | | | XRay logfile. |; +-------------------+-----------------+---------------+------------------------+; | verbosity | ``int`` | ``0`` | Runtime verbosity |; | | | | level. |; +-------------------+-----------------+---------------+------------------------+. If you choose to not use the default logging implementation that comes with the; XRay runtime and/or control when/how the XRay instrumentation runs, you may use; the XRay APIs directly for doing so. To do this, you'll need to include the; ``xray_log_interface.h`` from the compiler-rt ``xray`` directory. The important API; functions we list below:. - ``__xray_log_register_mode(...)``: Register a logging implementation against; a string Mode identifier. The implementat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:5925,install,install,5925,interpreter/llvm-project/llvm/docs/XRay.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst,1,['install'],['install']
Deployability," in the output. Can be specified; multiple times to rename multiple symbols. .. option:: --redefine-syms <filename>. Rename symbols in the output as described in the file ``<filename>``. In the; file, each line represents a single symbol to rename, with the old name and new; name separated by whitespace. Leading and trailing whitespace is ignored, as is; anything following a '#'. Can be specified multiple times to read names from; multiple files. .. option:: --regex. If specified, symbol and section names specified by other switches are treated; as extended POSIX regular expression patterns. .. option:: --remove-section <section>, -R. Remove the specified section from the output. Can be specified multiple times; to remove multiple sections simultaneously. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --set-section-alignment <section>=<align>. Set the alignment of section ``<section>`` to ``<align>``. Can be specified; multiple times to update multiple sections. .. option:: --set-section-flags <section>=<flag>[,<flag>,...]. Set section properties in the output of section ``<section>`` based on the; specified ``<flag>`` values. Can be specified multiple times to update multiple; sections. Supported flag names are `alloc`, `load`, `noload`, `readonly`, `exclude`,; `debug`, `code`, `data`, `rom`, `share`, `contents`, `merge`, `strings`, and; `large`. Not all flags are meaningful for all object file formats or target; architectures. For ELF objects, the flags have the following effects:. - `alloc` = add the `SHF_ALLOC` flag.; - `load` = if the section has `SHT_NOBITS` type, mark it as a `SHT_PROGBITS`; section.; - `readonly` = if this flag is not specified, add the `SHF_WRITE` flag.; - `exclude` = add the `SHF_EXCLUDE` flag.; - `code` = add the `SHF_EXECINSTR` flag.; - `merge` = add the `SHF_MERGE` flag.; - `strings` = add the `SHF_STRINGS` flag.; - `contents` = if the section has `SHT_NOBITS` type, mark it as a `SH",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:4581,update,update,4581,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,1,['update'],['update']
Deployability," include the CompileOnDemandLayer.h header, then add two new; members: a std::unique_ptr<JITCompileCallbackManager> and a CompileOnDemandLayer,; to our class. The CompileCallbackManager member is used by the CompileOnDemandLayer; to create the compile callback needed for each function. .. code-block:: c++. KaleidoscopeJIT(); : TM(EngineBuilder().selectTarget()), DL(TM->createDataLayout()),; ObjectLayer([]() { return std::make_shared<SectionMemoryManager>(); }),; CompileLayer(ObjectLayer, SimpleCompiler(*TM)),; OptimizeLayer(CompileLayer,; [this](std::shared_ptr<Module> M) {; return optimizeModule(std::move(M));; }),; CompileCallbackManager(; orc::createLocalCompileCallbackManager(TM->getTargetTriple(), 0)),; CODLayer(OptimizeLayer,; [this](Function &F) { return std::set<Function*>({&F}); },; *CompileCallbackManager,; orc::createLocalIndirectStubsManagerBuilder(; TM->getTargetTriple())) {; llvm::sys::DynamicLibrary::LoadLibraryPermanently(nullptr);; }. Next we have to update our constructor to initialize the new members. To create; an appropriate compile callback manager we use the; createLocalCompileCallbackManager function, which takes a TargetMachine and an; ExecutorAddr to call if it receives a request to compile an unknown; function. In our simple JIT this situation is unlikely to come up, so we'll; cheat and just pass '0' here. In a production quality JIT you could give the; address of a function that throws an exception in order to unwind the JIT'd; code's stack. Now we can construct our CompileOnDemandLayer. Following the pattern from; previous layers we start by passing a reference to the next layer down in our; stack -- the OptimizeLayer. Next we need to supply a 'partitioning function':; when a not-yet-compiled function is called, the CompileOnDemandLayer will call; this function to ask us what we would like to compile. At a minimum we need to; compile the function being called (given by the argument to the partitioning; function), but we could also reques",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst:5571,update,update,5571,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst,1,['update'],['update']
Deployability," indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_REG_STATUS Shader read-only status.; HW_REG_TRAPSTS Trap status.; HW_REG_HW_ID1 Id of wave, simd, compute unit, etc.; HW_REG_HW_ID2 Id of queue, pipeline, etc.; HW_REG_GPR_ALLOC Per-wave SGPR and VGPR allocation.; HW_REG_LDS_ALLOC Per-wave LDS allocation.; HW_REG_IB_STS Counters of outstanding instructions.; HW_REG_SH_MEM_BASES Memory aperture.; HW_REG_TBA_LO tba_lo register.; HW_REG_TBA_HI tba_hi register.; HW_REG_TMA_LO tma_lo register.; HW_REG_TMA_HI tma_hi register.; HW_REG_FLAT_SCR_LO flat_scratch_lo register.; HW_REG_FLAT_SCR_HI flat_scratch_hi register.; HW_REG_POPS_PACKER pops_packer register.; HW_REG_SHADER_CYCLES Current graphics clock counter value.; ============================== ==========================================. Examples:. .. parsed-literal::. reg = 1; offset = 2; size = 4; hwreg_enc = reg | (offset << 6) | ((size - 1) << 11). s_getreg_b32 s2, 0x1881; s_getreg_b32 s2, hwreg_enc // the same as above; s_getreg_b32 s2, hwreg(1, 2, 4) // the same as above; s_getreg_b32 s2, hwreg(reg, offset, size) // the same as above. s_getreg_b32 s2, hwreg(15); s_getreg_b32 s2, hwreg(51, 1, 31); s_getreg_b32 s2, hwre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst:2148,pipeline,pipeline,2148,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst,1,['pipeline'],['pipeline']
Deployability," indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_REG_STATUS Shader read-only status.; HW_REG_TRAPSTS Trap status.; HW_REG_HW_ID1 Id of wave, simd, compute unit, etc.; HW_REG_HW_ID2 Id of queue, pipeline, etc.; HW_REG_GPR_ALLOC Per-wave SGPR and VGPR allocation.; HW_REG_LDS_ALLOC Per-wave LDS allocation.; HW_REG_IB_STS Counters of outstanding instructions.; HW_REG_SH_MEM_BASES Memory aperture.; HW_REG_TBA_LO tba_lo register.; HW_REG_TBA_HI tba_hi register.; HW_REG_TMA_LO tma_lo register.; HW_REG_TMA_HI tma_hi register.; HW_REG_FLAT_SCR_LO flat_scratch_lo register.; HW_REG_FLAT_SCR_HI flat_scratch_hi register.; HW_REG_XNACK_MASK xnack_mask register.; HW_REG_POPS_PACKER pops_packer register.; ============================== ==========================================. Examples:. .. parsed-literal::. reg = 1; offset = 2; size = 4; hwreg_enc = reg | (offset << 6) | ((size - 1) << 11). s_getreg_b32 s2, 0x1881; s_getreg_b32 s2, hwreg_enc // the same as above; s_getreg_b32 s2, hwreg(1, 2, 4) // the same as above; s_getreg_b32 s2, hwreg(reg, offset, size) // the same as above. s_getreg_b32 s2, hwreg(15); s_getreg_b32 s2, hwreg(51, 1, 31); s_getreg_b32 s2, hwreg(HW_REG_LDS_ALLOC, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst:2146,pipeline,pipeline,2146,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst,1,['pipeline'],['pipeline']
Deployability," information about extracting the source files from [ROOT]. ## Building. To build, use the standard [CMake] procedure; on most systems, this looks like:. ```bash; mkdir PATH_TO_MINIUT2_BUILD; cd PATH_TO_MINUIT2_BUILD; cmake PATH_TO_MINUIT2_SOURCE; cmake --build .; ```. Of course, GUIs, IDEs, etc. that work with [CMake] will work with this package. The standard method of CMake building, with a build directory inside the Minuit2 source directory and using the makefile generator, would look like:. ```bash; cd PATH_TO_MINUIT2_SOURCE; mkdir build; cd build; cmake ..; make; ```. The standard [CMake] variables, such as `CMAKE_BUILD_TYPE` and `CMAKE_INSTALL_PREFIX`, work with Minuit2. There are two other options:. * `minuit2_mpi` activates the (outdated C++) MPI bindings.; * `minuit2_omp` activates OpenMP (make sure all FCNs are threadsafe). ## Testing. You can run `ctest` or `make test` to run the Minuit2 test suite. ## Installing or using in another package. You can install the package using `cmake --build --target install .` (or `make install` if directly using the make system), or you can use it from the build directory. You can also include it in another CMake project using `add_subdirectory()` and linking to the `Minuit2` target. Since this package also exports targets, `find_package(Minuit2)` will also work once this package is built or installed. (For the curious, CMake adds a config script to `~/.cmake/packages` when building or; `$CMAKE_INSTALL_PREFIX/share/cmake/Modules` when installing a package that has export commands.). To repeat; using this in your own CMake project usually amounts to:. ```cmake; find_package(Minuit2); # OR; add_subdirectory(Minuit2). target_link_libraries(MyExeOrLib PUBLIC Minuit2::Minuit2); ```. You do not need to add include directories or anything else for Minuit2; the CMake target system handles all of this for you. ## Packaging. To build a binary package (add other generators with `-G`):; ```bash; make package; ```. [DEVELOP.md]: ./DEV",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md:1460,install,install,1460,math/minuit2/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md,2,['install'],['install']
Deployability," information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-devel```, re-compile Python and ```configure```; will automatically link against the required libraries and produce a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up with your correct fingerprint. These; credentials are needed to sign the Debian package and create Debian changelogs.; On a build machine (Electric Commander), make sure the fingerprint is of the; user who is supposed to sign the official uploads. You might also want to; configure GnuPG to not ask for the passphrase",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:2097,install,installation,2097,interpreter/cling/tools/packaging/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md,1,['install'],['installation']
Deployability," insert; stack stores on its own, so it is best not to use these operations on variables; with automatic storage duration. Also, loads and stores may be implicit in code written between the ``ldrex`` and; ``strex``. Clang will not necessarily mitigate the effects of these either, so; care should be exercised. For these reasons the higher level atomic primitives should be preferred where; possible. Non-temporal load/store builtins; --------------------------------. Clang provides overloaded builtins allowing generation of non-temporal memory; accesses. .. code-block:: c. T __builtin_nontemporal_load(T *addr);; void __builtin_nontemporal_store(T value, T *addr);. The types ``T`` currently supported are:. * Integer types.; * Floating-point types.; * Vector types. Note that the compiler does not guarantee that non-temporal loads or stores; will be used. C++ Coroutines support builtins; --------------------------------. .. warning::; This is a work in progress. Compatibility across Clang/LLVM releases is not; guaranteed. Clang provides experimental builtins to support C++ Coroutines as defined by; https://wg21.link/P0057. The following four are intended to be used by the; standard library to implement the ``std::coroutine_handle`` type. **Syntax**:. .. code-block:: c. void __builtin_coro_resume(void *addr);; void __builtin_coro_destroy(void *addr);; bool __builtin_coro_done(void *addr);; void *__builtin_coro_promise(void *addr, int alignment, bool from_promise). **Example of use**:. .. code-block:: c++. template <> struct coroutine_handle<void> {; void resume() const { __builtin_coro_resume(ptr); }; void destroy() const { __builtin_coro_destroy(ptr); }; bool done() const { return __builtin_coro_done(ptr); }; // ...; protected:; void *ptr;; };. template <typename Promise> struct coroutine_handle : coroutine_handle<> {; // ...; Promise &promise() const {; return *reinterpret_cast<Promise *>(; __builtin_coro_promise(ptr, alignof(Promise), /*from-promise=*/false));; }; static",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:145333,release,releases,145333,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['release'],['releases']
Deployability," installers*; * Distros based on Red Hat Linux (Fedora/Scientific Linux CERN) - *RPM packages*; * Mac OS X - *Apple Disk Images*; * Virtually any UNIX-like platform which supports Bash - *Tarballs*. ### Requirements; Before using this tool, make sure you have the required packages installed on; your system. Detailed information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-devel```, re-compile Python and ```configure```; will automatically link against the required libraries and produce a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:1846,update,update,1846,interpreter/cling/tools/packaging/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md,1,['update'],['update']
Deployability," instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for the ``CPyCppyy`` and ``cppyy`` packages, to allow; the C++ standard chosen to match the local compiler. pip with conda; --------------. Although installing ``cppyy`` through `conda-forge`_ is recommended, it is; possible to build/install with ``pip`` under Anaconda/miniconda. Typical Python extensions only expose a C interface for use through the; Python C-API, requiring only calling conventions (and the Python C-API; version, of course) to match to be binary compatible.; Here, cppyy differs because it exposes C++ APIs: it thus requires a C++; run-time that is ABI compatible with the C++ compiler that was used during; build-time. A set of modern compilers is available through conda-forge, but are only; intended for use with ``conda-build``.; In particular, the corresponding run-time is installed (for use through rpath; when building), but not set up.; That is, the conda compilers are added to ``PATH`` but not their libraries; to ``LD_LIBRARY_PATH`` (Mac, Linux; ``PATH`` for both on MS Windows).; Thus, you get the conda compilers and your system libraries mixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PRE",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:3121,install,installing,3121,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,2,['install'],"['install', 'installing']"
Deployability," integral. It will automatically determine the coordinates and weights of such points before performing the integration.; We can use the example above, but replacing the creation of a `ROOT::Math::GaussIntegrator` object with `ROOT::Math::GaussLegendreIntegrator`. #### ROOT::Math::GSLIntegrator. This is a wrapper for the *QUADPACK* integrator implemented in the GSL library. It supports several integration methods that can be chosen in construction time.; The default type is adaptive integration with singularity applying a Gauss-Kronrod 21-point integration rule. For a detail description of the GSL methods visit the GSL user guide; This class implements the best algorithms for numerical integration for one dimensional functions. We encourage the use it as the main option, bearing in mind that it uses code from the; GSL library, wich is provided in the *MathMore* library of ROOT. The interface to use is the same as above. We have now the possibility to specify a different integration algorithm in the constructor of the `ROOT::Math::GSLIntegrator` class.; ```{.cpp}; // create the adaptive integrator with the 51 point rule; ROOT::Math::GSLIntegrator ig(ROOT::Math::Integration::kADAPTIVE, ROOT::Math::Integration::kGAUSS51);; ig.SetRelTolerance(1.E-6); // set relative tolerance; ig.SetAbsTolerance(1.E-6); // set absoulte tolerance; ```. The algorithm is controlled by the given absolute and relative tolerance. The iterations are continued until the following condition is satisfied; $$; absErr <= max ( epsAbs, epsRel * Integral); $$; Where *absErr* is an estimate of the absolute error (it can be retrieved with `GSLIntegrator::Error()`) and *Integral* is the estimate of the function integral; (it can be obtained with `GSLIntegrator::Result()`). The possible integration algorithm types to use with the GSLIntegrator are the following. More information is provided in the `GSL` users documentation.; * `ROOT::Math::Integration::kNONADAPTIVE` : based on `gsl_integration_qng`. It i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:55269,integrat,integration,55269,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['integrat'],['integration']
Deployability," into a single executable (which is fairly common in large apps).; Having a single malloc would just not suffice, and instead would simply; complicate the picture further because it adds an extra variant in; addition to the one each language provides. Instead, providing a default library version of malloc and free; (and perhaps a malloc_gc with garbage collection instead of free); would make a good implementation available to anyone who wants it. I don't recall all your arguments in favor so let's discuss this again,; and soon. o 'alloca' on the other hand sounds like a good idea, and the; implementation seems fairly language-independent so it doesn't have the; problems with malloc listed above. o About indirect call:; Your option #2 sounded good to me. I'm not sure I understand your; concern about an explicit 'icall' instruction?. o A pair of important synchronization instr'ns to think about:; load-linked; store-conditional. o Other classes of instructions that are valuable for pipeline performance:; conditional-move		 ; predicated instructions. o I believe tail calls are relatively easy to identify; do you know why; .NET has a tailcall instruction?. o I agree that we need a static data space. Otherwise, emulating global; data gets unnecessarily complex. o About explicit parallelism:. We once talked about adding a symbolic thread-id field to each; instruction. (It could be optional so single-threaded codes are; not penalized.) This could map well to multi-threaded architectures; while providing easy ILP for single-threaded onces. But it is probably; too radical an idea to include in a base version of LLVM. Instead, it; could a great topic for a separate study. What is the semantics of the IA64 stop bit?. o And finally, another thought about the syntax for arrays :-). Although this syntax:; 	 array <dimension-list> of <type>; is verbose, it will be used only in the human-readable assembly code so; size should not matter. I think we should consider it because I find i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveComments.txt:3433,pipeline,pipeline,3433,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveComments.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveComments.txt,1,['pipeline'],['pipeline']
Deployability," into the; initialization of the parameter. The implicit ``self`` parameter of a method may be marked as consumed by adding; ``__attribute__((ns_consumes_self))`` to the method declaration. Methods in; the ``init`` :ref:`family <arc.method-families>` are treated as if they were; implicitly marked with this attribute. It is undefined behavior if an Objective-C message send to a method with; ``ns_consumed`` parameters (other than self) is made with a null receiver. It; is undefined behavior if the method to which an Objective-C message send; statically resolves to has a different set of ``ns_consumed`` parameters than; the method it dynamically resolves to. It is undefined behavior if a block or; function call is made through a static type with a different set of; ``ns_consumed`` parameters than the implementation of the called block or; function. .. admonition:: Rationale. Consumed parameters with null receiver are a guaranteed leak. Mismatches; with consumed parameters will cause over-retains or over-releases, depending; on the direction. The rule about function calls is really just an; application of the existing C/C++ rule about calling functions through an; incompatible function type, but it's useful to state it explicitly. .. _arc.object.operands.retained-return-values:. Retained return values; ^^^^^^^^^^^^^^^^^^^^^^. A function or method which returns a retainable object pointer type may be; marked as returning a retained value, signifying that the caller expects to take; ownership of a +1 retain count. This is done by adding the; ``ns_returns_retained`` attribute to the function or method declaration, like; so:. .. code-block:: objc. id foo(void) __attribute((ns_returns_retained));; - (id) foo __attribute((ns_returns_retained));. This attribute is part of the type of the function or method. When returning from such a function or method, ARC retains the value at the; point of evaluation of the return statement, before leaving all local scopes. When receiving a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:18783,release,releases,18783,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['releases']
Deployability," introduction of defects.; * Best leverage the experience of other contributors for each proposed change.; * Help grow and develop new contributors, through mentorship by community leaders. It is important for all contributors to understand our code-review; practices and participate in the code-review process. General Policies; ================. What Code Should Be Reviewed?; -----------------------------. All developers are required to have significant changes reviewed before they; are committed to the repository. Must Code Be Reviewed Prior to Being Committed?; -----------------------------------------------. Code can be reviewed either before it is committed or after. We expect; significant patches to be reviewed before being committed. Smaller patches; (or patches where the developer owns the component) that meet; likely-community-consensus requirements (as apply to all patch approvals) can; be committed prior to an explicit review. In situations where there is any; uncertainty, a patch should be reviewed prior to being committed. Please note that the developer responsible for a patch is also; responsible for making all necessary review-related changes, including; those requested during any post-commit review. .. _post_commit_review:. Can Code Be Reviewed After It Is Committed?; -------------------------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussions),; they may ask for a revert to the original author who is responsible to revert; the patch promptly. Developers often disagree, and erring on the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:1338,patch,patch,1338,interpreter/llvm-project/llvm/docs/CodeReview.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst,1,['patch'],['patch']
Deployability," invocation.; set(extra_deps """"); if(""openmp"" IN_LIST LLVM_ENABLE_RUNTIMES); foreach(dep opt llvm-link llvm-extract clang clang-offload-packager); if(TARGET ${dep} AND OPENMP_ENABLE_LIBOMPTARGET); list(APPEND extra_deps ${dep}); endif(); endforeach(); endif(); if(""libc"" IN_LIST LLVM_ENABLE_PROJECTS AND; (LLVM_LIBC_FULL_BUILD OR LIBC_GPU_BUILD OR LIBC_GPU_ARCHITECTURES)); if(LIBC_HDRGEN_EXE); set(hdrgen_exe ${LIBC_HDRGEN_EXE}); else(); if(TARGET ${LIBC_TABLEGEN_EXE}); set(hdrgen_exe $<TARGET_FILE:${LIBC_TABLEGEN_EXE}>); else(); set(hdrgen_exe ${LIBC_TABLEGEN_EXE}); endif(); set(hdrgen_deps ${LIBC_TABLEGEN_TARGET}); endif(); if(NOT hdrgen_exe); message(FATAL_ERROR ""libc-hdrgen executable missing""); endif(); set(libc_cmake_args ""-DLIBC_HDRGEN_EXE=${hdrgen_exe}""; ""-DLLVM_LIBC_FULL_BUILD=ON""); list(APPEND extra_deps ${hdrgen_deps}); if(LIBC_GPU_BUILD OR LIBC_GPU_ARCHITECTURES); foreach(dep clang-offload-packager nvptx-arch amdgpu-arch); if(TARGET ${dep}); list(APPEND extra_deps ${dep}); endif(); endforeach(); endif(); endif(); if(NOT LLVM_RUNTIME_TARGETS); runtime_default_target(; DEPENDS ${builtins_dep} ${extra_deps}; CMAKE_ARGS ${libc_cmake_args}; PREFIXES ${prefixes}); set(test_targets check-runtimes); else(); if(""default"" IN_LIST LLVM_RUNTIME_TARGETS); runtime_default_target(; DEPENDS ${builtins_dep} ${extra_deps}; CMAKE_ARGS ${libc_cmake_args}; PREFIXES ${prefixes}); list(REMOVE_ITEM LLVM_RUNTIME_TARGETS ""default""); else(); add_custom_target(runtimes); add_custom_target(runtimes-configure); add_custom_target(install-runtimes); add_custom_target(install-runtimes-stripped); if(LLVM_INCLUDE_TESTS); add_custom_target(check-runtimes); add_custom_target(runtimes-test-depends); set(test_targets """"); endif(); if(LLVM_RUNTIME_DISTRIBUTION_COMPONENTS); foreach(component ${LLVM_RUNTIME_DISTRIBUTION_COMPONENTS}); add_custom_target(${component}); add_custom_target(install-${component}); add_custom_target(install-${component}-stripped); endforeach(); endif(); endif(). foreach(nam",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/runtimes/CMakeLists.txt:16909,install,install-runtimes,16909,interpreter/llvm-project/llvm/runtimes/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/runtimes/CMakeLists.txt,4,['install'],"['install', 'install-runtimes', 'install-runtimes-stripped']"
Deployability," is allowed. The; actual behavior depends on the content and line breaking rules and; penalties. * ``BBCDS_Always`` (in configuration: ``Always``); Always break before ``concept``, putting it in the line after the; template declaration. .. code-block:: c++. template <typename T>; concept C = ...;. .. _BreakBeforeInlineASMColon:. **BreakBeforeInlineASMColon** (``BreakBeforeInlineASMColonStyle``) :versionbadge:`clang-format 16` :ref:`¶ <BreakBeforeInlineASMColon>`; The inline ASM colon style to use. Possible values:. * ``BBIAS_Never`` (in configuration: ``Never``); No break before inline ASM colon. .. code-block:: c++. asm volatile(""string"", : : val);. * ``BBIAS_OnlyMultiline`` (in configuration: ``OnlyMultiline``); Break before inline ASM colon if the line length is longer than column; limit. .. code-block:: c++. asm volatile(""string"", : : val);; asm(""cmoveq %1, %2, %[result]""; : [result] ""=r""(result); : ""r""(test), ""r""(new), ""[result]""(old));. * ``BBIAS_Always`` (in configuration: ``Always``); Always break before inline ASM colon. .. code-block:: c++. asm volatile(""string"",; :; : val);. .. _BreakBeforeTernaryOperators:. **BreakBeforeTernaryOperators** (``Boolean``) :versionbadge:`clang-format 3.7` :ref:`¶ <BreakBeforeTernaryOperators>`; If ``true``, ternary operators will be placed after line breaks. .. code-block:: c++. true:; veryVeryVeryVeryVeryVeryVeryVeryVeryVeryVeryLongDescription; ? firstValue; : SecondValueVeryVeryVeryVeryLong;. false:; veryVeryVeryVeryVeryVeryVeryVeryVeryVeryVeryLongDescription ?; firstValue :; SecondValueVeryVeryVeryVeryLong;. .. _BreakConstructorInitializers:. **BreakConstructorInitializers** (``BreakConstructorInitializersStyle``) :versionbadge:`clang-format 5` :ref:`¶ <BreakConstructorInitializers>`; The break constructor initializers style to use. Possible values:. * ``BCIS_BeforeColon`` (in configuration: ``BeforeColon``); Break constructor initializers before the colon and after the commas. .. code-block:: c++. Constructor(); : initial",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:53476,configurat,configuration,53476,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:5369,release,release,5369,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['release'],['release']
Deployability," is example of a; configuration file:. ::. # Several options on line; -c --target=x86_64-unknown-linux-gnu. # Long option split between lines; -I/usr/lib/gcc/x86_64-linux-gnu/5.4.0/../../../../\; include/c++/5.4.0. # other config files may be included; @linux.options. Files included by ``@file`` directives in configuration files are resolved; relative to the including file. For example, if a configuration file; ``~/.llvm/target.cfg`` contains the directive ``@os/linux.opts``, the file; ``linux.opts`` is searched for in the directory ``~/.llvm/os``. Another way to; include a file content is using the command line option ``--config=``. It works; similarly but the included file is searched for using the rules for configuration; files. To generate paths relative to the configuration file, the ``<CFGDIR>`` token may; be used. This will expand to the absolute path of the directory containing the; configuration file. In cases where a configuration file is deployed alongside SDK contents, the; SDK directory can remain fully portable by using ``<CFGDIR>`` prefixed paths.; In this way, the user may only need to specify a root configuration file with; ``--config=`` to establish every aspect of the SDK with the compiler:. ::. --target=foo; -isystem <CFGDIR>/include; -L <CFGDIR>/lib; -T <CFGDIR>/ldscripts/link.ld. Language and Target-Independent Features; ========================================. Controlling Errors and Warnings; -------------------------------. Clang provides a number of ways to control which code constructs cause; it to emit errors and warning messages, and how they are displayed to; the console. Controlling How Clang Displays Diagnostics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. When Clang emits a diagnostic, it includes rich information in the; output, and gives you fine-grain control over which information is; printed. Clang has the ability to print this information, and these are; the options that control it:. #. A file/line/column indicator that shows ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:35287,configurat,configuration,35287,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,2,"['configurat', 'deploy']","['configuration', 'deployed']"
Deployability," is painted the same way in GL and non-GL mode.; The mismatch was reported in [this post](https://root-forum.cern.ch/t/how-to-specify-the-level-value-in-isosurface-drawing-with-tf3-and-gl/32179). ## Geometry Libraries. ## Database Libraries. The CMake module `FindOracle.cmake` was updated to support version 18.x; of the Oracle client libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ## JavaScript ROOT. ### New functionality from 5.7.0 release. - Add support of `TProfile2Poly` class; - Add support of `TGeoOverlap` class; - Add support of `TGeoHalfSpace` for composites; - Implement update of `TF2` drawings, see `tutorials/graphics/anim.C`; - Improve windows handling in flex(ible) layout; - Provide special widget for object inspector; - Use `requestAnimationFrame` when do monitoring, improves performance; - Better position for text in `TH2Poly` drawings; - Support eve7 geometry viewer - render data generated in ROOT itself; - Provide initial WebVR support, thanks to Diego Marcos; - Use `gStyle` attributes to draw histogram title; - Enable projections drawing also with `TH2` lego plots; - Many adjustment with new `TWebCanvas` - interactivity, attributes/position updates, context menus; - Upgrade three.js 86 -> 102, use `SoftwareRenderer` instead of `CanvasRenderer`; - Upgrade d3.js 4.4.4 -> 5.7.0; - Fix - support clipping for tracks and points in geo painter; - Fix - drawing of TGeoNode with finder; - Fix - key press events processed only in active pad (ROOT-9128); - Fix - use X0/Y0 in xtru shape, thanks to @altavir. ### New files location. JSROOT sources were moved from `etc/http/` into `js/` subfolder in ROOT sources tree.; OpenUI5 files were moved to `ui5/` subfolder. After ROOT compilation they can be found in; `$ROOTSYS/js/` and `$ROOTSYS/ui5/` subfolders respectively. ## Tutorials; - Add `RSqliteDS` examples.; - Make RCsvDS and RLazyDS tutorials standalone, i.e. downloading input csv directly us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:21091,update,updates,21091,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,1,['update'],['updates']
Deployability," is part of the compiler-rt project, which implements; the runtime components that perform the patching and unpatching of inserted; instrumentation points. When you use ``clang`` to link your binaries and the; ``-fxray-instrument`` flag, it will automatically link in the XRay runtime. The default implementation of the XRay runtime will enable XRay instrumentation; before ``main`` starts, which works for applications that have a short; lifetime. This implementation also records all function entry and exit events; which may result in a lot of records in the resulting trace. Also by default the filename of the XRay trace is ``xray-log.XXXXXX`` where the; ``XXXXXX`` part is randomly generated. These options can be controlled through the ``XRAY_OPTIONS`` environment; variable, where we list down the options and their defaults below. +-------------------+-----------------+---------------+------------------------+; | Option | Type | Default | Description |; +===================+=================+===============+========================+; | patch_premain | ``bool`` | ``false`` | Whether to patch |; | | | | instrumentation points |; | | | | before main. |; +-------------------+-----------------+---------------+------------------------+; | xray_mode | ``const char*`` | ``""""`` | Default mode to |; | | | | install and initialize |; | | | | before ``main``. |; +-------------------+-----------------+---------------+------------------------+; | xray_logfile_base | ``const char*`` | ``xray-log.`` | Filename base for the |; | | | | XRay logfile. |; +-------------------+-----------------+---------------+------------------------+; | verbosity | ``int`` | ``0`` | Runtime verbosity |; | | | | level. |; +-------------------+-----------------+---------------+------------------------+. If you choose to not use the default logging implementation that comes with the; XRay runtime and/or control when/how the XRay instrumentation runs, you may use; the XRay APIs directly for doing so. To do thi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:5708,patch,patch,5708,interpreter/llvm-project/llvm/docs/XRay.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst,1,['patch'],['patch']
Deployability," is the annual release schedule for LLVM. This is meant to be a; guide, and release managers are not required to follow this exactly.; Releases should be tagged on Tuesdays. =============================== =========================; Release Approx. Date; =============================== =========================; *release branch: even releases* *4th Tue in January*; *release branch: odd releases* *4th Tue in July*; X.1.0-rc1 3 days after branch.; X.1.0-rc2 2 weeks after branch.; X.1.0-rc3 4 weeks after branch; **X.1.0-final** **6 weeks after branch**; **X.1.1** **8 weeks after branch**; **X.1.2** **10 weeks after branch**; **X.1.3** **12 weeks after branch**; **X.1.4** **14 weeks after branch**; **X.1.5** **16 weeks after branch**; **X.1.6 (if necessary)** **18 weeks after branch**; =============================== =========================. Release Process Summary; -----------------------. * Announce release schedule to the LLVM community and update the website. Do; this at least 3 weeks before the -rc1 release. * Create release branch and begin release process. * Send out release candidate sources for first round of testing. Testing lasts; 6 weeks. During the first round of testing, any regressions found should be; fixed. Patches are merged from mainline into the release branch. Also, all; features need to be completed during this time. Any features not completed at; the end of the first round of testing will be removed or disabled for the; release. * Generate and send out the second release candidate sources. Only *critical*; bugs found during this testing phase will be fixed. Any bugs introduced by; merged patches will be fixed. If so a third round of testing is needed. * The release notes are updated. * Finally, release!. * Announce bug fix release schedule to the LLVM community and update the website. * Do bug-fix releases every two weeks until X.1.5 or X.1.6 (if necessary). Release Process; ===============. .. contents::; :local:. Release Administrative Tasks; -",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:2187,release,release,2187,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['release'],['release']
Deployability," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5607,configurat,configuration,5607,proof/doc/confman/DatasetStager.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md,2,['configurat'],['configuration']
Deployability," is:. # Build an LLVM toolchain with support for Windows Itanium.; # Use the toolchain from step 1. to build libc++, libc++abi, and libunwind. It is also possible to cross-compile from Linux. One method of building the libraries in step 2. is to build them ""stand-alone"".; A stand-alone build doesn't involve the rest of the LLVM tree. The steps are:. * ``cd build-dir``; * ``cmake -DLLVM_PATH=<path to llvm checkout e.g. /llvm-project/> -DCMAKE_INSTALL_PREFIX=<install path> <other options> <path to project e.g. /llvm-project/libcxxabi>``; * ``<make program e.g. ninja>``; * ``<make program> install``. More information on standalone builds can be found in the build documentation for; the respective libraries. The next section discuss the salient options and modifications; required for building and installing the libraries using standalone builds. This assumes; that we are building libunwind and ibc++ as DLLs and statically linking libc++abi into; libc++. Other build configurations are possible, but they are not discussed here. Common CMake configuration options:; -----------------------------------. * ``-D_LIBCPP_ABI_FORCE_ITANIUM'``. Tell the libc++ headers that the Itanium C++ ABI is being used. * ``-DCMAKE_C_FLAGS=""-lmsvcrt -llegacy_stdio_definitions -D_NO_CRT_STDIO_INLINE""``. Supply CRT definitions including stdio definitions that have been removed from the MS VS CRT.; We don't want the stdio functions declared inline as they will cause multiple definition; errors when the same symbols are pulled in from legacy_stdio_definitions.ib. * ``-DCMAKE_INSTALL_PREFIX=<install path>``. Where to install the library and headers. Building libunwind:; -------------------. * ``-DLIBUNWIND_ENABLE_SHARED=ON``; * ``-DLIBUNWIND_ENABLE_STATIC=OFF``. libunwind can be built as a DLL. It is not dependent on other projects. * ``-DLIBUNWIND_USE_COMPILER_RT=OFF``. We use the MS runtime. The CMake files will need to be edited to prevent them adding GNU specific libraries to the link line. Bui",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildWindowsItaniumPrograms.rst:4011,configurat,configurations,4011,interpreter/llvm-project/llvm/docs/HowToBuildWindowsItaniumPrograms.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildWindowsItaniumPrograms.rst,1,['configurat'],['configurations']
Deployability," is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_inv sc0`` is required which will invalidate; the L1 cache. * A ``buffer_inv sc0`` is required to invalidate the L1 cache for coherence; between wavefronts executing in different work-groups as they may be; executing on different CUs. * Atomic read-modify-write instructions implicitly bypass the L1 cache.; Therefore, they do not use the sc0 bit for coherence and instead use it to; indicate if the instruction returns the original value being updated. They; do use sc1 to indicate system or agent scope coherence. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache. * The gfx942 can be configured as a number of smaller agents with each having; a single L2 shared by all CUs on the same agent, or as fewer (possibly one); larger agents with groups of CUs on each agent each sharing separate L2; caches.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel for its associated L2.; Therefore, the vector and scalar memory operations performed by wavefronts; executing with different L1 caches and t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:286882,update,updated,286882,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['update'],['updated']
Deployability," it appears; within a map that has been added by the same *vendor-name*. .. table:: AMDPAL Code Object Metadata Map; :name: amdgpu-amdpal-code-object-metadata-map-table. =================== ============== ========= ======================================================================; String Key Value Type Required? Description; =================== ============== ========= ======================================================================; ""amdpal.version"" sequence of Required PAL code object metadata (major, minor) version. The current values; 2 integers are defined by *Util::Abi::PipelineMetadata(Major|Minor)Version*.; ""amdpal.pipelines"" sequence of Required Per-pipeline metadata. See; map :ref:`amdgpu-amdpal-code-object-pipeline-metadata-map-table` for the; definition of the keys included in that map.; =================== ============== ========= ======================================================================. .. .. table:: AMDPAL Code Object Pipeline Metadata Map; :name: amdgpu-amdpal-code-object-pipeline-metadata-map-table. ====================================== ============== ========= ===================================================; String Key Value Type Required? Description; ====================================== ============== ========= ===================================================; "".name"" string Source name of the pipeline.; "".type"" string Pipeline type, e.g. VsPs. Values include:. - ""VsPs""; - ""Gs""; - ""Cs""; - ""Ngg""; - ""Tess""; - ""GsTess""; - ""NggTess"". "".internal_pipeline_hash"" sequence of Required Internal compiler hash for this pipeline. Lower; 2 integers 64 bits is the ""stable"" portion of the hash, used; for e.g. shader replacement lookup. Upper 64 bits; is the ""unique"" portion of the hash, used for; e.g. pipeline cache lookup. The value is; implementation defined, and can not be relied on; between different builds of the compiler.; "".shaders"" map Per-API shader metadata. See; :ref:`amdgpu-amdpal-code-object-shader-map-table`; for ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:403218,pipeline,pipeline-metadata-map-table,403218,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['pipeline'],['pipeline-metadata-map-table']
Deployability," iterator and multidependences | :good:`done` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | misc | depobj directive and depobj dependency kind | :good:`done` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | misc | user-defined function variants | :good:`done`. | D67294, D64095, D71847, D71830, D109635 |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | misc | pointer/reference to pointer based array reductions | :good:`done` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | misc | prevent new type definitions in clauses | :good:`done` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | memory model | memory model update (seq_cst, acq_rel, release, acquire,...) | :good:`done` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+. .. _OpenMP 51 implementation details:. OpenMP 5.1 Implementation Details; =================================. The following table provides a quick overview over various OpenMP 5.1 features; and their implementation status.; Please post on the; `Discourse forums (Runtimes - OpenMP category)`_ for more; information or if you want to help with the; impl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst:20902,update,update,20902,interpreter/llvm-project/clang/docs/OpenMPSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst,2,"['release', 'update']","['release', 'update']"
Deployability," ivars and methods, designed to; allow a class's ``@interface`` to be split across multiple files; however,; there is still a primary implementation file which must see the; ``@interface``\ s of all class extensions. :arc-term:`Categories` allow; methods (but not ivars) to be declared *post hoc* on an arbitrary class; the; methods in the category's ``@implementation`` will be dynamically added to that; class's method tables which the category is loaded at runtime, replacing those; methods in case of a collision. In the standard environment, objects are allocated on the heap, and their; lifetime is manually managed using a reference count. This is done using two; instance methods which all classes are expected to implement: ``retain``; increases the object's reference count by 1, whereas ``release`` decreases it; by 1 and calls the instance method ``dealloc`` if the count reaches 0. To; simplify certain operations, there is also an :arc-term:`autorelease pool`, a; thread-local list of objects to call ``release`` on later; an object can be; added to this pool by calling ``autorelease`` on it. Block pointers may be converted to type ``id``; block objects are laid out in a; way that makes them compatible with Objective-C objects. There is a builtin; class that all block objects are considered to be objects of; this class; implements ``retain`` by adjusting the reference count, not by calling; ``Block_copy``. .. _arc.meta.evolution:. Evolution; ---------. ARC is under continual evolution, and this document must be updated as the; language progresses. If a change increases the expressiveness of the language, for example by; lifting a restriction or by adding new syntax, the change will be annotated; with a revision marker, like so:. ARC applies to Objective-C pointer types, block pointer types, and; :when-revised:`[beginning Apple 8.0, LLVM 3.8]` :revision:`BPTRs declared; within` ``extern ""BCPL""`` blocks. For now, it is sensible to version this document by the releases of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:7092,release,release,7092,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['release']
Deployability," just as you like. When clicking on; ""Apply"", the function plot is updated to reflect the actual value of the; parameters you have set. [f25]: figures/ROOTPanel_FitPanel.png ""f25""; <a name=""f25""></a>. ![Fit Panel. \label{f25}][f25]. Another very useful interactive tool is the `FitPanel`, available for the; classes `TGraphErrors` and `TH1F`. Predefined fit functions can be selected; from a pull-down menu, including ""`gaus`"", ""`expo`"" and ""`pol0`"" - ""`pol9`""; for Gaussian and exponential functions or polynomials of degree 0 to 9,; respectively. In addition, user-defined functions using the same syntax as; for functions with parameters are possible. After setting the initial parameters, a fit of the selected function to the; data of a graph or histogram can be performed and the result displayed on the plot.; The fit panel is shown in Figure [2.5](#f25). The fit panel has a number of control options to; select the fit method, fix or release individual parameters in the fit, to steer; the level of output printed on the console, or to extract and display additional; information like contour lines showing parameter correlations. As function fitting; is of prime importance in any kind of data analysis, this topic will again show up; later. If you are satisfied with your plot, you probably want to save it. Just; close all selector boxes you opened previously and select the menu item; `Save as...` from the menu line of the window. It will pop up a file; selector box to allow you to choose the format, file name and target; directory to store the image. There is one very noticeable feature here:; you can store a plot as a root macro! In this macro, you find the C++; representation of all methods and classes involved in generating the; plot. This is a valuable source of information for your own macros,; which you will hopefully write after having worked through this; tutorial. Using ROOT's interactive capabilities is useful for a first exploration; of possibilities. Other ROOT cl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md:15498,release,release,15498,documentation/primer/ROOT_as_calculator.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md,1,['release'],['release']
Deployability," labels. We recommend that active developers monitor incoming issues.; You can subscribe for notification for specific components by joining; one of the `issue-subscribers-* <https://github.com/orgs/llvm/teams?query=issue-subscribers>`_; teams.; You may also subscribe to the `llvm-bugs; <http://lists.llvm.org/mailman/listinfo/llvm-bugs>`_ email list to keep track; of bugs and enhancements occurring in the entire project. We really appreciate people; who are proactive at catching incoming bugs in their components and dealing with them; promptly. Please be aware that all public LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLVM. This makes it easy to apply the patch. For information on how to; clone from git, please see the :ref:`Getting Started Guide; <checkout>`. #. Similarly, patches should be submitted soon after they are generated. Old; patches may not apply correctly if the underlying code changes between the; time the patch was created and the time it is applied. #. Once you have created your patch, create a; :ref:`GitHub Pull Request <github-reviews>` for; it (or commit it directly if applicable). When submitting patches, please do not add confidentiality or non-disclosure; notices to the patches themselves. These notices conflict with the LLVM; licensing terms and may result in your contribution being excluded. .. _code review:. Code Reviews; ------------. LLVM has a code-review policy. Code review is one way to increase the quality of; software. Please see :doc:`CodeReview` for more information on LLVM's code-review; process. .. _breaking:. Making Potentially ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:3941,patch,patch,3941,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['patch'],['patch']
Deployability," last Python; reference to the proxy disappears.; You can check/change the ownership with the __python_owns__ flag that every; bound instance carries.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete(); >>> c.__python_owns__ # True: object created in Python; True; >>>. * ``__creates__``: a flag that every C++ overload carries and determines; whether the return value is owned by C++ or Python: if ``True``, Python owns; the return value, otherwise C++. * ``__set_lifeline__``: a flag that every C++ overload carries and determines; whether the return value should place a back-reference on ``self``, to; prevent the latter from going out of scope before the return value does.; The default is ``False``, but will be automatically set at run-time if a; return value's address is a C++ object pointing into the memory of ``this``,; or if ``self`` is a by-value return. * ``__release_gil__``: a flag that every C++ overload carries and determines; whether the Global Interpreter Lock (GIL) should be released during the C++; call to allow multi-threading.; The default is ``False``. * ``__useffi__``: a flag that every C++ overload carries and determines; whether generated wrappers or direct foreign functions should be used.; This is for PyPy only; the flag has no effect on CPython. * ``__sig2exc__``: a flag that every C++ overload carries and determines; whether C++ signals (such as SIGABRT) should be converted into Python; exceptions. * ``__cpp_name__``: a string that every C++ bound class carries and contains; the actual C++ name (as opposed to ``__name__`` which has the Python name).; This can be useful for template instantiations, documentation, etc. * ``__cpp_template__``: a back-reference to the template used to instantiate; a templated class.; This variable only exists if the class was dynamically instantiated from; Python at least once. `STL algorithms`; ----------------. It is usually easier to use a Python equivalent or code up the eff",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:2056,release,released,2056,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,1,['release'],['released']
Deployability," lead to leaks, and over-releases lead to uses-after-free.; The analyzer can help the programmer to check for unbalanced; retain/release calls.; The reference count checking is based on the principle of; locality: it should be possible to establish correctness; (lack of leaks/uses after free) by looking at each function body,; and the declarations (not the definitions) of all the functions it interacts; with.; In order to support such reasoning, it should be possible to summarize; the behavior of each function, with respect to reference count; of its returned values and attributes.; By default, the following summaries are assumed:. All functions starting with get or Get,; unless they are returning subclasses of OSIterator,; are assumed to be returning at +0.; That is, the caller has no reference; count obligations with respect to the reference count of the returned object; and should leave it untouched.; . All other functions are assumed to return at +1.; That is, the caller has an obligation to release such objects.; . Functions are assumed not to change the reference count of their parameters,; including the implicit this parameter.; . These summaries can be overriden with the following; attributes:; Attribute 'os_returns_retained'; The os_returns_retained attribute (accessed through the macro ; LIBKERN_RETURNS_RETAINED) plays a role identical to ns_returns_retained for functions; returning OSObject subclasses.; The attribute indicates that it is a callers responsibility to release the; returned object. Attribute 'os_returns_not_retained'; The os_returns_not_retained attribute (accessed through the macro ; LIBKERN_RETURNS_NOT_RETAINED) plays a role identical to ns_returns_not_retained for functions; returning OSObject subclasses.; The attribute indicates that the caller should not change the retain; count of the returned object. Example. class MyClass {; OSObject *f;; LIBKERN_RETURNS_NOT_RETAINED OSObject *myFieldGetter();; }. // Note that the annotation only has ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html:15252,release,release,15252,interpreter/llvm-project/clang/www/analyzer/annotations.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html,1,['release'],['release']
Deployability," like it's not the right; option, you can contact the cfe-dev mailing list to get more feedback; on the direction;. Commit access; =============. Once you've contributed a handful of patches to LLVM, start to think; about getting commit access yourself. It's probably a good idea if:. - you've landed 3-5 patches of larger scope than ""fix a typo"". - you'd be willing to review changes that are closely related to yours. - you'd like to keep contributing to LLVM. Getting commit access; ---------------------. LLVM uses Git for committing changes. The details are in the `developer; policy; document <https://llvm.org/docs/DeveloperPolicy.html#obtaining-commit-access>`__. With great power; ----------------. Actually, this would be a great time to read the rest of the `developer; policy <https://llvm.org/docs/DeveloperPolicy.html>`__, too. At minimum,; you need to be subscribed to the relevant commits list before landing; changes (e.g. llvm-commits@lists.llvm.org), as discussion often happens; there if a new patch causes problems. Post-commit errors; ------------------. Once your change is submitted it will be picked up by automated build; bots that will build and test your patch in a variety of configurations. You can see all configurations and their current state in a waterfall; view at http://lab.llvm.org/buildbot/#/waterfall. The waterfall view is good; to get a general overview over the tested configurations and to see; which configuration have been broken for a while. The console view at http://lab.llvm.org/buildbot/#/console helps to get a; better understanding of the build results of a specific patch. If you; want to follow along how your change is affecting the build bots, **this; should be the first place to look at** - the colored bubbles correspond; to projects in the waterfall. If you see a broken build, do not despair - some build bots are; continuously broken; if your change broke the build, you will see a red; bubble in the console view, while an already broke",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst:13545,patch,patch,13545,interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst,1,['patch'],['patch']
Deployability," list with components x and y,; //containing n coordinates which interpolate the given data points according to the method (and rule) desired.; r<<""points(approx(x, y), col = 2, pch = '*')"";; r<<""points(approx(x, y, method = 'constant'), col = 4, pch = '*')"";. //The function ""approxfun"" returns a function performing (linear or constant); //interpolation of the given data.; //For a given set of x values, this function will return the corresponding interpolated values.; r<<""f <- approxfun(x, y)"";. r<<""curve(f(x), 0, 11, col = 'green2')"";; r<<""points(x, y)"";. //using approxfun with const method; r<<""fc <- approxfun(x, y, method = 'const')"";; r<<""curve(fc(x), 0, 10, col = 'darkblue', add = TRUE)"";; // different interpolation on left and right side :; r<<""plot(approxfun(x, y, rule = 2:1), 0, 11,col = 'tomato', add = TRUE, lty = 3, lwd = 2)"";; }; ~~~; The image shows the interpolated function plotted within R:; \image html R_image3.png. ## Integration (Passing vectorized function to R); Numerical integration using R passing the function from ROOT. ~~~{.cxx}; #include<TMath.h>; #include<TRInterface.h>; #include<Math/Integrator.h>; #include<TF1.h>. //To integrate using R the function must be vectorized; //The idea is just to receive a vector like an argument,to evaluate; //every element saving the result in another vector; //and return the resultant vector.; std::vector<Double_t> BreitWignerVectorized(std::vector<Double_t> xx); {; std::vector<Double_t> result(xx.size());; for(Int_t i=0;i<xx.size();i++); {; result[i]=TMath::BreitWigner(xx[i]);; }; return result;; }. double BreitWignerWrap( double x){; return TMath::BreitWigner(x);; }. void Integration(); {. ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();. r[""BreitWigner""]=BreitWignerVectorized;. Double_t value=r.Eval(""integrate(BreitWigner, lower = -2, upper = 2)$value"");. std::cout.precision(18);; std::cout<<""Integral of the BreitWigner Function in the interval [-2, 2] R = ""<<value<<std::endl;. ROOT::Math::WrappedF",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:22254,integrat,integration,22254,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['integrat'],['integration']
Deployability," listing below) and has only been tested on; Linux on x86_64. Numba `is a JIT compiler`_ for Python functions that can be statically typed; based on their input arguments.; Since C++ objects are always statically typed and already implemented at the; machine level, they can be dynamically integrated into the Numba type tracing; and lowering by exposing type details through C++ reflection at runtime. JIT-compiling traces of mixed Python/bound C++ code reduces, and in some; cases removes, the overhead of boxing/unboxing native data into their Python; proxies and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for inte",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:1137,integrat,integrate,1137,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,1,['integrat'],['integrate']
Deployability," local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; 4. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 5. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - global 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:320420,release,released,320420,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['released']
Deployability," long unless there are critical issues remaining. In most cases, the only; kind of bugs that are critical enough to block a release would be a major regression; from a previous release. Official Testing; ----------------. A few developers in the community have dedicated time to validate the release; candidates and volunteered to be the official release testers for each; architecture. These will be the ones testing, generating and uploading the official binaries; to the server, and will be the minimum tests *necessary* for the release to; proceed. This will obviously not cover all OSs and distributions, so additional community; validation is important. However, if community input is not reached before the; release is out, all bugs reported will have to go on the next stable release. The official release managers are:. * Even releases: Tom Stellard (tstellar@redhat.com); * Odd releases: Tobias Hieta (tobias@hieta.se). The official release testers are volunteered from the community and have; consistently validated and released binaries for their targets/OSs. To contact; them, you should post on the `Discourse forums (Project; Infrastructure - Release Testers). <https://discourse.llvm.org/c/infrastructure/release-testers/66>`_. The official testers list is in the file ``RELEASE_TESTERS.TXT``, in the ``LLVM``; repository. Community Testing; -----------------. Once all testing has been completed and appropriate bugs filed, the release; candidate tarballs are put on the website and the LLVM community is notified. We ask that all LLVM developers test the release in any the following ways:. #. Download ``llvm-X.Y``, ``llvm-test-X.Y``, and the appropriate ``clang``; binary. Build LLVM. Run ``make check`` and the full LLVM test suite (``make; TEST=nightly report``). #. Download ``llvm-X.Y``, ``llvm-test-X.Y``, and the ``clang`` sources. Compile; everything. Run ``make check`` and the full LLVM test suite (``make; TEST=nightly report``). #. Download ``llvm-X.Y``, ``llvm-test-X.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:7535,release,release,7535,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,2,['release'],"['release', 'released']"
Deployability," make LLVM/Clang run faster, but can be an impediment for; step-by-step debugging.; * Builds with debug information can use a lot of RAM and disk space and is; usually slower to run. You can improve RAM usage by using ``lld``, see; the :ref:`LLVM_USE_LINKER <llvm_use_linker>` option.; * Assertions are internal checks to help you find bugs. They typically slow; down LLVM and Clang when enabled, but can be useful during development.; You can manually set :ref:`LLVM_ENABLE_ASSERTIONS <llvm_enable_assertions>`; to override the default from `CMAKE_BUILD_TYPE`. If you are using an IDE such as Visual Studio or Xcode, you should use; the IDE settings to set the build type. **CMAKE_INSTALL_PREFIX**:PATH; Path where LLVM will be installed when the ""install"" target is built. **CMAKE_{C,CXX}_FLAGS**:STRING; Extra flags to use when compiling C and C++ source files respectively. **CMAKE_{C,CXX}_COMPILER**:STRING; Specify the C and C++ compilers to use. If you have multiple; compilers installed, CMake might not default to the one you wish to; use. .. _Frequently Used LLVM-related variables:. Frequently Used LLVM-related variables; --------------------------------------. The default configuration may not match your requirements. Here are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. **LLVM_LIBDIR_SUFFIX**:STRING; Extra suffix to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:8640,install,installed,8640,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['install'],['installed']
Deployability," make subsequent changes to. Also, try to separate; formatting or whitespace changes from functional changes, either by; correcting the format first (ideally) or afterward. Such changes should be; highly localized and the commit message should clearly state that the commit; is not intended to change functionality, usually by stating it is; :ref:`NFC <nfc>`. #. You are allowed to commit patches without approval to those portions of LLVM; that you have contributed or maintain (i.e., have been assigned; responsibility for), with the proviso that such commits must not break the; build. This is a ""trust but verify"" policy, and commits of this nature are; reviewed after they are committed. #. Multiple violations of these policies or a single egregious violation may; cause commit access to be revoked. In any case, your changes are still subject to `code review`_ (either before or; after they are committed, depending on the nature of the change). You are; encouraged to review other peoples' patches as well, but you aren't required; to do so. .. _discuss the change/gather consensus:. Making a Major Change; ---------------------. When a developer begins a major new project with the aim of contributing it back; to LLVM, they should inform the community with a post to the `LLVM Discourse forums`_, to the extent; possible. The reason for this is to:. #. keep the community informed about future changes to LLVM,. #. avoid duplication of effort by preventing multiple parties working on the; same thing and not knowing about it, and. #. ensure that any technical issues around the proposed work are discussed and; resolved before any significant work is done. The design of LLVM is carefully controlled to ensure that all the pieces fit; together well and are as consistent as possible. If you plan to make a major; change to the way LLVM works or want to add a major new extension, it is a good; idea to get consensus with the development community before you start working on; it. Once the d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:25802,patch,patches,25802,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['patch'],['patches']
Deployability," mapping function; returns more usernames, the username specified by the client is used to; help choosing the effective username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username is chosen instead.; In XrdProofd, allow 'xpd.allowedgroups' to control also PROOF; groups, not only UNIX ones.In XrdProofd, simplify error; messages in case of login failure because of non-authorization.; Remove hardcoded additions of dirname(COMPILER) and of; '/bin:/usr/bin:/usr/local/bin' in front of PATH. These uncontrolled; additions could hide specific settings in PATH and be the source of; weird problems appearing in PROOF only.; Add more flexibility to the definition of the library path seen by; proofserv. So far to avoid ambiguites in some cases, $ROOTSYS/lib was; removed and the one of the ROOT version chosen was added later on in; front, which proved to be to aggressive in some cases.; All changes (and fixes) needed to build against the version of Xrootd,; now always installed as external.; Fixes. Fix GetSessionLogs in PROOF-Lite; Restore correct parsing of ""workers=N"" in PROOF-Lite; In Proof-Bench, make sure that it can be run from any directory; and no matter how ROOT was installed; Fix issue in TProofPlayer::HandleHistogram preventing proper; histogram cleaning right after merging when using TH1::Add; histogram; were still destroyed at the end of the query, but there was no; memory advantage in TH1::Add wrt TH1::Merge.; Make sure that the performance tree is removed from the output; list when saved to the output file. Solves a segv at quit.; Decouple from registered TChains in already TProof::Close(); allows; to avoid possible crash at exit ('.q') occuring after the recent; revision of the socket cleanup policy.; In XrdProofd, fix a few issues with option 'xpd.multiuser'.; In TXSocket::ProcessUnsolicitedMsg, fix an issue preventig server; messages to be displayed during setup, i.e. when the XrdClientConn; instance ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:3587,install,installed,3587,proof/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html,1,['install'],['installed']
Deployability," may only need to enable; your native target with, for example, ``-DLLVM_TARGETS_TO_BUILD=X86``. .. _llvm_use_linker:. **LLVM_USE_LINKER**:STRING; Override the system's default linker. For instance use ``lld`` with; ``-DLLVM_USE_LINKER=lld``. Rarely-used CMake variables; ---------------------------. Here are some of the CMake variables that are rarely used, along with a brief; explanation and LLVM-related notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_INCLUDEDIR**:PATH; The path to install header files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""include"". **CMAKE_INSTALL_DOCDIR**:PATH; The path to install documentation, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/doc"". **CMAKE_INSTALL_MANDIR**:PATH; The path to install manpage files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/man"". .. _LLVM-related variables:. LLVM-related variables; -----------------------. These variables provide fine control over the build of LLVM and; enabled sub-projects. Nearly all of these variable names begin with; ``LLVM_``. **BUILD_SHARED_LIBS**:BOOL; Flag indicating if each LLVM component (e.g. Support) is built as a shared; library (ON) or as a static library (OFF). Its default value is OFF. On; Windows, shared libraries may be used when building with MinGW, including; mingw-w64, but not when building with the Microsoft toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared library, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be bu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:11054,install,install,11054,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['install'],['install']
Deployability," movq	(%rsp), %rax # This load is redundant (oops!); 	 popq	%rdx; 	 retq. Note that the design as presented above is not fully implemented: in particular,; strategy-specific lowering is not present, and all GC transitions are emitted as; as single no-op before and after the call instruction. These no-ops are often; removed by the backend during dead machine instruction elimination. Before the abstract machine model is lowered to the explicit statepoint model; of relocations by the :ref:`RewriteStatepointsForGC` pass it is possible for; any derived pointer to get its base pointer and offset from the base pointer; by using the ``gc.get.pointer.base`` and the ``gc.get.pointer.offset``; intrinsics respectively. These intrinsics are inlined by the; :ref:`RewriteStatepointsForGC` pass and must not be used after this pass. .. _statepoint-stackmap-format:. Stack Map Format; ================. Locations for each pointer value which may need read and/or updated by; the runtime or collector are provided in a separate section of the; generated object file as specified in the PatchPoint documentation.; This special section is encoded per the; :ref:`Stack Map format <stackmap-format>`. The general expectation is that a JIT compiler will parse and discard this; format; it is not particularly memory efficient. If you need an alternate; format (e.g. for an ahead of time compiler), see discussion under; :ref: `open work items <OpenWork>` below. Each statepoint generates the following Locations:. * Constant which describes the calling convention of the call target. This; constant is a valid :ref:`calling convention identifier <callingconv>` for; the version of LLVM used to generate the stackmap. No additional compatibility; guarantees are made for this constant over what LLVM provides elsewhere w.r.t.; these identifiers.; * Constant which describes the flags passed to the statepoint intrinsic; * Constant which describes number of following deopt *Locations* (not; operands). Will be 0 i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:20064,update,updated,20064,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['update'],['updated']
Deployability," must implement these methods in a way such that the compiler,; modifying code in ways it deems safe according to these constraints, will not; violate their requirements. For example, if the user puts logging statements; in ``retain``, they should not be surprised if those statements are executed; more or less often depending on optimization settings. These constraints are; not exhaustive of the optimization opportunities: values held in local; variables are subject to additional restrictions, described later in this; document. It is undefined behavior if a computation history featuring a send of; ``retain`` followed by a send of ``release`` to the same object, with no; intervening ``release`` on that object, is not equivalent under the high-level; semantics to a computation history in which these sends are removed. Note that; this implies that these methods may not raise exceptions. It is undefined behavior if a computation history features any use whatsoever; of an object following the completion of a send of ``release`` that is not; preceded by a send of ``retain`` to the same object. The behavior of ``autorelease`` must be equivalent to sending ``release`` when; one of the autorelease pools currently in scope is popped. It may not throw an; exception. When the semantics call for performing one of these operations on a retainable; object pointer, if that pointer is ``null`` then the effect is a no-op. All of the semantics described in this document are subject to additional; :ref:`optimization rules <arc.optimization>` which permit the removal or; optimization of operations based on local knowledge of data flow. The; semantics describe the high-level behaviors that the compiler implements, not; an exact sequence of operations that a program will be compiled into. .. _arc.objects.operands:. Retainable object pointers as operands and arguments; ----------------------------------------------------. In general, ARC does not perform retain or release operations when s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:14586,release,release,14586,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['release']
Deployability," mutually exclusive to the existing local storage; qualifiers auto, register, and static. [testme] Variables qualified by; ``__block`` act as if they were in allocated storage and this storage; is automatically recovered after last use of said variable. An; implementation may choose an optimization where the storage is; initially automatic and only ""moved"" to allocated (heap) storage upon; a Block_copy of a referencing Block. Such variables may be mutated as; normal variables are. In the case where a ``__block`` variable is a Block one must assume; that the ``__block`` variable resides in allocated storage and as such; is assumed to reference a Block that is also in allocated storage; (that it is the result of a ``Block_copy`` operation). Despite this; there is no provision to do a ``Block_copy`` or a ``Block_release`` if; an implementation provides initial automatic storage for Blocks. This; is due to the inherent race condition of potentially several threads; trying to update the shared variable and the need for synchronization; around disposing of older values and copying new ones. Such; synchronization is beyond the scope of this language specification. Control Flow; ============. The compound statement of a Block is treated much like a function body; with respect to control flow in that goto, break, and continue do not; escape the Block. Exceptions are treated *normally* in that when; thrown they pop stack frames until a catch clause is found. Objective-C Extensions; ======================. Objective-C extends the definition of a Block reference type to be; that also of id. A variable or expression of Block type may be; messaged or used as a parameter wherever an id may be. The converse is; also true. Block references may thus appear as properties and are; subject to the assign, retain, and copy attribute logic that is; reserved for objects. All Blocks are constructed to be Objective-C objects regardless of; whether the Objective-C runtime is operational in the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:8123,update,update,8123,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['update'],['update']
Deployability," my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:34476,integrat,integrate,34476,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['integrat'],['integrate']
Deployability," necessary for targets to gain and retain their; status, but also markers to define bit-rot, and will be used to clean up the; tree from unmaintained targets. Those wishing to add a new target to LLVM must follow the procedure below:. 1. Read this section and make sure your target follows all requirements. For; minor issues, your community will be responsible for making all necessary; adjustments soon after the initial merge.; 2. Send a request for comment (RFC) to the `LLVM Discourse forums`_ describing; your target and how it follows all the requirements and what work has been; done and will need to be done to accommodate the official target requirements.; Make sure to expose any and all controversial issues, changes needed in the; base code, table gen, etc.; 3. Once the response is positive, the LLVM community can start reviewing the; actual patches (but they can be prepared before, to support the RFC). Create; a sequence of N patches, numbered '1/N' to 'N/N' (make sure N is an actual; number, not the letter 'N'), that completes the basic structure of the target.; 4. The initial patch should add documentation, code owners and triple support in; clang and LLVM. The following patches add TableGen infrastructure to describe; the target and lower instructions to assembly. The final patch must show that; the target can lower correctly with extensive LIT tests (IR to MIR, MIR to; ASM, etc).; 5. Some patches may be approved before others, but only after *all* patches are; approved that the whole set can be merged in one go. This is to guarantee; that all changes are good as a single block.; 6. After the initial merge, the target community can stop numbering patches and; start working asynchronously on the target to complete support. They should; still seek review from those who helped them in the initial phase, to make; sure the progress is still consistent.; 7. Once all official requirements have been fulfilled (as above), the code owner; should request the target to be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:43759,patch,patches,43759,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['patch'],['patches']
Deployability," need account for uses after a return from the code which calls the; method returning an interior pointer. As an exception, no extension is required if the receiver is loaded directly; from a ``__strong`` object with :ref:`precise lifetime semantics; <arc.optimization.precise>`. .. admonition:: Rationale. Implicit autoreleases carry the risk of significantly inflating memory use,; so it's important to provide users a way of avoiding these autoreleases.; Tying this to precise lifetime semantics is ideal, as for local variables; this requires a very explicit annotation, which allows ARC to trust the user; with good cheer. .. _arc.misc.c-retainable:. C retainable pointer types; --------------------------. A type is a :arc-term:`C retainable pointer type` if it is a pointer to; (possibly qualified) ``void`` or a pointer to a (possibly qualifier) ``struct``; or ``class`` type. .. admonition:: Rationale. ARC does not manage pointers of CoreFoundation type (or any of the related; families of retainable C pointers which interoperate with Objective-C for; retain/release operation). In fact, ARC does not even know how to; distinguish these types from arbitrary C pointer types. The intent of this; concept is to filter out some obviously non-object types while leaving a hook; for later tightening if a means of exhaustively marking CF types is made; available. .. _arc.misc.c-retainable.audit:. Auditing of C retainable pointer interfaces; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. :when-revised:`[beginning Apple 4.0, LLVM 3.1]`. A C function may be marked with the ``cf_audited_transfer`` attribute to; express that, except as otherwise marked with attributes, it obeys the; parameter (consuming vs. non-consuming) and return (retained vs. non-retained); conventions for a C function of its name, namely:. * A parameter of C retainable pointer type is assumed to not be consumed; unless it is marked with the ``cf_consumed`` attribute, and; * A result of C retainable pointer type is as",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:102337,release,release,102337,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['release']
Deployability," need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:228514,release,release,228514,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability," new object-oriented implementation, written in C++,; of the popular MINUIT minimization package. These new version provides basically; all the functionality present in the old Fortran version, with almost equivalent; numerical accuracy and computational performances. Furthermore, it contains new; functionality, like the possibility to set single side parameter limits or the; FUMILI algorithm, which is an optimized method for least square and log likelihood; minimizations. The package has been originally developed by M. Winkler and F. James.; More information on the new C++ version can be found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides all the information needed for using directly (without ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:1067,integrat,integrate,1067,math/minuit2/doc/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md,1,['integrat'],['integrate']
Deployability," no effect without; :option:`--prefix`. .. option:: --print-imm-hex. Use hex format when printing immediate values in disassembly output (default). .. option:: -S, --source. When disassembling, display source interleaved with the disassembly. Implies; :option:`--disassemble`. .. option:: --show-all-symbols. Show all symbols during disassembly, even if multiple symbols are defined at; the same location. .. option:: --show-lma. Display the LMA column when dumping ELF section headers. Defaults to off; unless any section has different VMA and LMAs. .. option:: --start-address=<address>. When disassembling, only disassemble from the specified address. When printing relocations, only print the relocations patching offsets from at least ``address``. When printing symbols, only print symbols with a value of at least ``address``. .. option:: --stop-address=<address>. When disassembling, only disassemble up to, but not including the specified address. When printing relocations, only print the relocations patching offsets up to ``address``. When printing symbols, only print symbols with a value up to ``address``. .. option:: --symbolize-operands. When disassembling, symbolize a branch target operand to print a label instead of a real address. When printing a PC-relative global symbol reference, print it as an offset from the leading symbol. When a bb-address-map section is present (i.e., the object file is built with ``-fbasic-block-sections=labels``), labels are retrieved from that section instead. Only works with PowerPC objects or X86 linked images. Example:; A non-symbolized branch instruction with a local target and pc-relative memory access like. .. code-block:: none. cmp eax, dword ptr [rip + 4112]; jge 0x20117e <_start+0x25>. might become. .. code-block:: none. <L0>:; cmp eax, dword ptr <g>; jge	<L0>. .. option:: --triple=<string>. Target triple to disassemble for, see ``--version`` for available targets. .. option:: -w, --wide. Ignored for compatibility with GNU objdu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:7731,patch,patching,7731,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,1,['patch'],['patching']
Deployability," node.js implementation to produce identical output with normal browser; 18. Create necessary infrastructure for testing with 'puppeteer'; 19. Support inject of ES6 modules via '&inject=path.mjs'; 20. Using importmap for 'jsroot' in all major HTML files and in demos; 21. Implement `settings.CutAxisLabels` flag to remove labels which may exceed graphical range; 22. Let disable usage of TAxis custom labels via context menu; 23. Let configure default draw options via context menu, they can be preserved in the local storage; 24. Let save canvas as JSON file from context menu, object as JSON from inspector; 25. Upgrade three.js r162 -> r168, use r162 only in node.js because of ""gl"" module; 26. Create unified svg2pdf/jspdf ES6 modules, integrate in jsroot builds; 27. Let create multipage PDF document - in TWebCanvas batch mode; 28. Let add external links via `#url[link]{label}` syntax - including jsPDF support; 29. Support TAttMarker style with line width bigger than 1; 30. Internals - upgrade to eslint 9; 31. Internals - do not select pad (aka gPad) for objects drawing, always use assigned pad painter; 32. Fix - properly save zoomed ranges in drawingJSON(); 33. Fix - properly redraw TMultiGraph; 34. Fix - show empty bin in TProfile2D if it has entries #316; 35. Fix - unzooming on log scale was extending range forevever; 36. Fix - do not force style 8 for hist markers; 37. Fix - ensure minimal hist title height; 38. Fix - disable Bloom effects on Android TGeo displays; 39. Fix - handle reordering of fragments in multipart reply #319; 40. Fix - properly show non-zero entries #320; 41. Fix - display empty hist bin if fSumw2 not zero. ## Changes in 7.7.4; 1. Fix - TGraph Y range selection, do not cross 0; 2. Fix - correctly handle `#font[id]` in latex; 3. Fix - store canvas with embed geometry drawing; 4. Fix - upgrade rollup and import.meta polyfill. ## Changes in 7.7.3; 1. Fix - correctly handle in I/O empty std::map; 2. Fix - reading of small (<1KB) ROOT files; 3. Fix - ra",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:2177,upgrade,upgrade,2177,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['upgrade'],['upgrade']
Deployability," not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache. * The gfx942 can be configured as a number of smaller agents with each having; a single L2 shared by all CUs on the same agent, or as fewer (possibly one); larger agents with groups of CUs on each agent each sharing separate L2; caches.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel for its associated L2.; Therefore, the vector and scalar memory operations performed by wavefronts; executing with different L1 caches and the same L2 cache can be reordered; relative to each other.; * A ``s_waitcnt vmcnt(0)`` is required to ensure synchronization between; vector memory operations of different CUs. It ensures a previous vector; memory operation has completed before executing a subsequent vector memory; or LDS operation and so can be used to meet the requirements of acquire and; release.; * An L2 cache can be kept coherent with other L2 caches by using the MTYPE RW; (read-write) for memory local to the L2, and MTYPE NC (non-coherent) with; the PTE C-bit set for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by the PTE C-bit.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter.; * To ensure coherence of local memory writes of CUs with different L1 caches; in the same agent a ``buffer_wbl2`` is required. It does nothing if the; agent is configured to have a single L2, or will writeback dirty L2 cache; lines if configured to have multiple L2 caches.; * To ensure coherence of local memory wri",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:288177,release,release,288177,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability," not; found``. This means you need to tweak the -rpath linker flag. This method will add an absolute path to the rpath of all executables. That's; fine for local development. If you want to distribute the binaries you build; so that they can run on older systems, copy ``libstdc++.so.6`` into the; ``lib/`` directory. All of LLVM's shipping binaries have an rpath pointing at; ``$ORIGIN/../lib``, so they will find ``libstdc++.so.6`` there. Non-distributed; binaries don't have an rpath set and won't find ``libstdc++.so.6``. Pass; ``-DLLVM_LOCAL_RPATH=""$HOME/toolchains/lib64""`` to cmake to add an absolute; path to ``libstdc++.so.6`` as above. Since these binaries are not distributed,; having an absolute local path is fine for them. When you build Clang, you will need to give *it* access to modern C++; standard library in order to use it as your new host in part of a bootstrap.; There are two easy ways to do this, either build (and install) libc++ along; with Clang and then use it with the ``-stdlib=libc++`` compile and link flag,; or install Clang into the same prefix (``$HOME/toolchains`` above) as GCC.; Clang will look within its own prefix for libstdc++ and use it if found. You; can also add an explicit prefix for Clang to look in for a GCC toolchain with; the ``--gcc-toolchain=/opt/my/gcc/prefix`` flag, passing it to both compile and; link commands when using your just-built-Clang to bootstrap. .. _Getting Started with LLVM:. Getting Started with LLVM; =========================. The remainder of this guide is meant to get you up and running with LLVM and to; give you some basic information about the LLVM environment. The later sections of this guide describe the `general layout`_ of the LLVM; source tree, a `simple example`_ using the LLVM tool chain, and `links`_ to find; more information about LLVM or to get help via e-mail. Terminology and Notation; ------------------------. Throughout this manual, the following names are used to denote paths specific to; the loca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:19633,install,install,19633,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,2,['install'],['install']
Deployability," notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigms.; * Modifying a C stable API.; * Notifying users about a potentially disruptive change expected to be made in; a future release, such as removal of a deprecated feature. In this case, the; release note should be added to a ``Potentially Breaking Changes`` section of; the notes with sufficient information and examples to demonstrate the; potential disruption. Additionally, any new entries to this section should be; announced in the `Announcements <https://discourse.llvm.org/c/announce/>`_; channel on Discourse. See :ref:`breaking` for more details. Code reviewers are encouraged to request a release note if they think one is; warranted when performing a code review. Quality; -------. The minimum quality standards that any change must satisfy before being; committed to the main development branch are:. #. Code must adhere to the `LLVM Coding Standards <CodingStandards.html>`_. #. Code must compile cleanly (no errors, no warnings) on at least one platform. #. Bug fixes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judge",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:11813,release,release,11813,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['release'],['release']
Deployability," now has a ``__builtin_vectorelements()`` function that determines the number of elements in a vector.; For fixed-sized vectors, e.g., defined via ``__attribute__((vector_size(N)))`` or ARM NEON's vector types; (e.g., ``uint16x8_t``), this returns the constant number of elements at compile-time.; For scalable vectors, e.g., SVE or RISC-V V, the number of elements is not known at compile-time and is; determined at runtime.; * The ``__datasizeof`` keyword has been added. It is similar to ``sizeof``; except that it returns the size of a type ignoring tail padding.; * ``__builtin_classify_type()`` now classifies ``_BitInt`` values as the return value ``18``; and vector types as return value ``19``, to match GCC 14's behavior.; * The default value of `_MSC_VER` was raised from 1920 to 1933.; * Since MSVC 19.33 added undocumented attribute ``[[msvc::constexpr]]``, this release adds the attribute as well. * Added ``#pragma clang fp reciprocal``. * The version of Unicode used by Clang (primarily to parse identifiers) has been updated to 15.1. * Clang now defines macro ``__LLVM_INSTR_PROFILE_GENERATE`` when compiling with; PGO instrumentation profile generation, and ``__LLVM_INSTR_PROFILE_USE`` when; compiling with PGO profile use. New Compiler Flags; ------------------. * ``-fverify-intermediate-code`` and its complement ``-fno-verify-intermediate-code``.; Enables or disables verification of the generated LLVM IR.; Users can pass this to turn on extra verification to catch certain types of; compiler bugs at the cost of extra compile time.; Since enabling the verifier adds a non-trivial cost of a few percent impact on; build times, it's disabled by default, unless your LLVM distribution itself is; compiled with runtime checks enabled.; * ``-fkeep-system-includes`` modifies the behavior of the ``-E`` option,; preserving ``#include`` directives for ""system"" headers instead of copying; the preprocessed text to the output. This can greatly reduce the size of the; preprocessed ou",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:15050,update,updated,15050,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['update'],['updated']
Deployability," objects; 2D Graphics - ROOT's two dimensional graphics interface; 3D Graphics - ROOT's three dimensional graphics interface; Graphical User Interface - from basic GUI elements to ROOT's own, complete dialogs; Histograming - counting values, spectra, and drawing them; HTML - the documentation generator; Input/Ouput - storing and reading data; Mathemathics - everything one can use to calculate: minimizers, matrixes, FFT, and much more; Miscellaneous - things that didn't make it into the other groups: table ; Monte Carlo - monte carlo and physics simulation interfaces; Networking - network-related parts, e.g. protocols and authentication interfaces; PROOF - parallel ROOT facility; RooFit - a fitting library; RooStats - a collection of statistical tools ; SQL - database interfaces; TMVA - multivariate analysis tools; Trees - ROOT's unique container class and related utilities; Tutorials - ROOT's Tutorials. Binaries for all supported platforms are available at:. https://root.cern/releases/release-52800/. For more information, see:. http://root.cern.ch; The following people have contributed to this new version:; Alberto Annovi, INFN, TH1, ; Kevin Belasco, Princeton University, RooStats,; Bertrand Bellenot, CERN/SFT,; Rene Brun, CERN/SFT,; Philippe Canal, FNAL,; Olivier Couet, CERN/SFT,; Kyle Cranmer, NYU, RooStats,; Jason Detwiler, LBL, TClonesArray, ; Valeri Fine, BNL/STAR,; Fabrizio Furano, CERN/IT, ; Gerri Ganis, CERN/SFT,; Andrei Gheata, CERN/Alice,; Oleksandr Grebenyuk, GSI, TLatex, TPostScript, ; Christian Gumpert, CERN and University Dresden, TEfficiency ; Bill Heintzelman, UPENN, TTree, ; Andreas Hoecker, CERN/Atlas, TMVA, ; Pierre Juillot, IN2P3, PostScript, ; Folkert Koetsveld, Nijmegen, RooFit, ; Alex Koutsman, Nikhef, RooFit, ; Sven Kreiss, NYU, RooStats, ; Wim Lavrijsen, LBNL, PyRoot,; Sergei Linev, GSI,; Benno List, Desy, MathCore and MathMore, ; Anar Manafov, GSI, ; Mike Marino, TUM, pyroot/tutorials; Ramon Medrano Llamas, University of Oviedo, PROOF ; Biag",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v528/index.html:1605,release,releases,1605,doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v528/index.html,2,['release'],"['release-', 'releases']"
Deployability," of handling of default number of entries. A new const expression value: `TTree::kMaxEntries` has been introduced to; express the largest possible entry number in a `TTree`. This is used in; two main cases:. - as the default value for the requested number of entries a routine should be; applied to; for example this is used for `TTree::Draw` and `TTree::Process`.; Previously the default was only 1 billions entries, causing those routines to; end early in case of very large trees. - as the default value for the number of entries returned by TChain::GetEntriesFast.; The previous value was kBigNumber (set to 1234567890) and internally (but somewhat; inconsistently, see [ROOT-6885]) a larger value was used (named theBigNumber). Now; `TTree::kMaxEntries` is used throughout TChain. `TChain::kBigNumber` is deprecated and its value has been changed to be equal; to `TTree::kMaxEntries`. ### MakeSelector. `TTree::MakeSelector` has been update to generate a code skeleton based on the `TTreeReader` rather than the old style relying on numeric data members replacements for the user objects. The main advantage is the lifting of the problem related to the fact that the old style was using fixed size array to represent variable size collection. `TTree::MakeSelector` takes an option parameter that can be used to specify the branches that will have a data member.; - If option is `""=legacy""`, a pre-ROOT6 selector will be generated (data members and branch pointers instead of TTreeReaders).; - If option is empty, readers will be generated for each leaf.; - If option is ""@"", readers will be generated for the topmost branches.; - Individual branches can also be picked by their name:; - ""X"" generates readers for leaves of X.; - ""@X"" generates a reader for X as a whole.; - ""@X;Y"" generates a reader for X as a whole and also readers for the; leaves of Y.; - For further examples see the figure below. \image html ttree_makeselector_option_examples.png. The generated code in selector.h includes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:9448,update,update,9448,README/ReleaseNotes/v606/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md,1,['update'],['update']
Deployability," of itself, whether directly or via other; substitutions, should be avoided. It usually produces an infinitely recursive; definition that cannot be fully expanded. It does *not* define the; substitution in terms of its previous value, even when using ``REDEFINE:``. The relationship between the ``DEFINE:`` and ``REDEFINE:`` directive is; analogous to the relationship between a variable declaration and variable; assignment in many programming languages:. - ``DEFINE: %{name} = value``. This directive assigns the specified value to a new substitution whose; pattern is ``%{name}``, or it reports an error if there is already a; substitution whose pattern contains ``%{name}`` because that could produce; confusing expansions (e.g., a lit configuration file might define a; substitution with the pattern ``%{name}\[0\]``). The new substitution is; inserted at the start of the substitution list so that it will expand first.; Thus, its value can contain any substitution previously defined, whether in; the same test file or in a lit configuration file, and both will expand. - ``REDEFINE: %{name} = value``. This directive assigns the specified value to an existing substitution whose; pattern is ``%{name}``, or it reports an error if there are no substitutions; with that pattern or if there are multiple substitutions whose patterns; contain ``%{name}``. The substitution's current position in the substitution; list does not change so that expansion order relative to other existing; substitutions is preserved. The following properties apply to both the ``DEFINE:`` and ``REDEFINE:``; directives:. - **Substitution name**: In the directive, whitespace immediately before or; after ``%{name}`` is optional and discarded. ``%{name}`` must start with; ``%{``, it must end with ``}``, and the rest must start with a letter or; underscore and contain only alphanumeric characters, hyphens, underscores, and; colons. This syntax has a few advantages:. - It is impossible for ``%{name}`` to contain se",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:33107,configurat,configuration,33107,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['configurat'],['configuration']
Deployability," of objects to call ``release`` on later; an object can be; added to this pool by calling ``autorelease`` on it. Block pointers may be converted to type ``id``; block objects are laid out in a; way that makes them compatible with Objective-C objects. There is a builtin; class that all block objects are considered to be objects of; this class; implements ``retain`` by adjusting the reference count, not by calling; ``Block_copy``. .. _arc.meta.evolution:. Evolution; ---------. ARC is under continual evolution, and this document must be updated as the; language progresses. If a change increases the expressiveness of the language, for example by; lifting a restriction or by adding new syntax, the change will be annotated; with a revision marker, like so:. ARC applies to Objective-C pointer types, block pointer types, and; :when-revised:`[beginning Apple 8.0, LLVM 3.8]` :revision:`BPTRs declared; within` ``extern ""BCPL""`` blocks. For now, it is sensible to version this document by the releases of its sole; implementation (and its host project), clang. ""LLVM X.Y"" refers to an; open-source release of clang from the LLVM project. ""Apple X.Y"" refers to an; Apple-provided release of the Apple LLVM Compiler. Other organizations that; prepare their own, separately-versioned clang releases and wish to maintain; similar information in this document should send requests to cfe-dev. If a change decreases the expressiveness of the language, for example by; imposing a new restriction, this should be taken as an oversight in the; original specification and something to be avoided in all versions. Such; changes are generally to be avoided. .. _arc.general:. General; =======. Automatic Reference Counting implements automatic memory management for; Objective-C objects and blocks, freeing the programmer from the need to; explicitly insert retains and releases. It does not provide a cycle collector;; users must explicitly manage the lifetime of their objects, breaking cycles; manually or w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:8065,release,releases,8065,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['releases']
Deployability," of outstanding; bugs, and then number of regressions when determining whether or not to make a; release. The community values time based releases, so releases should not be delayed for; too long unless there are critical issues remaining. In most cases, the only; kind of bugs that are critical enough to block a release would be a major regression; from a previous release. Official Testing; ----------------. A few developers in the community have dedicated time to validate the release; candidates and volunteered to be the official release testers for each; architecture. These will be the ones testing, generating and uploading the official binaries; to the server, and will be the minimum tests *necessary* for the release to; proceed. This will obviously not cover all OSs and distributions, so additional community; validation is important. However, if community input is not reached before the; release is out, all bugs reported will have to go on the next stable release. The official release managers are:. * Even releases: Tom Stellard (tstellar@redhat.com); * Odd releases: Tobias Hieta (tobias@hieta.se). The official release testers are volunteered from the community and have; consistently validated and released binaries for their targets/OSs. To contact; them, you should post on the `Discourse forums (Project; Infrastructure - Release Testers). <https://discourse.llvm.org/c/infrastructure/release-testers/66>`_. The official testers list is in the file ``RELEASE_TESTERS.TXT``, in the ``LLVM``; repository. Community Testing; -----------------. Once all testing has been completed and appropriate bugs filed, the release; candidate tarballs are put on the website and the LLVM community is notified. We ask that all LLVM developers test the release in any the following ways:. #. Download ``llvm-X.Y``, ``llvm-test-X.Y``, and the appropriate ``clang``; binary. Build LLVM. Run ``make check`` and the full LLVM test suite (``make; TEST=nightly report``). #. Download ``llvm-X.Y``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:7398,release,release,7398,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['release'],['release']
Deployability," of the location storage specified by; SL. 2. ``DW_OP_LLVM_offset_uconst`` *New*. ``DW_OP_LLVM_offset_uconst`` has a single unsigned LEB128 integer operand; that represents a byte displacement B. The operation is equivalent to performing ``DW_OP_constu B;; DW_OP_LLVM_offset``. *This operation is supplied specifically to be able to encode more field; displacements in two bytes than can be done with* ``DW_OP_lit*;; DW_OP_LLVM_offset``\ *.*. .. note::. Should this be named ``DW_OP_LLVM_offset_uconst`` to match; ``DW_OP_plus_uconst``, or ``DW_OP_LLVM_offset_constu`` to match; ``DW_OP_constu``?. 3. ``DW_OP_LLVM_bit_offset`` *New*. ``DW_OP_LLVM_bit_offset`` pops two stack entries. The first must be an; integral type value that represents a bit displacement B. The second must be; a location description L. It adds the value of B to the bit offset of each single location description; SL of L, and pushes the updated L. It is an evaluation error if the updated bit offset of any SL is less than 0; or greater than or equal to the size of the location storage specified by; SL. 4. ``DW_OP_push_object_address``. ``DW_OP_push_object_address`` pushes the location description L of the; current object. *This object may correspond to an independent variable that is part of a; user presented expression that is being evaluated. The object location; description may be determined from the variable's own debugging information; entry or it may be a component of an array, structure, or class whose; address has been dynamically determined by an earlier step during user; expression evaluation.*. *This operation provides explicit functionality (especially for arrays; involving descriptors) that is analogous to the implicit push of the base; location description of a structure prior to evaluation of a*; ``DW_AT_data_member_location`` *to access a data member of a structure.*. .. note::. This operation could be removed and the object location description; specified as the initial stack as for ``DW_A",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:99720,update,updated,99720,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['update'],['updated']
Deployability," of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions on how to cross-compile with CMake. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to set up various cross compiling toolchains`` section; for a quick solution. Also see the `LLVM-related variables`_ section for variables used when; cross-compiling. Embedding LLVM in your project; ==============================. From LLVM 3.5 onwards the CMake build system exports LLVM libraries as; importable CMake targets. This means that clients of LLVM can now reliably use; CMake to develop their own LLVM-based projects against an installed version of; LLVM regardless of how it was built. Here is a simple example of a CMakeLists.txt file that imports the LLVM libraries; and uses them to build a simple application ``simple-tool``. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(SimpleProject). find_package(LLVM REQUIRED CONFIG). message(STATUS ""Found LLVM ${LLVM_PACKAGE_VERSION}""); message(STATUS ""Using LLVMConfig.cmake in: ${LLVM_DIR}""). # Set your project compile flags.; # E.g. if using the C++ header files; # you will need to enable C++11 support; # for your compiler. include_directories(${LLVM_INCLUDE_DIRS}); separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}). # Now build our tools; add_executable(simple-tool tool.cpp). # Find the libraries that correspond to the LLVM components; # that we wish to use; llvm_map_components_to_libnames(llvm_libs support core irreader). # Link against LLVM libra",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:41063,install,installed,41063,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['install'],['installed']
Deployability," on it. Block pointers may be converted to type ``id``; block objects are laid out in a; way that makes them compatible with Objective-C objects. There is a builtin; class that all block objects are considered to be objects of; this class; implements ``retain`` by adjusting the reference count, not by calling; ``Block_copy``. .. _arc.meta.evolution:. Evolution; ---------. ARC is under continual evolution, and this document must be updated as the; language progresses. If a change increases the expressiveness of the language, for example by; lifting a restriction or by adding new syntax, the change will be annotated; with a revision marker, like so:. ARC applies to Objective-C pointer types, block pointer types, and; :when-revised:`[beginning Apple 8.0, LLVM 3.8]` :revision:`BPTRs declared; within` ``extern ""BCPL""`` blocks. For now, it is sensible to version this document by the releases of its sole; implementation (and its host project), clang. ""LLVM X.Y"" refers to an; open-source release of clang from the LLVM project. ""Apple X.Y"" refers to an; Apple-provided release of the Apple LLVM Compiler. Other organizations that; prepare their own, separately-versioned clang releases and wish to maintain; similar information in this document should send requests to cfe-dev. If a change decreases the expressiveness of the language, for example by; imposing a new restriction, this should be taken as an oversight in the; original specification and something to be avoided in all versions. Such; changes are generally to be avoided. .. _arc.general:. General; =======. Automatic Reference Counting implements automatic memory management for; Objective-C objects and blocks, freeing the programmer from the need to; explicitly insert retains and releases. It does not provide a cycle collector;; users must explicitly manage the lifetime of their objects, breaking cycles; manually or with weak or unsafe references. ARC may be explicitly enabled with the compiler flag ``-fobjc-arc``. It ma",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:8170,release,release,8170,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['release']
Deployability," on-line profile merging. The runtime takes care of selecting a raw profile; from the pool, locking it, and updating it before the program exits. If N is; not specified (i.e the pattern is ""%m""), it's assumed that ``N = 1``. The; merge pool specifier can only occur once per filename pattern. * ""%c"" expands out to nothing, but enables a mode in which profile counter; updates are continuously synced to a file. This means that if the; instrumented program crashes, or is killed by a signal, perfect coverage; information can still be recovered. Continuous mode does not support value; profiling for PGO, and is only supported on Darwin at the moment. Support for; Linux may be mostly complete but requires testing, and support for Windows; may require more extensive changes: please get involved if you are interested; in porting this feature. .. code-block:: console. # Step 2: Run the program.; % LLVM_PROFILE_FILE=""foo.profraw"" ./foo. Note that continuous mode is also used on Fuchsia where it's the only supported; mode, but the implementation is different. The Darwin and Linux implementation; relies on padding and the ability to map a file over the existing memory; mapping which is generally only available on POSIX systems and isn't suitable; for other platforms. On Fuchsia, we rely on the ability to relocate counters at runtime using a; level of indirection. On every counter access, we add a bias to the counter; address. This bias is stored in ``__llvm_profile_counter_bias`` symbol that's; provided by the profile runtime and is initially set to zero, meaning no; relocation. The runtime can map the profile into memory at arbitrary locations,; and set bias to the offset between the original and the new counter location,; at which point every subsequent counter access will be to the new location,; which allows updating profile directly akin to the continuous mode. The advantage of this approach is that doesn't require any special OS support.; The disadvantage is the extra overh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst:3931,continuous,continuous,3931,interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,1,['continuous'],['continuous']
Deployability," one or more talks. You do; not have to stick to one format forever.; * Whatever format you choose, `LLVM Weekly <http://llvmweekly.org/>`_ is an; excellent topic starter: go through the 3-4 recent LLVM Weekly posts and; prepare a list of the most interesting/notable news and discuss them with the; group. Advertisement; -------------. * Try to advertise via similar meetups/user groups; * Advertise your meetup on the mailing lists (llvm-dev, cfe-dev, lldb-dev,; ...). Feel free to post to all of them, or at least to llvm-dev.; But as these mailing lists have high traffic and some LLVM developers are not; very active on them, you may reach more interested people using the mailing; feature from meetup.com.; * Advertise the meetup on Twitter and mention; `@llvmweekly <http://twitter.com/llvmweekly>`_ and; `@llvmorg <http://twitter.com/llvmorg>`_.; * Announce the next meetup in advance, and remind in one week or so. Tech talks; ----------. * It’s a great idea to have several talks scheduled for several upcoming; meetups to get the ball rolling.; * Keep looking for speakers far in advance, ideally you should have 2-3; speakers ready in the pipeline.; * Try to record the talks if possible. It adds visibility to the meetup and; just a good idea in general. Any modern smartphone or tablet should work, but; you can also get a camera. Though, it is recommended to get an external; microphone for better sound. Where to host the meetup?; -------------------------. * Look around for bars/café with projectors.; * Talk to tech companies in the area.; * Some co-working spaces provide their facilities for non-profit (i.e., you do; not charge attendees any fees) meetups.; * Ask nearby universities or university departments. How to pick the date?; ---------------------. * Make sure you do not clash with the similar meetups in the city (e.g.,; C++ user groups).; * Prefer not to have a meetup the same week when the other similar meetups; happen (e.g., it’s not a good idea to have LLVM meetu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MeetupGuidelines.rst:2303,rolling,rolling,2303,interpreter/llvm-project/llvm/docs/MeetupGuidelines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MeetupGuidelines.rst,1,['rolling'],['rolling']
Deployability," only inside correspondent pad; 3. Adjust of frame size when Y-axis exceed pad limits; 4. Correct values in tooltip for THStack; 5. Exclude drawing of markers from TGraph outside visible range; 6. Drawing of canvas without TFrame object; 7. Many other small bug fixes and improvements, thanks to Maximilian Dietrich. ### October 2014; 1. Add ""shortcut icon""; 2. Add demo of online THttpServer - shell script copies data from; running httpserver.C macro on Apache webserver; 3. Evaluate 'monitoring' parameter for online server like:; <http://localhost:8080/?monitoring=1000>; Parameter defines how often displayed objects should be updated.; 4. Implement 'opt' and 'opts' URL parameters for main page.; 5. Show progress with scripts loading in the browser window; 6. When one appends ""+"" to the filename, its content read completely with first I/O operation.; 7. Implement JS custom streamer for TCanvas, restore aspect ratio when drawing; 8. Major redesign of drawing classes. Resize and update of TCanvas are implemented.; All major draw functions working with HTML element id as first argument.; 9. Extract 3D drawings into separate JSRoot3DPainter.js script; 10. Use newest three.min.js (r68) for 3D drawings, solves problem with Firefox.; 11. Introduce generic list of draw functions for all supported classes.; 12. Add possibility to 'expand' normal objects in the hierarchy browser.; For instance, this gives access to single elements of canvas,; when whole canvas cannot be drawn.; 13. Correct usage of colors map, provided with TCanvas.; 14. Introduce JSROOT.redraw() function which is capable to create or update object drawing.; 15. In main index.htm page browser can be disabled (nobrowser parameter) and; page can be used to display only specified items from the file; 16. Add support of TPolyMarker3D in binary I/O. ### September 2014; 1. First try to handle resize of the browser,; for the moment works only with collapsible layout; 2. Also first try to interactively move separation l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:71092,update,update,71092,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['update'],['update']
Deployability," opened from within an environment with MSVC setup,; otherwise the compiler will not be accessible. When installing from source, the only requirement is a compiler that supports; C++14, this in order to build LLVM. With CPython on Linux or MacOS, probably by far the easiest way to install; cppyy, is through conda-forge on `Anaconda`_ (or `miniconda`_).; A Windows recipe for ``conda`` is not available yet, but is forthcoming, so; use ``pip`` for that platform for now (see below).; PyPI always has the authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:1390,install,install,1390,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,1,['install'],['install']
Deployability," option instead of the ``-fmodules`` option, or use ``-fmodule-map-file=`` option to explicitly specify the module map files to load. Compilation model; -----------------; The binary representation of modules is automatically generated by the compiler on an as-needed basis. When a module is imported (e.g., by an ``#include`` of one of the module's headers), the compiler will spawn a second instance of itself [#]_, with a fresh preprocessing context [#]_, to parse just the headers in that module. The resulting Abstract Syntax Tree (AST) is then persisted into the binary representation of the module that is then loaded into translation unit where the module import was encountered. The binary representation of modules is persisted in the *module cache*. Imports of a module will first query the module cache and, if a binary representation of the required module is already available, will load that representation directly. Thus, a module's headers will only be parsed once per language configuration, rather than once per translation unit that uses the module. Modules maintain references to each of the headers that were part of the module build. If any of those headers changes, or if any of the modules on which a module depends change, then the module will be (automatically) recompiled. The process should never require any user intervention. Command-line parameters; -----------------------; ``-fmodules``; Enable the modules feature. ``-fbuiltin-module-map``; Load the Clang builtins module map file. (Equivalent to ``-fmodule-map-file=<resource dir>/include/module.modulemap``). ``-fimplicit-module-maps``; Enable implicit search for module map files named ``module.modulemap`` and similar. This option is implied by ``-fmodules``. If this is disabled with ``-fno-implicit-module-maps``, module map files will only be loaded if they are explicitly specified via ``-fmodule-map-file`` or transitively used by another module map file. ``-fmodules-cache-path=<directory>``; Specify the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:13964,configurat,configuration,13964,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['configurat'],['configuration']
Deployability," or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible valu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:3206,install,installation,3206,proof/doc/confman/UsingVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md,1,['install'],['installation']
Deployability," or older BSDs sometimes have; extremely old versions of GCC. These steps attempt to help you upgrade you; compiler even on such a system. However, if at all possible, we encourage you; to use a recent version of a distribution with a modern system compiler that; meets these requirements. Note that it is tempting to install a prior; version of Clang and libc++ to be the host compiler, however libc++ was not; well tested or set up to build on Linux until relatively recently. As; a consequence, this guide suggests just using libstdc++ and a modern GCC as the; initial host in a bootstrap, and then using Clang (and potentially libc++). The first step is to get a recent GCC toolchain installed. The most common; distribution on which users have struggled with the version requirements is; Ubuntu Precise, 12.04 LTS. For this distribution, one easy option is to install; the `toolchain testing PPA`_ and use it to install a modern GCC. There is; a really nice discussions of this on the `ask ubuntu stack exchange`_ and a; `github gist`_ with updated commands. However, not all users can use PPAs and; there are many other distributions, so it may be necessary (or just useful, if; you're here you *are* doing compiler development after all) to build and install; GCC from source. It is also quite easy to do these days. .. _toolchain testing PPA:; https://launchpad.net/~ubuntu-toolchain-r/+archive/test; .. _ask ubuntu stack exchange:; https://askubuntu.com/questions/466651/how-do-i-use-the-latest-gcc-on-ubuntu/581497#58149; .. _github gist:; https://gist.github.com/application2000/73fd6f4bf1be6600a2cf9f56315a2d91. Easy steps for installing a specific version of GCC:. .. code-block:: console. % gcc_version=7.4.0; % wget https://ftp.gnu.org/gnu/gcc/gcc-${gcc_version}/gcc-${gcc_version}.tar.bz2; % wget https://ftp.gnu.org/gnu/gcc/gcc-${gcc_version}/gcc-${gcc_version}.tar.bz2.sig; % wget https://ftp.gnu.org/gnu/gnu-keyring.gpg; % signature_invalid=`gpg --verify --no-default-keyring --keyr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:16380,update,updated,16380,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['update'],['updated']
Deployability," own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-memory-model-gfx10-gfx11:. Memory Model GFX10-GFX11; ++++++++++++++++++++++++. For GFX10-GFX11:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple work-group processors (WGP).; * Each WGP has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same; WGP. In CU wavefront execution mode the wave",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:334491,release,release,334491,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability," own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-memory-model-gfx90a:. Memory Model GFX90A; +++++++++++++++++++. For GFX90A:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs. The exception is when in tgsplit execution mode; when the wavefronts may be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:233497,release,release,233497,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability," own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-memory-model-gfx942:. Memory Model GFX942; +++++++++++++++++++. For GFX942:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs. The exception is when in tgsplit execution mode; when the wavefronts may be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:283645,release,release,283645,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability," own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-trap-handler-abi:. Trap Handler ABI; ~~~~~~~~~~~~~~~~. For code objects generated by the AMDGPU backend for HSA [HSA]_ compatible; runtimes (see :ref:`amdgpu-os`), the runtime installs a trap handler that; supports the ``s_trap`` instruction. For usage see:. - :ref:`amdgpu-trap-handler-for-amdhsa-os-v2-table`; - :ref:`amdgpu-trap-handler-for-amdhsa-os-v3-table`; - :ref:`amdgpu-trap-handler-for-amdhsa-os-v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:379617,release,release,379617,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability," own vendor clones of LLVM and Clang (part of ROOT's trunk); on which it is based. This tool is the easiest way to build Cling for your favorite; platorm and bundle it into an installer. If you want to manually compile Cling; from source, go through the [README] of Cling or the build instructions [here]. [README]:https://github.com/root-project/cling/blob/master/README.md; [here]:https://root.cern/cling/cling_build_instructions/. Below is a list of platforms currently supported by CPT:; * Ubuntu and distros based on Debian - *DEB packages*; * Windows - *NSIS installers*; * Distros based on Red Hat Linux (Fedora/Scientific Linux CERN) - *RPM packages*; * Mac OS X - *Apple Disk Images*; * Virtually any UNIX-like platform which supports Bash - *Tarballs*. ### Requirements; Before using this tool, make sure you have the required packages installed on; your system. Detailed information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:1147,install,install,1147,interpreter/cling/tools/packaging/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md,1,['install'],['install']
Deployability," painter and checker objects are not written,; as well as the temporary current navigation properties: current node; path, point or direction. On the other hand, all objects belonging to; the geometrical hierarchy will always be written. The idea is to be able; to retrieve the geometry in a ready state, ignoring what the state; variables that can be always re-initialized. When the code is generated; for a given **`TGeoVolume`** in the geometry, just the branch starting; with that volume will be saved in the file. Executing the generated code; will create a geometry that has `MyVolume` as top volume. In this case,; only the materials/media/matrices used effectively in the `MyVolume`; branch are exported to file. Volumes can be made persistent in the same way the full geometry is.; Exporting is straightforward (module1, 2 are pointers to; **`TGeoVolume`** objects):. ``` {.cpp}; module1->Export(""file.root"");; // by default file is overwritten; module2->Export(""file.root"","""",""update"");; // to the same file; ```. Importing will append the volume to the current TGeoManager or will; create one:. ``` {.cpp}; TGeoManager *geom = new TGeoManager(""myGeom"", """");; TGeoVolume *top = geom->MakeBox(...);; geom->SetTopVolume(top);; //name of volume or key (depending on export usage); TGeoVolume *module1 = TGeoVolume::Import(""file.root"", ""MOD1"");; TGeoVolume *module2 = TGeoVolume::Import(""file.root"", ""MOD2"");; top->AddNode(module1, 1, new TGeoTranslation(0,0,100));; top->AddNode(module2, 1, new TGeoTranslation(0,0,-100));; // One should close oneself the geometry; geom->CloseGeometry();; ```. ### GDML. Few lines above word GDML was used. GDML stands for **G**eometry; **D**escription **M**arkup **L**anguage. It is an application-independent; geometry description format based on XML. It is mainly used for geometry; interchange between ROOT and Geant4 framework. More details about this; project can be found http://gdml.web.cern.ch. This feature; (importing/exporting from/to gdml file fo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:153370,update,update,153370,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['update'],['update']
Deployability," parent scope; containing the lambda signature. Possible values:. * ``LBI_Signature`` (in configuration: ``Signature``); Align lambda body relative to the lambda signature. This is the default. .. code-block:: c++. someMethod(; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; });. * ``LBI_OuterScope`` (in configuration: ``OuterScope``); For statements within block scope, align lambda body relative to the; indentation level of the outer scope the lambda signature resides in. .. code-block:: c++. someMethod(; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; });. someMethod(someOtherMethod(; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; }));. .. _Language:. **Language** (``LanguageKind``) :versionbadge:`clang-format 3.5` :ref:`¶ <Language>`; Language, this format style is targeted at. Possible values:. * ``LK_None`` (in configuration: ``None``); Do not use. * ``LK_Cpp`` (in configuration: ``Cpp``); Should be used for C, C++. * ``LK_CSharp`` (in configuration: ``CSharp``); Should be used for C#. * ``LK_Java`` (in configuration: ``Java``); Should be used for Java. * ``LK_JavaScript`` (in configuration: ``JavaScript``); Should be used for JavaScript. * ``LK_Json`` (in configuration: ``Json``); Should be used for JSON. * ``LK_ObjC`` (in configuration: ``ObjC``); Should be used for Objective-C, Objective-C++. * ``LK_Proto`` (in configuration: ``Proto``); Should be used for Protocol Buffers; (https://developers.google.com/protocol-buffers/). * ``LK_TableGen`` (in configuration: ``TableGen``); Should be used for TableGen code. * ``LK_TextProto`` (in configuration: ``TextProto``); Should be used for Protocol Buffer messages in text format; (https://developers.google.com/protocol-buffers/). * ``LK_Verilog`` (in configuration: ``Verilog``); Should be used for Verilog and SystemVerilog.; https://standards.ieee.org/ieee/1800/6700/; https://sci-hub.st/10.1109/IEEESTD.2018.8299595. .. _LineEnding:. **LineEnding** (``LineEndingStyle``) :versionbadge:`clan",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:83399,configurat,configuration,83399,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," performing the; store that is being; released. 3. buffer/global/flat_store; sc0=1 sc1=1; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic sc0=1; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being rele",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:310667,release,release,310667,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability," pi = make_unique<int>();; Borrow(pi);; if (smth) {; pi = make_unique<int>();; Borrow(pi);; }; }; ```. In the following example, the raw pointer is used to access the heap object; after the ownership has been transferred. ```c++; void UniqueOwnership3() {; int *pi = new int; // pi is Defined; if (...) {; Borrow(pi);; delete pi; // pi is Compatible; } else {; vector<unique_ptr<int>> v = {std::unique_ptr(pi)}; // pi is Compatible; print(*pi);; use(v);; }; // pi is Compatible; }; ```. We can refactor this code to use `unique_ptr`, however we would have to; introduce a non-owning pointer variable, since we can't use the moved-from; `unique_ptr` to access the object:. ```c++; void UniqueOwnership3() {; std::unique_ptr<int> pi = std::make_unique<int>();; if (...) {; Borrow(pi);; } else {; int *pi_non_owning = pi.get();; vector<unique_ptr<int>> v = {std::move(pi)};; print(*pi_non_owning);; use(v);; }; }; ```. If the original code didn't call `delete` at the very end of the function, then; our refactoring may change the point at which we run the destructor and release; memory. Specifically, if there is some user code after `delete`, then extending; the lifetime of the object until the end of the function may hold locks for; longer than necessary, introduce memory overhead etc. One solution is to always replace `delete` with a call to `reset()`, and then; perform another analysis that removes unnecessary `reset()` calls. ```c++; void AddedMemoryOverhead() {; HugeObject *ho = new HugeObject();; use(ho);; delete ho; // Release the large amount of memory quickly.; LongRunningFunction();; }; ```. This analysis will refuse to refactor code that mixes borrowed pointer values; and unique ownership. In the following code, `GetPtr()` returns a borrowed; pointer, which is assigned to `pi`. Then, `pi` is used to hold a uniquely-owned; pointer. We don't distinguish between these two assignments, and we want each; assignment to be paired with a corresponding sink; otherwise, we transitio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:24268,release,release,24268,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['release'],['release']
Deployability," placed after non-static imports. Possible values:. * ``SJSIO_Before`` (in configuration: ``Before``); Static imports are placed before non-static imports. .. code-block:: java. import static org.example.function1;. import org.example.ClassA;. * ``SJSIO_After`` (in configuration: ``After``); Static imports are placed after non-static imports. .. code-block:: java. import org.example.ClassA;. import static org.example.function1;. .. _SortUsingDeclarations:. **SortUsingDeclarations** (``SortUsingDeclarationsOptions``) :versionbadge:`clang-format 5` :ref:`¶ <SortUsingDeclarations>`; Controls if and how clang-format will sort using declarations. Possible values:. * ``SUD_Never`` (in configuration: ``Never``); Using declarations are never sorted. .. code-block:: c++. using std::chrono::duration_cast;; using std::move;; using boost::regex;; using boost::regex_constants::icase;; using std::string;. * ``SUD_Lexicographic`` (in configuration: ``Lexicographic``); Using declarations are sorted in the order defined as follows:; Split the strings by ""::"" and discard any initial empty strings. Sort; the lists of names lexicographically, and within those groups, names are; in case-insensitive lexicographic order. .. code-block:: c++. using boost::regex;; using boost::regex_constants::icase;; using std::chrono::duration_cast;; using std::move;; using std::string;. * ``SUD_LexicographicNumeric`` (in configuration: ``LexicographicNumeric``); Using declarations are sorted in the order defined as follows:; Split the strings by ""::"" and discard any initial empty strings. The; last element of each list is a non-namespace name; all others are; namespace names. Sort the lists of names lexicographically, where the; sort order of individual names is that all non-namespace names come; before all namespace names, and within those groups, names are in; case-insensitive lexicographic order. .. code-block:: c++. using boost::regex;; using boost::regex_constants::icase;; using std::move;; using st",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:111122,configurat,configuration,111122,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," pointer base types to be complete if they would be significant under the Microsoft ABI; -fcoverage-mapping Generate coverage mapping to enable code coverage analysis; -fcrash-diagnostics-dir=<dir>; Put crash-report files in <dir>; -fdebug-macro Emit macro debug information; -fdelayed-template-parsing; Parse templated function definitions at the end of the translation unit; -fdiagnostics-absolute-paths; Print absolute paths in diagnostics; -fdiagnostics-parseable-fixits; Print fix-its in machine parseable form; -flto=<value> Set LTO mode to either 'full' or 'thin'; -flto Enable LTO in 'full' mode; -fmerge-all-constants Allow merging of constants; -fms-compatibility-version=<value>; Dot-separated value representing the Microsoft compiler version; number to report in _MSC_VER (0 = don't define it; default is same value as installed cl.exe, or 1933); -fms-compatibility Enable full Microsoft Visual C++ compatibility; -fms-extensions Accept some non-standard constructs supported by the Microsoft compiler; -fmsc-version=<value> Microsoft compiler version number to report in _MSC_VER; (0 = don't define it; default is same value as installed cl.exe, or 1933); -fno-addrsig Don't emit an address-significance table; -fno-builtin-<value> Disable implicit builtin knowledge of a specific function; -fno-builtin Disable implicit builtin knowledge of functions; -fno-complete-member-pointers; Do not require member pointer base types to be complete if they would be significant under the Microsoft ABI; -fno-coverage-mapping Disable code coverage analysis; -fno-crash-diagnostics Disable auto-generation of preprocessed source files and a script for reproduction during a clang crash; -fno-debug-macro Do not emit macro debug information; -fno-delayed-template-parsing; Disable delayed template parsing; -fno-sanitize-address-poison-custom-array-cookie; Disable poisoning array cookies when using custom operator new[] in AddressSanitizer; -fno-sanitize-address-use-after-scope; Disable use-afte",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:179283,install,installed,179283,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['install'],['installed']
Deployability," pointers used as mutexes for @synchronized. void test(id x) {; if (!x); @synchronized(x) {} // warn: nil value used as mutex; }. void test() {; id y;; @synchronized(y) {} // warn: uninitialized value used as mutex; }. osx.cocoa.ClassRelease; (ObjC); Check for sending retain, release, or ; autorelease directly to a class. @interface MyClass : NSObject; @end. void test(void) {; [MyClass release]; // warn; }. osx.cocoa.Dealloc; (ObjC); Warn about Objective-C classes that lack a correct implementation; of -dealloc. @interface MyObject : NSObject {; id _myproperty;; }; @end. @implementation MyObject // warn: lacks 'dealloc'; @end. @interface MyObject : NSObject {}; @property(assign) id myproperty;; @end. @implementation MyObject // warn: does not send 'dealloc' to super; - (void)dealloc {; self.myproperty = 0;; }; @end. @interface MyObject : NSObject {; id _myproperty;; }; @property(retain) id myproperty;; @end. @implementation MyObject; @synthesize myproperty = _myproperty;; // warn: var was retained but wasn't released; - (void)dealloc {; [super dealloc];; }; @end. @interface MyObject : NSObject {; id _myproperty;; }; @property(assign) id myproperty;; @end. @implementation MyObject; @synthesize myproperty = _myproperty;; // warn: var wasn't retained but was released; - (void)dealloc {; [_myproperty release];; [super dealloc];; }; @end. osx.cocoa.IncompatibleMethodTypes; (ObjC); Check for an incompatible type signature when overriding an Objective-C method. @interface MyClass1 : NSObject; - (int)foo;; @end. @implementation MyClass1; - (int)foo { return 1; }; @end. @interface MyClass2 : MyClass1; - (float)foo;; @end. @implementation MyClass2; - (float)foo { return 1.0; } // warn; @end. osx.cocoa.MissingSuperCall; (ObjC); Warn about Objective-C methods that lack a necessary call to super. (Note: The; compiler now has a warning for methods annotated with objc_requires_super; attribute. The checker exists to check methods in the Cocoa frameworks; that haven't yet adopted t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/available_checks.html:15672,release,released,15672,interpreter/llvm-project/clang/www/analyzer/available_checks.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/available_checks.html,1,['release'],['released']
Deployability," prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:23571,update,update,23571,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['update'],['update']
Deployability," problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured differently, was thus also never a problem.; Or rather, the same problem exists for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can break them.; The two typical solutions are to either restrict the choice of Python; interpreter and version that are supported (common in HPC) or to provide; binaries (wheels) for a large range of different interpreters and versions; (as e.g. done for conda). In the case of cppyy, only CPython/CPyCppyy and PyPy/_cppyy (an internal; module) depend on the Python interpreter (see:; :ref:`Package Structure <package-structure>`).; The user-facing ``cppyy`` module is pure Python and the backend (Cling) is; Python-independent.; Most importantly, since all bindings are generated at run-time, there are no; extension modules to regenerate and/or recompile. Thus, the end-user only needs to rebuild/reinstall CPyCppyy for each relevant; version of Python (and nothing extra is needed for PyPy) to switch Python; versions and/or interpreter.; The rest of the software stack remains completely unchanged.; Only if Cling in cppyy's backend is updated",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:10701,install,installation,10701,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,3,"['install', 'patch', 'release']","['installation', 'patch', 'releases']"
Deployability," problems and produce a report. See the tool's in-source documentation for information on how to check your system or library headers. Future Directions; =================; Modules support is under active development, and there are many opportunities remaining to improve it. Here are a few ideas:. **Detect unused module imports**; Unlike with ``#include`` directives, it should be fairly simple to track whether a directly-imported module has ever been used. By doing so, Clang can emit ``unused import`` or ``unused #include`` diagnostics, including Fix-Its to remove the useless imports/includes. **Fix-Its for missing imports**; It's fairly common for one to make use of some API while writing code, only to get a compiler error about ""unknown type"" or ""no function named"" because the corresponding header has not been included. Clang can detect such cases and auto-import the required module, but should provide a Fix-It to add the import. **Improve modularize**; The modularize tool is both extremely important (for deployment) and extremely crude. It needs better UI, better detection of problems (especially for C++), and perhaps an assistant mode to help write module maps for you. Where To Learn More About Modules; =================================; The Clang source code provides additional information about modules:. ``clang/lib/Headers/module.modulemap``; Module map for Clang's compiler-specific header files. ``clang/test/Modules/``; Tests specifically related to modules functionality. ``clang/include/clang/Basic/Module.h``; The ``Module`` class in this header describes a module, and is used throughout the compiler to implement modules. ``clang/include/clang/Lex/ModuleMap.h``; The ``ModuleMap`` class in this header describes the full module map, consisting of all of the module map files that have been parsed, and providing facilities for looking up module maps and mapping between modules and headers (in both directions). PCHInternals_; Information about the serialized AST",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:56899,deploy,deployment,56899,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['deploy'],['deployment']
Deployability," process of ratification by providing an existence proof of an implementation, and simplifying efforts to validate the value of a proposed extension against large code bases. Experimental extensions are expected to either transition to ratified status, or be eventually removed. The decision on whether to accept an experimental extension is currently done on an entirely case by case basis; if you want to propose one, attending the bi-weekly RISC-V sync-up call is strongly advised. ``experimental-zacas``; LLVM implements the `1.0-rc1 draft specification <https://github.com/riscv/riscv-zacas/releases/tag/v1.0-rc1>`_. ``experimental-zfbfmin``, ``experimental-zvfbfmin``, ``experimental-zvfbfwma``; LLVM implements assembler support for the `1.0.0-rc2 specification <https://github.com/riscv/riscv-bfloat16/releases/tag/v59042fc71c31a9bcb2f1957621c960ed36fac401>`_. ``experimental-zicfilp``, ``experimental-zicfiss``; LLVM implements the `0.4 draft specification <https://github.com/riscv/riscv-cfi/releases/tag/v0.4.0>`__. ``experimental-ztso``; LLVM implements the `v0.1 proposed specification <https://github.com/riscv/riscv-isa-manual/releases/download/draft-20220723-10eea63/riscv-spec.pdf>`__ (see Chapter 25). The mapping from the C/C++ memory model to Ztso has not yet been ratified in any standards document. There are multiple possible mappings, and they are *not* mutually ABI compatible. The mapping LLVM implements is ABI compatible with the default WMO mapping. This mapping may change and there is *explicitly* no ABI stability offered while the extension remains in experimental status. User beware. ``experimental-zimop``; LLVM implements the `v0.1 proposed specification <https://github.com/riscv/riscv-isa-manual/blob/main/src/zimop.adoc>`__. ``experimental-zcmop``; LLVM implements the `v0.2 proposed specification <https://github.com/riscv/riscv-isa-manual/blob/main/src/zimop.adoc>`__. To use an experimental extension from `clang`, you must add `-menable-experimental-extens",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/RISCVUsage.rst:10876,release,releases,10876,interpreter/llvm-project/llvm/docs/RISCVUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/RISCVUsage.rst,1,['release'],['releases']
Deployability," processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the output list contained TProofOutputFile objects.; Move the creation and start of the idle timeout from the end; of SetupCommon to the end of CreateServer, so that the timeout is not; active during worker setup.; Make sure that the TProof instance on the client is invalidated after an idle timeout.; Fix an old issue with DeactivateWorker(""*"") (the session is; was terminated because no worker was active; this call coudl not be; used as intermediate step to select a small number of workers).; Consistently check both Proof.Sandbox and ProofLite.Sandbox for sandbox non-default location as done in TProofLite; Fix a problem with the registration of missing files in the; 'MissingFiles' list (files which could not be open on the workers were; not always added to the list). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:12568,update,update,12568,proof/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html,1,['update'],['update']
Deployability," project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/umbrella.git; git fetch umbrella. # Put myproj in local/myproj; echo ""myproj local/myproj"" > my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=local \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Note that if the umbrella has submodules to non-LLVM repositories,; ``zip-downstream-fork.py`` needs to know about them to be able to; rewrite commits. That is why the first step above is to fetch commits; from such repositories. With ``--update-tags`` the tool will migrate annotated tags pointing; to submodule commits that were inlined into the zipped history. If; the umbrella pulled in an upstream commit that happened to have a tag; pointing to it, that tag will be migrated, which is almost certainly; not what is wanted. The tag can always be moved back to its original; commit after rewriting, or the ``--update-tags`` option may be; discarded and any local tags would then be migrated manually. **Example 2: Nested sources layout**. The tool handles nested submodules (e.g. llvm is a submodule in; umbrella and clang is a submodule in l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:29279,update,update-tags,29279,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['update'],['update-tags']
Deployability," proxy docu](https://httpd.apache.org/docs/2.4/mod/mod_proxy_fcgi.html).; After restarting apache server one should be able to open address: `http://apache_host_name/root.app/`.; There are many ways to configure user authentication in Apache. Example of digest auth for FastCGI server:. ```; <Location ""/root.app/"">; AuthType Digest; AuthName ""root""; AuthDigestDomain ""/root.app/"" ""root""; AuthDigestProvider file; AuthUserFile ""/srv/auth/auth.txt""; Require valid-user; </Location>; ```. ### Configure fastcgi with lighttpd. An example of configuration file for **lighttpd** server is:. ```; server.modules += ( ""mod_fastcgi"" ); fastcgi.server = (; ""/root.app"" =>; (( ""host"" => ""192.168.1.11"",; ""port"" => 9000,; ""check-local"" => ""disable"",; ""docroot"" => ""/""; )); ); ```. Be aware, that with *lighttpd* one should specify IP address of the host, where ROOT application is running. Address of the ROOT application will be following: `http://lighttpd_host_name/root.app/`. Example of authorization configuration for FastCGI connection:. auth.require = ( ""/root.app"" => (; ""method"" => ""digest"",; ""realm"" => ""root"",; ""require"" => ""valid-user""; ) ). ## Integration with existing applications. In many practical cases no change of existing code is required. Opened files (and all objects inside), existing canvas and histograms are automatically scanned by the server and will be available to the users. If necessary, any object can be registered directly to the server with a [THttpServer::Register()](https://root.cern/doc/master/classTHttpServer.html#a73658daf379e87a4832fe9dc5c1483ed) call. Central point of integration - when and how THttpServer get access to data from a running application. By default it is done during the `gSystem->ProcessEvents()` call - THttpServer uses a synchronous timer which is activated every 100 ms. Such approach works perfectly when running macros in an interactive ROOT session. If an application runs in compiled code and does not contain `gSystem->ProcessEvents()` cal",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:12423,configurat,configuration,12423,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['configurat'],['configuration']
Deployability," ptr %ptr; %add = add i64 %val, 3; ret i64 %add. May require one byte of nop-padding:. .. code-block:: none. 0x00 callq _runtime; 0x05 nop <--- stack map address; 0x06 movq (%rdi), %rax; 0x07 addq $3, %rax; 0x0a popq %rdx; 0x0b ret <---- end of 8-byte shadow. Now, if the runtime needs to invalidate the compiled code, it may; patch 8 bytes of code at the stack map's address at follows:. .. code-block:: none. 0x00 callq _runtime; 0x05 movl $0xffff, %rax <--- patched code at stack map address; 0x0a callq *%rax <---- end of 8-byte shadow. This way, after the normal call to the runtime returns, the code will; execute a patched call to a special entry point that can rebuild a; stack frame from the values located by the stack map. '``llvm.experimental.patchpoint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.patchpoint.void(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...); declare i64; @llvm.experimental.patchpoint.i64(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.patchpoint.*``' intrinsics creates a function; call to the specified ``<target>`` and records the location of specified; values in the stack map. Operands:; """""""""""""""""". The first operand is an ID, the second operand is the number of bytes; reserved for the patchable region, the third operand is the target; address of a function (optionally null), and the fourth operand; specifies how many of the following variable operands are considered; function call arguments. The remaining variable number of operands are; the ``live values`` for which locations will be recorded in the stack; map. Semantics:; """""""""""""""""""". The patch point intrinsic generates a stack map. It also emits a; function call to the address specified by ``<target>`` if the address; is not a constant null. The function call and its arguments are; lowered according to the calling convention specified at the; intr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:7585,patch,patchpoint,7585,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['patch'],['patchpoint']
Deployability," publishing; mechanism. To prevent inclusion of a base-class into the compound editor, call:. ``` {.cpp}; void TGedEditor::ExcludeClassEditor(TClass* class, Bool_t recurse); ```. Pointer to the compound GED-editor is available in **`TGedFrame`**‘s; data-member:. ``` {.cpp}; TGedEditor *fGedEditor; ```. Ordering of base-class editor frames follows the order of the classes in; the class hierarchy. This order can be changed by modifying the value of; **`TGedFrame`**'s data member `Int_t fPriority`. The default value is; 50; smaller values move the frame towards to the top. This priority; should be set in the editor constructor. ## Drag and Drop. Drag and Drop support is introduced for Linux (via Xdnd - the drag and; drop protocol for X window system) and for Windows (via Clipboard).; Users can selects something in ROOT with a mouse press, drags it (moves; the mouse while keeping the mouse button pressed) and releases the mouse; button someplace else. When the button is released the selected data is; ""dropped"" at that location. This way, a histogram from an opened ROOT; file in the browser can be dragged to any **`TCanvas`**. ![](pictures/03000223.png). A script file from the browser can be dropped to a **`TGTextView`** or; TGTextEdit widget in **`TGTextEditor`**. On Linux, it is possible to drag objects between ROOT and an external; application. For example to drag a macro file from the ROOT browser to; the Kate editor. On Windows, drag and drop works only within a single; ROOT application (for the time being), but works also from Windows; Explorer to **`TCanvas`** ot to **`TGTextEdit`**. ### Drag and Drop Data Class. The Drag and Drop Cata class **`TDNDdata`** is used to describe and; handle the transferred data during an drag and drop operation. It; consists of:. `Atom_t fDataType`: atom describing the data type. `Atom_t fAction`: atom describing the action (copy, move, link);; currently, only copy is used. `void *fData`: actual data (buffer). `Int_t` `fDataLength`: ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md:107875,release,released,107875,documentation/users-guide/WritingGUI.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md,1,['release'],['released']
Deployability," quadrature integration method for multi dimensional functions. It is described in this paper; *Genz, A.A. Malik, An adaptive algorithm for numerical integration over an N-dimensional rectangular region, J. Comput. Appl. Math. 6 (1980) 295-302*.; It is part of the *MathCore* library.; The user can control the relative and absolute tolerance and the maximum allowed number of function evaluation. #### `ROOT::Math::GSLMCIntegrator`. It is a class for performing numerical integration of a multidimensional function. It uses the numerical integration algorithms of GSL, which reimplements the algorithms used; in the QUADPACK, a numerical integration package written in Fortran. Plain MC, MISER and VEGAS integration algorithms are supported for integration over finite (hypercubic) ranges.; For a detail description of the GSL methods visit the GSL users guide.; Specific configuration options (documented in the GSL user guide) for the `ROOT::Math::GSLMCIntegration` can be set directly in the class, or when using it via the `ROOT::Math::IntegratorMultiDim`; interface, can be defined using the `ROOT::Math::IntegratorMultiDimOptions`. ## Function Derivation. There are in ROOT only two classes to perform numerical derivation. One of them is in the MathCore library while the other is in the MathMore wrapping an integration function from the GSL library.; * RichardsonDerivator: Implements the Richardson method for numerical integration. It can calculate up to the third derivative of a function.; * GSLDerivator of *MathMore* based on GSL. ## Numerical Minimization. The algorithms provided by ROOT for numerical integration are implemented following the hierarchy shown in the next image. The left branch of classes are used for one dimensional minimization, while; the right one is used for multidimensional minimization. In the case of multidimensional minimization we have also the classes `TMinuitMinimizer` implemented using `TMinuit`, `TFumiliMinimizer`; implemented using `TFumili` for",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:62089,configurat,configuration,62089,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['configurat'],['configuration']
Deployability," queries; waiting on dependent symbols. .. _connection_to_orc_runtime:. Connection to the ORC Runtime; =============================. The ORC Runtime (currently under development) aims to provide runtime support; for advanced JIT features, including object format features that require; non-trivial action in the executor (e.g. running initializers, managing thread; local storage, registering with language runtimes, etc.). ORC Runtime support for object format features typically requires cooperation; between the runtime (which executes in the executor process) and JITLink (which; runs in the JIT process and can inspect LinkGraphs to determine what actions; must be taken in the executor). For example: Execution of MachO static; initializers in the ORC runtime is performed by the ``jit_dlopen`` function,; which calls back to the JIT process to ask for the list of address ranges of; ``__mod_init`` sections to walk. This list is collated by the; ``MachOPlatformPlugin``, which installs a pass to record this information for; each object as it is linked into the target. .. _constructing_linkgraphs:. Constructing LinkGraphs; =======================. Clients usually access and manipulate ``LinkGraph`` instances that were created; for them by an ``ObjectLinkingLayer`` instance, but they can be created manually:. #. By directly constructing and populating a ``LinkGraph`` instance. #. By using the ``createLinkGraph`` family of functions to create a; ``LinkGraph`` from an in-memory buffer containing an object file. This is how; ``ObjectLinkingLayer`` usually creates ``LinkGraphs``. #. ``createLinkGraph_<Object-Format>_<Architecture>`` can be used when; both the object format and architecture are known ahead of time. #. ``createLinkGraph_<Object-Format>`` can be used when the object format is; known ahead of time, but the architecture is not. In this case the; architecture will be determined by inspection of the object header. #. ``createLinkGraph`` can be used when neither the obj",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:33558,install,installs,33558,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['install'],['installs']
Deployability," recomputing data unless it needs to.; For this reason, passes are allowed to declare that they preserve (i.e., they; don't invalidate) an existing analysis if it's available. For example, a; simple constant folding pass would not modify the CFG, so it can't possibly; affect the results of dominator analysis. By default, all passes are assumed; to invalidate all others. The ``AnalysisUsage`` class provides several methods which are useful in; certain circumstances that are related to ``addPreserved``. In particular, the; ``setPreservesAll`` method can be called to indicate that the pass does not; modify the LLVM program at all (which is true for analyses), and the; ``setPreservesCFG`` method can be used by transformations that change; instructions in the program but do not modify the CFG or terminator; instructions. ``addPreserved`` is particularly useful for transformations like; ``BreakCriticalEdges``. This pass knows how to update a small set of loop and; dominator related analyses if they exist, so it can preserve them, despite the; fact that it hacks on the CFG. Example implementations of ``getAnalysisUsage``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. // This example modifies the program, but does not modify the CFG; void LICM::getAnalysisUsage(AnalysisUsage &AU) const {; AU.setPreservesCFG();; AU.addRequired<LoopInfoWrapperPass>();; }. .. _writing-an-llvm-pass-getAnalysis:. The ``getAnalysis<>`` and ``getAnalysisIfAvailable<>`` methods; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``Pass::getAnalysis<>`` method is automatically inherited by your class,; providing you with access to the passes that you declared that you required; with the :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. It takes a single template argument that specifies which pass class; you want, and returns a reference to that pass. For example:. .. code-block:: c++. bool LICM::runOnFunction(Function &F) {; LoopInfo &L",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:32282,update,update,32282,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['update'],['update']
Deployability," regular expression.; Mappings:. # Set a ""--target=thumbv7m-none-eabi"" flag if the regular expression matches; # any of the flags generated from the command line options.; # Match is a POSIX extended regular expression string.; - Match: --target=thumbv([7-9]|[1-9][0-9]+).*; # Flags is a list of one or more strings.; Flags: [--target=thumbv7m-none-eabi]. Design principles; =================. Stable interface; ----------------. ``multilib.yaml`` and ``-print-multi-flags-experimental`` are new; interfaces to Clang. In order for them to be usable over time and across LLVM; versions their interfaces should be stable.; The new multilib system will be considered experimental in LLVM 17, but in; LLVM 18 it will be stable. In particular this is important to which multilib; selection flags Clang generates from command line options. Once a flag is; generated by a released version of Clang it may be used in ``multilib.yaml``; files that exist independently of the LLVM release cycle, and therefore; ceasing to generate the flag would be a breaking change and should be; avoided. However, an exception is the normalization of ``-march``.; ``-march`` for Arm architectures contains a list of enabled and disabled; extensions and this list is likely to grow. Therefore ``-march`` flags are; unstable. Incomplete interface; --------------------. The new multilib system does multilib selection based on only a limited set of; command line options, and limits which flags can be used for multilib; selection. This is in order to avoid committing to too large an interface.; Later LLVM versions can add support for multilib selection from more command; line options as needed. Extensible; ----------. It is likely that the configuration format will need to evolve in future to; adapt to new requirements.; Using a format like YAML that supports key-value pairs helps here as it's; trivial to add new keys alongside existing ones. Backwards compatibility; -----------------------. New versions of Clang sh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst:9846,release,release,9846,interpreter/llvm-project/clang/docs/Multilib.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst,1,['release'],['release']
Deployability," relatedrepo_GetClosestMatch(REPO_NAME <repo> ORIGIN_PREFIX <originp> UPSTREAM_PREFIX <upstreamp>; # FETCHURL_VARIABLE <output_url> FETCHREF_VARIABLE <output_ref>); # Return the clone URL and head/tag of the closest match for `repo` (e.g. roottest), based on the; # current head name.; function(relatedrepo_GetClosestMatch); cmake_parse_arguments(_ """" ""REPO_NAME;ORIGIN_PREFIX;UPSTREAM_PREFIX;FETCHURL_VARIABLE;FETCHREF_VARIABLE"" """" ${ARGN}). set(${__FETCHURL_VARIABLE} ${__UPSTREAM_PREFIX}/${__REPO_NAME} PARENT_SCOPE). if(NOT IS_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/.git); set(${__FETCHREF_VARIABLE} v${ROOT_MAJOR_VERSION}-${ROOT_MINOR_VERSION}-${ROOT_PATCH_VERSION} PARENT_SCOPE); return(); endif(). execute_process(COMMAND ${GIT_EXECUTABLE} --git-dir=${CMAKE_CURRENT_SOURCE_DIR}/.git; rev-parse --abbrev-ref HEAD; OUTPUT_VARIABLE current_head OUTPUT_STRIP_TRAILING_WHITESPACE); set(${__FETCHREF_VARIABLE} ${current_head} PARENT_SCOPE). # `current_head` is a well-known branch, e.g. master, or v6-28-00-patches. Use the matching branch; # upstream as the fork repository may be out-of-sync; string(REGEX MATCH ""^(master|latest-stable|v[0-9]+-[0-9]+-[0-9]+(-patches)?)$"" known_head ${current_head}); if(NOT ""${known_head}"" STREQUAL """"); if(""${current_head}"" STREQUAL ""latest-stable""); # Resolve the 'latest-stable' branch to the latest merged head/tag; execute_process(COMMAND ${GIT_EXECUTABLE} --git-dir=${CMAKE_CURRENT_SOURCE_DIR}/.git; for-each-ref --points-at=latest-stable^2 --format=%\(refname:short\); OUTPUT_VARIABLE current_head OUTPUT_STRIP_TRAILING_WHITESPACE); set(${__FETCHREF_VARIABLE} ${current_head} PARENT_SCOPE); endif(); return(); endif(). # Otherwise, try to use a branch that matches `current_head` in the fork repository; execute_process(COMMAND ${GIT_EXECUTABLE} ls-remote --heads --tags; ${__ORIGIN_PREFIX}/${__REPO_NAME} ${current_head} OUTPUT_VARIABLE matching_refs); if(NOT ""${matching_refs}"" STREQUAL """"); set(${__FETCHURL_VARIABLE} ${__ORIGIN_PREFIX}/${__REPO_NAME} PAR",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt:4852,patch,patches,4852,CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt,1,['patch'],['patches']
Deployability," release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 3. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc1=1; store atomic release - system - global 1. buffer_wbl2 sc0=1 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:308781,release,release,308781,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability," release or release; candidate. You don't need to fix all the bugs in the test-suite, since they're; not necessarily meant to pass on all architectures all the time. This is; due to the nature of the result checking, which relies on direct comparison,; and most of the time, the failures are related to bad output checking, rather; than bad code generation. If the errors are in LLVM itself, please report every single regression found; as blocker, and all the other bugs as important, but not necessarily blocking; the release to proceed. They can be set as ""known failures"" and to be; fix on a future date. .. _pre-release-process:. Pre-Release Process; ===================. .. contents::; :local:. When the release process is announced on the mailing list, you should prepare; for the testing, by applying the same testing you'll do on the release; candidates, on the previous release. You should:. * Download the previous release sources from; https://llvm.org/releases/download.html. * Run the test-release.sh script on ``final`` mode (change ``-rc 1`` to; ``-final``). * Once all three stages are done, it'll test the final stage. * Using the ``Phase3/Release+Asserts/llvmCore-MAJ.MIN-final.install`` base,; run the test-suite. If the final phase's ``make check-all`` failed, it's a good idea to also test; the intermediate stages by going on the obj directory and running; ``make check-all`` to find if there's at least one stage that passes (helps; when reducing the error for bug report purposes). .. _release-process:. Release Process; ===============. .. contents::; :local:. When the Release Manager sends you the release candidate, download all sources,; unzip on the same directory (there will be sym-links from the appropriate places; to them), and run the release test as above. You should:. * Download the current candidate sources from where the release manager points; you (ex. https://llvm.org/pre-releases/3.3/rc1/). * Repeat the steps above with ``-rc 1``, ``-rc 2`` etc modes a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst:5140,release,release,5140,interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,1,['release'],['release']
Deployability," reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.; * When re-applying a reverted patch, the commit message should be updated to; indicate the problem that was addressed and how it was addressed. Obtaining Commit Access; -----------------------. We grant commit access to contributors with a track record of submitting high; quality patches. If you would like commit access, please send an email to; `Chris <mailto:clattner@llvm.org>`_ with your GitHub username. This is true; for former contributors with SVN access as well as new contributors. If; approved, a GitHub invitation will be sent to your GitHub account. In case you; don't get notification from GitHub, go to; `Invitation Link <https://github.com/orgs/llvm/invitation>`_ directly. Once; accept the invitation, you'll get commit access. Prior to obtaining commit access, it is common practice to request that; someone with commit access commits on your behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on a commits mailing list soon after the commit lands (e.g. llvm-commits_).; Note that these mailing lists are moderated, and it is not unusual for a large; commit to requi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:23072,patch,patches,23072,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['patch'],['patches']
Deployability," return a retainable object pointer type.; * ``copy`` methods must return a retainable object pointer type.; * ``mutableCopy`` methods must return a retainable object pointer type.; * ``new`` methods must return a retainable object pointer type.; * ``init`` methods must be instance methods and must return an Objective-C; pointer type. Additionally, a program is ill-formed if it declares or; contains a call to an ``init`` method whose return type is neither ``id`` nor; a pointer to a super-class or sub-class of the declaring class (if the method; was declared on a class) or the static receiver type of the call (if it was; declared on a protocol). .. admonition:: Rationale. There are a fair number of existing methods with ``init``-like selectors; which nonetheless don't follow the ``init`` conventions. Typically these; are either accidental naming collisions or helper methods called during; initialization. Because of the peculiar retain/release behavior of; ``init`` methods, it's very important not to treat these methods as; ``init`` methods if they aren't meant to be. It was felt that implicitly; defining these methods out of the family based on the exact relationship; between the return type and the declaring class would be much too subtle; and fragile. Therefore we identify a small number of legitimate-seeming; return types and call everything else an error. This serves the secondary; purpose of encouraging programmers not to accidentally give methods names; in the ``init`` family. Note that a method with an ``init``-family selector which returns a; non-Objective-C type (e.g. ``void``) is perfectly well-formed; it simply; isn't in the ``init`` family. A program is ill-formed if a method's declarations, implementations, and; overrides do not all have the same method family. .. _arc.family.attribute:. Explicit method family control; ------------------------------. A method may be annotated with the ``objc_method_family`` attribute to; precisely control which method f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:69164,release,release,69164,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['release']
Deployability," running on physical hosts: the recommended setup is in practice the same; as the ready-to-go Virtual Analysis Facility. If you want to use PROOF; on the clouds there is no configuration to go through. Setup a resource management system; ----------------------------------. Although PROOF on Demand can run on a cluster of nodes without using a; resource management system (using `pod-ssh`), it is recommended to setup a; dedicated one to benefit from the scheduling in a multiuser environment, or a; dedicated queue on an existing one. As there's a variety of resource management systems, this guide does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the latest CernVM-FS can be found; > [here](http://cernvm.cern.ch/portal/filesystem/techinformation). A brief step-by-step procedure to install CernVM-FS is hereby described. - Download and install the latest stable version from; [here](http://cernvm.cern.ch/portal/filesystem): pick one which is; appropriate to your operating system. You need the `cvmfs` package,; you *don't* need the `cvmfs-devel` or `cvmfs-server` ones. - As root user, run:. # cvmfs_config setup. - Start the `autofs` service: how to to this depends on your operating; system. On Ubuntu using Upstart:. # restart autofs. On RHEL-based or older Ubuntus:. # service autofs restart. - Prepare a `/etc/cvmfs/default.local` file (create it if it does not; exists) with the following configuration bits:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:1887,install,installed,1887,proof/doc/confman/ConfigProofPoD.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md,1,['install'],['installed']
Deployability," runtime does not need to consider this corner case. For example, a stack map with 8 byte shadow:. .. code-block:: llvm. call void @runtime(); call void (i64, i32, ...) @llvm.experimental.stackmap(i64 77, i32 8,; ptr %ptr); %val = load i64, ptr %ptr; %add = add i64 %val, 3; ret i64 %add. May require one byte of nop-padding:. .. code-block:: none. 0x00 callq _runtime; 0x05 nop <--- stack map address; 0x06 movq (%rdi), %rax; 0x07 addq $3, %rax; 0x0a popq %rdx; 0x0b ret <---- end of 8-byte shadow. Now, if the runtime needs to invalidate the compiled code, it may; patch 8 bytes of code at the stack map's address at follows:. .. code-block:: none. 0x00 callq _runtime; 0x05 movl $0xffff, %rax <--- patched code at stack map address; 0x0a callq *%rax <---- end of 8-byte shadow. This way, after the normal call to the runtime returns, the code will; execute a patched call to a special entry point that can rebuild a; stack frame from the values located by the stack map. '``llvm.experimental.patchpoint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.patchpoint.void(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...); declare i64; @llvm.experimental.patchpoint.i64(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.patchpoint.*``' intrinsics creates a function; call to the specified ``<target>`` and records the location of specified; values in the stack map. Operands:; """""""""""""""""". The first operand is an ID, the second operand is the number of bytes; reserved for the patchable region, the third operand is the target; address of a function (optionally null), and the fourth operand; specifies how many of the following variable operands are considered; function call arguments. The remaining variable number of operands are; the ``live values`` for which locations will be recorded in the stack; map. Semantics:; """""""""""""""""""". The patch point intrinsic ge",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:7345,patch,patchpoint,7345,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['patch'],['patchpoint']
Deployability," sample2[n2] containing the data; ; ROOT::Math::GoFTest goftest(n1, sample1, n2, sample2);; double pValueAD = goftest.AndersonDarling2SamplesTest();; double pValueKS = goftest.KolmogorovSmirnov2SamplesTest();; ; The class can return optionally also the test statistics instead of; the p value.; Example 2: perform a 1 sample test with a pre-defined; distribution starting from a data set sample[n]. ROOT::Math::GoFTest goftest(n, sample, ROOT::Math::GoFTest::kGaussian);; double pValueAD = goftest.AndersonDarlingTest();; double pValueKS = goftest.KolmogorovSmirnovTest();; . Example 3: perform a 1 sample test with a user-defined; distribution provided as cdf; ; ROOT::Math::Functor1D cdf_func(&ROOT::Math::landau_cdf);; ROOT::Math::GofTest goftest(n, sample, cdf_func, ROOT::Math::GoFTest::kCDF);; double pValueAD = goftest.AndersonDarlingTest();; . Example 4: perform a 1 sample test with a user-defined; distribution provided as pdf. Note that in this case to avoid; integration problems is sometimes recommended to give some; reasonable xmin and xmax values. xmin (and xmax) should however be; smaller (larger) than the minimum (maximum) data value.; ; ROOT::Math::Functor1D pdf_func(&ROOT::Math::landau_pdf);; double xmin = 5*TMath::Min_Element(n,sample);; double xmax = 5*TMath::Max_Element(n,sample);; ROOT::Math::GofTest goftest(n, sample, pdf_func, ROOT::Math::GoFTest::kPDF,xmin,xmax);; double pValueAD = goftest.AndersonDarlingTest();; . The tutorial math/goftest.C is an example on; how to use the ROOT::Math::GofTest class. New class TKDTreeBinning for binning multidimensional data.; ; The class implements multidimensional binning by constructing a; TKDTree inner structure form the data which is used as the bins.; The bins are retrieved as two double*, one for the minimum bin edges,; the other as the maximum bin edges. For one dimension one of these is enough; to correctly define the bins. The bin edges of d-dimensional data is a d-tet; of the bin's thresholds. For example if d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v528/index.html:2183,integrat,integration,2183,math/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v528/index.html,1,['integrat'],['integration']
Deployability," scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:256891,release,release,256891,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability," script ``llvm/utils/git/sync-release-repo.sh``. Then add a comment to the issue stating that the fix has been merged along with; the git hashes from the release branch. Add the release:merged label to the issue; and close it. Release Patch Rules; -------------------. Below are the rules regarding patching the release branch:. #. Patches applied to the release branch may only be applied by the release; manager, the official release testers or the code owners with approval from; the release manager. #. Release managers are encouraged, but not required, to get approval from code; owners before approving patches. If there is no code owner or the code owner; is unreachable then release managers can ask approval from patch reviewers or; other developers active in that area. #. *Before RC1* Patches should be limited to bug fixes, important optimization; improvements, or completion of features that were started before the branch; was created. As with all phases, release managers and code owners can reject; patches that are deemed too invasive. #. *Before RC2* Patches should be limited to bug fixes or backend specific; improvements that are determined to be very safe. #. *Before RC3/Final Major Release* Patches should be limited to critical; bugs or regressions. #. *Bug fix releases* Patches should be limited to bug fixes or very safe; and critical performance improvements. Patches must maintain both API and; ABI compatibility with the previous major release. Release Final Tasks; -------------------. The final stages of the release process involves tagging the ""final"" release; branch, updating documentation that refers to the release, and updating the; demo page. Update Documentation; ^^^^^^^^^^^^^^^^^^^^. Review the documentation in the release branch and ensure that it is up; to date. The ""Release Notes"" must be updated to reflect new features, bug; fixes, new known issues, and changes in the list of supported platforms.; The ""Getting Started Guide"" should be updated to re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:13187,release,release,13187,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,2,"['patch', 'release']","['patches', 'release']"
Deployability," section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers will now diagnose the use of deprecated interfaces in user code.; - Added new 'builtin_vc' option to bundle a version of Vc within ROOT.; The default is OFF, however if the Vc package is not found in the system the option is switched to; ON if the option 'vc' option is ON.; - Many improvements (provided by Mattias Ellert):; - Build RFIO using dpm libraries if castor libraries are not available; - Add missing glib header path in GFAL module for version > 2; - Search also for globus libraries wouthout the flavour in the name; - Add missing io/hdfs/CMakeLists.txt; - net/globusauth has no installed headers - remove ROOT_INSTALL_HEADERS(); - Add missing pieces to the cmake config that are built by configure: bin/pq2, bin/rootd, bin/xpdtest, initd and xinitd start-up scripts; - Only link to libgfortranbegin.a when it is provided by the compiler; - Don't remove -Wall without also removing -Werror=*; - Don't overwrite the initial value of CMAKE_Fortran_FLAGS. Inconsistent case variant of CMAKE_Fortran_FLAGS; - Use the same sonames in cmake as in configure; - Allow building for ppc64 as well as ppc64le; - Add build instructions for 32 bit ARM; - Add build instructions for System Z (s390 and s390x); - Make sure that the roots wrapper can be executed; - Move gl2ps.h to its own subdir; - Added new 'builtin-unuran' option (provided by Mattias Ellert); - Added new 'builtin-gl2ps' option (provided by Mattias Ellert); - Added new 'macos_native' option (only for MacOS) to disable looking for binaries, libraires and headers for dependent; packages at locations other than native MacOS installations. Needed when wanting to ignore packages from Fink, Brew or Ports.; - Added new 'cuda' option to enable looking for CUDA in the system. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:29928,install,installations,29928,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['install'],['installations']
Deployability," see more of that later.; With this tool you ca use any library or R package wich allows you to access a big amount of benefits to make statistical analysis.; ROOTR also has a R events processing system, which allows to use the R graphical system from `C++`. ## INSTALLATION; To install ROOTR please read first. - [https://root.cern.ch/building-root](https://root.cern.ch/building-root); - [https://root.cern.ch/build-prerequisites](https://root.cern.ch/build-prerequisites). ### COMPILING ROOTR ON MAC WITH CMAKE:; **NOTE:** Mac OSX Yosemite last xcode and without macports. **Prerequisites**. - xcode; - [xquartz](http://xquartz.macosforge.org/); - [R last version](https://www.r-project.org); - [cmake](https://cmake.org/download/). To compile with cmake added into ~/.profile. ~~~{.sh}; export PATH=$PATH:/Applications/CMake.app/Contents/bin/; ~~~; and. ~~~{.sh}; source ~/.profile; ~~~. Install needed R packages, open R and in the prompt type. ~~~{.sh}; install.packages(c('Rcpp','RInside')); ~~~; select a mirror and install. Install the next additional packages for R TMVA interface. ~~~{.sh}; install.packages(c('C50','RSNNS','e1071','xgboost')); ~~~. Download code from git repo. ~~~{.sh}; git clone http://root.cern.ch/git/root.git; ~~~. To compile ROOTR lets to create a compilation directory and to activate it use cmake -Dr=ON .. ~~~{.sh}; mkdir compile; cd compile; cmake -Dr=ON ..; make -j 5; ~~~. ### Compiling ROOTR on Gnu/Linux with CMake:; **NOTE:** Tested on Gnu/Linux Debian Jessie with gcc 4.9. **Prerequisities**; install; (For debian-based distros). ~~~{.sh}; apt-get install r-base r-base-dev; ~~~; Install needed R packages, open R and in the prompt type. ~~~{.sh}; install.packages(c('Rcpp','RInside')); ~~~; select a mirror and install. Install the next additional packages for R TMVA interface. ~~~{.sh}; install.packages(c('C50','RSNNS','e1071','xgboost')); ~~~. Download code from git repo. ~~~{.sh}; git clone http://root.cern.ch/git/root.git; ~~~. To compile ROOTR l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:1961,install,install,1961,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['install'],['install']
Deployability," select the option `Delete branch` to delete the branch; from your fork. You can also merge via the CLI by switching to your branch locally and run:. ::. gh pr merge --squash --delete-branch. If you observe an error message from the above informing you that your pull; request is not mergeable, then that is likely because upstream has been; modified since your pull request was authored in a way that now results in a; merge conflict. You must first resolve this merge conflict in order to merge; your pull request. In order to do that:. ::. git fetch upstream; git rebase upstream/main. Then fix the source files causing merge conflicts and make sure to rebuild and; retest the result. Then:. ::. git add <files with resolved merge conflicts>; git rebase --continue. Finally, you'll need to force push to your branch one more time before you can; merge:. ::. git push -f; gh pr merge --squash --delete-branch. This force push may ask if you intend to push hundreds, or potentially; thousands of patches (depending on how long it's been since your pull request; was initially authored vs. when you intended to merge it). Since you're pushing; to a branch in your fork, this is ok and expected. Github's UI for the pull; request will understand that you're rebasing just your patches, and display; this result correctly with a note that a force push did occur. Checking out another PR locally; -------------------------------; Sometimes you want to review another person's PR on your local machine to run; tests or inspect code in your preferred editor. This is easily done with the; CLI:. ::. gh pr checkout <PR Number>. This is also possible with the web interface and the normal git command line; tools, but the process is a bit more complicated. See GitHub's; `documentation <https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/reviewing-changes-in-pull-requests/checking-out-pull-requests-locally?platform=linux&tool=webui#modifying-an-inactive-pull-request-locally>`_; on ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitHub.rst:6540,patch,patches,6540,interpreter/llvm-project/llvm/docs/GitHub.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitHub.rst,1,['patch'],['patches']
Deployability," setting called `ROOT.ZipMode` is now unused and ignored.; Instead, use `Root.CompressionAlgorithm` which sets the compression algorithm according to the values of [ECompression](https://root.cern/doc/master/Compression_8h.html#a0a7df9754a3b7be2b437f357254a771c):. * 0: use the default value of `R__ZipMode` (currently selecting ZLIB); * 1: use ZLIB (the default until 6.12 and from 6.16); * 2: use LZMA; * 3: legacy, please don't use; * 4: LZ4. ### TRef. * Improve thread scalability of `TRef`. Creating and looking up a lot of `TRef` from the same `processID` now has practically perfect weak scaling. ### Parallelism; * Upgrade the built-in TBB version to 2019_U1. ### Type System; * Upgrade the `TClass::GetMissingDictionaries` method to support `std::unique_ptr`, `std::array` and `std::tuple` without getting trapped in the internal STL implementation details. ## I/O Libraries. * To allow for increase run-time performance and increase thread scalability the override ability of `TFile::GetStreamerInfoList` is replaced by an override of `TFile::GetStreamerInfoListImp` with updated return type and arguments. If a class override `TFile::GetStreamerInfoList` you will now see a compilation error like:. ```; /opt/build/root_builds/rootcling.cmake/include/TSQLFile.h:225:19: error: declaration of 'GetStreamerInfoList' overrides a 'final' function; virtual TList *GetStreamerInfoList();; ^; /opt/build/root_builds/rootcling.cmake/include/TFile.h:231:24: note: overridden virtual function is here; virtual TList *GetStreamerInfoList() final; // Note: to override behavior, please override GetStreamerInfoListImpl; ^; ```. Instead you need to override the protected method:. ```; InfoListRet GetStreamerInfoListImpl(bool lookupSICache);; ```. which can be implemented as. ```; InfoListRet DerivedClass::GetStreamerInfoListImpl(bool /*lookupSICache*/) {; ROOT::Internal::RConcurrentHashColl::HashValue hash;; TList *infolist = nullptr;; //; // Body of the former Derived::GetStreamerInfoList with ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md:4133,update,updated,4133,README/ReleaseNotes/v616/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md,1,['update'],['updated']
Deployability," severity is used for; diagnostics indicating the program is never acceptable under any circumstances.; When an error is emitted, the AST for the input code may not be fully built.; The ``EXTENSION`` and ``EXTWARN`` severities are used for extensions to the; language that Clang accepts. This means that Clang fully understands and can; represent them in the AST, but we produce diagnostics to tell the user their; code is non-portable. The difference is that the former are ignored by; default, and the later warn by default. The ``WARNING`` severity is used for; constructs that are valid in the currently selected source language but that; are dubious in some way. The ``REMARK`` severity provides generic information; about the compilation that is not necessarily related to any dubious code. The; ``NOTE`` level is used to staple more information onto previous diagnostics. These *severities* are mapped into a smaller set (the ``Diagnostic::Level``; enum, {``Ignored``, ``Note``, ``Remark``, ``Warning``, ``Error``, ``Fatal``}) of; output; *levels* by the diagnostics subsystem based on various configuration options.; Clang internally supports a fully fine grained mapping mechanism that allows; you to map almost any diagnostic to the output level that you want. The only; diagnostics that cannot be mapped are ``NOTE``\ s, which always follow the; severity of the previously emitted diagnostic and ``ERROR``\ s, which can only; be mapped to ``Fatal`` (it is not possible to turn an error into a warning, for; example). Diagnostic mappings are used in many ways. For example, if the user specifies; ``-pedantic``, ``EXTENSION`` maps to ``Warning``, if they specify; ``-pedantic-errors``, it turns into ``Error``. This is used to implement; options like ``-Wunused_macros``, ``-Wundef`` etc. Mapping to ``Fatal`` should only be used for diagnostics that are considered so; severe that error recovery won't be able to recover sensibly from them (thus; spewing a ton of bogus errors). One example",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:5225,configurat,configuration,5225,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['configurat'],['configuration']
Deployability," shouldn't be; happening. Because the code may have been generated for a remote target,; the client should be given a chance to re-map the section addresses before; relocations are applied. It is possible to apply relocations multiple; times, but in the case where addresses are to be re-mapped, this first; application is wasted effort.]. Address Remapping; =================. At any time after initial code has been generated and before; finalizeObject is called, the client can remap the address of sections in; the object. Typically this is done because the code was generated for an; external process and is being mapped into that process' address space.; The client remaps the section address by calling MCJIT::mapSectionAddress.; This should happen before the section memory is copied to its new; location. When MCJIT::mapSectionAddress is called, MCJIT passes the call on to; RuntimeDyldImpl (via its Dyld member). RuntimeDyldImpl stores the new; address in an internal data structure but does not update the code at this; time, since other sections are likely to change. When the client is finished remapping section addresses, it will call; MCJIT::finalizeObject to complete the remapping process. Final Preparations; ==================. When MCJIT::finalizeObject is called, MCJIT calls; RuntimeDyld::resolveRelocations. This function will attempt to locate any; external symbols and then apply all relocations for the object. External symbols are resolved by calling the memory manager's; getPointerToNamedFunction method. The memory manager will return the; address of the requested symbol in the target address space. (Note, this; may not be a valid pointer in the host process.) RuntimeDyld will then; iterate through the list of relocations it has stored which are associated; with this symbol and invoke the resolveRelocation method which, through an; format-specific implementation, will apply the relocation to the loaded; section memory. Next, RuntimeDyld::resolveRelocations itera",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst:6586,update,update,6586,interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,1,['update'],['update']
Deployability," significant impact on users and/or downstream code bases,; reviewers can request an RFC achieving consensus before proceeding with code; review. That having been said, posting initial patches can help with; discussions on an RFC. Code-Review Workflow; ====================. Code review can be an iterative process, which continues until the patch is; ready to be committed. Specifically, once a patch is sent out for review, it; needs an explicit approval before it is committed. Do not assume silent; approval, or solicit objections to a patch with a deadline. Acknowledge All Reviewer Feedback; ---------------------------------. All comments by reviewers should be acknowledged by the patch author. It is; generally expected that suggested changes will be incorporated into a future; revision of the patch unless the author and/or other reviewers can articulate a; good reason to do otherwise (and then the reviewers must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:5270,patch,patch,5270,interpreter/llvm-project/llvm/docs/CodeReview.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst,3,"['patch', 'update']","['patch', 'updated']"
Deployability," simpler. First of all, a simple observation is that if one needs to see all; the outside users, they can just iterate over all the (loop closing); PHI nodes in the exit blocks (the alternative would be to; scan the def-use chain [#def-use-chain]_ of all instructions in the loop). Then, consider for example; :ref:`simple-loop-unswitch <passes-simple-loop-unswitch>` ing the loop above.; Because it is in LCSSA form, we know that any value defined inside of; the loop will be used either only inside the loop or in a loop closing; PHI node. In this case, the only loop closing PHI node is X4.; This means that we can just copy the loop and change the X4; accordingly, like so:. .. code-block:: C. c = ...;; if (c) {; for (...) {; if (true); X1 = ...; else; X2 = ...; X3 = phi(X1, X2);; }; } else {; for (...) {; if (false); X1' = ...; else; X2' = ...; X3' = phi(X1', X2');; }; }; X4 = phi(X3, X3'). Now, all uses of X4 will get the updated value (in general,; if a loop is in LCSSA form, in any loop transformation,; we only need to update the loop closing PHI nodes for the changes; to take effect). If we did not have Loop Closed SSA form, it means that X3 could; possibly be used outside the loop. So, we would have to introduce the; X4 (which is the new X3) and replace all uses of X3 with that.; However, we should note that because LLVM keeps a def-use chain; [#def-use-chain]_ for each Value, we wouldn't need; to perform data-flow analysis to find and replace all the uses; (there is even a utility function, replaceAllUsesWith(),; that performs this transformation by iterating the def-use chain). Another important advantage is that the behavior of all uses; of an induction variable is the same. Without this, you need to; distinguish the case when the variable is used outside of; the loop it is defined in, for example:. .. code-block:: C. for (i = 0; i < 100; i++) {; for (j = 0; j < 100; j++) {; k = i + j;; use(k); // use 1; }; use(k); // use 2; }. Looking from the outer loop with t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst:13869,update,updated,13869,interpreter/llvm-project/llvm/docs/LoopTerminology.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst,2,['update'],"['update', 'updated']"
Deployability," site-packages>; $ make -j <N> install. where the ``cmake`` command needs to be given the full path to; `site-packages/cppyy_backend` in the virtual environment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to pypi.org and creating a local ""clean"" build environment from the; cached or remote wheels.; Instead, by skipping PEP 517, the local installation will be used.; This is imperative if there was a change in public headers or if the version; of ``cppyy-cling`` was locally updated and is thus not available on PyPI. Upgrading ``CPyCppyy`` (if on CPython; it's not needed for PyPy) and ``cppyy``; is very similar::. $ git clone https://github.com/wlav/CPyCppyy.git; $ cd CPyCppyy; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Just like ``cppyy-cling``, ``CPyCppyy`` has ``cmake`` scripts which are the; recommended way for development, as incremental builds are faster::. $ mkdir build; $ cmake ../CPyCppyy; $ make -j <N>. then simply point the ``PYTHONPATH`` envar to the `build` directory above to; pick up the local `cppyy.so` module. Finally, the top-level package ``cppyy``::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy; $ python -m pip install . --upgrade --no-deps. Please see the `pip documentation`_ for more options, such as developer mode. .. _`setuptools`: https://setuptools.readthed",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:5790,install,installation,5790,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,1,['install'],['installation']
Deployability," specification per language and each delimiter; and enclosing function should not occur in multiple specifications. To configure this in the .clang-format file, use:. .. code-block:: yaml. RawStringFormats:; - Language: TextProto; Delimiters:; - 'pb'; - 'proto'; EnclosingFunctions:; - 'PARSE_TEXT_PROTO'; BasedOnStyle: google; - Language: Cpp; Delimiters:; - 'cc'; - 'cpp'; BasedOnStyle: llvm; CanonicalDelimiter: 'cc'. .. _ReferenceAlignment:. **ReferenceAlignment** (``ReferenceAlignmentStyle``) :versionbadge:`clang-format 13` :ref:`¶ <ReferenceAlignment>`; Reference alignment style (overrides ``PointerAlignment`` for; references). Possible values:. * ``RAS_Pointer`` (in configuration: ``Pointer``); Align reference like ``PointerAlignment``. * ``RAS_Left`` (in configuration: ``Left``); Align reference to the left. .. code-block:: c++. int& a;. * ``RAS_Right`` (in configuration: ``Right``); Align reference to the right. .. code-block:: c++. int &a;. * ``RAS_Middle`` (in configuration: ``Middle``); Align reference in the middle. .. code-block:: c++. int & a;. .. _ReflowComments:. **ReflowComments** (``Boolean``) :versionbadge:`clang-format 3.8` :ref:`¶ <ReflowComments>`; If ``true``, clang-format will attempt to re-flow comments. That is it; will touch a comment and *reflow* long comments into new lines, trying to; obey the ``ColumnLimit``. .. code-block:: c++. false:; // veryVeryVeryVeryVeryVeryVeryVeryVeryVeryVeryLongComment with plenty of information; /* second veryVeryVeryVeryVeryVeryVeryVeryVeryVeryVeryLongComment with plenty of information */. true:; // veryVeryVeryVeryVeryVeryVeryVeryVeryVeryVeryLongComment with plenty of; // information; /* second veryVeryVeryVeryVeryVeryVeryVeryVeryVeryVeryLongComment with plenty of; * information */. .. _RemoveBracesLLVM:. **RemoveBracesLLVM** (``Boolean``) :versionbadge:`clang-format 14` :ref:`¶ <RemoveBracesLLVM>`; Remove optional braces of control statements (``if``, ``else``, ``for``,; and ``while``) in C++ according to th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:100252,configurat,configuration,100252,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," specify the delay between the last; image and the fist image in case of infinite loop. (Fernando Hueso González; <f.gonzalez@hzdr.de>). ### TPadPainter; - Offer 0 as line width option. Useful to make a line invisible. ### TPad. - In `TPad::ShowGuidelines` the number of guide lines is limited to 15. Above; that they become useless.; - Print a warning if one of the pad limit is a NaN.; - Fix https://sft.its.cern.ch/jira/browse/ROOT-6703. ### TCanvas. - Make sure that ""/"" and ""."" are not part of the method name when a canvas is; saved as a .C file. ### TLatex. - With the Cocoa backend the PDF and PS output produced miss-aligned exponents; because the `GetTextExtend` method behaved differently in batch mode and ""screen""; mode. This is now fixed. See http://root.cern.ch/phpBB3/viewtopic.php?f=3&t=18883; - Improve the square-root drawing in case it is small.; - Better adjustment of the tilde accent position in case of Cocoa backend. ### TMathText. - `\mu` is now working for Postscript output.; - `\splitline` is now implemented. ### Cocoa backend. - Line width and line style were not applied on boxes. ## 3D Graphics Libraries. ### GL Viewer; - New option ""Rotate scene"" in the ""Extras"" tab of the GL Viewer. It allows to; do a real rotation instead of a wobbling when the ""Auto Rotator"" is launched.; - New methods from Jeremi Niedziela <jeremi.niedziela@cern.ch> to return the; image in memory. ## Tutorials. - New tutorial `textviewostream.C` showing how to use the TGTextViewostream widget. ## Build, Configuration and Testing Infrastructure. ### New functionalities. - Support ARM 64 bits architecture. - Partial support for PPC 64 bits Little Endian architecture. - Add ""Optimized"" CMAKE_BUILD_TYPE: allow highest level of optimisation of the GCC and Clang compilers (-Ofast). - Support ccache activation with cmake configuration switch. - Support link to jemalloc and tcmalloc allocators. - Careful suppression of known and understood warnings, e.g. coming from external packages.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:24934,configurat,configuration,24934,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['configurat'],['configuration']
Deployability," standard library constructs in general,; including modelling implementation-defined fields within C++ standard library; objects, in particular constructing objects into pointers held by such fields,; and separation of responsibilities between analyzer's core and checkers. **Artem:**. I've seen a few false positives that appear because we construct; C++11 std::initializer_list objects with brace initializers, and such; construction is not properly modeled. For instance, if a new object is; constructed on the heap only to be put into a brace-initialized STL container,; the object is reported to be leaked. Approach (0): This can be trivially fixed by this patch, which causes pointers; passed into initializer list expressions to immediately escape. This fix is overly conservative though. So i did a bit of investigation as to; how model std::initializer_list better. According to the standard, ``std::initializer_list<T>`` is an object that has; methods ``begin(), end(), and size()``, where ``begin()`` returns a pointer to continuous; array of ``size()`` objects of type T, and end() is equal to begin() plus size().; The standard does hint that it should be possible to implement; ``std::initializer_list<T>`` as a pair of pointers, or as a pointer and a size; integer, however specific fields that the object would contain are an; implementation detail. Ideally, we should be able to model the initializer list's methods precisely.; Or, at least, it should be possible to explain to the analyzer that the list; somehow ""takes hold"" of the values put into it. Initializer lists can also be; copied, which is a separate story that i'm not trying to address here. The obvious approach to modeling ``std::initializer_list`` in a checker would be to; construct a SymbolMetadata for the memory region of the initializer list object,; which would be of type ``T*`` and represent ``begin()``, so we'd trivially model ``begin()``; as a function that returns this symbol. The array pointed to by th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst:1240,continuous,continuous,1240,interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,1,['continuous'],['continuous']
Deployability," store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:359127,release,released,359127,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['released']
Deployability," such links and/or metadata should not be used in place of making the commit; message self-explanatory. Note that such non-public links should not be; included in the submitted code. For minor violations of these recommendations, the community normally favors; reminding the contributor of this policy over reverting. Minor corrections and; omissions can be handled by sending a reply to the commits mailing list. .. _revert_policy:. Patch reversion policy; ----------------------. As a community, we strongly value having the tip of tree in a good state while; allowing rapid iterative development. As such, we tend to make much heavier; use of reverts to keep the tree healthy than some other open source projects,; and our norms are a bit different. How should you respond if someone reverted your change?. * Remember, it is normal and healthy to have patches reverted. Having a patch; reverted does not necessarily mean you did anything wrong.; * We encourage explicitly thanking the person who reverted the patch for doing; the task on your behalf.; * If you need more information to address the problem, please follow up in the; original commit thread with the reverting patch author. When should you revert your own change?. * Any time you learn of a serious problem with a change, you should revert it.; We strongly encourage ""revert to green"" as opposed to ""fixing forward"". We; encourage reverting first, investigating offline, and then reapplying the; fixed patch - possibly after another round of review if warranted.; * If you break a buildbot in a way which can't be quickly fixed, please revert.; * If a test case that demonstrates a problem is reported in the commit thread,; please revert and investigate offline.; * If you receive substantial :ref:`post-commit review <post_commit_review>`; feedback, please revert and address said feedback before recommitting.; (Possibly after another round of review.); * If you are asked to revert by another contributor, please revert and discu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:19045,patch,patch,19045,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['patch'],['patch']
Deployability," symbol to rename, with the old name and new; name separated by whitespace. Leading and trailing whitespace is ignored, as is; anything following a '#'. Can be specified multiple times to read names from; multiple files. .. option:: --regex. If specified, symbol and section names specified by other switches are treated; as extended POSIX regular expression patterns. .. option:: --remove-section <section>, -R. Remove the specified section from the output. Can be specified multiple times; to remove multiple sections simultaneously. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --set-section-alignment <section>=<align>. Set the alignment of section ``<section>`` to ``<align>``. Can be specified; multiple times to update multiple sections. .. option:: --set-section-flags <section>=<flag>[,<flag>,...]. Set section properties in the output of section ``<section>`` based on the; specified ``<flag>`` values. Can be specified multiple times to update multiple; sections. Supported flag names are `alloc`, `load`, `noload`, `readonly`, `exclude`,; `debug`, `code`, `data`, `rom`, `share`, `contents`, `merge`, `strings`, and; `large`. Not all flags are meaningful for all object file formats or target; architectures. For ELF objects, the flags have the following effects:. - `alloc` = add the `SHF_ALLOC` flag.; - `load` = if the section has `SHT_NOBITS` type, mark it as a `SHT_PROGBITS`; section.; - `readonly` = if this flag is not specified, add the `SHF_WRITE` flag.; - `exclude` = add the `SHF_EXCLUDE` flag.; - `code` = add the `SHF_EXECINSTR` flag.; - `merge` = add the `SHF_MERGE` flag.; - `strings` = add the `SHF_STRINGS` flag.; - `contents` = if the section has `SHT_NOBITS` type, mark it as a `SHT_PROGBITS`; section.; - `large` = add the `SHF_X86_64_LARGE` on x86_64; rejected if the target; architecture is not x86_64. For COFF objects, the flags have the following effects:. - `alloc` = add the `IMAGE_SCN_CNT_UNINITIALIZED",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:4810,update,update,4810,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,1,['update'],['update']
Deployability," syntax.Lines; in the input file starting with ""\#"" are ignored. A **`TBranch`** object; is created for each variable in the expression. The total number of rows; read from the file is returned. ## Trees in Analysis. The methods `TTree::Draw`, `TTree::MakeClass` and; `TTree::MakeSelector` are available for data analysis using trees. The; **`TTree::Draw`** method is a powerful yet simple way to look and draw the; trees contents. It enables you to plot a variable (a leaf) with just one; line of code. However, the Draw method falls short once you want to look; at each entry and design more sophisticated acceptance criteria for your; analysis. For these cases, you can use `TTree::MakeClass`. It creates a; class that loops over the trees entries one by one. You can then expand; it to do the logic of your analysis. The `TTree::MakeSelector` is the recommended method for ROOT data; analysis. It is especially important for large data set in a parallel; processing configuration where the analysis is distributed over several; processors and you can specify which entries to send to each processor.; With `MakeClass` the user has control over the event loop, with; `MakeSelector `the tree is in control of the event loop. ## Simple Analysis Using TTree::Draw. We will use the tree in `cernstaff.root` that was made by the macro in; `$ROOTSYS/tutorials/tree/staff.C`. First, open the file and lists its contents. ``` {.cpp}; root[] TFile f (""cernstaff.root""); root[] f.ls(); TFile** cernstaff.root; TFile* cernstaff.root; KEY: TTree T;1 staff data from ascii file; ```. We can see the **`TTree `**""`T`"" in the file. We will use it to; experiment with the **`TTree::Draw`** method, so let's create a pointer to it:. ``` {.cpp}; root[] TTree *MyTree = T; ```. Cling allows us to get simply the object by using it. Here we define a; pointer to a **`TTree`** object and assign it the value of ""`T`"", the; **`TTree`** in the file. Cling looks for an object named ""`T`"" in the; current ROOT file and re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:68301,configurat,configuration,68301,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['configurat'],['configuration']
Deployability," template parameter list. This fixes a number of issues where valid programs would be rejected due to; mangling collisions, or would in some cases be silently miscompiled. Clang; will use the old manglings if ``-fclang-abi-compat=17`` or lower is; specified.; (`#48216 <https://github.com/llvm/llvm-project/issues/48216>`_),; (`#49884 <https://github.com/llvm/llvm-project/issues/49884>`_), and; (`#61273 <https://github.com/llvm/llvm-project/issues/61273>`_). - The `ClassScopeFunctionSpecializationDecl` AST node has been removed.; Dependent class scope explicit function template specializations now use; `DependentFunctionTemplateSpecializationInfo` to store candidate primary; templates and explicit template arguments. This should not impact users of; Clang as a compiler, but it may break assumptions in Clang-based tools; iterating over the AST. - The warning `-Wenum-constexpr-conversion` is now also enabled by default on; system headers and macros. It will be turned into a hard (non-downgradable); error in the next Clang release. - The flag `-fdelayed-template-parsing` won't be enabled by default with C++20; when targetting MSVC to match the behavior of MSVC.; (`MSVC Docs <https://learn.microsoft.com/en-us/cpp/build/reference/permissive-standards-conformance?view=msvc-170>`_). - Remove the hardcoded path to the imported modules for C++20 named modules. Now we; require all the dependent modules to specified from the command line.; See (`#62707 <https://github.com/llvm/llvm-project/issues/62707>`_). - Forbid `import XXX;` in C++ to find module `XXX` comes from explicit clang modules.; See (`#64755 <https://github.com/llvm/llvm-project/issues/64755>`_). ABI Changes in This Version; ---------------------------; - Following the SystemV ABI for x86-64, ``__int128`` arguments will no longer; be split between a register and a stack slot. - Fixed Microsoft calling convention for returning certain classes with a; templated constructor. If a class has a templated constructor, it s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:5941,release,release,5941,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['release'],['release']
Deployability," tests); install(FILES; cmake/modules/RootMacros.cmake; cmake/modules/RootTestDriver.cmake; DESTINATION ${CMAKE_INSTALL_CMAKEDIR}); install(FILES; ""cmake/modules/FindVdt.cmake""; DESTINATION ""${CMAKE_INSTALL_CMAKEDIR}/modules""); endif(). #---Add configuration files for kernel and jupyter----------------------------------------------; # Make sure the Jupyter ROOT C++ kernel runs with the same Python version as ROOT; set(root_jupyter_dir notebook); set(root_jupyter_config jupyter_notebook_config.py); configure_file(etc/${root_jupyter_dir}/${root_jupyter_config}.in etc/${root_jupyter_dir}/${root_jupyter_config}); install(FILES ${CMAKE_BINARY_DIR}/etc/${root_jupyter_dir}/${root_jupyter_config} DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}/${root_jupyter_dir}). set(root_kernel_dir ${root_jupyter_dir}/kernels/root); set(root_kernel_file kernel.json); configure_file(etc/${root_kernel_dir}/${root_kernel_file}.in etc/${root_kernel_dir}/${root_kernel_file}); install(FILES ${CMAKE_BINARY_DIR}/etc/${root_kernel_dir}/${root_kernel_file} DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}/${root_kernel_dir}). #---install clad header files-------------------------------------------------------------------; if(clad); install(DIRECTORY ${CMAKE_BINARY_DIR}/etc/cling/plugins/; DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}/cling/plugins); endif(). #---Set flag for PyROOT tests that are expected to fail; if(pyroot); set(PYTESTS_WILLFAIL WILLFAIL); endif(). #---Configure Testing using CTest----------------------------------------------------------------; configure_file(${CMAKE_SOURCE_DIR}/cmake/modules/CTestCustom.cmake ${CMAKE_BINARY_DIR} COPYONLY); if(testing); include(RootCTest); set(upstreamprefix https://github.com/root-project). if(roottest); find_package(Git REQUIRED). # Check whether the repository exists in the source directory or its parent; get_filename_component(source_dir ${CMAKE_CURRENT_SOURCE_DIR} REALPATH); if(IS_DIRECTORY ${source_dir}/roottest/.git); set(repo_dir ${source_dir}/roottest); elseif(",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt:27309,install,install,27309,CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt,1,['install'],['install']
Deployability," text or source; files to HTML. ## Reference Guide. The Reference Guide for the ROOT classes at; <http://root.cern.ch/root/html/> has been generated by ROOT's; **`THtml`** class. Just as for ROOT's classes, it can generate (and; update) a reference guide for your classes, too. You document your; classes using source code comments. All comments will be automatically; put into a `<pre></pre>` environment to keep the indentation and line; length. You can write ""raw"" HTML by enclosing comments in the keywords; `Begin_Html` and `End_Html`. To generate documentation for the class **`TObject`** you could run the; following commands:. ``` {.cpp}; root[] THtml h; root[] h.SetInputDir(""$(ROOTSYS)"");; root[] h.MakeClass(""TObject"");; root[] h.CreateJavascript();; root[] h.CreateStylesheet();; ```. The comments following the first comment of the form; //\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_, before any method, is; assumed to be the **class description**. As with any other documentation; part, it has to be a continuous block of comments. Any documented class will have an **class index entry** in the; `ClassIndex.html`, showing their name with a link to their documentation; page and a miniature description. This description for e.g. the class; `MyClass` has to be given in `MyClass's` header file as documentation. A **method description** block starts immediately after '`{`' and looks; like this:. ``` {.cpp}; void TWorld::HelloWorldFunc(string *text); {; // This is a documentation example of the function TWorld::HelloWorldFunc; helloWorld.Print(text);; }; ```. Like in a class description block, everything until the first; non-commented line is considered as a valid member function description; block. **Data members** are documented by putting a C++ comment behind their; declaration in the header file, e.g. ``` {.cpp}; Int_t fIAmADataMember; // this is a data member; ```. When documenting a class, **`THtml`** creates both a ""beautified""; version of the source file and a web page ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/HTMLDoc.md:1200,continuous,continuous,1200,documentation/users-guide/HTMLDoc.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/HTMLDoc.md,1,['continuous'],['continuous']
Deployability," that area. #. *Before RC1* Patches should be limited to bug fixes, important optimization; improvements, or completion of features that were started before the branch; was created. As with all phases, release managers and code owners can reject; patches that are deemed too invasive. #. *Before RC2* Patches should be limited to bug fixes or backend specific; improvements that are determined to be very safe. #. *Before RC3/Final Major Release* Patches should be limited to critical; bugs or regressions. #. *Bug fix releases* Patches should be limited to bug fixes or very safe; and critical performance improvements. Patches must maintain both API and; ABI compatibility with the previous major release. Release Final Tasks; -------------------. The final stages of the release process involves tagging the ""final"" release; branch, updating documentation that refers to the release, and updating the; demo page. Update Documentation; ^^^^^^^^^^^^^^^^^^^^. Review the documentation in the release branch and ensure that it is up; to date. The ""Release Notes"" must be updated to reflect new features, bug; fixes, new known issues, and changes in the list of supported platforms.; The ""Getting Started Guide"" should be updated to reflect the new release; version number tag available from Subversion and changes in basic system; requirements. .. _tag:. Tag the LLVM Final Release; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Tag the final release sources:. ::. $ git tag -sa llvmorg-X.Y.Z; $ git push https://github.com/llvm/llvm-project.git llvmorg-X.Y.Z. Update the LLVM Website; ^^^^^^^^^^^^^^^^^^^^^^^. The website must be updated before the release announcement is sent out. Here; is what to do:. #. Check out the ``www-releases`` module from GitHub. #. Create a new sub-directory ``X.Y.Z`` in the releases directory. #. Copy and commit the ``llvm/docs`` and ``LICENSE.txt`` files into this new; directory. #. Update the ``releases/download.html`` file with links to the release; binaries on GitHub. #. Update ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:13977,release,release,13977,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['release'],['release']
Deployability," that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focuses on the last item - compiler support for; safepoints in generated code. We will assume that an outside; mechanism has decided where to place safepoints. From our; perspective, all safepoints will be function calls. To support; relocation of objects directly reachable from values in compiled code,; the collector must be able to:. #. identify every copy of a pointer (including copies introduced by; the compiler itself) at the safepoint,; #. identify which object each pointer relates to, and; #. potentially update each of those copies. This document describes the mechanism by which an LLVM based compiler; can provide this information to a language runtime/collector, and; ensure that all pointers can be read and updated if desired. Abstract Machine Model; ^^^^^^^^^^^^^^^^^^^^^^^. At a high level, LLVM has been extended to support compiling to an abstract; machine which extends the actual target with a non-integral pointer type; suitable for representing a garbage collected reference to an object. In; particular, such non-integral pointer type have no defined mapping to an; integer representation. This semantic quirk allows the runtime to pick a; integer mapping for each point in the program allowing relocations of objects; without visible effects. This high level abstract machine model is used for most of the optimizer. As; a result, transform passes do not need to be extended to look through explicit; relocation sequence. Before starting code generation, we switch; representations to an explicit form. The exact location chosen for lowering; is an implementation detail. Note that most of the value of the abstract m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:4506,update,updated,4506,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['update'],['updated']
Deployability," that they use, i.e. they have a different set of; preinstalled binaries. Debian8 is very minimal, nvidia-cuda is larger, but has; preinstalled CUDA libraries and allows to access a GPU, installed on your; machine. If you need a minimal linux distribution with only clang and libstdc++ included,; you should try Debian10-based image. If you want to use CUDA libraries and have access to a GPU on your machine,; you should choose nvidia-cuda-based image and use `nvidia-docker; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker container that is running the built; image. If you have a different use-case, you could create your own image based on; ``example/`` folder. Any docker image can be built and run using only the docker binary, i.e. you can; run debian10 build on Fedora or any other Linux distribution. You don't need to; install CMake, compilers or any other clang dependencies. It is all handled; during the build process inside Docker's isolated environment. Stable build; ============; If you want a somewhat recent and somewhat stable build, use the; ``branches/google/stable`` branch, i.e. the following command will produce a; Debian10-based image using the latest ``google/stable`` sources for you:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	-s debian10 --d clang-debian10 -t ""staging"" \; 	--branch branches/google/stable \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Minimizing docker image size; ============================; Due to how Docker's filesystem works, all intermediate writes are persisted in; the resulting image, even if they are removed in the following commands.; To minimize the resulting image size we use `multi-stage Docker builds; <https://docs.docker.com/develop/develop-images/multistage-build/>`_.; Internally Docker builds ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:6724,install,install,6724,interpreter/llvm-project/llvm/docs/Docker.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst,1,['install'],['install']
Deployability," that will be scanned for tests. **test_exec_root** For out-of-dir builds, the path to the test suite root inside; the object directory. This is where tests will be run and temporary output files; placed. **environment** A dictionary representing the environment to use when executing; tests in the suite. **standalone_tests** When true, mark a directory with tests expected to be run; standalone. Test discovery is disabled for that directory. *lit.suffixes* and; *lit.excludes* must be empty when this variable is true. **suffixes** For **lit** test formats which scan directories for tests, this; variable is a list of suffixes to identify test files. Used by: *ShTest*. **substitutions** For **lit** test formats which substitute variables into a test; script, the list of substitutions to perform. Used by: *ShTest*. **unsupported** Mark an unsupported directory, all tests within it will be; reported as unsupported. Used by: *ShTest*. **parent** The parent configuration, this is the config object for the directory; containing the test suite, or None. **root** The root configuration. This is the top-most :program:`lit` configuration in; the project. **pipefail** Normally a test using a shell pipe fails if any of the commands; on the pipe fail. If this is not desired, setting this variable to false; makes the test fail only if the last command in the pipe fails. **available_features** A set of features that can be used in `XFAIL`,; `REQUIRES`, and `UNSUPPORTED` directives. TEST DISCOVERY; ~~~~~~~~~~~~~~. Once test suites are located, :program:`lit` recursively traverses the source; directory (following *test_source_root*) looking for tests. When :program:`lit`; enters a sub-directory, it first checks to see if a nested test suite is; defined in that directory. If so, it loads that test suite recursively,; otherwise it instantiates a local test config for the directory (see; :ref:`local-configuration-files`). Tests are identified by the test suite they are contained within, a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:16862,configurat,configuration,16862,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['configurat'],['configuration']
Deployability," the IR each of the address spaces will be represented by unique number; provided in the Clang source code. The specific IDs for an address space do not; have to match between the AST and the IR. Typically in the AST address space; numbers represent logical segments while in the IR they represent physical; segments.; Therefore, machines with flat memory segments can map all AST address space; numbers to the same physical segment ID or skip address space attribute; completely while generating the IR. However, if the address space information; is needed by the IR passes e.g. to improve alias analysis, it is recommended; to keep it and only lower to reflect physical memory segments in the late; machine passes. The mapping between logical and target address spaces is; specified in the Clang's source code. .. _cxx_for_opencl_impl:. C++ for OpenCL Implementation Status; ====================================. Clang implements language versions 1.0 and 2021 published in `the official; release of C++ for OpenCL Documentation; <https://github.com/KhronosGroup/OpenCL-Docs/releases/tag/cxxforopencl-docrev2021.12>`_. Limited support of experimental C++ libraries is described in the :ref:`experimental features <opencl_experimenal>`. GitHub issues for this functionality are typically prefixed; with '[C++4OpenCL]' - click `here; <https://github.com/llvm/llvm-project/issues?q=is%3Aissue+is%3Aopen+%5BC%2B%2B4OpenCL%5D>`__; to view the full bug list. Missing features or with limited support; ----------------------------------------. - Support of C++ for OpenCL 2021 is currently in experimental phase. Refer to; :ref:`OpenCL 3.0 status <opencl_300>` for details of common missing; functionality from OpenCL 3.0. - IR generation for non-trivial global destructors is incomplete (See:; `PR48047 <https://llvm.org/PR48047>`_). - Support of `destructors with non-default address spaces; <https://www.khronos.org/opencl/assets/CXX_for_OpenCL.html#_construction_initialization_and_destruction>`_; is ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenCLSupport.rst:13112,release,release,13112,interpreter/llvm-project/clang/docs/OpenCLSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenCLSupport.rst,1,['release'],['release']
Deployability," the LLVM coding standards and provides useful information on writing; efficient C++ code. :doc:`GitHub`; Describes how to use the llvm-project repository and code reviews on GitHub. :doc:`GitBisecting`; Describes how to use ``git bisect`` on LLVM's repository. :doc:`GitRepositoryPolicy`; Collection of policies around the git repositories. .. _development-process:. Development Process; -------------------. Information about LLVM's development process. .. toctree::; :hidden:. Projects; HowToReleaseLLVM; Packaging; ReleaseProcess; HowToAddABuilder; ReleaseNotes. :doc:`Projects`; How-to guide and templates for new projects that *use* the LLVM; infrastructure. The templates (directory organization, Makefiles, and test; tree) allow the project code to be located outside (or inside) the ``llvm/``; tree, while using LLVM header files and libraries. :doc:`HowToReleaseLLVM`; This is a guide to preparing LLVM releases. Most developers can ignore it. :doc:`ReleaseProcess`; This is a guide to validate a new release, during the release process. Most developers can ignore it. :doc:`HowToAddABuilder`; Instructions for adding new builder to LLVM buildbot master. :doc:`Packaging`; Advice on packaging LLVM into a distribution. :doc:`Release notes for the current release <ReleaseNotes>`; This describes new features, known bugs, and other limitations. .. _lists-forums:. Forums & Mailing Lists; ----------------------. If you can't find what you need in these docs, try consulting the; Discourse forums. There are also commit mailing lists for all commits to the LLVM Project.; The :doc:`CodeOfConduct` applies to all these forums and mailing lists. `LLVM Discourse`__; The forums for all things LLVM and related sub-projects. There are categories and subcategories for a wide variety of areas within LLVM. You can also view tags or search for a specific topic. .. __: https://discourse.llvm.org/. `Commits Archive (llvm-commits)`__; This list contains all commit messages that are made when LLVM d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingInvolved.rst:2021,release,release,2021,interpreter/llvm-project/llvm/docs/GettingInvolved.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingInvolved.rst,2,['release'],['release']
Deployability," the actual site of the; safepoint or statepoint. The statepoint returns a token value (which; exists only at compile time). To get back the original return value; of the call, we use the ``gc.result`` intrinsic. To get the relocation; of each pointer in turn, we use the ``gc.relocate`` intrinsic with the; appropriate index. Note that both the ``gc.relocate`` and ``gc.result`` are; tied to the statepoint. The combination forms a ""statepoint relocation; sequence"" and represents the entirety of a parseable call or 'statepoint'. When lowered, this example would generate the following x86 assembly:. .. code-block:: gas. 	 .globl	test1; 	 .align	16, 0x90; 	 pushq	%rax; 	 callq	foo; .Ltmp1:; 	 movq	(%rsp), %rax # This load is redundant (oops!); 	 popq	%rdx; 	 retq. Each of the potentially relocated values has been spilled to the; stack, and a record of that location has been recorded to the; :ref:`Stack Map section <stackmap-section>`. If the garbage collector; needs to update any of these pointers during the call, it knows; exactly what to change. The relevant parts of the StackMap section for our example are:. .. code-block:: gas. # This describes the call site; # Stack Maps: callsite 2882400000; 	 .quad	2882400000; 	 .long	.Ltmp1-test1; 	 .short	0; # .. 8 entries skipped ..; # This entry describes the spill slot which is directly addressable; # off RSP with offset 0. Given the value was spilled with a pushq,; # that makes sense.; # Stack Maps: Loc 8: Direct RSP [encoding: .byte 2, .byte 8, .short 7, .int 0]; 	 .byte	2; 	 .byte	8; 	 .short	7; 	 .long	0. This example was taken from the tests for the :ref:`RewriteStatepointsForGC`; utility pass. As such, its full StackMap can be easily examined with the; following command. .. code-block:: bash. opt -rewrite-statepoints-for-gc test/Transforms/RewriteStatepointsForGC/basics.ll -S | llc -debug-only=stackmaps. Simplifications for Non-Relocating GCs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Some of the complexity in the previous",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:10531,update,update,10531,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['update'],['update']
Deployability," the conda compilers are added to ``PATH`` but not their libraries; to ``LD_LIBRARY_PATH`` (Mac, Linux; ``PATH`` for both on MS Windows).; Thus, you get the conda compilers and your system libraries mixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PREFIX/lib``.; Note that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been modified, which can can lead to parsing problems if; your system C library does not support C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard with pip; ---------------------. The C++20 standard is the default on all systems as of release 3.0.1 (both; PyPI and conda-forge); it is C++17 for older releases.; When installing from PyPI using ``pip``, you can control the standard; selection by setting the ``STDCXX`` envar to '20', '17', or '14' (for Linux,; the backend does not need to be recompiled) for the 3.x releases; '17', '14',; or '11' for the 2.x releases.; Note that the build will automatically lower your choice if the compiler used; does not support a newer standard. Install from source; -------------------; .. _installation_from_source:. To build an existing release from source, tell ``pip`` to not download any; binary wheels.; Build-time only dependencies are ``cmake`` (for general build), ``python``; (obviously, but also for LLVM), and a modern C++ compiler (one that supports; at least C++14).; Use the envar ``STDCXX`` to control the C++ standard version; ``MAKE`` to; change the ``make`` command, ``MAKE_NPROCS`` to control the maximum number of; parallel jobs allowed, and ``VERBOSE",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:4871,release,release,4871,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,1,['release'],['release']
Deployability," the drawing of the current canvas in a format; selectable from the submenu. The current canvas name is used as a; file name for various formats such as PostScript, GIF, JPEG, C; macro file, root file. - *Save As...*: popup a dialog for saving the current canvas drawing; in a new filename. - *Print*: popup a dialog to print the current canvas drawing. - *Quit ROOT*: exit the ROOT session. ![](pictures/0300000B.png). #### Edit Menu. There is only one active menu entry in the Edit menu. The others menu; entries will be implemented and will become active in the near future. - *Clear:* delete all objects in the canvas; or in the selected pad according to the selected entry in the; submenu. #### View Menu. - *Editor*: toggles the view of the editor. If it is selected; activates and shows up the editor on the left side of the canvas; window. According to the selected object, the editor loads the; corresponding user interface for easy change of the object's; attributes. - *Toolbar*: toggles the view of the toolbar. If it is selected; activates and shows up the toolbar. It contains buttons for easy; and fast access to most frequently used commands and for graphics; primitive drawing. Tool tips are provided for helping users. - *Status Bar*: toggles the view of the status bar. If it is; selected, the status bar below the canvas window shows up. There; the identification of the objects is displayed when moving the; mouse (such as the object's name, the object's type, its; coordinates, etc.). - *Colors*: creates a new canvas showing the color palette. - *Markers*: creates a new canvas showing the various marker styles. - *Iconify*: create the canvas window icon, does not close the; canvas. - *View With...*: If the last selected pad contains a 3-d structure,; a new canvas is created with a 3-D picture according to the; selection made from the cascaded menu: X3D or OpenGL. The 3-D; image can be interactively rotated, zoomed in wire-frame, solid,; hidden line or stereo mode. ![](",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md:8734,toggle,toggles,8734,documentation/users-guide/GettingStarted.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md,1,['toggle'],['toggles']
Deployability," the fitted function; TGraph *gr3 = new TGraph(f_fitted);; gr3->SetMarkerColor(kGreen);; gr3->SetMarkerStyle(8);; gr3->SetMarkerSize(1);. mg->Add(gr3);; mg->Draw(""ap"");. //displaying basic results; TPaveText *pt = new TPaveText(0.1,0.6,0.5,0.9,""brNDC"");; pt->SetFillColor(18);; pt->SetTextAlign(12);; pt->AddText(""Fitting x^power "");; pt->AddText("" \""Blue\"" Points with gaussian noise to be fitted"");; pt->AddText("" \""Red\"" Known function x^3"");; TString fmsg;; fmsg.Form("" \""Green\"" Fitted function with power=%.4lf"",power);; pt->AddText(fmsg);; pt->Draw();; c1->Update();; return c1;; }; ~~~; In the first image you can see the blue dots which are the function `x^3` with gaussian noise, the red dots correspond to; the original function and the green ones correspond to the fitted function. \image html R_image1.png. ## Global Minimization in R using the package DEoptim; DEoptim is a R package for Differential Evolution Minimization that lets you do global; Minimization.; To install this package you just need to run:. ~~~{.cxx}; #include<TRInterface.h>; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; r<<""install.packages('DEoptim',repos='http://cran.rstudio.com/')"";; ~~~. Then create a macro named GlobalMinimization.C with the next code. ~~~{.cxx}; #include<TRInterface.h>; #include<TBenchmark.h>; #include<math.h>; #include<stdlib.h>; //In the next function the *double pointer should be changed by a TVectorD datatype,; //because the pointer has no meaning in the R environment.; //This is a generalization of the RosenBrock function, with the min xi=1 and i>0.; Double_t GenRosenBrock(const TVectorD xx ); {; int length=xx.GetNoElements();. Double_t result=0;; for(int i=0;i<(length-1);i++); {; result+=pow(1-xx[i],2)+100*pow(xx[i+1]-pow(xx[i],2),2);; }; return result;; }. //the min xi=0 i>0; Double_t Rastrigin(const TVectorD xx); {; int length=xx.GetNoElements();; Double_t result=10*length;; for(int i=0;i<length;i++); {; result+=xx[i]*xx[i]-10*cos(6.2831853*xx[i]);; }; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:17161,install,install,17161,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['install'],['install']
Deployability," the kernarg memory; visible to the kernel; code. 127:96 4 bytes Reserved, must be 0.; 191:128 8 bytes KERNEL_CODE_ENTRY_BYTE_OFFSET Byte offset (possibly; negative) from base; address of kernel; descriptor to kernel's; entry point instruction; which must be 256 byte; aligned.; 351:272 20 Reserved, must be 0.; bytes; 383:352 4 bytes COMPUTE_PGM_RSRC3 GFX6-GFX9; Reserved, must be 0.; GFX90A, GFX940; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx90a-table`.; GFX10-GFX11; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx10-gfx11-table`.; GFX12; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table`.; 415:384 4 bytes COMPUTE_PGM_RSRC1 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC1``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`.; 447:416 4 bytes COMPUTE_PGM_RSRC2 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC2``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table`.; 458:448 7 bits *See separate bits below.* Enable the setup of the; SGPR user data registers; (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). The total number of SGPR; user data registers; requested must not exceed; 16 and match value in; ``compute_pgm_rsrc2.user_sgpr.user_sgpr_count``.; Any requests beyond 16; will be ignored.; >448 1 bit ENABLE_SGPR_PRIVATE_SEGMENT If the *Target Properties*; _BUFFER column of; :ref:`amdgpu-processor-table`; specifies *Architected flat; scratch* then not supported; and must be 0,; >449 1 bit ENABLE_SGPR_DISPATCH_PTR; >450 1 bit ENABLE_SGPR_QUEUE_PTR; >451 1 bit ENABLE_SGPR_KERNARG_SEGMENT_PTR; >452 1 bit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:160895,configurat,configuration,160895,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['configurat'],['configuration']
Deployability," the non-ARC rule which states that such; properties are implicitly ``assign``. However, that rule is clearly; untenable in ARC, since it leads to default-unsafe code. The main merit to; banning the properties is to avoid confusion with non-ARC practice, which did; not ultimately strike us as sufficient to justify requiring extra syntax and; (more importantly) forcing novices to understand ownership rules just to; declare a property when the default is so reasonable. Changing the rule away; from non-ARC practice was acceptable because we had conservatively banned the; synthesis in order to give ourselves exactly this leeway. Applying ``__attribute__((NSObject))`` to a property not of retainable object; pointer type has the same behavior it does outside of ARC: it requires the; property type to be some sort of pointer and permits the use of modifiers other; than ``assign``. These modifiers only affect the synthesized getter and; setter; direct accesses to the ivar (even if synthesized) still have primitive; semantics, and the value in the ivar will not be automatically released during; deallocation. .. _arc.ownership.semantics:. Semantics; ---------. There are five :arc-term:`managed operations` which may be performed on an; object of retainable object pointer type. Each qualifier specifies different; semantics for each of these operations. It is still undefined behavior to; access an object outside of its lifetime. A load or store with ""primitive semantics"" has the same semantics as the; respective operation would have on an ``void*`` lvalue with the same alignment; and non-ownership qualification. :arc-term:`Reading` occurs when performing a lvalue-to-rvalue conversion on an; object lvalue. * For ``__weak`` objects, the current pointee is retained and then released at; the end of the current full-expression. In particular, messaging a ``__weak``; object keeps the object retained until the end of the full expression. .. code-block:: objc. __weak MyObject *weakObj;. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:37314,release,released,37314,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['released']
Deployability," the one found in the executable name. The following canonical driver names are used:. - ``clang`` for the ``gcc`` driver (used to compile C programs); - ``clang++`` for the ``gxx`` driver (used to compile C++ programs); - ``clang-cpp`` for the ``cpp`` driver (pure preprocessor); - ``clang-cl`` for the ``cl`` driver; - ``flang`` for the ``flang`` driver; - ``clang-dxc`` for the ``dxc`` driver. For example, when calling ``x86_64-pc-linux-gnu-clang-g++``,; the driver will first attempt to use the configuration file named::. x86_64-pc-linux-gnu-clang++.cfg. If this file is not found, it will attempt to use the name found; in the executable instead::. x86_64-pc-linux-gnu-clang-g++.cfg. Note that options such as ``--driver-mode=``, ``--target=``, ``-m32`` affect; the search algorithm. For example, the aforementioned executable called with; ``-m32`` argument will instead search for::. i386-pc-linux-gnu-clang++.cfg. If none of the aforementioned files are found, the driver will instead search; for separate driver and target configuration files and attempt to load both.; The former is named ``<driver>.cfg`` while the latter is named; ``<triple>.cfg``. Similarly to the previous variants, the canonical driver name; will be preferred, and the compiler will fall back to the actual name. For example, ``x86_64-pc-linux-gnu-clang-g++`` will attempt to load two; configuration files named respectively::. clang++.cfg; x86_64-pc-linux-gnu.cfg. with fallback to trying::. clang-g++.cfg; x86_64-pc-linux-gnu.cfg. It is not an error if either of these files is not found. The configuration file consists of command-line options specified on one or; more lines. Lines composed of whitespace characters only are ignored as well as; lines in which the first non-blank character is ``#``. Long options may be split; between several lines by a trailing backslash. Here is example of a; configuration file:. ::. # Several options on line; -c --target=x86_64-unknown-linux-gnu. # Long option split between",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:33514,configurat,configuration,33514,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['configurat'],['configuration']
Deployability," the resident and virtual; memory of a proofserv using 'ulimit', which has less limitations and; more flexibility than setrlimit.; Deactivate workers when the requested packages could not be enabled properly.; Add support for reconfiguring the group manager and the; {env,rootrc} settings. The related configuration files are checked for; changes during the regular checks done by the XrdProofdManager.; Add support for selective definition of env and rootrc; variables. Different values can be set for different users, groups, SVN; versions or ROOT versions.; Improve the diagnostic in case of exceptions. Information; about the event and file being processed at the moment the exception; was raised is sent to the client, e.g.;    0.5: caught exception triggered by signal '1' while; processing dset:'EventTree',; file:'http://root.cern.ch/files/data/event_3.root', event:1 - check; logs for possible stacktrace; The patch also fixes a problem with submergers observed when a worker; was stopped because above the memory limits: this worker was; established as merger but could not do the work, for obvious reasons,; freezing the session.; Add two new methods to TProof: ShowMissingFiles() to facilitate; the display of the list of missing files; and GetMissingFiles() to get; a TFileCollection (dataset) with the missing files for further; processing. Fixes. Fix a bug in error status transmission which avoid; session freezing in some cases; FIx; a few issues in libXrdProofd.so with handling of connection used for; admin operation: this should solve some cases where the daemon was not; responding. ; Fix a few memory leaks showing up when; running several queries in the same session; Fix a few issues affecting the new sub-merging option; Fix an issue preventing proper real-time notification; during VerifyDataSet; Fix an issue with TQueryResult ordering (was causing; random 'stressProof' failures); Fix; an issue with TProof::AskStatistics (fBytesRead, fRealTime and fCpuTime; were not corr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:9026,patch,patch,9026,proof/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html,1,['patch'],['patch']
Deployability," the third entry becomes the second entry. *Examples illustrating many of these stack operations are found in Appendix; D.1.2 on page 289.*. .. _amdgpu-dwarf-control-flow-operations:. A.2.5.4.2 Control Flow Operations; #################################. .. note::. This section replaces DWARF Version 5 section 2.5.1.5. The following operations provide simple control of the flow of a DWARF operation; expression. 1. ``DW_OP_nop``. ``DW_OP_nop`` is a place holder. It has no effect on the DWARF stack; entries. 2. ``DW_OP_le``, ``DW_OP_ge``, ``DW_OP_eq``, ``DW_OP_lt``, ``DW_OP_gt``,; ``DW_OP_ne``. .. note::. The same as in DWARF Version 5 section 2.5.1.5. 3. ``DW_OP_skip``. ``DW_OP_skip`` is an unconditional branch. Its single operand is a 2-byte; signed integer constant. The 2-byte constant is the number of bytes of the; DWARF expression to skip forward or backward from the current operation,; beginning after the 2-byte constant. If the updated position is at one past the end of the last operation, then; the operation expression evaluation is complete. Otherwise, the DWARF expression is ill-formed if the updated operation; position is not in the range of the first to last operation inclusive, or; not at the start of an operation. 4. ``DW_OP_bra``. ``DW_OP_bra`` is a conditional branch. Its single operand is a 2-byte signed; integer constant. This operation pops the top of stack. If the value popped; is not the constant 0, the 2-byte constant operand is the number of bytes of; the DWARF operation expression to skip forward or backward from the current; operation, beginning after the 2-byte constant. If the updated position is at one past the end of the last operation, then; the operation expression evaluation is complete. Otherwise, the DWARF expression is ill-formed if the updated operation; position is not in the range of the first to last operation inclusive, or; not at the start of an operation. 5. ``DW_OP_call2, DW_OP_call4, DW_OP_call_ref``. ``DW_OP_call2``, ``DW_OP_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:71232,update,updated,71232,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['update'],['updated']
Deployability," the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/myrepo/release); do; branch=${ref#refs/remotes/myrepo/}; git -C my-monorepo branch --no-track myrepo/${branch} ${ref}; done. # Preserve main.; git -C my-monorepo branch --no-track myrepo/main refs/remotes/myrepo/main. # Merge main.; git -C my-monorepo checkout local/zip/main # Or local/octopus/main; git -C my-monorepo merge myrepo/main. You may want to merge other corresponding branches, for example; ``myrepo`` release branches if they were in lockstep with LLVM project; releases. ``--tag-prefix`` tells ``import-downstream-repo.py`` to rename; annotated tags with the given prefix. Due to limitations with; ``fast_filter_branch.py``, unannotated tags cannot be ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:35248,release,release,35248,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,2,"['hotfix', 'release']","['hotfix', 'release']"
Deployability," the; :ref:`cppyy-generator <cppyy-generator>` (included in the package) as well as; other runtime support included in ``cppyy``. CMake usage; -----------. The CMake usage is via two modules:. * FindLibClang.cmake provides some bootstrap support needed to locate clang.; This is provided mostly as a temporary measure; hopefully upstream support; will allow this to be eliminated in due course.; * FindCppyy.cmake provides the interface described further here. Details of the usage of these modules is within the modules themselves, but; here is a summary of the usage. ``FindLibClang.cmake`` sets the following; variables:. ::. LibClang_FOUND - True if libclang is found.; LibClang_LIBRARY - Clang library to link against.; LibClang_VERSION - Version number as a string (e.g. ""3.9"").; LibClang_PYTHON_EXECUTABLE - Compatible python version. ``FindCppyy.cmake`` sets the following variables:. ::. Cppyy_FOUND - set to true if Cppyy is found; Cppyy_DIR - the directory where Cppyy is installed; Cppyy_EXECUTABLE - the path to the Cppyy executable; Cppyy_INCLUDE_DIRS - Where to find the Cppyy header files.; Cppyy_VERSION - the version number of the Cppyy backend. and also defines the following functions::. cppyy_add_bindings - Generate a set of bindings from a set of header files.; cppyy_find_pips - Return a list of available pip programs. cppyy_add_bindings; ^^^^^^^^^^^^^^^^^^. Generate a set of bindings from a set of header files. Somewhat like CMake's; add_library(), the output is a compiler target. In addition ancillary files; are also generated to allow a complete set of bindings to be compiled,; packaged and installed::. cppyy_add_bindings(; pkg; pkg_version; author; author_email; [URL url]; [LICENSE license]; [LANGUAGE_STANDARD std]; [LINKDEFS linkdef...]; [IMPORTS pcm...]; [GENERATE_OPTIONS option...]; [COMPILE_OPTIONS option...]; [INCLUDE_DIRS dir...]; [LINK_LIBRARIES library...]; [H_DIRS H_DIRSectory]; H_FILES h_file...). The bindings are based on https://cppyy.readthedocs.i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:3194,install,installed,3194,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,1,['install'],['installed']
Deployability," there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:1975,install,install,1975,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,1,['install'],['install']
Deployability," to be able to be optimized more than if each loop pass were run; separately. Inserting Passes into Default Pipelines; =======================================. Rather than manually adding passes to a pass manager, the typical way of; creating a pass manager is to use a ``PassBuilder`` and call something like; ``PassBuilder::buildPerModuleDefaultPipeline()`` which creates a typical; pipeline for a given optimization level. Sometimes either frontends or backends will want to inject passes into the; pipeline. For example, frontends may want to add instrumentation, and target; backends may want to add passes that lower custom intrinsics. For these; cases, ``PassBuilder`` exposes callbacks that allow injecting passes into; certain parts of the pipeline. For example,. .. code-block:: c++. PassBuilder PB;; PB.registerPipelineStartEPCallback([&](ModulePassManager &MPM,; PassBuilder::OptimizationLevel Level) {; MPM.addPass(FooPass());; };. will add ``FooPass`` near the very beginning of the pipeline for pass; managers created by that ``PassBuilder``. See the documentation for; ``PassBuilder`` for the various places that passes can be added. If a ``PassBuilder`` has a corresponding ``TargetMachine`` for a backend, it; will call ``TargetMachine::registerPassBuilderCallbacks()`` to allow the; backend to inject passes into the pipeline. Clang's ``BackendUtil.cpp`` shows examples of a frontend adding (mostly; sanitizer) passes to various parts of the pipeline.; ``AMDGPUTargetMachine::registerPassBuilderCallbacks()`` is an example of a; backend adding passes to various parts of the pipeline. Pass plugins can also add passes into default pipelines. Different tools have; different ways of loading dynamic pass plugins. For example, ``opt; -load-pass-plugin=path/to/plugin.so`` loads a pass plugin into ``opt``. For; information on writing a pass plugin, see :doc:`WritingAnLLVMNewPMPass`. Using Analyses; ==============. LLVM provides many analyses that passes can use, such as a dominator",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst:5863,pipeline,pipeline,5863,interpreter/llvm-project/llvm/docs/NewPassManager.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst,1,['pipeline'],['pipeline']
Deployability," to do so. In particular, every (non-PHI) machine instruction that; defines a register must be followed by a ``DBG_VALUE`` use of that def. If; an instruction does not define a register, but can be followed by a debug inst,; MIRDebugify inserts a ``DBG_VALUE`` that references a constant. Insertion of; ``DBG_VALUE``'s can be disabled by setting ``-debugify-level=locations``. To run MIRDebugify once, simply insert ``mir-debugify`` into your ``llc``; invocation, like:. .. code-block:: bash. # Before some other pass.; $ llc -run-pass=mir-debugify,other-pass ... # After some other pass.; $ llc -run-pass=other-pass,mir-debugify ... To run MIRDebugify before each pass in a pipeline, use; ``-debugify-and-strip-all-safe``. This can be combined with ``-start-before``; and ``-start-after``. For example:. .. code-block:: bash. $ llc -debugify-and-strip-all-safe -run-pass=... <other llc args>; $ llc -debugify-and-strip-all-safe -O1 <other llc args>. If you want to check it after each pass in a pipeline, use; ``-debugify-check-and-strip-all-safe``. This can also be combined with; ``-start-before`` and ``-start-after``. For example:. .. code-block:: bash. $ llc -debugify-check-and-strip-all-safe -run-pass=... <other llc args>; $ llc -debugify-check-and-strip-all-safe -O1 <other llc args>. To check all debug info from a test, use ``mir-check-debugify``, like:. .. code-block:: bash. $ llc -run-pass=mir-debugify,other-pass,mir-check-debugify. To strip out all debug info from a test, use ``mir-strip-debug``, like:. .. code-block:: bash. $ llc -run-pass=mir-debugify,other-pass,mir-strip-debug. It can be useful to combine ``mir-debugify``, ``mir-check-debugify`` and/or; ``mir-strip-debug`` to identify backend transformations which break in; the presence of debug info. For example, to run the AArch64 backend tests; with all normal passes ""sandwiched"" in between MIRDebugify and; MIRStripDebugify mutation passes, run:. .. code-block:: bash. $ llvm-lit test/CodeGen/AArch64 -Dllc=""llc -debug",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst:18319,pipeline,pipeline,18319,interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,1,['pipeline'],['pipeline']
Deployability," to follow this exactly.; Releases should be tagged on Tuesdays. =============================== =========================; Release Approx. Date; =============================== =========================; *release branch: even releases* *4th Tue in January*; *release branch: odd releases* *4th Tue in July*; X.1.0-rc1 3 days after branch.; X.1.0-rc2 2 weeks after branch.; X.1.0-rc3 4 weeks after branch; **X.1.0-final** **6 weeks after branch**; **X.1.1** **8 weeks after branch**; **X.1.2** **10 weeks after branch**; **X.1.3** **12 weeks after branch**; **X.1.4** **14 weeks after branch**; **X.1.5** **16 weeks after branch**; **X.1.6 (if necessary)** **18 weeks after branch**; =============================== =========================. Release Process Summary; -----------------------. * Announce release schedule to the LLVM community and update the website. Do; this at least 3 weeks before the -rc1 release. * Create release branch and begin release process. * Send out release candidate sources for first round of testing. Testing lasts; 6 weeks. During the first round of testing, any regressions found should be; fixed. Patches are merged from mainline into the release branch. Also, all; features need to be completed during this time. Any features not completed at; the end of the first round of testing will be removed or disabled for the; release. * Generate and send out the second release candidate sources. Only *critical*; bugs found during this testing phase will be fixed. Any bugs introduced by; merged patches will be fixed. If so a third round of testing is needed. * The release notes are updated. * Finally, release!. * Announce bug fix release schedule to the LLVM community and update the website. * Do bug-fix releases every two weeks until X.1.5 or X.1.6 (if necessary). Release Process; ===============. .. contents::; :local:. Release Administrative Tasks; ----------------------------. This section describes a few administrative tasks that need to be done for the; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:2258,release,release,2258,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['release'],['release']
Deployability," to have '.' in the PATH to execute the build. Add a new optional parameter to TDirectory::Append: replace.; If replace is true (the default is false), the Append will; first remove from the directory any existing object and; print the message:. Replacing existing OldClass: thename (Potential memory leak). Add a new option parameter to TDirectory::CloneObject: 'autoadd'; If autoadd is true (the default), CloneObject will call the; object 'DirectoryAutoAdd' function (if any). In TDirectory::CloneObject add support for multiple inheritance; from TObject where TObject is not the left most base class. Schema Evolution. Fix schema evolution problem in TTree::Draw by extending support in; TStreamerInfo::ReadValueAux to 'converted' numerical types, (; see issue in ROOT forum). When reading more than one TStreamerInfo for the same versioned; class, we now use the highest possible class version as the current; version of the class. Practically, we update the class version; when reading new (higher versioned) StreamerInfo until the Class; is actually used (i.e. TClass::GetClassVersion is call directly; or indirectly). In particular, if a file has several StreamerInfos for the same; versioned class, we will use the highest version number as the; 'current' class version (as opposed to the lowest until now). For backward compatibility TStreamerInfo::BuildCheck compares the checksum of; the on-file StreamerInfo not only to the current value of the class checksum; but also to the checksum calculated using the older algorithms. This patch extends this test to also be done when comparing 2 on-file StreamerInfos. This removes spurrious warning message when loading 2 older files which; were written with 2 different version of the TClass CheckSum algorithm; (and the in-memory class's version is greater than both TStreamerInfos'; class version). Extend support of TStreamerInfo::ReadValueAux to 'converted' numerical types, hence solving TTree::Draw's schema evolution problem (see http://r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v520/index.html:1322,update,update,1322,io/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v520/index.html,1,['update'],['update']
Deployability," to kernel's; entry point instruction; which must be 256 byte; aligned.; 351:272 20 Reserved, must be 0.; bytes; 383:352 4 bytes COMPUTE_PGM_RSRC3 GFX6-GFX9; Reserved, must be 0.; GFX90A, GFX940; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx90a-table`.; GFX10-GFX11; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx10-gfx11-table`.; GFX12; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table`.; 415:384 4 bytes COMPUTE_PGM_RSRC1 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC1``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`.; 447:416 4 bytes COMPUTE_PGM_RSRC2 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC2``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table`.; 458:448 7 bits *See separate bits below.* Enable the setup of the; SGPR user data registers; (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). The total number of SGPR; user data registers; requested must not exceed; 16 and match value in; ``compute_pgm_rsrc2.user_sgpr.user_sgpr_count``.; Any requests beyond 16; will be ignored.; >448 1 bit ENABLE_SGPR_PRIVATE_SEGMENT If the *Target Properties*; _BUFFER column of; :ref:`amdgpu-processor-table`; specifies *Architected flat; scratch* then not supported; and must be 0,; >449 1 bit ENABLE_SGPR_DISPATCH_PTR; >450 1 bit ENABLE_SGPR_QUEUE_PTR; >451 1 bit ENABLE_SGPR_KERNARG_SEGMENT_PTR; >452 1 bit ENABLE_SGPR_DISPATCH_ID; >453 1 bit ENABLE_SGPR_FLAT_SCRATCH_INIT If the *Target Properties*; column of; :ref:`amdgpu-processor-table`; specifies *Architected flat; scratch* then not supported; and must be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:161101,configurat,configuration,161101,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['configurat'],['configuration']
Deployability," to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to scale up the existing hand-coded mitigations is simply to; inject an `lfence` instruction into both the target and fallthrough; destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:45672,deploy,deploy,45672,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['deploy'],['deploy']
Deployability," to the options described in :doc:`UsersManual` there are the; following options specific to the OpenCL frontend. All the options in this section are frontend-only and therefore if used; with regular clang driver they require frontend forwarding, e.g. ``-cc1``; or ``-Xclang``. .. _opencl_finclude_default_header:. .. option:: -finclude-default-header. Adds most of builtin types and function declarations during compilations. By; default the OpenCL headers are not loaded by the frontend and therefore certain; builtin types and most of builtin functions are not declared. To load them; automatically this flag can be passed to the frontend (see also :ref:`the; section on the OpenCL Header <opencl_header>`):. .. code-block:: console. $ clang -Xclang -finclude-default-header test.cl. Alternatively the internal header `opencl-c.h` containing the declarations; can be included manually using ``-include`` or ``-I`` followed by the path; to the header location. The header can be found in the clang source tree or; installation directory. .. code-block:: console. $ clang -I<path to clang sources>/lib/Headers/opencl-c.h test.cl; $ clang -I<path to clang installation>/lib/clang/<llvm version>/include/opencl-c.h/opencl-c.h test.cl. In this example it is assumed that the kernel code contains; ``#include <opencl-c.h>`` just as a regular C include. Because the header is very large and long to parse, PCH (:doc:`PCHInternals`); and modules (:doc:`Modules`) can be used internally to improve the compilation; speed. To enable modules for OpenCL:. .. code-block:: console. $ clang --target=spir-unknown-unknown -c -emit-llvm -Xclang -finclude-default-header -fmodules -fimplicit-module-maps -fmodules-cache-path=<path to the generated module> test.cl. Another way to circumvent long parsing latency for the OpenCL builtin; declarations is to use mechanism enabled by :ref:`-fdeclare-opencl-builtins; <opencl_fdeclare_opencl_builtins>` flag that is available as an alternative; feature. .. _opencl_fdecl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenCLSupport.rst:3458,install,installation,3458,interpreter/llvm-project/clang/docs/OpenCLSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenCLSupport.rst,1,['install'],['installation']
Deployability," to the window manager arrow when; exiting a `TCanvas`. ### `freetype` library. Updates `builtin_freetype` to 2.6.1 (current upstream version), which can detect; `PPC64LE` machine. This was compiled and tested on `SLC6 + ICC + x86_64`,; `F21 + GCC + ppc64le`, `MacOSX 10.11.1 + Xcode 7.1` and `Windows (ROOT 5.34)`.; `$ROOTSYS/graf2d/freetype/src/README` was removed, because no issues were noticed; with `ICC` compiler and `-Wall -pedantic -ansi` flags.; Additionally `--with-png=no --with-bzip2=no` flags are passed to freetype; configuration script. Default values for these options are auto.; `freetype` finds `libpng` and `libbzip2` on the system and builds extra; modules. Then attempting to link against `freetype` one would need to link; `-lpng -lbzip2` explicitly otherwise linking will returns in undefined; references. Otherwise we would need to check for `libpng` and `libbzip2` on the system; and adjust `FREETYPE_LIBRARIES` to include `-lpng` and `-lbzip2`.; The current solution goes for the minimal configuration. The original request for; this update was posted [here](https://sft.its.cern.ch/jira/browse/ROOT-7631). ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ### THttpServer. Support of POST HTTP requests. For example, ROOT objects can be send with POST request and used as arguments of; objects method execution in exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class. When command is registered with THttpServer::RegisterCommand() method,; one could configure additional arguments which should be submitted when; command is executed with cmd.json requests. Introduce restriction rules for objects access with THttpServer::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the cli",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:18475,configurat,configuration,18475,README/ReleaseNotes/v606/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md,1,['configurat'],['configuration']
Deployability," to verify that ROOT-based code really includes all necessary ROOT headers. ## RDataFrame. - Starting from this version, when `RSnapshotOptions.fMode` is `""UPDATE""` (i.e. the output file is opened in ""UPDATE""; mode), Snapshot will refuse to write out a TTree if one with the same name is already present in the output file.; Users can set the new flag `RSnapshotOption::fOverwriteIfExists` to `true` to force the deletion of the TTree that is; already present and the writing of a new TTree with the same name. See; [ROOT-10573](https://sft.its.cern.ch/jira/browse/ROOT-10573) for more details.; - RDataFrame changed its error handling strategy in case of unreadable input files. Instead of simply logging an error; and skipping the file, it now throws an exception if any of the input files is unreadable (this could also happen in; the middle of an event loop). See [ROOT-10549](https://sft.its.cern.ch/jira/browse/ROOT-10549) for more details.; - New analysis examples based on the recent ATLAS Open Data release ([`Higgs to two photons`](https://root.cern/doc/master/df104__HiggsToTwoPhotons_8py.html), [`W boson analysis`](https://root.cern/doc/master/df105__WBosonAnalysis_8py.html), [`Higgs to four leptons`](https://root.cern/doc/master/df106__HiggsToFourLeptons_8py.html)); - An exception is now thrown in case the size of ROOT's thread-pool changes between RDataFrame construction time and the time the event loop begins.; - Just-in-time compilation of large portions of the computation graph has been optimized, and it is now much faster. Please report any regressions you might encounter on [our issue tracker](https://sft.its.cern.ch/jira/projects/ROOT).; - `MakeRootDataFrame` is now a safe way to construct RDFs. It used to return RDFs with more limited functionality. ## PyROOT. - Introduce the `ROOT.Numba.Declare` decorator which provides a simple way to call Python callables from C++. The Python callables are; just-in-time compiled with [numba](http://numba.pydata.org/), which en",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v622/index.md:10113,release,release,10113,README/ReleaseNotes/v622/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v622/index.md,1,['release'],['release']
Deployability," to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput* is the reciprocal of the instruction throughput. Throughput; is computed as the maximum number of instructions of a same type that can be; executed per clock cycle in the absence of operand dependencies. In this; example, the reciprocal throughput of a vector float multiply is 1; cycles/instruction. That is because the FP multiplier JFPM is only available; from pipeline JFPU1. Instruction encodings are displayed within the instruction info view when flag; `-show-encoding` is specified. Below is an example of `-show-encoding` output for the dot-product kernel:. .. code-block:: none. Instruction Info:; [1]: #uOps; [2]: Latency; [3]: RThroughput; [4]: MayLoad; [5]: MayStore; [6]: HasSideEffects (U); [7]: Encoding Size. [1] [2] [3] [4] [5] [6] [7] Encodings: Instructions:; 1 2 1.00 4 c5 f0 59 d0 vmulps	%xmm0, %xmm1, %xmm2; 1 4 1.00 4 c5 eb 7c da vhaddps	%xmm2, %xmm2, %xmm3; 1 4 1.00 4 c5 e3 7c e3 vhaddps	%xmm3, %xmm3, %xmm4. The `Encoding Size` column shows the size in bytes of instructions. The; `Encodings` column shows the actual instruction encodings (byte sequences in; hex). The third section is the *Resource pressure view*. This view reports; the average number of resource cycles consumed every iteration by instructions; for every processor resource unit available on the target. Information is; structured in two table",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:19197,pipeline,pipeline,19197,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['pipeline'],['pipeline']
Deployability," to; let people know you are working on it. Then try to reproduce and fix the bug with upstream LLVM. Start by building; LLVM from source as described in :doc:`GettingStarted` and; use the built binaries to reproduce the failure described in the bug. Use; a debug build (`-DCMAKE_BUILD_TYPE=Debug`) or a build with assertions; (`-DLLVM_ENABLE_ASSERTIONS=On`, enabled for Debug builds). Reporting a Security Issue; --------------------------. There is a separate process to submit security-related bugs, see :ref:`report-security-issue`. Bigger Pieces of Work; ---------------------; In case you are interested in taking on a bigger piece of work, a list of; interesting projects is maintained at the `LLVM's Open Projects page`_. In case; you are interested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:2013,patch,patch,2013,interpreter/llvm-project/llvm/docs/Contributing.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst,1,['patch'],['patch']
Deployability," toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared library, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be built with ABI breaking checks or; not. Allowed values are `WITH_ASSERTS` (default), `FORCE_ON` and; `FORCE_OFF`. `WITH_ASSERTS` turns on ABI breaking checks in an; assertion enabled build. `FORCE_ON` (`FORCE_OFF`) turns them on; (off) irrespective of whether normal (`NDEBUG`-based) assertions are; enabled or not. A version of LLVM built with ABI breaking checks; is not ABI compatible with a version built without it. **LLVM_ADDITIONAL_BUILD_TYPES**:LIST; Adding a semicolon separated list of additional build types to this flag; allows for them to be specified as values in CMAKE_BUILD_TYPE without; encountering a fatal error during the configuration process. **LLVM_UNREACHABLE_OPTIMIZE**:BOOL; This flag controls the behavior of `llvm_unreachable()` in release build; (when assertions are disabled in general). When ON (default) then; `llvm_unreachable()` is considered ""undefined behavior"" and optimized as; such. When OFF it is instead replaced with a guaranteed ""trap"". **LLVM_APPEND_VC_REV**:BOOL; Embed version control revision info (Git revision id).; The version info is provided by the ``LLVM_REVISION`` macro in; ``llvm/include/llvm/Support/VCSRevision.h``. Developers using git who don't; need revision info can disable this option to avoid re-linking most binaries; after a branch switch. Defaults to ON. **LLVM_FORCE_VC_REVISION**:STRING; Force a specific Git revision id rather than calling to git to determine it.; This is useful in environments where git is not available or non-functional; but the VC revision is available through other means. **LLVM_FORCE_VC_REPOSITORY**:STRING; Set the git repository to include in version info rather than calling git to; determine it. **LLVM_BUILD_32_BITS**:BOOL; Build 32-bit exe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:12821,release,release,12821,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['release'],['release']
Deployability," triple used to configure LLVM. **--ignore-libllvm**. Ignore libLLVM and link component libraries instead. **--includedir**. Print the installation directory for LLVM headers. **--ldflags**. Print the flags needed to link against LLVM libraries. **--libdir**. Print the installation directory for LLVM libraries. **--libfiles**. Similar to **--libs**, but print the full path to each library file. This is; useful when creating makefile dependencies, to ensure that a tool is relinked if; any library it uses changes. **--libnames**. Similar to **--libs**, but prints the bare filenames of the libraries; without **-l** or pathnames. Useful for linking against a not-yet-installed; copy of LLVM. **--libs**. Print all the libraries needed to link against the specified LLVM; *components*, including any dependencies. **--link-shared**. Link the components as shared libraries. **--link-static**. Link the component libraries statically. **--obj-root**. Print the object root used to build LLVM. **--prefix**. Print the installation prefix for LLVM. **--shared-mode**. Print how the provided components can be collectively linked (`shared` or `static`). **--system-libs**. Print all the system libraries needed to link against the specified LLVM; *components*, including any dependencies. **--targets-built**. Print the component names for all targets supported by this copy of LLVM. **--version**. Print the version number of LLVM. COMPONENTS; ----------. To print a list of all available components, run **llvm-config; --components**. In most cases, components correspond directly to LLVM; libraries. Useful ""virtual"" components include:. **all**. Includes all LLVM libraries. The default if no components are specified. **backend**. Includes either a native backend or the C backend. **engine**. Includes either a native JIT or the bitcode interpreter. EXIT STATUS; -----------. If **llvm-config** succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-config.rst:2488,install,installation,2488,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-config.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-config.rst,1,['install'],['installation']
Deployability," true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfectly within their; scheduling model, :program:`llvm-mca` isn't always able to simulate them; perfectly. Modifying the scheduling model isn't always a viable; option though (maybe because the instruction is modeled incorrectly on; purpose or the instruction's behaviour is quite complex). The; CustomBehaviour class can be used in these cases to enforce proper; instruction modeling (often by customizing data dependencies and detecting; hazards that :program:`llvm-mca` has no way of knowing about). :program:`llvm-mca` comes with one generic and multiple target specific; CustomBehaviour classes. The generic class will be used if the ``-disable-cb``; flag is used or if a target specific CustomBehaviour class doesn't exist for; that target. (The generic class does nothing.) Currently, the CustomBehaviour; class is only a part of the in-order pipeline, but there are plans to add it; to the out-of-order pipeline in the future. CustomBehaviour's main method is `checkCustomHazard()` which uses the; current instruction and a list of all instructions still executing within; the pipeline to determine if the current instruction should be dispatched.; As output, the method returns an integer representing the number of cycles; that the current instruction must stall for (this can be an underestimate; if you don't know the exact number and a value of 0 represents no stall). If you'd like to add a CustomBehaviour class for a target that doesn't; already have one, refer to an existing implementation to see how to set it; up. The classes are implemented within the target specific backend (for; example `/llvm/lib/Target/AMDGPU/MCA/`) so that they can access backend symbols. Instrument Manager; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; On certain architectures, scheduling information for certain instructions; do not contain all of the information re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:44814,pipeline,pipeline,44814,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['pipeline'],['pipeline']
Deployability," types means that an; attempt to change one of these functions to return ``Error`` or ``Expected<T>``; instead often results in an avalanche of changes to callers, callers of callers,; and so on. (The first such attempt, returning an ``Error`` from; MachOObjectFile's constructor, was abandoned after the diff reached 3000 lines,; impacted half a dozen libraries, and was still growing). To solve this problem, the ``Error``/``std::error_code`` interoperability requirement was; introduced. Two pairs of functions allow any ``Error`` value to be converted to a; ``std::error_code``, any ``Expected<T>`` to be converted to an ``ErrorOr<T>``, and vice; versa:. .. code-block:: c++. std::error_code errorToErrorCode(Error Err);; Error errorCodeToError(std::error_code EC);. template <typename T> ErrorOr<T> expectedToErrorOr(Expected<T> TOrErr);; template <typename T> Expected<T> errorOrToExpected(ErrorOr<T> TOrEC);. Using these APIs it is easy to make surgical patches that update individual; functions from ``std::error_code`` to ``Error``, and from ``ErrorOr<T>`` to; ``Expected<T>``. Returning Errors from error handlers; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Error recovery attempts may themselves fail. For that reason, ``handleErrors``; actually recognises three different forms of handler signature:. .. code-block:: c++. // Error must be handled, no new errors produced:; void(UserDefinedError &E);. // Error must be handled, new errors can be produced:; Error(UserDefinedError &E);. // Original error can be inspected, then re-wrapped and returned (or a new; // error can be produced):; Error(std::unique_ptr<UserDefinedError> E);. Any error returned from a handler will be returned from the ``handleErrors``; function so that it can be handled itself, or propagated up the stack. .. _err_exitonerr:. Using ExitOnError to simplify tool code; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Library code should never call ``exit`` for a recoverable error, however in tool; code (especially command li",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:29475,patch,patches,29475,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,2,"['patch', 'update']","['patches', 'update']"
Deployability," until X.1.5 or X.1.6 (if necessary). Release Process; ===============. .. contents::; :local:. Release Administrative Tasks; ----------------------------. This section describes a few administrative tasks that need to be done for the; release process to begin. Specifically, it involves:. * Updating version numbers,. * Creating the release branch, and. * Tagging release candidates for the release team to begin testing. Create Release Branch; ^^^^^^^^^^^^^^^^^^^^^. Branch the Git trunk using the following procedure:. #. Remind developers that the release branching is imminent and to refrain from; committing patches that might break the build. E.g., new features, large; patches for works in progress, an overhaul of the type system, an exciting; new TableGen feature, etc. #. Verify that the current git trunk is in decent shape by; examining nightly tester and buildbot results. #. Bump the version in trunk to N.0.0git and tag the commit with llvmorg-N-init.; If ``X`` is the version to be released, then ``N`` is ``X + 1``. ::. $ git tag -sa llvmorg-N-init. #. Clear the release notes in trunk. #. Create the release branch from the last known good revision from before the; version bump. The branch's name is release/X.x where ``X`` is the major version; number and ``x`` is just the letter ``x``. #. On the newly-created release branch, immediately bump the version; to X.1.0git (where ``X`` is the major version of the branch.). #. All tags and branches need to be created in both the llvm/llvm-project and; llvm/llvm-test-suite repos. Update LLVM Version; ^^^^^^^^^^^^^^^^^^^. After creating the LLVM release branch, update the release branches'; version with the script in ``llvm/utils/release/bump-version.py``. Tagging the LLVM Release Candidates; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Tag release candidates:. ::. $ git tag -sa llvmorg-X.Y.Z-rcN. The Release Manager must supply pre-packaged source tarballs for users. This can; be done with the export.sh script in utils/release. Ta",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:4042,release,released,4042,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['release'],['released']
Deployability," update of a condition bitmap that is local to a; function and will cause the ``-instrprof`` pass to generate the code to; instrument the control flow around each condition in a boolean expression. The; ID of each condition corresponds to a bit index in the condition bitmap which; is set based on the evaluation of the condition. '``llvm.instrprof.mcdc.tvbitmap.update``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.instrprof.mcdc.tvbitmap.update(ptr <name>, i64 <hash>,; i32 <bitmap-bytes>); i32 <bitmap-index>,; ptr <mcdc-temp-addr>). Overview:; """""""""""""""""". The '``llvm.instrprof.mcdc.tvbitmap.update``' intrinsic is used to track MC/DC; test vector execution after each boolean expression has been fully executed.; The overall value of the condition bitmap, after it has been successively; updated using the '``llvm.instrprof.mcdc.condbitmap.update``' intrinsic with; the true or false evaluation of each condition, uniquely identifies an executed; MC/DC test vector and is used as a bit index into the global test vector; bitmap. Arguments:; """""""""""""""""""". The first argument is a pointer to a global variable containing the; name of the entity being instrumented. This should generally be the; (mangled) function name for a set of counters. The second argument is a hash value that can be used by the consumer; of the profile data to detect changes to the instrumented source. The third argument is the number of bitmap bytes required by the function to; record the number of test vectors executed for each boolean expression. The fourth argument is the byte index into the global test vector bitmap; corresponding to the function. The fifth argument is the address of the condition bitmap, which contains a; value representing an executed MC/DC test vector. It is loaded and used as the; bit index of the test vector bitmap. Semantics:; """""""""""""""""""". This intrinsic represents the final operation of an MC/DC instrumentation; sequence and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:535327,update,update,535327,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['update'],['update']
Deployability," updated. * When performing the code review for the change, please add any applicable; ""vendors"" group to the review for their awareness. The purpose of these; groups is to give vendors early notice that potentially disruptive changes; are being considered but have not yet been accepted. Vendors can give early; testing feedback on the changes to alert us to unacceptable breakages. The; current list of vendor groups is:. * `Clang vendors <https://reviews.llvm.org/project/members/113/>`_; * `libc++ vendors <https://reviews.llvm.org/project/members/109/>`_. People interested in joining the vendors group can do so by clicking the; ""Join Project"" link on the vendor's ""Members"" page in Phabricator. * When committing the change to the repository, add appropriate information; about the potentially breaking changes to the ``Potentially Breaking Changes``; section of the project's release notes. The release note should have; information about what the change is, what is potentially disruptive about; it, as well as any code examples, links, and motivation that is appropriate; to share with users. This helps users to learn about potential issues with; upgrading to that release. * After the change has been committed to the repository, the potentially; disruptive changes described in the release notes should be posted to the; `Announcements <https://discourse.llvm.org/c/announce/>`_ channel on; Discourse. The post should be tagged with the ``potentially-breaking`` label; and a label specific to the project (such as ``clang``, ``llvm``, etc). This; is another mechanism by which we can give pre-release notice to users about; potentially disruptive changes. It is a lower-traffic alternative to the; joining ""vendors"" group. To automatically be notified of new announcements; with the ``potentially-breaking`` label, go to your user preferences page in; Discourse, and add the label to one of the watch categories under; ``Notifications->Tags``. .. _code owners:. Code Owners; -----------.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:6617,release,release,6617,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['release'],['release']
Deployability," usage by using ``lld``, see; the :ref:`LLVM_USE_LINKER <llvm_use_linker>` option.; * Assertions are internal checks to help you find bugs. They typically slow; down LLVM and Clang when enabled, but can be useful during development.; You can manually set :ref:`LLVM_ENABLE_ASSERTIONS <llvm_enable_assertions>`; to override the default from `CMAKE_BUILD_TYPE`. If you are using an IDE such as Visual Studio or Xcode, you should use; the IDE settings to set the build type. **CMAKE_INSTALL_PREFIX**:PATH; Path where LLVM will be installed when the ""install"" target is built. **CMAKE_{C,CXX}_FLAGS**:STRING; Extra flags to use when compiling C and C++ source files respectively. **CMAKE_{C,CXX}_COMPILER**:STRING; Specify the C and C++ compilers to use. If you have multiple; compilers installed, CMake might not default to the one you wish to; use. .. _Frequently Used LLVM-related variables:. Frequently Used LLVM-related variables; --------------------------------------. The default configuration may not match your requirements. Here are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. **LLVM_LIBDIR_SUFFIX**:STRING; Extra suffix to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These options, when you use the Ninja generator, allow you; to restrict the parallelism. For example, to avoid OOMs or going; into swap, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:8841,configurat,configuration,8841,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['configurat'],['configuration']
Deployability," usage of `TRef` in the `TFoamCell` class has ben replaced with array indices. This avoids, when generating a large number of toys requiring a re-initialization of `TFoam` an increase in the memory usage caused by `TRef`. ### RVec. - a number of new helper functions have been added to [RVec](https://root.cern/doc/master/classROOT_1_1VecOps_1_1RVec.html): [Range](https://root.cern/doc/master/group__vecops.html#ga59cc6e477803f2bfd7dae29e56048cc1), [Product](https://root.cern/doc/master/group__vecops.html#ga25e4c2cf5c82fe56dd6bbc86b2386b69) and Enumerate; - the [Take](https://root.cern/doc/master/group__vecops.html#gac719439afb1ec9d32a28acdc7aee5948) helper function now allows passing a default value that will be used to fill the output array in case it's longer than the input. ## RooFit Libraries. ### Consistent definition of the default minimizer type for all of RooFit/RooStats. In previous releases, the default minimizer type that RooFit used was hardcoded to be the original `Minuit`, while RooStats used the default minimizer specified by `ROOT::Math::MinimizerOptions::DefaultMinimizerType()`. Now it is possible to centrally define the global minimizer for all RooFit libraries via `ROOT::Math::MinimizerOptions::SetDefaultMinimizer()`, or alternatively in the `.rootrc` file by adding for example `Root.Fitter: Minuit2` to select Minuit2. ### Code modernization by using `std::string` in RooFit interfaces. The following lesser-used RooFit functions now return a `std::string` instead of a `const char*`, potentially requiring the update of your code:. - [std::string RooCmdConfig::missingArgs() const](https://root.cern/doc/v628/classRooCmdConfig.html#aec50335293c45a507d347c604bf9651f); ### Uniquely identifying RooArgSet and RooDataSet objects. Before v6.28, it was ensured that no `RooArgSet` and `RooDataSet` objects on the heap were located at an address that had already been used for an instance of the same class before.; With v6.28, this is not guaranteed anymore.; Hence",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md:18808,release,releases,18808,README/ReleaseNotes/v628/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md,1,['release'],['releases']
Deployability," use this in config files, etc. Use at your own risk. .. _FixNamespaceComments:. **FixNamespaceComments** (``Boolean``) :versionbadge:`clang-format 5` :ref:`¶ <FixNamespaceComments>`; If ``true``, clang-format adds missing namespace end comments for; namespaces and fixes invalid existing ones. This doesn't affect short; namespaces, which are controlled by ``ShortNamespaceLines``. .. code-block:: c++. true: false:; namespace longNamespace { vs. namespace longNamespace {; void foo(); void foo();; void bar(); void bar();; } // namespace a }; namespace shortNamespace { namespace shortNamespace {; void baz(); void baz();; } }. .. _ForEachMacros:. **ForEachMacros** (``List of Strings``) :versionbadge:`clang-format 3.7` :ref:`¶ <ForEachMacros>`; A vector of macros that should be interpreted as foreach loops; instead of as function calls. These are expected to be macros of the form:. .. code-block:: c++. FOREACH(<variable-declaration>, ...); <loop-body>. In the .clang-format configuration file, this can be configured like:. .. code-block:: yaml. ForEachMacros: ['RANGES_FOR', 'FOREACH']. For example: BOOST_FOREACH. .. _IfMacros:. **IfMacros** (``List of Strings``) :versionbadge:`clang-format 13` :ref:`¶ <IfMacros>`; A vector of macros that should be interpreted as conditionals; instead of as function calls. These are expected to be macros of the form:. .. code-block:: c++. IF(...); <conditional-body>; else IF(...); <conditional-body>. In the .clang-format configuration file, this can be configured like:. .. code-block:: yaml. IfMacros: ['IF']. For example: `KJ_IF_MAYBE; <https://github.com/capnproto/capnproto/blob/master/kjdoc/tour.md#maybes>`_. .. _IncludeBlocks:. **IncludeBlocks** (``IncludeBlocksStyle``) :versionbadge:`clang-format 6` :ref:`¶ <IncludeBlocks>`; Dependent on the value, multiple ``#include`` blocks can be sorted; as one and divided based on category. Possible values:. * ``IBS_Preserve`` (in configuration: ``Preserve``); Sort each ``#include`` block separatel",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:64419,configurat,configuration,64419,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," used to implement; vector and matrix expressions such that these expressions can be transformed at compile time; to code which is equivalent to hand optimized code in a low-level language like FORTRAN or; C (see for example ref. 1). The SMatrix has been developed initially by T. Glebe of the Max-Planck-Institut, Heidelberg,; as part of the HeraB analysis framework. A subset of the original package has been now incorporated; in the %ROOT distribution, with the aim to provide to the LHC experiments a stand-alone and; high performant matrix package for reconstruction. The API of the current package differs; from the original one, in order to be compliant to the %ROOT coding conventions. SMatrix contains generic \ref SMatrixSVector to describe matrix and vector of arbitrary; dimensions and of arbitrary type. The classes are templated on the scalar type and on the; size of the matrix (number of rows and columns) or the vector. Therefore, the size has to; be known at compile time. Since the release 5.10, SMatrix supports symmetric matrices using; a storage class (ROOT::Math::MatRepSym) which contains only the N*(N+1)/2 independent element; of a NxN symmetric matrix.; It is not in the mandate of this package to provide a complete linear algebra functionality; for these classes. What is provided are basic \ref MatrixFunctions and \ref VectFunction,; such as the matrix-matrix, matrix-vector, vector-vector operations, plus some extra; functionality for square matrices, like inversion, which is based on the optimized Cramer; method for squared matrices of size up to 6x6, and determinant calculation.; For a more detailed descriptions and usage examples see:. * \ref SVectorDoc; * \ref SMatrixDoc; * \ref MatVecFunctions. The SMatrix package contains only header files. Normally one does not need to build any library.; In the %ROOT distribution a library, _libSmatrix_ is produced with the C++ dictionary information; for vectors, symmetric and squared matrices for double, float type",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md:1409,release,release,1409,math/smatrix/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md,1,['release'],['release']
Deployability," value in; ``BinPackParameters``. If that is ``true``, bin-packs Objective-C; protocol conformance list items into as few lines as possible; whenever they go over ``ColumnLimit``. If ``Always``, always bin-packs Objective-C protocol conformance; list items into as few lines as possible whenever they go over; ``ColumnLimit``. If ``Never``, lays out Objective-C protocol conformance list items; onto individual lines whenever they go over ``ColumnLimit``. .. code-block:: objc. Always (or Auto, if BinPackParameters=true):; @interface ccccccccccccc () <; ccccccccccccc, ccccccccccccc,; ccccccccccccc, ccccccccccccc> {; }. Never (or Auto, if BinPackParameters=false):; @interface ddddddddddddd () <; ddddddddddddd,; ddddddddddddd,; ddddddddddddd,; ddddddddddddd> {; }. Possible values:. * ``BPS_Auto`` (in configuration: ``Auto``); Automatically determine parameter bin-packing behavior. * ``BPS_Always`` (in configuration: ``Always``); Always bin-pack parameters. * ``BPS_Never`` (in configuration: ``Never``); Never bin-pack parameters. .. _ObjCBlockIndentWidth:. **ObjCBlockIndentWidth** (``Unsigned``) :versionbadge:`clang-format 3.7` :ref:`¶ <ObjCBlockIndentWidth>`; The number of characters to use for indentation of ObjC blocks. .. code-block:: objc. ObjCBlockIndentWidth: 4. [operation setCompletionBlock:^{; [self onOperationDone];; }];. .. _ObjCBreakBeforeNestedBlockParam:. **ObjCBreakBeforeNestedBlockParam** (``Boolean``) :versionbadge:`clang-format 11` :ref:`¶ <ObjCBreakBeforeNestedBlockParam>`; Break parameters list into lines when there is nested block; parameters in a function call. .. code-block:: c++. false:; - (void)_aMethod; {; [self.test1 t:self w:self callback:^(typeof(self) self, NSNumber; *u, NSNumber *v) {; u = c;; }]; }; true:; - (void)_aMethod; {; [self.test1 t:self; w:self; callback:^(typeof(self) self, NSNumber *u, NSNumber *v) {; u = c;; }]; }. .. _ObjCPropertyAttributeOrder:. **ObjCPropertyAttributeOrder** (``List of Strings``) :versionbadge:`clang-format 18`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:89249,configurat,configuration,89249,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," value. If they are; equal, it tries to store a new value into the memory. Arguments:; """""""""""""""""""". There are three arguments to the '``cmpxchg``' instruction: an address; to operate on, a value to compare to the value currently be at that; address, and a new value to place at that address if the compared values; are equal. The type of '<cmp>' must be an integer or pointer type whose; bit width is a power of two greater than or equal to eight and less; than or equal to a target-specific size limit. '<cmp>' and '<new>' must; have the same type, and the type of '<pointer>' must be a pointer to; that type. If the ``cmpxchg`` is marked as ``volatile``, then the; optimizer is not allowed to modify the number or order of execution of; this ``cmpxchg`` with other :ref:`volatile operations <volatile>`. The success and failure :ref:`ordering <ordering>` arguments specify how this; ``cmpxchg`` synchronizes with other atomic operations. Both ordering parameters; must be at least ``monotonic``, the failure ordering cannot be either; ``release`` or ``acq_rel``. A ``cmpxchg`` instruction can also take an optional; "":ref:`syncscope <syncscope>`"" argument. Note: if the alignment is not greater or equal to the size of the `<value>`; type, the atomic operation is likely to require a lock and have poor; performance. The alignment is only optional when parsing textual IR; for in-memory IR, it is; always present. If unspecified, the alignment is assumed to be equal to the; size of the '<value>' type. Note that this default alignment assumption is; different from the alignment used for the load/store instructions when align; isn't specified. The pointer passed into cmpxchg must have alignment greater than or; equal to the size in memory of the operand. Semantics:; """""""""""""""""""". The contents of memory at the location specified by the '``<pointer>``' operand; is read and compared to '``<cmp>``'; if the values are equal, '``<new>``' is; written to the location. The original value at the locatio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:426962,release,release,426962,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['release'],['release']
Deployability," values, the continuation function may optionally return ordinary; results when the coroutine has run to completion. The coroutine frame is maintained in a fixed-size buffer that is; passed to the `coro.id` intrinsic, which guarantees a certain size; and alignment statically. The same buffer must be passed to the; continuation function(s). The coroutine will allocate memory if the; buffer is insufficient, in which case it will need to store at; least that pointer in the buffer; therefore the buffer must always; be at least pointer-sized. How the coroutine uses the buffer may; vary between suspend points. In addition to the buffer pointer, continuation functions take an; argument indicating whether the coroutine is being resumed normally; (zero) or abnormally (non-zero). LLVM is currently ineffective at statically eliminating allocations; after fully inlining returned-continuation coroutines into a caller.; This may be acceptable if LLVM's coroutine support is primarily being; used for low-level lowering and inlining is expected to be applied; earlier in the pipeline. Async Lowering; --------------. In async-continuation lowering, signaled by the use of `llvm.coro.id.async`,; handling of control-flow must be handled explicitly by the frontend. In this lowering, a coroutine is assumed to take the current `async context` as; one of its arguments (the argument position is determined by; `llvm.coro.id.async`). It is used to marshal arguments and return values of the; coroutine. Therefore an async coroutine returns `void`. .. code-block:: llvm. define swiftcc void @async_coroutine(ptr %async.ctxt, ptr, ptr) {; }. Values live across a suspend point need to be stored in the coroutine frame to; be available in the continuation function. This frame is stored as a tail to the; `async context`. Every suspend point takes an `context projection function` argument which; describes how-to obtain the continuations `async context` and every suspend; point has an associated `resume fun",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:7638,pipeline,pipeline,7638,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['pipeline'],['pipeline']
Deployability," values.; It is possible to print the list of default control parameters using the `ROOT::Math::IntegratorMultiDimOptions::Print` function.; Example:; ```{.cpp}; ROOT::Math::IntegratorMultiDimOptions opt;; opt.Print();; Integrator Type : ADAPTIVE; Absolute tolerance : 1e-09; Relative tolerance : 1e-09; Workspace size : 100000; (max) function calls : 100000; ```; Depending on the algorithm, some of the control parameters might have no effect. #### `ROOT::Math::AdaptiveIntegratorMultiDim`. This class implements an adaptive quadrature integration method for multi dimensional functions. It is described in this paper; *Genz, A.A. Malik, An adaptive algorithm for numerical integration over an N-dimensional rectangular region, J. Comput. Appl. Math. 6 (1980) 295-302*.; It is part of the *MathCore* library.; The user can control the relative and absolute tolerance and the maximum allowed number of function evaluation. #### `ROOT::Math::GSLMCIntegrator`. It is a class for performing numerical integration of a multidimensional function. It uses the numerical integration algorithms of GSL, which reimplements the algorithms used; in the QUADPACK, a numerical integration package written in Fortran. Plain MC, MISER and VEGAS integration algorithms are supported for integration over finite (hypercubic) ranges.; For a detail description of the GSL methods visit the GSL users guide.; Specific configuration options (documented in the GSL user guide) for the `ROOT::Math::GSLMCIntegration` can be set directly in the class, or when using it via the `ROOT::Math::IntegratorMultiDim`; interface, can be defined using the `ROOT::Math::IntegratorMultiDimOptions`. ## Function Derivation. There are in ROOT only two classes to perform numerical derivation. One of them is in the MathCore library while the other is in the MathMore wrapping an integration function from the GSL library.; * RichardsonDerivator: Implements the Richardson method for numerical integration. It can calculate up to the thir",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:61689,integrat,integration,61689,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['integrat'],['integration']
Deployability," variants, the canonical driver name; will be preferred, and the compiler will fall back to the actual name. For example, ``x86_64-pc-linux-gnu-clang-g++`` will attempt to load two; configuration files named respectively::. clang++.cfg; x86_64-pc-linux-gnu.cfg. with fallback to trying::. clang-g++.cfg; x86_64-pc-linux-gnu.cfg. It is not an error if either of these files is not found. The configuration file consists of command-line options specified on one or; more lines. Lines composed of whitespace characters only are ignored as well as; lines in which the first non-blank character is ``#``. Long options may be split; between several lines by a trailing backslash. Here is example of a; configuration file:. ::. # Several options on line; -c --target=x86_64-unknown-linux-gnu. # Long option split between lines; -I/usr/lib/gcc/x86_64-linux-gnu/5.4.0/../../../../\; include/c++/5.4.0. # other config files may be included; @linux.options. Files included by ``@file`` directives in configuration files are resolved; relative to the including file. For example, if a configuration file; ``~/.llvm/target.cfg`` contains the directive ``@os/linux.opts``, the file; ``linux.opts`` is searched for in the directory ``~/.llvm/os``. Another way to; include a file content is using the command line option ``--config=``. It works; similarly but the included file is searched for using the rules for configuration; files. To generate paths relative to the configuration file, the ``<CFGDIR>`` token may; be used. This will expand to the absolute path of the directory containing the; configuration file. In cases where a configuration file is deployed alongside SDK contents, the; SDK directory can remain fully portable by using ``<CFGDIR>`` prefixed paths.; In this way, the user may only need to specify a root configuration file with; ``--config=`` to establish every aspect of the SDK with the compiler:. ::. --target=foo; -isystem <CFGDIR>/include; -L <CFGDIR>/lib; -T <CFGDIR>/ldscripts/link.ld.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:34657,configurat,configuration,34657,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['configurat'],['configuration']
Deployability," vectorized code. The diagram below shows; the CFG for a typical epilogue vectorized loop with runtime checks. As; illustrated the control flow is structured in a way that avoids duplicating the; runtime pointer checks and optimizes the path length for loops that have very; small trip counts. .. image:: epilogue-vectorization-cfg.png. Performance; -----------. This section shows the execution time of Clang on a simple benchmark:; `gcc-loops <https://github.com/llvm/llvm-test-suite/tree/main/SingleSource/UnitTests/Vectorizer>`_.; This benchmarks is a collection of loops from the GCC autovectorization; `page <http://gcc.gnu.org/projects/tree-ssa/vectorization.html>`_ by Dorit Nuzman. The chart below compares GCC-4.7, ICC-13, and Clang-SVN with and without loop vectorization at -O3, tuned for ""corei7-avx"", running on a Sandybridge iMac.; The Y-axis shows the time in msec. Lower is better. The last column shows the geomean of all the kernels. .. image:: gcc-loops.png. And Linpack-pc with the same configuration. Result is Mflops, higher is better. .. image:: linpack-pc.png. Ongoing Development Directions; ------------------------------. .. toctree::; :hidden:. VectorizationPlan. :doc:`VectorizationPlan`; Modeling the process and upgrading the infrastructure of LLVM's Loop Vectorizer. .. _slp-vectorizer:. The SLP Vectorizer; ==================. Details; -------. The goal of SLP vectorization (a.k.a. superword-level parallelism) is; to combine similar independent instructions; into vector instructions. Memory accesses, arithmetic operations, comparison; operations, PHI-nodes, can all be vectorized using this technique. For example, the following function performs very similar operations on its; inputs (a1, b1) and (a2, b2). The basic-block vectorizer may combine these; into vector operations. .. code-block:: c++. void foo(int a1, int a2, int b1, int b2, int *A) {; A[0] = a1*(a1 + b1);; A[1] = a2*(a2 + b2);; A[2] = a1*(a1 + b1);; A[3] = a2*(a2 + b2);; }. The SLP-vectorizer ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:12929,configurat,configuration,12929,interpreter/llvm-project/llvm/docs/Vectorizers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst,1,['configurat'],['configuration']
Deployability," very long; warning messages complaining that some ""``.gnu.linkonce.t.*``"" symbol was; defined in a discarded section. You can safely ignore these messages as they are; erroneous and the linkage is correct. These messages disappear using ld 2.17. **GNU binutils 2.17**: Binutils 2.17 contains `a bug; <http://sourceware.org/bugzilla/show_bug.cgi?id=3111>`__ which causes huge link; times (minutes instead of seconds) when building LLVM. We recommend upgrading; to a newer version (2.17.50.0.4 or later). **GNU Binutils 2.19.1 Gold**: This version of Gold contained `a bug; <http://sourceware.org/bugzilla/show_bug.cgi?id=9836>`__ which causes; intermittent failures when building LLVM with position independent code. The; symptom is an error about cyclic dependencies. We recommend upgrading to a; newer version of Gold. Getting a Modern Host C++ Toolchain; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This section mostly applies to Linux and older BSDs. On macOS, you should; have a sufficiently modern Xcode, or you will likely need to upgrade until you; do. Windows does not have a ""system compiler"", so you must install either Visual; Studio 2019 (or later), or a recent version of mingw64. FreeBSD 10.0 and newer; have a modern Clang as the system compiler. However, some Linux distributions and some other or older BSDs sometimes have; extremely old versions of GCC. These steps attempt to help you upgrade you; compiler even on such a system. However, if at all possible, we encourage you; to use a recent version of a distribution with a modern system compiler that; meets these requirements. Note that it is tempting to install a prior; version of Clang and libc++ to be the host compiler, however libc++ was not; well tested or set up to build on Linux until relatively recently. As; a consequence, this guide suggests just using libstdc++ and a modern GCC as the; initial host in a bootstrap, and then using Clang (and potentially libc++). The first step is to get a recent GCC toolchain installe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:15061,upgrade,upgrade,15061,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['upgrade'],['upgrade']
Deployability," view. Our goal is to take advantage of tight; integration between the linker and the optimizer by sharing this information; during various linking phases. Phase 1 : Read LLVM Bitcode Files; ---------------------------------. The linker first reads all object files in natural order and collects symbol; information. This includes native object files as well as LLVM bitcode files.; To minimize the cost to the linker in the case that all .o files are native; object files, the linker only calls ``lto_module_create()`` when a supplied; object file is found to not be a native object file. If ``lto_module_create()``; returns that the file is an LLVM bitcode file, the linker then iterates over the; module using ``lto_module_get_symbol_name()`` and; ``lto_module_get_symbol_attribute()`` to get all symbols defined and referenced.; This information is added to the linker's global symbol table. The lto* functions are all implemented in a shared object libLTO. This allows; the LLVM LTO code to be updated independently of the linker tool. On platforms; that support it, the shared object is lazily loaded. Phase 2 : Symbol Resolution; ---------------------------. In this stage, the linker resolves symbols using global symbol table. It may; report undefined symbol errors, read archive members, replace weak symbols, etc.; The linker is able to do this seamlessly even though it does not know the exact; content of input LLVM bitcode files. If dead code stripping is enabled then the; linker collects the list of live symbols. Phase 3 : Optimize Bitcode Files; --------------------------------. After symbol resolution, the linker tells the LTO shared object which symbols; are needed by native object files. In the example above, the linker reports; that only ``foo1()`` is used by native object files using; ``lto_codegen_add_must_preserve_symbol()``. Next the linker invokes the LLVM; optimizer and code generators using ``lto_codegen_compile()`` which returns a; native object file creating by ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:6280,update,updated,6280,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['update'],['updated']
Deployability," warranted.; * If you break a buildbot in a way which can't be quickly fixed, please revert.; * If a test case that demonstrates a problem is reported in the commit thread,; please revert and investigate offline.; * If you receive substantial :ref:`post-commit review <post_commit_review>`; feedback, please revert and address said feedback before recommitting.; (Possibly after another round of review.); * If you are asked to revert by another contributor, please revert and discuss; the merits of the request offline (unless doing so would further destabilize; tip of tree). When should you revert someone else's change?. * In general, if the author themselves would revert the change per these; guidelines, we encourage other contributors to do so as a courtesy to the; author. This is one of the major cases where our norms differ from others;; we generally consider reverting a normal part of development. We don't; expect contributors to be always available, and the assurance that a; problematic patch will be reverted and we can return to it at our next; opportunity enables this. What are the expectations around a revert?. * Use your best judgment. If you're uncertain, please start an email on; the commit thread asking for assistance. We aren't trying to enumerate; every case, but rather give a set of guidelines.; * You should be sure that reverting the change improves the stability of tip; of tree. Sometimes reverting one change in a series can worsen things; instead of improving them. We expect reasonable judgment to ensure that; the proper patch or set of patches is being reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Wh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:20555,patch,patch,20555,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['patch'],['patch']
Deployability," welcome and appreciate such contributions!; This short guide tries to make contributing as quick and painless as possible. > [!NOTE]; > These guidelines should be applicable to most contributes. At the same time, these are not 'one-size-fits-all' rules,; > and there might be cases where diverging from these guidelines is warranted. If you are unsure about how to structure; > your contribution, don't hesitate to reach out! We are always happy to provide help and feedback. ## Your Code Contribution. The source code for ROOT is kept in [GitHub](https://github.com/root-project/root).; Changes go through pull requests (""PRs"").; The primary branch for development is `master`. > [!IMPORTANT]; > We require PRs to cleanly apply to master without a merge commit, i.e. through ""fast-forward"".; > Please follow the [coding conventions](https://root.cern.ch/coding-conventions), as this is a simple item for; > reviewers to otherwise get stuck on.; > To make your (and our own) life easier, we provide a; > [`clang-format` configuration file](https://github.com/root-project/root/blob/master/.clang-format). By providing code, you agree to transfer your copyright on the code to the ""ROOT project"".; Of course you will be duly credited: for sizable contributions your name will appear in the; [CREDITS](https://raw.githubusercontent.com/root-project/root/master/README/CREDITS); file shipped with every binary and source distribution.; The copyright transfer helps us with effectively defending the project in case of litigation. ## Your Commit. Each commit is a self-contained, _atomic_ change. This means that:; 1. **Each commit should be able to successfully build ROOT.**; Doing so makes traveling through the git history, for example during a `git bisect` much easier.; Ideally, the commit also should not depend on other commits to _run_ ROOT.; 2. **Each commit does not contain more than one independent change.**; This allows us to revert changes when needed, without affecting anything else. > ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/CONTRIBUTING.md:1119,configurat,configuration,1119,CONTRIBUTING.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/CONTRIBUTING.md,1,['configurat'],['configuration']
Deployability," well as the; binaries to be compiled with ASLR. In the event one of those assumptions is; incorrect, the security will be greatly reduced. Scudo further randomizes how; blocks are allocated in the Primary, can randomize how caches are assigned to; threads. Memory reclaiming; -----------------; Primary and Secondary allocators have different behaviors with regard to; reclaiming. While Secondary mapped allocations can be unmapped on deallocation,; it isn't the case for the Primary, which could lead to a steady growth of the; RSS of a process. To counteract this, if the underlying OS allows it, pages; that are covered by contiguous free memory blocks in the Primary can be; released: this generally means they won't count towards the RSS of a process and; be zero filled on subsequent accesses). This is done in the deallocation path,; and several options exist to tune this behavior. Usage; =====. Platform; --------; If using Fuchsia or an Android version greater than 11, your memory allocations; are already service by Scudo (note that Android Svelte configurations still use; jemalloc). Library; -------; The allocator static library can be built from the LLVM tree thanks to the; ``scudo_standalone`` CMake rule. The associated tests can be exercised thanks to; the ``check-scudo_standalone`` CMake rule. Linking the static library to your project can require the use of the; ``whole-archive`` linker flag (or equivalent), depending on your linker.; Additional flags might also be necessary. Your linked binary should now make use of the Scudo allocation and deallocation; functions. You may also build Scudo like this:. .. code:: console. cd $LLVM/compiler-rt/lib; clang++ -fPIC -std=c++17 -msse4.2 -O2 -pthread -shared \; -I scudo/standalone/include \; scudo/standalone/*.cpp \; -o $HOME/libscudo.so. and then use it with existing binaries as follows:. .. code:: console. LD_PRELOAD=$HOME/libscudo.so ./a.out. Clang; -----; With a recent version of Clang (post rL317337), the ""old"" versi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:5692,configurat,configurations,5692,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['configurat'],['configurations']
Deployability," when the start time is within 1; second.; Fix worker name in TSlaveLite.; Fix problem with enabling packages with option 'notOnClient' in; PROOF-Lite .; Make sure the log file is flushed at the end of startup to avoid; spurious log messages on next commands .; In CreateSession(), fix an issue with the validity check for existing; sessions .; In TProofLite: fix problem with passing the 'varexp' and 'selection'; strings for processing, preventing correct usage of the operators '|'; and '||' in TTreeFormula.; In the TProofOutputFile constructor, remove the 'localroot' prefix; only if present in the path. Fixes possible truncation problems; occuring when the paths are not under the localroot scope.; In TXSocket and TXSlave: fix problem with the way collection over a; socket just marked as 'bad' was interrupted; the interrupt was de facto; ineffective, so that collection stayed always until the timeout expired; (default: 5 minutes). Should solve some of the cases were slow response; was experienced.; Fix a problem with log path transmission when the node dies early or; not even starts. The log path was empty and wrong was filled in when; retrieving the log buffers, disorienting debugging.; Fix a bug checking the first event which rendered ineffective the; request for processing a subset of events in a given dataset or; chain.; In pq2-ana-dist, fix problem with the labels of the distribution; histo occuring when machines are represented by IPs instead of; names.; Add missing calls to closedir() and TSystem::FreeDirectory, cuasing a; large number of filedescriptors remaining opened after xproofd; initialization.; Fix a problem with the final update of the progress information; affecting occasionally cases with skipped events.; Fix merging of TproofOutputFile when using submergers (the; intermediate files were not correctly handled).; Fix the way TChain weights are transmitted to TProofDraw in; DrawSelect operations. AoB; ; The class TFileMerger has been moved to 'io/io'. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:7742,update,update,7742,proof/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html,1,['update'],['update']
Deployability," when we; have a condition it is. .. code-block:: c++. void foo(int arg1,; double arg2) noexcept;. void bar(int arg1, double arg2); noexcept(noexcept(baz(arg1)) &&; noexcept(baz(arg2)));. * ``BBNSS_Always`` (in configuration: ``Always``); Line breaks are allowed. But note that because of the associated; penalties ``clang-format`` often prefers not to break before the; ``noexcept``. .. code-block:: c++. void foo(int arg1,; double arg2) noexcept;. void bar(int arg1, double arg2); noexcept(noexcept(baz(arg1)) &&; noexcept(baz(arg2)));. .. _AllowShortBlocksOnASingleLine:. **AllowShortBlocksOnASingleLine** (``ShortBlockStyle``) :versionbadge:`clang-format 3.5` :ref:`¶ <AllowShortBlocksOnASingleLine>`; Dependent on the value, ``while (true) { continue; }`` can be put on a; single line. Possible values:. * ``SBS_Never`` (in configuration: ``Never``); Never merge blocks into a single line. .. code-block:: c++. while (true) {; }; while (true) {; continue;; }. * ``SBS_Empty`` (in configuration: ``Empty``); Only merge empty blocks. .. code-block:: c++. while (true) {}; while (true) {; continue;; }. * ``SBS_Always`` (in configuration: ``Always``); Always merge short blocks into a single line. .. code-block:: c++. while (true) {}; while (true) { continue; }. .. _AllowShortCaseLabelsOnASingleLine:. **AllowShortCaseLabelsOnASingleLine** (``Boolean``) :versionbadge:`clang-format 3.6` :ref:`¶ <AllowShortCaseLabelsOnASingleLine>`; If ``true``, short case labels will be contracted to a single line. .. code-block:: c++. true: false:; switch (a) { vs. switch (a) {; case 1: x = 1; break; case 1:; case 2: return; x = 1;; } break;; case 2:; return;; }. .. _AllowShortCompoundRequirementOnASingleLine:. **AllowShortCompoundRequirementOnASingleLine** (``Boolean``) :versionbadge:`clang-format 18` :ref:`¶ <AllowShortCompoundRequirementOnASingleLine>`; Allow short compound requirement on a single line. .. code-block:: c++. true:; template <typename T>; concept c = requires(T x) {; { x + 1 } -> st",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:27195,configurat,configuration,27195,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," where you will enter the patch number of the parent patch; (or patches). The patch number is of the form D<number> and you can find it by; looking at the URL for the review e.g. reviews.llvm/org/D12345.; * Click ""Save Parent Revisions"" after entering them.; * You should now see a ""Stack"" tab in the ""Revision Contents"" section of the web; interface, showing the parent patch that you added. Repeat this with each previous review until you reach the first in the series. This; one won't have a parent since it's the start of the series. If you prefer to start with the first in the series and go forward, you can use the; ""Edit Child Revisions"" option instead. .. _using-patch-summaries:. Using patch summaries; ^^^^^^^^^^^^^^^^^^^^^. This applies to new and existing reviews, uploaded with `arc` or the web interface. * Upload the first review and note its patch number, either with the web interface; or `arc`.; * For each commit after that, add the following line to the commit message or patch; summary: ""Depends on D<num>"", where ""<num>"" is the patch number of the previous review.; This must be entirely on its own line, with a blank line before it.; For example::. [llvm] Example commit. Depends on D12345. * If you want a single review to have multiple parent reviews then; add more with ""and"", for example: ""Depends on D12344 and D12345"".; * Upload the commit with the web interface or `arc`; (``arc diff --verbatim`` to update an existing review).; * You will see a ""Stack"" tab in the ""Revision Contents"" section of the review; in the web interface, showing the parent review.; * Repeat these steps until you've uploaded or updated all the patches in; your series. When you push the patches, please remove the ""Depends on"" lines from the; commit messages, since they add noise and duplicate git's implicit ordering. One frequently used workflow for creating a series of patches using patch summaries; is based on git's rebasing. These steps assume that you have a series of commits that; y",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst:6782,patch,patch,6782,interpreter/llvm-project/llvm/docs/Phabricator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst,2,['patch'],['patch']
Deployability," which [can be more readable] for longer links since; it disrupts the flow less. You can put the `[link name]: <URL>` block; pretty much anywhere later in the document. [can be more readable]: http://en.wikipedia.org/wiki/LLVM. Lists can be made like this:. 1. A list starting with `[0-9].` will be automatically numbered. 1. This is a second list element. 1. Use indentation to create nested lists. You can also use unordered lists. * Stuff. + Deeper stuff. * More stuff. #### Example Subsubsection. You can make blocks of code like this:. ```; int main() {; return 0;; }; ```. As an extension to markdown, you can also specify a highlighter to use. ``` C++; int main() {; return 0;; }; ```. For a shell session, use a `console` code block. ```console; $ echo ""Goodbye cruel world!""; $ rm -rf /; ```. If you need to show LLVM IR use the `llvm` code block. ``` llvm; define i32 @test1() {; entry:; ret i32 0; }; ```. Some other common code blocks you might need are `c`, `objc`, `make`,; and `cmake`. If you need something beyond that, you can look at the [full; list] of supported code blocks. [full list]: http://pygments.org/docs/lexers/. However, don't waste time fiddling with syntax highlighting when you could; be adding meaningful content. When in doubt, show preformatted text; without any syntax highlighting like this:. .; +:.; ..:: ::; .++:+:: ::+:.:.; .:+ :; ::.::..:: .+.; ..:+ :: :; ......+:. ..; :++. .. :; .+:::+:: :; .. . .+ ::; +.: .::+.; ...+. .: .; .++:..; ... ##### Hopefully you won't need to be this deep. If you need to do fancier things than what has been shown in this document,; you can mail the list or check the [Common Mark spec]. Sphinx specific; integration documentation can be found in the [myst-parser docs]. [Common Mark spec]: http://spec.commonmark.org/0.28/; [myst-parser docs]: https://myst-parser.readthedocs.io/en/latest/. ## Generating the documentation. see [Sphinx Quickstart Template](project:SphinxQuickstartTemplate.rst#Generating the documentation); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MarkdownQuickstartTemplate.md:4287,integrat,integration,4287,interpreter/llvm-project/llvm/docs/MarkdownQuickstartTemplate.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MarkdownQuickstartTemplate.md,1,['integrat'],['integration']
Deployability," which libraries were related and belonged; together. In the new structure we've added a set of meta directories; that are used to group the sources of related libraries, and that also; reflects the ROOT team work package structure.; Note, the name and number of libraries has not been changed.; This new structure also facilitates the maintaining of the release notes; and other documentation items per meta package. On Linux, MacOS X and Windows, there is no need anymore to define the; environment variable ROOTSYS. Internally ROOTSYS is set depending on the; location of the ROOT libraries. ROOTSYS was never needed when ROOT was; configured using --prefix. On MacOS X when configure'ing with --enable-rpath (and not specifying; --prefix) the installation does not need (DY)LD_LIBRARY_PATH to be set; anymore. The installation is completely relocatable. The (DY)LD_LIBRARY_PATH; is determined relative to the location of the root executable. On Windows .root files are now associated with the most recently executed; ROOT installation, i.e. run ROOT once and .root files open with ROOT. Class TMessageHandler derives now from TQObject and does emit signals.; This allows for easier usage of this class. In this release xrootd and libAfterImage are managed in Subversion; via so called ""vendor branches"". This is completely transparent; except for people who do directly use svn. You will get the message:. $ svn up; svn: Failed to add directory 'xrootd/src/xrootd': object of the same name already exists; $ rm -rf xrootd/src/xrootd; $ svn up; svn: Failed to add directory 'asimage/src/libAfterImage': object of the same name already exists; $ rm -rf asimage/src/libAfterImage; $ svn up. Port to gcc 4.3.1. This version of gcc is much stricker with respect to; implicit header files so in many source files <stdlib.h> and <string.h>; had to be added. TPRegexp. Modularized Match() and Substitute() functions so that the low-level work; is done by MatchInternal() and SubstituteInternal(). Added f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v520/index.html:1283,install,installation,1283,core/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v520/index.html,1,['install'],['installation']
Deployability," which might cause an object to be deallocated; before it would otherwise be. Without this, it would be almost; impossible to eliminate any ``retain``/``release`` pairs. For; example, consider the following code:. .. code-block:: objc. id x = _ivar;; [x foo];. If we were not permitted in any event to shorten the lifetime of the; object in ``x``, then we would not be able to eliminate this retain; and release unless we could prove that the message send could not; modify ``_ivar`` (or deallocate ``self``). Since message sends are; opaque to the optimizer, this is not possible, and so ARC's hands; would be almost completely tied. ARC makes no guarantees about the execution of a computation history; which contains undefined behavior. In particular, ARC makes no; guarantees in the presence of race conditions. ARC may assume that any retainable object pointers it receives or; generates are instantaneously valid from that point until a point; which, by the concurrency model of the host language, happens-after; the generation of the pointer and happens-before a release of that; object (possibly via an aliasing pointer or indirectly due to; destruction of a different object). .. admonition:: Rationale. There is very little point in trying to guarantee correctness in the; presence of race conditions. ARC does not have a stack-scanning; garbage collector, and guaranteeing the atomicity of every load and; store operation would be prohibitive and preclude a vast amount of; optimization. ARC may assume that non-ARC code engages in sensible balancing; behavior and does not rely on exact or minimum retain count values; except as guaranteed by ``__strong`` object invariants or +1 transfer; conventions. For example, if an object is provably double-retained; and double-released, ARC may eliminate the inner retain and release;; it does not need to guard against code which performs an unbalanced; release followed by a ""balancing"" retain. .. _arc.optimization.liveness:. Object liveness; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:77752,release,release,77752,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['release']
Deployability," which this document does not discuss. Requirements; ============; Before you begin to use the LLVM system, review the requirements given; below. This may save you some trouble by knowing ahead of time what hardware; and software you will need. Hardware; --------; Any system that can adequately run Visual Studio 2019 is fine. The LLVM; source tree including the git index consumes approximately 3GB.; Object files, libraries and executables consume approximately 5GB in; Release mode and much more in Debug mode. SSD drive and >16GB RAM are; recommended. Software; --------; You will need `Visual Studio <https://visualstudio.microsoft.com/>`_ 2019 or; later, with the latest Update installed. Visual Studio Community Edition; suffices. You will also need the `CMake <http://www.cmake.org/>`_ build system since it; generates the project files you will use to build with. CMake is bundled with; Visual Studio 2019 so separate installation is not required. If you do install; CMake separately, Visual Studio 2022 will require CMake Version 3.21 or later. If you would like to run the LLVM tests you will need `Python; <http://www.python.org/>`_. Version 3.6 and newer are known to work. You can; install Python with Visual Studio 2019, from the Microsoft store or from; the `Python web site <http://www.python.org/>`_. We recommend the latter since it; allows you to adjust installation options. You will need `Git for Windows <https://git-scm.com/>`_ with bash tools, too.; Git for Windows is also bundled with Visual Studio 2019. Getting Started; ===============; Here's the short story for getting up and running quickly with LLVM.; These instruction were tested with Visual Studio 2019 and Python 3.9.6:. 1. Download and install `Visual Studio <https://visualstudio.microsoft.com/>`_.; 2. In the Visual Studio installer, Workloads tab, select the; **Desktop development with C++** workload. Under Individual components tab,; select **Git for Windows**.; 3. Complete the Visual Studio installatio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst:2149,install,install,2149,interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,1,['install'],['install']
Deployability," while using ``noduplicate`` would disallow this. Also ``noduplicate`` doesn't; have the same safe semantics of CFG as ``convergent`` and can cause changes in; CFG that modify semantics of the original program. ``noduplicate`` is kept for backwards compatibility only and it considered to be; deprecated for future uses. .. _cxx_for_opencl:. C++ for OpenCL; --------------. Starting from clang 9 kernel code can contain C++17 features: classes, templates,; function overloading, type deduction, etc. Please note that this is not an; implementation of `OpenCL C++; <https://www.khronos.org/registry/OpenCL/specs/2.2/pdf/OpenCL_Cxx.pdf>`_ and; there is no plan to support it in clang in any new releases in the near future. Clang currently supports C++ for OpenCL 1.0 and 2021.; For detailed information about this language refer to the C++ for OpenCL; Programming Language Documentation available; in `the latest build; <https://www.khronos.org/opencl/assets/CXX_for_OpenCL.html>`_; or in `the official release; <https://github.com/KhronosGroup/OpenCL-Docs/releases/tag/cxxforopencl-docrev2021.12>`_. To enable the C++ for OpenCL mode, pass one of following command line options when; compiling ``.clcpp`` file:. - C++ for OpenCL 1.0: ``-cl-std=clc++``, ``-cl-std=CLC++``, ``-cl-std=clc++1.0``,; ``-cl-std=CLC++1.0``, ``-std=clc++``, ``-std=CLC++``, ``-std=clc++1.0`` or; ``-std=CLC++1.0``. - C++ for OpenCL 2021: ``-cl-std=clc++2021``, ``-cl-std=CLC++2021``,; ``-std=clc++2021``, ``-std=CLC++2021``. Example of use:; .. code-block:: c++. template<class T> T add( T x, T y ); {; return x + y;; }. __kernel void test( __global float* a, __global float* b); {; auto index = get_global_id(0);; a[index] = add(b[index], b[index+1]);; }. .. code-block:: console. clang -cl-std=clc++1.0 test.clcpp; clang -cl-std=clc++ -c --target=spirv64 test.cl. By default, files with ``.clcpp`` extension are compiled with the C++ for; OpenCL 1.0 mode. .. code-block:: console. clang test.clcpp. For backward compatibili",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:152865,release,release,152865,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['release'],['release']
Deployability," will have one line each. .. code-block:: c++. true:; void f(int aaaaaaaaaaaaaaaaaaaa, int aaaaaaaaaaaaaaaaaaaa,; int aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa) {}. false:; void f(int aaaaaaaaaaaaaaaaaaaa,; int aaaaaaaaaaaaaaaaaaaa,; int aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa) {}. .. _BitFieldColonSpacing:. **BitFieldColonSpacing** (``BitFieldColonSpacingStyle``) :versionbadge:`clang-format 12` :ref:`¶ <BitFieldColonSpacing>`; The BitFieldColonSpacingStyle to use for bitfields. Possible values:. * ``BFCS_Both`` (in configuration: ``Both``); Add one space on each side of the ``:``. .. code-block:: c++. unsigned bf : 2;. * ``BFCS_None`` (in configuration: ``None``); Add no space around the ``:`` (except when needed for; ``AlignConsecutiveBitFields``). .. code-block:: c++. unsigned bf:2;. * ``BFCS_Before`` (in configuration: ``Before``); Add space before the ``:`` only. .. code-block:: c++. unsigned bf :2;. * ``BFCS_After`` (in configuration: ``After``); Add space after the ``:`` only (space may be added before if; needed for ``AlignConsecutiveBitFields``). .. code-block:: c++. unsigned bf: 2;. .. _BraceWrapping:. **BraceWrapping** (``BraceWrappingFlags``) :versionbadge:`clang-format 3.8` :ref:`¶ <BraceWrapping>`; Control of individual brace wrapping cases. If ``BreakBeforeBraces`` is set to ``BS_Custom``, use this to specify how; each individual brace case should be handled. Otherwise, this is ignored. .. code-block:: yaml. # Example of usage:; BreakBeforeBraces: Custom; BraceWrapping:; AfterEnum: true; AfterStruct: false; SplitEmptyFunction: false. Nested configuration flags:. Precise control over the wrapping of braces. .. code-block:: c++. # Should be declared this way:; BreakBeforeBraces: Custom; BraceWrapping:; AfterClass: true. * ``bool AfterCaseLabel`` Wrap case labels. .. code-block:: c++. false: true:; switch (foo) { vs. switch (foo) {; case 1: { case 1:; bar(); {; break; bar();; } break;; default: { }; plop(); default:; } {; } plop();; }; }. * ``bool A",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:38115,configurat,configuration,38115,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-devel```, re-compile Python and ```configure```; will automatically link against the required libraries and produce a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up with your correct fingerprint. These; credentials are needed to sign the Debian package and create Debian changelogs.; On a build machine (Electric Commander), make sure the fingerprint is of the; user who is supposed to sign the official uploads. You might also want to; configure GnuPG to not ask for the passphrase while signing the Debian package. The [Ubuntu Packaging Guide] contains a quick guide on creating a GPG key on an; Ubuntu system. To test if you have successfully set up your GnuPG key, use the following command:; ```sh; gpg --fingerprint; ```; Again, all these checks are performed by default when you launch CPT with ```-c``` option.; [Ubuntu Packaging Guide]:http://packaging.ubuntu.com/html/getting-set-up.html#create-your-gpg-key. #### Wi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:2522,install,install,2522,interpreter/cling/tools/packaging/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md,3,"['install', 'update']","['install', 'update']"
Deployability," with a **`TFile`** containing two; **`TTree`**s: one for the signal, the other for the background, a; simple script is used:. ``` {.cpp}; void mlpHiggs(Int_t ntrain=100) {; if (!gROOT->GetClass(""TMultiLayerPerceptron"")); gSystem->Load(""libMLP"");; // prepare inputs - the 2 trees are merged into one, and a; // ""type"" branch, equal to 1 for the signal and 0 for the; // background is added; TFile input(""mlpHiggs.root"");; TTree *signal = (TTree *)input.Get(""sig_filtered"");; TTree *background = (TTree *)input.Get(""bg_filtered"");; TTree *simu = new TTree(""MonteCarlo"",; ""Filtered Monte Carlo Events"");; ...; ```. Since the input is a **`TTree`** and we are starting from two; different **`TTree`**s (with different names), they are first merged; into one, and a ""`type`"" branch is added, that says whether there is; a signal or a background event. Those irrelevant details are skipped; here. ``` {.cpp}; ...; TMultiLayerPerceptron *mlp = new TMultiLayerPerceptron(; ""msumf,ptsumf, acolin, acopl:8:type"",""ptsumf"",simu,; ""Entry$%2"",""Entry$/2"");; mlp->Train(ntrain, ""text,graph,update=10"");; ```. The neural network is instantiated and trained. ""`ptsumf`"" is used as; a weight, and the standard event lists are explicit. The network that; is then build has four input neurons, eight additional ones in the; only hidden layer and one single output neuron. ``` {.cpp}; // Use the NN to plot the results for each sample; TH1F *bg = new TH1F(""bgh"",""NN output"",50,-.5,1.5);; TH1F *sig = new TH1F(""sigh"",""NN output"",50,-.5,1.5);; bg->SetDirectory(0);; sig->SetDirectory(0);; Double_t params[4];; for (i = 0; i < background->GetEntries(); i++) {; background->GetEntry(i);; params[0] = msumf; params[1] = ptsumf;; params[2] = acolin; params[3] = acopl;; bg->Fill(mlp->Evaluate(0,params));; }; for (i = 0; i < signal->GetEntries(); i++) {; signal->GetEntry(i);; params[0] = msumf;; params[1] = ptsumf;; params[2] = acolin;; params[3] = acopl;; sig->Fill(mlp->Evaluate(0,params));; }; TCanvas *cv = new TCanvas(""N",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:78929,update,update,78929,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['update'],['update']
Deployability," with respect; to the parameters.; This information might be useful for some types of fits. In this case he needs to provide the function object as a class deriving from the; `ROOT::Math::IParametricGradFunctionMultiDim` interface.; Note that the wrapper class `ROOT::Math::WrappedMultiTF1` implements also the gradient interface, using internally `TF1::GradientPar`,; which is based on numerical differentiation, apart for the case of linear functions (i.e. when `TF1::IsLinear()` is `true`).; The parameter derivatives of the model function can be useful to some minimization algorithms, such as Fumili.; However, in general is better to leave the minimization algorithm (e.g. Minuit) to compute the needed derivatives using its own customised; numerical differentiation algorithm.; In order to not provide to the fitter the parameter derivatives, we explicitly passed in `Fitter::SetFunction` a `false` value. ### Fit Configuration. The configuration of the fit is done via the `ROOT::Fit::FitConfig` class and its contained `ROOT::Fit::ParameterSettings` class.; These are the possible allowed fit configurations:. - setting the initial values of the parameters;; - setting the parameter step sizes;; - setting eventual parameter bounds;; - setting the minimizer library and the particular algorithm to use;; - setting different minimization options (print level, tolerance, max iterations, etc...); - setting the type of parameter errors to compute (parabolic error, Minos errors, re-normalize errors using fitted chi2 values). The initial parameter values can be set directly in the input model function object.; However, for setting parameter bounds and step sizes to values different than the automatically computed ones, one needs to use the `ROOT::Fit::ParameterSetting` class.; This example code will set the lower/upper bounds for the first parameter and a lower bound for the second parameter. ``` {.cpp}; fitter.SetFunction( fitFunction, false);; fitter.Config().ParSettings(0).SetLimit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:38252,configurat,configuration,38252,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['configurat'],['configuration']
Deployability," with this bit set; cannot add friend trees nor can be added as friends, unless the friend `TTree` has an appropriate `TTreeIndex`. ## Histogram Libraries. ## Math Libraries. ## RooFit Libraries. ### RooWorkspace::Import() for Python; `RooWorkspace.import()` cannot be used in Python, since it is a reserved keyword. Users therefore had to resort; to; getattr(workspace, 'import')(...); Now,; workspace.Import(...); has been defined for the new PyROOT, which makes calling the function easier. ### Modernised category classes; RooFit's categories were modernised. Previously, the class RooCatType was used to store category states. It stores; two members, an integer for the category index, and up to 256 characters for a category name. Now, such states are; stored only using an integer, and category names can have arbitrary length. This will use 4 instead of 288 bytes; per category entry in a dataset, and make computations that rely on category states faster. The interface to define or manipulate category states was also updated. Since categories are mappings from state names; to state index, this is now reflected in the interface. Among others, this is now possible:; | ROOT 6.22 | Before (still supported) |; |------------------------------------------------|----------------------------------------------------------------|; | `RooCategory cat(""cat"", ""Lepton flavour"");` | `RooCategory cat(""cat"", ""Lepton flavour"");` |; | `cat[""electron""] = 1;` | `cat.defineType(""electron"", 1);` |; | `cat[""muon""] = 2;` | `cat.defineType(""muon"", 2);` |. See also [Category reference guide](https://root.cern.ch/doc/master/classRooCategory.html). ### Type-safe proxies for RooFit objects; RooFit's proxy classes have been modernised. The class `RooTemplateProxy` allows for access to other RooFit objects; similarly to a smart pointer. In older versions of RooFit, the objects held by *e.g.* `RooRealProxy` had to be; accessed like this:; RooAbsArg* absArg = realProxy.absArg();; RooAbsPdf* pdf = dynamic_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v622/index.md:3455,update,updated,3455,README/ReleaseNotes/v622/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v622/index.md,1,['update'],['updated']
Deployability," you are; implementing, you just override the interfaces you can improve. .. _aliasanalysis-chaining:. ``AliasAnalysis`` chaining behavior; -----------------------------------. Every alias analysis pass chains to another alias analysis implementation (for; example, the user can specify ""``-basic-aa -ds-aa -licm``"" to get the maximum; benefit from both alias analyses). The alias analysis class automatically; takes care of most of this for methods that you don't override. For methods; that you do override, in code paths that return a conservative MayAlias or; Mod/Ref result, simply return whatever the superclass computes. For example:. .. code-block:: c++. AliasResult alias(const Value *V1, unsigned V1Size,; const Value *V2, unsigned V2Size) {; if (...); return NoAlias;; ... // Couldn't determine a must or no-alias result.; return AliasAnalysis::alias(V1, V1Size, V2, V2Size);; }. In addition to analysis queries, you must make sure to unconditionally pass LLVM; `update notification`_ methods to the superclass as well if you override them,; which allows all alias analyses in a change to be updated. .. _update notification:. Updating analysis results for transformations; ---------------------------------------------. Alias analysis information is initially computed for a static snapshot of the; program, but clients will use this information to make transformations to the; code. All but the most trivial forms of alias analysis will need to have their; analysis results updated to reflect the changes made by these transformations. The ``AliasAnalysis`` interface exposes four methods which are used to; communicate program changes from the clients to the analysis implementations.; Various alias analysis implementations should use these methods to ensure that; their internal data structures are kept up-to-date as the program changes (for; example, when an instruction is deleted), and clients of alias analysis must be; sure to call these interfaces appropriately. The ``deleteVal",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:13486,update,update,13486,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,2,['update'],"['update', 'updated']"
Deployability," you can also get objects with names that don't qualify as a Python variable. Here is a short demo:; ```python; import ROOT. with ROOT.TFile.Open(""my_file.root"", ""RECREATE"") as my_file:. # Populate the TFile with simple objects.; my_file.WriteObject(ROOT.std.string(""hello world""), ""my_string""); my_file.WriteObject(ROOT.vector[""int""]([1, 2, 3]), ""my vector""). print(my_file[""my_string""]) # new syntax; print(my_file.my_string) # old deprecated syntax. # With the dictionary syntax, you can also use names that don't qualify as; # a Python variable:; print(my_file[""my vector""]); # print(my_file.my vector) # the old syntax would not work here!; ```. The old pythonization with the `__getattr__` syntax still works, but emits a deprecation warning and will be removed from ROOT 6.34. ### Removal of Python 2 support. ROOT does no longer support Python 2. The minimum Python version necessary to use ROOT in a Python application is 3.8.; As a consequence, any reference to Python 2 in ROOT code was removed and certain configuration options are no longer; usable, e.g. * `root-config --python2-version`; * cmake -Dpyroot-python2. The cmake build system now looks for the standard `Python3` package and previously custom Python-related cmake variables; are now just the ones automatically produced by cmake (see https://cmake.org/cmake/help/latest/module/FindPython.html). ### More usage of the public cppyy API. Many implementation details of the ROOT pythonizations were moved from C++ functions to pure Python bindings using the; public cppyy API. This helps in the integration with the tool but also improves code efficiency and memory usage. ## Class Reference Guide. - Define missing doxygen groups.; - Fix a few typos in the `THStack` documentation.; - Small fixes in the `THistPainter` documentation.; - Improve the `TColor` documentation: use modern C++ in the examples.; - Make sure the python examples do not generate wrong namespaces in the documentation.; - The dataframe tutorials json sp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:22645,configurat,configuration,22645,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['configurat'],['configuration']
Deployability," you're compiling 64-bit code for; the host, you're also compiling 64-bit code for the device.) Note that as of; v10.0 CUDA SDK `no longer supports compilation of 32-bit; applications <https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#deprecated-features>`_. * ``<GPU arch>`` -- the `compute capability; <https://developer.nvidia.com/cuda-gpus>`_ of your GPU. For example, if you; want to run your program on a GPU with compute capability of 3.5, specify; ``--cuda-gpu-arch=sm_35``. Note: You cannot pass ``compute_XX`` as an argument to ``--cuda-gpu-arch``;; only ``sm_XX`` is currently supported. However, clang always includes PTX in; its binaries, so e.g. a binary compiled with ``--cuda-gpu-arch=sm_30`` would be; forwards-compatible with e.g. ``sm_35`` GPUs. You can pass ``--cuda-gpu-arch`` multiple times to compile for multiple archs. The `-L` and `-l` flags only need to be passed when linking. When compiling,; you may also need to pass ``--cuda-path=/path/to/cuda`` if you didn't install; the CUDA SDK into ``/usr/local/cuda`` or ``/usr/local/cuda-X.Y``. Flags that control numerical code; ---------------------------------. If you're using GPUs, you probably care about making numerical code run fast.; GPU hardware allows for more control over numerical operations than most CPUs,; but this results in more compiler options for you to juggle. Flags you may wish to tweak include:. * ``-ffp-contract={on,off,fast}`` (defaults to ``fast`` on host and device when; compiling CUDA) Controls whether the compiler emits fused multiply-add; operations. * ``off``: never emit fma operations, and prevent ptxas from fusing multiply; and add instructions.; * ``on``: fuse multiplies and adds within a single statement, but never; across statements (C11 semantics). Prevent ptxas from fusing other; multiplies and adds.; * ``fast``: fuse multiplies and adds wherever profitable, even across; statements. Doesn't prevent ptxas from fusing additional multiplies and; adds. Fused mul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:3765,install,install,3765,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,1,['install'],['install']
Deployability," { if (shouldProcessAttr(A)); handleAttr(A); handleAttr(A);; } }; }; }. if (isa<FunctionDecl>(D)) { vs. if (isa<FunctionDecl>(D)); for (auto *A : D.attrs()) { for (auto *A : D.attrs()); handleAttr(A); handleAttr(A);; }; }. if (auto *D = (T)(D)) { vs. if (auto *D = (T)(D)) {; if (shouldProcess(D)) { if (shouldProcess(D)); handleVarDecl(D); handleVarDecl(D);; } else { else; markAsIgnored(D); markAsIgnored(D);; } }; }. if (a) { vs. if (a); b(); b();; } else { else if (c); if (c) { d();; d(); else; } else { e();; e();; }; }. .. _RemoveParentheses:. **RemoveParentheses** (``RemoveParenthesesStyle``) :versionbadge:`clang-format 17` :ref:`¶ <RemoveParentheses>`; Remove redundant parentheses. .. warning::. Setting this option to any value other than ``Leave`` could lead to; incorrect code formatting due to clang-format's lack of complete semantic; information. As such, extra care should be taken to review code changes; made by this option. Possible values:. * ``RPS_Leave`` (in configuration: ``Leave``); Do not remove parentheses. .. code-block:: c++. class __declspec((dllimport)) X {};; co_return (((0)));; return ((a + b) - ((c + d)));. * ``RPS_MultipleParentheses`` (in configuration: ``MultipleParentheses``); Replace multiple parentheses with single parentheses. .. code-block:: c++. class __declspec(dllimport) X {};; co_return (0);; return ((a + b) - (c + d));. * ``RPS_ReturnStatement`` (in configuration: ``ReturnStatement``); Also remove parentheses enclosing the expression in a; ``return``/``co_return`` statement. .. code-block:: c++. class __declspec(dllimport) X {};; co_return 0;; return (a + b) - (c + d);. .. _RemoveSemicolon:. **RemoveSemicolon** (``Boolean``) :versionbadge:`clang-format 16` :ref:`¶ <RemoveSemicolon>`; Remove semicolons after the closing brace of a non-empty function. .. warning::. Setting this option to ``true`` could lead to incorrect code formatting; due to clang-format's lack of complete semantic information. As such,; extra care should be taken ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:102953,configurat,configuration,102953,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability," | use server in read-only mode (default) |; | readwrite, rw | use server in read-write mode |; | global | let scan global directories for canvases and files (default) |; | noglobal | disable scan of global directories |; | basic_sniffer | use basic `TRootSniffer` without support of hist, gpad, graph, tree classes |. Example:. ```cpp; new THttpServer(""http:8080;ro;noglobal""); ```. ## Registering objects. At any time, one could register other objects with the command:. ```cpp; TGraph* gr = new TGraph(10);; gr->SetName(""gr1"");; serv->Register(""graphs/subfolder"", gr);; ```. One should specify sub-folder name, where objects will be registered.; If sub-folder name does not starts with slash `/`, than top-name folder `/Objects/` will be prepended.; At any time one could unregister objects:. ```cpp; serv->Unregister(gr);; ```. THttpServer does not take ownership over registered objects - they should be deleted by user. If the objects content is changing in the application, one could enable monitoring flag in the browser - then objects view will be regularly updated. ## Accessing file system. THttpServer provides partial access to the files from file system.; First of all, JSROOT scripts and files can be accessed via ""jsrootsys/"" path like ""http://localhost:8080/jsrootsys/modules/core.mjs"".; Files from ROOT install directory can be get via ""rootsys/"" path like ""http://localhost:8080/rootsys/icons/about.xpm"".; Also files from current directory where ROOT is running can be accessed via ""currentdir/"" path like ""http://localhost:8080/currentdir/file.txt"". If necessary, one can add custom path as well, using [THttpServer::AddLocation](https://root.cern/doc/master/classTHttpServer.html#a5322c3bbfddb8eb6849297d83ccaf87f) method:. ```cpp; serv->AddLocation(""mydir/"", ""/home/user/specials"");; ```. Then files from that directory could be addressed via URL like ""http://localhost:8080/mydir/myfile.root"". ## Command interface. THttpServer class provide simple interface to invoke command ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:4036,update,updated,4036,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['update'],['updated']
Deployability," |; | | 1.5 or later recommended. |; +-------------------------+----------------------------------------------------+; | LLVM_BUILD_LLVM_DYLIB | Generate libLLVM.so. This library contains a |; | | default set of LLVM components that can be |; | | overridden with ``LLVM_DYLIB_COMPONENTS``. The |; | | default contains most of LLVM and is defined in |; | | ``tools/llvm-shlib/CMakelists.txt``. This option is|; | | not available on Windows. |; +-------------------------+----------------------------------------------------+; | LLVM_OPTIMIZED_TABLEGEN | Builds a release tablegen that gets used during |; | | the LLVM build. This can dramatically speed up |; | | debug builds. |; +-------------------------+----------------------------------------------------+. To configure LLVM, follow these steps:. #. Change directory into the object root directory:. .. code-block:: console. % cd OBJ_ROOT. #. Run the ``cmake``:. .. code-block:: console. % cmake -G ""Unix Makefiles"" -DCMAKE_BUILD_TYPE=<type> -DCMAKE_INSTALL_PREFIX=/install/path; [other options] SRC_ROOT. Compiling the LLVM Suite Source Code; ------------------------------------. Unlike with autotools, with CMake your build type is defined at configuration.; If you want to change your build type, you can re-run cmake with the following; invocation:. .. code-block:: console. % cmake -G ""Unix Makefiles"" -DCMAKE_BUILD_TYPE=<type> SRC_ROOT. Between runs, CMake preserves the values set for all options. CMake has the; following build types defined:. Debug. These builds are the default. The build system will compile the tools and; libraries unoptimized, with debugging information, and asserts enabled. Release. For these builds, the build system will compile the tools and libraries; with optimizations enabled and not generate debug info. CMakes default; optimization level is -O3. This can be configured by setting the; ``CMAKE_CXX_FLAGS_RELEASE`` variable on the CMake command line. RelWithDebInfo. These builds are useful when debugging.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:28382,install,install,28382,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['install'],['install']
Deployability,"![CivetWeb](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/civetweb_64x64.png ""CivetWeb"") CivetWeb; =======. **The official home of CivetWeb is [https://github.com/civetweb/civetweb](https://github.com/civetweb/civetweb)**. [![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT); [![GitHub contributors](https://img.shields.io/github/contributors/civetweb/civetweb.svg)](https://github.com/civetweb/civetweb/blob/master/CREDITS.md). Continuous integration for Linux and macOS ([Travis CI](https://app.travis-ci.com/github/civetweb/civetweb)):. [![Travis Build Status](https://api.travis-ci.com/civetweb/civetweb.svg?branch=master)](https://app.travis-ci.com/github/civetweb/civetweb). Continuous integration for Windows ([AppVeyor](https://ci.appveyor.com/project/civetweb/civetweb)):. [![Appveyor Build Status](https://ci.appveyor.com/api/projects/status/github/civetweb/civetweb?svg=true)](https://ci.appveyor.com/project/civetweb/civetweb/branch/master). Test coverage check ([coveralls](https://coveralls.io/github/civetweb/civetweb), [codecov](https://codecov.io/gh/civetweb/civetweb/branch/master)) (using different tools/settings):. [![Coveralls](https://img.shields.io/coveralls/civetweb/civetweb.svg?maxAge=3600)](); [![Coverage Status](https://coveralls.io/repos/github/civetweb/civetweb/badge.svg?branch=master)](https://coveralls.io/github/civetweb/civetweb?branch=master). [![codecov](https://codecov.io/gh/civetweb/civetweb/branch/master/graph/badge.svg)](https://codecov.io/gh/civetweb/civetweb). Static source code analysis ([Coverity](https://scan.coverity.com/projects/5784)):. [![Coverity Scan Build Status](https://scan.coverity.com/projects/5784/badge.svg)](https://scan.coverity.com/projects/5784). Project Mission; -----------------. Project mission is to provide easy to use, powerful, C (C/C++) embeddable web server with optional CGI, SSL and Lua support.; CivetWeb has a MIT license so you can innovate wit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:512,integrat,integration,512,net/http/civetweb/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md,2,['integrat'],['integration']
Deployability,""" ""${webassembly_files}""); add_header_target(""x86-resource-headers"" ""${x86_files}""). # Other header groupings; add_header_target(""hlsl-resource-headers"" ${hlsl_files}); add_header_target(""opencl-resource-headers"" ${opencl_files}); add_header_target(""llvm-libc-resource-headers"" ${llvm_libc_wrapper_files}); add_header_target(""openmp-resource-headers"" ${openmp_wrapper_files}); add_header_target(""windows-resource-headers"" ${windows_only_files}); add_header_target(""utility-resource-headers"" ${utility_files}). get_clang_resource_dir(header_install_dir SUBDIR include). #############################################################; # Install rules for the catch-all clang-resource-headers target; install(; FILES ${files} ${generated_files}; DESTINATION ${header_install_dir}; COMPONENT clang-resource-headers). install(; FILES ${cuda_wrapper_files}; DESTINATION ${header_install_dir}/cuda_wrappers; COMPONENT clang-resource-headers). install(; FILES ${cuda_wrapper_bits_files}; DESTINATION ${header_install_dir}/cuda_wrappers/bits; COMPONENT clang-resource-headers). install(; FILES ${ppc_wrapper_files}; DESTINATION ${header_install_dir}/ppc_wrappers; COMPONENT clang-resource-headers). install(; FILES ${llvm_libc_wrapper_files}; DESTINATION ${header_install_dir}/llvm_libc_wrappers; COMPONENT clang-resource-headers). install(; FILES ${openmp_wrapper_files}; DESTINATION ${header_install_dir}/openmp_wrappers; COMPONENT clang-resource-headers). #############################################################; # Install rules for separate header lists; install(; FILES ${core_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT core-resource-headers). install(; FILES ${arm_common_files} ${arm_common_generated_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT arm-common-resource-headers). install(; FILES ${arm_only_files} ${arm_only_generated_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT arm-resource-headers). install(; FILES ${a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt:12335,install,install,12335,interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,1,['install'],['install']
Deployability,""" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:34080,update,update-tags,34080,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['update'],['update-tags']
Deployability,""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. while.end:; %s.final = call i8 @llvm.coro.suspend(token none, i1 true); switch i8 %s.final, label %suspend [i8 0, label %trap; i8 1, label %cleanup]; trap:; call void @llvm.trap(); unreachable. Semantics:; """""""""""""""""""". If a coroutine that was suspended at the suspend point marked by this intrinsic; is resumed via `coro.resume`_ the control will transfer to the basic block; of the 0-case. If it is resumed via `coro.destroy`_, it will proceed to the; basic block indicated by the 1-case. To suspend, coroutine proceed to the; default label. If suspend intrinsic is marked as final, it can consider the `true` branch; unreachable and can perform optimizations that can take advantage of that fact. .. _coro.save:. 'llvm.coro.save' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.save(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.save``' marks the point where a coroutine need to update its; state to prepare for resumption to be considered suspended (and thus eligible; for resumption). It is illegal to merge two '``llvm.coro.save``' calls unless their; '``llvm.coro.suspend``' users are also merged. So '``llvm.coro.save``' is currently; tagged with the `no_merge` function attribute. Arguments:; """""""""""""""""""". The first argument points to a coroutine handle of the enclosing coroutine. Semantics:; """""""""""""""""""". Whatever coroutine state changes are required to enable resumption of; the coroutine from the corresponding suspend point should be done at the point; of `coro.save` intrinsic. Example:; """""""""""""""". Separate save and suspend points are necessary when a coroutine is used to; represent an asynchronous control flow driven by callbacks representing; completions of asynchronous operations. In such a case, a coroutine should be ready for resumption prior to a call to; `async_op` function that may trigger resumption of a coroutine from the same or; a different thread possibly prior to `async_op` cal",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:51866,update,update,51866,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['update'],['update']
Deployability,"""""""""""""""""""""""""""""""""""; Warn about Objective-C method signatures with type incompatibilities. .. code-block:: objc. @interface MyClass1 : NSObject; - (int)foo;; @end. @implementation MyClass1; - (int)foo { return 1; }; @end. @interface MyClass2 : MyClass1; - (float)foo;; @end. @implementation MyClass2; - (float)foo { return 1.0; } // warn; @end. .. _osx-cocoa-Loops:. osx.cocoa.Loops; """"""""""""""""""""""""""""""; Improved modeling of loops using Cocoa collection types. .. _osx-cocoa-MissingSuperCall:. osx.cocoa.MissingSuperCall (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Warn about Objective-C methods that lack a necessary call to super. .. code-block:: objc. @interface Test : UIViewController; @end; @implementation test; - (void)viewDidLoad {} // warn; @end. .. _osx-cocoa-NSAutoreleasePool:. osx.cocoa.NSAutoreleasePool (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Warn for suboptimal uses of NSAutoreleasePool in Objective-C GC mode. .. code-block:: objc. void test() {; NSAutoreleasePool *pool = [[NSAutoreleasePool alloc] init];; [pool release]; // warn; }. .. _osx-cocoa-NSError:. osx.cocoa.NSError (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""; Check usage of NSError parameters. .. code-block:: objc. @interface A : NSObject; - (void)foo:(NSError """""""""""""""""""""""""""""""""""""""""""""""")error;; @end. @implementation A; - (void)foo:(NSError """""""""""""""""""""""""""""""""""""""""""""""")error {; // warn: method accepting NSError"""""""""""""""""""""""""""""""""""""""""""""""" should have a non-void; // return value; }; @end. @interface A : NSObject; - (BOOL)foo:(NSError """""""""""""""""""""""""""""""""""""""""""""""")error;; @end. @implementation A; - (BOOL)foo:(NSError """""""""""""""""""""""""""""""""""""""""""""""")error {; *error = 0; // warn: potential null dereference; return 0;; }; @end. .. _osx-cocoa-NilArg:. osx.cocoa.NilArg (ObjC); """"""""""""""""""""""""""""""""""""""""""""""; Check for prohibited nil arguments to ObjC method calls. - caseInsensitiveCompare:; - compare:; - compare:options:; - compare:options:range:; - compare:options:range:locale:; - componentsSeparatedByCharactersInSet:; - initWithFormat:. .. code-blo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:38187,release,release,38187,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['release'],['release']
Deployability,"""""); break(); endif(); if(_cxx_inc_join); set(_cxx_inc_join ""${_cxx_inc_join}:${_cxx_inc_path}""); else(); set(_cxx_inc_join ""${_cxx_inc_path}""); endif(); endforeach(); set(CLING_CXX_HEADERS ""${_cxx_inc_join}""); if (NOT CLING_CXX_HEADERS); MESSAGE(WARNING ""Cannot determine location of C++ headers for runtime.""); endif(); endif(). MESSAGE(STATUS ""Cling will look for C++ headers in '${CLING_CXX_HEADERS}' at runtime.""). # In modules builds we 'mount' our own stl modulemap for libstdc++. In order to do this,; # we need to know where is ROOT/cling STL.; set_property(GLOBAL PROPERTY ROOT_CLING_CXX_HEADERS_LOCATION ""${CLING_CXX_HEADERS}""). # FIXME: We should use file(GENERATE) cmake command.; file(WRITE ${CMAKE_CURRENT_BINARY_DIR}/cling-compiledata.h.in; ""; #define CLING_CXX_INCL \""${CLING_CXX_HEADERS}\""; #define CLING_INCLUDE_PATHS \""${CLING_INCLUDE_PATHS}\""; ""); if (CMAKE_OSX_SYSROOT); # CMAKE_OSX_SYSROOT hardcodes the concrete version of the sdk; # (eg .../MacOSX11.1.sdk) which changes after every update of XCode. We use; # the assumption that in the parent folder there is a symlink MacOSX.sdk; # which points to the current active sdk. This change allows releases; # to work when the users update their sdks.; # FIXME: That is a horrible hack and we should teach CIFactory to pick up; # the SDK directory at runtime, just as we do for the include paths to C++.; set (OSX_SYSROOT_DEFAULT_SDK ${CMAKE_OSX_SYSROOT}); if (${OSX_SYSROOT_DEFAULT_SDK} MATCHES ""MacOSX[.0-9]+\.sdk""); get_filename_component(OSX_SYSROOT_DEFAULT_SDK ${OSX_SYSROOT_DEFAULT_SDK} DIRECTORY); set (OSX_SYSROOT_DEFAULT_SDK ${OSX_SYSROOT_DEFAULT_SDK}/MacOSX.sdk/); endif(). file(APPEND ${CMAKE_CURRENT_BINARY_DIR}/cling-compiledata.h.in; ""; #define CLING_OSX_SYSROOT \""${OSX_SYSROOT_DEFAULT_SDK}\""; ""); endif(); if (CLING_CXX_PATH); MESSAGE(STATUS ""And if not found, will invoke: '${CLING_CXX_PATH}' for them.""); file(APPEND ${CMAKE_CURRENT_BINARY_DIR}/cling-compiledata.h.in; ""; #define CLING_CXX_PATH \""${CLING_CXX_PATH",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/CMakeLists.txt:9021,update,update,9021,interpreter/cling/lib/Interpreter/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/CMakeLists.txt,1,['update'],['update']
Deployability,"""${CMAKE_BINARY_DIR}/cmake_install.cmake""); endif(); endif(); set_property(GLOBAL APPEND PROPERTY CLING_EXPORTS ${name}); else(); # Add empty ""phony"" target; add_custom_target(${name}); endif(). set_target_properties(${name} PROPERTIES FOLDER ""Cling libraries""); set_cling_windows_version_resource_properties(${name}); endmacro(add_cling_library). macro(add_cling_executable name); add_llvm_executable( ${name} ${ARGN} ); set_target_properties(${name} PROPERTIES FOLDER ""Cling executables""); set_cling_windows_version_resource_properties(${name}); endmacro(add_cling_executable). set(CMAKE_INCLUDE_CURRENT_DIR ON). include_directories(BEFORE; ${CMAKE_CURRENT_BINARY_DIR}/include; ${CMAKE_CURRENT_SOURCE_DIR}/include; ). if (NOT LLVM_INSTALL_TOOLCHAIN_ONLY); install(DIRECTORY include/cling include/cling-c; DESTINATION include; FILES_MATCHING; PATTERN ""*.def""; PATTERN ""*.h""; PATTERN ""config.h"" EXCLUDE; PATTERN "".svn"" EXCLUDE; ). install(DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/include/cling; DESTINATION include; FILES_MATCHING; PATTERN ""CMakeFiles"" EXCLUDE; PATTERN ""*.inc""; PATTERN ""*.h""; PATTERN ""*.modulemap""; ); endif(). add_definitions( -D_GNU_SOURCE -DCLING_VERSION=${CLING_VERSION}). option(CLING_INCLUDE_TESTS; ""Generate build targets for the Cling unit tests.""; ${LLVM_INCLUDE_TESTS}). if (NOT WIN32); set(cling_path_delim "":""); else(); set(cling_path_delim "";""); endif(). if( CLING_INCLUDE_TESTS ); set(cling_include_deflt ${CMAKE_INSTALL_PREFIX}/include; ${CMAKE_CURRENT_SOURCE_DIR}/include; ${CLANG_INCLUDE_DIRS}; ${LLVM_INCLUDE_DIRS}; ). # CLANG_INCLUDE_DIRS and LLVM_INCLUDE_DIRS can be a semicolon separated lists.; string(REPLACE "";"" ""${cling_path_delim}"" cling_include_deflt ""${cling_include_deflt}""); endif(). if(NOT CLING_INCLUDE_PATHS); set(CLING_INCLUDE_PATHS ""${cling_include_deflt}""); else(); set(CLING_INCLUDE_PATHS ""${CLING_INCLUDE_PATHS}${cling_path_delim}${cling_include_deflt}""); endif(). # All targets below may depend on all tablegen'd files.; get_property(CLANG_TABLEG",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/CMakeLists.txt:15524,install,install,15524,interpreter/cling/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/CMakeLists.txt,1,['install'],['install']
Deployability,"""${clang_cmake_builddir}""); set(CLANG_CONFIG_LLVM_CMAKE_DIR ""${llvm_cmake_builddir}""); set(CLANG_CONFIG_INCLUDE_EXPORTS ""include(\""${clang_cmake_builddir}/ClangTargets.cmake\"")""); set(CLANG_CONFIG_INCLUDE_DIRS; ""${CLANG_SOURCE_DIR}/include""; ""${CLANG_BINARY_DIR}/include""; ); configure_file(; ${CMAKE_CURRENT_SOURCE_DIR}/ClangConfig.cmake.in; ${clang_cmake_builddir}/ClangConfig.cmake; @ONLY); configure_file(; ${CMAKE_CURRENT_SOURCE_DIR}/ClangConfigVersion.cmake.in; ${clang_cmake_builddir}/ClangConfigVersion.cmake; @ONLY); set(CLANG_CONFIG_CMAKE_DIR); set(CLANG_CONFIG_LLVM_CMAKE_DIR). # For compatibility with projects that include(ClangConfig); # via CMAKE_MODULE_PATH, place API modules next to it.; # Copy without source permissions because the source could be read-only,; # but we need to write into the copied folder.; file(COPY .; DESTINATION ${clang_cmake_builddir}; NO_SOURCE_PERMISSIONS; FILES_MATCHING PATTERN *.cmake; PATTERN CMakeFiles EXCLUDE; ). # Generate ClangConfig.cmake for the install tree.; find_prefix_from_config(CLANG_CONFIG_CODE CLANG_INSTALL_PREFIX ""${CLANG_INSTALL_PACKAGE_DIR}""); extend_path(CLANG_CONFIG_CMAKE_DIR ""\${CLANG_INSTALL_PREFIX}"" ""${CLANG_INSTALL_PACKAGE_DIR}""); extend_path(CLANG_CONFIG_LLVM_CMAKE_DIR ""\${CLANG_INSTALL_PREFIX}"" ""${LLVM_INSTALL_PACKAGE_DIR}""); get_config_exports_includes(Clang CLANG_CONFIG_INCLUDE_EXPORTS); extend_path(base_includedir ""\${CLANG_INSTALL_PREFIX}"" ""${CMAKE_INSTALL_INCLUDEDIR}""); set(CLANG_CONFIG_INCLUDE_DIRS; ""${base_includedir}""; ); configure_file(; ${CMAKE_CURRENT_SOURCE_DIR}/ClangConfig.cmake.in; ${CMAKE_CURRENT_BINARY_DIR}/CMakeFiles/ClangConfig.cmake; @ONLY); configure_file(; ${CMAKE_CURRENT_SOURCE_DIR}/ClangConfigVersion.cmake.in; ${CMAKE_CURRENT_BINARY_DIR}/CMakeFiles/ClangConfigVersion.cmake; @ONLY); set(CLANG_CONFIG_CODE); set(CLANG_CONFIG_CMAKE_DIR). if (NOT LLVM_INSTALL_TOOLCHAIN_ONLY); install_distribution_exports(Clang). install(FILES; ${CMAKE_CURRENT_BINARY_DIR}/CMakeFiles/ClangConfig.cmake; ${CMAK",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/cmake/modules/CMakeLists.txt:2325,install,install,2325,interpreter/llvm-project/clang/cmake/modules/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/cmake/modules/CMakeLists.txt,1,['install'],['install']
Deployability,"""``new``"", and the method is a class method,; or. * the first word is ""``autorelease``"", ""``init``"", ""``retain``"", or ""``self``"",; and the method is an instance method. If a method with a related result type is overridden by a subclass method, the; subclass method must also return a type that is compatible with the subclass; type. For example:. .. code-block:: objc. @interface NSString : NSObject; - (NSUnrelated *)init; // incorrect usage: NSUnrelated is not NSString or a superclass of NSString; @end. Related result types only affect the type of a message send or property access; via the given method. In all other respects, a method with a related result; type is treated the same way as method that returns ``id``. Use ``__has_feature(objc_instancetype)`` to determine whether the; ``instancetype`` contextual keyword is available. Automatic reference counting; ----------------------------. Clang provides support for :doc:`automated reference counting; <AutomaticReferenceCounting>` in Objective-C, which eliminates the need; for manual ``retain``/``release``/``autorelease`` message sends. There are three; feature macros associated with automatic reference counting:; ``__has_feature(objc_arc)`` indicates the availability of automated reference; counting in general, while ``__has_feature(objc_arc_weak)`` indicates that; automated reference counting also includes support for ``__weak`` pointers to; Objective-C objects. ``__has_feature(objc_arc_fields)`` indicates that C structs; are allowed to have fields that are pointers to Objective-C objects managed by; automatic reference counting. .. _objc-weak:. Weak references; ---------------. Clang supports ARC-style weak and unsafe references in Objective-C even; outside of ARC mode. Weak references must be explicitly enabled with; the ``-fobjc-weak`` option; use ``__has_feature((objc_arc_weak))``; to test whether they are enabled. Unsafe references are enabled; unconditionally. ARC-style weak and unsafe references cannot be used",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:70948,release,release,70948,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['release'],['release']
Deployability,"""curve(fc(x), 0, 10, col = 'darkblue', add = TRUE)"";; // different interpolation on left and right side :; r<<""plot(approxfun(x, y, rule = 2:1), 0, 11,col = 'tomato', add = TRUE, lty = 3, lwd = 2)"";; }; ~~~; The image shows the interpolated function plotted within R:; \image html R_image3.png. ## Integration (Passing vectorized function to R); Numerical integration using R passing the function from ROOT. ~~~{.cxx}; #include<TMath.h>; #include<TRInterface.h>; #include<Math/Integrator.h>; #include<TF1.h>. //To integrate using R the function must be vectorized; //The idea is just to receive a vector like an argument,to evaluate; //every element saving the result in another vector; //and return the resultant vector.; std::vector<Double_t> BreitWignerVectorized(std::vector<Double_t> xx); {; std::vector<Double_t> result(xx.size());; for(Int_t i=0;i<xx.size();i++); {; result[i]=TMath::BreitWigner(xx[i]);; }; return result;; }. double BreitWignerWrap( double x){; return TMath::BreitWigner(x);; }. void Integration(); {. ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();. r[""BreitWigner""]=BreitWignerVectorized;. Double_t value=r.Eval(""integrate(BreitWigner, lower = -2, upper = 2)$value"");. std::cout.precision(18);; std::cout<<""Integral of the BreitWigner Function in the interval [-2, 2] R = ""<<value<<std::endl;. ROOT::Math::WrappedFunction<> wf(BreitWignerWrap);; ROOT::Math::Integrator i(wf);; value=i.Integral(-2,2);; std::cout<<""Integral of the BreitWigner Function in the interval [-2, 2] MathMore = ""<<value<<std::endl;. TF1 f1(""BreitWigner"",""BreitWignerWrap(x)"");; value=f1.Integral(-2,2);; std::cout<<""Integral of the BreitWigner Function in the interval [-2, 2] TF1 = ""<<value<<std::endl;. //infinte limits; value=r.Eval(""integrate(BreitWigner, lower = -Inf, upper = Inf)$value"");; std::cout<<""Integral of BreitWigner Function in the interval [-Inf, Inf] R = ""<<value<<std::endl;. }; ~~~. ## Users Guide Sites; - http://oproject.org/tiki-index.php?page=ROOT+R+Users+Guide. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:23048,integrat,integrate,23048,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,2,['integrat'],['integrate']
Deployability,"""global""; ID number space for the current translation unit, providing a 1-1 mapping; between entities (in whatever AST file they inhabit) and global ID numbers.; If that translation unit is then serialized into an AST file, this mapping; will be stored for use when the AST file is imported. Declaration merging; It is possible for a given entity (from the language's perspective) to be; declared multiple times in different places. For example, two different; headers can have the declaration of ``printf`` or could forward-declare; ``struct stat``. If each of those headers is included in a module, and some; third party imports both of those modules, there is a potentially serious; problem: name lookup for ``printf`` or ``struct stat`` will find both; declarations, but the AST nodes are unrelated. This would result in a; compilation error, due to an ambiguity in name lookup. Therefore, the AST; reader performs declaration merging according to the appropriate language; semantics, ensuring that the two disjoint declarations are merged into a; single redeclaration chain (with a common canonical declaration), so that it; is as if one of the headers had been included before the other. Name Visibility; Modules allow certain names that occur during module creation to be ""hidden"",; so that they are not part of the public interface of the module and are not; visible to its clients. The AST reader maintains a ""visible"" bit on various; AST nodes (declarations, macros, etc.) to indicate whether that particular; AST node is currently visible; the various name lookup mechanisms in Clang; inspect the visible bit to determine whether that entity, which is still in; the AST (because other, visible AST nodes may depend on it), can actually be; found by name lookup. When a new (sub)module is imported, it may make; existing, non-visible, already-deserialized AST nodes visible; it is the; responsibility of the AST reader to find and update these AST nodes when it; is notified of the import. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:30006,update,update,30006,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,1,['update'],['update']
Deployability,"# Appendix A: Install and Build ROOT; \index{install ROOT}. ## License. ROOT is made available under the LGPL v2.1 license. For full details see; the file LICENSE in the ROOT distribution. ## Installing ROOT. To install ROOT you will need to go to the ROOT website at:; <https://root.cern/install/>. You have a choice to download the binaries or the source. The source is; quicker to transfer since it is only 31 MB, but you will need to compile; and link it. The binaries range from 50 MB to 100 MB depending on the; target platform. ## Choosing a Version. The ROOT developers follow the principle of ""release early and release; often"", however a very large portion of a user base requires a stable; product therefore generally three versions of the system is available; for download - new, old and pro:. - The *new* version evolves quickly, with weekly or bi-weekly; releases. Use this to get access to the latest and greatest, but it; may not be stable. By trying out the new version you can help us; converge quickly to a stable version that can then become the new; pro version. If you are a new user we would advice you to try the; new version. - The *pro* (production) version is a version we feel comfortable with; to exposing to a large audience for serious work. The change rate of; this version is much lower than for the new version, it is about 3; to 6 months. - The *old* version is the previous pro version that people might need; for some time before switching the new pro version. The old change; rate is the same as for pro. ## Installing Precompiled Binaries. The binaries are available for downloading from; <https://root.cern/install/>. Once downloaded; you need to unzip and de-tar the file. For example, if you have; downloaded ROOT v5.30 for Linux-SLC5:. ``` {.cpp}; % gunzip root_v5.30.00.Linux-slc5-gcc4.3.tar.gz; % tar xvf root_v5.30.00.Linux-slc5-gcc4.3.tar; ```. This will create the directory root. Before getting started read the; file README/README. Also, read the Intr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InstallandBuild.md:45,install,install,45,documentation/users-guide/InstallandBuild.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InstallandBuild.md,6,"['install', 'release']","['install', 'release', 'releases']"
Deployability,"# Automatic HTML Documentation; \index{documentation!class}. **`THtml`** is ROOT's documentation engine. It can be used to document; your classes in a reference guide, and to convert your text or source; files to HTML. ## Reference Guide. The Reference Guide for the ROOT classes at; <http://root.cern.ch/root/html/> has been generated by ROOT's; **`THtml`** class. Just as for ROOT's classes, it can generate (and; update) a reference guide for your classes, too. You document your; classes using source code comments. All comments will be automatically; put into a `<pre></pre>` environment to keep the indentation and line; length. You can write ""raw"" HTML by enclosing comments in the keywords; `Begin_Html` and `End_Html`. To generate documentation for the class **`TObject`** you could run the; following commands:. ``` {.cpp}; root[] THtml h; root[] h.SetInputDir(""$(ROOTSYS)"");; root[] h.MakeClass(""TObject"");; root[] h.CreateJavascript();; root[] h.CreateStylesheet();; ```. The comments following the first comment of the form; //\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_, before any method, is; assumed to be the **class description**. As with any other documentation; part, it has to be a continuous block of comments. Any documented class will have an **class index entry** in the; `ClassIndex.html`, showing their name with a link to their documentation; page and a miniature description. This description for e.g. the class; `MyClass` has to be given in `MyClass's` header file as documentation. A **method description** block starts immediately after '`{`' and looks; like this:. ``` {.cpp}; void TWorld::HelloWorldFunc(string *text); {; // This is a documentation example of the function TWorld::HelloWorldFunc; helloWorld.Print(text);; }; ```. Like in a class description block, everything until the first; non-commented line is considered as a valid member function description; block. **Data members** are documented by putting a C++ comment behind their; declaration in the header ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/HTMLDoc.md:416,update,update,416,documentation/users-guide/HTMLDoc.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/HTMLDoc.md,1,['update'],['update']
Deployability,"# BACKGROUND ELIMINATION. ## 1-DIMENSIONAL SPECTRA. This function calculates background spectrum from the source spectrum. The; result is placed in the vector pointed by spectrum pointer. On; successful completion it returns 0. On error it returns pointer to the; string describing error. ``` {.cpp}; char *Background1(float *spectrum,; int size,; int number_of_iterations);; ```. Function parameters:. - **`spectrum`**: pointer to the vector of the source spectrum; - **`size`**: length of spectrum; - **`number_of_iterations`**: or width of the clipping window. The function allows to separate useless spectrum information (continuous; background) from peaks, based on Sensitive Nonlinear Iterative Peak; Clipping Algorithm. In fact, it represents the second order difference filter; (-1,2,-1). The basic algorithm is described in details in [1], [2]. $$ v_p(i)= min\left\{v_{p-1} , \frac{[v_{p-1}(i+p)+v_{p-1}(i-p)]}{2} \right\} $$. where `p` can be changed as follows:. a. from 1 up to a given parameter value `w` by incrementing it in each; iteration step by 1 - INCREASING CLIPPING WINDOW. b. from a given value `w` by decrementing it in each iteration step by; 1 - DECREASING CLIPPING WINDOW. An example of the original spectrum and estimated background (INCREASING; CLIPPING WINDOW) is given in the Figure 1.1. ![Example of the original spectrum and estimated background (INCREASING; CLIPPING WINDOW)](figures/image004.png). One can notice that on the edges of the peaks the estimated background; goes under the peaks. An alternative approach is to decrease the; clipping window from a given value to the value of one (DECREASING; CLIPPING WINDOW). Then the result obtained is given in the Figure 1.2. ![An alternative approach is to decrease the clipping window from a given value to the value of one (DECREASING CLIPPING WINDOW)](figures/image006.png). The estimated background is smoother. The method does not deform the; shape of peaks. However, sometimes the shape of the background is ve",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md:626,continuous,continuous,626,documentation/spectrum/Spectrum.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md,1,['continuous'],['continuous']
Deployability,"# Building shared libraries requires PIC objects.; if(LLVM_ENABLE_PIC). set(LLVM_LINK_COMPONENTS; Remarks; ). set(SOURCES; libremarks.cpp; ). if (NOT (BUILD_SHARED_LIBS OR LLVM_LINK_LLVM_DYLIB)); set(LLVM_EXPORTED_SYMBOL_FILE ${CMAKE_CURRENT_SOURCE_DIR}/Remarks.exports); endif(). add_llvm_library(Remarks SHARED INSTALL_WITH_TOOLCHAIN ${SOURCES}). if (LLVM_INTEGRATED_CRT_ALLOC AND MSVC); # Make sure we search LLVMSupport first, before the CRT libs; set(CMAKE_SHARED_LINKER_FLAGS ""${CMAKE_SHARED_LINKER_FLAGS} -INCLUDE:malloc""); endif(); ; install(FILES ${LLVM_MAIN_INCLUDE_DIR}/llvm-c/Remarks.h; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}/llvm-c""; COMPONENT Remarks). if (APPLE); set(REMARKS_VERSION ${LLVM_VERSION_MAJOR}); set_property(TARGET Remarks APPEND_STRING PROPERTY; LINK_FLAGS; "" -compatibility_version 1 -current_version ${REMARKS_VERSION}.${LLVM_VERSION_MINOR}.${LLVM_VERSION_PATCH}""); endif(). endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/remarks-shlib/CMakeLists.txt:542,install,install,542,interpreter/llvm-project/llvm/tools/remarks-shlib/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/remarks-shlib/CMakeLists.txt,1,['install'],['install']
Deployability,"# C++ Modules in ROOT. Technology Overview. *Vassil Vassilev, Oksana Shadura, Yuka Takahashi and Raphael Isemann*. ## Overview. ROOT has several features which interact with libraries and require implicit; header inclusion. This can be triggered by reading or writing data on disk,; or user actions at the prompt. Often, the headers are immutable and reparsing is; redundant. C++ Modules are designed to minimize the reparsing of the same; header content by providing an efficient on-disk representation of C++ Code. The ROOT v6.16 release came with a preview of the module technology;; dedicated binaries have been built and can be reproduced by passing; `-Druntime_cxxmodules=On` as configure flag. The goals of this technology are:; * Gain feedback from early adoption -- the technology is being long anticipated; by some of the users of ROOT. It improves correctness of ROOT and improves; performance when carefully adopted.; * Study performance bottlenecks -- the feature is designed with performance; considerations in mind. In this document we describe the current performance; bottlenecks and trade-offs.; * Understand if the gradual migration policy is sufficient -- C++ Modules in; ROOT support gradual migration. In particular, ROOT can enable C++ Modules for; itself and still run in legacy mode for the third-party code (generating; rootmap files and other scaffolding). C++ Modules are here and we would like to give a brief introduction of how the; feature works, what are its pros and cons, what's the current state of the; implementation and how third-party code can use it. Read more [[1]]. C++ Modules in ROOT are default since v6.20 (Unix) and v6.22 (OSX). ## Design Goals. * Coherence with standard C++ -- C++ Modules TS is advancing and will be; likely part the upcoming C++20 standard;; * Performance -- provide performance that is competitive to ROOT with PCH and; advance further the implementation of the C++ Modules in clang to optimize; memory footprint and execution time;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:532,release,release,532,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['release'],['release']
Deployability,# Cling Kernel. C++ Kernel for Jupyter with Cling. Requires ipykernel ≥ 4.0. ## Install. To install the kernel with sources in src/tools/cling:. export PATH=/cling-install-prefix/bin:$PATH; cd /cling-install-prefix/share/cling/Jupyter/kernel. pip install -e .; # or: pip3 install -e . # register the kernelspec for C++17/C++1z/C++14/C++11:; # the user can install whichever kernel(s) they; # wish:; jupyter-kernelspec install [--user] cling-cpp17; jupyter-kernelspec install [--user] cling-cpp1z; jupyter-kernelspec install [--user] cling-cpp14; jupyter-kernelspec install [--user] cling-cpp11. To run it:. jupyter-notebook; # or: jupyter notebook; ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md:92,install,install,92,interpreter/cling/tools/Jupyter/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md,10,['install'],"['install', 'install-prefix']"
Deployability,"# Concluding Remarks #. This is the end of our guided tour for beginners through ROOT. There is; still a lot coming to mind to be said, but by now you are experienced; enough to use the ROOT documentation, most importantly the **[ROOT home; page](http://root.cern.ch)** and the **[ROOT reference; guide](https://root.cern/doc/master/)** with the; documentation of all ROOT classes, or the **[ROOT users; manual](https://root.cern/manual/)**. A very useful way for you to continue exploring ROOT is to study the; examples in the sub-directory `tutorials/` of any ROOT installation. There are some powerful features of ROOT which were not treated in this; document, e.g. packages named RooFit and RooStats providing an advanced; framework for model building, fitting and statistical analysis. The ROOT; namespace `TMVA` offers multi-variate analysis tools including an artificial; neural network and many other advanced tools for classification; problems. The remarkable ability of ROOT to handle large data volumes; was already mentioned in this guide, implemented through the class; `TTree`. But there is still much more for you to explore!. **End of this guide ... but hopefully not of your interaction with ROOT !**; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/concludingRemarks.md:567,install,installation,567,documentation/primer/concludingRemarks.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/concludingRemarks.md,1,['install'],['installation']
Deployability,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. # CMakeLists.txt for the ROOT tutorials programs.; # Author: Pere Mato, 25/10/2010; cmake_minimum_required(VERSION 3.10 FATAL_ERROR). project(tutorials). # Sergey: make no sence while CMakeLists.txt file cannot be used separately from ROOT; # but variables like ROOT_asimage_FOUND used here and produced in ROOTConfig.cmake; find_package(ROOT REQUIRED). if(DEFINED ROOT_SOURCE_DIR) # Testing using the binary tree; set(ROOT_root_CMD root.exe); if(NOT MSVC) # Ignore environment on Windows; set(ROOT_environ PATH=${CMAKE_BINARY_DIR}/bin:$ENV{PATH}; ${ld_library_path}=${CMAKE_BINARY_DIR}/lib:$ENV{${ld_library_path}}; ROOTSYS=${CMAKE_BINARY_DIR}; PYTHONPATH=${CMAKE_BINARY_DIR}/lib:$ENV{PYTHONPATH}); else(); set(ROOT_environ ROOTSYS=${CMAKE_BINARY_DIR}; PYTHONPATH=${CMAKE_BINARY_DIR}/bin;$ENV{PYTHONPATH}); endif(); else() # testing using an installation; include(${ROOT_USE_FILE}); if(DEFINED ROOT_CONFIG_EXECUTABLE) #---If ROOT was built with the classic configure/make---; set(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} ${CMAKE_CURRENT_SOURCE_DIR}/../cmake/modules); include(RootMacros); set(ROOT_root_CMD root.exe); endif(); enable_testing(); endif(). # Set the environment for the tutorials, which is the eventual ROOT_environ; # plus some environment variables related to limiting the number of threads; # used by NumPy.; # See: https://stackoverflow.com/questions/30791550/limit-number-of-threads-in-numpy; set(TUTORIAL_ENV ${ROOT_environ} OMP_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 MKL_NUM_THREADS=1). #---Copy the CTestCustom.cmake file into the build directory--------; configure_file(${CMAKE_CURRENT_SOURCE_DIR}/CTestCustom.cmake ${CMAKE_CURRENT_BINARY_DIR} COPYONLY). #---Provide a rootlogon.C file in the current build directory that; # will affect the way we run all tutorials.; # This overwrites ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/CMakeLists.txt:1038,install,installation,1038,tutorials/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/CMakeLists.txt,1,['install'],['installation']
Deployability,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. ############################################################################; # CMakeLists.txt file for building ROOT core/base package; ############################################################################. if(MSVC AND MSVC_VERSION GREATER_EQUAL 1925 AND MSVC_VERSION LESS 1929); # FIXME: since Visual Studio v16.5.0 the /O2 optimization flag makes most of the roofit/roostats tests failing; # Try to re-enable /O2 after the upgrade of llvm & clang, or when upgrading Visual Studio; string(REPLACE ""-O2"" ""-O1 -Oi"" CMAKE_CXX_FLAGS_RELEASE ""${CMAKE_CXX_FLAGS_RELEASE}""); string(REPLACE ""-O2"" ""-O1 -Oi"" CMAKE_CXX_FLAGS_RELWITHDEBINFO ""${CMAKE_CXX_FLAGS_RELWITHDEBINFO}""); endif(). set(BASE_HEADERS; ROOT/TErrorDefaultHandler.hxx; ROOT/TExecutorCRTP.hxx; ROOT/TSequentialExecutor.hxx; ROOT/StringConv.hxx; Buttons.h; Bytes.h; Byteswap.h; KeySymbols.h; MessageTypes.h; Riostream.h; Rtypes.h; TApplication.h; TAtt3D.h; TAttAxis.h; TAttBBox2D.h; TAttBBox.h; TAttFill.h; TAttLine.h; TAttMarker.h; TAttPad.h; TAttText.h; TBase64.h; TBenchmark.h; TBuffer3D.h; TBuffer3DTypes.h; TBuffer.h; TColor.h; TColorGradient.h; TDatime.h; TDirectory.h; TEnv.h; TException.h; TExec.h; TFileCollection.h; TFileInfo.h; TFolder.h; TInetAddress.h; TMacro.h; TMathBase.h; TMD5.h; TMemberInspector.h; TMessageHandler.h; TNamed.h; TNotifyLink.h; TObject.h; TObjString.h; TParameter.h; TPluginManager.h; TPoint.h; TPRegexp.h; TProcessID.h; TProcessUUID.h; TQClass.h; TQCommand.h; TQConnection.h; TQObject.h; TRedirectOutputGuard.h; TRefCnt.h; TRef.h; TRegexp.h; TRemoteObject.h; TROOT.h; TRootIOCtor.h; TStopwatch.h; TStorage.h; TString.h; TStringLong.h; TStyle.h; TSysEvtHandler.h; TSystemDirectory.h; TSystemFile.h; TSystem.h; TTask.h; TThreadSlots.h; TTime.h; TTimer.h; TTimeStamp.h; TUri.h; TUrl.h; TUUID.h; TVersionCheck.h;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/CMakeLists.txt:628,upgrade,upgrade,628,core/base/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/CMakeLists.txt,1,['upgrade'],['upgrade']
Deployability,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. ############################################################################; # CMakeLists.txt file for building ROOT graf3d/gl package; ############################################################################. if(WIN32 OR cocoa); set(installoptions FILTER ""TX11GL""); endif(). if(x11); set(RGL_EXTRA_HEADERS TX11GL.h); set(RGL_EXTRA_SOURCES TX11GL.cxx); endif(). if(builtin_gl2ps); set(RGL_EXTRA_SOURCES ${RGL_EXTRA_SOURCES} src/gl2ps.cxx); endif(). set_source_files_properties(src/TGLFontManager.cxx PROPERTIES COMPILE_FLAGS ""${FTGL_CFLAGS}""); set_source_files_properties(src/TGLText.cxx PROPERTIES COMPILE_FLAGS ""${FTGL_CFLAGS}""). ROOT_STANDARD_LIBRARY_PACKAGE(RGL; HEADERS; TArcBall.h; TF2GL.h; TGL5DDataSetEditor.h; TGL5D.h; TGLAdapter.h; TGLAnnotation.h; TGLAutoRotator.h; TGLAxis.h; TGLAxisPainter.h; TGLBoundingBox.h; TGLBoxPainter.h; TGLCameraGuide.h; TGLCamera.h; TGLCameraOverlay.h; TGLClip.h; TGLClipSetEditor.h; TGLContext.h; TGLCylinder.h; TGLEmbeddedViewer.h; TGLEventHandler.h; TGLFaceSet.h; TGLFBO.h; TGLFontManager.h; TGLFormat.h; TGLH2PolyPainter.h; TGLHistPainter.h; TGLLegoPainter.h; TGLLightSetEditor.h; TGLLightSet.h; TGLLockable.h; TGLLogicalShape.h; TGLManip.h; TGLManipSet.h; TGLObject.h; TGLOrthoCamera.h; TGLOutput.h; TGLOverlayButton.h; TGLOverlay.h; TGLPadPainter.h; TGLPadUtils.h; TGLParametricEquationGL.h; TGLParametric.h; TGLPerspectiveCamera.h; TGLPhysicalShape.h; TGLPlot3D.h; TGLPlotBox.h; TGLPlotCamera.h; TGLPlotPainter.h; TGLPolyLine.h; TGLPolyMarker.h; TGLPShapeObjEditor.h; TGLPShapeObj.h; TGLPShapeRef.h; TGLQuadric.h; TGLRnrCtx.h; TGLRotateManip.h; TGLSAFrame.h; TGLSAViewer.h; TGLScaleManip.h; TGLSceneBase.h; TGLScene.h; TGLSceneInfo.h; TGLScenePad.h; TGLSelectBuffer.h; TGLSelectRecord.h; TGLSphere.h; TGLStopwatch.h; TGLSurfacePainter.h; TGLText.h; TGLTF3",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/CMakeLists.txt:434,install,installoptions,434,graf3d/gl/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/CMakeLists.txt,1,['install'],['installoptions']
Deployability,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. ############################################################################; # CMakeLists.txt file for building ROOT graph3d/rglew package; ############################################################################. # This package is only needed for user backward compatibility! (TGLIncludes.h). add_library(RGlew INTERFACE); target_include_directories(RGlew INTERFACE inc/); target_link_libraries(RGlew INTERFACE GLEW::GLEW); #target_include_directories(RGlew INTERFACE $<BUILD_INTERFACE:${GLEW_INCLUDE_DIR}>). # We still need to install TGLIncludes.h into include/; ROOT_INSTALL_HEADERS(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/rglew/CMakeLists.txt:729,install,install,729,graf3d/rglew/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/rglew/CMakeLists.txt,1,['install'],['install']
Deployability,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. ############################################################################; # CMakeLists.txt file for building ROOT math/unurun package; ############################################################################. #---Define package related variables-----------------------------------------------------------------. if(builtin_unuran). set(UNR_SRCDIR ${CMAKE_CURRENT_SOURCE_DIR}/src); set(UNR_VERSION ""1.8.0-root""); set(UNR_TARNAME ""unuran-${UNR_VERSION}""); set(UNR_TARGZFILE ${UNR_SRCDIR}/${UNR_TARNAME}.tar.gz); set(UNR_TARFILE ${UNR_SRCDIR}/${UNR_TARNAME}.tar); set(UNR_UNTARDIR ${CMAKE_CURRENT_BINARY_DIR}/${UNR_TARNAME}). #---Untar sources at configuration/generation time (needed for listing sources); if(NOT EXISTS ${UNR_UNTARDIR}); execute_process( COMMAND ${CMAKE_COMMAND} -E tar xzf ${UNR_TARGZFILE}; WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR} ); # This is necessary to replace the config.guess of unuran 1.8.0 as it does not allow to compile the ; # package on arm64.; execute_process( COMMAND ${CMAKE_COMMAND} -E copy ${CMAKE_CURRENT_SOURCE_DIR}/config.guess_patch1 ${UNR_UNTARDIR}/autoconf/config.guess; WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR} ); endif(). if(WIN32); configure_file(${CMAKE_CURRENT_SOURCE_DIR}/config.h.win.in ${UNR_UNTARDIR}/config.h); else(); #---Define special compiler settings for unurun-----------------------------------------------------; set(UNR_CC ${CMAKE_C_COMPILER}); if(ROOT_ARCHITECTURE MATCHES hpuxia64acc); set(UNR_CC ""${UNR_CC} +DD64 -Ae""); elseif(ROOT_ARCHITECTURE MATCHES linuxppc64gcc); set(UNR_CC ""${UNR_CC} -m64 -fPIC""); elseif(ROOT_ARCHITECTURE MATCHES linuxx8664gcc); set(UNR_CFLAGS ""-m64 -fPIC""); elseif(ROOT_ARCHITECTURE MATCHES linuxicc); set(UNR_CFLAGS ""-m32""); elseif(ROOT_ARCHITECTURE MATCHES linuxx8664icc); set(UNR_CFLAGS ""-m64""); e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/unuran/CMakeLists.txt:847,configurat,configuration,847,math/unuran/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/unuran/CMakeLists.txt,1,['configurat'],['configuration']
Deployability,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. ############################################################################; # CMakeLists.txt file for building ROOT proof/proofbench package; ############################################################################. ROOT_STANDARD_LIBRARY_PACKAGE(ProofBench; HEADERS; TProofBenchDataSet.h; TProofBench.h; TProofBenchRunCPU.h; TProofBenchRunDataRead.h; TProofBenchRun.h; TProofBenchTypes.h; TProofNodes.h; TProofPerfAnalysis.h; SOURCES; src/TProofBench.cxx; src/TProofBenchDataSet.cxx; src/TProofBenchRunCPU.cxx; src/TProofBenchRun.cxx; src/TProofBenchRunDataRead.cxx; src/TProofNodes.cxx; src/TProofPerfAnalysis.cxx; DEPENDENCIES; Core; Gpad; Hist; ProofPlayer; INSTALL_OPTIONS; FILTER ""TSel""; ). # Generation and installation of the PAR files required by the benchmark; add_custom_target(ProofBenchPARFiles ALL; DEPENDS; ${CMAKE_BINARY_DIR}/etc/proof/proofbench/ProofBenchCPUSel.par; ${CMAKE_BINARY_DIR}/etc/proof/proofbench/ProofBenchDataSel.par; ). add_custom_command(OUTPUT; ${CMAKE_BINARY_DIR}/etc/proof/proofbench/ProofBenchCPUSel.par; ${CMAKE_BINARY_DIR}/etc/proof/proofbench/ProofBenchDataSel.par; DEPENDS; ${CMAKE_SOURCE_DIR}/etc/proof/utils/makepbenchpars.sh; COMMAND; ${CMAKE_COMMAND} -E make_directory ${CMAKE_BINARY_DIR}/etc/proof/proofbench; COMMAND; ${CMAKE_SOURCE_DIR}/etc/proof/utils/makepbenchpars.sh ProofBenchCPUSel ${CMAKE_SOURCE_DIR} ${CMAKE_BINARY_DIR}; COMMAND; ${CMAKE_SOURCE_DIR}/etc/proof/utils/makepbenchpars.sh ProofBenchDataSel ${CMAKE_SOURCE_DIR} ${CMAKE_BINARY_DIR}; WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}; ). install(DIRECTORY ${CMAKE_BINARY_DIR}/etc/proof/proofbench; DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}/proof USE_SOURCE_PERMISSIONS); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proofbench/CMakeLists.txt:914,install,installation,914,proof/proofbench/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proofbench/CMakeLists.txt,2,['install'],"['install', 'installation']"
Deployability,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. ############################################################################; # CMakeLists.txt file for building ROOT tmva package; # @author Pere Mato, CERN; ############################################################################. if(NOT tmva-gpu); set(installoptions ${installoptions} FILTER ""Cuda""); endif(). if (imt); list(APPEND TMVA_EXTRA_DEPENDENCIES Imt); endif(imt). set (EXTRA_DICT_OPTS); if (runtime_cxxmodules AND WIN32); set (EXTRA_DICT_OPTS NO_CXXMODULE); endif(). ROOT_STANDARD_LIBRARY_PACKAGE(TMVA; HEADERS; TMVA/BDTEventWrapper.h; TMVA/BinarySearchTree.h; TMVA/BinarySearchTreeNode.h; TMVA/BinaryTree.h; TMVA/CCPruner.h; TMVA/CCTreeWrapper.h; TMVA/Classification.h; TMVA/ClassifierFactory.h; TMVA/ClassInfo.h; TMVA/Config.h; TMVA/Configurable.h; TMVA/ConvergenceTest.h; TMVA/CostComplexityPruneTool.h; TMVA/CrossEntropy.h; TMVA/CrossValidation.h; TMVA/CvSplit.h; TMVA/DataInputHandler.h; TMVA/DataLoader.h; TMVA/DataSetFactory.h; TMVA/DataSet.h; TMVA/DataSetInfo.h; TMVA/DataSetManager.h; TMVA/DecisionTree.h; TMVA/DecisionTreeNode.h; TMVA/Envelope.h; TMVA/Event.h; TMVA/ExpectedErrorPruneTool.h; TMVA/Executor.h; TMVA/Factory.h; TMVA/FitterBase.h; TMVA/GeneticAlgorithm.h; TMVA/GeneticFitter.h; TMVA/GeneticGenes.h; TMVA/GeneticPopulation.h; TMVA/GeneticRange.h; TMVA/GiniIndex.h; TMVA/GiniIndexWithLaplace.h; TMVA/HyperParameterOptimisation.h; TMVA/IFitterTarget.h; TMVA/IMethod.h; TMVA/Interval.h; TMVA/IPruneTool.h; TMVA/KDEKernel.h; TMVA/LDA.h; TMVA/LogInterval.h; TMVA/LossFunction.h; TMVA/MCFitter.h; TMVA/MethodANNBase.h; TMVA/MethodBase.h; TMVA/MethodBayesClassifier.h; TMVA/MethodBDT.h; TMVA/MethodBoost.h; TMVA/MethodCategory.h; TMVA/MethodCFMlpANN_def.h; TMVA/MethodCFMlpANN.h; TMVA/MethodCFMlpANN_Utils.h; TMVA/MethodCompositeBase.h; TMVA/MethodCrossValidation.h; TMVA/Me",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/CMakeLists.txt:454,install,installoptions,454,tmva/tmva/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/CMakeLists.txt,2,['install'],['installoptions']
Deployability,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. ###########################################################; # CMakeLists.txt file for building JupyROOT; ###########################################################. set(py_sources; JupyROOT/__init__.py; JupyROOT/helpers/__init__.py; JupyROOT/helpers/cppcompleter.py; JupyROOT/helpers/handlers.py; JupyROOT/helpers/utils.py; JupyROOT/html/__init__.py; JupyROOT/html/cpphighlighter.py; JupyROOT/kernel/__init__.py; JupyROOT/kernel/rootkernel.py; JupyROOT/kernel/utils.py; JupyROOT/kernel/magics/__init__.py; JupyROOT/kernel/magics/cppmagic.py; JupyROOT/kernel/magics/jsrootmagic.py; JupyROOT/magics/__init__.py; JupyROOT/magics/cppmagic.py; JupyROOT/magics/jsrootmagic.py; ). set(JupyROOTPySrcDir python/JupyROOT); file(COPY ${JupyROOTPySrcDir} DESTINATION ${localruntimedir}). # Compile .py files; foreach(py_source ${py_sources}); install(CODE ""execute_process(COMMAND ${Python3_EXECUTABLE} -m py_compile ${localruntimedir}/${py_source})""); install(CODE ""execute_process(COMMAND ${Python3_EXECUTABLE} -O -m py_compile ${localruntimedir}/${py_source})""); endforeach(). # Install Python sources and bytecode; install(DIRECTORY ${localruntimedir}/JupyROOT; DESTINATION ${CMAKE_INSTALL_PYTHONDIR}; COMPONENT libraries); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/jupyroot/CMakeLists.txt:1028,install,install,1028,bindings/jupyroot/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/jupyroot/CMakeLists.txt,3,['install'],['install']
Deployability,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. add_subdirectory (geom) # special CMakeLists.txt; if(geombuilder); add_subdirectory (geombuilder) # special CMakeLists.txt; endif(); add_subdirectory (geompainter) # special CMakeLists.txt. if(gdml); add_subdirectory(gdml); if(NOT gnuinstall); install(DIRECTORY gdml/ DESTINATION geom/gdml; FILES_MATCHING PATTERN ""*.py""; PATTERN ""inc"" EXCLUDE; PATTERN ""src"" EXCLUDE); endif(); endif(). if(vecgeom); add_subdirectory(vecgeom); endif(). if(webgui); add_subdirectory(webviewer); endif(). ROOT_ADD_TEST_SUBDIRECTORY(test); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/CMakeLists.txt:439,install,install,439,geom/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/CMakeLists.txt,1,['install'],['install']
Deployability,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. cmake_minimum_required(VERSION 3.10); # This is a test of the Minuit2 CMake build system. project(Quad1F LANGUAGES CXX). # CMake should be able to find the Minuit2 package if you have either built it or installed it; find_package(Minuit2 CONFIG REQUIRED). # Reusing the existing test file for simplicity; add_executable(Quad1F; ../../test/MnTutorial/Quad1FMain.cxx; ../../test/MnTutorial/Quad1F.h; ). # Linking with Minuit2::Minuit2 target; target_link_libraries(Quad1F PUBLIC Minuit2::Minuit2). # Run this executable as a test with make test; enable_testing(); add_test(NAME Quad1F COMMAND Quad1F); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/examples/simple/CMakeLists.txt:398,install,installed,398,math/minuit2/examples/simple/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/examples/simple/CMakeLists.txt,1,['install'],['installed']
Deployability,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. if(NOT MSVC AND _BUILD_TYPE_UPPER MATCHES ""DEBUG|RELWITHDEBINFO""); file(GLOB PRETTY_PRINTERS ""*.so-gdb.py""); if(NOT roofit); list(FILTER PRETTY_PRINTERS EXCLUDE REGEX libRooFitCore.so-gdb.py); endif(); set(PRETTY_PRINTER_DESTS); foreach(PRETTY_PRINTER ${PRETTY_PRINTERS}); get_filename_component(PRETTY_PRINTER_DEST ${PRETTY_PRINTER} NAME); if(soversion); string(REPLACE "".so-gdb.py"" "".so.${ROOT_VERSION}-gdb.py""; PRETTY_PRINTER_DEST ${PRETTY_PRINTER_DEST}); endif(soversion); set(PRETTY_PRINTER_DEST ${CMAKE_BINARY_DIR}/lib/${PRETTY_PRINTER_DEST}); add_custom_command(OUTPUT ${PRETTY_PRINTER_DEST}; COMMAND ${CMAKE_COMMAND} -E copy ${PRETTY_PRINTER} ${PRETTY_PRINTER_DEST}; DEPENDS ${PRETTY_PRINTER}); list(APPEND PRETTY_PRINTER_DESTS ${PRETTY_PRINTER_DEST}); endforeach(); add_custom_target(copy_pretty_printers ALL DEPENDS ${PRETTY_PRINTER_DESTS}). install(FILES ${PRETTY_PRINTER_DESTS}; DESTINATION ${CMAKE_INSTALL_LIBDIR}; CONFIGURATIONS Debug RelWithDebInfo); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/misc/gdbPrinters/CMakeLists.txt:1047,install,install,1047,misc/gdbPrinters/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/misc/gdbPrinters/CMakeLists.txt,1,['install'],['install']
Deployability,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. include(ExternalProject). find_package(libuuid REQUIRED); find_package(LibXml2 REQUIRED); find_package(OpenSSL REQUIRED). set(DAVIX_VERSION ""0.8.7""); set(DAVIX_URL ""http://lcgpackages.web.cern.ch/lcgpackages/tarFiles/sources""); set(DAVIX_URLHASH ""SHA256=78c24e14edd7e4e560392d67147ec8658c2aa0d3640415bdf6bc513afcf695e6""); set(DAVIX_PREFIX ${CMAKE_CURRENT_BINARY_DIR}/DAVIX-prefix); set(DAVIX_LIBNAME ${CMAKE_STATIC_LIBRARY_PREFIX}davix${CMAKE_STATIC_LIBRARY_SUFFIX}). list(APPEND DAVIX_LIBRARIES ${DAVIX_PREFIX}/lib/${CMAKE_STATIC_LIBRARY_PREFIX}davix${CMAKE_STATIC_LIBRARY_SUFFIX}); list(APPEND DAVIX_LIBRARIES ${DAVIX_PREFIX}/src/DAVIX-build/deps/curl-install/usr/lib/${CMAKE_STATIC_LIBRARY_PREFIX}curl${CMAKE_STATIC_LIBRARY_SUFFIX}). string(REPLACE ""-Werror "" """" DAVIX_CXX_FLAGS ""${CMAKE_CXX_FLAGS} ""). ExternalProject_Add(DAVIX; URL ${DAVIX_URL}/davix-${DAVIX_VERSION}.tar.gz; URL_HASH ${DAVIX_URLHASH}; CMAKE_CACHE_ARGS; -DCMAKE_PREFIX_PATH:STRING=${OPENSSL_PREFIX}; -DUUID_INCLUDE_DIR:STRING=${UUID_INCLUDE_DIR}; -DUUID_LIBRARY:STRING=${UUID_LIBRARY}; -DLIBXML2_INCLUDE_DIR:PATH=${LIBXML2_INCLUDE_DIR}; -DLIBXML2_INCLUDE_DIRS:STRING=${LIBXML2_INCLUDE_DIRS}; -DLIBXML2_LIBRARY:PATH=${LIBXML2_LIBRARY}; -DLIBXML2_LIBRARIES:STRING=${LIBXML2_LIBRARIES}; CMAKE_ARGS; -DCMAKE_INSTALL_PREFIX=<INSTALL_DIR>; -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE}; -DENABLE_HTML_DOCS=OFF; -DENABLE_IPV6=OFF; -DSTATIC_LIBRARY=ON; -DSHARED_LIBRARY=OFF; -DENABLE_TOOLS=OFF; -DDAVIX_TESTS=OFF; -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}; -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER}; -DCMAKE_C_FLAGS=${CMAKE_C_FLAGS}; -DCMAKE_CXX_FLAGS=${DAVIX_CXX_FLAGS}\ -fPIC; -DCMAKE_OSX_SYSROOT=${CMAKE_OSX_SYSROOT}; -DCMAKE_OSX_DEPLOYMENT_TARGET=${CMAKE_OSX_DEPLOYMENT_TARGET}; -DLIB_SUFFIX=; PATCH_COMMAND sed -i """" -e ""s|sed -i '| sed -i \""\"" '",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/builtins/davix/CMakeLists.txt:849,install,install,849,builtins/davix/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/builtins/davix/CMakeLists.txt,1,['install'],['install']
Deployability,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. project(GLEW C). find_package(OpenGL REQUIRED). include_directories (${CMAKE_CURRENT_SOURCE_DIR}/inc). set(GLEW_HEADERS; inc/GL/glew.h; inc/GL/glxew.h; inc/GL/wglew.h; ). set(GLEW_SOURCES; src/glew.c; ). unset(GLEW_FOUND CACHE); unset(GLEW_FOUND PARENT_SCOPE); set(GLEW_FOUND TRUE CACHE BOOL """" FORCE). set(GLEW_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/inc CACHE INTERNAL """" FORCE); set(GLEW_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/inc CACHE INTERNAL """" FORCE). if(APPLE); if(NOT cocoa); set(GLEW_DEFINITIONS -DGLEW_APPLE_GLX); endif(); endif(). if(NOT MSVC); add_library(GLEW SHARED ${GLEW_HEADERS} ${GLEW_SOURCES}); target_compile_options(GLEW PRIVATE -fPIC); else(); add_library(GLEW STATIC ${GLEW_HEADERS} ${GLEW_SOURCES}); set_target_properties(GLEW PROPERTIES COMPILE_DEFINITIONS ""GLEW_STATIC"" PREFIX ""lib""); target_compile_definitions (GLEW PRIVATE ""GLEW_STATIC""); endif(); target_compile_options(GLEW PRIVATE ${GLEW_DEFINITIONS}); target_include_directories(GLEW INTERFACE $<BUILD_INTERFACE:${GLEW_INCLUDE_DIR}>); target_link_libraries(GLEW PRIVATE OpenGL::GL OpenGL::GLU). target_link_libraries(GLEW::GLEW INTERFACE GLEW). set(GLEW_LIBRARY $<TARGET_FILE:GLEW> CACHE INTERNAL """"); set(GLEW_LIBRARIES GLEW::GLEW CACHE INTERNAL """"). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS GLEW::GLEW). install(TARGETS GLEW; LIBRARY DESTINATION lib; ARCHIVE DESTINATION lib; ). ROOT_INSTALL_HEADERS(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/builtins/glew/CMakeLists.txt:1504,install,install,1504,builtins/glew/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/builtins/glew/CMakeLists.txt,1,['install'],['install']
Deployability,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. set(py_sources; cppyy/_stdcpp_fix.py; cppyy/__init__.py; cppyy/_cpython_cppyy.py; cppyy/_pypy_cppyy.py; cppyy/_pythonization.py; cppyy/_typemap.py; cppyy/_version.py; cppyy/interactive.py; cppyy/ll.py; cppyy/numba_ext.py; cppyy/reflex.py; cppyy/types.py; ). set(cppyyPySrcDir python/cppyy); file(COPY ${cppyyPySrcDir} DESTINATION ${localruntimedir}). # Compile .py files; foreach(py_source ${py_sources}); install(CODE ""execute_process(COMMAND ${Python3_EXECUTABLE} -m py_compile ${localruntimedir}/${py_source})""); install(CODE ""execute_process(COMMAND ${Python3_EXECUTABLE} -O -m py_compile ${localruntimedir}/${py_source})""); endforeach(). # Install Python sources and bytecode; install(DIRECTORY ${localruntimedir}/cppyy; DESTINATION ${CMAKE_INSTALL_PYTHONDIR}; COMPONENT libraries); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/CMakeLists.txt:601,install,install,601,bindings/pyroot/cppyy/cppyy/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/CMakeLists.txt,3,['install'],['install']
Deployability,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. set(roofit_legacy_eval_backend ON CACHE BOOL """" FORCE). add_subdirectory(batchcompute); if (roofit_multiprocess); add_subdirectory(roofitZMQ); add_subdirectory(multiprocess); endif(); add_subdirectory(roofitcore); add_subdirectory(roofit); if(mathmore); add_subdirectory(roofitmore); endif(); add_subdirectory(roostats); add_subdirectory(histfactory); add_subdirectory(jsoninterface); add_subdirectory(hs3); if(roofit_legacy_eval_backend AND NOT MSVC); add_subdirectory(xroofit); endif(). generateManual(hist2workspaceMan; ${CMAKE_CURRENT_SOURCE_DIR}/histfactory/src/hist2workspace-argparse.py; ${CMAKE_BINARY_DIR}/man/hist2workspace.1). set(roofit_etc_files; etc/HistFactorySchema.dtd; etc/RooFitHS3_wsfactoryexpressions.json; etc/RooFitHS3_wsexportkeys.json; ). foreach(roofit_etc_file ${roofit_etc_files}); configure_file(""${CMAKE_CURRENT_SOURCE_DIR}/${roofit_etc_file}"" ""${CMAKE_BINARY_DIR}/${roofit_etc_file}"" COPYONLY); endforeach(). install(FILES ${roofit_etc_files} DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}); install(DIRECTORY man/ DESTINATION ${CMAKE_INSTALL_MANDIR} ${DIR_PERMISSIONS}); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/CMakeLists.txt:1135,install,install,1135,roofit/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/CMakeLists.txt,2,['install'],['install']
Deployability,"# Copyright (C) 1995-2023, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. #####################################################################################################################. # Details about integrating ROOT into CMake projects:; # https://root.cern/manual/integrate_root_into_my_cmake_project/. #####################################################################################################################. # CMakeLists.txt that creates a library with dictionary and a main program; cmake_minimum_required(VERSION 3.10 FATAL_ERROR). project(treeUsingCustomClass). #---Locate the ROOT package and defines a number of variables (e.g. ROOT_INCLUDE_DIRS); find_package(ROOT REQUIRED COMPONENTS Tree TreePlayer ROOTDataFrame). #---Include a CMake module which makes use of the previous variables and loads modules ; # with useful macros or functions such as ROOT_GENERATE_DICTIONARY; # For further details: https://root-forum.cern.ch/t/how-to-integrate-root-into-my-project-with-cmake/37175; include(${ROOT_USE_FILE}). #---Add include directory of ROOT to the build; include_directories(${CMAKE_SOURCE_DIR}). # CMake function provided by ROOT, used to generate the dictionary file, G__data2Tree.cxx; # See this link for further details:; # https://root.cern/manual/io_custom_classes/#using-cmake; ROOT_GENERATE_DICTIONARY(G__data2Tree data2Tree.hxx LINKDEF data2TreeLinkDef.hxx). #---Create a shared library from; # * the previously generated dictionary, G__data2Tree.cxx; # * the class implementation; add_library(data2TreeLib SHARED data2Tree.cxx G__data2Tree.cxx); target_link_libraries(data2TreeLib ${ROOT_LIBRARIES} ) ; add_dependencies(data2TreeLib G__data2Tree ). #--- This is needed on Windows in order to export the symbols and create the data2TreeLib.lib file; if(MSVC); set_target_properties(data2TreeLib PROPERTIES WINDOWS_EXPORT_ALL_SYMBOLS TRUE)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/tree/dictionary/CMakeLists.txt:330,integrat,integrating,330,tutorials/tree/dictionary/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/tree/dictionary/CMakeLists.txt,1,['integrat'],['integrating']
Deployability,"# Copyright (C) 1995-2023, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. cmake_minimum_required(VERSION 3.10 FATAL_ERROR). project(RootShower). find_package(ROOT REQUIRED). set(CMAKE_CXX_FLAGS ${ROOT_CXX_FLAGS}). include_directories(${ROOT_INCLUDE_DIRS} ${CMAKE_CURRENT_SOURCE_DIR}). set(SOURCES; GButtonFrame.cxx; GTitleFrame.cxx; MyDetector.cxx; MyEvent.cxx; MyParticle.cxx; RootShower.cxx; RSAbout.cxx; RSHelpText.cxx; RSMsgBox.cxx; SettingsDlg.cxx; ). set(HEADERS MyParticle.h MyDetector.h MyEvent.h). if(MSVC); set(RCFILE RootShower.rc); endif(). ROOT_GENERATE_DICTIONARY(RootShowerDict ${HEADERS} LINKDEF RSLinkDef.h); file(COPY ${HEADERS} DESTINATION ${CMAKE_CURRENT_BINARY_DIR}); file(COPY "".rootshowerrc"" DESTINATION ${CMAKE_CURRENT_BINARY_DIR}). add_executable(RootShower ${SOURCES} RootShowerDict.cxx ${RCFILE}); target_link_libraries(RootShower ROOT::Core ROOT::Rint ROOT::Gui ROOT::RIO ROOT::Hist ROOT::Gpad; ROOT::Graf ROOT::EG ROOT::Html ROOT::Geom ROOT::Tree; ); set_target_properties(RootShower PROPERTIES ENABLE_EXPORTS 1); if(MSVC AND NOT CMAKE_GENERATOR MATCHES Ninja); add_custom_command(TARGET RootShower POST_BUILD; COMMAND ${CMAKE_COMMAND} -E copy ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIG>/RootShower.exe; ${CMAKE_CURRENT_BINARY_DIR}; ); set_target_properties(RootShower PROPERTIES WINDOWS_EXPORT_ALL_SYMBOLS TRUE); endif(). file(COPY anim DESTINATION ${CMAKE_CURRENT_BINARY_DIR}); file(COPY icons DESTINATION ${CMAKE_CURRENT_BINARY_DIR}). install(TARGETS RootShower RUNTIME DESTINATION ${PROJECT_NAME} COMPONENT applications); install(DIRECTORY anim DESTINATION ${PROJECT_NAME}/anim COMPONENT anim); install(DIRECTORY icons DESTINATION ${PROJECT_NAME}/icons COMPONENT icons); install(FILES ${HEADERS} DESTINATION ${PROJECT_NAME} COMPONENT headers); install(FILES "".rootshowerrc"" DESTINATION ${PROJECT_NAME} COMPONENT settings); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/test/RootShower/CMakeLists.txt:1582,install,install,1582,test/RootShower/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/test/RootShower/CMakeLists.txt,5,['install'],['install']
Deployability,"# Discourse Migration Guide . ## Current Status of Migration: Discourse is back online at a new URL: [https://discourse.llvm.org](https://discourse.llvm.org). The old one still works as well. We are aware of an issue with reply by email to emails from before the merge. We will update once we know more. This document is intended to help LLVM users to migrate from the mailing lists to; Discourse. Discourse has two basic ways for interaction: Via the [web; UI](https://llvm.discourse.group/) and via emails. ## Setting up your account. The easiest way is to create an account using your GitHub account:. 1. Navigate to https://llvm.discourse.group/; 1. Click on ""Sign Up"" in the top right corner.; 1. Choose ""With GitHub"" on the right side and log in with your GitHub account. ## Structure of Discourse. Discourse's structure is similar to a set of mailing lists, however different; terms are used there. To help with the transition, here's a translation table; for the terms:. <table border=1>; <tr><th>Mailing list</th><th>Discourse</th></tr>; <tr><td><i>Mailing list</i>, consists of threads</td><td><i>category</i>, consists of topics</td></tr>; <tr><td><i>thread</i>, consists of emails</td><td><i>topic</i>, consists of posts</td></tr>; <tr><td>email</td><td>post</td></tr>; </table>. ## Setting up email interactions. Some folks want to interact with Discourse purely via their email program. Here; are the typical use cases:. * You can [subscribe to a category or topic](https://discourse.mozilla.org/t/how-do-i-subscribe-to-categories-and-topics/16024); * You can reply to a post, including quoting other peoples texts; ([tested](https://llvm.discourse.group/t/email-interaction-with-discourse/3306/4) on GMail).; * [Quoting previous topics in an reply](https://meta.discourse.org/t/single-quote-block-dropped-in-email-reply/144802); * You can filter incoming emails in your email client by category using the; `List-ID` email header field.; * You can create topics through email using the e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:278,update,update,278,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,1,['update'],['update']
Deployability,"# Do not depend on CMake scripts from the rest of the ROOT build; set(CMAKE_MODULE_PATH """"). #--- Check if we need to build llvm and clang ------------------------------------------------------; if (NOT builtin_clang); message(WARNING ""Due to ROOT-specific patches you need a special version of clang. You cannot use vanilla clang.""); endif(). #--Set the LLVM version required for ROOT-----------------------------------------------------------; set(ROOT_LLVM_VERSION_REQUIRED_MAJOR 18). #---Define the way we want to build and what of llvm/clang/cling------------------------------------; set(LLVM_ENABLE_RTTI ON CACHE BOOL """"); set(LLVM_APPEND_VC_REV OFF CACHE BOOL """"); set(LLVM_ENABLE_BINDINGS OFF CACHE BOOL """"); set(LLVM_ENABLE_FFI OFF CACHE BOOL """"); set(LLVM_ENABLE_OCAMLDOC OFF CACHE BOOL """"); set(LLVM_ENABLE_Z3_SOLVER OFF CACHE BOOL """"); set(LLVM_ENABLE_WARNINGS OFF CACHE BOOL """"); set(CLANG_ENABLE_STATIC_ANALYZER OFF CACHE BOOL """"); set(CLANG_ENABLE_ARCMT OFF CACHE BOOL """"); set(LLVM_INCLUDE_TESTS OFF CACHE BOOL """"); set(LLVM_INCLUDE_BENCHMARKS OFF CACHE BOOL """"); set(CLANG_INCLUDE_TESTS OFF CACHE BOOL """"); set(LLVM_INCLUDE_EXAMPLES OFF CACHE BOOL """"); set(CLANG_BUILD_TOOLS OFF CACHE BOOL """"); # It looks like that turning off CLANG_BUILD_TOOLS is not enough.; set(CLANG_TOOL_ARCMT_TEST_BUILD OFF CACHE BOOL """"); set(CLANG_TOOL_CLANG_CHECK_BUILD OFF CACHE BOOL """"); set(CLANG_TOOL_CLANG_FORMAT_BUILD OFF CACHE BOOL """"); set(CLANG_TOOL_CLANG_FORMAT_VS_BUILD OFF CACHE BOOL """"); set(CLANG_TOOL_CLANG_FUZZER_BUILD OFF CACHE BOOL """"); set(CLANG_TOOL_CLANG_IMPORT_TEST_BUILD OFF CACHE BOOL """"); set(CLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD OFF CACHE BOOL """"); set(CLANG_TOOL_CLANG_RENAME_BUILD OFF CACHE BOOL """"); set(CLANG_TOOL_C_ARCMT_TEST_BUILD OFF CACHE BOOL """"); set(CLANG_TOOL_C_INDEX_TEST_BUILD OFF CACHE BOOL """"); set(CLANG_TOOL_DIAGTOOL_BUILD OFF CACHE BOOL """"); set(CLANG_TOOL_LIBCLANG_BUILD OFF CACHE BOOL """"); set(CLANG_TOOL_SCAN_BUILD_BUILD OFF CACHE BOOL """"); set(CLANG_TOOL_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/CMakeLists.txt:257,patch,patches,257,interpreter/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/CMakeLists.txt,1,['patch'],['patches']
Deployability,"# Example analysis illustrating the use of rootdrawtree / TSimpleAnalysis.; # Run as:; # $ rootdrawtree tutorials/tree/simpleAnalysis.txt. file_output.root #the output file in which histograms are stored. # The next line has the name of the tree of the input data. It is; # optional if there is exactly one tree in the first input file.; ntuple #name of the input tree. # The lines of the next block correspond to .root input files that; # contain the tree. In this case we use only one input file.; tutorials/hsimple.root # this is the input file. # The next block is composed by lines that allow to configure the; # histograms. They have the following syntax:; # NAME = EXPRESSION if CUT; # which corresponds to chain->Draw(""EXPRESSION >> NAME"", ""CUT""); # i.e. it will create a histogram called NAME and store it in; # file_output.root.; # ""if CUT"" is optional; hpx=px if px<-3 #first histogram; hpxpy=px:py #second histogram. # End of the configuration file; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/tree/simpleAnalysis.txt:942,configurat,configuration,942,tutorials/tree/simpleAnalysis.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/tree/simpleAnalysis.txt,1,['configurat'],['configuration']
Deployability,"# Getting Started. We begin by showing you how to use ROOT interactively. There are two; examples to click through and learn how to use the GUI. We continue by; using the command line, and explaining the coding conventions, global; variables and the environment setup. If you have not installed ROOT,; you can do so by following the instructions in the appendix, or on the; ROOT web site: <http://root.cern.ch/root/Availability.html>. ## Setting the Environment Variables. Before you can run ROOT you need to set the environment variable; `ROOTSYS` and change your path to include `root/bin` and library path; variables to include `root/lib`. Please note: the syntax is for; `bash`, if you are running `tcsh` you will have to use `setenv`; instead of `export`. 1. Define the variable \$ROOTSYS to the directory where you unpacked; the ROOT:. ```; $ export ROOTSYS=$HOME/root; ```. 2. Add ROOTSYS/bin to your PATH:. ```; $ export PATH=$PATH:$ROOTSYS/bin; ```. 3. Setting the Library Path. On HP-UX, before executing the interactive module, you must set the; library path:. ```; $ export SHLIB_PATH=$SHLIB_PATH:$ROOTSYS/lib; ```. On AIX, before executing the interactive module, you must set the; library path:. ```; $ [ -z ""$LIBPATH"" ] && export LIBPATH=/lib:/usr/lib; $ export LIBPATH=$LIBPATH:$ROOTSYS/lib; ```. On Linux, Solaris, Alpha OSF and SGI, before executing the interactive; module, you must set the library path:. ```; $ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$ROOTSYS/lib; ```. On Solaris, in case your LD\_LIBRARY\_PATH is empty, you should set; it:. ```; $ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$ROOTSYS/lib:/usr/dt/lib; ```. If you use the `afs` version you should set (*vers* = version number,; *arch* = architecture):. ```; $ export ROOTSYS=/afs/cern.ch/sw/lcg/external/root/vers/arch/root; ```. If ROOT was installed in `$HOME/myroot` directory on a local machine,; one can do:. ```; cd $HOME/myroot; . bin/thisroot.sh // or source bin/thisroot.sh; ```. The new `$ROOTSYS/bin/this",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md:285,install,installed,285,documentation/users-guide/GettingStarted.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md,1,['install'],['installed']
Deployability,"# Install nlohmann/json.hpp include to have it. # file only used when ACLiC or ROOT macros will include REve headers,; # it is not used for ROOT compilation. # extract version from existing header file; file(STRINGS ""json.hpp"" JSON_H REGEX ""^#define NLOHMANN_JSON_VERSION_[A-Z]+[ ]+[0-9]+.*$""); string(REGEX REPLACE "".+NLOHMANN_JSON_VERSION_MAJOR[ ]+([0-9]+).*$"" ""\\1"" JSON_VERSION_MAJOR ""${JSON_H}""); string(REGEX REPLACE "".+NLOHMANN_JSON_VERSION_MINOR[ ]+([0-9]+).*$"" ""\\1"" JSON_VERSION_MINOR ""${JSON_H}""); string(REGEX REPLACE "".+NLOHMANN_JSON_VERSION_PATCH[ ]+([0-9]+).*$"" ""\\1"" JSON_VERSION_PATCH ""${JSON_H}""); set(nlohmann_json_VERSION ""${JSON_VERSION_MAJOR}.${JSON_VERSION_MINOR}.${JSON_VERSION_PATCH}"" PARENT_SCOPE); unset(JSON_H). add_custom_command(; OUTPUT ${CMAKE_BINARY_DIR}/include/nlohmann/json.hpp; COMMAND ${CMAKE_COMMAND} -E copy ${CMAKE_SOURCE_DIR}/builtins/nlohmann/json.hpp ${CMAKE_BINARY_DIR}/include/nlohmann/json.hpp; COMMENT ""Copying nlohmann/json.hpp header to ${CMAKE_BINARY_DIR}/include""; DEPENDS ${CMAKE_SOURCE_DIR}/builtins/nlohmann/json.hpp). add_custom_target(builtin_nlohmann_json_incl DEPENDS ${CMAKE_BINARY_DIR}/include/nlohmann/json.hpp). set_property(GLOBAL APPEND PROPERTY ROOT_HEADER_TARGETS builtin_nlohmann_json_incl). install(FILES ${CMAKE_SOURCE_DIR}/builtins/nlohmann/json.hpp DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}/nlohmann/). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/builtins/nlohmann/CMakeLists.txt:1260,install,install,1260,builtins/nlohmann/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/builtins/nlohmann/CMakeLists.txt,1,['install'],['install']
Deployability,"# JavaScript ROOT. The JSROOT project allows:; - reading of binary and JSON ROOT files in JavaScript;; - drawing of different ROOT classes in web browsers;; - reading and drawing TTree data;; - using in node.js. ## Installing JSROOT. In most practical cases it is not necessary to install JSROOT - it can be used directly from project web sites <https://root.cern/js/> and <https://jsroot.gsi.de/>. When required, there are following alternatives to install JSROOT on other web servers:. - download and unpack [provided](https://github.com/root-project/jsroot/releases) packages (recommended); - use [npm](https://npmjs.com/package/jsroot) package manager and invoke `npm install jsroot`; - clone master branch from [repository](https://github.com/root-project/jsroot/). ## Drawing objects in JSROOT. [The main page](https://root.cern/js/latest/) of the JSROOT project provides the possibility to interactively open ROOT files and draw objects like histogram or canvas. To automate files loading and objects drawing, one can provide number of URL parameters in address string like:. - file - name of the file, which will be automatically open with page loading; - files - array of file names for loading; - json - name of JSON file with stored ROOT object like histogram or canvas; - item - item name to be displayed; - opt - drawing option for the item; - items - array of items name to be displayed; - opts - array of drawing options for the items; - expand - item name(s) to be expanded in the hierarchy browser; - focus - item name to be focused on in the hierarchy browser; - title - set browser title; - dir - list files in directory on http server, see https://github.com/root-project/jsroot/issues/283; - layout - can be 'simple', 'flex', 'tabs', 'gridNxM', 'horizNMK', 'vertNMK'; - browser - layout of the browser 'fix' (default), 'float', 'no' (hidden), 'off' (fully disabled); - nobrowser - do not display file browser (same as browser=no); - float - display floating browser (same as brows",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:281,install,install,281,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,4,"['install', 'release']","['install', 'releases']"
Deployability,"# JupyROOT; A software layer to integrate Jupyter notebooks and ROOT. ## Installation; 1. [Install ROOT6](https://root.cern.ch/building-root) (> 6.05); 2. Install dependencies: `pip install jupyter metakernel`. ## Start using ROOTbooks; Set up the ROOT environment (`. $ROOTSYS/bin/thisroot.[c]sh`) and type in your; shell:; ```shell; root --notebook; ```; This will start a ROOT-flavoured notebook server in your computer. Alternatively, if you would like to use the Jupyter command directly, you; can do:; ```shell; jupyter kernelspec install $ROOTSYS/etc/root/notebook/kernels/root --user; ```. Once the server is up, you can use ROOT with two kernels:. 1. ROOT C++: new kernel provided by ROOT; 2. Python: already provided by Jupyter. ## C++ ROOTbook; ROOT offers a C++ kernel that transforms the notebook in a ROOT prompt.; Embedded graphics, syntax highlighting and tab completion are among; the features provided by this kernel. An example of how you would plot a histogram in a C++ ROOTbook is:; ```cpp; TCanvas c;; TH1F h(""h"",""ROOT Histo;X;Y"",64,-4,4);; h.FillRandom(""gaus"");; h.Draw();; c.Draw();; ```. ## Python ROOTbook; If you prefer to use Python, you can create a new Python kernel and; import the ROOT libraries:; ```python; import ROOT; ```; And then you could write something like:; ```python; c = ROOT.TCanvas(""c""); h = ROOT.TH1F(""h"",""ROOT Histo;X;Y"",64,-4,4); ```; Additionally, you can mix Python and C++ in the same notebook; by using the **%%cpp** magic:; ```cpp; %%cpp; h->FillRandom(""gaus"");; h->Draw();; c->Draw();; ```; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/jupyroot/README.md:32,integrat,integrate,32,bindings/jupyroot/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/jupyroot/README.md,3,"['install', 'integrat']","['install', 'integrate']"
Deployability,"# Jupyter Tools for TableGen. This folder contains notebooks relating to TableGen and a Jupyter kernel for; TableGen. ## Notebooks. [LLVM_TableGen.ipynb](LLVM_TableGen.ipynb) - A demo of the kernel's capabilities. [tablegen_tutorial_part_1.ipynb](tablegen_tutorial_part_1.ipynb) - A tutorial on the TableGen language. [sql_query_backend.ipynb](sql_query_backend.ipynb) - How to write a backend using; JSON output and Python. Notebooks can be viewed in browser on Github or downloaded and run locally. If; that is not possible, there are Markdown versions next to the notebook files. ## TableGen Kernel. To use the kernel, first install it into jupyter. If you have installed Jupyter into a virtual environment, adjust `python3` to; be the interpreter for that environment. This will ensure that tools run the; kernel in the correct context. ```shell; python3 -m tablegen_kernel.install; ```. If you are going to open the notebook in an IDE like Visual Studio Code,; you should restart it now so that it will find the newly installed kernel. Then run one of:. ```shell; jupyter notebook; # Then in the notebook interface, select 'LLVM TableGen' from the 'New' menu. # To run the example notebook in this folder.; jupyter notebook LLVM_TableGen.ipynb. # To use the kernel from the command line.; jupyter console --kernel tablegen; ```. Or open the notebook in a tool with built in Jupyter support. `llvm-tblgen` is expected to be either in the `PATH` or you can set; the environment variable `LLVM_TBLGEN_EXECUTABLE` to point to it directly. If you see an error like this:; ```shell; Cell In[8], line 2; // This is some tablegen; ^; SyntaxError: invalid syntax; ```. You are probably running the notebook using the iPython kernel. Make sure you; have selected the tablegen kernel. To run the kernel's doctests do:. ```shell; python3 tablegen_kernel/kernel.py; ```; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md:628,install,install,628,interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md,4,['install'],"['install', 'installed']"
Deployability,"# Math Libraries in ROOT. The aim of Math libraries in ROOT is to provide and to support a; coherent set of mathematical and statistical functions. The latest; developments have been concentrated in providing first versions of the; `MathCore` and `MathMore` libraries, included in ROOT v5.08. Other; recent developments include the new version of `MINUIT`, which has been; re-designed and re-implemented in the C++ language. It is integrated in; ROOT. In addition, an optimized package for describing small matrices; and vector with fixed sizes and their operation has been developed; (`SMatrix`). The structure is shown in the following picture. ![Math libraries and packages](pictures/02000109.jpg). ## MathCore Library. `MathCore` provides a collection of functions and C++ classes for; numerical computing. This library includes only the basic mathematical; functions and algorithms and not all the functionality required by the; physics community. A more advanced mathematical functionality is; provided by the `MathMore` library. The current set of included classes,; which are provided in the `ROOT::Math` namespace are:. - Basic special functions like the gamma, beta and error function. - Mathematical functions used in statistics, such as the probability; density functions and the cumulative distributions functions (lower; and upper integral of the pdf's). - Generic function classes and interfaces; for evaluating one-dimensional (`ROOT::Math::IBaseFunctiononeDim`) and multi-dimensional functions; (`ROOT::Math::IBaseFunctionMultiDim`) and parametric function interfaces for evaluating functions with parameters in one; (`ROOT::Math::IParametricFunctionOneDim`) or multi dimensions (`ROOT::Math::IParametricFunctionMultiDim`).; 	A set of user convenient wrapper classes, such as `ROOT::Math::Functor` is provided for wrapping user-classes in the needed interface,; 	required to use the algorithms of the `ROOT` Mathematical libraries. - Numerical algorithms interfaces and in same cases ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:431,integrat,integrated,431,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['integrat'],['integrated']
Deployability,"# OS X 10.11 El Capitan has just been released. One of the new features, System; # Integrity Protection, prevents modifying the base OS install, even with sudo.; # This prevents LLVM developers on OS X from being able to easily install new; # system compilers. The feature can be disabled, but to make it easier for; # developers to work without disabling SIP, this file can generate an Xcode; # toolchain. Xcode toolchains are a mostly-undocumented feature that allows; # multiple copies of low level tools to be installed to different locations, and; # users can easily switch between them. # Setting an environment variable TOOLCHAINS to the toolchain's identifier will; # result in /usr/bin/<tool> or xcrun <tool> to find the tool in the toolchain. # To make this work with Xcode 7.1 and later you can install the toolchain this; # file generates anywhere on your system and set EXTERNAL_TOOLCHAINS_DIR to the; # path specified by $CMAKE_INSTALL_PREFIX/Toolchains. # This file generates a custom install-xcode-toolchain target which constructs; # and installs a toolchain with the identifier in the pattern:; # org.llvm.${PACKAGE_VERSION}. This toolchain can then be used to override the; # system compiler by setting TOOLCHAINS=org.llvm.${PACKAGE_VERSION} in the; # in the environment. # Example usage:; # cmake -G Ninja -DLLVM_CREATE_XCODE_TOOLCHAIN=On; # -DCMAKE_INSTALL_PREFIX=$PWD/install; # ninja install-xcode-toolchain; # export EXTERNAL_TOOLCHAINS_DIR=$PWD/install/Toolchains; # export TOOLCHAINS=org.llvm.3.8.0svn. # `xcrun -find clang` should return the installed clang, and `clang --version`; # should show 3.8.0svn. if(NOT APPLE); return(); endif(). option(LLVM_CREATE_XCODE_TOOLCHAIN ""Create a target to install LLVM into an Xcode toolchain"" Off). if(NOT LLVM_CREATE_XCODE_TOOLCHAIN); return(); endif(). # XCODE_VERSION is set by CMake when using the Xcode generator, otherwise we need; # to detect it manually here.; if(NOT XCODE_VERSION); execute_process(; COMMAND xcodebuild -vers",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/xcode-toolchain/CMakeLists.txt:38,release,released,38,interpreter/llvm-project/llvm/tools/xcode-toolchain/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/xcode-toolchain/CMakeLists.txt,5,"['install', 'release']","['install', 'installed', 'released']"
Deployability,"# Policies on git repositories. This document explains our current policies around git repositories. Everything; not covered in this document is most likely a case-by-case decision. In these; cases please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## New GitHub repositories. Requirements for *new* repositories as part of the; [LLVM organisation on GitHub](https://github.com/llvm):. * The repo will be used for something related to the LLVM ecosystem or community.; * The repo contains a `README.md` explaining the contents.; * The repo contains a `CONTRIBUTING.md`, ideally copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/CONTRIBUTING.md).; * The repo contains a `LICENSE.TXT`, preferably copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/LICENSE.TXT).; Other licences need to be discussed case-by-case. If you want to integrate your project as part of the Monorepo, please take a; look at the; [Developer Policy](project:DeveloperPolicy.rst#Adding an Established Project To the LLVM Monorepo). To request a new repository, please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## Repo access on GitHub. Some 3rd party applications require write access to our GitHub organisation in; order to work properly. Typical examples are continuous integration services; reporting build results back to GitHub. We consider granting access to such; application if they provide benefits to the LLVM community and do not raise; privacy or security concerns. To request access please run an RFC on the mailing list and get community; feedback.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md:936,integrat,integrate,936,interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md,3,"['continuous', 'integrat']","['continuous', 'integrate', 'integration']"
Deployability,"# RNTuple Binary Format Specification 0.2.12.0. **Note:** This is work in progress. The RNTuple specification is not yet finalized. ## Versioning Notes. The RNTuple binary format version is inspired by semantic versioning.; It uses the following scheme: EPOCH.MAJOR.MINOR.PATCH. _Epoch_: an increment of the epoch indicates backward-incompatible changes.; The RNTuple pre-release has epoch 0.; The first public release will get epoch 1.; There is currently no further epoch foreseen. _Major_: an increment of the major version indicates forward-incompatible changes.; A forward-incompatible change is known to break reading in previous software versions that do not support that feature.; The use of new, forward-incompatible features must be indicated in the feature flag in the header (see below).; For the RNTuple pre-release (epoch == 0), the major version is the release candidate number. _Minor_: an increment of the minor version indicates new, optional format features.; Such optional features, although unknown to previous software versions,; won't prevent those software versions from properly reading the file.; Old readers will safely ignore these features. _Patch_: an increment of the patch version indicates backported features from newer format versions.; The backported features may correspond to a major or a minor release. Except for the epoch, the versioning is for reporting only.; Readers should use the feature flag in the header to determine whether they support reading the file. ## Introduction. The RNTuple binary format describes the serialized, on-disk representation of an RNTuple data set.; The data on disk is organized in **pages** (typically tens to hundreds of kilobytes in size); and several **envelopes** that contain information about the data such as header and footer.; The RNTuple format specifies the binary layout of the pages and the envelopes. Pages and envelopes are meant to be embedded in a data container; such as a ROOT file or a set of objects in an ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:372,release,release,372,tree/ntuple/v7/doc/BinaryFormatSpecification.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md,4,['release'],['release']
Deployability,"# ROOT Basics #. Now that you have installed ROOT, what's this interactive shell thing; you're running ? It's like this: ROOT leads a double life. It has an; interpreter for macros (Cling [@Cling]) that you can run from the command; line or run like applications. But it is also an interactive shell that; can evaluate arbitrary statements and expressions. This is extremely; useful for debugging, quick hacking and testing. Let us first have a; look at some very simple examples. ## ROOT as calculator ##. You can even use the ROOT interactive shell in lieu of a calculator!; Launch the ROOT interactive shell with the command. ``` {.cpp}; > root; ```. on your Linux box. The prompt should appear shortly:. ``` {.cpp}; root [0]; ```. and let's dive in with the steps shown here:. ``` {.cpp}; root [0] 1+1; (int) 2; root [1] 2*(4+2)/12.; (double) 1.000000; root [2] sqrt(3.); (double) 1.732051; root [3] 1 > 2; (bool) false; root [4] TMath::Pi(); (double) 3.141593; root [5] TMath::Erf(.2); (double) 0.222703; ```. Not bad. You can see that ROOT offers you the possibility not only to; type in `C++` statements, but also advanced mathematical functions,; which live in the `TMath` namespace. Now let's do something more elaborated. A numerical example with the; well known geometrical series:. ``` {.cpp}; root [6] double x=.5; (double) 0.500000; root [7] int N=30; (int) 30; root [8] double geom_series=0; (double) 0.000000; root [9] for (int i=0;i<N;++i)geom_series+=TMath::Power(x,i); root [10] cout << TMath::Abs(geom_series - (1-TMath::Power(x,N-1))/(1-x)) <<endl;; 1.86265e-09; ```. Here we made a step forward. We even declared variables and used a *for*; control structure. Note that there are some subtle differences between; Cling and the standard `C++` language. You do not need the "";"" at the end; of line in interactive mode -- try the difference e.g. using the command; at line `root [6]`. ## Learn C++ at the ROOT prompt ##; Behind the ROOT prompt there is an interpreter based on a rea",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md:35,install,installed,35,documentation/primer/ROOT_as_calculator.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md,1,['install'],['installed']
Deployability,"# ROOT Development Practice. ## Overview. The development of ROOT almost exclusively happens using the [pull request](https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/about-pull-requests); model of github. A pull request (PR) should contain a set focused changes; organized in one or more [atomic commits](https://en.wikipedia.org/wiki/Atomic_commit#Revision_control).; PRs should be well-documented and well-tested in order to allow other community; members to use, maintain and modify. If the PR contains performance-critical; code consider writing a benchmark against the [rootbench repository](https://github.com/root-project/rootbench). ## Quality Assurance. Each contribution should contain developer documentation in the form of code; comments and sufficient amount of tests in the form of unit and/or integration; tests. Unit tests are relatively small and quick programs focused to check if; small pieces of code and API work as expected. Integration tests are checks; which ensure the synergy between different (unit tested) components. Put in; practice, unit tests verify (member) function behavior whereas integration tests; check classes and their cooperation. The boundary between both kinds of testing; is blurred. ROOT has support for both kinds of tests in the [roottest repository](https://github.com/root-project/roottest); and supports ""inline"" unit tests in each component's `test` folder. Unit testing; uses the [GTest and GMock](https://github.com/google/googletest) infrastructure; along with small ROOT-specific extensions located in; [TestSupport](../core/test_support/). The documentation of GTest; and GMock is rather extensive and we will describe some of the features of; ROOT::TestSupport. In order to write an inline unit test, add a new file in the; nearest to the tested component's `test` folder and call `ROOT_ADD_GTEST` in the; `CMakeLists.txt` file. In many cases using standard GTest facility is sufficient to write a good test.; How",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/DEVELOPMENT.md:838,integrat,integration,838,README/DEVELOPMENT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/DEVELOPMENT.md,1,['integrat'],['integration']
Deployability,"# ROOT::TestSupport: the unit-test support library. This library supports ROOT's unit tests. It implements two main functions; 1. It provides a static library target `ROOT::TestSupport`. All google tests that are defined using `ROOT_ADD_GTEST` will be linked against this target.; When a test executable starts up, this will install a ROOT message handler that intercepts all messages / diagnostics.; If a message with severity > kInfo is issued, this message handler will register a test failure. This way, we are ensuring that no gtest can issue unnoticed warning or error messages.; 2. However, some warnings and errors are expected as the result of certain tests. Therefore, the library provides tools to declare when messages are expected during a test. For this,; 1. Include the header `ROOT/TestSupport.hxx`.; 2. Declare a RAII object that temporarily replaces the message handler from 1.; 3. Register the expected messages to this object, so it can check that they are indeed sent. This could look as follows:; ```c++; #include <ROOT/TestSupport.hxx>. // In a test function:; ROOT::TestSupport::CheckDiagsRAII checkDiag;; checkDiag.requiredDiag(kError, ""prepareMethod"", ""Can't compile function TFormula"", /*matchFullMessage=*/false);; checkDiag.requiredDiag(kError, ""TFormula::InputFormulaIntoCling"", ""Error compiling formula expression in Cling"", true);; // run test that generates the above errors; ```; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/testsupport/README.md:325,install,install,325,core/testsupport/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/testsupport/README.md,1,['install'],['install']
Deployability,"# See docs/CMake.html for instructions about how to build LLVM with CMake. cmake_minimum_required(VERSION 3.20.0). set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake); include(${LLVM_COMMON_CMAKE_UTILS}/Modules/CMakePolicy.cmake; NO_POLICY_SCOPE). # Builds with custom install names and installation rpath setups may not work; # in the build tree. Allow these cases to use CMake's default build tree; # behavior by setting `LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE` to do this.; option(LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE ""If set, use CMake's default build tree install name directory logic (Darwin only)"" OFF); mark_as_advanced(LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE); if(NOT LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE); set(CMAKE_BUILD_WITH_INSTALL_NAME_DIR ON); endif(). if(NOT DEFINED LLVM_VERSION_MAJOR); set(LLVM_VERSION_MAJOR 18); endif(); if(NOT DEFINED LLVM_VERSION_MINOR); set(LLVM_VERSION_MINOR 1); endif(); if(NOT DEFINED LLVM_VERSION_PATCH); set(LLVM_VERSION_PATCH 6); endif(); if(NOT DEFINED LLVM_VERSION_SUFFIX); set(LLVM_VERSION_SUFFIX); endif(). if (NOT PACKAGE_VERSION); set(PACKAGE_VERSION; ""${LLVM_VERSION_MAJOR}.${LLVM_VERSION_MINOR}.${LLVM_VERSION_PATCH}${LLVM_VERSION_SUFFIX}""); endif(). if(NOT DEFINED LLVM_SHLIB_SYMBOL_VERSION); # ""Symbol version prefix for libLLVM.so""; set(LLVM_SHLIB_SYMBOL_VERSION ""LLVM_${LLVM_VERSION_MAJOR}.${LLVM_VERSION_MINOR}""); endif(). if ((CMAKE_GENERATOR MATCHES ""Visual Studio"") AND (MSVC_TOOLSET_VERSION LESS 142) AND (CMAKE_GENERATOR_TOOLSET STREQUAL """")); message(WARNING ""Visual Studio generators use the x86 host compiler by ""; ""default, even for 64-bit targets. This can result in linker ""; ""instability and out of memory errors. To use the 64-bit ""; ""host compiler, pass -Thost=x64 on the CMake command line.""); endif(). if (CMAKE_GENERATOR STREQUAL ""Xcode"" AND NOT CMAKE_OSX_ARCHITECTURES); # Some CMake features like object libraries get confused if you don't; # explicitly specify an architecture setting with the Xcode g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:283,install,install,283,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,3,['install'],"['install', 'installation']"
Deployability,"# Support library for diagnostic handling in ROOT unit tests.; # This library is linked into all googletest executables. It installs; # a ROOT message handler that triggers test failures when diagnostics; # higher than kInfo are issued by tests.; # Stephan Hageboeck, CERN, 2022. if(NOT testsupport); return(); endif(). set(libname TestSupport); set(header_dir ROOT/). add_library(${libname} OBJECT src/TestSupport.cxx); target_include_directories(${libname} PUBLIC; $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/inc/>; $<INSTALL_INTERFACE:./>; ); target_link_libraries(${libname} PUBLIC Core gtest). # Installation of header and library:; set_target_properties(${libname} PROPERTIES PUBLIC_HEADER inc/${header_dir}/TestSupport.hxx); install(TARGETS ${libname}; EXPORT ${CMAKE_PROJECT_NAME}Exports; OBJECTS DESTINATION ${CMAKE_INSTALL_LIBDIR}/${libname}; PUBLIC_HEADER DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}/${header_dir}); set_property(GLOBAL APPEND PROPERTY ROOT_EXPORTED_TARGETS ${libname}). # Make it usable inside and outside of ROOT under a single name if somebody writes their own tests using ROOT_ADD_GTEST; add_library(ROOT::${libname} ALIAS ${libname}). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/testsupport/CMakeLists.txt:124,install,installs,124,core/testsupport/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/testsupport/CMakeLists.txt,2,['install'],"['install', 'installs']"
Deployability,"# TODO: Set the install directory. include(ExternalProject). set(known_subdirs; ""libcxx""; ). foreach (dir ${known_subdirs}); if (EXISTS ${CMAKE_CURRENT_SOURCE_DIR}/${dir}/CMakeLists.txt); add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/${dir}); endif(); endforeach(). function(get_ext_project_build_command out_var target); if (CMAKE_GENERATOR MATCHES ""Make""); # Use special command for Makefiles to support parallelism.; set(${out_var} ""$(MAKE)"" ""${target}"" PARENT_SCOPE); else(); set(${out_var} ${CMAKE_COMMAND} --build . --target ${target}; --config $<CONFIG> PARENT_SCOPE); endif(); endfunction(). set(COMPILER_RT_SRC_ROOT ${LLVM_MAIN_SRC_DIR}/projects/compiler-rt); # Fallback to the external path, if the other one isn't available.; # This is the same behavior (try ""internal"", then check the LLVM_EXTERNAL_...; # variable) as in add_llvm_external_project; if(NOT EXISTS ${COMPILER_RT_SRC_ROOT}); # We don't want to set it if LLVM_EXTERNAL_COMPILER_RT_SOURCE_DIR is """"; if(LLVM_EXTERNAL_COMPILER_RT_SOURCE_DIR); set(COMPILER_RT_SRC_ROOT ${LLVM_EXTERNAL_COMPILER_RT_SOURCE_DIR}); endif(); endif(). if(LLVM_BUILD_EXTERNAL_COMPILER_RT AND EXISTS ${COMPILER_RT_SRC_ROOT}/). # Add compiler-rt as an external project.; set(COMPILER_RT_PREFIX ${CMAKE_BINARY_DIR}/projects/compiler-rt). set(STAMP_DIR ${CMAKE_CURRENT_BINARY_DIR}/compiler-rt-stamps/); set(BINARY_DIR ${CMAKE_CURRENT_BINARY_DIR}/compiler-rt-bins/). add_custom_target(compiler-rt-clear; COMMAND ${CMAKE_COMMAND} -E remove_directory ${BINARY_DIR}; COMMAND ${CMAKE_COMMAND} -E remove_directory ${STAMP_DIR}; COMMENT ""Clobberring compiler-rt build and stamp directories""; ). # Find all variables that start with COMPILER_RT and populate a variable with; # them.; get_cmake_property(variableNames VARIABLES); foreach(variableName ${variableNames}); if(variableName MATCHES ""^COMPILER_RT""); string(REPLACE "";"" ""\;"" value ""${${variableName}}""); list(APPEND COMPILER_RT_PASSTHROUGH_VARIABLES; -D${variableName}=${value}); endif(); endforeach(). set(",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/runtime/CMakeLists.txt:16,install,install,16,interpreter/llvm-project/clang/runtime/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/runtime/CMakeLists.txt,1,['install'],['install']
Deployability,"# The C++ Interpreter Cling; \index{cling}. ROOT has a C++ interpreter called *cling* built in. It is used for the prompt, both C++ and; Python. It also serves as a source of information to store C++ objects, and; provides the back-end for ROOT's signal/slot and plug-in mechanisms. This chapter focuses on the parts of *cling* that you will encounter while; interacting with ROOT. ## The ROOT Prompt. Start up a ROOT session by typing `root` at the system prompt. ``` {.cpp}; $ root; -------------------------------------------------------------------------; | Welcome to ROOT 6.10/01 http://root.cern.ch |; | (c) 1995-2017, The ROOT Team |; | Built for macosx64 |; | From heads/v6-10-00-patches@v6-10-00-25-g9f78c3a, Jul 03 2017, 11:39:44 |; | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |; -------------------------------------------------------------------------. root [0]; ```. Now we create a `TLine` object:. ``` {.cpp}; root [1] TLine l;; root [2] l.Print(); TLine X1=0.000000 Y1=0.000000 X2=0.000000 Y2=0.000000; root [3] l.SetX1(10); root [4] l.SetY1(11); root [5] l.Print(); TLine X1=10.000000 Y1=11.000000 X2=0.000000 Y2=0.000000; root [6] .g l; .g l; ROOT_prompt_0 1 (address: NA) class TLine l, size = 72; root [7] l.GetX1();; root [8] l.GetX1(); (Double_t) 1.000000e+01; ```. Note some of the features of the ROOT prompt:; - Terminating with ‘`;`‘ is not required, see ""C++ Extensions To Ease; Scripting"" below.; - `Emacs` style command line editing.; - Raw interpreter commands start with a dot; `.g l` for instance shows the; interpreter information on the global called `l`.; - To show the result of an expression just do not type the trailing `;`. For the further examples we will ""abbreviate"" `root [0]` etc by `root []`. ``` {.cpp}; root [] .class TLine; ===========================================================================; class TLine; SIZE: 72 FILE: TLine.h LINE: 39; Base classes: --------------------------------------------------------; 0x20 public TAt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md:689,patch,patches,689,documentation/users-guide/Cling.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md,1,['patch'],['patches']
Deployability,"# The SOVERSION should be updated only if a change is made to the libclang; # ABI, and when it is updated, it should be updated to the current; # LLVM_VERSION_MAJOR.; # Please also see clang/tools/libclang/libclang.map. # This option defaults to CLANG_FORCE_MATCHING_LIBCLANG_SOVERSION; # to ON - which means that it by default matches CLANG_VERSION_MAJOR; #; # TODO: This should probably not be a option going forward but we; # we should commit to a way to do it. But due to getting this out; # in LLVM 15.x we opted for a option.; set(LIBCLANG_SOVERSION_ARG); if(NOT CLANG_FORCE_MATCHING_LIBCLANG_SOVERSION); set(LIBCLANG_SOVERSION_ARG SOVERSION 13); endif(). # TODO: harmonize usage of LIBCLANG_SOVERSION / LIBCLANG_LIBARY_VERSION; # below; this was added under time-pressure to avoid reverting the; # better default from LLVM 14 for LLVM 15.0.0-rc3, hence no time; # to clean up previous inconsistencies. set(SOURCES; ARCMigrate.cpp; BuildSystem.cpp; CIndex.cpp; CIndexCXX.cpp; CIndexCodeCompletion.cpp; CIndexDiagnostic.cpp; CIndexHigh.cpp; CIndexInclusionStack.cpp; CIndexUSRs.cpp; CIndexer.cpp; CXComment.cpp; CXCursor.cpp; CXExtractAPI.cpp; CXIndexDataConsumer.cpp; CXCompilationDatabase.cpp; CXLoadedDiagnostic.cpp; CXSourceLocation.cpp; CXStoredDiagnostic.cpp; CXString.cpp; CXType.cpp; Indexing.cpp; FatalErrorHandler.cpp; Rewrite.cpp. ADDITIONAL_HEADERS; CIndexDiagnostic.h; CIndexer.h; CXCursor.h; CXLoadedDiagnostic.h; CXSourceLocation.h; CXString.h; CXTranslationUnit.h; CXType.h; Index_Internal.h; ../../include/clang-c/Index.h; ). set(LIBS; clangAST; clangBasic; clangDriver; clangExtractAPI; clangFrontend; clangIndex; clangLex; clangRewrite; clangSema; clangSerialization; clangTooling; ). if (CLANG_ENABLE_ARCMT); list(APPEND LIBS clangARCMigrate); endif (). if (HAVE_LIBDL); list(APPEND LIBS ${CMAKE_DL_LIBS}); elseif (CLANG_BUILT_STANDALONE); find_library(DL_LIBRARY_PATH dl); if (DL_LIBRARY_PATH); list(APPEND LIBS dl); endif (); endif (). option(LIBCLANG_BUILD_STATIC; ""Build l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/libclang/CMakeLists.txt:26,update,updated,26,interpreter/llvm-project/clang/tools/libclang/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/libclang/CMakeLists.txt,3,['update'],['updated']
Deployability,"# The Tutorials and Tests. This chapter is a guide to the examples that come with the installation; of ROOT. They are located in two directories: `$ROOTSYS/tutorials` and; `$ROOTSYS/test`. ## \$ROOTSYS/tutorials. ![](pictures/030001F9.png). The tutorials directory contains many example; scripts. *To have all examples working you must have write permission; and you will need to execute`hsimple.C` first*. If you do not have write; permission in the directory` $ROOTSYS/tutorials`, copy the entire; directory to your area. The script `hsimple.C` displays a histogram as; it is being filled, and creates a ROOT file used by the other examples. To execute it type:. ``` {.cpp}; $ cd $ROOTSYS/tutorials; $ root; -------------------------------------------------------------------------; | Welcome to ROOT 6.10/01 http://root.cern.ch |; | (c) 1995-2017, The ROOT Team |; | Built for macosx64 |; | From heads/v6-10-00-patches@v6-10-00-25-g9f78c3a, Jul 03 2017, 11:39:44 |; | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |; -------------------------------------------------------------------------. root [0] .x hsimple.C; ```. Now execute `demos.C`, which brings up the button bar shown on the left.; You can click on any button to execute another example. To see the; source, open the corresponding source file (for example `fit1.C`). Once; you are done, and want to quit the ROOT session, you can do so by typing; **`.q`**. ``` {.cpp}; root[] .x demos.C; root[] .q; ```. ## \$ROOTSYS/test. The test directory contains a set of examples that represent all areas; of the framework. When a new release is cut, the examples in this; directory are compiled and run to test the new release's backward; compatibility. We see these source files:. +-------------------+--------------------------------------------------------+; | `Makefile` | Makefile to build all test programs. |; +-------------------+--------------------------------------------------------+; | `hsimple.cxx` | Simple test progra",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/TutorialsandTests.md:86,install,installation,86,documentation/users-guide/TutorialsandTests.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/TutorialsandTests.md,2,"['install', 'patch']","['installation', 'patches']"
Deployability,"# The configured file is not placed in the correct location; # until the tests are run as we need to copy it into; # a copy of the tests folder; configure_lit_site_cfg(; ""${CMAKE_CURRENT_SOURCE_DIR}/tests/lit.site.cfg.in""; ""${CMAKE_CURRENT_BINARY_DIR}/lit.site.cfg""; ). # Lit's test suite creates output files next to the sources which makes the; # source tree dirty. This is undesirable because we do out of source builds.; # To work around this the tests and the configuration file are copied into the; # build directory just before running them. The tests are not copied over at; # configure time (i.e. `file(COPY ...)`) because this could lead to stale; # tests being run.; add_custom_target(prepare-check-lit; COMMAND ${CMAKE_COMMAND} -E remove_directory ""${CMAKE_CURRENT_BINARY_DIR}/tests""; COMMAND ${CMAKE_COMMAND} -E copy_directory ""${CMAKE_CURRENT_SOURCE_DIR}/tests"" ""${CMAKE_CURRENT_BINARY_DIR}/tests""; COMMAND ${CMAKE_COMMAND} -E copy ""${CMAKE_CURRENT_BINARY_DIR}/lit.site.cfg"" ""${CMAKE_CURRENT_BINARY_DIR}/tests""; COMMENT ""Preparing lit tests""; ). # Add rules for lit's own test suite; add_lit_testsuite(check-lit ""Running lit's tests""; ${CMAKE_CURRENT_BINARY_DIR}; DEPENDS ""FileCheck"" ""not"" ""prepare-check-lit""; ). # For IDEs; set_target_properties(check-lit PROPERTIES FOLDER ""Tests""); set_target_properties(prepare-check-lit PROPERTIES FOLDER ""Tests""); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/lit/CMakeLists.txt:465,configurat,configuration,465,interpreter/llvm-project/llvm/utils/lit/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/lit/CMakeLists.txt,1,['configurat'],['configuration']
Deployability,# This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally; - [ ] updated the docs (if necessary). This PR fixes # . ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/.github/pull_request_template.md:95,update,updated,95,.github/pull_request_template.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/.github/pull_request_template.md,1,['update'],['updated']
Deployability,"# `ROOT::Math::GSLMCIntegrator`. It is a class for performing numerical integration of a multidimensional function. It uses the numerical integration algorithms of GSL, which reimplements the algorithms used; in the QUADPACK, a numerical integration package written in Fortran. Plain MC, MISER and VEGAS integration algorithms are supported for integration over finite (hypercubic) ranges.; For a detail description of the GSL methods visit the GSL users guide.; Specific configuration options (documented in the GSL user guide) for the `ROOT::Math::GSLMCIntegration` can be set directly in the class, or when using it via the `ROOT::Math::IntegratorMultiDim`; interface, can be defined using the `ROOT::Math::IntegratorMultiDimOptions`. ## Function Derivation. There are in ROOT only two classes to perform numerical derivation. One of them is in the MathCore library while the other is in the MathMore wrapping an integration function from the GSL library.; * RichardsonDerivator: Implements the Richardson method for numerical integration. It can calculate up to the third derivative of a function.; * GSLDerivator of *MathMore* based on GSL. ## Numerical Minimization. The algorithms provided by ROOT for numerical integration are implemented following the hierarchy shown in the next image. The left branch of classes are used for one dimensional minimization, while; the right one is used for multidimensional minimization. In the case of multidimensional minimization we have also the classes `TMinuitMinimizer` implemented using `TMinuit`, `TFumiliMinimizer`; implemented using `TFumili` for least square or likelihood minimizations.; We encourage the use of the GSL algorithms for one dimensional minimization and `Minuit2` (or the old version`Minuit`) for multi dimensional minimization. ![Numerical Minimization classes](pictures/Minimization.png). ### One-Dimensional Minimization. These algorithms are for finding the minimum of a one-dimensional minimization function.; The function to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:62647,integrat,integration,62647,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['integrat'],['integration']
Deployability,"# for use by clang_complete, YouCompleteMe, etc.; set(CMAKE_EXPORT_COMPILE_COMMANDS 1). option(LLVM_INSTALL_BINUTILS_SYMLINKS; ""Install symlinks from the binutils tool names to the corresponding LLVM tools."" OFF). option(LLVM_INSTALL_CCTOOLS_SYMLINKS; ""Install symlinks from the cctools tool names to the corresponding LLVM tools."" OFF). # By default we use symlinks on Unix platforms and copy binaries on Windows; # If you have the correct setup on Windows you can use this option to enable; # symlinks and save a lot of diskspace.; option(LLVM_USE_SYMLINKS ""Use symlinks instead of copying binaries"" ${CMAKE_HOST_UNIX}). option(LLVM_INSTALL_UTILS ""Include utility binaries in the 'install' target."" OFF). option(LLVM_INSTALL_TOOLCHAIN_ONLY ""Only include toolchain files in the 'install' target."" OFF). # Unfortunatly Clang is too eager to search directories for module maps, which can cause the; # installed version of the maps to be found when building LLVM from source. Therefore we turn off; # the installation by default. See llvm.org/PR31905.; option(LLVM_INSTALL_MODULEMAPS ""Install the modulemap files in the 'install' target."" OFF). option(LLVM_USE_FOLDERS ""Enable solution folders in Visual Studio. Disable for Express versions."" ON); if ( LLVM_USE_FOLDERS ); set_property(GLOBAL PROPERTY USE_FOLDERS ON); endif(). include(VersionFromVCS). option(LLVM_APPEND_VC_REV; ""Embed the version control system revision in LLVM"" ON). set(LLVM_FORCE_VC_REVISION; """" CACHE STRING ""Force custom VC revision for LLVM_APPEND_VC_REV""). set(LLVM_FORCE_VC_REPOSITORY; """" CACHE STRING ""Force custom VC repository for LLVM_APPEND_VC_REV""). option(LLVM_TOOL_LLVM_DRIVER_BUILD ""Enables building the llvm multicall tool"" OFF). set(PACKAGE_NAME LLVM); set(PACKAGE_STRING ""${PACKAGE_NAME} ${PACKAGE_VERSION}""); set(PACKAGE_BUGREPORT ""https://github.com/llvm/llvm-project/issues/""). set(BUG_REPORT_URL ""${PACKAGE_BUGREPORT}"" CACHE STRING; ""Default URL where bug reports are to be submitted.""); set(LLDB_BUG_REPORT_U",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:14299,install,installation,14299,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['install'],['installation']
Deployability,"# into normal CMake variables rather than cache variables.; set(LLVM_TOOL_${upper_proj}_BUILD; ${SHOULD_ENABLE_PROJECT}; CACHE; BOOL ""Whether to build ${upper_proj} as part of LLVM"" FORCE; ); endforeach(); endif(); unset(SHOULD_ENABLE_PROJECT). # Build llvm with ccache if the package is present; set(LLVM_CCACHE_BUILD OFF CACHE BOOL ""Set to ON for a ccache enabled build""); if(LLVM_CCACHE_BUILD); find_program(CCACHE_PROGRAM ccache); if(CCACHE_PROGRAM); set(LLVM_CCACHE_MAXSIZE """" CACHE STRING ""Size of ccache""); set(LLVM_CCACHE_DIR """" CACHE STRING ""Directory to keep ccached data""); set(LLVM_CCACHE_PARAMS ""CCACHE_CPP2=yes CCACHE_HASHDIR=yes""; CACHE STRING ""Parameters to pass through to ccache""). if(NOT CMAKE_SYSTEM_NAME MATCHES ""Windows""); set(CCACHE_PROGRAM ""${LLVM_CCACHE_PARAMS} ${CCACHE_PROGRAM}""); if (LLVM_CCACHE_MAXSIZE); set(CCACHE_PROGRAM ""CCACHE_MAXSIZE=${LLVM_CCACHE_MAXSIZE} ${CCACHE_PROGRAM}""); endif(); if (LLVM_CCACHE_DIR); set(CCACHE_PROGRAM ""CCACHE_DIR=${LLVM_CCACHE_DIR} ${CCACHE_PROGRAM}""); endif(); set_property(GLOBAL PROPERTY RULE_LAUNCH_COMPILE ${CCACHE_PROGRAM}); else(); if(LLVM_CCACHE_MAXSIZE OR LLVM_CCACHE_DIR OR; NOT LLVM_CCACHE_PARAMS MATCHES ""CCACHE_CPP2=yes CCACHE_HASHDIR=yes""); message(FATAL_ERROR ""Ccache configuration through CMake is not supported on Windows. Please use environment variables.""); endif(); # RULE_LAUNCH_COMPILE should work with Ninja but currently has issues; # with cmd.exe and some MSVC tools other than cl.exe; set(CMAKE_C_COMPILER_LAUNCHER ${CCACHE_PROGRAM}); set(CMAKE_CXX_COMPILER_LAUNCHER ${CCACHE_PROGRAM}); endif(); else(); message(FATAL_ERROR ""Unable to find the program ccache. Set LLVM_CCACHE_BUILD to OFF""); endif(); endif(). set(LLVM_EXTERNAL_PROJECT_BUILD_TOOL_ARGS """" CACHE STRING; ""Optional arguments for the native tool used in CMake --build invocations for external projects.""); mark_as_advanced(LLVM_EXTERNAL_PROJECT_BUILD_TOOL_ARGS). option(LLVM_DEPENDENCY_DEBUGGING ""Dependency debugging mode to verify correctly expres",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:11393,configurat,configuration,11393,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['configurat'],['configuration']
Deployability,"# libAferImage CMakeLists.txt. PROJECT(AFTERIMAGE); if(WIN32); # required for the following feature & bug fix:; # 3.15: Added $<REMOVE_DUPLICATES:list> generator expression; # 3.16: Bug fix with CMAKE_WINDOWS_EXPORT_ALL_SYMBOLS: the auto-generated exports; # are now updated only when the object files providing the symbols are updated; cmake_minimum_required(VERSION 3.16 FATAL_ERROR); # Set CMP0091 (MSVC runtime library flags are selected by an abstraction) to OLD; # to keep the old way of selecting the runtime library with the -MD/-MDd compiler flag; cmake_policy(SET CMP0091 OLD); else(); cmake_minimum_required(VERSION 3.10 FATAL_ERROR); endif(). SET(LIB_NAME libAfterImage). # Microsoft Visual Studio:; IF(MSVC); # Define; ADD_DEFINITIONS(-D_CRT_SECURE_NO_DEPRECATE); SET(CMAKE_C_FLAGS ""${CMAKE_C_FLAGS} /DNO_DEBUG_OUTPUT /D_MBCS /D_LIB /wd4996 /wd4267 /wd4018 /wd4244""); ENDIF(). set(FREETYPE_INCLUDE_DIR """" CACHE PATH ""Path to Freetype include dir""); set(ZLIB_INCLUDE_DIR """" CACHE PATH ""Path to zlib include dir""). if(NOT EXISTS ""${FREETYPE_INCLUDE_DIR}/ft2build.h""); message(ERROR ""Can't find ft2build.h in ${FREETYPE_INCLUDE_DIR}""); endif(). if(NOT EXISTS ""${ZLIB_INCLUDE_DIR}/zlib.h""); message(ERROR ""Can't find zlib.h in ${ZLIB_INCLUDE_DIR}""); endif(). INCLUDE_DIRECTORIES(${FREETYPE_INCLUDE_DIR} ${ZLIB_INCLUDE_DIR}). set (LIB_DESTINATION ""${CMAKE_INSTALL_PREFIX}/lib${LIB_SUFFIX}""). FILE(GLOB H_FILES ""*.h""). SET(SRC_FILES; libpng/png.c libpng/pngmem.c libpng/pngrio.c libpng/pngset.c libpng/pngwio.c libpng/pngwutil.c; libpng/pngerror.c libpng/pngpread.c libpng/pngrtran.c libpng/pngtest.c libpng/pngwrite.c; libpng/pngget.c libpng/pngread.c libpng/pngrutil.c libpng/pngtrans.c libpng/pngwtran.c; libjpeg/jcapimin.c libjpeg/jcapistd.c libjpeg/jccoefct.c libjpeg/jccolor.c libjpeg/jcdctmgr.c libjpeg/jchuff.c libjpeg/jcinit.c; libjpeg/jcmainct.c libjpeg/jcmarker.c libjpeg/jcmaster.c libjpeg/jcomapi.c libjpeg/jcparam.c libjpeg/jcphuff.c libjpeg/jcprepct.c; libjpeg/jcsample.c libjpeg",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/asimage/src/libAfterImage/CMakeLists.txt:267,update,updated,267,graf2d/asimage/src/libAfterImage/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/asimage/src/libAfterImage/CMakeLists.txt,2,['update'],['updated']
Deployability,"# llvm-exegesis. `llvm-exegesis` is a benchmarking tool that accepts or assembles a snippet and; can measure characteristics of that snippet by executing it while keeping track; of performance counters. ### Currently Supported Platforms. `llvm-exegesis` is quite platform-dependent and currently only supports a couple; platform configurations for benchmarking. The limitations are listed below.; Analysis mode in `llvm-exegesis` is supported on all platforms on which LLVM is. #### Currently Supported Operating Systems for Benchmarking. Currently, `llvm-exegesis` only supports benchmarking on Linux. This is mainly; due to a dependency on the Linux perf subsystem for reading performance; counters. The subprocess execution mode and memory annotations currently only supports; Linux due to a heavy reliance on many Linux specific syscalls/syscall; implementations. #### Currently Supported Architectures for Benchmarking. Currently, using `llvm-exegesis` for benchmarking is supported on the following; architectures:; * x86; * 64-bit only due to this being the only implemented calling convention; in `llvm-exegesis` currently.; * ARM; * AArch64 only; * MIPS; * PowerPC (PowerPC64LE only). Note that not benchmarking functionality is guaranteed to work on all platforms. Memory annotations are currently only supported on 64-bit X86. There is no; inherent limitations for porting memory annotations to other architectures, but; parts of the test harness are implemented as MCJITed assembly that is generated; in `./lib/X86/Target.cpp` that would need to be implemented on other architectures; to bring up support.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md:329,configurat,configurations,329,interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md,1,['configurat'],['configurations']
Deployability,"# rootreadspeed. `rootreadspeed` is a tool used to help identify bottlenecks in root analysis programs; by providing an idea of what throughput you can expect when reading ROOT files in; certain configurations. It does this by providing information about the number of bytes read from your files,; how long this takes, and the different throughputs in MB/s, both in total and per thread. ## Compressed vs Uncompressed Throughput:. Throughput speeds are provided as compressed and uncompressed - ROOT files are usually; saved in compressed format, so these will often differ. Compressed bytes is the total; number of bytes read from TFiles during the readspeed test (possibly including meta-data).; Uncompressed bytes is the number of bytes processed by reading the branch values in the TTree.; Throughput is calculated as the total number of bytes over the total runtime (including; decompression time) in the uncompressed and compressed cases. ## Interpreting results:. ### There are three possible scenarios when using rootreadspeed, namely:. - The 'Real Time' is significantly lower than your own analysis runtime.; This would imply your actual application code is dominating the runtime of your analysis,; ie. your analysis logic or framework is taking up the time.; The best way to decrease the runtime would be to optimize your code (or the framework's),; parallelize it onto multiple threads if possible (for example with; [RDataFrame](https://root.cern/doc/master/classROOT_1_1RDataFrame.html); and [EnableImplicitMT](https://root.cern/doc/master/namespaceROOT.html#a06f2b8b216b615e5abbc872c9feff40f)); or switch to a machine with a more performant CPU.; - The 'Real Time' is significantly higher than 'CPU Time / number of threads'*.; If the real time is higher than the CPU time per core it implies the reading of data is the; bottleneck, as the CPU cores are wasting time waiting for data to arrive from your disk/drive; or network connection in order to decompress it.; The best way to dec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md:195,configurat,configurations,195,tree/readspeed/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md,1,['configurat'],['configurations']
Deployability,"# runtime_register_target(name); # Utility function to register external runtime target.; function(runtime_register_target name); cmake_parse_arguments(ARG """" ""BASE_NAME"" ""DEPENDS;CMAKE_ARGS;EXTRA_ARGS"" ${ARGN}); include(${LLVM_BINARY_DIR}/runtimes/${name}/Components.cmake OPTIONAL); set_property(DIRECTORY APPEND PROPERTY CMAKE_CONFIGURE_DEPENDS ${LLVM_BINARY_DIR}/runtimes/${name}/Components.cmake). set(runtime_names ${RUNTIME_NAMES}); foreach(_name IN ITEMS ${ARG_BASE_NAME} ${name}); if(RUNTIMES_${_name}_LLVM_ENABLE_RUNTIMES); set(runtime_names); foreach(entry ${RUNTIMES_${_name}_LLVM_ENABLE_RUNTIMES}); _get_runtime_name(${entry} runtime_name); list(APPEND runtime_names ${runtime_name}); endforeach(); endif(); endforeach(). foreach(runtime_name ${runtime_names}); set(${runtime_name}-${name} ${runtime_name}); set(install-${runtime_name}-${name} install-${runtime_name}); set(install-${runtime_name}-${name}-stripped install-${runtime_name}-stripped); list(APPEND ${name}_extra_targets ${runtime_name}-${name} install-${runtime_name}-${name} install-${runtime_name}-${name}-stripped); if(LLVM_INCLUDE_TESTS); set(check-${runtime_name}-${name} check-${runtime_name} ); list(APPEND ${name}_test_targets check-${runtime_name}-${name}); endif(); endforeach(). foreach(component IN LISTS SUB_COMPONENTS); set(${component}-${name} ${component}); list(APPEND ${name}_extra_targets ${component}-${name}); endforeach(). foreach(target IN LISTS SUB_INSTALL_TARGETS); set(${target}-${name} ${target}); set(${target}-${name}-stripped ${target}-stripped); list(APPEND ${name}_extra_targets ${target}-${name} ${target}-${name}-stripped); endforeach(). foreach(component ${LLVM_RUNTIME_DISTRIBUTION_COMPONENTS}); if(NOT component IN_LIST SUB_COMPONENTS); set(${component}-${name} ${component}); set(install-${component}-${name} install-${component}); set(install-${component}-${name}-stripped install-${component}-stripped); list(APPEND ${name}_extra_targets ${component}-${name} install-${component}-${n",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/runtimes/CMakeLists.txt:10145,install,install,10145,interpreter/llvm-project/llvm/runtimes/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/runtimes/CMakeLists.txt,6,['install'],['install']
Deployability,"# tree, both the generated LLVMExports.cmake file and the rest of the cmake; # source files are put in the same cmake directory.; set(LLVM_CONFIG_EXPORTS ""${LLVM_EXPORTS};${LLVM_EXPORTS_BUILDTREE_ONLY}""); set(LLVM_CONFIG_INCLUDE_EXPORTS ""include(\""${LLVM_EXPORTS_FILE}\"")""); set(llvm_config_include_buildtree_only_exports; ""include(\""${LLVM_BUILDTREEONLY_EXPORTS_FILE}\"")""); configure_file(; LLVMConfig.cmake.in; ${llvm_cmake_builddir}/LLVMConfig.cmake; @ONLY); set(llvm_config_include_buildtree_only_exports). # For compatibility with projects that include(LLVMConfig); # via CMAKE_MODULE_PATH, place API modules next to it.; # Copy without source permissions because the source could be read-only,; # but we need to write into the copied folder.; # This should be removed in the future.; file(COPY .; DESTINATION ${llvm_cmake_builddir}; NO_SOURCE_PERMISSIONS; FILES_MATCHING PATTERN *.cmake; PATTERN CMakeFiles EXCLUDE; PATTERN llvm-driver-template.cpp.in; ). #; # Generate LLVMConfig.cmake for the install tree.; #. find_prefix_from_config(LLVM_CONFIG_CODE LLVM_INSTALL_PREFIX ""${LLVM_INSTALL_PACKAGE_DIR}""). extend_path(LLVM_CONFIG_MAIN_INCLUDE_DIR ""\${LLVM_INSTALL_PREFIX}"" ""${CMAKE_INSTALL_INCLUDEDIR}""); # This is the same as the above because the handwritten and generated headers; # are combined in one directory at install time.; set(LLVM_CONFIG_INCLUDE_DIR ""${LLVM_CONFIG_MAIN_INCLUDE_DIR}""); set(LLVM_CONFIG_INCLUDE_DIRS; ""${LLVM_CONFIG_MAIN_INCLUDE_DIR}""; ""${LLVM_CONFIG_INCLUDE_DIR}""; ); list(REMOVE_DUPLICATES LLVM_CONFIG_INCLUDE_DIRS). extend_path(LLVM_CONFIG_LIBRARY_DIR ""\${LLVM_INSTALL_PREFIX}"" ""lib\${LLVM_LIBDIR_SUFFIX}""); set(LLVM_CONFIG_LIBRARY_DIRS; ""${LLVM_CONFIG_LIBRARY_DIR}""; # FIXME: Should there be other entries here?; ); list(REMOVE_DUPLICATES LLVM_CONFIG_LIBRARY_DIRS). set(LLVM_CONFIG_BINARY_DIR ""\${LLVM_INSTALL_PREFIX}""); extend_path(LLVM_CONFIG_CMAKE_DIR ""\${LLVM_INSTALL_PREFIX}"" ""${LLVM_INSTALL_PACKAGE_DIR}""); extend_path(LLVM_CONFIG_TOOLS_BINARY_DIR ""\${LLVM_I",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/cmake/modules/CMakeLists.txt:4580,install,install,4580,interpreter/llvm-project/llvm/cmake/modules/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/cmake/modules/CMakeLists.txt,1,['install'],['install']
Deployability,"## Configuration for the address sanitizer.; When built with `-Dasan=ON`, build flags for address sanitizer are added to ROOT's build setup. In this directory, an additional library is created; that holds default sanitizer configs for ROOT executables. It e.g. contains suppressions for leak sanitizer, which automatically runs with address; sanitizer. When asan starts up, it checks if somebody defined the symbols in `SanitizerConfig.cxx`. In the standard asan runtime, these; functions are weak symbols, i.e. one can just override them with the desired configuration. That's what's happening here. This can be achieved in two ways:; 1. `LD_PRELOAD`: A micro library `libROOTSanitizerConfig.<dylib|so>` is created with the setup in this folder, and can be found in `<builddir>/lib/`.; Loading it with `LD_PRELOAD` will bring ROOT's default sanitiser config into any non-sanitised executable, e.g. python.; 2. ROOT executables will get the config automatically, using a static version of the config library, `libROOTStaticSanitizerConfig.a`.; All ROOT executables statically link against it, so they start up without reporting lots of unfixable memory leaks (e.g. llvm). #### Small linker magic to get the config symbols into ROOT's executables; When linking a ROOT executable, the setup functions from the sanitiser config library might get ignored, because they are not used in any of our executables.; In `cmake/modules/SetUp{Linux|MacOS}.cmake`, the functions are therefore marked as ""undefined"" for the linker, so it starts copying; them into all ROOT executables.; This way, root.exe, cling, ... can start up with a sane default config. ### Use your own address/leak sanitizer configuration; The default configurations can be overridden using the environment variables `ASAN_OPTIONS` and `LSAN_OPTIONS`. Refer to the; [address sanitizer documentation](https://github.com/google/sanitizers/wiki/AddressSanitizer) or use `ASAN_OPTIONS=help=1` when starting; up a sanitised executable (e.g. `root.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/sanitizer/README.md:556,configurat,configuration,556,core/sanitizer/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/sanitizer/README.md,1,['configurat'],['configuration']
Deployability,## Math Libraries. ### Minuit2. - Remove the TFitterMinuit class and the similar ones used to implement the `TVirtualFitter` interface using Minuit2. users should switch to use the; `ROOT::Math::Minimizer` interface. All other changes in the Math packages have been applied also in the 5.34 patched versions of ROOT. See their release notes for the detailed list of applied improvements. ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v600/index.md:291,patch,patched,291,math/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v600/index.md,2,"['patch', 'release']","['patched', 'release']"
Deployability,"## PROOF System. All the fixes and improvements in the PROOF system occured since the release of 5.34/00 are available both in the latest 5.34 tags and in 6.00/00.; The following is a summary of the major modifications since 5.34 . ### New developments/functionality. - Several improvements in the merging phase; in particular:; - Modification of output sending protocol to control memory usage, significantly reducing the memory footprint on the master, in particular when merging; large numbers of histograms.; - Use an hash table for the output list to significantly speed up names lookups during merging.; - Add support for dynamic addition of workers to a currently running process (currently supported by the unit packetizer).; - Automatization of the usage of file-based technology to handle outputs.; - [Improved dataset management model](https://root.cern/doc/v628/classTDataSetManagerAliEn.html); where the PROOF (ROOT) dataset manager is a light frontend to the experiment file catalogs; TDataSetManagerFile is still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:86,release,release,86,proof/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md,1,['release'],['release']
Deployability,"## Windows; CPT is meant to be executed on cmd.exe prompt. Make sure you have set the; environment properly before continuing.; Below is a list of required packages for Windows (Win32-x86):. [MSYS Git] for Windows. [Python] for Windows. Microsoft Visual Studio 11 (2012), with Microsoft Visual C++ 2012. [MSYS Git]:http://msysgit.github.io/; [Python]:https://www.python.org/. ###### Setting Up:; Unlike other UNIX-like platforms, Windows requires you to follow some rules.; Do not ignore this section unless you want CPT to fail mid-way with wierd; errors. You should require these instructions only once. * While installing the packages make sure the executable is in a path that; doesn't contain spaces. For example, you should install Python in a path like. ```sh; C:\Python27; ```; rather than. ```sh; C:\Program Files (x86)\Python 2.7; ```; * Path to all the required executables should be present in the Windows; **PATH** environment variable.; * In case of MSYS Git, choose the option ""Run Git from Windows; Command Prompt"" during installation. A good way to check if everything is detected properly by the script is to; run the following command:; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```. #### Red Hat Linux (Fedora/Scientific Linux CERN); This section applies to all distros based on Red Hat Linux like Fedora, and; Scientific Linux CERN (SLC). Apparently, you can build RPM packages in any; distro regardless of the package manager it uses. This has been tested on; Fedora, SLC, Ubuntu, and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package manager of your distro, you can install the; packages required by CPT to build RPM bundles. For a Red Hat based distro; (which uses ```yum``` package manager), you can use the following command; (also performed automatically by CPT):; ```sh; sudo yum update; sudo yum install git gcc gcc-c++ rpm-build python; ```. #### Mac OS X; Mac OS X provide",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:4593,install,installation,4593,interpreter/cling/tools/packaging/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md,1,['install'],['installation']
Deployability,"### Example project using cling as library. This example project uses cling as an external library.; It compiles code and calls it, moving values from the compiled part to the; interpreted part and back. It showcases how to use cling as a library, and shows how to set up a simple; CMake configuration that uses cling. ### How to build. After installing cling (say into /where/cling/is/installed), configure this; project using CMake like this:; ```bash; cmake -Dcling_DIR=/cling-install-dir/lib/cmake/cling /cling-source-dir/tools/cling/tools/demo; make && ./cling-demo; ```; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/demo/README.md:288,configurat,configuration,288,interpreter/cling/tools/demo/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/demo/README.md,4,"['configurat', 'install']","['configuration', 'install-dir', 'installed', 'installing']"
Deployability,############################################################################; # CMakeLists.txt file for building ROOT core/zstd package; ############################################################################. find_package(ZSTD REQUIRED). target_sources(Core PRIVATE src/ZipZSTD.cxx); target_link_libraries(Core PRIVATE ${ZSTD_LIBRARIES}); target_compile_definitions(Core PRIVATE ${ZSTD_DEFINITIONS}); target_include_directories(Core PUBLIC; $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/inc>; $<BUILD_INTERFACE:${ZSTD_INCLUDE_DIR}>; ). ROOT_INSTALL_HEADERS(); install(FILES ${ZSTD_headers} DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}); ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/zstd/CMakeLists.txt:566,install,install,566,core/zstd/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/zstd/CMakeLists.txt,1,['install'],['install']
Deployability,"##########################################################. # These files depend on cling/clang/llvm; they need to be linked into libCling.; # They are used by rootcling_stage1, rootcling and libCling. set_property(TARGET Core APPEND PROPERTY DICT_HEADERS; root_std_complex.h; ). target_include_directories(Core PUBLIC; $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/inc>; $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/res>; ). ROOT_OBJECT_LIBRARY(ClingUtils; src/RStl.cxx; src/TClingUtils.cxx; ). add_dependencies(ClingUtils CLING). target_include_directories(ClingUtils PRIVATE ; ${CLING_INCLUDE_DIRS}; ${CMAKE_SOURCE_DIR}/core/foundation/res; ${CMAKE_SOURCE_DIR}/core/foundation/inc; ${CMAKE_SOURCE_DIR}/core/base/inc; ${CMAKE_SOURCE_DIR}/core/clib/inc; ${CMAKE_SOURCE_DIR}/core/meta/inc; ${CMAKE_BINARY_DIR}/ginclude). # Register the llvm include directories after clangs. This instructs the compiler to resolve; # headers from our builtin clang. That's an issue when we are building with bultin_llvm=Off; # and we have installed clang headers, too.; target_include_directories(ClingUtils SYSTEM PRIVATE ${CLANG_INCLUDE_DIRS} ${LLVM_INCLUDE_DIRS}); set_target_properties(ClingUtils PROPERTIES; COMPILE_FLAGS ""${CMAKE_CXX_FLAGS} ${CLING_CXXFLAGS}""; VISIBILITY_INLINES_HIDDEN ""ON""; ). ROOT_INSTALL_HEADERS(). #### STL dictionary (replacement for cintdlls)##############################. set(stldicts; vector; list; forward_list; deque; map map2 unordered_map; multimap multimap2 unordered_multimap; set unordered_set; multiset unordered_multiset; complex); if(NOT WIN32); list(APPEND stldicts valarray); endif(); foreach(dict ${stldicts}); string(REPLACE ""2"" """" header ${dict}); string(REPLACE ""complex"" ""root_std_complex.h"" header ${header}); string(REPLACE ""multi"" """" header ${header}); ROOT_STANDARD_LIBRARY_PACKAGE(${dict}Dict; NO_SOURCES NO_INSTALL_HEADERS NO_CXXMODULE; STAGE1; NODEPHEADERS ${header}; LINKDEF src/${dict}Linkdef.h; DICTIONARY_OPTIONS --noIncludePaths; DEPENDENCIES Core); targe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/clingutils/CMakeLists.txt:1379,install,installed,1379,core/clingutils/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/clingutils/CMakeLists.txt,1,['install'],['installed']
Deployability,"######################################################. set(py_sources; DistRDF/__init__.py; DistRDF/_graph_cache.py; DistRDF/ComputationGraphGenerator.py; DistRDF/DataFrame.py; DistRDF/HeadNode.py; DistRDF/Node.py; DistRDF/Operation.py; DistRDF/Proxy.py; DistRDF/PythonMergeables.py; DistRDF/Ranges.py; DistRDF/Backends/__init__.py; DistRDF/Backends/Base.py; DistRDF/Backends/Utils.py; DistRDF/Backends/Spark/__init__.py; DistRDF/Backends/Spark/Backend.py; DistRDF/Backends/Dask/__init__.py; DistRDF/Backends/Dask/Backend.py; DistRDF/LiveVisualize.py; ). # Add custom rules to copy the Python sources into the build directory; foreach(py_source ${py_sources}); add_custom_command(; OUTPUT ${localruntimedir}/${py_source}; COMMAND ${CMAKE_COMMAND} -E copy ${CMAKE_CURRENT_SOURCE_DIR}/python/${py_source}; ${localruntimedir}/${py_source}; DEPENDS python/${py_source}; COMMENT ""Copying ${CMAKE_CURRENT_SOURCE_DIR}/python/${py_source}""); list(APPEND py_sources_in_localruntimedir ${localruntimedir}/${py_source}); endforeach(). # A custom target that depends on the Python sources being present in the build; # directory. This will be used as a dependency of the pythonization libraries,; # such that the Python sources get re-copied to the build directory when; # changed.; add_custom_target(DistRDF ALL DEPENDS ${py_sources_in_localruntimedir}). # Compile .py files; # We include DistRDF in the build only if Python 3.8+ is used,; # so we can directly use the main Python executable to compile the sources; foreach(py_source ${py_sources}); install(CODE ""execute_process(COMMAND ${Python3_EXECUTABLE} -m py_compile ${localruntimedir}/${py_source})""); install(CODE ""execute_process(COMMAND ${Python3_EXECUTABLE} -O -m py_compile ${localruntimedir}/${py_source})""); endforeach(). # Install Python sources and bytecode; install(DIRECTORY ${localruntimedir}/DistRDF; DESTINATION ${CMAKE_INSTALL_PYTHONDIR}; COMPONENT libraries). ROOT_ADD_TEST_SUBDIRECTORY(test); ROOT_ADD_TEST_SUBDIRECTORY(test/backend); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/experimental/distrdf/CMakeLists.txt:1845,install,install,1845,bindings/experimental/distrdf/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/experimental/distrdf/CMakeLists.txt,3,['install'],['install']
Deployability,"#######################. if(WIN32); set(PLATFORM_FILTER FILTER ""Posix""); set(PLATFORM_HEADERS; TWin32Condition.h; TWin32Mutex.h; TWin32Thread.h; TWin32ThreadFactory.h; ); else(); set(PLATFORM_FILTER FILTER ""Win32""); set(PLATFORM_HEADERS; TPosixCondition.h; TPosixMutex.h; TPosixThread.h; TPosixThreadFactory.h; PosixThreadInc.h; ); endif(). ROOT_STANDARD_LIBRARY_PACKAGE(Thread; HEADERS; ${PLATFORM_HEADERS}; TAtomicCount.h; TCondition.h; TConditionImp.h; TMutex.h; TMutexImp.h; TRWLock.h; TSemaphore.h; TThreadFactory.h; TThread.h; TThreadImp.h; TThreadPool.h; ROOT/RConcurrentHashColl.hxx; ROOT/TRWSpinLock.hxx; ROOT/TSpinMutex.hxx; ROOT/TThreadedObject.hxx; SOURCES; src/RConcurrentHashColl.cxx; src/TCondition.cxx; src/TConditionImp.cxx; src/TMutex.cxx; src/TMutexImp.cxx; src/TReentrantRWLock.cxx; src/TRWLock.cxx; src/TRWMutexImp.cxx; src/TRWSpinLock.cxx; src/TSemaphore.cxx; src/TThread.cxx; src/TThreadFactory.cxx; src/TThreadImp.cxx; STAGE1; DICTIONARY_OPTIONS; -writeEmptyRootPCM; DEPENDENCIES; Core; BUILTINS; TBB; INSTALL_OPTIONS ${installoptions}; ). target_include_directories(Core PUBLIC; $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/inc>; ). target_link_libraries(Thread PUBLIC ${CMAKE_THREAD_LIBS_INIT}). target_include_directories(Thread PUBLIC; $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/inc>; ). # keep include directory for ROOT/RSha256.hxx private; set_source_files_properties(src/RConcurrentHashColl.cxx; PROPERTIES COMPILE_FLAGS -I${CMAKE_SOURCE_DIR}/core/foundation/res). if((tbb OR builtin_tbb) AND NOT MSVC); target_include_directories(Thread PRIVATE ${TBB_INCLUDE_DIRS}); target_link_libraries(Thread PRIVATE ${TBB_LIBRARIES}); set_target_properties(Thread PROPERTIES COMPILE_FLAGS ""${TBB_CXXFLAGS}""); endif(). if(WIN32); target_sources(Thread PRIVATE; src/TWin32Condition.cxx; src/TWin32Mutex.cxx; src/TWin32Thread.cxx; src/TWin32ThreadFactory.cxx; ); target_include_directories(Thread PRIVATE ${CMAKE_SOURCE_DIR}/core/winnt/inc); else(); target_sources(Thread PRIVATE",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/thread/CMakeLists.txt:1431,install,installoptions,1431,core/thread/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/thread/CMakeLists.txt,1,['install'],['installoptions']
Deployability,###################; # Install rules for separate header lists; install(; FILES ${core_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT core-resource-headers). install(; FILES ${arm_common_files} ${arm_common_generated_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT arm-common-resource-headers). install(; FILES ${arm_only_files} ${arm_only_generated_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT arm-resource-headers). install(; FILES ${aarch64_only_files} ${aarch64_only_generated_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT aarch64-resource-headers). install(; FILES ${cuda_wrapper_files}; DESTINATION ${header_install_dir}/cuda_wrappers; EXCLUDE_FROM_ALL; COMPONENT cuda-resource-headers). install(; FILES ${cuda_wrapper_bits_files}; DESTINATION ${header_install_dir}/cuda_wrappers/bits; EXCLUDE_FROM_ALL; COMPONENT cuda-resource-headers). install(; FILES ${cuda_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT cuda-resource-headers). install(; FILES ${hexagon_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT hexagon-resource-headers). install(; FILES ${hip_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT hip-resource-headers). install(; FILES ${loongarch_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT loongarch-resource-headers). install(; FILES ${mips_msa_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT mips-resource-headers). install(; FILES ${ppc_wrapper_files}; DESTINATION ${header_install_dir}/ppc_wrappers; EXCLUDE_FROM_ALL; COMPONENT ppc-resource-headers). install(; FILES ${ppc_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT ppc-resource-headers). install(; FILES ${ppc_htm_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT ppc-htm-resource-headers). install(; FILES ${riscv_generated_files}; DESTINATION ${header_install_di,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt:13833,install,install,13833,interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,1,['install'],['install']
Deployability,"#------------------------------------------------------------------------------; # CLING - the C++ LLVM-based InterpreterG :); #; # This file is dual-licensed: you can choose to license it under the University; # of Illinois Open Source License or the GNU Lesser General Public License. See; # LICENSE.TXT for details.; #------------------------------------------------------------------------------. set( LLVM_LINK_COMPONENTS; support; ). if(NOT EXISTS ${CMAKE_CURRENT_SOURCE_DIR}/textinput); set(TEXTINPUTSRC ${CMAKE_SOURCE_DIR}/core/textinput/src/); include_directories(${TEXTINPUTSRC}); else(); # For cling, install textinput *.h in include/cling/UserInterface/textinput.; install(DIRECTORY ${TEXTINPUTSRC}textinput; DESTINATION include/cling/UserInterface; FILES_MATCHING; PATTERN ""CMakeFiles"" EXCLUDE; PATTERN ""*.cpp"" EXCLUDE; PATTERN ""doc"" EXCLUDE; PATTERN ""*.h""; ); endif(). add_cling_library(clingUserInterface; UserInterface.cpp; ${TEXTINPUTSRC}textinput/Editor.cpp; ${TEXTINPUTSRC}textinput/History.cpp; ${TEXTINPUTSRC}textinput/KeyBinding.cpp; ${TEXTINPUTSRC}textinput/Range.cpp; ${TEXTINPUTSRC}textinput/SignalHandler.cpp; ${TEXTINPUTSRC}textinput/StreamReader.cpp; ${TEXTINPUTSRC}textinput/StreamReaderUnix.cpp; ${TEXTINPUTSRC}textinput/StreamReaderWin.cpp; ${TEXTINPUTSRC}textinput/TerminalConfigUnix.cpp; ${TEXTINPUTSRC}textinput/TerminalDisplay.cpp; ${TEXTINPUTSRC}textinput/TerminalDisplayUnix.cpp; ${TEXTINPUTSRC}textinput/TerminalDisplayWin.cpp; ${TEXTINPUTSRC}textinput/TextInput.cpp; ${TEXTINPUTSRC}textinput/TextInputContext.cpp. LINK_LIBS; clingMetaProcessor; clingInterpreter; clingUtils; ). if( MSVC ); # Don't use Unicode in the User Interface (command prompt); remove_definitions(-DUNICODE -D_UNICODE); endif(). if(UNIX); set_source_files_properties(UserInterface.cpp COMPILE_FLAGS ""-fexceptions""); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/UserInterface/CMakeLists.txt:612,install,install,612,interpreter/cling/lib/UserInterface/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/UserInterface/CMakeLists.txt,2,['install'],['install']
Deployability,"#include ""TF1.h""; #include ""Math/WrappedTF1.h""; #include ""Math/GaussIntegrator.h"". int main(); {; TF1 f(""Sin Function"", ""sin(x)"", 0, TMath::Pi());; ROOT::Math::WrappedTF1 wf1(f);. ROOT::Math::GaussIntegrator ig;. ig.SetFunction(wf1, false);; ig.SetRelTolerance(0.001);. cout << ig.Integral(0, TMath::PiOver2()) << endl;. return 0;; }; ```; #### ROOT::Math::GaussLegendreIntegrator. This class implementes the Gauss-Legendre quadrature formulas. This sort of numerical methods requieres that the user specifies the number of intermediate function points; used in the calculation of the integral. It will automatically determine the coordinates and weights of such points before performing the integration.; We can use the example above, but replacing the creation of a `ROOT::Math::GaussIntegrator` object with `ROOT::Math::GaussLegendreIntegrator`. #### ROOT::Math::GSLIntegrator. This is a wrapper for the *QUADPACK* integrator implemented in the GSL library. It supports several integration methods that can be chosen in construction time.; The default type is adaptive integration with singularity applying a Gauss-Kronrod 21-point integration rule. For a detail description of the GSL methods visit the GSL user guide; This class implements the best algorithms for numerical integration for one dimensional functions. We encourage the use it as the main option, bearing in mind that it uses code from the; GSL library, wich is provided in the *MathMore* library of ROOT. The interface to use is the same as above. We have now the possibility to specify a different integration algorithm in the constructor of the `ROOT::Math::GSLIntegrator` class.; ```{.cpp}; // create the adaptive integrator with the 51 point rule; ROOT::Math::GSLIntegrator ig(ROOT::Math::Integration::kADAPTIVE, ROOT::Math::Integration::kGAUSS51);; ig.SetRelTolerance(1.E-6); // set relative tolerance; ig.SetAbsTolerance(1.E-6); // set absoulte tolerance; ```. The algorithm is controlled by the given absolute and relative t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:54681,integrat,integration,54681,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['integrat'],['integration']
Deployability,"$ github-upload-release.py upload --token <github-token> --release X.Y.Z-rcN --files <release_files>. ::. $ ./export.sh -release X.Y.Z -rc $RC. This will generate source tarballs for each LLVM project being validated, which; can be uploaded to github for further testing. Build The Binary Distribution; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Creating the binary distribution requires following the instructions; :doc:`here <ReleaseProcess>`. That process will perform both Release+Asserts and Release builds but only; pack the Release build for upload. You should use the Release+Asserts sysroot,; normally under ``final/Phase3/Release+Asserts/llvmCore-3.8.1-RCn.install/``,; for test-suite and run-time benchmarks, to make sure nothing serious has; passed through the net. For compile-time benchmarks, use the Release version. The minimum required version of the tools you'll need are :doc:`here <GettingStarted>`. Release Qualification Criteria; ------------------------------. There are no official release qualification criteria. It is up to the; the release manager to determine when a release is ready. The release manager; should pay attention to the results of community testing, the number of outstanding; bugs, and then number of regressions when determining whether or not to make a; release. The community values time based releases, so releases should not be delayed for; too long unless there are critical issues remaining. In most cases, the only; kind of bugs that are critical enough to block a release would be a major regression; from a previous release. Official Testing; ----------------. A few developers in the community have dedicated time to validate the release; candidates and volunteered to be the official release testers for each; architecture. These will be the ones testing, generating and uploading the official binaries; to the server, and will be the minimum tests *necessary* for the release to; proceed. This will obviously not cover all OSs and distributions, so addit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:6206,release,release,6206,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['release'],['release']
Deployability,"$CONDA_PREFIX/lib``.; Note that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been modified, which can can lead to parsing problems if; your system C library does not support C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard with pip; ---------------------. The C++20 standard is the default on all systems as of release 3.0.1 (both; PyPI and conda-forge); it is C++17 for older releases.; When installing from PyPI using ``pip``, you can control the standard; selection by setting the ``STDCXX`` envar to '20', '17', or '14' (for Linux,; the backend does not need to be recompiled) for the 3.x releases; '17', '14',; or '11' for the 2.x releases.; Note that the build will automatically lower your choice if the compiler used; does not support a newer standard. Install from source; -------------------; .. _installation_from_source:. To build an existing release from source, tell ``pip`` to not download any; binary wheels.; Build-time only dependencies are ``cmake`` (for general build), ``python``; (obviously, but also for LLVM), and a modern C++ compiler (one that supports; at least C++14).; Use the envar ``STDCXX`` to control the C++ standard version; ``MAKE`` to; change the ``make`` command, ``MAKE_NPROCS`` to control the maximum number of; parallel jobs allowed, and ``VERBOSE=1`` to see full build/compile commands.; Example (using ``--verbose`` to see ``pip`` progress)::. $ STDCXX=17 MAKE_NPROCS=32 pip install --verbose cppyy --no-binary=cppyy-cling. Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:5153,release,releases,5153,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,1,['release'],['releases']
Deployability,"$ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. #####################################################################################################################. # Details about integrating ROOT into CMake projects:; # https://root.cern/manual/integrate_root_into_my_cmake_project/. #####################################################################################################################. # CMakeLists.txt that creates a library with dictionary and a main program; cmake_minimum_required(VERSION 3.10 FATAL_ERROR). project(treeUsingCustomClass). #---Locate the ROOT package and defines a number of variables (e.g. ROOT_INCLUDE_DIRS); find_package(ROOT REQUIRED COMPONENTS Tree TreePlayer ROOTDataFrame). #---Include a CMake module which makes use of the previous variables and loads modules ; # with useful macros or functions such as ROOT_GENERATE_DICTIONARY; # For further details: https://root-forum.cern.ch/t/how-to-integrate-root-into-my-project-with-cmake/37175; include(${ROOT_USE_FILE}). #---Add include directory of ROOT to the build; include_directories(${CMAKE_SOURCE_DIR}). # CMake function provided by ROOT, used to generate the dictionary file, G__data2Tree.cxx; # See this link for further details:; # https://root.cern/manual/io_custom_classes/#using-cmake; ROOT_GENERATE_DICTIONARY(G__data2Tree data2Tree.hxx LINKDEF data2TreeLinkDef.hxx). #---Create a shared library from; # * the previously generated dictionary, G__data2Tree.cxx; # * the class implementation; add_library(data2TreeLib SHARED data2Tree.cxx G__data2Tree.cxx); target_link_libraries(data2TreeLib ${ROOT_LIBRARIES} ) ; add_dependencies(data2TreeLib G__data2Tree ). #--- This is needed on Windows in order to export the symbols and create the data2TreeLib.lib file; if(MSVC); set_target_properties(data2TreeLib PROPERTIES WINDOWS_EXPORT_ALL_SYMBOLS TRUE); endif(). #---Create a main program using the library; add_executable(treeExample main.cpp writeTree.cxx readTree.c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/tree/dictionary/CMakeLists.txt:1085,integrat,integrate-root-into-my-project-with-cmake,1085,tutorials/tree/dictionary/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/tree/dictionary/CMakeLists.txt,1,['integrat'],['integrate-root-into-my-project-with-cmake']
Deployability,"${CMAKE_COMMAND} -E copy_directory; # ${CMAKE_SOURCE_DIR}/interpreter/cling/tools/plugins/clad/patches <SOURCE_DIR>; # && git checkout <SOURCE_DIR>; # && git apply --ignore-space-change --ignore-whitespace ${_clad_patches_list}; # ). ExternalProject_Add(; clad; GIT_REPOSITORY https://github.com/vgvassilev/clad.git; GIT_TAG v1.7; UPDATE_COMMAND """"; PATCH_COMMAND ${_clad_patch_command}; CMAKE_ARGS -G ${CMAKE_GENERATOR}; -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE}; -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}; -DCMAKE_C_FLAGS=${CMAKE_C_FLAGS}; -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER}; -DCMAKE_CXX_FLAGS=${CLAD_CXX_FLAGS}; -DCMAKE_INSTALL_PREFIX=${clad_install_dir}/plugins; -DLLVM_DIR=${LLVM_BINARY_DIR}; -DCLANG_INCLUDE_DIRS=${CLANG_INCLUDE_DIRS}; ${_clad_extra_cmake_args}; # FIXME; # Building with 1 core is a temporary workaround for #16654 and has to be ; # there until the behaviour of the clad build on ubuntu 24.10 is understood.; # The performance penalty in the build is negligible.; BUILD_COMMAND ${CMAKE_COMMAND} --build . ${EXTRA_BUILD_ARGS} -j 1; INSTALL_COMMAND ${CMAKE_COMMAND} --build . ${EXTRA_BUILD_ARGS} -j 1 --target install; BUILD_BYPRODUCTS ${CLAD_BYPRODUCTS}; ${_clad_extra_settings}; # We need the target clangBasic to be built before building clad. However, we; # support building prebuilt clang and adding clangBasic breaks this case.; # Delegate the dependency resolution to the clingInterpreter target (which; # will always depend on clangBasic).; DEPENDS clingInterpreter; ). # Register cladPlugin, cladDifferentiator; foreach (lib cladPlugin cladDifferentiator); add_library(${lib} IMPORTED STATIC GLOBAL); add_dependencies(${lib} clad); endforeach(). set_property(TARGET cladPlugin PROPERTY IMPORTED_LOCATION ${_CLAD_LIBRARY_PATH}/${CMAKE_STATIC_LIBRARY_PREFIX}cladPlugin${CMAKE_STATIC_LIBRARY_SUFFIX}); set_property(TARGET cladDifferentiator PROPERTY IMPORTED_LOCATION ${_CLAD_LIBRARY_PATH}/${CMAKE_STATIC_LIBRARY_PREFIX}cladDifferentiator${CMAKE_STATIC_LIBRARY_SUFFIX}); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/plugins/clad/CMakeLists.txt:3861,install,install,3861,interpreter/cling/tools/plugins/clad/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/plugins/clad/CMakeLists.txt,1,['install'],['install']
Deployability,"${CMAKE_INSTALL_TUTDIR} COMPONENT tests). if(runtime_cxxmodules); add_dependencies(hsimple modules_idx); endif(). #---copy special headers required for building on Windows----------------------------------------; if(WIN32); file(COPY cmake/win/w32pragma.h DESTINATION ${CMAKE_BINARY_DIR}/include/); file(COPY cmake/win/sehmap.h DESTINATION ${CMAKE_BINARY_DIR}/include/); endif(). #---version--------------------------------------------------------------------------------------; if(NOT WIN32); add_custom_target(version COMMAND ${Python3_EXECUTABLE} ${CMAKE_SOURCE_DIR}/cmake/unix/makeversion.py; WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}); endif(). #---distribution commands------------------------------------------------------------------------; add_custom_target(distsrc COMMAND ${CMAKE_SOURCE_DIR}/cmake/unix/makedistsrc.sh ""${ROOT_FULL_VERSION}"" ""${CMAKE_SOURCE_DIR}""); add_custom_target(dist COMMAND cpack --config CPackConfig.cmake). #---Configure and install various files neded later and for clients -----------------------------; include(RootConfiguration). #---Installation of project-wise artifacts-------------------------------------------------------; if(NOT CMAKE_SOURCE_DIR STREQUAL CMAKE_INSTALL_PREFIX); install(FILES LICENSE DESTINATION ${CMAKE_INSTALL_DOCDIR}); if(gnuinstall); install(DIRECTORY README/ DESTINATION ${CMAKE_INSTALL_DOCDIR}); else(); install(DIRECTORY README DESTINATION ${CMAKE_INSTALL_DOCDIR}); endif(); install(DIRECTORY etc/ DESTINATION ${CMAKE_INSTALL_SYSCONFDIR} USE_SOURCE_PERMISSIONS; ${DIR_PERMISSIONS}; PATTERN ""system.rootrc"" EXCLUDE; PATTERN ""system.rootauthrc"" EXCLUDE; PATTERN ""system.rootdaemonrc"" EXCLUDE; PATTERN ""root.mimes"" EXCLUDE; PATTERN ""*.in"" EXCLUDE); install(DIRECTORY fonts/ DESTINATION ${CMAKE_INSTALL_FONTDIR} ${DIR_PERMISSIONS}); install(DIRECTORY icons/ DESTINATION ${CMAKE_INSTALL_ICONDIR} ${DIR_PERMISSIONS}); install(DIRECTORY macros/ DESTINATION ${CMAKE_INSTALL_MACRODIR} ${DIR_PERMISSIONS}); if(http); install(DIRECTORY js/ DESTINA",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt:24769,install,install,24769,CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt,1,['install'],['install']
Deployability,"${project}; done. # Import umbrella history.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/umbrella.git; git fetch umbrella. # Put myproj in local/myproj; echo ""myproj local/myproj"" > my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=local \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Note that if the umbrella has submodules to non-LLVM repositories,; ``zip-downstream-fork.py`` needs to know about them to be able to; rewrite commits. That is why the first step above is to fetch commits; from such repositories. With ``--update-tags`` the tool will migrate annotated tags pointing; to submodule commits that were inlined into the zipped history. If; the umbrella pulled in an upstream commit that happened to have a tag; pointing to it, that tag will be migrated, which is almost certainly; not what is wanted. The tag can always be moved back to its original; commit after rewriting, or the ``--update-tags`` option may be; discarded and any local tags would then be migrated manually. **Example 2: Nested sources layout**. The tool handles nested submodules (e.g. llvm is a submodule in; umbrella and clang is a submodule in llvm). The file; ``submodule-map.txt`` is a list of pairs, one per line. The first; pair item describes the path to a submodule in the umbrella; repository. The second pair item describes the path where trees for; that submodule should be written in the zipped history. Let's say your umbrella repository is actually the llvm repository and; it has submodules in the ""nested sources"" layout (clang in; tools/clang, etc.). Let's also say ``projects/myp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:29675,update,update-tags,29675,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['update'],['update-tags']
Deployability,${ve_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT ve-resource-headers). install(; FILES ${webassembly_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT webassembly-resource-headers). install(; FILES ${x86_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT x86-resource-headers). if(NOT CLANG_ENABLE_HLSL); set(EXCLUDE_HLSL EXCLUDE_FROM_ALL); endif(). install(; FILES ${hlsl_h}; DESTINATION ${header_install_dir}; ${EXCLUDE_HLSL}; COMPONENT hlsl-resource-headers). install(; FILES ${hlsl_subdir_files}; DESTINATION ${header_install_dir}/hlsl; ${EXCLUDE_HLSL}; COMPONENT hlsl-resource-headers). install(; FILES ${opencl_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT opencl-resource-headers). install(; FILES ${openmp_wrapper_files}; DESTINATION ${header_install_dir}/openmp_wrappers; EXCLUDE_FROM_ALL; COMPONENT openmp-resource-headers). install(; FILES ${openmp_wrapper_files}; DESTINATION ${header_install_dir}/openmp_wrappers; EXCLUDE_FROM_ALL; COMPONENT openmp-resource-headers). install(; FILES ${utility_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT utility-resource-headers). install(; FILES ${windows_only_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT windows-resource-headers); #############################################################. if (NOT LLVM_ENABLE_IDE); add_llvm_install_targets(install-clang-resource-headers; DEPENDS clang-resource-headers; COMPONENT clang-resource-headers). add_llvm_install_targets(install-core-resource-headers; DEPENDS core-resource-headers; COMPONENT core-resource-headers); add_llvm_install_targets(install-arm-common-resource-headers; DEPENDS arm-common-resource-headers; COMPONENT arm-common-resource-headers); add_llvm_install_targets(install-arm-resource-headers; DEPENDS arm-resource-headers; COMPONENT arm-resource-headers); add_llvm_install_targets(install-aarch64-resource-headers; DEPENDS aarch64-resourc,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt:16136,install,install,16136,interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,1,['install'],['install']
Deployability,"% ROOT Version 6.00/00 Release Notes; % May 2014; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.00/00 has been released on May 30, 2014. It introduces the new; Cling C++11 interpreter, replacing CINT that has served ROOT well for many years. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. Bertrand Bellenot, CERN/SFT,\; Dario Berzano, CERN/SFT,\; Rene Brun, CERN/SFT,\; Ioan Gabriel Bucur, CERN/SFT \; Philippe Canal, FNAL,\; Cristina Cristescu, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Kyle Cranmer, NYU, RooStats,\; Anders Eie, NTNU,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/Alice,\; Wim Lavrijsen, LBNL, PyRoot,\; Sergey Linev, GSI, http,\; Anna-Pia Lohfink,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Paul Russo, FNAL, \; Joerg Stelzer, DESY/Atlas, TMVA, \; Alja Tadel, UCSD/CMS, Eve, \; Matevz Tadel, UCSD/CMS, Eve, \; Eckhard von Toerne, University Bonn, ATLAS, TMVA, \; Vassil Vassilev, CERN/SFT \; Wouter Verkerke, NIKHEF/Atlas, RooFit, \; Yue Shi Lai, MIT. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v600/index.md:123,release,released,123,doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v600/index.md,1,['release'],['released']
Deployability,"% ROOT Version 6.02/00 Release Notes; % May 2014; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.02/00 has been released on [ ]. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. Bertrand Bellenot, CERN/SFT,\; Dario Berzano, CERN/SFT,\; Rene Brun, CERN/SFT,\; Ioan Gabriel Bucur, CERN/SFT \; Philippe Canal, FNAL,\; Cristina Cristescu, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Kyle Cranmer, NYU, RooStats,\; Anders Eie, NTNU,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/Alice,\; Wim Lavrijsen, LBNL, PyRoot,\; Sergey Linev, GSI, http,\; Anna-Pia Lohfink,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Paul Russo, FNAL, \; Joerg Stelzer, DESY/Atlas, TMVA, \; Alja Tadel, UCSD/CMS, Eve, \; Matevz Tadel, UCSD/CMS, Eve, \; Eckhard von Toerne, University Bonn, ATLAS, TMVA, \; Vassil Vassilev, CERN/SFT \; Wouter Verkerke, NIKHEF/Atlas, RooFit, \; Yue Shi Lai, MIT. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v602/index.md:123,release,released,123,doc/v602/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v602/index.md,1,['release'],['released']
Deployability,"% ROOT Version 6.04/00 Release Notes; % 2 June 2015; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.04/00 was released on 2 June, 2015. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. David Abdurachmanov, CERN, CMS,\; Bertrand Bellenot, CERN/SFT,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Cristina Cristescu, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Kyle Cranmer, NYU, RooStats,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/Alice,\; Lukasz Janyst, CERN/IT,\; Christopher Jones, Fermilab, CMS,\; Wim Lavrijsen, LBNL, PyRoot,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Liza Sakellari, CERN/SFT,\; Manuel Tobias Schiller,\; David Smith, CERN/IT,\; Matevz Tadel, UCSD/CMS, Eve, \; Vassil Vassilev, CERN/SFT \; Wouter Verkerke, NIKHEF/Atlas, RooFit, \; Yue Shi Lai, MIT,\; Maciej Zimnoch. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v604/index.md:121,release,released,121,doc/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v604/index.md,1,['release'],['released']
Deployability,"% ROOT Version 6.04/00 Release Notes; % 2 June 2015; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.04/00 was released on 2 June, 2015. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. David Abdurachmanov, CERN, CMS,\; Bertrand Bellenot, CERN/SFT,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Cristina Cristescu, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Kyle Cranmer, NYU, RooStats,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/Alice,\; Lukasz Janyst, CERN/IT,\; Christopher Jones, Fermilab, CMS,\; Wim Lavrijsen, LBNL, PyRoot,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Liza Sakellari, CERN/SFT,\; Manuel Tobias Schiller,\; David Smith, CERN/IT,\; Matevz Tadel, UCSD/CMS, Eve, \; Vassil Vassilev, CERN/SFT \; Wouter Verkerke, NIKHEF/Atlas, RooFit, \; Yue Shi Lai, MIT,\; Maciej Zimnoch. ## Core Libraries. ### General. #### Platform support. ROOT now works on linuxarm64 / AArch64 / ARMv8 64-bit - thanks, David Abdurachmanov!. ROOT supports GCC 5.0 (using the GCC4 ABI) and XCode 6.3, Mac OSX 10.10.3. #### Thread-Safety. A lot of effort went into improving the thread-safety of Core and Meta classes / functions. A special thanks to Chris Jones from CMS!. #### std::string_view. Introduce a preview of C++17's std::string_view. To take advantage of this new; class use:; ```{.cpp}; #include ""RStringView.h""; ```; The documentation of this can be found at `http://en.cppreference.com/w/cpp/experimental/basic_string_view`; The implementation provided is extracted from libcxx. Whenever the current; compiler and standard library provide an implmentation, it is used. The type string_view describes an object that can refer to a constant contiguous sequence of char-like objects with the first element of the sequence",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:121,release,released,121,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['release'],['released']
Deployability,"% ROOT Version 6.06 Release Notes; % 2015-12-08; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.06/00 is scheduled for release in November, 2015. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. David Abdurachmanov, CERN, CMS,\; Bertrand Bellenot, CERN/SFT,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Cristina Cristescu, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Kyle Cranmer, NYU, RooStats,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT, \; Burt Holzman, Fermilab, CMS,\; Lukasz Janyst, CERN/IT,\; Christopher Jones, Fermilab, CMS,\; Wim Lavrijsen, LBNL, PyRoot,\; Sergey Linev, GSI, http, JSROOT, \; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/IT/Openlab,\; Enric Tejedor Saavedra, CERN/SFT,\; Liza Sakellari, CERN/SFT,\; Manuel Tobias Schiller,CERN, LHCb\; David Smith, CERN/IT,\; Matevz Tadel, UCSD/CMS, Eve, \; Vassil Vassilev, CERN/SFT \; Wouter Verkerke, NIKHEF/Atlas, RooFit, \; Omar, Zapata, Medellin, Columbia \; Maciej Zimnoch, GSoC, Poland. ## ROOT reference manual. The ROOT reference manual has been moved into Doxygen. Still some work and; polish has to be done but the reference guide in this new format is now online; and can be seen from the [ROOT home page](https://root.cern.ch/doc/master/index.html). ## Core Libraries. ### Dictionary generation. Fixed the dictionary generation in the case of class inside a namespace; marked inlined. Added mechanisms to stop the dictionary generation while parsing the XML and while selecting in presence of duplicates. Fix [ROOT-7760] : fully allow the usage of the dylib extension on OSx. Fix [ROOT-7723] : allow IOCtors to have as argument a ref to a type called __void__. We added a dictionary for map<string,string> as part of the default STL dictionary. We added support for template parameter pa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:130,release,release,130,README/ReleaseNotes/v606/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md,1,['release'],['release']
Deployability,"% ROOT Version 6.08 Release Notes; % 2015-11-12; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.08/00 is scheduled for release in October, 2016. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. David Abdurachmanov, CERN, CMS,\; Adrian Bevan, Queen Mary University of London, ATLAS,\; Attila Bagoly, GSoC,\; Bertrand Bellenot, CERN/SFT,\; Rene Brun, CERN/SFT,\; Philippe Canal, Fermilab,\; Andrew Carnes, University of Florida, CMS, \; Cristina Cristescu, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Paul Gessinger, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Luca Giommi, CERN/SFT,\; Sergei Gleyzer, University of Florida, CMS\; Christopher Jones, Fermilab, CMS,\; Wim Lavrijsen, LBNL, PyRoot,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Abhinav Moudgil, GSoC, \; Axel Naumann, CERN/SFT,\; Simon Pfreundschuh, GSoC, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/IT,\; Paul Russo, Fermilab,\; Enric Tejedor Saavedra, CERN/SFT,\; George Troska, Dortmund Univ.,\; Liza Sakellari, CERN/SFT,\; Alex Saperstein, ANL,\; Manuel Tobias Schiller, CERN/LHCb,\; David Smith, CERN/IT,\; Peter Speckmayer,\; Tom Stevenson, Queen Mary University of London, ATLAS\; Matevz Tadel, UCSD/CMS, Eve,\; Peter van Gemmeren, ANL, ATLAS,\; Xavier Valls, CERN/SFT, \; Vassil Vassilev, Fermilab/CMS,\; Stefan Wunsch, KIT, CMS\; Omar Zapata, University of Antioquia, CERN/SFT.; . <a name=""core-libs""></a>. ## General. * Remove many instances of new warnings issued by gcc 6.1; * Significant update of the valgrind suppression file to hide intentional lack; of delete of some entities at the end of the process.; * Resolved several memory leaks.; * Added deprecation system: when compiling against interfaces marked R__DEPRECATED, the compiler will issue a warning showing the ROOT version when the interface will be removed.; * From this version",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:130,release,release,130,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['release'],['release']
Deployability,"% ROOT Version 6.10 Release Notes; % 2016-09-30; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.10/00 is scheduled for release in 2017. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. Bertrand Bellenot, CERN/SFT,\; Georgios Bitzes, CERN/IT,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Vassil Vassilev, Fermilab/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.08. ### CINT remnants, dysfunctional for ROOT 6. - `TInterpreter`'s `Getgvp()`, `Getp2f2funcname(void*)`, `Setgvp(Long_t)`, `SetRTLD_NOW()`, `SetRTLD_LAZY()`.; - `SetFCN(void*)` from TVirtualFitter, TFitter, TBackCompFitter, TMinuit; - `TFoam::SetRhoInt(void*)`. ### Core. - The enum constant `TRef::kNotComputed`, `TLink::kObjIsParent` were never used and have been removed.; - The enum constant `TClonesArray::kNoSplit` has not been used since v2.26 and has been removed. ## Interpreter. - Automatic declaration of variables (`h = new TH1F(...)`) is *only* available at the prompt. The side-effects of relying on this in source files is simply too grave. Due to a bug (ROOT-8538), automatically declared variables must currently reside on the top-most scope, i.e. not inside an `if` block etc.; - Improved the stack frame information generated by the JIT. By avoiding interleaving of the memory associated to multiple JIT module, the generation of stack trace involving jitted code and the catching of exception going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:130,release,release,130,README/ReleaseNotes/v610/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md,1,['release'],['release']
Deployability,"% ROOT Version 6.12 Release Notes; % 2017-05-18. <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.12/00 is scheduled for release in 2018. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. Kim Albertsson, CERN,\; Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Brian Bockelman, UNL,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; David Clark, ANL (SULI),\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Raphael Isemann, Chalmers Univ. of Tech.,\; Sergey Linev, GSI,\; Timur Pocheptsov, CERN/SFT,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Simon Pfreundschuh,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Arthur Tsang, CERN/SFT, \; Peter van Gemmeren, ANL,\; Vassil Vassilev, Princeton Univ./CMS,\; Xavier Valls Pla, CERN/UJI, \; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, KIT,\; Omar Zapata. ## General News. This release now supports building with C++17 enabled using either libstdc++ or; libc++. This requires Clang >= 5.0, or GCC >= 7.3.0. At the date of this; release, GCC 7.2.0 still does not provide full support to compile ROOT with C++17. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.10. - Remove the deprecated `TSelectorCint.h` and `TSelectorCint.cxx`.; - Remove the deprecated `Riosfwd.h` and `Rtypeinfo.h`.; - `TTreeReader::SetLastEntry()` was replaced by `TTreeReader::SetEntriesRange()`. ## Core Libraries. - Added support for XCode 9 and MacOS High Sierra.; - When invoking root with the ""-t"" argument, ROOT enables thread-safety and,; if configured, implicit multithreading within ROOT.; - `NULL` is not defined by `Rtypes.h` anymore. Instead, its definition is expected to be; provided by `Rtype.h`'s `#include` of `stddef.h`.; - ROOT now supports dic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:130,release,release,130,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,1,['release'],['release']
Deployability,"% ROOT Version 6.14 Release Notes; % 2017-11-19. <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.14/00 is scheduled for release in 2018. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. Kim Albertsson, CERN/EP-ADP-OS,\; Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Brian Bockelman, UNL,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Raphael Isemann, Chalmers Univ. of Tech.,\; Vladimir Ilievski, GSOC 2017,\; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Saurav Shekhar, GSOC 2017,\; Xavier Valls Pla, UJI, CERN/SFT,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, CERN/SFT, \; Zhe Zhang, UNL. ## Important Notice. The default compression algorithm used when writing ROOT files has been updated to use LZ4 in particular to improve read (decompression) performance. You can change this default for each file through (for example) the `TFile constructor` or `TFile::SetCompressionAlgorithm`. It should be noted that ROOT files written with LZ4 compression can not be read with older release of ROOT. Support for LZ4 was however back-ported to the patch branches of previous releases and the following tags (and later release in the same patch series) can read ROOT files written with LZ4 compression:. * v5.34/38; * v6.08/06 [not yet released]; * v6.10/08; * v6.12/02. ## Removed interfaces. ## Core Libraries; - Optimize away redundant deserialization of template specializations. This reduces the memory footprint for hsimple by around 30% while improving the runtime performance for various cases by around 15%.; - When ROOT is signaled with a SIGUSR2 (i.e. on Linux and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:130,release,release,130,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,1,['release'],['release']
Deployability,"% ROOT Version 6.16 Release Notes; % 2018-06-25; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.16/00 is scheduled for release end of 2018. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Kim Albertsson, CERN/ATLAS,\; Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Iliana Betsou, CERN/SFT,\; Brian Bockelman, UNL,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Stephan Hageboeck, CERN/SFT,\; Siddhartha Rao Kamalakara, GSOC, \; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Alja Mrak Tadel, UCSD/CMS,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Ravi Kiran Selvam, GSOC, \; Manos, Stergiadis, GSOC, \; Matevz Tadel, UCSD/CMS,\; Yuka Takahashi, Princeton,\; Massimo Tumolo, Politecnico di Torino,\; Mohammad Uzair, CERN/SFT, \; Xavier Valls, CERN/SFT,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas,\; Stefan Wunsch, CERN/SFT. ## Deprecation and Removal. ### Ruby bindings. The ruby binding has been unmaintained for several years; it does not build with current ruby versions.; Given that this effectively meant that Ruby was dysfunctional and given that nobody (but package maintainers) has complained, we decided to remove it. ### Removal of previously deprecated or disabled packages. The packages `afs`, `chirp`, `glite`, `sapdb`, `srp` and `ios` have been removed from ROOT.; They were deprecated before, or never ported from configure, make to CMake. ### Remove GLUtesselator forward declaration from TVirtualX.h. It was never used in TVirtualX interfaces. If GLUtesselator forward declaration is required, use TGLUtil.h include instead. ## C++ Modules Technology Preview. ROOT has several features which interact with libraries and require",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md:130,release,release,130,README/ReleaseNotes/v616/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md,1,['release'],['release']
Deployability,"% ROOT Version 6.18 Release Notes; % 2019-05-28; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.18/00 is scheduled for release in June, 2019. For more information, see [http://root.cern](http://root.cern). The following people have contributed to this new version:. Kim Albertsson, CERN/ATLAS,\; Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Iliana Betsou, CERN/SFT,\; Jakob Blomer, CERN/SFT,\; Brian Bockelman, Nebraska,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Javier Cervantes Villanueva, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Alexandra Dobrescu, CERN/SFT,\; Giulio Eulisse, CERN/ALICE,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Stephan Hageboeck, CERN/SFT,\; Jan Knedlik, GSI,\; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Alja Mrak-Tadel, UCSD/CMS,\; Axel Naumann, CERN/SFT,\; Vincenzo Eduardo Padulano, Bicocca/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Henry Schreiner, Princeton,\; Oksana Shadura, Nebraska,\; Simon Spies, GSI,\; Yuka Takahashi, Princeton and CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Matevz Tadel, UCSD/CMS,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas,\; Zhe Zhang, Nebraska,\; Stefan Wunsch, CERN/SFT. ## Deprecation and Removal. ### Deprecated packages. The Virtual Monte Carlo (VMC) interfaces have been deprecated for this release; and will be removed in a future release. It is no longer built by default, but; can still be enabled with the option `-Dvmc=ON` in the CMake configuration phase.; A standalone version of VMC is being developed at [https://github.com/vmc-project/vmc](https://github.com/vmc-project/vmc); to replace the deprecated version in ROOT. ### Removed packages. Support for the following optional components of ROOT has been removed:. * afdsmgrd (Dataset manager for PROOF-based analysis facilities); * bonjour (Avahi/Bonjour/Zeroconf); * castor (CERN Advanced STORage manager); * geocad (OpenCasca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:130,release,release,130,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,1,['release'],['release']
Deployability,"% ROOT Version 6.20 Release Notes; % 2019-05-29; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.20/00 is scheduled for release in November 2019. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Kim Albertsson, CERN/ATLAS,\; Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Iliana Betsou, CERN/SFT,\; Jakob Blomer, CERN/SFT,\; Brian Bockelman, Nebraska,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Javier Cervantes Villanueva, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Alexandra Dobrescu, CERN/SFT,\; Giulio Eulisse, CERN/ALICE,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Stephan Hageboeck, CERN/SFT,\; Desislava Kalaydjieva, CERN/SFT,\; Jan Knedlik, GSI,\; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Alja Mrak-Tadel, UCSD/CMS,\; Axel Naumann, CERN/SFT,\; Vincenzo Eduardo Padulano, CERN/SFT and UPV,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Otto Schaile, Uni-Muenchen,\; Henry Schreiner, Princeton,\; Oksana Shadura, Nebraska,\; Simon Spies, GSI,\; Yuka Takahashi, Princeton and CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Matevz Tadel, UCSD/CMS,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas,\; Zhe Zhang, Nebraska,\; Stefan Wunsch, CERN/SFT. ## ROOT. ### Splash screen. The venerable splash screen is now disabled by default to make ROOT's startup; faster. Many users already use `root -l` to start ROOT, but this also hides the; useful text banner with version information along with the splash screen. With; this new default, starting up ROOT as just `root` will show only the text banner; instead of the splash screen. The splash screen can still be seen with `root -a`; or in `TBrowser` by opening `Browser Help → About ROOT`. ## Deprecation and Removal; * rootcling flags `-cint`, `-gccxml`, `-p`, `-r` and `-c` have no effect; and will be removed. Please remove them from the rootcl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md:130,release,release,130,README/ReleaseNotes/v620/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md,1,['release'],['release']
Deployability,"% ROOT Version 6.22 Release Notes; % 2020-05-19; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.22/00 is scheduled for release in May, 2020. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Jakob Blomer, CERN/SFT,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Stephan Hageboeck, CERN/SFT,\; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Alja Mrak-Tadel, UCSD/CMS,\; Jan Musinsky, SAS Kosice,\; Axel Naumann, CERN/SFT,\; Vincenzo Eduardo Padulano, CERN/SFT and UPV,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsoff, Qt Company,\; Renato Quagliani, LPNHE, CNRS/IN2P3, Sorbonne Université,\; Fons Rademakers, CERN/SFT,\; Oksana Shadura, Nebraska,\; Enric Tejedor Saavedra, CERN/SFT,\; Matevz Tadel, UCSD/CMS,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas,\; Stefan Wunsch, CERN/SFT. ## Deprecation and Removal. - `ROOT::GetImplicitMTPoolSize` has been deprecated in favor of the newly added `ROOT::GetThreadPoolSize` and; will be removed in v6.24.; - Manually setting `TThreadedObject::fgMaxSlots` is deprecated: TThreadedObject now increases the number of slots; on-demand rather than running out and throwing an exception. ## Core Libraries. - ROOT comes with C++ Modules enabled. More details about the technology found [here](../../README.CXXMODULES.md).; - The `ACLiC` can be configured to pass options to the `rootcling` invocation by enabling in the `.rootrc` the `ACLiC.ExtraRootclingFlags [-opts]` line.; - A call to `ROOT::EnableThreadSafety` is not required before using `TThreadExecutor` or `TTreeProcessorMT` anymore; - `TTreeProcessorMT` does not silently activate implicit multi-threading features anymore. An explicit call to; `ROOT::EnableImplicitMT` is required instead; - `TTreeProcessorMT` now has a constr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v622/index.md:130,release,release,130,README/ReleaseNotes/v622/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v622/index.md,1,['release'],['release']
Deployability,"% ROOT Version 6.24 Release Notes; % 2020-05-19; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.24/00 is scheduled for release in November 2020. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Josh Bendavid, CERN/CMS,\; Jakob Blomer, CERN/SFT,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Massimiliano Galli, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Hadrien Grasland, IJCLab/LAL,\; Enrico Guiraud, CERN/SFT,\; Claire Guyot, CERN/SFT,\; Jonas Hahnfeld, CERN/SFT,\; Emmanouil Michalainas, CERN/SFT,\; Stephan Hageboeck, CERN/SFT,\; Sergey Linev, GSI,\; Javier Lopez-Gomez, CERN/SFT,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Alja Mrak-Tadel, UCSD/CMS,\; Axel Naumann, CERN/SFT,\; Vincenzo Eduardo Padulano, CERN/SFT and UPV,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Jonas Rembser, CERN/SFT,\; Andrea Sciandra, SCIPP-UCSC/Atlas, \; Oksana Shadura, UNL/CMS,\; Enric Tejedor Saavedra, CERN/SFT,\; Christian Tacke, GSI, \; Matevz Tadel, UCSD/CMS,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas,\; Stefan Wunsch, CERN/SFT,\; Anirudh Dagar, CERN-HSF/GSoC. ## Deprecation and Removal. - [`RooAbsReal::evaluateBatch()`](https://root.cern/doc/v624/classRooAbsReal.html#a261580dfe94f2b107f9b9a77cad78a62) has been removed in favour of the faster evaluateSpan(). See section ""RooFit Libraries"" for instructions on how to use [`RooAbsReal::evaluateSpan()`](https://root.cern/doc/v624/classRooAbsReal.html#a1e5129ffbc63bfd04c01511fd354b1b8).; - `TTreeProcessorMT::SetMaxTasksPerFilePerWorker` has been deprecated in favour of `TTreeProcessorMT::SetTasksPerWorkerHint`. ## Core Libraries. Due to internal changes required to comply with the deprecation of Intel TBB's `task_scheduler_init` and related; interfaces in recent TBB versions, as of v6.24 ROOT will not honor a maximum concurrency",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:130,release,release,130,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['release'],['release']
Deployability,"% ROOT Version 6.26 Release Notes; % 2021-03-03; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.26/00 is scheduled for release in May, 2021. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Sitong An, CERN/SFT,\; Simone Azeglio, CERN/SFT,\; Rahul Balasubramanian, NIKHEF/ATLAS,\; Bertrand Bellenot, CERN/SFT,\; Josh Bendavid, CERN/CMS,\; Jakob Blomer, CERN/SFT,\; Patrick Bos, Netherlands eScience Center,\; Rene Brun, CERN/SFT,\; Carsten D. Burgard, DESY/ATLAS,\; Will Buttinger, STFC/ATLAS,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Mattias Ellert, Uppsala University, \; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Stephan Hageboeck, CERN/IT,\; Jonas Hahnfeld, CERN/SFT,\; Ahmat Hamdan, GSOC, \; Fernando Hueso-González, University of Valencia,\; Ivan Kabadzhov, CERN/SFT,\; Shamrock Lee (@ShamrockLee),\; Sergey Linev, GSI,\; Javier Lopez-Gomez, CERN/SFT,\; Pere Mato, CERN/SFT,\; Emmanouil Michalainas, CERN/SFT, \; Lorenzo Moneta, CERN/SFT,\; Nicolas Morange, CNRS/IJCLab, \; Axel Naumann, CERN/SFT,\; Vincenzo Eduardo Padulano, CERN/SFT and UPV,\; Max Orok, U Ottawa,\; Alexander Penev, University of Plovdiv,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Jonas Rembser, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Aaradhya Saxena, GSOC,\; Oksana Shadura, UNL/CMS,\; Sanjiban Sengupta, GSOC,\; Federico Sossai, CERN/SFT,\; Harshal Shende, GSOC,\; Matevz Tadel, UCSD/CMS,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/ATLAS,\; Zef Wolffs, NIKHEF/ATLAS,\; Stefan Wunsch, CERN/SFT. ## Deprecation, Removal, Backward Incompatibilities. - The ""Virtual MonteCarlo"" facility VMC (`montecarlo/vmc`) has been removed from ROOT. The development of this package has moved to a [separate project](https://github.com/vmc-project/). ROOT's copy of VMC was deprecated since v6.18.; - `TTreeProcessorMT::SetMaxTasksPerFilePerWorker` has been rem",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:130,release,release,130,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['release'],['release']
Deployability,"% ROOT Version 6.28 Release Notes; % 2022-01-05; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.28/00 is scheduled for release in May 2022. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Rahul Balasubramanian, NIKHEF/ATLAS,\; Bertrand Bellenot, CERN/SFT,\; Jakob Blomer, CERN/SFT,\; Patrick Bos, Netherlands eScience Center,\; Rene Brun, CERN/SFT,\; Carsten D. Burgard, TU Dortmund University/ATLAS,\; Will Buttinger, RAL/ATLAS,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Michel De Cian, EPFL/LHCb,\; Mattias Ellert, Uppsala University,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Konstantin Gizdov, University of Edinburgh/LHCb,\; Max Goblirsch, CERN/ATLAS,\; Enrico Guiraud, CERN/SFT,\; Stephan Hageboeck, CERN/IT,\; Jonas Hahnfeld, CERN/SFT,\; Ahmat Mahamat Hamdan, CERN/SFT,\; Fernando Hueso-González, University of Valencia,\; Subham Jyoti, ITER Bhubaneswar,\; Sergey Linev, GSI,\; Javier Lopez-Gomez, CERN/SFT,\; Enrico Lusiani, INFN/CMS,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Nicolas Morange, CNRS/ATLAS,\; Axel Naumann, CERN/SFT,\; Hanna Olvhammar, CERN/SFT,\; Vincenzo Eduardo Padulano, CERN/SFT and UPV,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Jonas Rembser, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Neel Shah, GSOC,\; Sanjiban Sengupta, CERN/SFT,\; Harshal Shende, GSOC,\; Garima Singh, Princeton/SFT,\; Matevz Tadel, UCSD/CMS,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/ATLAS,\; Zef Wolffs, NIKHEF/ATLAS,\; Ivan Kabadzhov, CERN/SFT,\; David Poulton, Wits/SFT. ## Deprecation and Removal. - The deprecated types `ROOT::Experimental::TBufferMerger` and `ROOT::Experimental::TBufferMergerFile` are removed.; Please use their non-experimental counterparts `ROOT::TBufferMerger` and `ROOT::TBufferMergerFile` instead.; - `ROOT::RVec::shrink_to_fit()` has now been removed after deprecation; it is not needed.; - `ROOT::RVec::em",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md:130,release,release,130,README/ReleaseNotes/v628/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md,1,['release'],['release']
Deployability,"% ROOT Version 6.30 Release Notes; % 2022-12-21; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.30/00 is scheduled for release in October, 2023. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Daniel Álvarez Conde, CERN/EP-SFT,\; Guilherme Amadio, CERN/IT,\; Bertrand Bellenot, CERN/EP-SFT,\; Jakob Blomer, CERN/EP-SFT,\; Patrick Bos, Netherlands eScience Center,\; Rene Brun,\; Carsten Burgard, TU Dortmund,\; Will Buttinger, Rutherford Appleton Lab,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/EP-SFT,\; Marta Czurylo, CERN/EP-SFT,\; Mattias Ellert, Uppsala Uni,\; Edward Finkelstein, JGU Mainz,\; Gerri Ganis, CERN/EP-SFT,\; Paul Gessinger, CERN/EP-SFT,\; Florine de Geus, CERN/ATLAS,\; Andrei Gheata, CERN/EP-SFT,\; Enrico Guiraud, CERN/EP-SFT and Princeton,\; Ahmat Hamdan, CERN/EP-SFT,\; Stephan Hageboeck, CERN/IT,\; Jonas Hahnfeld, CERN/EP-SFT,\; Fernando Hueso González, CSIC/UV,\; Attila Krasznahorkay, CERN/ATLAS,\; Baidyanath Kundu, CERN/EP-SFT and Princeton,\; Giovanna Lazzari Miotto, CERN/EP-SFT,\; Sergey Linev, GSI,\; Jerry Ling, Harvard Uni,\; Javier Lopez-Gomez, CERN/EP-SFT,\; Pere Mato, CERN/EP-SFT,\; Lorenzo Moneta, CERN/EP-SFT,\; Ole Morud, CERN/EP-SFT,\; Alja Mrak Tadel, UCSD/CMS,\; Axel Naumann, CERN/EP-SFT,\; Dante Niewenhuis, UvA and CERN/EP-SFT,\; Vincenzo Eduardo Padulano, CERN/EP-SFT,\; Ioanna Maria Panagou, CERN/EP-SFT,\; Danilo Piparo, CERN/EP-SFT,\; Fons Rademakers, CERN/IT,\; Jonas Rembser, CERN/EP-SFT,\; Jakob Schneekloth, CERN/EP-SFT,\; Sanjiban Sengupta, CERN/EP-SFT,\; Neel Shah, GSoC,\; Garima Singh, CERN/EP-SFT and Princeton,\; Yash Solanki, GSoC,\; Uri Stern, CERN/EP-SFT,\; Silia Taider, CPE Lyon and CERN EP-SFT,\; Enric Tejedor Saavedra, CERN/IT,\; Matevz Tadel, UCSD/CMS,\; [QuillPusher](https://github.com/QuillPusher), [Compiler Research Group](https://compiler-research.org/team/),\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/ATLAS,\; Dan",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md:130,release,release,130,README/ReleaseNotes/v630/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md,1,['release'],['release']
Deployability,"% ROOT Version 6.32 Release Notes; % 2024-05-26; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.32.00 was released on 28 May 2024.; This release is a long term support one, ideal for inclusion in production or; data taking software stacks of experiments. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Anton Alkin, Sungkyunkwan University\; Guilherme Amadio, CERN/IT,\; Abhigyan Acherjee, University of Cincinnati,\; Bertrand Bellenot, CERN/EP-SFT,\; Jakob Blomer, CERN/EP-SFT,\; Rene Brun,\; Carsten Burgard, DESY\; Will Buttinger, RAL,\; Philippe Canal, FNAL,\; Jolly Chen, CERN/EP-SFT,\; Olivier Couet, CERN/EP-SFT,\; Marta Czurylo, CERN/EP-SFT,\; Monica Dessole, CERN/EP-SFT,\; Mattias Ellert, Uppsala University,\; Gerri Ganis, CERN/EP-SFT,\; Florine de Geus, CERN/University of Twente,\; Andrei Gheata, CERN/EP-SFT,\; Bernhard Manfred Gruber,\; Enrico Guiraud,; Jonas Hahnfeld, CERN/Goethe University Frankfurt,\; Fernando Hueso Gonzalez, University of Valencia\; Attila Krasznahorkay, CERN/EP-ADP-OS,\; Wim Lavrijsen, LBL,\; Dennis Klein, GSI,\; Christoph Langenbruch, Heidelberg University/LHCb,\; Sergey Linev, GSI,\; Javier Lopez-Gomez,\; Pere Mato, CERN/EP-SFT,\; Alaettin Serhan Mete, Argonne,\; Thomas Madlener, DESY,\; Lorenzo Moneta, CERN/EP-SFT,\; Alja Mrak Tadel, UCSD/CMS,\; Axel Naumann, CERN/EP-SFT,\; Dante Niewenhuis, VU Amsterdam\; Luis Antonio Obis Aparicio, University of Zaragoza,; Ianna Osborne, Princeton University,\; Vincenzo Eduardo Padulano, CERN/EP-SFT,\; Danilo Piparo, CERN/EP-SFT,\; Fons Rademakers, CERN/IT,\; Jonas Rembser, CERN/EP-SFT,\; Andrea Rizzi, University of Pisa,\; Andre Sailer, CERN/EP-SFT,\; Garima Singh, ETH,\; Juraj Smiesko, CERN/RCS-PRJ-FC,; Pavlo Svirin, National Technical University of Ukraine,\; Maciej Szymanski, Argonne,\; Christian Tacke, Darmstadt University,\; Matevz Tadel, UCSD/CMS,\; Alvaro Tolosa Delgado, CERN/RCS-PRJ-FC,\; Devajith Valaparamb",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:117,release,released,117,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,2,['release'],"['release', 'released']"
Deployability,"% ROOT Version 6.34 Release Notes; % 2025-05; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.34.00 is scheduled for release at the end of May 2025. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Anton Alkin, Sungkyunkwan University\; Guilherme Amadio, CERN/IT,\; Abhigyan Acherjee, University of Cincinnati,\; Bertrand Bellenot, CERN/EP-SFT,\; Jakob Blomer, CERN/EP-SFT,\; Rene Brun,\; Carsten Burgard, DESY\; Will Buttinger, RAL,\; Philippe Canal, FNAL,\; Jolly Chen, CERN/EP-SFT,\; Olivier Couet, CERN/EP-SFT,\; Marta Czurylo, CERN/EP-SFT,\; Monica Dessole, CERN/EP-SFT,\; Mattias Ellert, Uppsala University,\; Gerri Ganis, CERN/EP-SFT,\; Florine de Geus, CERN/University of Twente,\; Andrei Gheata, CERN/EP-SFT,\; Bernhard Manfred Gruber,\; Enrico Guiraud,\; Jonas Hahnfeld, CERN/Goethe University Frankfurt,\; Fernando Hueso Gonzalez, University of Valencia\; Attila Krasznahorkay, CERN/EP-ADP-OS,\; Wim Lavrijsen, LBL,\; Valerii Kholoimov, National University of Kyiv/IRIS-HEP, \; Dennis Klein, GSI,\; Christoph Langenbruch, Heidelberg University/LHCb,\; Sergey Linev, GSI,\; Javier Lopez-Gomez,\; Pere Mato, CERN/EP-SFT,\; Alaettin Serhan Mete, Argonne,\; Thomas Madlener, DESY,\; Lorenzo Moneta, CERN/EP-SFT,\; Alja Mrak Tadel, UCSD/CMS,\; Axel Naumann, CERN/EP-SFT,\; Dante Niewenhuis, VU Amsterdam\; Luis Antonio Obis Aparicio, University of Zaragoza,\; Ianna Osborne, Princeton University,\; Vincenzo Eduardo Padulano, CERN/EP-SFT,\; Danilo Piparo, CERN/EP-SFT,\; Fons Rademakers, CERN/IT,\; Jonas Rembser, CERN/EP-SFT,\; Andrea Rizzi, University of Pisa,\; Andre Sailer, CERN/EP-SFT,\; Garima Singh, ETH,\; Juraj Smiesko, CERN/RCS-PRJ-FC,\; Pavlo Svirin, National Technical University of Ukraine,\; Robin Syring, Leibniz University Hannover, CERN/EP-SFT,\; Maciej Szymanski, Argonne,\; Christian Tacke, Darmstadt University,\; Matevz Tadel, UCSD/CMS,\; Alvaro Tolosa Delgado, CERN/RCS-PRJ-FC,\; Devaj",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v634/index.md:127,release,release,127,README/ReleaseNotes/v634/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v634/index.md,1,['release'],['release']
Deployability,"% ROOT Version ?.?? Release Notes; % 20??-??-??; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.??.00 is scheduled for release in ???. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Anton Alkin, Sungkyunkwan University\; Guilherme Amadio, CERN/IT,\; Abhigyan Acherjee, University of Cincinnati,\; Bertrand Bellenot, CERN/EP-SFT,\; Jakob Blomer, CERN/EP-SFT,\; Rene Brun,\; Carsten Burgard, DESY\; Will Buttinger, RAL,\; Philippe Canal, FNAL,\; Jolly Chen, CERN/EP-SFT,\; Olivier Couet, CERN/EP-SFT,\; Marta Czurylo, CERN/EP-SFT,\; Monica Dessole, CERN/EP-SFT,\; Mattias Ellert, Uppsala University,\; Gerri Ganis, CERN/EP-SFT,\; Florine de Geus, CERN/University of Twente,\; Andrei Gheata, CERN/EP-SFT,\; Bernhard Manfred Gruber,\; Enrico Guiraud,; Jonas Hahnfeld, CERN/Goethe University Frankfurt,\; Fernando Hueso Gonzalez, University of Valencia\; Attila Krasznahorkay, CERN/EP-ADP-OS,\; Wim Lavrijsen, LBL,\; Dennis Klein, GSI,\; Christoph Langenbruch, Heidelberg University/LHCb,\; Sergey Linev, GSI,\; Javier Lopez-Gomez,\; Pere Mato, CERN/EP-SFT,\; Alaettin Serhan Mete, Argonne,\; Thomas Madlener, DESY,\; Lorenzo Moneta, CERN/EP-SFT,\; Alja Mrak Tadel, UCSD/CMS,\; Axel Naumann, CERN/EP-SFT,\; Dante Niewenhuis, VU Amsterdam\; Luis Antonio Obis Aparicio, University of Zaragoza,; Ianna Osborne, Princeton University,\; Vincenzo Eduardo Padulano, CERN/EP-SFT,\; Danilo Piparo, CERN/EP-SFT,\; Fons Rademakers, CERN/IT,\; Jonas Rembser, CERN/EP-SFT,\; Andrea Rizzi, University of Pisa,\; Andre Sailer, CERN/EP-SFT,\; Garima Singh, ETH,\; Juraj Smiesko, CERN/RCS-PRJ-FC,; Pavlo Svirin, National Technical University of Ukraine,\; Maciej Szymanski, Argonne,\; Christian Tacke, Darmstadt University,\; Matevz Tadel, UCSD/CMS,\; Alvaro Tolosa Delgado, CERN/RCS-PRJ-FC,\; Devajith Valaparambil Sreeramaswamy, CERN/EP-SFT,\; Peter Van Gemmeren, Argonne,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHE",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/empty.md:130,release,release,130,README/ReleaseNotes/empty.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/empty.md,1,['release'],['release']
Deployability,"'s `LibTooling <LibTooling.html>`_. It is; explicitly aimed at people who are new to Clang, so all you should need; is a working knowledge of C++ and the command line. In order to work on the compiler, you need some basic knowledge of the; abstract syntax tree (AST). To this end, the reader is encouraged to; skim the :doc:`Introduction to the Clang; AST <IntroductionToTheClangAST>`. Step 0: Obtaining Clang; =======================. As Clang is part of the LLVM project, you'll need to download LLVM's; source code first. Both Clang and LLVM are in the same git repository,; under different directories. For further information, see the `getting; started guide <https://llvm.org/docs/GettingStarted.html>`_. .. code-block:: console. mkdir ~/clang-llvm && cd ~/clang-llvm; git clone https://github.com/llvm/llvm-project.git. Next you need to obtain the CMake build system and Ninja build tool. .. code-block:: console. cd ~/clang-llvm; git clone https://github.com/martine/ninja.git; cd ninja; git checkout release; ./configure.py --bootstrap; sudo cp ninja /usr/bin/. cd ~/clang-llvm; git clone https://gitlab.kitware.com/cmake/cmake.git; cd cmake; git checkout next; ./bootstrap; make; sudo make install. Okay. Now we'll build Clang!. .. code-block:: console. cd ~/clang-llvm; mkdir build && cd build; cmake -G Ninja ../llvm-project/llvm -DLLVM_ENABLE_PROJECTS=""clang;clang-tools-extra"" -DCMAKE_BUILD_TYPE=Release -DLLVM_BUILD_TESTS=ON; ninja; ninja check # Test LLVM only.; ninja clang-test # Test Clang only.; ninja install. And we're live. All of the tests should pass. Finally, we want to set Clang as its own compiler. .. code-block:: console. cd ~/clang-llvm/build; ccmake ../llvm-project/llvm. The second command will bring up a GUI for configuring Clang. You need; to set the entry for ``CMAKE_CXX_COMPILER``. Press ``'t'`` to turn on; advanced mode. Scroll down to ``CMAKE_CXX_COMPILER``, and set it to; ``/usr/bin/clang++``, or wherever you installed it. Press ``'c'`` to; configure, th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst:1309,release,release,1309,interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst,1,['release'],['release']
Deployability,"'s a bit of a grey area what; should be fixed before the next candidate and what can wait until the next; release. It'll depend on:. * The severity of the bug, how many people it affects and if it's a regression; or a known bug. Known bugs are ""unsupported features"" and some bugs can be; disabled if they have been implemented recently. * The stage in the release. Less critical bugs should be considered to be; fixed between RC1 and RC2, but not so much at the end of it. * If it's a correctness or a performance regression. Performance regression; tends to be taken more lightly than correctness. .. _scripts:. Scripts; =======. The scripts are in the ``utils/release`` directory. test-release.sh; ---------------. This script will check-out, configure and compile LLVM+Clang (+ most add-ons,; like ``compiler-rt``, ``libcxx``, ``libomp`` and ``clang-extra-tools``) in; three stages, and will test the final stage.; It'll have installed the final binaries on the Phase3/Releasei(+Asserts); directory, and that's the one you should use for the test-suite and other; external tests. To run the script on a specific release candidate run::. ./test-release.sh \; -release 3.3 \; -rc 1 \; -no-64bit \; -test-asserts \; -no-compare-files. Each system will require different options. For instance, x86_64 will; obviously not need ``-no-64bit`` while 32-bit systems will, or the script will; fail. The important flags to get right are:. * On the pre-release, you should change ``-rc 1`` to ``-final``. On RC2,; change it to ``-rc 2`` and so on. * On non-release testing, you can use ``-final`` in conjunction with; ``-no-checkout``, but you'll have to create the ``final`` directory by hand; and link the correct source dir to ``final/llvm.src``. * For release candidates, you need ``-test-asserts``, or it won't create a; ""Release+Asserts"" directory, which is needed for release testing and; benchmarking. This will take twice as long. * On the final candidate you just need Release builds, and that's th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst:1851,install,installed,1851,interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,1,['install'],['installed']
Deployability,"( ~ "" ~ ); RooArgSet(x, y) }, // Variables to create in dataset; {""x"", ""y""} // Column names from RDataFrame; );; ```; For more details, consult the tutorial [rf408_RDataFrameToRooFit](https://root.cern/doc/v626/rf408__RDataFrameToRooFit_8C.html). ### Storing global observables in RooFit datasets. RooFit groups model variables into *observables* and *parameters*, depending on if their values are stored in the dataset.; For fits with parameter constraints, there is a third kind of variables, called *global observables*.; These represent the results of auxiliary measurements that constrain the nuisance parameters.; In the RooFit implementation, a likelihood is generally the sum of two terms:; * the likelihood of the data given the parameters, where the normalization set is the set of observables (implemented by `RooNLLVar`); * the constraint term, where the normalization set is the set of *global observables* (implemented by `RooConstraintSum`). Before this release, the global observable values were always taken from the model/pdf.; With this release, a mechanism is added to store a snapshot of global observables in any `RooDataSet` or `RooDataHist`.; For toy studies where the global observables assume a different values for each toy, the bookkeeping of the set of global observables and in particular their values is much easier with this change. Usage example for a model with global observables `g1` and `g2`:; ```C++; auto data = model.generate(x, 1000); // data has only the single observables x; data->setGlobalObservables(g1, g2); // now, data also stores a snapshot of g1 and g2. // If you fit the model to the data, the global observables and their values; // are taken from the dataset:; model.fitTo(*data);. // You can still define the set of global observables yourself, but the values; // will be takes from the dataset if available:; model.fitTo(*data, GlobalObservables(g1, g2));. // To force `fitTo` to take the global observable values from the model even; // though",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:27470,release,release,27470,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['release'],['release']
Deployability,"(""Modern"");; ; It has very little decoration. It was made looking at the default styles; usually used by the experiments.; ; A new parameter Canvas.Style in etc/system.rootrc allows; to define the default style. If it is not specified, the Modern; style is used. To use the old default style one can set it to Classic or add. gROOT->SetStyle(""Classic"");; ; to your scripts. We seek feedback on improving the Modern style.; Please leave comments in the forum.; ; The following table shows the two plots hpx->Draw() and hpxpy->Draw(""colz""); in the ""Classic"" and ""Modern"" styles.; . Classic Style; Modern Style. An other example:; ; Classic style:. Modern style:. ACLiC. ACLiC now passes the macro __ACLIC__ to both the rootcint and compiler phases. TWinNTSystem. Fix 64-bit compatibility issues (__asm keyword is not allowed).; Try (as much as possible) to avoid the disturbing ""There is no disk in the drive. Please insert a disk into drive \Device\..."" popup message box when calling AccessPathName() on removable disk drives with no media installed. This should fix the problem reported on the forum.; Prevent short timers (e.g. 10ms) to keep looping in the DispatchOneEvent() infinite loop.; Better stdout/stderr redirection (it was impossible to restore stdout using freopen on Windows 7, leaving the console as a zombie...); Make sure the stdout/stderr redirection works also in the case there is no console (i.e. in stand-alone applications).; Make sure the file descriptors are valid before using them.; The shortcuts are now working on Windows. Building with CMake. ROOT can now be build using the CMake build system (version 2.8). ; The initial supported platforms are Linux(gcc), Windows (vc9), MacOSX(gcc). The installed libraries and executables should be compatible to the standard build of ROOT.  CMake generates native makefiles and workspaces (i.e. Xcode, Eclipse, Visual Studio) that can be used in the; compiler environment of your choice. The main difference with respect; the Module",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v530/index.html:3521,install,installed,3521,core/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v530/index.html,1,['install'],['installed']
Deployability,"(""mhs3.so""); // or; root[] gSystem->Load(""CalcPiThread.so"");; ```. 4. Creating. Create a thread instance (see also example `RunMhs3.C `or` RunPi.C`); with:. ``` {.cpp}; root[] TThread *th = new TThread(UserFun,UserArgs);; ```. When called from the interpreter, this gives the name ""`UserFun`"" to the; thread. This name can be used to retrieve the thread later. However,; when called from compiled code, this method does not give any name to; the thread. So give a name to the thread in compiled use:. ``` {.cpp}; root[] TThread *th = new TThread(""MyThread"", UserFun, UserArgs);; ```. You can pass arguments to the thread function using the; `UserArgs`-pointer. When you want to start a method of a class as a; thread, you have to give the pointer to the class instance as; `UserArgs`. 5. Running. ``` {.cpp}; root[] th->Run();; root[] TThread::Ps(); // like UNIX ps c.ommand;; ```. With the `mhs3` example, you should be able to see a canvas with two; pads on it. Both pads keep histograms updated and filled by three; different threads. With the `CalcPi` example, you should be able to see; two threads calculating Pi with the given number of intervals as; precision. ### TThread in More Details. Cling is not thread safe yet, and it will block the execution of the; threads until it has finished executing. #### Asynchronous Actions. Different threads can work simultaneously with the same object. Some; actions can be dangerous. For example, when two threads create a; histogram object, ROOT allocates memory and puts them to the same; collection. If it happens at the same time, the results are; undetermined. To avoid this problem, the user has to synchronize these; actions with:. ``` {.cpp}; TThread::Lock() // Locking the following part of code; ... // Create an object, etc...; TThread::UnLock() // Unlocking; ```. The code between `Lock()` and `UnLock()` will be performed; uninterrupted. No other threads can perform actions or access; objects/collections while it is being executed. The m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:6187,update,updated,6187,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,1,['update'],['updated']
Deployability,"() now accepts a new argument ShowProgress() that will print a dot for every; function evaluation performed in the process of creating the plot. This can be useful when plotting very expensive; functions such as profile likelihoods; Automatic handling of constraint terms; It is no longer necessary to add a Constrain() argument to fitTo() calls to have internal constraints; applied. Any pdf term appearing in a product that does not contain an observable and shares one or more parameters; with another pdf term in the same product that does contain an observable is automatically picked up as a constraint term.; For example given a dataset D(x) which defines variable x as observable, the default logic works out as follows. F(x,a,b)*G(a,a0,a1) --> G is constraint term (a also appears in F(x)); F(x,a,b)*G(y,c,d) --> G is dropped (factorizing term). A Constrain(y) term in the above example will still force term G(y,c,d) to be interpreted as constraint term; Automatic caching of numeric integral calculations; Integrals that require numeric integrations in two of more dimensions are now automatically cached in the expensive object store.; The expensive object store allows to cache such values between difference instance of integral objects that represent the; same configuration. If integrals are created from an object (function or pdf) that live in a RooWorkspace the ; expensive object cache of the workspace will be used instead of the global store instance, and values stored in the workspace; store will also be persisted if the workspace is persisted. The global caching behavior of integral objects can be ; controlled through RooRealIntegral::setCacheAllNumeric(Int_t nDimNumMin). Miscellaneous improvements data classes. The RooAbsData::tree() method has been restored. It will only return a TTree* pointer for datasets; that are based on a RooTreeDataStore implementation, i.e. not for the composite datasets mentioned below; A new composite data storage class RooCompositeDataS",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:7758,integrat,integrations,7758,roofit/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html,1,['integrat'],['integrations']
Deployability,"() { return std::make_unique<SectionMemoryManager>(); }),; CompileLayer(ES, ObjectLayer, ConcurrentIRCompiler(std::move(JTMB))),; TransformLayer(ES, CompileLayer, optimizeModule),; DL(std::move(DL)), Mangle(ES, this->DL),; Ctx(std::make_unique<LLVMContext>()) {; ES.getMainJITDylib().addGenerator(; cantFail(DynamicLibrarySearchGenerator::GetForCurrentProcess(DL.getGlobalPrefix())));; }. Our extended KaleidoscopeJIT class starts out the same as it did in Chapter 1,; but after the CompileLayer we introduce a new member, TransformLayer, which sits; on top of our CompileLayer. We initialize our OptimizeLayer with a reference to; the ExecutionSession and output layer (standard practice for layers), along with; a *transform function*. For our transform function we supply our classes; optimizeModule static method. .. code-block:: c++. // ...; return cantFail(OptimizeLayer.addModule(std::move(M),; std::move(Resolver)));; // ... Next we need to update our addModule method to replace the call to; ``CompileLayer::add`` with a call to ``OptimizeLayer::add`` instead. .. code-block:: c++. static Expected<ThreadSafeModule>; optimizeModule(ThreadSafeModule M, const MaterializationResponsibility &R) {; // Create a function pass manager.; auto FPM = std::make_unique<legacy::FunctionPassManager>(M.get());. // Add some optimizations.; FPM->add(createInstructionCombiningPass());; FPM->add(createReassociatePass());; FPM->add(createGVNPass());; FPM->add(createCFGSimplificationPass());; FPM->doInitialization();. // Run the optimizations over all functions in the module being added to; // the JIT.; for (auto &F : *M); FPM->run(F);. return M;; }. At the bottom of our JIT we add a private method to do the actual optimization:; *optimizeModule*. This function takes the module to be transformed as input (as; a ThreadSafeModule) along with a reference to a reference to a new class:; ``MaterializationResponsibility``. The MaterializationResponsibility argument; can be used to query JIT state for th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst:4217,update,update,4217,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,1,['update'],['update']
Deployability,"(Function &F) = 0;. The ``runOnFunction`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. .. _writing-an-llvm-pass-doFinalization-mod:. The ``doFinalization(Module &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization(Module &M);. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnFunction; <writing-an-llvm-pass-runOnFunction>` for every function in the program being; compiled. .. _writing-an-llvm-pass-LoopPass:. The ``LoopPass`` class; ----------------------. All ``LoopPass`` execute on each :ref:`loop <loop-terminology>` in the function; independent of all of the other loops in the function. ``LoopPass`` processes; loops in loop nest order such that outer most loop is processed last. ``LoopPass`` subclasses are allowed to update loop nest using ``LPPassManager``; interface. Implementing a loop pass is usually straightforward.; ``LoopPass``\ es may override three virtual methods to do their work. All; these methods should return ``true`` if they modified the program, or ``false``; if they didn't. A ``LoopPass`` subclass which is intended to run as part of the main loop pass; pipeline needs to preserve all of the same *function* analyses that the other; loop passes in its pipeline require. To make that easier,; a ``getLoopAnalysisUsage`` function is provided by ``LoopUtils.h``. It can be; called within the subclass's ``getAnalysisUsage`` override to get consistent; and correct behavior. Analogously, ``INITIALIZE_PASS_DEPENDENCY(LoopPass)``; will initialize this set of function analyses. The ``doInitialization(Loop *, LPPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Loop *, LPPassManager &LPM);. The ``doInitialization`` method",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:20533,update,update,20533,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['update'],['update']
Deployability,"(JFpuPRF); and one for integer registers (JIntegerPRF). The table shows that of the 900; instructions processed, there were 900 mappings created. Since this dot-product; example utilized only floating point registers, the JFPuPRF was responsible for; creating the 900 mappings. However, we see that the pipeline only used a; maximum of 35 of 72 available register slots at any given time. We can conclude; that the floating point PRF was the only register file used for the example, and; that it was never resource constrained. The register file statistics are; displayed by using the command option ``-all-stats`` or; ``-register-file-stats``. In this example, we can conclude that the IPC is mostly limited by data; dependencies, and not by resource pressure. Instruction Flow; ^^^^^^^^^^^^^^^^; This section describes the instruction flow through the default pipeline of; :program:`llvm-mca`, as well as the functional units involved in the process. The default pipeline implements the following sequence of stages used to; process instructions. * Dispatch (Instruction is dispatched to the schedulers).; * Issue (Instruction is issued to the processor pipelines).; * Write Back (Instruction is executed, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipeline implements the following sequence of stages:; * InOrderIssue (Instruction is issued to the processor pipelines).; * Retire (Instruction is retired; writes are architecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not modeled. Performance bottlenecks in the frontend are not; diagnosed. Also, :program:`llvm-mca` does not model branch prediction. Instruction Dispatch; """"""""""""""""""""""""""""""""""""""""; During the dispatch stage, instructions are picked in program order from a; queue of already decoded instructions, and disp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:34009,pipeline,pipeline,34009,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['pipeline'],['pipeline']
Deployability,"(LLVM_DEFAULT_TARGET_TRIPLE_DEFAULT ""${LLVM_HOST_TRIPLE}""); endif(); endif(). set(LLVM_DEFAULT_TARGET_TRIPLE ""${LLVM_DEFAULT_TARGET_TRIPLE_DEFAULT}"" CACHE STRING; ""Default target for which LLVM will generate code."" ); message(STATUS ""LLVM default target triple: ${LLVM_DEFAULT_TARGET_TRIPLE}""). set(LLVM_TARGET_TRIPLE ""${LLVM_DEFAULT_TARGET_TRIPLE}""). if(WIN32 OR CYGWIN); if(BUILD_SHARED_LIBS OR LLVM_BUILD_LLVM_DYLIB); set(LLVM_ENABLE_PLUGINS_default ON); else(); set(LLVM_ENABLE_PLUGINS_default OFF); endif(); else(); set(LLVM_ENABLE_PLUGINS_default ${LLVM_ENABLE_PIC}); endif(); option(LLVM_ENABLE_PLUGINS ""Enable plugin support"" ${LLVM_ENABLE_PLUGINS_default}). set(LLVM_ENABLE_NEW_PASS_MANAGER TRUE CACHE BOOL; ""Enable the new pass manager by default.""); if(NOT LLVM_ENABLE_NEW_PASS_MANAGER); message(FATAL_ERROR ""Enabling the legacy pass manager on the cmake level is""; "" no longer supported.""); endif(). include(HandleLLVMOptions). ######. # Configure all of the various header file fragments LLVM uses which depend on; # configuration variables.; set(LLVM_ENUM_TARGETS """"); set(LLVM_ENUM_ASM_PRINTERS """"); set(LLVM_ENUM_ASM_PARSERS """"); set(LLVM_ENUM_DISASSEMBLERS """"); set(LLVM_ENUM_TARGETMCAS """"); set(LLVM_ENUM_EXEGESIS """"); foreach(t ${LLVM_TARGETS_TO_BUILD}); set( td ${LLVM_MAIN_SRC_DIR}/lib/Target/${t} ). # Make sure that any experimental targets were passed via; # LLVM_EXPERIMENTAL_TARGETS_TO_BUILD, not LLVM_TARGETS_TO_BUILD.; # We allow experimental targets that are not in LLVM_ALL_EXPERIMENTAL_TARGETS,; # as long as they are passed via LLVM_EXPERIMENTAL_TARGETS_TO_BUILD.; if ( NOT ""${t}"" IN_LIST LLVM_ALL_TARGETS AND NOT ""${t}"" IN_LIST LLVM_EXPERIMENTAL_TARGETS_TO_BUILD ); if( ""${t}"" IN_LIST LLVM_ALL_EXPERIMENTAL_TARGETS ); message(FATAL_ERROR ""The target `${t}' is experimental and must be passed ""; ""via LLVM_EXPERIMENTAL_TARGETS_TO_BUILD.""); else(); message(FATAL_ERROR ""The target `${t}' is not a core tier target. It may be ""; ""experimental, if so it must be passed via",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:39380,configurat,configuration,39380,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['configurat'],['configuration']
Deployability,"(ROOT). #---Set the locale to default C to prevent issued due to localization of commands---------------; # This is necessary as we for example call `clang -v` and parse its output. But on a localized; # program, the output parsing is much more error prone as certrain strings we're looking for; # could be missing or be in a different order. To prevent those errors, let's just force all; # output to use the default C locale which is more or less identical on all systems.; set(ENV{LANG} C). #---Set paths where to put the libraries, executables and headers------------------------------; file(MAKE_DIRECTORY ${CMAKE_BINARY_DIR}/lib) # prevent mkdir races; set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib); set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib); set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin). # Set permissions for installed folders and subfolders that come from the source tree in case; # the permissions in the source tree are wrong since the install command will preserve them; set(DIR_PERMISSIONS DIRECTORY_PERMISSIONS OWNER_READ OWNER_WRITE OWNER_EXECUTE GROUP_READ GROUP_EXECUTE WORLD_READ WORLD_EXECUTE). # Before setting ROOTSYS, make sure that the environment isn't polluted by a different; # ROOT build. This is significant e,g. for roottest, which will otherwise have libraries; # of a different ROOT build available / visible / reachable.; if(NOT $ENV{ROOTSYS} STREQUAL """"); string(REPLACE ""$ENV{ROOTSYS}/bin"" """" ENV_PATH ""$ENV{PATH}""); string(REPLACE ""$ENV{ROOTSYS}/lib"" """" ENV_LD_LIBRARY_PATH ""$ENV{LD_LIBRARY_PATH}""); string(REPLACE ""$ENV{ROOTSYS}/lib"" """" ENV_PYTHONPATH ""$ENV{PYTHONPATH}""); string(REPLACE ""$ENV{ROOTSYS}"" """" ENV_CMAKE_PREFIX_PATH ""$ENV{CMAKE_PREFIX_PATH}""); set(ENV{PATH} ""${ENV_PATH}""); set(ENV{LD_LIBRARY_PATH} ""${ENV_LD_LIBRARY_PATH}""); set(ENV{PYTHONPATH} ""${ENV_PYTHONPATH}""); set(ENV{CMAKE_PREFIX_PATH} ""${ENV_CMAKE_PREFIX_PATH}""); set(ENV{ROOTSYS} ${CMAKE_BINARY_DIR}); endif(). set(ROOTSYS ${CMAKE_BINARY_DIR});",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt:1931,install,installed,1931,CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt,2,['install'],"['install', 'installed']"
Deployability,"(accessed through the macro ; LIBKERN_RETURNS_RETAINED) plays a role identical to ns_returns_retained for functions; returning OSObject subclasses.; The attribute indicates that it is a callers responsibility to release the; returned object. Attribute 'os_returns_not_retained'; The os_returns_not_retained attribute (accessed through the macro ; LIBKERN_RETURNS_NOT_RETAINED) plays a role identical to ns_returns_not_retained for functions; returning OSObject subclasses.; The attribute indicates that the caller should not change the retain; count of the returned object. Example. class MyClass {; OSObject *f;; LIBKERN_RETURNS_NOT_RETAINED OSObject *myFieldGetter();; }. // Note that the annotation only has to be applied to the function declaration.; OSObject * MyClass::myFieldGetter() {; return f;; }. Attribute 'os_consumed'; Similarly to ns_consumed attribute,; os_consumed (accessed through LIBKERN_CONSUMED) attribute,; applied to a parameter,; indicates that the call to the function consumes the parameter:; the callee should either release it or store it and release it in the destructor,; while the caller should assume one is subtracted from the reference count; after the call. IOReturn addToList(LIBKERN_CONSUMED IOPMinformee *newInformee);. Attribute 'os_consumes_this'; Similarly to ns_consumes_self,; the os_consumes_self attribute indicates that the method call; consumes the implicit this argument: the caller; should assume one was subtracted from the reference count of the object; after the call, and the callee has on obligation to either; release the argument, or store it and eventually release it in the; destructor. void addThisToList(OSArray *givenList) LIBKERN_CONSUMES_THIS;. Out Parameters. A function can also return an object to a caller by a means of an out parameter; (a pointer-to-OSObject-pointer is passed, and a callee writes a pointer to an; object into an argument).; Currently the analyzer does not track unannotated out; parameters by default, but with a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html:16575,release,release,16575,interpreter/llvm-project/clang/www/analyzer/annotations.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html,2,['release'],['release']
Deployability,"(both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for the ``CPyCppyy`` and ``cppyy`` packages, to allow; the C++ standard chosen to match the local compiler. pip with conda; --------------. Although installing ``cppyy`` through `conda-forge`_ is recommended, it is; possible to build/install with ``pip`` under Anaconda/miniconda. Typical Python extensions only expose a C interface for use through the; Python C-API, requiring only calling conventions (and the Python C-API; version, of course) to match to be binary compatible.; Here, cppyy differs because it exposes C++ APIs: it thus requires a C++; run-time that is ABI compatible with the C++ compiler that was used during; build-time. A set of modern compilers is available through conda-forge, but are only; intended for use with ``conda-build``.; In particular, the corresponding run-time is installed (for use through rpath; when building), but not set up.; That is, the conda compilers are added to ``PATH`` but not their libraries; to ``LD_LIBRARY_PATH`` (Mac, Linux; ``PATH`` for both on MS Windows).; Thus, you get the conda compilers and your system libraries mixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PREFIX/lib``.; Note that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been modified, which can can lead to parsing problems if; your system C library does not support C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:3773,install,installed,3773,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,1,['install'],['installed']
Deployability,"(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }; ~~~. Validation code `$ROOTSYS/test/vmatrix.cxx` and `vvector.cxx` contain; a few more examples of that kind. #### 6. Lazy matrices:. instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; ~~~. THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. ### Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:19379,install,installation,19379,math/matrix/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md,2,['install'],['installation']
Deployability,"(int sz) {; ... int* iptr = (int*)malloc(sizeof(int)*sz);; ... for (int i=0; i<sz; ++i) iptr[i] = i;; ... return iptr;; ... }""""""); ...; >>> NDATA = 4; >>> d = cppyy.gbl.get_data(NDATA); >>> print(d); <cppyy.LowLevelView object at 0x1068cba30>; >>> d = cppyy.ll.cast['int*'](d); >>> d.reshape((NDATA,)); >>> print(list(d)); [0, 1, 2, 3]; >>>. * **C++-style casts**: Similar to the C-style cast, there are; ``ll.static_cast`` and ``ll.reinterpret_cast``.; There should never be a reason for a ``dynamic_cast``, since that only; applies to objects, for which auto-casting will work.; The syntax is ""template-style"", just like for the C-style cast above. .. _npcasts:. `NumPy casts`; -------------. The ``cppyy.LowLevelView`` type returned for pointers to basic types,; including for ``void*``, is a simple and light-weight view on memory, given a; pointer, type, and number of elements (or unchecked, if unknown).; It only supports basic operations such as indexing and iterations, but also; the buffer protocol for integration with full-fledged functional arrays such; as NumPy`s ``ndarray``. In addition, specifically when dealing with ``void*`` returns, you can use; NumPy's low-level ``frombuffer`` interface to perform the cast.; Example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... void* create_float_array(int sz) {; ... float* pf = (float*)malloc(sizeof(float)*sz);; ... for (int i = 0; i < sz; ++i) pf[i] = 2*i;; ... return pf;; ... }""""""); ...; >>> import numpy as np; >>> NDATA = 8; >>> arr = cppyy.gbl.create_float_array(NDATA); >>> print(arr); <cppyy.LowLevelView object at 0x109f15230>; >>> arr.reshape((NDATA,)) # adjust the llv's size; >>> v = np.frombuffer(arr, dtype=np.float32, count=NDATA) # cast to float; >>> print(len(v)); 8; >>> print(v); array([ 0., 2., 4., 6., 8., 10., 12., 14.], dtype=float32); >>>. Note that NumPy will internally check the total buffer size, so if the size; you are casting *to* is larger than the size you are casting *from*, then; the number of ele",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:4815,integrat,integration,4815,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,1,['integrat'],['integration']
Deployability,"(normally ~10000 nodes and ~200000 elementary faces are shown); - all - try to display all geometry volumes (may lead to browser hanging); - maxnodesN - configure maximal number of rendered nodes (like maxnodes100K); - maxfacesN - configure maximal number of rendered faces (like maxfaces3M); - highlight - force highlighting of selected volume, normally activated for moderate-size geometries; - nohighlight - disable volumes highlighting (can be activated via context menu); - hscene - enable highlight of extra objects like tracks or hits; - hsceneonly - enable only highlight of extra objects like tracks or hits; - nohscene - disable highlight of extra objects like tracks or hits; - macro:name.C - invoke ROOT configuration macro; - dflt - set default volumes colors as TGeoManager::DefaultColors() does; - transpXY - set global transparency value (XY is number between 1 and 99); - zoomFACTOR - set initial zoom factor (FACTOR is integer value from 1 to 10000, default is 100); - rotyANGLE - set Y rotation angle in degrees (like roty10); - rotzANGLE - set Z rotation angle in degrees (like rotz20); - rotate - enable automatic rotation of the geometry; - trzVALUE - set transformation along Z axis (like trz50); - trrVALUE - set radial transformation (like trr100); - ortho_camera - use THREE.OrthographicCamera without possibility to rotate it; - ortho_camera_rotate - use THREE.OrthographicCamera and enable it rotation; - ctrl - show control UI from the beginning; - tracks - show tracks from TGeoManager; - showtop - show top-level volume of TGeoManager (default off); - no_screen - let ignore kVisOnScreen bits for nodes visibility; - dray - calculate rendering order using raytracing (extensive calculations); - dbox - use distance to nearest point from bounding box for rendering order (default); - dpnt - use distance to shape center as rendering order; - dsize - use volume size as rendering order; - ddflt - let three.js to calculate rendering order; - comp - show left and right com",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:20903,configurat,configuration,20903,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['configurat'],['configuration']
Deployability,"(tutorials). get_property(__allHeaders GLOBAL PROPERTY ROOT_HEADER_TARGETS); get_property(__allBuiltins GLOBAL PROPERTY ROOT_BUILTIN_TARGETS); add_custom_target(move_headers ALL DEPENDS ${__allHeaders} ${__allBuiltins} gitinfotxt). #---CXX MODULES-----------------------------------------------------------------------------------; if(MSVC); set(_os_cat ""type""); else(); set(_os_cat ""cat""); endif(); file(TO_NATIVE_PATH ""${CMAKE_BINARY_DIR}/include/module.modulemap.extra"" _from_native); file(TO_NATIVE_PATH ""${CMAKE_BINARY_DIR}/include/ROOT.modulemap"" _to_native). add_custom_target(copymodulemap DEPENDS ""${CMAKE_BINARY_DIR}/include/ROOT.modulemap""); add_custom_command(; 		 OUTPUT ""${CMAKE_BINARY_DIR}/include/ROOT.modulemap""; DEPENDS cmake/unix/module.modulemap ""${CMAKE_BINARY_DIR}/include/module.modulemap.extra""; 		 COMMAND ${CMAKE_COMMAND} -E copy ""${CMAKE_SOURCE_DIR}/cmake/unix/module.modulemap"" ""${CMAKE_BINARY_DIR}/include/ROOT.modulemap""; COMMAND ${_os_cat} ""${_from_native}"" >> ""${_to_native}""; ); install(FILES ""${CMAKE_BINARY_DIR}/include/ROOT.modulemap"" DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT headers). add_dependencies(move_headers copymodulemap). # Take all the modulemap contents we collected from the packages and append them to our modulemap.; # We have to delay this because the ROOT_CXXMODULES_EXTRA_MODULEMAP_CONTENT is filled in the; # add_subdirectory calls above.; get_property(__modulemap_extra_content GLOBAL PROPERTY ROOT_CXXMODULES_EXTRA_MODULEMAP_CONTENT); string(REPLACE "";"" """" __modulemap_extra_content ""${__modulemap_extra_content}""); # Write module.modulemap.extra to a temporary file first, to not touch module.modulemap.extra; # if it's unchanged.; file(WRITE ""${CMAKE_BINARY_DIR}/include/module.modulemap.extra.tmp"" ""${__modulemap_extra_content}""); configure_file(""${CMAKE_BINARY_DIR}/include/module.modulemap.extra.tmp""; ""${CMAKE_BINARY_DIR}/include/module.modulemap.extra""; COPYONLY). # From now on we handled all exposed module and want to make a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt:17636,install,install,17636,CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt,1,['install'],['install']
Deployability,"(using Minuit2), one should create a `RooMinimizer` using a new constructor with a `RooAbsL` likelihood parameter as follows:. ```c++; using RooFit::TestStatistics::RooAbsL;; using RooFit::TestStatistics::buildLikelihood;. RooAbsPdf* pdf = ...; // build a pdf; RooAbsData* data = ...; // get some data. std::shared_ptr<RooAbsL> likelihood = buildLikelihood(pdf, data, [OPTIONAL ARGUMENTS]);. RooMinimizer m(likelihood);; m.migrad();; ```. The `RooMinimizer` object behaves as usual, except that behind the scenes it will now calculate each partial derivative on a separate process, ideally running on a separate CPU core.; This can be used to speed up fits with many parameters (at least as many as there are cores to parallelize over), since every parameter corresponds to a partial derivative.; The resulting fit parameters will be identical to those obtained with the non-parallelized gradients minimizer in most cases (see the usage notes linked below for exceptions). In upcoming releases, further developments are planned:. - Benchmark/profile and optimize performance further; - Add a `RooAbsPdf::fitTo` interface around these new classes; - Achieve feature parity with existing `RooNLLVar` functionality, e.g. ranges are not yet supported. For more details, consult the usage notes in the [TestStatistics README.md](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/TestStatistics/README.md).; For benchmarking results on the prototype version of the parallelized gradient calculator, see the corresponding [CHEP19 proceedings paper](https://doi.org/10.1051/epjconf/202024506027). ### New pythonizations. Various new pythonizations are introduced to streamline your RooFit code in Python. For a complete list of all pythonized classes and functions, please see the [RooFit pythonizations page in the reference guide](https://root.cern/doc/v626/group__RoofitPythonizations.html).; All RooFit Python tutorials have been updated to profit from all available pythonizations. S",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:18157,release,releases,18157,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['release'],['releases']
Deployability,") ; cms4.root N 1.47 Gb 10.18s +/- 0.19 (2500 entries) ; cms4.root Y 1.43 Gb 9.24s +/- 0.06 (2500 entries) . Non Split files. FilenameMemberwiseSizeCpu Time To read. cms2.root N 1.65 Gb 10.95s +/- 0.05 (1000 entries) ; cms2.root Y 1.53 Gb 8.20s +/- 0.05 (1000 entries) ; cms3.root N 0.780 Gb 10.59s +/- 0.05 (700 entries) ; cms3.root Y 0.717 Gb 8.29s +/- 0.08 (700 entries) ; cms5.root N 1.55 Gb 10.20s +/- 0.17 (700 entries) ; cms5.root Y 1.40 Gb 8.09s +/- 0.08 (700 entries) . In the case of a data member which is a pointer to a STL container, eg:; std::container<Data> *fDataObjects;; and which is stored member-wise, add support for the schema evolution of the class 'Data'. This requires a change in the on file format used to store this type; of data members (i.e. by adding inline the version number of the class; 'Data'). To read file containing this construct and written with this revision; using an older version of ROOT you will need the following patches:; For v5.22/00, you will need the patch r33174; or v5.22/00k; For v5.26/00, you will need patch r33176; or v5.26/00c. Additionally, we no longer allow the member wise streaming of a class which; has a custom streamer nor of any data members marked with //||. Run time performance. We introduced an optimized infrastructure for reading objects using a StreamerInfo. Rather than driving the streaming using a switch statement inside TStreamerInfo::ReadBuffer,; the streaming is now driven using a simple loop over a sequence of configured StreamerInfo actions. This improves run-time performance by allowing a dramatic reduction in function calls and code; branches at the expense of some code duplication. There are 3 versions of this loop implemented in TBufferFile and overloaded in TBufferXML and TBufferSQL:. virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence, void *object);; virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence,; void *start_collection, void *end_colle",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html:2591,patch,patch,2591,io/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html,1,['patch'],['patch']
Deployability,") can be used to provide rule; based improvements in a way similar to the use of directives in an; intermediate language. On a practical note, it's often said that an automatic binder can provide; bindings to 95% of your code out-of-the-box, with only the remaining part; needing manual intervention.; This is broadly true, but realize that that 5% contains the most difficult; cases and is where 20-30% of the effort would have gone in case the bindings; were done fully manually.; It is therefore important to consider what manual tools an automatic binder; offers and to make sure they fit your work style and needs, because you are; going to spend a significant amount of time with them. `LLVM dependency`; -----------------. cppyy depends on `LLVM`_, through Cling.; LLVM is properly internalized, so that it doesn't conflict with other uses;; and in particular it is fine to mix `Numba`_ and cppyy code.; It does mean a download cost of about 20MB for the binary wheel (exact size; differs per platform) on installation, and additional `primarily initial`; memory overheads at run-time.; Whether this is onerous depends strongly not only on the application, but; also on the rest of the software stack. The initial cost of loading cppyy, and thus starting the Cling interpreter,; is about 45MB (platform dependent).; Initial uses of standard (e.g. STL) C++ results in deserialization of the; precompiled header at another eventual total cost of about 25MB (again,; platform dependent).; The actual bindings of course also carry overheads.; As a rule of thumb, you should budget for ~100MB all-in for the overhead; caused by the bindings. Other binders do not have this initial memory overhead, but do of course; occur an overhead per module, class, function, etc.; At scale, however, cppyy has some advantages: all binding is lazy (including; the option of automatic loading), standard classes are never duplicated, and; there is no additional ""per-module"" overhead.; Thus, eventually (depending",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:8155,install,installation,8155,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,1,['install'],['installation']
Deployability,") const override {; return ""Finds and renames symbols in code with no indexer support"";; }. RefactoringActionRules createActionRules() const override {; ...; }; };. Refactoring Action Rules; ------------------------. An individual refactoring action is responsible for creating the set of; grouped refactoring action rules that represent one refactoring operation.; Although the rules in one action may have a number of different implementations,; they should strive to produce a similar result. It should be easy for users to; identify which refactoring action produced the result regardless of which; refactoring action rule was used. The distinction between actions and rules enables the creation of actions; that define a set of different rules that produce similar results. For example,; the ""add missing switch cases"" refactoring operation typically adds missing; cases to one switch at a time. However, it could be useful to have a; refactoring that works on all switches that operate on a particular enum, as; one could then automatically update all of them after adding a new enum; constant. To achieve that, we can create two different rules that will use one; ``clang-refactor`` subcommand. The first rule will describe a local operation; that's initiated when the user selects a single switch. The second rule will; describe a global operation that works across translation units and is initiated; when the user provides the name of the enum to clang-refactor (or the user could; select the enum declaration instead). The clang-refactor tool will then analyze; the selection and other options passed to the refactoring action, and will pick; the most appropriate rule for the given selection and other options. Rule Types; ^^^^^^^^^^. Clang's refactoring engine supports several different refactoring rules:. - ``SourceChangeRefactoringRule`` produces source replacements that are applied; to the source files. Subclasses that choose to implement this rule have to; implement the ``create",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/RefactoringEngine.rst:2966,update,update,2966,interpreter/llvm-project/clang/docs/RefactoringEngine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/RefactoringEngine.rst,1,['update'],['update']
Deployability,") looking for tests. When :program:`lit`; enters a sub-directory, it first checks to see if a nested test suite is; defined in that directory. If so, it loads that test suite recursively,; otherwise it instantiates a local test config for the directory (see; :ref:`local-configuration-files`). Tests are identified by the test suite they are contained within, and the; relative path inside that suite. Note that the relative path may not refer to; an actual file on disk; some test formats (such as *GoogleTest*) define; ""virtual tests"" which have a path that contains both the path to the actual; test file and a subpath to identify the virtual test. .. _local-configuration-files:. LOCAL CONFIGURATION FILES; ~~~~~~~~~~~~~~~~~~~~~~~~~. When :program:`lit` loads a subdirectory in a test suite, it instantiates a; local test configuration by cloning the configuration for the parent directory; --- the root of this configuration chain will always be a test suite. Once the; test configuration is cloned :program:`lit` checks for a *lit.local.cfg* file; in the subdirectory. If present, this file will be loaded and can be used to; specialize the configuration for each individual directory. This facility can; be used to define subdirectories of optional tests, or to change other; configuration parameters --- for example, to change the test format, or the; suffixes which identify test files. SUBSTITUTIONS; ~~~~~~~~~~~~~. :program:`lit` allows patterns to be substituted inside RUN commands. It also; provides the following base set of substitutions, which are defined in; TestRunner.py:. ======================= ==============; Macro Substitution; ======================= ==============; %s source path (path to the file currently being run); %S source dir (directory of the file currently being run); %p same as %S; %{pathsep} path separator; %{fs-src-root} root component of file system paths pointing to the LLVM checkout; %{fs-tmp-root} root component of file system paths pointing to the tes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:18517,configurat,configuration,18517,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['configurat'],['configuration']
Deployability,") or a publicly available simulator/hardware; (either free or cheap enough) - preferably both. This allows; developers to validate assumptions, understand constraints and review code; that can affect the target. In addition, the rules for a back-end to be promoted to **official** are:. * The target must have addressed every other minimum requirement and; have been stable in tree for at least 3 months. This cool down; period is to make sure that the back-end and the target community can; endure continuous upstream development for the foreseeable future. * The target's code must have been completely adapted to this policy; as well as the :doc:`coding standards<CodingStandards>`. Any exceptions that; were made to move into experimental mode must have been fixed **before**; becoming official. * The test coverage needs to be broad and well written (small tests,; well documented). The build target ``check-all`` must pass with the; new target built, and where applicable, the ``test-suite`` must also; pass without errors, in at least one configuration (publicly; demonstrated, for example, via buildbots). * Public buildbots need to be created and actively maintained, unless; the target requires no additional buildbots (ex. ``check-all`` covers; all tests). The more relevant and public the new target's CI infrastructure; is, the more the LLVM community will embrace it. To **continue** as a supported and official target:. * The maintainer(s) must continue following these rules throughout the lifetime; of the target. Continuous violations of aforementioned rules and policies; could lead to complete removal of the target from the code base. * Degradation in support, documentation or test coverage will make the target as; nuisance to other targets and be considered a candidate for deprecation and; ultimately removed. In essence, these rules are necessary for targets to gain and retain their; status, but also markers to define bit-rot, and will be used to clean up the; tree from u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:41999,configurat,configuration,41999,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['configurat'],['configuration']
Deployability,") to find what's new. ### Binaries; Our nightly binary snapshots are currently unavailable. ### Building from Source. ```bash; git clone https://github.com/root-project/llvm-project.git; cd llvm-project; git checkout cling-latest; cd ..; git clone https://github.com/root-project/cling.git; mkdir cling-build && cd cling-build; cmake -DLLVM_EXTERNAL_PROJECTS=cling -DLLVM_EXTERNAL_CLING_SOURCE_DIR=../cling/ -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_TARGETS_TO_BUILD=""host;NVPTX"" -DCMAKE_BUILD_TYPE=Release ../llvm-project/llvm; cmake --build . --target cling; ```. See also the instructions [on the webpage](https://root.cern/cling/cling_build_instructions/). Usage; -----; Assuming we're in the build folder:; ```bash; ./bin/cling '#include <stdio.h>' 'printf(""Hello World!\n"")'; ```. To get started run:; ```bash; ./bin/cling --help; ```; or; ```bash; ./bin/cling; [cling]$ .help; ```. Jupyter; -------; Cling comes with a [Jupyter](http://jupyter.org) kernel. After building cling,; install Jupyter and cling's kernel by following the README.md in; [tools/Jupyter](tools/Jupyter). Make sure cling is in your PATH when you start jupyter!. Citing Cling; ------------; ```latex; % Peer-Reviewed Publication; %; % 19th International Conference on Computing in High Energy and Nuclear Physics (CHEP); % 21-25 May, 2012, New York, USA; %; @inproceedings{Cling,; author = {Vassilev,V. and Canal,Ph. and Naumann,A. and Moneta,L. and Russo,P.},; title = {{Cling} -- The New Interactive Interpreter for {ROOT} 6}},; journal = {Journal of Physics: Conference Series},; year = 2012,; month = {dec},; volume = {396},; number = {5},; pages = {052071},; doi = {10.1088/1742-6596/396/5/052071},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/396/5/052071/pdf},; publisher = {{IOP} Publishing}; }; ```. Developers' Corner; ==================; [Cling's latest doxygen documentation](http://cling.web.cern.ch/cling/doxygen/). Contributions; -------------; Every contribution is considered a donation and it",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md:2310,install,install,2310,interpreter/cling/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md,1,['install'],['install']
Deployability,")(const double * x, const double * p) is now const. This change makes the caching of parameter not hidden and the interface is now; thread-safe. ; A similar change in the ROOT::Math::IParamGradFunction, ROOT::Math::IParamMultiGradFunction interfaces, where the parameter values are now required for calculating the partial derivatives with respect to the parameters.; This changes the signature of the pure abstract method, DoParameterDerivative(const double *x, const double * p, , which takes also a pointer (type const double *) to the parameters.; In addition, these classes do not inherit anymore from the function gradient interface (ROOT::Math::IGradFunction and ROOT::Math::IMultiGradFunction). They define only the parameter gradient which is needed for fitting and not the coordinate gradient. A derived class, like ROOT::Math::Polynomial, implementing both functionality (coordinate and parameter gradient) inherits then from both interfaces.; . More detailed description of the current MathCore release can be found at this location. MathMore; This new release contains:. Modify and rename the class ROOT::Math::RootFinder to ROOT::Math::GSLRootFinder to distinguish from the main interface class which has been put in the Mathcore library and it can create the GSLRootFinder using the plug-in manager. Furthermore, the class ROOT::Math::GSLRootFinder is not anymore a template class on the algorithm. They type of root-finder algorithm can now be selected via an enumeration; Fixed a bug in the ROOT::Math::GSLNLSMultiFi class.; Changes also in the class for the new enumeration names (all names start with k, like kADAPTIVE for the integration types).; . More detailed description of the current MathMore release can be found at this location. GenVector; The new physics vector classes have been moved out from the MathCore library in a new library, libGenVector. The library contains as well the CINT dictionary including main instantiations for the template classes. For this release t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v520/index.html:10241,release,release,10241,math/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v520/index.html,1,['release'],['release']
Deployability,"),; when the browser blocks requests to files from domains other than current web page.; To enable CORS on Apache web server, hosting ROOT files, one should add following lines to `.htaccess` file:. <IfModule mod_headers.c>; <FilesMatch ""\.root"">; Header set Access-Control-Allow-Origin ""*""; Header set Access-Control-Allow-Headers ""range""; Header set Access-Control-Expose-Headers ""content-range,content-length,accept-ranges""; Header set Access-Control-Allow-Methods ""GET""; </FilesMatch>; </IfModule>. More details about configuring of CORS headers can be found [here](https://developer.mozilla.org/en/http_access_control). Alternative - enable CORS requests in the browser. It can be easily done with [CORS Everywhere plugin](https://addons.mozilla.org/de/firefox/addon/cors-everywhere/) for the Firefox browser or [Allow CORS plugin](https://chrome.google.com/webstore/detail/allow-control-allow-origi/nlfbmbojpeacfghkpbjhddihlkkiljbi?hl=en) for the Chrome browser. Next solution - install JSROOT on the server hosting ROOT files. In such configuration JSROOT does not issue CORS requests, therefore server and browsers can be used with their default settings. A simplified variant of such solution - copy only the top index.htm file from JSROOT package and specify the full path to `modules/gui.mjs` script like:. ```javascript; <script type=""module"">; import { openFile, draw } from 'https://root.cern/js/latest/modules/gui.mjs';; // ...; </script>; ```. In the main `<div>` element one can specify many custom parameters like one do it in URL string:. ```html; <div id=""simpleGUI"" path=""files/path"" files=""userfile1.root;subdir/usefile2.root"">; loading scripts ...; </div>; ```. ## Reading local ROOT files. JSROOT can read files from local file system using HTML5 FileReader functionality.; Main limitation here - user should interactively select files for reading.; There is button __""...""__ on the main JSROOT page, which starts file selection dialog.; If valid ROOT file is selected, JSROOT ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:28676,install,install,28676,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['install'],['install']
Deployability,"). This; is another mechanism by which we can give pre-release notice to users about; potentially disruptive changes. It is a lower-traffic alternative to the; joining ""vendors"" group. To automatically be notified of new announcements; with the ``potentially-breaking`` label, go to your user preferences page in; Discourse, and add the label to one of the watch categories under; ``Notifications->Tags``. .. _code owners:. Code Owners; -----------. The LLVM Project relies on two features of its process to maintain rapid; development in addition to the high quality of its source base: the combination; of code review plus post-commit review for trusted maintainers. Having both is; a great way for the project to take advantage of the fact that most people do; the right thing most of the time, and only commit patches without pre-commit; review when they are confident they are right. The trick to this is that the project has to guarantee that all patches that are; committed are reviewed after they go in: you don't want everyone to assume; someone else will review it, allowing the patch to go unreviewed. To solve this; problem, we have a notion of an 'owner' for a piece of the code. The sole; responsibility of a code owner is to ensure that a commit to their area of the; code is appropriately reviewed, either by themself or by someone else. The list; of current code owners can be found in the file `CODE_OWNERS.TXT; <https://github.com/llvm/llvm-project/blob/main/llvm/CODE_OWNERS.TXT>`_ in the; root of the LLVM source tree. Note that code ownership is completely different than reviewers: anyone can; review a piece of code, and we welcome code review from anyone who is; interested. Code owners are the ""last line of defense"" to guarantee that all; patches that are committed are actually reviewed. Being a code owner is a somewhat unglamorous position, but it is incredibly; important for the ongoing success of the project. Because people get busy,; interests change, and unexpecte",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:8218,patch,patches,8218,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,2,['patch'],"['patch', 'patches']"
Deployability,"). To compile with cmake added into ~/.profile. ~~~{.sh}; export PATH=$PATH:/Applications/CMake.app/Contents/bin/; ~~~; and. ~~~{.sh}; source ~/.profile; ~~~. Install needed R packages, open R and in the prompt type. ~~~{.sh}; install.packages(c('Rcpp','RInside')); ~~~; select a mirror and install. Install the next additional packages for R TMVA interface. ~~~{.sh}; install.packages(c('C50','RSNNS','e1071','xgboost')); ~~~. Download code from git repo. ~~~{.sh}; git clone http://root.cern.ch/git/root.git; ~~~. To compile ROOTR lets to create a compilation directory and to activate it use cmake -Dr=ON .. ~~~{.sh}; mkdir compile; cd compile; cmake -Dr=ON ..; make -j 5; ~~~. ### Compiling ROOTR on Gnu/Linux with CMake:; **NOTE:** Tested on Gnu/Linux Debian Jessie with gcc 4.9. **Prerequisities**; install; (For debian-based distros). ~~~{.sh}; apt-get install r-base r-base-dev; ~~~; Install needed R packages, open R and in the prompt type. ~~~{.sh}; install.packages(c('Rcpp','RInside')); ~~~; select a mirror and install. Install the next additional packages for R TMVA interface. ~~~{.sh}; install.packages(c('C50','RSNNS','e1071','xgboost')); ~~~. Download code from git repo. ~~~{.sh}; git clone http://root.cern.ch/git/root.git; ~~~. To compile ROOTR lets to create a compilation directory and to activate it use cmake -Dr=ON .. ~~~{.sh}; mkdir compile; cd compile; cmake -Dr=ON ..; make -j 5; ~~~. ## How does it work ?; There is a class called TRInterface which is located at the header TRInterface.h and uses the namespace `ROOT::R`, it is in charge; of making calls to R to give and obtain data. This class has a series of overcharged operators which ease the passing and obtaining of data; and code from R to C++ and vice versa. To create an object of this class the user must use the static methods `ROOT::R::TRInterface::Instance`; and `ROOT::R::TRInterface::InstancePtr` which return a reference object and a pointer object respectively. ~~~{.cxx}; #include<TRInterface.h>; ROO",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:2694,install,install,2694,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['install'],['install']
Deployability,). install(; FILES ${aarch64_only_files} ${aarch64_only_generated_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT aarch64-resource-headers). install(; FILES ${cuda_wrapper_files}; DESTINATION ${header_install_dir}/cuda_wrappers; EXCLUDE_FROM_ALL; COMPONENT cuda-resource-headers). install(; FILES ${cuda_wrapper_bits_files}; DESTINATION ${header_install_dir}/cuda_wrappers/bits; EXCLUDE_FROM_ALL; COMPONENT cuda-resource-headers). install(; FILES ${cuda_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT cuda-resource-headers). install(; FILES ${hexagon_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT hexagon-resource-headers). install(; FILES ${hip_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT hip-resource-headers). install(; FILES ${loongarch_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT loongarch-resource-headers). install(; FILES ${mips_msa_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT mips-resource-headers). install(; FILES ${ppc_wrapper_files}; DESTINATION ${header_install_dir}/ppc_wrappers; EXCLUDE_FROM_ALL; COMPONENT ppc-resource-headers). install(; FILES ${ppc_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT ppc-resource-headers). install(; FILES ${ppc_htm_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT ppc-htm-resource-headers). install(; FILES ${riscv_generated_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT riscv-resource-headers). install(; FILES ${riscv_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT riscv-resource-headers). install(; FILES ${systemz_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT systemz-resource-headers). install(; FILES ${ve_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT ve-resource-headers). install(; FILES ${webassembly_files}; DESTINATION ${header_install_dir}; ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt:14319,install,install,14319,interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,1,['install'],['install']
Deployability,"):. ::. arc patch D<Revision>. This will create a new branch called ``arcpatch-D<Revision>`` based on the; current ``main`` and will create a commit corresponding to ``D<Revision>`` with a; commit message derived from information in the Phabricator review. Check you are happy with the commit message and amend it if necessary.; For example, ensure the 'Author' property of the commit is set to the original author.; You can use a command to correct the author property if it is incorrect:. ::. git commit --amend --author=""John Doe <jdoe@llvm.org>"". Then, make sure the commit is up-to-date, and commit it. This can be done by running; the following:. ::. git pull --rebase https://github.com/llvm/llvm-project.git main; git show # Ensure the patch looks correct.; ninja check-$whatever # Rerun the appropriate tests if needed.; git push https://github.com/llvm/llvm-project.git HEAD:main. Abandoning a change; -------------------. If you decide you should not commit the patch, you should explicitly abandon; the review so that reviewers don't think it is still open. In the web UI,; scroll to the bottom of the page where normally you would enter an overall; comment. In the drop-down Action list, which defaults to ""Comment,"" you should; select ""Abandon Revision"" and then enter a comment explaining why. Click the; Submit button to finish closing the review. Status; ------. Please let us know whether you like it and what could be improved! We're still; working on setting up a bug tracker, but you can email klimek-at-google-dot-com; and chandlerc-at-gmail-dot-com and CC the llvm-dev mailing list with questions; until then. We also could use help implementing improvements. This sadly is; really painful and hard because the Phabricator codebase is in PHP and not as; testable as you might like. However, we've put exactly what we're deploying up; on an `llvm-reviews GitHub project`_ where folks can hack on it and post pull; requests. We're looking into what the right long-term hosting for",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst:16150,patch,patch,16150,interpreter/llvm-project/llvm/docs/Phabricator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst,1,['patch'],['patch']
Deployability,"); list(APPEND CMAKE_MODULE_PATH ""${LLVM_CMAKE_PATH}""); include(${LLVMCONFIG_FILE}); else(); message(FATAL_ERROR ""Not found: ${LLVMCONFIG_FILE}""); endif(); # We already FORCE-d the CACHE value to OFF, but LLVMConfig.cmake might have; # set the variable to ON again...; set(LLVM_ENABLE_WARNINGS OFF). # They are used as destination of target generators.; # We try to keep these locations consistent with the builtin_llvm. This is important; # for the LLVMRES target.; # FIXME: In longer term, we do not really need this and may want to adjust LLVMRES.; set(LLVM_RUNTIME_OUTPUT_INTDIR ${CMAKE_CURRENT_BINARY_DIR}/llvm-project/llvm/${CMAKE_CFG_INTDIR}/bin); set(LLVM_LIBRARY_OUTPUT_INTDIR ${CMAKE_CURRENT_BINARY_DIR}/llvm-project/llvm/${CMAKE_CFG_INTDIR}/lib). if(WIN32 OR CYGWIN); # DLL platform -- put DLLs into bin.; set(LLVM_SHLIB_OUTPUT_INTDIR ${LLVM_RUNTIME_OUTPUT_INTDIR}); else(); set(LLVM_SHLIB_OUTPUT_INTDIR ${LLVM_LIBRARY_OUTPUT_INTDIR}); endif(). option(LLVM_INSTALL_TOOLCHAIN_ONLY; ""Only include toolchain files in the 'install' target."" OFF). option(LLVM_FORCE_USE_OLD_HOST_TOOLCHAIN; ""Set to ON to force using an old, unsupported host toolchain."" OFF); option(CLANG_ENABLE_BOOTSTRAP ""Generate the clang bootstrap target"" OFF). include(AddLLVM); include(TableGen); include(HandleLLVMOptions); include(VersionFromVCS). set(PACKAGE_VERSION ""${LLVM_PACKAGE_VERSION}""); if (${PACKAGE_VERSION} MATCHES ""${ROOT_LLVM_VERSION_REQUIRED_MAJOR}\\.1(|\\.[0-9]+)""); message(STATUS ""Using LLVM external library - ${PACKAGE_VERSION}""); else(); message(FATAL_ERROR ""LLVM version ${LLVM_PACKAGE_VERSION} different from ROOT supported, please try ${ROOT_LLVM_VERSION_REQUIRED_MAJOR}.1.x""); endif(). if (NOT DEFINED LLVM_INCLUDE_TESTS); set(LLVM_INCLUDE_TESTS ON); endif(). include_directories(""${LLVM_BINARY_DIR}/include"" ""${LLVM_MAIN_INCLUDE_DIR}""); link_directories(""${LLVM_LIBRARY_DIR}""). # set( CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin ); # set( CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINAR",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/CMakeLists.txt:15647,install,install,15647,interpreter/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/CMakeLists.txt,1,['install'],['install']
Deployability,");; h->SetDirectory(0);; h->FillRandom(""gaus"", 1000);; return h;; }. TProcPool pool;; auto hist = pool.MapReduce(CreateAndFillHists, 10, PoolUtils::ReduceObjects);; hist->DrawClone();; }; ```. Tutorials illustrating other usages of the new class TProcPool are available under tutorials/multicore. ## Language Bindings. ### Notebooks; We provided integration of ROOT with the Jupyter technology, integrating ROOT with Python Notebooks and providing a ROOT Kernel like functionality - de facto an enhanced C++ web based shell. Tab completion, output and graphics inlining have been added. These functionalities are automatically available upon import of the ROOT module in a Notebook or at startup of a ROOT prompt kernel.; We made it easier to use ROOT notebooks locally, by providing a 'root --notebook' command option to start a local notebook server customised with all the ROOT features. New tutorials and code examples have been provided. The simplest example showing the integration of ROOT with the notebook technology can be found [here](https://root.cern.ch/notebooks/HowTos/HowTo_ROOT-Notebooks.html) and many more snippets [here](https://root.cern.ch/code-examples#notebooks). Support for capturing large outputs (stderr/stdout) coming from C++ libraries has been added. ## JavaScript ROOT. - support registered in THttpServer commands with arguments.; - provide workaround for websites using require.js and older jquery-ui; - support custom requests to remote objects, demonstrated in httptextlog.C tutorial; - rewrite draw.htm (page for individual object drawing) to support all custom features as main gui does; - See also the [JSRoot 3.9 examples page](https://root.cern.ch/js/3.9/) and the [JSRoot 3.9 release notes](https://github.com/linev/jsroot/releases/tag/3.9). ## Class Reference Guide. The ROOT [reference guide](https://root.cern.ch/doc/master/index.html) is moving; to the Doxygen system. Doxygen is the de-facto standard for code documentation. It offers; many nice features",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:22724,integrat,integration,22724,README/ReleaseNotes/v606/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md,1,['integrat'],['integration']
Deployability,")draw tooltips on canvas with many subpads. ## Code Examples. - New graphics tutorial AtlasExample.C illustrating the ATLAS style.; - New TLazyDS tutorial added tdf015_LazyDataSource.C.; - Show how to inspect a `TCutFlowReport` object. ## Class Reference Guide. - Replace low resolution images with bigger ones more suited for modern screens. ## Build System and Configuration. - ROOT can now be built against an externally built llvm and clang (llvm can be used unpatched, clang still require ROOT specific patches). The options are builtin_llvm and builtin_clang both defaulting to ON.; - Update RConfigure.h with R__HAS__VDT if the package is found/builtin; - CMake exported targets now have the `INTERFACE_INCLUDE_DIRECTORIES` property set ([ROOT-8062](https://sft.its.cern.ch/jira/browse/ROOT-8062)).; - The `-fPIC` compile flag is no longer propagated to dependent projects via `CMAKE_CXX_FLAGS` ([ROOT-9212](https://sft.its.cern.ch/jira/browse/ROOT-9212)).; - Several builtins have updated versions:; - OpenSSL was updated from 1.0.2d to 1.0.2.o (latest lts release, [ROOT-9359](https://sft.its.cern.ch/jira/browse/ROOT-9359)); - Davix was updated from 0.6.4 to 0.6.7 (support for OpenSSL 1.1, [ROOT-9353](https://sft.its.cern.ch/jira/browse/ROOT-9353)); - Vdt has been updated from 0.3.9 to 0.4.1 (includes new atan function); - XRootd has been updated from 4.6.1 to 4.8.2 (for GCC 8.x support); - Builtin TBB can now be used on Windows; - xxHash and LZ4 have been separated so that a system version of LZ4 can be used even if it does not include xxHash headers ([ROOT-9099](https://sft.its.cern.ch/jira/browse/ROOT-9099)); - In addition, several updates have been made to fix minor build system issues, such as not checking for external packages if their builtin is turned off, or checking for packages even when the respective option is disabled ([ROOT-8806](https://sft.its.cern.ch/jira/browse/ROOT-8806), [ROOT-9190](https://sft.its.cern.ch/jira/browse/ROOT-9190), [ROOT-9315](https://sft",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:18267,update,updated,18267,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,2,['update'],['updated']
Deployability,"* (``Boolean``) :versionbadge:`clang-format 3.7` :ref:`¶ <SpacesInSquareBrackets>`; If ``true``, spaces will be inserted after ``[`` and before ``]``.; Lambdas without arguments or unspecified size array declarations will not; be affected. .. code-block:: c++. true: false:; int a[ 5 ]; vs. int a[5];; std::unique_ptr<int[]> foo() {} // Won't be affected. .. _Standard:. **Standard** (``LanguageStandard``) :versionbadge:`clang-format 3.7` :ref:`¶ <Standard>`; Parse and format C++ constructs compatible with this standard. .. code-block:: c++. c++03: latest:; vector<set<int> > x; vs. vector<set<int>> x;. Possible values:. * ``LS_Cpp03`` (in configuration: ``c++03``); Parse and format as C++03.; ``Cpp03`` is a deprecated alias for ``c++03``. * ``LS_Cpp11`` (in configuration: ``c++11``); Parse and format as C++11. * ``LS_Cpp14`` (in configuration: ``c++14``); Parse and format as C++14. * ``LS_Cpp17`` (in configuration: ``c++17``); Parse and format as C++17. * ``LS_Cpp20`` (in configuration: ``c++20``); Parse and format as C++20. * ``LS_Latest`` (in configuration: ``Latest``); Parse and format using the latest supported language version.; ``Cpp11`` is a deprecated alias for ``Latest``. * ``LS_Auto`` (in configuration: ``Auto``); Automatic detection based on the input. .. _StatementAttributeLikeMacros:. **StatementAttributeLikeMacros** (``List of Strings``) :versionbadge:`clang-format 12` :ref:`¶ <StatementAttributeLikeMacros>`; Macros which are ignored in front of a statement, as if they were an; attribute. So that they are not parsed as identifier, for example for Qts; emit. .. code-block:: c++. AlignConsecutiveDeclarations: true; StatementAttributeLikeMacros: []; unsigned char data = 'x';; emit signal(data); // This is parsed as variable declaration. AlignConsecutiveDeclarations: true; StatementAttributeLikeMacros: [emit]; unsigned char data = 'x';; emit signal(data); // Now it's fine again. .. _StatementMacros:. **StatementMacros** (``List of Strings``) :versionbadge:`cla",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:129487,configurat,configuration,129487,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"* [[#14211](https://github.com/root-project/root/issues/14211)] - Implement value printing for `std::source_location`; * [[#14205](https://github.com/root-project/root/issues/14205)] - [cling] Replace llvm::Optional and llvm::None with std::optional; * [[#14199](https://github.com/root-project/root/issues/14199)] - Memory hoarding triggered by the TPluginManager; * [[#14188](https://github.com/root-project/root/issues/14188)] - cmake find_package ROOT 6.30 broken: it requires nlohmann-json; * [[#14163](https://github.com/root-project/root/issues/14163)] - cmake find_package ROOT broken with 6.30, nlohmann and vdt are builtin but not found; * [[#14162](https://github.com/root-project/root/issues/14162)] - `RooFFTConvPdf` is not working for ROOT 6.30/02; * [[#14157](https://github.com/root-project/root/issues/14157)] - Minuit2 standalone build: StandAlone.cmake looks for the wrong path for VERSION_FILE; * [[#14113](https://github.com/root-project/root/issues/14113)] - The `find_package(root)` command fails when using Root installed via Homebrew.; * [[#14101](https://github.com/root-project/root/issues/14101)] - Missing documentation for `RDataSetSpec`; * [[#14097](https://github.com/root-project/root/issues/14097)] - Cleaner stack traces in python; * [[#14085](https://github.com/root-project/root/issues/14085)] - thisroot.sh does not recognize bash when running in qemu-x86_64; * [[#14084](https://github.com/root-project/root/issues/14084)] - [ntuple] `RRecordField` creation crashes when `TStreamerInfo` has insufficient information; * [[#14075](https://github.com/root-project/root/issues/14075)] - [FreeBSD] root.exe crash at end of compilation during modules.idx generation; * [[#14068](https://github.com/root-project/root/issues/14068)] - ROOT 6.30/00 reports `root-config --version` as 6.30.00; * [[#14064](https://github.com/root-project/root/issues/14064)] - Include Tex Gyre Heros in ROOT fonts; * [[#14032](https://github.com/root-project/root/issues/14032)] - `TPaveTe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:35620,install,installed,35620,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['install'],['installed']
Deployability,"* ``int8_t Hex`` Format separators in hexadecimal literals. .. code-block:: text. /* -1: */ h = 0xDEADBEEFDEADBEEFuz;; /* 0: */ h = 0xDEAD'BEEF'DE'AD'BEE'Fuz;; /* 2: */ h = 0xDE'AD'BE'EF'DE'AD'BE'EFuz;. * ``int8_t HexMinDigits`` Format separators in hexadecimal literals with a minimum number of; digits. .. code-block:: text. // Hex: 2; // HexMinDigits: 6; h1 = 0xABCDE;; h2 = 0xAB'CD'EF;. .. _JavaImportGroups:. **JavaImportGroups** (``List of Strings``) :versionbadge:`clang-format 8` :ref:`¶ <JavaImportGroups>`; A vector of prefixes ordered by the desired groups for Java imports. One group's prefix can be a subset of another - the longest prefix is; always matched. Within a group, the imports are ordered lexicographically.; Static imports are grouped separately and follow the same group rules.; By default, static imports are placed before non-static imports,; but this behavior is changed by another option,; ``SortJavaStaticImport``. In the .clang-format configuration file, this can be configured like; in the following yaml example. This will result in imports being; formatted as in the Java example below. .. code-block:: yaml. JavaImportGroups: ['com.example', 'com', 'org']. .. code-block:: java. import static com.example.function1;. import static com.test.function2;. import static org.example.function3;. import com.example.ClassA;; import com.example.Test;; import com.example.a.ClassB;. import com.test.ClassC;. import org.example.ClassD;. .. _JavaScriptQuotes:. **JavaScriptQuotes** (``JavaScriptQuoteStyle``) :versionbadge:`clang-format 3.9` :ref:`¶ <JavaScriptQuotes>`; The JavaScriptQuoteStyle to use for JavaScript strings. Possible values:. * ``JSQS_Leave`` (in configuration: ``Leave``); Leave string quotes as they are. .. code-block:: js. string1 = ""foo"";; string2 = 'bar';. * ``JSQS_Single`` (in configuration: ``Single``); Always use single quotes. .. code-block:: js. string1 = 'foo';; string2 = 'bar';. * ``JSQS_Double`` (in configuration: ``Double``); Always use ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:79925,configurat,configuration,79925,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"*. Apple Clang Builds (A More Complex Bootstrap); =============================================. Apple's Clang builds are a slightly more complicated example of the simple; bootstrapping scenario. Apple Clang is built using a 2-stage build. The stage1 compiler is a host-only compiler with some options set. The stage1; compiler is a balance of optimization vs build time because it is a throwaway.; The stage2 compiler is the fully optimized compiler intended to ship to users. Setting up these compilers requires a lot of options. To simplify the; configuration the Apple Clang build settings are contained in CMake Cache files.; You can build an Apple Clang compiler using the following commands:. .. code-block:: console. $ cmake -G Ninja -C <path to source>/clang/cmake/caches/Apple-stage1.cmake <path to source>/llvm; $ ninja stage2-distribution. This CMake invocation configures the stage1 host compiler, and sets; CLANG_BOOTSTRAP_CMAKE_ARGS to pass the Apple-stage2.cmake cache script to the; stage2 configuration step. When you build the stage2-distribution target it builds the minimal stage1; compiler and required tools, then configures and builds the stage2 compiler; based on the settings in Apple-stage2.cmake. This pattern of using cache scripts to set complex settings, and specifically to; make later stage builds include cache scripts is common in our more advanced; build configurations. Multi-stage PGO; ===============. Profile-Guided Optimizations (PGO) is a really great way to optimize the code; clang generates. Our multi-stage PGO builds are a workflow for generating PGO; profiles that can be used to optimize clang. At a high level, the way PGO works is that you build an instrumented compiler,; then you run the instrumented compiler against sample source files. While the; instrumented compiler runs it will output a bunch of files containing; performance counters (.profraw files). After generating all the profraw files; you use llvm-profdata to merge the files into a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst:4304,configurat,configuration,4304,interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,1,['configurat'],['configuration']
Deployability,"*; X.1.0-rc1 3 days after branch.; X.1.0-rc2 2 weeks after branch.; X.1.0-rc3 4 weeks after branch; **X.1.0-final** **6 weeks after branch**; **X.1.1** **8 weeks after branch**; **X.1.2** **10 weeks after branch**; **X.1.3** **12 weeks after branch**; **X.1.4** **14 weeks after branch**; **X.1.5** **16 weeks after branch**; **X.1.6 (if necessary)** **18 weeks after branch**; =============================== =========================. Release Process Summary; -----------------------. * Announce release schedule to the LLVM community and update the website. Do; this at least 3 weeks before the -rc1 release. * Create release branch and begin release process. * Send out release candidate sources for first round of testing. Testing lasts; 6 weeks. During the first round of testing, any regressions found should be; fixed. Patches are merged from mainline into the release branch. Also, all; features need to be completed during this time. Any features not completed at; the end of the first round of testing will be removed or disabled for the; release. * Generate and send out the second release candidate sources. Only *critical*; bugs found during this testing phase will be fixed. Any bugs introduced by; merged patches will be fixed. If so a third round of testing is needed. * The release notes are updated. * Finally, release!. * Announce bug fix release schedule to the LLVM community and update the website. * Do bug-fix releases every two weeks until X.1.5 or X.1.6 (if necessary). Release Process; ===============. .. contents::; :local:. Release Administrative Tasks; ----------------------------. This section describes a few administrative tasks that need to be done for the; release process to begin. Specifically, it involves:. * Updating version numbers,. * Creating the release branch, and. * Tagging release candidates for the release team to begin testing. Create Release Branch; ^^^^^^^^^^^^^^^^^^^^^. Branch the Git trunk using the following procedure:. #. Remind developers",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:2634,release,release,2634,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['release'],['release']
Deployability,"*CMAKE_{C,CXX}_FLAGS**:STRING; Extra flags to use when compiling C and C++ source files respectively. **CMAKE_{C,CXX}_COMPILER**:STRING; Specify the C and C++ compilers to use. If you have multiple; compilers installed, CMake might not default to the one you wish to; use. .. _Frequently Used LLVM-related variables:. Frequently Used LLVM-related variables; --------------------------------------. The default configuration may not match your requirements. Here are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. **LLVM_LIBDIR_SUFFIX**:STRING; Extra suffix to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These options, when you use the Ninja generator, allow you; to restrict the parallelism. For example, to avoid OOMs or going; into swap, permit only one link job per 15GB of RAM available on a; 32GB machine, specify ``-G Ninja -DLLVM_PARALLEL_LINK_JOBS=2``. **LLVM_TARGETS_TO_BUILD**:STRING; Control which targets are enabled. For example you may only need to enable; your native target with, for example, ``-DLLVM_TARGETS_TO_BUILD=X86``. .. _llvm_use_linker:. **LLVM_USE_LINKER**:STRING; Override the system's default linker. For instance use ``lld`` with; ``-DLLVM_USE_LINKER=lld``. Rarely-used CMake variables; ---------------------------. Here are some of the CMake variables that are rarely used, along wit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:9476,install,installed,9476,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['install'],['installed']
Deployability,"*X.1.3** **12 weeks after branch**; **X.1.4** **14 weeks after branch**; **X.1.5** **16 weeks after branch**; **X.1.6 (if necessary)** **18 weeks after branch**; =============================== =========================. Release Process Summary; -----------------------. * Announce release schedule to the LLVM community and update the website. Do; this at least 3 weeks before the -rc1 release. * Create release branch and begin release process. * Send out release candidate sources for first round of testing. Testing lasts; 6 weeks. During the first round of testing, any regressions found should be; fixed. Patches are merged from mainline into the release branch. Also, all; features need to be completed during this time. Any features not completed at; the end of the first round of testing will be removed or disabled for the; release. * Generate and send out the second release candidate sources. Only *critical*; bugs found during this testing phase will be fixed. Any bugs introduced by; merged patches will be fixed. If so a third round of testing is needed. * The release notes are updated. * Finally, release!. * Announce bug fix release schedule to the LLVM community and update the website. * Do bug-fix releases every two weeks until X.1.5 or X.1.6 (if necessary). Release Process; ===============. .. contents::; :local:. Release Administrative Tasks; ----------------------------. This section describes a few administrative tasks that need to be done for the; release process to begin. Specifically, it involves:. * Updating version numbers,. * Creating the release branch, and. * Tagging release candidates for the release team to begin testing. Create Release Branch; ^^^^^^^^^^^^^^^^^^^^^. Branch the Git trunk using the following procedure:. #. Remind developers that the release branching is imminent and to refrain from; committing patches that might break the build. E.g., new features, large; patches for works in progress, an overhaul of the type system, an exciting; new ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:2805,patch,patches,2805,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['patch'],['patches']
Deployability,"+ S->getKind() <= SK_OtherSpecialSquare;; + }. The reason that we need to test a range like this instead of just equality; is that both ``SpecialSquare`` and ``OtherSpecialSquare`` ""is-a""; ``Square``, and so ``classof`` needs to return ``true`` for them. This approach can be made to scale to arbitrarily deep hierarchies. The; trick is that you arrange the enum values so that they correspond to a; preorder traversal of the class hierarchy tree. With that arrangement, all; subclass tests can be done with two comparisons as shown above. If you just; list the class hierarchy like a list of bullet points, you'll get the; ordering right::. | Shape; | Square; | SpecialSquare; | OtherSpecialSquare; | Circle. A Bug to be Aware Of; --------------------. The example just given opens the door to bugs where the ``classof``\s are; not updated to match the ``Kind`` enum when adding (or removing) classes to; (from) the hierarchy. Continuing the example above, suppose we add a ``SomewhatSpecialSquare`` as; a subclass of ``Square``, and update the ``ShapeKind`` enum like so:. .. code-block:: c++. enum ShapeKind {; SK_Square,; SK_SpecialSquare,; SK_OtherSpecialSquare,; + SK_SomewhatSpecialSquare,; SK_Circle; }. Now, suppose that we forget to update ``Square::classof()``, so it still; looks like:. .. code-block:: c++. static bool classof(const Shape *S) {; // BUG: Returns false when S->getKind() == SK_SomewhatSpecialSquare,; // even though SomewhatSpecialSquare ""is a"" Square.; return S->getKind() >= SK_Square &&; S->getKind() <= SK_OtherSpecialSquare;; }. As the comment indicates, this code contains a bug. A straightforward and; non-clever way to avoid this is to introduce an explicit ``SK_LastSquare``; entry in the enum when adding the first subclass(es). For example, we could; rewrite the example at the beginning of `Concrete Bases and Deeper; Hierarchies`_ as:. .. code-block:: c++. enum ShapeKind {; SK_Square,; + SK_SpecialSquare,; + SK_OtherSpecialSquare,; + SK_LastSquare,; SK_Circl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst:9240,update,update,9240,interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst,1,['update'],['update']
Deployability,"+ h2); //where h1 = this; ```. - It works for `1D` , `2D` , etc. histograms. The parameter `c2` is; an optional argument that gives a relative weight between the two; histograms, and `dc` `2` is the error on this weight. This is; useful, for example, when forming an asymmetry between two; histograms from two different data sets that need to be normalized; to each other in some way. The function calculates the errors; assuming Poisson statistics on `h1` and `h2`; (that is, `dh=sqrt(h)`). In the next example we assume that `h1`; and `h2` are already filled:. ``` {.cpp}; h3 = h1->GetAsymmetry(h2);; ```. - Then `h3` is created and filled with the asymmetry between `h1`; and `h2` ; `h1` and `h2` are left intact. - Note that the user's responsibility is to manage the created; histograms. - **`TH1`**`::Reset()` - resets the bin contents and errors of a; histogram. ## Important note on returned statistics (`GetMean`, `GetStdDev`, etc.). By default, histogram statistics are computed at fill time using the; unbinned data used to update the bin content. **This means the values; returned by `GetMean`, `GetStdDev`, etc., are those of the dataset used; to fill the histogram**, not those of the binned content of the histogram; itself, **unless one of the axes has been zoomed**. (See the documentation; on `TH1::GetStats()`.) This is useful if you want to keep track of the; mean and standard deviation of the dataset you are visualizing with the histogram,; but it can lead to some unintuitive results. For example, suppose you have a histogram; with one bin between 0 and 100, then you fill it with a; Gaussian dataset with mean 20 and standard deviation 2:; ``` {.cpp}; TH1F * h = new TH1F(""h"", ""h"", 1, 0, 100);; for(int i=0; i<10000; i++) h->Fill(gRandom->Gaus(20, 2));; ```; Right now, `h->GetMean()` will return 20 and `h->GetStdDev()` will return 2;; ROOT calculated these values as we filled `h`.; Next, zoom in on the Gaussian:; ``` {.cpp}; h->GetXaxis()->SetRangeUser(10, 30);; ```; No",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Histograms.md:53137,update,update,53137,documentation/users-guide/Histograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Histograms.md,1,['update'],['update']
Deployability,"+ methods, Objective-C class methods, Objective-C; instance methods when ExprEngine is confident about the dynamic type of the; instance). * ``analyzer-config ipa=dynamic`` - Inline instance methods for which the type is; determined at runtime and we are not 100% sure that our type info is; correct. For virtual calls, inline the most plausible definition. * ``analyzer-config ipa=dynamic-bifurcate`` - Same as -analyzer-config ipa=dynamic,; but the path is split. We inline on one branch and do not inline on the; other. This mode does not drop the coverage in cases when the parent class; has code that is only exercised when some of its methods are overridden. Currently, ``-analyzer-config ipa=dynamic-bifurcate`` is the default mode. While ``-analyzer-config ipa`` determines in general how aggressively the analyzer; will try to inline functions, several additional options control which types of; functions can inlined, in an all-or-nothing way. These options use the; analyzer's configuration table, so they are all specified as follows:. ``-analyzer-config OPTION=VALUE``. c++-inlining; ------------. This option controls which C++ member functions may be inlined. ``-analyzer-config c++-inlining=[none | methods | constructors | destructors]``. Each of these modes implies that all the previous member function kinds will be; inlined as well; it doesn't make sense to inline destructors without inlining; constructors, for example. The default c++-inlining mode is 'destructors', meaning that all member; functions with visible definitions will be considered for inlining. In some; cases the analyzer may still choose not to inline the function. Note that under 'constructors', constructors for types with non-trivial; destructors will not be inlined. Additionally, no C++ member functions will be; inlined under -analyzer-config ipa=none or -analyzer-config ipa=basic-inlining,; regardless of the setting of the c++-inlining mode. c++-template-inlining; ^^^^^^^^^^^^^^^^^^^^^. This option",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst:1714,configurat,configuration,1714,interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,1,['configurat'],['configuration']
Deployability,"+ || |; Delta | | Data N | || |; | +---------------------+ || | CounterPtr1; | || |; | CounterPtr2 || |; | || |; | || |; + --> start(__llvm_prf_cnts) --> +---------------------+ || |; | ... | || |; +---------------------+ -----||----+; | Counter for | ||; | Data 1 | ||; +---------------------+ ||; | ... | ||; +---------------------+ =====||; | Counter for |; | Data 2 |; +---------------------+; | ... |; +---------------------+; | Counter for |; | Data N |; +---------------------+. In the graph,. * The profile header records ``CounterDelta`` with the value as ``start(__llvm_prf_cnts) - start(__llvm_prf_data)``.; We will call it ``CounterDeltaInitVal`` below for convenience.; * For each profile data record ``ProfileDataN``, ``CounterPtr`` is recorded as; ``start(CounterN) - start(ProfileDataN)``, where ``ProfileDataN`` is the N-th; entry in ``__llvm_prf_data``, and ``CounterN`` represents the corresponding; profile counters. Each time the reader advances to the next data record, it `updates`_ ``CounterDelta``; to minus the size of one ``ProfileData``. .. _`updates`: https://github.com/llvm/llvm-project/blob/17ff25a58ee4f29816d932fdb75f0d305718069f/llvm/include/llvm/ProfileData/InstrProfReader.h#L439-L444. For the counter corresponding to the first data record, the byte offset; relative to the start of the counter section is calculated as ``CounterPtr1 - CounterDeltaInitVal``.; When profile reader advances to the second data record, note ``CounterDelta``; is updated to ``CounterDeltaInitVal - sizeof(ProfileData)``.; Thus the byte offset relative to the start of the counter section is calculated; as ``CounterPtr2 - (CounterDeltaInitVal - sizeof(ProfileData))``. .. _`bitmap`:. Bitmap; ^^^^^^^; This section is used for source-based `Modified Condition/Decision Coverage`_ code coverage. Check out `Bitmap RFC`_; for the design. .. _`Modified Condition/Decision Coverage`: https://en.wikipedia.org/wiki/Modified_condition/decision_coverage; .. _`Bitmap RFC`: https://discourse.l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst:11032,update,updates,11032,interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst,1,['update'],['updates']
Deployability,"+---------------+------------------------+. If you choose to not use the default logging implementation that comes with the; XRay runtime and/or control when/how the XRay instrumentation runs, you may use; the XRay APIs directly for doing so. To do this, you'll need to include the; ``xray_log_interface.h`` from the compiler-rt ``xray`` directory. The important API; functions we list below:. - ``__xray_log_register_mode(...)``: Register a logging implementation against; a string Mode identifier. The implementation is an instance of; ``XRayLogImpl`` defined in ``xray/xray_log_interface.h``.; - ``__xray_log_select_mode(...)``: Select the mode to install, associated with; a string Mode identifier. Only implementations registered with; ``__xray_log_register_mode(...)`` can be chosen with this function.; - ``__xray_log_init_mode(...)``: This function allows for initializing and; re-initializing an installed logging implementation. See; ``xray/xray_log_interface.h`` for details, part of the XRay compiler-rt; installation. Once a logging implementation has been initialized, it can be ""stopped"" by; finalizing the implementation through the ``__xray_log_finalize()`` function.; The finalization routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:7375,install,installation,7375,interpreter/llvm-project/llvm/docs/XRay.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst,1,['install'],['installation']
Deployability,"+; | verbosity | ``int`` | ``0`` | Runtime verbosity |; | | | | level. |; +-------------------+-----------------+---------------+------------------------+. If you choose to not use the default logging implementation that comes with the; XRay runtime and/or control when/how the XRay instrumentation runs, you may use; the XRay APIs directly for doing so. To do this, you'll need to include the; ``xray_log_interface.h`` from the compiler-rt ``xray`` directory. The important API; functions we list below:. - ``__xray_log_register_mode(...)``: Register a logging implementation against; a string Mode identifier. The implementation is an instance of; ``XRayLogImpl`` defined in ``xray/xray_log_interface.h``.; - ``__xray_log_select_mode(...)``: Select the mode to install, associated with; a string Mode identifier. Only implementations registered with; ``__xray_log_register_mode(...)`` can be chosen with this function.; - ``__xray_log_init_mode(...)``: This function allows for initializing and; re-initializing an installed logging implementation. See; ``xray/xray_log_interface.h`` for details, part of the XRay compiler-rt; installation. Once a logging implementation has been initialized, it can be ""stopped"" by; finalizing the implementation through the ``__xray_log_finalize()`` function.; The finalization routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:7263,install,installed,7263,interpreter/llvm-project/llvm/docs/XRay.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst,1,['install'],['installed']
Deployability,", ""i386"", {3}, object; 5: bind-arch, ""x86_64"", {3}, object; 6: lipo, {4, 5}, object; 7: input, ""t1.c"", c; 8: preprocessor, {7}, cpp-output; 9: compiler, {8}, assembler; 10: assembler, {9}, object; 11: bind-arch, ""i386"", {10}, object; 12: bind-arch, ""x86_64"", {10}, object; 13: lipo, {11, 12}, object. After this stage is complete the compilation process is divided into; a simple set of actions which need to be performed to produce; intermediate or final outputs (in some cases, like ``-fsyntax-only``,; there is no ""real"" final output). Phases are well known compilation; steps, such as ""preprocess"", ""compile"", ""assemble"", ""link"", etc. #. **Bind: Tool & Filename Selection**. This stage (in conjunction with the Translate stage) turns the tree; of Actions into a list of actual subprocess to run. Conceptually, the; driver performs a top down matching to assign Action(s) to Tools. The; ToolChain is responsible for selecting the tool to perform a; particular action; once selected the driver interacts with the tool; to see if it can match additional actions (for example, by having an; integrated preprocessor). Once Tools have been selected for all actions, the driver determines; how the tools should be connected (for example, using an inprocess; module, pipes, temporary files, or user provided filenames). If an; output file is required, the driver also computes the appropriate; file name (the suffix and file location depend on the input types and; options such as ``-save-temps``). The driver interacts with a ToolChain to perform the Tool bindings.; Each ToolChain contains information about all the tools needed for; compilation for a particular architecture, platform, and operating; system. A single driver invocation may query multiple ToolChains; during one compilation in order to interact with tools for separate; architectures. The results of this stage are not computed directly, but the driver; can print the results via the ``-ccc-print-bindings`` option. For; example:. .. c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst:8937,integrat,integrated,8937,interpreter/llvm-project/clang/docs/DriverInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst,1,['integrat'],['integrated']
Deployability,", 2011. Bindings - packages related to the interplay with other programming languages (Python, Ruby); Cint - the C++ interpreter; Core - the basic ROOT functionality; Geometry - building, representing and drawing geometrical objects; 2D Graphics - ROOT's two dimensional graphics interface; 3D Graphics - ROOT's three dimensional graphics interface; Graphical User Interface - from basic GUI elements to ROOT's own, complete dialogs; Histograming - counting values, spectra, and drawing them; HTML - the documentation generator; Input/Ouput - storing and reading data; Mathemathics - everything one can use to calculate: minimizers, matrixes, FFT, and much more; Miscellaneous - things that didn't make it into the other groups: table ; Monte Carlo - monte carlo and physics simulation interfaces; Networking - network-related parts, e.g. protocols and authentication interfaces; PROOF - parallel ROOT facility; RooFit - a fitting library; RooStats - a collection of statistical tools ; SQL - database interfaces; TMVA - multivariate analysis tools; Trees - ROOT's unique container class and related utilities; Tutorials - ROOT's Tutorials. Binaries for all supported platforms are available at:. https://root.cern/releases/release-52800/. For more information, see:. http://root.cern.ch; The following people have contributed to this new version:; Bertrand Bellenot, CERN/SFT,; Dario Berzano, INFN and University of Torino, ALICE, Proof,; Rene Brun, CERN/SFT,; Philippe Canal, FNAL,; Olivier Couet, CERN/SFT,; Kyle Cranmer, NYU, RooStats,; Gerri Ganis, CERN/SFT,; Andrei Gheata, CERN/Alice,; Wim Lavrijsen, LBNL, PyRoot,; Sergei Linev, GSI,; Lorenzo Moneta, CERN/SFT,; Axel Naumann, CERN/SFT,; Eddy Offermann, Renaissance, ; Bartolomeu Rabacal, CERN/ADL, Math, ; Fons Rademakers, CERN/SFT,; Paul Russo, FNAL, ; Joerg Stelzer, DESY/Atlas, TMVA, ; Alja Tadel, UCSD/CMS, Eve, ; Matevz Tadel, UCSD/CMS, Eve, ; Eckhard von Toerne, University Bonn, ATLAS, TMVA, ; Wouter Verkerke, NIKHEF/Atlas, RooFit, . ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v530/index.html:1671,release,releases,1671,doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v530/index.html,2,['release'],"['release-', 'releases']"
Deployability,", Size\ :sub:`32`, CPUType\ :sub:`32`]; :raw-html:`</blockquote></tt>`. Each of the fields are 32-bit fields stored in little endian form (as with the; rest of the bitcode file fields). The Magic number is always ``0x0B17C0DE`` and; the version is currently always ``0``. The Offset field is the offset in bytes; to the start of the bitcode stream in the file, and the Size field is the size; in bytes of the stream. CPUType is a target-specific value that can be used to; encode the CPU of the target. .. _native object file:. Native Object File Wrapper Format; =================================. Bitcode files for LLVM IR may also be wrapped in a native object file; (i.e. ELF, COFF, Mach-O). The bitcode must be stored in a section of the object; file named ``__LLVM,__bitcode`` for MachO or ``.llvmbc`` for the other object; formats. ELF objects additionally support a ``.llvm.lto`` section for; :doc:`FatLTO`, which contains bitcode suitable for LTO compilation (i.e. bitcode; that has gone through a pre-link LTO pipeline). The ``.llvmbc`` section; predates FatLTO support in LLVM, and may not always contain bitcode that is; suitable for LTO (i.e. from ``-fembed-bitcode``). The wrapper format is useful; for accommodating LTO in compilation pipelines where intermediate objects must; be native object files which contain metadata in other sections. . Not all tools support this format. For example, lld and the gold plugin will; ignore the ``.llvmbc`` section when linking object files, but can use; ``.llvm.lto`` sections when passed the correct command line options. .. _encoding of LLVM IR:. LLVM IR Encoding; ================. LLVM IR is encoded into a bitstream by defining blocks and records. It uses; blocks for things like constant pools, functions, symbol tables, etc. It uses; records for things like instructions, global variable descriptors, type; descriptions, etc. This document does not describe the set of abbreviations; that the writer uses, as these are fully self-described ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:19391,pipeline,pipeline,19391,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,1,['pipeline'],['pipeline']
Deployability,", for example allowing you to select; diffs between different versions of the patch as it was reviewed in the; *Revision Update History*. Most features are self descriptive - explore, and; if you have a question, drop by on #llvm in IRC to get help. Note that as e-mail is the system of reference for code reviews, and some; people prefer it over a web interface, we do not generate automated mail; when a review changes state, for example by clicking ""Accept Revision"" in; the web interface. Thus, please type LGTM into the comment box to accept; a change from Phabricator. .. _pre-merge-testing:. Pre-merge testing; -----------------. The pre-merge tests are a continuous integration (CI) workflow. The workflow; checks the patches uploaded to Phabricator before a user merges them to the main; branch - thus the term *pre-merge testing*. When a user uploads a patch to Phabricator, Phabricator triggers the checks and; then displays the results. This way bugs in a patch are contained during the; code review stage and do not pollute the main branch. Our goal with pre-merge testing is to report most true problems while strongly; minimizing the number of false positive reports. Our goal is that problems; reported are always actionable. If you notice a false positive, please report; it so that we can identify the cause. If you notice issues or have an idea on how to improve pre-merge checks, please; `create a new issue <https://github.com/google/llvm-premerge-checks/issues/new>`_; or give a ❤️ to an existing one. Requirements; ^^^^^^^^^^^^. To get a patch on Phabricator tested, the build server must be able to apply the; patch to the checked out git repository. Please make sure that either:. * You set a git hash as ``sourceControlBaseRevision`` in Phabricator which is; available on the GitHub repository,; * **or** you define the dependencies of your patch in Phabricator,; * **or** your patch can be applied to the main branch. Only then can the build server apply the patch locally a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst:10727,patch,patch,10727,interpreter/llvm-project/llvm/docs/Phabricator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst,1,['patch'],['patch']
Deployability,", lookup then proceeds; to the identifier table in the precompiled header it depends on, and so one.; Once a lookup succeeds, that result is considered definitive, overriding any; results from earlier precompiled headers. Update records; There are various ways in which a later precompiled header can modify the; entities described in an earlier precompiled header. For example, later; precompiled headers can add entries into the various name-lookup tables for; the translation unit or namespaces, or add new categories to an Objective-C; class. Each of these updates is captured in an ""update record"" that is; stored in the chained precompiled header file and will be loaded along with; the original entity. .. _pchinternals-modules:. Modules; -------. Modules generalize the chained precompiled header model yet further, from a; linear chain of precompiled headers to an arbitrary directed acyclic graph; (DAG) of AST files. All of the same techniques used to make chained; precompiled headers work --- ID number, name lookup, update records --- are; shared with modules. However, the DAG nature of modules introduce a number of; additional complications to the model:. Numbering of IDs; The simple, linear numbering scheme used in chained precompiled headers falls; apart with the module DAG, because different modules may end up with; different numbering schemes for entities they imported from common shared; modules. To account for this, each module file provides information about; which modules it depends on and which ID numbers it assigned to the entities; in those modules, as well as which ID numbers it took for its own new; entities. The AST reader then maps these ""local"" ID numbers into a ""global""; ID number space for the current translation unit, providing a 1-1 mapping; between entities (in whatever AST file they inhabit) and global ID numbers.; If that translation unit is then serialized into an AST file, this mapping; will be stored for use when the AST file is imported. Dec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:27389,update,update,27389,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,1,['update'],['update']
Deployability,", meaning that its current pointee will be used but the object may be left; in a different (but still valid) state. This arises with ``__block`` variables; and rvalue references in C++. For ``__strong`` lvalues, moving is equivalent; to loading the lvalue with primitive semantics, writing a null pointer to it; with primitive semantics, and then releasing the result of the load at the end; of the current full-expression. For all other lvalues, moving is equivalent to; reading the object. .. _arc.ownership.restrictions:. Restrictions; ------------. .. _arc.ownership.restrictions.weak:. Weak-unavailable types; ^^^^^^^^^^^^^^^^^^^^^^. It is explicitly permitted for Objective-C classes to not support ``__weak``; references. It is undefined behavior to perform an operation with weak; assignment semantics with a pointer to an Objective-C object whose class does; not support ``__weak`` references. .. admonition:: Rationale. Historically, it has been possible for a class to provide its own; reference-count implementation by overriding ``retain``, ``release``, etc.; However, weak references to an object require coordination with its class's; reference-count implementation because, among other things, weak loads and; stores must be atomic with respect to the final release. Therefore, existing; custom reference-count implementations will generally not support weak; references without additional effort. This is unavoidable without breaking; binary compatibility. A class may indicate that it does not support weak references by providing the; ``objc_arc_weak_reference_unavailable`` attribute on the class's interface declaration. A; retainable object pointer type is **weak-unavailable** if; is a pointer to an (optionally protocol-qualified) Objective-C class ``T`` where; ``T`` or one of its superclasses has the ``objc_arc_weak_reference_unavailable``; attribute. A program is ill-formed if it applies the ``__weak`` ownership; qualifier to a weak-unavailable type or if the value oper",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:41452,release,release,41452,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['release']
Deployability,", which relies on direct comparison,; and most of the time, the failures are related to bad output checking, rather; than bad code generation. If the errors are in LLVM itself, please report every single regression found; as blocker, and all the other bugs as important, but not necessarily blocking; the release to proceed. They can be set as ""known failures"" and to be; fix on a future date. .. _pre-release-process:. Pre-Release Process; ===================. .. contents::; :local:. When the release process is announced on the mailing list, you should prepare; for the testing, by applying the same testing you'll do on the release; candidates, on the previous release. You should:. * Download the previous release sources from; https://llvm.org/releases/download.html. * Run the test-release.sh script on ``final`` mode (change ``-rc 1`` to; ``-final``). * Once all three stages are done, it'll test the final stage. * Using the ``Phase3/Release+Asserts/llvmCore-MAJ.MIN-final.install`` base,; run the test-suite. If the final phase's ``make check-all`` failed, it's a good idea to also test; the intermediate stages by going on the obj directory and running; ``make check-all`` to find if there's at least one stage that passes (helps; when reducing the error for bug report purposes). .. _release-process:. Release Process; ===============. .. contents::; :local:. When the Release Manager sends you the release candidate, download all sources,; unzip on the same directory (there will be sym-links from the appropriate places; to them), and run the release test as above. You should:. * Download the current candidate sources from where the release manager points; you (ex. https://llvm.org/pre-releases/3.3/rc1/). * Repeat the steps above with ``-rc 1``, ``-rc 2`` etc modes and run the; test-suite the same way. * Compare the results, report all errors on Bugzilla and publish the binary blob; where the release manager can grab it. Once the release manages announces that the latest candid",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst:5333,install,install,5333,interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,1,['install'],['install']
Deployability,", you're unlikely to be the only one. Please; remember that it is not in the long-term best interest of the community to have; components that are only understood well by a small number of people. Extra; comments and/or test cases can often help (and asking for comments in the test; cases is fine as well). Moreover, authors are encouraged to interpret questions as a reason to reexamine; the readability of the code in question. Structural changes, or further; comments, may be appropriate. If you're new to the LLVM community, you might also find this presentation helpful:; .. _How to Contribute to LLVM, A 2019 LLVM Developers' Meeting Presentation: https://youtu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:11094,patch,patch,11094,interpreter/llvm-project/llvm/docs/CodeReview.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst,1,['patch'],['patch']
Deployability,"-----------+------------------------+; | xray_logfile_base | ``const char*`` | ``xray-log.`` | Filename base for the |; | | | | XRay logfile. |; +-------------------+-----------------+---------------+------------------------+; | verbosity | ``int`` | ``0`` | Runtime verbosity |; | | | | level. |; +-------------------+-----------------+---------------+------------------------+. If you choose to not use the default logging implementation that comes with the; XRay runtime and/or control when/how the XRay instrumentation runs, you may use; the XRay APIs directly for doing so. To do this, you'll need to include the; ``xray_log_interface.h`` from the compiler-rt ``xray`` directory. The important API; functions we list below:. - ``__xray_log_register_mode(...)``: Register a logging implementation against; a string Mode identifier. The implementation is an instance of; ``XRayLogImpl`` defined in ``xray/xray_log_interface.h``.; - ``__xray_log_select_mode(...)``: Select the mode to install, associated with; a string Mode identifier. Only implementations registered with; ``__xray_log_register_mode(...)`` can be chosen with this function.; - ``__xray_log_init_mode(...)``: This function allows for initializing and; re-initializing an installed logging implementation. See; ``xray/xray_log_interface.h`` for details, part of the XRay compiler-rt; installation. Once a logging implementation has been initialized, it can be ""stopped"" by; finalizing the implementation through the ``__xray_log_finalize()`` function.; The finalization routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:7009,install,install,7009,interpreter/llvm-project/llvm/docs/XRay.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst,1,['install'],['install']
Deployability,"-----------------+. In the graph,. * The profile header records ``CounterDelta`` with the value as ``start(__llvm_prf_cnts) - start(__llvm_prf_data)``.; We will call it ``CounterDeltaInitVal`` below for convenience.; * For each profile data record ``ProfileDataN``, ``CounterPtr`` is recorded as; ``start(CounterN) - start(ProfileDataN)``, where ``ProfileDataN`` is the N-th; entry in ``__llvm_prf_data``, and ``CounterN`` represents the corresponding; profile counters. Each time the reader advances to the next data record, it `updates`_ ``CounterDelta``; to minus the size of one ``ProfileData``. .. _`updates`: https://github.com/llvm/llvm-project/blob/17ff25a58ee4f29816d932fdb75f0d305718069f/llvm/include/llvm/ProfileData/InstrProfReader.h#L439-L444. For the counter corresponding to the first data record, the byte offset; relative to the start of the counter section is calculated as ``CounterPtr1 - CounterDeltaInitVal``.; When profile reader advances to the second data record, note ``CounterDelta``; is updated to ``CounterDeltaInitVal - sizeof(ProfileData)``.; Thus the byte offset relative to the start of the counter section is calculated; as ``CounterPtr2 - (CounterDeltaInitVal - sizeof(ProfileData))``. .. _`bitmap`:. Bitmap; ^^^^^^^; This section is used for source-based `Modified Condition/Decision Coverage`_ code coverage. Check out `Bitmap RFC`_; for the design. .. _`Modified Condition/Decision Coverage`: https://en.wikipedia.org/wiki/Modified_condition/decision_coverage; .. _`Bitmap RFC`: https://discourse.llvm.org/t/rfc-source-based-mc-dc-code-coverage/59244. Names; ^^^^^^. This section contains possibly compressed concatenated string of functions' PGO; names. If compressed, zlib library is used. Function names serve as keys in the PGO data hash table when raw profiles are; converted into indexed profiles. They are also crucial for ``llvm-profdata`` to; show the profiles in a human-readable way. Value Profile Data; ^^^^^^^^^^^^^^^^^^^^. This section contains the p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst:11516,update,updated,11516,interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst,1,['update'],['updated']
Deployability,"--------------------+--------------------------+-----------------------------------------------------------------------+; | device | clause: use_device_addr for target data | :good:`done` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | device | support close modifier on map clause | :good:`done` | D55719,D55892 |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | device | teams construct on the host device | :good:`done` | r371553 |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | device | support non-contiguous array sections for target update | :good:`done` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | device | pointer attachment | :good:`done` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | atomic | hints for the atomic construct | :good:`done` | D51233 |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | base language | C11 support | :good:`done` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | base language | C++11/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst:16981,update,update,16981,interpreter/llvm-project/clang/docs/OpenMPSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst,1,['update'],['update']
Deployability,"-----------------------------+----------------+-------------------------------------------------+; | delete_size_mismatch | true | Whether or not we report errors on mismatch |; | | | between sizes of new and delete. |; +---------------------------------+----------------+-------------------------------------------------+; | zero_contents | false | Whether or not we zero chunk contents on |; | | | allocation. |; +---------------------------------+----------------+-------------------------------------------------+; | pattern_fill_contents | false | Whether or not we fill chunk contents with a |; | | | byte pattern on allocation. |; +---------------------------------+----------------+-------------------------------------------------+; | may_return_null | true | Whether or not a non-fatal failure can return a |; | | | NULL pointer (as opposed to terminating). |; +---------------------------------+----------------+-------------------------------------------------+; | release_to_os_interval_ms | 5000 | The minimum interval (in ms) at which a release |; | | | can be attempted (a negative value disables |; | | | reclaiming). |; +---------------------------------+----------------+-------------------------------------------------+; | allocation_ring_buffer_size | 32768 | If stack trace collection is requested, how |; | | | many previous allocations to keep in the |; | | | allocation ring buffer. |; | | | |; | | | This buffer is used to provide allocation and |; | | | deallocation stack traces for MTE fault |; | | | reports. The larger the buffer, the more |; | | | unrelated allocations can happen between |; | | | (de)allocation and the fault. |; | | | If your sync-mode MTE faults do not have |; | | | (de)allocation stack traces, try increasing the |; | | | buffer size. |; | | | |; | | | Stack trace collection can be requested using |; | | | the scudo_malloc_set_track_allocation_stacks |; | | | function. |; +---------------------------------+----------------+-------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:10984,release,release,10984,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['release'],['release']
Deployability,"-------------------------------------------------------------+; |String Key |Value Type |Description |; +=============+==============+=======================================================================+; |- "".ls"" |map |See :ref:`amdgpu-amdpal-code-object-hardware-stage-metadata-map-table` |; |- "".hs"" | |for the definition of the keys included in that map. |; |- "".es"" | | |; |- "".gs"" | | |; |- "".vs"" | | |; |- "".ps"" | | |; |- "".cs"" | | |; +-------------+--------------+-----------------------------------------------------------------------+. .. .. table:: AMDPAL Code Object Hardware Stage Metadata Map; :name: amdgpu-amdpal-code-object-hardware-stage-metadata-map-table. ========================== ============== ========= ===============================================================; String Key Value Type Required? Description; ========================== ============== ========= ===============================================================; "".entry_point"" string The ELF symbol pointing to this pipeline's stage entry point.; "".scratch_memory_size"" integer Scratch memory size in bytes.; "".lds_size"" integer Local Data Share size in bytes.; "".perf_data_buffer_size"" integer Performance data buffer size in bytes.; "".vgpr_count"" integer Number of VGPRs used.; "".agpr_count"" integer Number of AGPRs used.; "".sgpr_count"" integer Number of SGPRs used.; "".vgpr_limit"" integer If non-zero, indicates the shader was compiled with a; directive to instruct the compiler to limit the VGPR usage to; be less than or equal to the specified value (only set if; different from HW default).; "".sgpr_limit"" integer SGPR count upper limit (only set if different from HW; default).; "".threadgroup_dimensions"" sequence of Thread-group X/Y/Z dimensions (Compute only).; 3 integers; "".wavefront_size"" integer Wavefront size (only set if different from HW default).; "".uses_uavs"" boolean The shader reads or writes UAVs.; "".uses_rovs"" boolean The shader reads or writes ROVs.; "".writes_uavs"" boolean The sh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:408990,pipeline,pipeline,408990,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['pipeline'],['pipeline']
Deployability,"-------------------------------------------------------------------===//. clang -O3 -fno-exceptions currently compiles this code:. void f(char* a, int n) {; __builtin_memset(a, 0, n);; for (int i = 0; i < n; ++i); a[i] = 0;; }. into:. define void @_Z1fPci(i8* nocapture %a, i32 %n) nounwind {; entry:; %conv = sext i32 %n to i64; tail call void @llvm.memset.p0i8.i64(i8* %a, i8 0, i64 %conv, i32 1, i1 false); %cmp8 = icmp sgt i32 %n, 0; br i1 %cmp8, label %for.body.lr.ph, label %for.end. for.body.lr.ph: ; preds = %entry; %tmp10 = add i32 %n, -1; %tmp11 = zext i32 %tmp10 to i64; %tmp12 = add i64 %tmp11, 1; call void @llvm.memset.p0i8.i64(i8* %a, i8 0, i64 %tmp12, i32 1, i1 false); ret void. for.end: ; preds = %entry; ret void; }. This shouldn't need the ((zext (%n - 1)) + 1) game, and it should ideally fold; the two memset's together. The issue with the addition only occurs in 64-bit mode, and appears to be at; least partially caused by Scalar Evolution not keeping its cache updated: it; returns the ""wrong"" result immediately after indvars runs, but figures out the; expected result if it is run from scratch on IR resulting from running indvars. //===---------------------------------------------------------------------===//. clang -O3 -fno-exceptions currently compiles this code:. struct S {; unsigned short m1, m2;; unsigned char m3, m4;; };. void f(int N) {; std::vector<S> v(N);; extern void sink(void*); sink(&v);; }. into poor code for zero-initializing 'v' when N is >0. The problem is that; S is only 6 bytes, but each element is 8 byte-aligned. We generate a loop and; 4 stores on each iteration. If the struct were 8 bytes, this gets turned into; a memset. In order to handle this we have to:; A) Teach clang to generate metadata for memsets of structs that have holes in; them.; B) Teach clang to use such a memset for zero init of this struct (since it has; a hole), instead of doing elementwise zeroing. //===---------------------------------------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:59372,update,updated,59372,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['update'],['updated']
Deployability,"---------------------------------------------------------; if(asan); if(NOT CMAKE_COMPILER_IS_GNUCXX AND NOT CMAKE_CXX_COMPILER_ID MATCHES Clang); message(WARNING ""Address sanitizer builds only tested with gcc and Clang""); endif(). if(NOT MSVC); set(ASAN_EXTRA_LD_PRELOAD ""${CMAKE_BINARY_DIR}/lib/${CMAKE_SHARED_LIBRARY_PREFIX}ROOTSanitizerConfig${CMAKE_SHARED_LIBRARY_SUFFIX}:${ASAN_RUNTIME_LIBRARY}""); endif(). foreach(item IN LISTS ASAN_EXTRA_CXX_FLAGS); add_compile_options($<$<COMPILE_LANGUAGE:CXX>:${item}>); endforeach(); #add_link_options() not available in our CMake version:; set(CMAKE_SHARED_LINKER_FLAGS ""${CMAKE_SHARED_LINKER_FLAGS} ${ASAN_EXTRA_SHARED_LINKER_FLAGS}""); set(CMAKE_EXE_LINKER_FLAGS ""${CMAKE_EXE_LINKER_FLAGS} ${ASAN_EXTRA_EXE_LINKER_FLAGS}""); endif(). #---Enable CTest package -----------------------------------------------------------------------; #include(CTest); if(testing); enable_testing(); endif(). #---Here we look for installed software and switch on and of the different build options--------; include(SearchInstalledSoftware). #---Here we add tcmalloc to the linker flags if needed------------------------------------------; if (TCMALLOC_FOUND); set(CMAKE_EXE_LINKER_FLAGS ""${CMAKE_EXE_LINKER_FLAGS} -ltcmalloc -L${TCMALLOC_LIBRARY_PATH}""); set(CMAKE_SHARED_LINKER_FLAGS ""${CMAKE_SHARED_LINKER_FLAGS} -ltcmalloc -L${TCMALLOC_LIBRARY_PATH}""); endif(). #---Here we add jemalloc to the linker flags if needed------------------------------------------; if (JEMALLOC_FOUND); set(CMAKE_EXE_LINKER_FLAGS ""${CMAKE_EXE_LINKER_FLAGS} -ljemalloc -L${JEMALLOC_LIBRARY_PATH}""); set(CMAKE_SHARED_LINKER_FLAGS ""${CMAKE_SHARED_LINKER_FLAGS} -ljemalloc -L${JEMALLOC_LIBRARY_PATH}""); endif(). #---Populate the configure arguments returned by 'root-config --config'-------------------------; get_cmake_property(variables CACHE_VARIABLES); foreach(var ${variables}); if((var MATCHES ""_(LIBRARIES|LIBRARY|INCLUDE|VERSION)"") AND; (NOT ${${var}} STREQUAL """") AND; (NOT ${var} MATCHES",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt:12274,install,installed,12274,CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt,1,['install'],['installed']
Deployability,"----------------------------------------------------; generateHeader(hadd; ${CMAKE_SOURCE_DIR}/main/src/hadd-argparse.py; ${CMAKE_BINARY_DIR}/ginclude/haddCommandLineOptionsHelp.h; ). if(fortran AND CMAKE_Fortran_COMPILER); ROOT_EXECUTABLE(g2root g2root.f LIBRARIES minicern); set_target_properties(g2root PROPERTIES COMPILE_FLAGS ""-w""); ROOT_EXECUTABLE(h2root h2root.cxx LIBRARIES Core RIO Net Hist Graf Graf3d Gpad Tree Matrix MathCore Thread minicern); endif(). file(GLOB utils RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} python/root*); foreach(rawUtilName ${utils}); get_filename_component(utilName ${rawUtilName} NAME); if(NOT WIN32); # We need the .py only on Windows; string(REPLACE "".py"" """" utilName ${utilName}); set(python python3); else(); set(python python); endif(); configure_file(${rawUtilName} ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_BINDIR}/${utilName} @ONLY). install(FILES ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_BINDIR}/${utilName}; DESTINATION ${CMAKE_INSTALL_BINDIR}; RENAME ${utilName}; PERMISSIONS OWNER_EXECUTE OWNER_WRITE OWNER_READ; GROUP_EXECUTE GROUP_READ; WORLD_EXECUTE WORLD_READ; COMPONENT applications); endforeach(). install(FILES python/cmdLineUtils.py DESTINATION ${runtimedir}); if(IS_ABSOLUTE ${runtimedir}); set(absruntimedir ${runtimedir}); else(); set(absruntimedir \${CMAKE_INSTALL_PREFIX}/${runtimedir}); endif(); install(CODE ""execute_process(COMMAND ${Python3_EXECUTABLE} -m py_compile \$ENV{DESTDIR}${absruntimedir}/cmdLineUtils.py)""); install(CODE ""execute_process(COMMAND ${Python3_EXECUTABLE} -O -m py_compile \$ENV{DESTDIR}${absruntimedir}/cmdLineUtils.py)""); configure_file(python/cmdLineUtils.py ${localruntimedir}/cmdLineUtils.py @ONLY). set_source_files_properties(src/rootcling.cxx PROPERTIES; COMPILE_FLAGS ""${CLING_CXXFLAGS}""; VISIBILITY_INLINES_HIDDEN ""ON""; ). ROOT_EXECUTABLE(rootcling src/rootcling.cxx LIBRARIES RIO Cling Core Rint). # rootcling includes the ROOT complex header which would build the complex; # dictionary with modules. To make sure that ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/main/CMakeLists.txt:2741,install,install,2741,main/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/main/CMakeLists.txt,1,['install'],['install']
Deployability,"--------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:355759,release,released,355759,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['released']
Deployability,"-----------------------------------------===//. Poor codegen test/CodeGen/ARM/select.ll f7:. 	ldr r5, LCPI1_0; LPC0:; 	add r5, pc; 	ldr r6, LCPI1_1; 	ldr r2, LCPI1_2; 	mov r3, r6; 	mov lr, pc; 	bx r5. //===---------------------------------------------------------------------===//. Make register allocator / spiller smarter so we can re-materialize ""mov r, imm"",; etc. Almost all Thumb instructions clobber condition code. //===---------------------------------------------------------------------===//. Thumb load / store address mode offsets are scaled. The values kept in the; instruction operands are pre-scale values. This probably ought to be changed; to avoid extra work when we convert Thumb2 instructions to Thumb1 instructions. //===---------------------------------------------------------------------===//. We need to make (some of the) Thumb1 instructions predicable. That will allow; shrinking of predicated Thumb2 instructions. To allow this, we need to be able; to toggle the 's' bit since they do not set CPSR when they are inside IT blocks. //===---------------------------------------------------------------------===//. Make use of hi register variants of cmp: tCMPhir / tCMPZhir. //===---------------------------------------------------------------------===//. Thumb1 immediate field sometimes keep pre-scaled values. See; ThumbRegisterInfo::eliminateFrameIndex. This is inconsistent from ARM and; Thumb2. //===---------------------------------------------------------------------===//. Rather than having tBR_JTr print a "".align 2"" and constant island pass pad it,; add a target specific ALIGN instruction instead. That way, getInstSizeInBytes; won't have to over-estimate. It can also be used for loop alignment pass. //===---------------------------------------------------------------------===//. We generate conditional code for icmp when we don't need to. This code:. int foo(int s) {; return s == 1;; }. produces:. foo:; cmp r0, #1; mov.w r0, #0; it eq; moveq r0, #1; bx l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README-Thumb.txt:5674,toggle,toggle,5674,interpreter/llvm-project/llvm/lib/Target/ARM/README-Thumb.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README-Thumb.txt,1,['toggle'],['toggle']
Deployability,"------------------------------. Code can be reviewed either before it is committed or after. We expect; significant patches to be reviewed before being committed. Smaller patches; (or patches where the developer owns the component) that meet; likely-community-consensus requirements (as apply to all patch approvals) can; be committed prior to an explicit review. In situations where there is any; uncertainty, a patch should be reviewed prior to being committed. Please note that the developer responsible for a patch is also; responsible for making all necessary review-related changes, including; those requested during any post-commit review. .. _post_commit_review:. Can Code Be Reviewed After It Is Committed?; -------------------------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussions),; they may ask for a revert to the original author who is responsible to revert; the patch promptly. Developers often disagree, and erring on the side of the; developer asking for more review prevents any lingering disagreement over; code in the tree. This does not indicate any fault from the patch author,; this is inherent to our post-commit review practices.; Reverting a patch ensures that design discussions can happen without blocking; other development; it's entirely possible the patch will end up being reapplied; essentially as-is once concerns have been resolved. Before being recommitted, the patch generally should undergo further review.; The community member who identified the problem is expected to engage; actively",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:1921,patch,patch,1921,interpreter/llvm-project/llvm/docs/CodeReview.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst,1,['patch'],['patch']
Deployability,"----------------------------===//. Think about doing i64 math in SSE regs on x86-32. //===---------------------------------------------------------------------===//. This testcase should have no SSE instructions in it, and only one load from; a constant pool:. double %test3(bool %B) {; %C = select bool %B, double 123.412, double 523.01123123; ret double %C; }. Currently, the select is being lowered, which prevents the dag combiner from; turning 'select (load CPI1), (load CPI2)' -> 'load (select CPI1, CPI2)'. The pattern isel got this one right. //===---------------------------------------------------------------------===//. Lower memcpy / memset to a series of SSE 128 bit move instructions when it's; feasible. //===---------------------------------------------------------------------===//. Codegen:; if (copysign(1.0, x) == copysign(1.0, y)); into:; if (x^y & mask); when using SSE. //===---------------------------------------------------------------------===//. Use movhps to update upper 64-bits of a v4sf value. Also movlps on lower half; of a v4sf value. //===---------------------------------------------------------------------===//. Better codegen for vector_shuffles like this { x, 0, 0, 0 } or { x, 0, x, 0}.; Perhaps use pxor / xorp* to clear a XMM register first?. //===---------------------------------------------------------------------===//. External test Nurbs exposed some problems. Look for; __ZN15Nurbs_SSE_Cubic17TessellateSurfaceE, bb cond_next140. This is what icc; emits:. movaps (%edx), %xmm2 #59.21; movaps (%edx), %xmm5 #60.21; movaps (%edx), %xmm4 #61.21; movaps (%edx), %xmm3 #62.21; movl 40(%ecx), %ebp #69.49; shufps $0, %xmm2, %xmm5 #60.21; movl 100(%esp), %ebx #69.20; movl (%ebx), %edi #69.20; imull %ebp, %edi #69.49; addl (%eax), %edi #70.33; shufps $85, %xmm2, %xmm4 #61.21; shufps $170, %xmm2, %xmm3 #62.21; shufps $255, %xmm2, %xmm2 #63.21; lea (%ebp,%ebp,2), %ebx #69.49; negl %ebx #69.49; lea -3(%edi,%ebx), %ebx #70.33; shll $4, %ebx #68.37; addl ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:3318,update,update,3318,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,1,['update'],['update']
Deployability,"---------------------------===//. These instructions describe how to build and install Clang. //===----------------------------------------------------------------------===//; // Step 1: Organization; //===----------------------------------------------------------------------===//. Clang is designed to be built as part of an LLVM build. Assuming that the LLVM; source code is located at $LLVM_SRC_ROOT, then the clang source code should be; installed as:. $LLVM_SRC_ROOT/tools/clang. The directory is not required to be called clang, but doing so will allow the; LLVM build system to automatically recognize it and build it along with LLVM. //===----------------------------------------------------------------------===//; // Step 2: Configure and Build LLVM; //===----------------------------------------------------------------------===//. Configure and build your copy of LLVM (see $LLVM_SRC_ROOT/GettingStarted.html; for more information). Assuming you installed clang at $LLVM_SRC_ROOT/tools/clang then Clang will; automatically be built with LLVM. Otherwise, run 'make' in the Clang source; directory to build Clang. //===----------------------------------------------------------------------===//; // Step 3: (Optional) Verify Your Build; //===----------------------------------------------------------------------===//. It is a good idea to run the Clang tests to make sure your build works; correctly. From inside the Clang build directory, run 'make test' to run the; tests. //===----------------------------------------------------------------------===//; // Step 4: Install Clang; //===----------------------------------------------------------------------===//. From inside the Clang build directory, run 'make install' to install the Clang; compiler and header files into the prefix directory selected when LLVM was; configured. The Clang compiler is available as 'clang' and 'clang++'. It supports a gcc like; command line interface. See the man page for clang for more information.;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/INSTALL.txt:1125,install,installed,1125,interpreter/llvm-project/clang/INSTALL.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/INSTALL.txt,1,['install'],['installed']
Deployability,"--------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; configuration. How to do so depends on your experiment, but usually you; should essentially specify the version of the experiment's software you; need. For instance, in the CMS use case, only one file is needed:; `~/.vaf/common.before`, which contains something like:. ``` {.bash}; # Version of CMSSW (as reported by ""scram list""); export VafCmsswVersion='CMSSW_5_3_9_sherpa2beta2'; ```. ### Entering the VAF environment. Open a terminal on your client machine (can be either your local; computer or a remote user interface) and type:. vaf-enter <username>@cloud-gw-213.to.infn.it. You'll substitute `<username>` with the username that either your system; administrator or the web authentication (if you used it) provided you. You'll be presented with a neat shell which looks like the following:. Entering VAF environment: dberzano@cloud-gw-213.to.infn.it; Remember: you are still in a shell on your local com",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:9185,configurat,configuration,9185,proof/doc/confman/UsingVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md,1,['configurat'],['configuration']
Deployability,"--------------------------===//. These instructions describe how to build and install Clang. //===----------------------------------------------------------------------===//; // Step 1: Organization; //===----------------------------------------------------------------------===//. Clang is designed to be built as part of an LLVM build. Assuming that the LLVM; source code is located at $LLVM_SRC_ROOT, then the clang source code should be; installed as:. $LLVM_SRC_ROOT/tools/clang. The directory is not required to be called clang, but doing so will allow the; LLVM build system to automatically recognize it and build it along with LLVM. //===----------------------------------------------------------------------===//; // Step 2: Configure and Build LLVM; //===----------------------------------------------------------------------===//. Configure and build your copy of LLVM (see $LLVM_SRC_ROOT/GettingStarted.html; for more information). Assuming you installed clang at $LLVM_SRC_ROOT/tools/clang then Clang will; automatically be built with LLVM. Otherwise, run 'make' in the Clang source; directory to build Clang. //===----------------------------------------------------------------------===//; // Step 3: (Optional) Verify Your Build; //===----------------------------------------------------------------------===//. It is a good idea to run the Clang tests to make sure your build works; correctly. From inside the Clang build directory, run 'make test' to run the; tests. //===----------------------------------------------------------------------===//; // Step 4: Install Clang; //===----------------------------------------------------------------------===//. From inside the Clang build directory, run 'make install' to install the Clang; compiler and header files into the prefix directory selected when LLVM was; configured. The Clang compiler is available as 'clang' and 'clang++'. It supports a gcc like; command line interface. See the man page for clang for more information.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/INSTALL.txt:1892,install,install,1892,interpreter/llvm-project/clang/INSTALL.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/INSTALL.txt,2,['install'],['install']
Deployability,"-------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussions),; they may ask for a revert to the original author who is responsible to revert; the patch promptly. Developers often disagree, and erring on the side of the; developer asking for more review prevents any lingering disagreement over; code in the tree. This does not indicate any fault from the patch author,; this is inherent to our post-commit review practices.; Reverting a patch ensures that design discussions can happen without blocking; other development; it's entirely possible the patch will end up being reapplied; essentially as-is once concerns have been resolved. Before being recommitted, the patch generally should undergo further review.; The community member who identified the problem is expected to engage; actively in the review. In cases where the problem is identified by a buildbot,; a community member with access to hardware similar to that on the buildbot is; expected to engage in the review. Please note: The bar for post-commit feedback is not higher than for pre-commit; feedback. Don't delay unnecessarily in providing feedback. However, if you see; something after code has been committed about which you would have commented; pre-commit (had you noticed it earlier), please feel free to provide that; feedback at any time. That having been said, if a substantial period of time has passed since the; original change was committed, it may be better to create a new patch to; address the issues than comment on the original commit. The ori",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:2568,patch,patch,2568,interpreter/llvm-project/llvm/docs/CodeReview.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst,2,['patch'],['patch']
Deployability,"-------------------------. The function SelectionDAGBuilder::visitConstrainedFPIntrinsic builds DAG nodes; using mappings specified in ConstrainedOps.def. If however this default build is; not sufficient, the build can be modified, see how it is implemented for; STRICT_FP_ROUND. The new STRICT node will eventually be converted; to the matching non-STRICT node. For this reason it should have the same; operands and values as the non-STRICT version but should also use the chain.; This makes subsequent sharing of code for STRICT and non-STRICT code paths; easier::. lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp. Most of the STRICT nodes get legalized the same as their matching non-STRICT; counterparts. A new STRICT node with this property must get added to the; switch in SelectionDAGLegalize::LegalizeOp().::. lib/CodeGen/SelectionDAG/LegalizeDAG.cpp. Other parts of the legalizer may need to be updated as well. Look for; places where the non-STRICT counterpart is legalized and update as needed.; Be careful of the chain since STRICT nodes use it but their counterparts; often don't. The code to do the conversion or mutation of the STRICT node to a non-STRICT; version of the node happens in SelectionDAG::mutateStrictFPToFP(). In most cases; the function can do the conversion using information from ConstrainedOps.def. Be; careful updating this function since some nodes have the same return type; as their input operand, but some are different. Both of these cases must; be properly handled::. lib/CodeGen/SelectionDAG/SelectionDAG.cpp. Whether the mutation may happens or not, depends on how the new node has been; registered in TargetLoweringBase::initActions(). By default all strict nodes are; registered with Expand action::. lib/CodeGen/TargetLoweringBase.cpp. To make debug logs readable it is helpful to update the SelectionDAG's; debug logger:::. lib/CodeGen/SelectionDAG/SelectionDAGDumper.cpp. Add documentation and tests; ===========================. ::. docs/LangRef.rst; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AddingConstrainedIntrinsics.rst:2973,update,update,2973,interpreter/llvm-project/llvm/docs/AddingConstrainedIntrinsics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AddingConstrainedIntrinsics.rst,1,['update'],['update']
Deployability,"-----------------------; install(DIRECTORY ${CMAKE_BINARY_DIR}/etc/cling/lib/clang/${CLANG_RESOURCE_DIR_VERSION}/include/; DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}/cling/lib/clang/${CLANG_RESOURCE_DIR_VERSION}/include USE_SOURCE_PERMISSIONS). #---Install a bunch of files to /etc/cling------------------------------------; set(clinginclude ${CMAKE_SOURCE_DIR}/interpreter/cling/include). set(custom_modulemaps); if (runtime_cxxmodules); set(custom_modulemaps boost.modulemap tinyxml2.modulemap cuda.modulemap module.modulemap.build); # FIXME: We should install vc.modulemap only when Vc is found (Vc_FOUND) but; # some systems install it under /usr/include/Vc/Vc which allows rootcling to; # discover it and assert that the modulemap is not found.; set(custom_modulemaps ${custom_modulemaps} vc.modulemap). # We need to override the default modulemap because instead of producing a; # single std.pcm, produces hundreds of pcms. This changed with MacOSX14.4.sdk; # To support macOS 13 with LLVM 18, we need to patch the modulemap from; # MacOSX14.2.sdk; if (APPLE); if (CMAKE_CXX_COMPILER_VERSION VERSION_LESS 15.0.0.15000309); set(custom_modulemaps ${custom_modulemaps} std_darwin.MacOSX14.2.sdk.modulemap); else(); set(custom_modulemaps ${custom_modulemaps} std_darwin.modulemap); endif(); endif(). if (NOT libcxx); if (MSVC); set(custom_modulemaps ${custom_modulemaps} vcruntime.modulemap); set(custom_modulemaps ${custom_modulemaps} services_msvc.modulemap); set(custom_modulemaps ${custom_modulemaps} std_msvc.modulemap); else(); set(custom_modulemaps ${custom_modulemaps} std.modulemap); endif(); endif(); # Handle libc. Apple's libc is modularized.; if (MSVC); set(custom_modulemaps ${custom_modulemaps} libc_msvc.modulemap); elseif (NOT APPLE); set(custom_modulemaps ${custom_modulemaps} libc.modulemap); endif(); endif(runtime_cxxmodules). foreach(file ${custom_modulemaps}; Interpreter/DynamicExprInfo.h; Interpreter/DynamicLookupRuntimeUniverse.h; Interpreter/DynamicLookupLifetimeHandler.h; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/clingutils/CMakeLists.txt:4709,patch,patch,4709,core/clingutils/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/clingutils/CMakeLists.txt,1,['patch'],['patch']
Deployability,"-------------------. The tool to create and review patches in Phabricator is called; *Differential*. Note that you can upload patches created through git, but using `arc` on the; command line (see previous section) is preferred: it adds more metadata to; Phabricator which are useful for the pre-merge testing system and for; propagating attribution on commits when someone else has to push it for you. To make reviews easier, please always include **as much context as; possible** with your diff! Don't worry, Phabricator; will automatically send a diff with a smaller context in the review; email, but having the full file in the web interface will help the; reviewer understand your code. To get a full diff, use one of the following commands (or just use Arcanist; to upload your patch):. * ``git show HEAD -U999999 > mypatch.patch``; * ``git diff -U999999 @{u} > mypatch.patch``; * ``git diff HEAD~1 -U999999 > mypatch.patch``. Before uploading your patch, please make sure it is formatted properly, as; described in :ref:`How to Submit a Patch <format patches>`. To upload a new patch:. * Click *Differential*.; * Click *+ Create Diff*.; * Paste the text diff or browse to the patch file. Leave this first Repository; field blank. (We'll fill in the Repository later, when sending the review.); Click *Create Diff*.; * Leave the drop down on *Create a new Revision...* and click *Continue*.; * Enter a descriptive title and summary. The title and summary are usually; in the form of a :ref:`commit message <commit messages>`.; * Add reviewers (see below for advice). (If you set the Repository field; correctly, llvm-commits or cfe-commits will be subscribed automatically;; otherwise, you will have to manually subscribe them.); * In the Repository field, enter ""rG LLVM Github Monorepo"".; * Click *Save*. To submit an updated patch:. * Click *Differential*.; * Click *+ Create Diff*.; * Paste the updated diff or browse to the updated patch file. Click *Create Diff*.; * Select the review you",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst:3482,patch,patch,3482,interpreter/llvm-project/llvm/docs/Phabricator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst,2,['patch'],"['patch', 'patches']"
Deployability,"------------. *Previously*: ``EXCLUSIVE_LOCKS_REQUIRED``, ``SHARED_LOCKS_REQUIRED``. ``REQUIRES`` is an attribute on functions or methods, which; declares that the calling thread must have exclusive access to the given; capabilities. More than one capability may be specified. The capabilities; must be held on entry to the function, *and must still be held on exit*. ``REQUIRES_SHARED`` is similar, but requires only shared access. .. code-block:: c++. Mutex mu1, mu2;; int a GUARDED_BY(mu1);; int b GUARDED_BY(mu2);. void foo() REQUIRES(mu1, mu2) {; a = 0;; b = 0;; }. void test() {; mu1.Lock();; foo(); // Warning! Requires mu2.; mu1.Unlock();; }. ACQUIRE(...), ACQUIRE_SHARED(...), RELEASE(...), RELEASE_SHARED(...), RELEASE_GENERIC(...); ------------------------------------------------------------------------------------------. *Previously*: ``EXCLUSIVE_LOCK_FUNCTION``, ``SHARED_LOCK_FUNCTION``,; ``UNLOCK_FUNCTION``. ``ACQUIRE`` and ``ACQUIRE_SHARED`` are attributes on functions or methods; declaring that the function acquires a capability, but does not release it.; The given capability must not be held on entry, and will be held on exit; (exclusively for ``ACQUIRE``, shared for ``ACQUIRE_SHARED``). ``RELEASE``, ``RELEASE_SHARED``, and ``RELEASE_GENERIC`` declare that the; function releases the given capability. The capability must be held on entry; (exclusively for ``RELEASE``, shared for ``RELEASE_SHARED``, exclusively or; shared for ``RELEASE_GENERIC``), and will no longer be held on exit. .. code-block:: c++. Mutex mu;; MyClass myObject GUARDED_BY(mu);. void lockAndInit() ACQUIRE(mu) {; mu.Lock();; myObject.init();; }. void cleanupAndUnlock() RELEASE(mu) {; myObject.cleanup();; } // Warning! Need to unlock mu. void test() {; lockAndInit();; myObject.doSomething();; cleanupAndUnlock();; myObject.doSomething(); // Warning, mu is not locked.; }. If no argument is passed to ``ACQUIRE`` or ``RELEASE``, then the argument is; assumed to be ``this``, and the analysis will not",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:8629,release,release,8629,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['release'],['release']
Deployability,"---------. cppyy requires C/C++ headers to be available at run-time, which was never a; problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured differently, was thus also never a problem.; Or rather, the same problem exists for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can break them.; The two typical solutions are to either restrict the choice of Python; interpreter and version that are supported (common in HPC) or to provide; binaries (wheels) for a large range of different interpreters and versions; (as e.g. done for conda). In the case of cppyy, only CPython/CPyCppyy and PyPy/_cppyy (an internal; module) depend on the Python interpreter (see:; :ref:`Package Structure <package-structure>`).; The user-facing ``cppyy`` module is pure Python and the backend (Cling) is; Python-independent.; Most importantly, since all bindings are generated at run-time, there are no; extension modules to regenerate and/or recompile. Thus, the end-user only needs to rebuild/reinstall CPyCppyy for each relevant; version of Python (and nothing extra is needed for PyPy) to switch Python; versions and/or interpreter.; The rest of the so",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:10622,deploy,deployment,10622,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,1,['deploy'],['deployment']
Deployability,"-------. Immutability; ^^^^^^^^^^^^. Clang AST nodes (types, declarations, statements, expressions, and so on) are; generally designed to be immutable once created. This provides a number of key; benefits:. * Canonicalization of the ""meaning"" of nodes is possible as soon as the nodes; are created, and is not invalidated by later addition of more information.; For example, we :ref:`canonicalize types <CanonicalType>`, and use a; canonicalized representation of expressions when determining whether two; function template declarations involving dependent expressions declare the; same entity.; * AST nodes can be reused when they have the same meaning. For example, we; reuse ``Type`` nodes when representing the same type (but maintain separate; ``TypeLoc``\s for each instance where a type is written), and we reuse; non-dependent ``Stmt`` and ``Expr`` nodes across instantiations of a; template.; * Serialization and deserialization of the AST to/from AST files is simpler:; we do not need to track modifications made to AST nodes imported from AST; files and serialize separate ""update records"". There are unfortunately exceptions to this general approach, such as:. * The first declaration of a redeclarable entity maintains a pointer to the; most recent declaration of that entity, which naturally needs to change as; more declarations are parsed.; * Name lookup tables in declaration contexts change after the namespace; declaration is formed.; * We attempt to maintain only a single declaration for an instantiation of a; template, rather than having distinct declarations for an instantiation of; the declaration versus the definition, so template instantiation often; updates parts of existing declarations.; * Some parts of declarations are required to be instantiated separately (this; includes default arguments and exception specifications), and such; instantiations update the existing declaration. These cases tend to be fragile; mutable AST state should be avoided where; possible. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:58626,update,update,58626,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['update'],['update']
Deployability,"------; http://www.highproductivity.org/SSCABmks.htm. This web site does not exist any more, but there seems to be a copy of; some of the benchmarks; https://github.com/gtcasl/hpc-benchmarks/tree/master/SSCA2v2.2. Kokkos; ------; https://github.com/kokkos/kokkos-kernels/tree/master/perf_test; https://github.com/kokkos/kokkos/tree/master/benchmarks. PolyMage; --------; https://github.com/bondhugula/polymage-benchmarks. PolyBench; ---------; https://sourceforge.net/projects/polybench/. A modified version of Polybench 3.2 is already presented in; SingleSource/Benchmarks/Polybench. A newer version 4.2.1 is available. High Performance Geometric Multigrid; ------------------------------------; https://crd.lbl.gov/departments/computer-science/PAR/research/hpgmg/. RAJA Performance Suite; ----------------------; https://github.com/LLNL/RAJAPerf. CORAL-2 Benchmarks; ------------------; https://asc.llnl.gov/coral-2-benchmarks/. Many of its programs have already been integrated in; MultiSource/Benchmarks/DOE-ProxyApps-C and; MultiSource/Benchmarks/DOE-ProxyApps-C++. * Nekbone; * QMCPack; * LAMMPS; * Kripke; * Quicksilver; * PENNANT; * Big Data Analytic Suite; * Deep Learning Suite; * Stream; * Stride; * ML/DL micro-benchmark; * Pynamic; * ACME; * VPIC; * Laghos; * Parallel Integer Sort; * Havoq. NWChem; ------; http://www.nwchem-sw.org/index.php/Benchmarks. TVM; ----; https://github.com/dmlc/tvm/tree/main/apps/benchmark. HydroBench; ----------; https://github.com/HydroBench/Hydro. ParRes; ------; https://github.com/ParRes/Kernels/tree/default/Cxx11. Applications/Libraries; ======================. GnuPG; -----; https://gnupg.org/. Blitz++; -------; https://sourceforge.net/projects/blitz/. FFmpeg; ------; https://ffmpeg.org/. FreePOOMA; ---------; http://www.nongnu.org/freepooma/. FTensors; --------; http://www.wlandry.net/Projects/FTensor. rawspeed; --------; https://github.com/darktable-org/rawspeed. Its test dataset is 756 MB in size, which is too large to be included; into th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:4601,integrat,integrated,4601,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,1,['integrat'],['integrated']
Deployability,"-----. JITLink passes are ``std::function<Error(LinkGraph&)>`` instances. They are free; to inspect and modify the given ``LinkGraph`` subject to the constraints of; whatever phase they are running in (see :ref:`generic_link_algorithm`). If a; pass returns ``Error::success()`` then linking continues. If a pass returns; a failure value then linking is stopped and the ``JITLinkContext`` is notified; that the link failed. Passes may be used by both JITLink backends (e.g. MachO/x86-64 implements GOT; and PLT construction as a pass), and external clients like; ``ObjectLinkingLayer::Plugin``. In combination with the open ``LinkGraph`` API, JITLink passes enable the; implementation of powerful new features. For example:. * Relaxation optimizations -- A pre-fixup pass can inspect GOT accesses and PLT; calls and identify situations where the addresses of the entry target and the; access are close enough to be accessed directly. In this case the pass can; rewrite the instruction stream of the containing block and update the fixup; edges to make the access direct. Code for this looks like:. .. code-block:: c++. Error relaxGOTEdges(LinkGraph &G) {; for (auto *B : G.blocks()); for (auto &E : B->edges()); if (E.getKind() == x86_64::GOTLoad) {; auto &GOTTarget = getGOTEntryTarget(E.getTarget());; if (isInRange(B.getFixupAddress(E), GOTTarget)) {; // Rewrite B.getContent() at fixup address from; // MOVQ to LEAQ. // Update edge target and kind.; E.setTarget(GOTTarget);; E.setKind(x86_64::PCRel32);; }; }. return Error::success();; }. * Metadata registration -- Post allocation passes can be used to record the; address range of sections in the target. This can be used to register the; metadata (e.g exception handling frames, language metadata) in the target; once memory has been finalized. .. code-block:: c++. Error registerEHFrameSection(LinkGraph &G) {; if (auto *Sec = G.findSectionByName(""__eh_frame"")) {; SectionRange SR(*Sec);; registerEHFrameSection(SR.getStart(), SR.getEnd());; }.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:23812,update,update,23812,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['update'],['update']
Deployability,"----. * Upgrade cppyy-cling to 6.18.2; * Various patches to upstream's pre-compiled header generation and use; * Instantiate templates with larger integer types if argument values require; * Improve cppyy.interactive and partially enable it on PyPy, IPython, etc.; * Let ``__overload__`` be more flexible in signature matching; * Make list filtering of dir(cppyy.gbl) on Windows same as Linux/Mac; * Extended documentation. 2019-08-18: 1.5.0; -----------------. * Upgrade cppyy-cling to 6.18.0; * Allow python-derived classes to be used in templates; * Stricter template resolution and better caching/performance; * Detailed memory management for make_shared and shared_ptr; * Two-way memory management for cross-inherited objects; * Reduced memory footprint of proxy objects in most common cases; * Allow implicit conversion from a tuple of arguments; * Data set on namespaces reflected on C++ even if data not yet bound; * Generalized resolution of binary operators in wrapper generation; * Proper naming of arguments in namespaces for ``std::function<>``; * Cover more cases of STL-liker iterators; * Allow ``std::vector`` initialization with a list of constructor arguments; * Consistent naming of ``__cppname__`` to ``__cpp_name__``; * Added ``__set_lifeline__`` attribute to overloads; * Fixes to the cmake fragments for Ubuntu; * Fixes linker errors on Windows in some configurations; * Support C++ naming of typedef of bool types; * Basic views of 2D arrays of builtin types; * Extended documentation. 2019-07-01 : 1.4.12; -------------------. * Automatic conversion of python functions to ``std::function`` arguments; * Fix for templated operators that can map to different python names; * Fix on p3 crash when setting a detailed exception during exception handling; * Fix lookup of ``std::nullopt``; * Fix bug that prevented certain templated constructors from being considered; * Support for enum values as data members on ""enum class"" enums; * Support for implicit conversion when passing ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:18515,configurat,configurations,18515,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,1,['configurat'],['configurations']
Deployability,"---. Some changes are too significant for just a code review. Changes that should; change the LLVM Language Reference (e.g., adding new target-independent; intrinsics), adding language extensions in Clang, and so on, require an RFC; (Request for Comment) email on the project's ``*-dev`` mailing list first. For; changes that promise significant impact on users and/or downstream code bases,; reviewers can request an RFC achieving consensus before proceeding with code; review. That having been said, posting initial patches can help with; discussions on an RFC. Code-Review Workflow; ====================. Code review can be an iterative process, which continues until the patch is; ready to be committed. Specifically, once a patch is sent out for review, it; needs an explicit approval before it is committed. Do not assume silent; approval, or solicit objections to a patch with a deadline. Acknowledge All Reviewer Feedback; ---------------------------------. All comments by reviewers should be acknowledged by the patch author. It is; generally expected that suggested changes will be incorporated into a future; revision of the patch unless the author and/or other reviewers can articulate a; good reason to do otherwise (and then the reviewers must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:5016,patch,patch,5016,interpreter/llvm-project/llvm/docs/CodeReview.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst,1,['patch'],['patch']
Deployability,"--. This section describes a few administrative tasks that need to be done for the; release process to begin. Specifically, it involves:. * Updating version numbers,. * Creating the release branch, and. * Tagging release candidates for the release team to begin testing. Create Release Branch; ^^^^^^^^^^^^^^^^^^^^^. Branch the Git trunk using the following procedure:. #. Remind developers that the release branching is imminent and to refrain from; committing patches that might break the build. E.g., new features, large; patches for works in progress, an overhaul of the type system, an exciting; new TableGen feature, etc. #. Verify that the current git trunk is in decent shape by; examining nightly tester and buildbot results. #. Bump the version in trunk to N.0.0git and tag the commit with llvmorg-N-init.; If ``X`` is the version to be released, then ``N`` is ``X + 1``. ::. $ git tag -sa llvmorg-N-init. #. Clear the release notes in trunk. #. Create the release branch from the last known good revision from before the; version bump. The branch's name is release/X.x where ``X`` is the major version; number and ``x`` is just the letter ``x``. #. On the newly-created release branch, immediately bump the version; to X.1.0git (where ``X`` is the major version of the branch.). #. All tags and branches need to be created in both the llvm/llvm-project and; llvm/llvm-test-suite repos. Update LLVM Version; ^^^^^^^^^^^^^^^^^^^. After creating the LLVM release branch, update the release branches'; version with the script in ``llvm/utils/release/bump-version.py``. Tagging the LLVM Release Candidates; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Tag release candidates:. ::. $ git tag -sa llvmorg-X.Y.Z-rcN. The Release Manager must supply pre-packaged source tarballs for users. This can; be done with the export.sh script in utils/release. Tarballs, release binaries, or any other release artifacts must be uploaded to; GitHub. This can be done using the github-upload-release.py script in utils",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:4162,release,release,4162,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['release'],['release']
Deployability,"-4,4);; h1->FillRandom(""gaus"",20000);; h1->SetFillColor(kRed);; hs->Add(h1);. TH1F *h2 = new TH1F(""h2"",""h2"",10,-4,4);; h2->FillRandom(""gaus"",15000);; h2->SetFillColor(kBlue);; hs->Add(h2);. TH1F *h3 = new TH1F(""h3"",""h3"",10,-4,4);; h3->FillRandom(""gaus"",10000);; h3->SetFillColor(kGreen);; hs->Add(h3);. hs->Draw(""nostackb"");; return cst0;; }. ```; ![NOSTACKB plot example](nostackb.png ""NOSTACKB plot example""). ## GUI Libraries. ### TGTextViewostream. - A new `TGTextViewostream` class has been added. It is a text viewer widget and is a specialization of `TGTextView` and `std::ostream`. It uses a `TGTextViewStreamBuf`, which inherits from `std::streambuf`, allowing to stream text directly to the text view in a `cout` - like fashion. A new tutorial showing how to use the `TGTextViewostream` widget has also been added. ## 2D Graphics Libraries. ### TText. - The character position was not correct with the Cocoa backend.; (see https://sft.its.cern.ch/jira/browse/ROOT-6561); - Interactive update of `TText` position did not work in NDC mode.; (se https://sft.its.cern.ch/jira/browse/ROOT-7284). ### TLegend. - Use the new `TStyle` global attribute `gStyle->GetLegendTextSize()` to set the; legend item text size. If this value is 0 and if the text size directly set on; the `TLegend` object is also 0, then the text size is automatically computed to; fit the legend box. If `gStyle->GetLegendTextSize()` is non equal to 0 and if; text size directly set on the `TLegend` object is 0, then the `gStyle` value is; used to draw the legend text. If the text size directly set on the `TLegend`; object is not null, then it is used to draw the legend text. ### TTexDump. - The hollow fill style was not rendered correctly.; (see https://sft.its.cern.ch/jira/browse/ROOT-6841); - Better line width matching with screen and pdf output.; - Text color was ignored. It was always black.; - Text color was ignored. It was always black.; - The underscore `_` produced an error outside the TeX math context.; -",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:20474,update,update,20474,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['update'],['update']
Deployability,"->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5162,release,release,5162,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,2,"['integrat', 'release']","['integrators', 'release']"
Deployability,"-Wno-dev -DCMAKE_CXX_STANDARD=17 -DLLVM_ENABLE_EH=0 -DLLVM_ENABLE_RTTI=0 -DLLVM_ENABLE_TERMINFO=0 -DLLVM_ENABLE_ASSERTIONS=0 -Dminimal=ON -Druntime_cxxmodules=OFF -Dbuiltin_zlib=ON -Dbuiltin_cling=ON -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_INSTALL_PREFIX=<path to environment python site-packages>; $ make -j <N> install. where the ``cmake`` command needs to be given the full path to; `site-packages/cppyy_backend` in the virtual environment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to pypi.org and creating a local ""clean"" build environment from the; cached or remote wheels.; Instead, by skipping PEP 517, the local installation will be used.; This is imperative if there was a change in public headers or if the version; of ``cppyy-cling`` was locally updated and is thus not available on PyPI. Upgrading ``CPyCppyy`` (if on CPython; it's not needed for PyPy) and ``cppyy``; is very similar::. $ git clone https://github.com/wlav/CPyCppyy.git; $ cd CPyCppyy; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Just like ``cppyy-cling``, ``CPyCppyy`` has ``cmake`` scripts which are the; recommended way for development, as incremental builds are faster::. $ mkdir build; $ cmake ../CPyCppyy; $ make -j <N>. then simply point the ``PYTHONPATH`` envar to the `build` directory above to; pick up the local `cppyy.so",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:5521,install,install,5521,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,1,['install'],['install']
Deployability,"-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any P",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:19589,configurat,configurations,19589,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['configurat'],['configurations']
Deployability,"-block:: json. ""type"": {; ""qualType"": ""foo"",; ""desugaredQualType"": ""foo""; }. which will now be dumped as just:. .. code-block:: json. ""type"": {; ""qualType"": ""foo""; }. Clang Frontend Potentially Breaking Changes; -------------------------------------------; - Target OS macros extension; A new Clang extension (see :ref:`here <target_os_detail>`) is enabled for; Darwin (Apple platform) targets. Clang now defines ``TARGET_OS_*`` macros for; these targets, which could break existing code bases with improper checks for; the ``TARGET_OS_`` macros. For example, existing checks might fail to include; the ``TargetConditionals.h`` header from Apple SDKs and therefore leaving the; macros undefined and guarded code unexercised. Affected code should be checked to see if it's still intended for the specific; target and fixed accordingly. The extension can be turned off by the option ``-fno-define-target-os-macros``; as a workaround. What's New in Clang |release|?; ==============================; Some of the major new features and improvements to Clang are listed; here. Generic improvements to Clang as a whole or to its underlying; infrastructure are described first, followed by language-specific; sections with improvements to Clang's support for those languages. C++ Language Changes; --------------------. C++20 Feature Support; ^^^^^^^^^^^^^^^^^^^^^; - Implemented `P1907R1 <https://wg21.link/P1907R1>`_ which extends allowed non-type template argument; kinds with e.g. floating point values and pointers and references to subobjects.; This feature is still experimental. Accordingly, ``__cpp_nontype_template_args`` was not updated.; However, its support can be tested with ``__has_extension(cxx_generalized_nttp)``. - Clang won't perform ODR checks for decls in the global module fragment any; more to ease the implementation and improve the user's using experience.; This follows the MSVC's behavior. Users interested in testing the more strict; behavior can use the flag '-Xclang -fno-skip-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:8389,release,release,8389,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['release'],['release']
Deployability,"-deb-tag DEB_TAG] [--rpm-tag RPM_TAG] [--nsis-tag NSIS_TAG]; [--dmg-tag DMG_TAG] [--with-llvm-url WITH_LLVM_URL]; [--with-clang-url WITH_CLANG_URL]; [--with-cling-url WITH_CLING_URL] [--no-test]; [--create-dev-env CREATE_DEV_ENV] [--with-workdir WITH_WORKDIR]; [--make-proper MAKE_PROPER]. Cling Packaging Tool. optional arguments:; -h, --help show this help message and exit; -c, --check-requirements; Check if packages required by the script are installed; --current-dev CURRENT_DEV; Package the latest development snapshot in one of; these formats: tar | deb | nsis | rpm | dmg | pkg; --last-stable LAST_STABLE; Package the last stable snapshot in one of these; formats: tar | deb | nsis | rpm | dmg | pkg; --tarball-tag TARBALL_TAG; Package the snapshot of a given tag in a tarball; (.tar.bz2); --deb-tag DEB_TAG Package the snapshot of a given tag in a Debian; package (.deb); --rpm-tag RPM_TAG Package the snapshot of a given tag in an RPM package; (.rpm); --nsis-tag NSIS_TAG Package the snapshot of a given tag in an NSIS; installer (.exe); --dmg-tag DMG_TAG Package the snapshot of a given tag in a DMG package; (.dmg); --with-llvm-url WITH_LLVM_URL; Specify an alternate URL of LLVM repo; --with-clang-url WITH_CLANG_URL; Specify an alternate URL of Clang repo; --with-cling-url WITH_CLING_URL; Specify an alternate URL of Cling repo; --no-test Do not run test suite of Cling; --create-dev-env CREATE_DEV_ENV; Set up a release/debug environment; --with-workdir WITH_WORKDIR; Specify an alternate working directory for CPT; --make-proper MAKE_PROPER; Internal option to support calls from build system. ```; If you want CPT to build a package by detecting your platform automatically,; use the value 'pkg'.; ```sh; ./cpt.py --current-dev=pkg; ```; or; ```sh; ./cpt.py --last-stable=pkg; ```; ### Overriding Default Variables; There are a select number of variables which can be set to make CPT work; differently. This eliminates the need to manually edit the script.; You can overrride varia",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:7444,install,installer,7444,interpreter/cling/tools/packaging/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md,1,['install'],['installer']
Deployability,"-exec TLS model (called small local-exec).; * XCOFF toc-data peephole optimization and bug fixes.; * Move less often used __ehinfo TOC entries to the end of the TOC section.; * Fixed problems when the AIX libunwind unwinds starting from a signal handler; and the function that raised the signal happens to be a leaf function that; shares the stack frame with its caller or a leaf function that does not store; the stack frame backchain. Changes to the RISC-V Backend; -----------------------------. * The Zfa extension version was upgraded to 1.0 and is no longer experimental.; * Zihintntl extension version was upgraded to 1.0 and is no longer experimental.; * Intrinsics were added for Zk*, Zbb, and Zbc. See https://github.com/riscv-non-isa/riscv-c-api-doc/blob/master/riscv-c-api.md#scalar-bit-manipulation-extension-intrinsics; * Default ABI with F but without D was changed to ilp32f for RV32 and to lp64f for RV64.; * The Zvbb, Zvbc, Zvkb, Zvkg, Zvkn, Zvknc, Zvkned, Zvkng, Zvknha, Zvknhb, Zvks,; Zvksc, Zvksed, Zvksg, Zvksh, and Zvkt extension version was upgraded to 1.0; and is no longer experimental. However, the C intrinsics for these extensions; are still experimental. To use the C intrinsics for these extensions,; ``-menable-experimental-extensions`` needs to be passed to Clang.; * XSfcie extension and SiFive CSRs and instructions that were associated with; it have been removed. None of these CSRs and instructions were part of; ""SiFive Custom Instruction Extension"" as SiFive defines it. The LLVM project; needs to work with SiFive to define and document real extension names for; individual CSRs and instructions.; * ``-mcpu=sifive-p450`` was added.; * CodeGen of RV32E/RV64E was supported experimentally.; * CodeGen of ilp32e/lp64e was supported experimentally.; * Support was added for the Ziccif, Ziccrse, Ziccamoa, Zicclsm, Za64rs, Za128rs; and Zic64b extensions which were introduced as a part of the RISC-V Profiles; specification.; * The Smepmp 1.0 extension is now suppo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst:7384,upgrade,upgraded,7384,interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,1,['upgrade'],['upgraded']
Deployability,"-facility):. ``` {.bash}; git clone git://github.com/dberzano/virtual-analysis-facility.git /dest/dir; ```. The client will be found in `/dest/dir/client/bin/vaf-enter`: it is; convenient to add it to the `$PATH` so that the users might simply start; it by typing `vaf-enter`. ### Install the experiment's configuration files system-wide. A system administrator might find convenient to install the experiment; environment scripts system-wide. Configuration scripts for LHC experiments are shipped with the VAF; client and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/dest/dir/etc`; directory like this:. ``` {.bash}; rsync -a /dest/dir/client/config-samples/<experiment_name>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:7941,configurat,configuration,7941,proof/doc/confman/UsingVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md,2,['configurat'],['configuration']
Deployability,"-format will always break after a Json array ``[``; otherwise it will scan until the closing ``]`` to determine if it should; add newlines between elements (prettier compatible). .. note::. This is currently only for formatting JSON. .. code-block:: c++. true: false:; [ vs. [1, 2, 3, 4]; 1,; 2,; 3,; 4; ]. .. _BreakBeforeBinaryOperators:. **BreakBeforeBinaryOperators** (``BinaryOperatorStyle``) :versionbadge:`clang-format 3.6` :ref:`¶ <BreakBeforeBinaryOperators>`; The way to wrap binary operators. Possible values:. * ``BOS_None`` (in configuration: ``None``); Break after operators. .. code-block:: c++. LooooooooooongType loooooooooooooooooooooongVariable =; someLooooooooooooooooongFunction();. bool value = aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa +; aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa ==; aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa &&; aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa >; ccccccccccccccccccccccccccccccccccccccccc;. * ``BOS_NonAssignment`` (in configuration: ``NonAssignment``); Break before operators that aren't assignments. .. code-block:: c++. LooooooooooongType loooooooooooooooooooooongVariable =; someLooooooooooooooooongFunction();. bool value = aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa; + aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa; == aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa; && aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa; > ccccccccccccccccccccccccccccccccccccccccc;. * ``BOS_All`` (in configuration: ``All``); Break before operators. .. code-block:: c++. LooooooooooongType loooooooooooooooooooooongVariable; = someLooooooooooooooooongFunction();. bool value = aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa; + aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa; == aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa; && aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa; > ccccccccccccccccccccccccccccccccccccccccc;. .. _BreakBeforeBraces:. **BreakBeforeBraces** (``BraceBreakingStyle``) :versionbadge:`clang-format 3.7` :ref:`¶ <BreakBeforeBraces>`; The brace breaking style to u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:46664,configurat,configuration,46664,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will be built alongside clang, and; the git integration can be run from; ``clang/tools/clang-format/git-clang-format``. The LLVM project has migrated to GitHub Pull Requests as its review process.; We still have an active :ref:`Phabricator <phabricator-reviews>`; instance for the duration of the migration. If you want to contribute to LLVM; now, please use GitHub. For more information about the workflow of using GitHub; Pull Requests see our :ref:`GitHub <github-reviews>` documentation. To make sure the right people see your patch, please select suitable reviewers; and add them to your patch when requesting a review. Suitable reviewers are the; code owner (see CODE_OWNERS.txt) and other people doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:3134,update,update,3134,interpreter/llvm-project/llvm/docs/Contributing.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst,1,['update'],['update']
Deployability,"-indentation for GCC: Some LLVM source files; # are too large.; set(cxx_flags_prev ${CMAKE_CXX_FLAGS}); if(CMAKE_CXX_COMPILER_ID STREQUAL ""GNU""); set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -Wno-misleading-indentation""); endif(). if(builtin_llvm); # Since debug builds of LLVM are quite large, we want to be able; # to control the build types of ROOT and LLVM independently. The; # logic below is to make that possible. LLVM is built in Release; # mode unless a different build type is chosen via LLVM_BUILD_TYPE. if(NOT DEFINED LLVM_BUILD_TYPE); set(LLVM_BUILD_TYPE Release CACHE STRING ""Build type used for LLVM""); endif(). message(STATUS ""Building LLVM in '${LLVM_BUILD_TYPE}' mode.""). if(NOT DEFINED LLVM_ENABLE_ASSERTIONS); if(CMAKE_BUILD_TYPE MATCHES ""Debug""; OR LLVM_BUILD_TYPE MATCHES ""(Debug|RelWithDebInfo)""); set(LLVM_ENABLE_ASSERTIONS TRUE); else(); set(LLVM_ENABLE_ASSERTIONS FALSE); endif(); endif(). # Multi-configuration generators ignore CMAKE_BUILD_TYPE, so; # in that case we set the flags for all configurations to the; # flags of the build type assigned to LLVM_BUILD_TYPE. if(MSVC OR XCODE); string(TOUPPER ${LLVM_BUILD_TYPE} LLVM_BUILD_TYPE); set(LLVM_C_FLAGS ${CMAKE_C_FLAGS_${LLVM_BUILD_TYPE}}); set(LLVM_CXX_FLAGS ${CMAKE_CXX_FLAGS_${LLVM_BUILD_TYPE}}); # On Windows, use the same compiler flags than ROOT and not; # the other way around; if(NOT MSVC); foreach(CONFIG ${CMAKE_CONFIGURATION_TYPES}); string(TOUPPER ${CONFIG} CONFIG); set(CMAKE_C_FLAGS_${CONFIG} ${LLVM_C_FLAGS}); set(CMAKE_CXX_FLAGS_${CONFIG} ${LLVM_CXX_FLAGS}); endforeach(); endif(); elseif(NOT LLVM_BUILD_TYPE STREQUAL CMAKE_BUILD_TYPE); set(CMAKE_BUILD_TYPE ${LLVM_BUILD_TYPE}); endif(). set(BUILD_SHARED_LIBS FALSE). #---Remove the inherited include_directories(); set_directory_properties(PROPERTIES INCLUDE_DIRECTORIES """"). set(LLVM_ENABLE_PROJECTS ""clang"" CACHE STRING """"). #---Add the sub-directory excluding all the targets from all-----------------------------------------; if(CMAKE_GENERATOR MATCHES ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/CMakeLists.txt:10045,configurat,configuration,10045,interpreter/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/CMakeLists.txt,2,['configurat'],"['configuration', 'configurations']"
Deployability,"-libc-resource-headers"" ${llvm_libc_wrapper_files}); add_header_target(""openmp-resource-headers"" ${openmp_wrapper_files}); add_header_target(""windows-resource-headers"" ${windows_only_files}); add_header_target(""utility-resource-headers"" ${utility_files}). get_clang_resource_dir(header_install_dir SUBDIR include). #############################################################; # Install rules for the catch-all clang-resource-headers target; install(; FILES ${files} ${generated_files}; DESTINATION ${header_install_dir}; COMPONENT clang-resource-headers). install(; FILES ${cuda_wrapper_files}; DESTINATION ${header_install_dir}/cuda_wrappers; COMPONENT clang-resource-headers). install(; FILES ${cuda_wrapper_bits_files}; DESTINATION ${header_install_dir}/cuda_wrappers/bits; COMPONENT clang-resource-headers). install(; FILES ${ppc_wrapper_files}; DESTINATION ${header_install_dir}/ppc_wrappers; COMPONENT clang-resource-headers). install(; FILES ${llvm_libc_wrapper_files}; DESTINATION ${header_install_dir}/llvm_libc_wrappers; COMPONENT clang-resource-headers). install(; FILES ${openmp_wrapper_files}; DESTINATION ${header_install_dir}/openmp_wrappers; COMPONENT clang-resource-headers). #############################################################; # Install rules for separate header lists; install(; FILES ${core_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT core-resource-headers). install(; FILES ${arm_common_files} ${arm_common_generated_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT arm-common-resource-headers). install(; FILES ${arm_only_files} ${arm_only_generated_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT arm-resource-headers). install(; FILES ${aarch64_only_files} ${aarch64_only_generated_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT aarch64-resource-headers). install(; FILES ${cuda_wrapper_files}; DESTINATION ${header_install_dir}/cuda_wrappers; EXCLUDE_FROM_ALL; COMPON",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt:12589,install,install,12589,interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,1,['install'],['install']
Deployability,"-merge testing*. When a user uploads a patch to Phabricator, Phabricator triggers the checks and; then displays the results. This way bugs in a patch are contained during the; code review stage and do not pollute the main branch. Our goal with pre-merge testing is to report most true problems while strongly; minimizing the number of false positive reports. Our goal is that problems; reported are always actionable. If you notice a false positive, please report; it so that we can identify the cause. If you notice issues or have an idea on how to improve pre-merge checks, please; `create a new issue <https://github.com/google/llvm-premerge-checks/issues/new>`_; or give a ❤️ to an existing one. Requirements; ^^^^^^^^^^^^. To get a patch on Phabricator tested, the build server must be able to apply the; patch to the checked out git repository. Please make sure that either:. * You set a git hash as ``sourceControlBaseRevision`` in Phabricator which is; available on the GitHub repository,; * **or** you define the dependencies of your patch in Phabricator,; * **or** your patch can be applied to the main branch. Only then can the build server apply the patch locally and run the builds and; tests. Accessing build results; ^^^^^^^^^^^^^^^^^^^^^^^; Phabricator will automatically trigger a build for every new patch you upload or; modify. Phabricator shows the build results at the top of the entry. Clicking on; the links (in the red box) will show more details:. .. image:: Phabricator_premerge_results.png. The CI will compile and run tests, run clang-format and clang-tidy on lines; changed. If a unit test failed, this is shown below the build status. You can also expand; the unit test to see the details:. .. image:: Phabricator_premerge_unit_tests.png. Opting Out; ^^^^^^^^^^. In case you want to opt-out entirely of pre-merge testing, add yourself to the; `OPT OUT project <https://reviews.llvm.org/project/view/83/>`_. If you decide; to opt-out, please let us know why, so we might b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst:11626,patch,patch,11626,interpreter/llvm-project/llvm/docs/Phabricator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst,2,['patch'],['patch']
Deployability,"-native atomic operations (if you see link errors; referring to ``__atomic_*`` functions). Unwind library; --------------. The unwind library provides a family of ``_Unwind_*`` functions implementing; the language-neutral stack unwinding portion of the Itanium C++ ABI; (`Level I <https://itanium-cxx-abi.github.io/cxx-abi/abi-eh.html#base-abi>`_).; It is a dependency of the C++ ABI library, and sometimes is a dependency; of other runtimes. libunwind (LLVM); ^^^^^^^^^^^^^^^^. LLVM's unwinder library is part of the llvm-project git repository. To; build it, pass ``-DLLVM_ENABLE_RUNTIMES=libunwind`` to the cmake invocation. If using libc++abi, you may need to configure it to use libunwind; rather than libgcc_s by passing ``-DLIBCXXABI_USE_LLVM_UNWINDER=YES``; to ``cmake``. If libc++abi is configured to use some version of; libunwind, that library will be implicitly linked into binaries that; link to libc++abi. libgcc_s (GNU); ^^^^^^^^^^^^^^. libgcc_s has an integrated unwinder, and does not need an external unwind; library to be provided. libunwind (nongnu.org); ^^^^^^^^^^^^^^^^^^^^^^. This is another implementation of the libunwind specification.; See `libunwind (nongnu.org) <https://www.nongnu.org/libunwind>`_. libunwind (PathScale); ^^^^^^^^^^^^^^^^^^^^^. This is another implementation of the libunwind specification.; See `libunwind (pathscale) <https://github.com/pathscale/libunwind>`_. Sanitizer runtime; -----------------. The instrumentation added by Clang's sanitizers (``-fsanitize=...``) implicitly; makes calls to a runtime library, in order to maintain side state about the; execution of the program and to issue diagnostic messages when a problem is; detected. The only supported implementation of these runtimes is provided by LLVM's; compiler-rt, and the relevant portion of that library; (``libclang_rt.<sanitizer>.<arch>.a``); will be implicitly linked when linking with a ``-fsanitize=...`` flag. C standard library; ------------------. Clang supports a wide varie",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Toolchain.rst:9142,integrat,integrated,9142,interpreter/llvm-project/clang/docs/Toolchain.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Toolchain.rst,1,['integrat'],['integrated']
Deployability,-resource-headers). install(; FILES ${riscv_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT riscv-resource-headers). install(; FILES ${systemz_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT systemz-resource-headers). install(; FILES ${ve_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT ve-resource-headers). install(; FILES ${webassembly_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT webassembly-resource-headers). install(; FILES ${x86_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT x86-resource-headers). if(NOT CLANG_ENABLE_HLSL); set(EXCLUDE_HLSL EXCLUDE_FROM_ALL); endif(). install(; FILES ${hlsl_h}; DESTINATION ${header_install_dir}; ${EXCLUDE_HLSL}; COMPONENT hlsl-resource-headers). install(; FILES ${hlsl_subdir_files}; DESTINATION ${header_install_dir}/hlsl; ${EXCLUDE_HLSL}; COMPONENT hlsl-resource-headers). install(; FILES ${opencl_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT opencl-resource-headers). install(; FILES ${openmp_wrapper_files}; DESTINATION ${header_install_dir}/openmp_wrappers; EXCLUDE_FROM_ALL; COMPONENT openmp-resource-headers). install(; FILES ${openmp_wrapper_files}; DESTINATION ${header_install_dir}/openmp_wrappers; EXCLUDE_FROM_ALL; COMPONENT openmp-resource-headers). install(; FILES ${utility_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT utility-resource-headers). install(; FILES ${windows_only_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT windows-resource-headers); #############################################################. if (NOT LLVM_ENABLE_IDE); add_llvm_install_targets(install-clang-resource-headers; DEPENDS clang-resource-headers; COMPONENT clang-resource-headers). add_llvm_install_targets(install-core-resource-headers; DEPENDS core-resource-headers; COMPONENT core-resource-headers); add_llvm_install_targets(install-arm-common-resource-header,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt:15868,install,install,15868,interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,1,['install'],['install']
Deployability,"-web:. Requesting a review via the web interface; -----------------------------------------. The tool to create and review patches in Phabricator is called; *Differential*. Note that you can upload patches created through git, but using `arc` on the; command line (see previous section) is preferred: it adds more metadata to; Phabricator which are useful for the pre-merge testing system and for; propagating attribution on commits when someone else has to push it for you. To make reviews easier, please always include **as much context as; possible** with your diff! Don't worry, Phabricator; will automatically send a diff with a smaller context in the review; email, but having the full file in the web interface will help the; reviewer understand your code. To get a full diff, use one of the following commands (or just use Arcanist; to upload your patch):. * ``git show HEAD -U999999 > mypatch.patch``; * ``git diff -U999999 @{u} > mypatch.patch``; * ``git diff HEAD~1 -U999999 > mypatch.patch``. Before uploading your patch, please make sure it is formatted properly, as; described in :ref:`How to Submit a Patch <format patches>`. To upload a new patch:. * Click *Differential*.; * Click *+ Create Diff*.; * Paste the text diff or browse to the patch file. Leave this first Repository; field blank. (We'll fill in the Repository later, when sending the review.); Click *Create Diff*.; * Leave the drop down on *Create a new Revision...* and click *Continue*.; * Enter a descriptive title and summary. The title and summary are usually; in the form of a :ref:`commit message <commit messages>`.; * Add reviewers (see below for advice). (If you set the Repository field; correctly, llvm-commits or cfe-commits will be subscribed automatically;; otherwise, you will have to manually subscribe them.); * In the Repository field, enter ""rG LLVM Github Monorepo"".; * Click *Save*. To submit an updated patch:. * Click *Differential*.; * Click *+ Create Diff*.; * Paste the updated diff or browse ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst:3451,patch,patch,3451,interpreter/llvm-project/llvm/docs/Phabricator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst,1,['patch'],['patch']
Deployability,". !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so the above example is only representative, not literal). The; ``ImplicitNullChecks`` pass runs during codegen, if; ``-enable-implicit-null-checks`` is passed to ``llc``. The ``ImplicitNullChecks`` pass adds entries to the; ``__llvm_faultmaps`` section described above as needed. ``make.implicit`` metadata; --------------------------. Making null checks implicit is an aggressive optimization, and it can; be a net performance pessimization if too many memory operations end; up faulting because of it. A language runtime typically needs to; ensure that only a negligible number of implicit null checks actually; fault once the application has reached a steady state. A standard way; of doing this is by healing failed implicit null checks into explicit; null checks via code patching or recompilation. It follows that there; are two requirements an explicit null check needs to satisfy for it to; be profitable to convert it to an implicit null check:. 1. The case where the pointer is actually null (i.e. the ""failing""; case) is extremely rare. 2. The failing path heals the implicit null check into an explicit; null check so that the application does not repeatedly page; fault. The frontend is expected to mark branches that satisfy (1) and (2); using a ``!make.implicit`` metadata node (the actual content of the; metadata node is ignored). Only branches that are marked with; ``!make.implicit`` metadata are considered as candidates for; conversion into implicit null checks. (Note that while we could deal with (1) using profiling data, dealing; with (2) requires some information not present in branch profiles.); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:3594,patch,patching,3594,interpreter/llvm-project/llvm/docs/FaultMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst,1,['patch'],['patching']
Deployability,". # Re-run tests and make sure nothing broke.; ninja check. # Push your changes to your fork branch, be mindful of; # your remotes here, if you don't remember what points to your; # fork, use git remote -v to see. Usually origin points to your; # fork and upstream to llvm/llvm-project; git push origin my_change. Before merging the PR, it is recommended that you rebase locally and re-run test; checks:. ::. # Add upstream as a remote (if you don't have it already); git remote add upstream https://github.com/llvm/llvm-project.git. # Make sure you have all the latest changes; git fetch upstream && git rebase -i upstream/main. # Make sure tests pass with latest changes and your change; ninja check. # Push the rebased changes to your fork.; git push origin my_change -f. Once your PR is approved, rebased, and tests are passing, click `Squash and; Merge` on your PR in the GitHub web interface. See more in-depth information about how to contribute in the following documentation:. * :doc:`Contributing`; * :doc:`MyFirstTypoFix`. Releases; ========. Backporting Fixes to the Release Branches; -----------------------------------------; You can use special comments on issues to make backport requests for the; release branches. This is done by making a comment containing one of the; following commands on any issue that has been added to one of the ""X.Y.Z Release""; milestones. ::. /cherry-pick <commit> <commit> <...>. This command takes one or more git commit hashes as arguments and will attempt; to cherry-pick the commit(s) to the release branch. If the commit(s) fail to; apply cleanly, then a comment with a link to the failing job will be added to; the issue. If the commit(s) do apply cleanly, then a pull request will; be created with the specified commits. ::. /branch <owner>/<repo>/<branch>. This command will create a pull request against the latest release branch using; the <branch> from the <owner>/<repo> repository. <branch> cannot contain any; forward slash '/' characters.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitHub.rst:12259,release,release,12259,interpreter/llvm-project/llvm/docs/GitHub.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitHub.rst,3,['release'],['release']
Deployability,". ## 3D Graphics Libraries. ### Gl in Pad. - Transparency is now implemented for ""GL in Pad"" (`gStyle->SetCanvasPreferGL(1)`).; - Introduce the flag `CanvasPreferGL` in `rootrc.in`. So OpenGL can be use by; default. The default value for this flag is 0 (no OpenGL).; - Fix size issues with the FTGL text.; - Make `TMathText` work with FTGL; - Linear and radial color gradients are implemented for ""GL in Pad""; (only a simple radial color gradient),; see also the notes about TLinearGradient and TRadialGradient classes.; - ""GL in Pad"" and gl hist painters were updated to support Retina displays; (OS X + Cocoa).; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v600/index.md:561,update,updated,561,graf3d/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v600/index.md,1,['update'],['updated']
Deployability,". ## I/O Libraries. ### I/O Behavior change. #### Classes with custom streamer. Classes for which a Streamer function was externally provided are no longer; split; they were split in v5 if the dictionary was generated via rootcint but; were not split if the dictionary was generated via genreflex. Classes with a custom Streamer function and classes with an older, non StreamerInfo; based automatic streamer are also no longer split. To force the splitting of those classes, thus by-passing the custom Streamer,; when storing the object in a TTree and in a collection object, use:. ``` {.cpp}; TClass::GetClass(classname)->SetCanSplit(true);; ```. ### I/O Schema Checksum. The algorithm used to calculate a single number giving an indication on whether; the schema layout has changed (i.e. if two StreamerInfo are equivalent) have; been update to. - Use the normalized name for the types (i.e. two different spelling of the same; name will lead to the same checksum); - Take into account the base classes' checksum in the derived class checksum;; this is necessary to properly support base classes during memberwise streaming. The algorithm that checks whether two StreamerInfo are equal even-though their; checksum is different has been significantly enhanced in particular to also; check the base classes. ### TFileMerger. - Added possibility to merge only a list of objects/folders from the; input files, specified by name, \; or to skip them from merging. This is fully integrated with the new; PartialMerge(flags) schema. \; Usage: \; The names of the objects to be merged or skipped have to be; specified using the interface:. ``` {.cpp}; TFileMerger::AddObjectNames(const char *names); ```. This method can be called several times to add object names. Several; names can be added with one call separated by single blancs (no; blanc at the end). Directory names are accepted, applying the; merging selection to all content. Two new options are being; supported for partial merging:. ``` {.cpp}; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md:837,update,update,837,io/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md,1,['update'],['update']
Deployability,. ## Python Bindings. The Python bindings are fully supported in ROOT 6. ## Ruby Bindings. The Ruby bindings have not been ported yet to the new interpreter interface in ROOT 6. We hope to have this fixed in a future release. ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/doc/v600/index.md:217,release,release,217,bindings/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/doc/v600/index.md,1,['release'],['release']
Deployability,". $ clang -include-pch test.h.pch test.c -o test. The ``clang`` driver will check if the PCH file ``test.h.pch`` is; available; if so, the contents of ``test.h`` (and the files it includes); will be processed from the PCH file. Otherwise, Clang will report an error. .. note::. Clang does *not* automatically use PCH files for headers that are directly; included within a source file or indirectly via :option:`-include`.; For example:. .. code-block:: console. $ clang -x c-header test.h -o test.h.pch; $ cat test.c; #include ""test.h""; $ clang test.c -o test. In this example, ``clang`` will not automatically use the PCH file for; ``test.h`` since ``test.h`` was included directly in the source file and not; specified on the command line using ``-include-pch``. Relocatable PCH Files; ^^^^^^^^^^^^^^^^^^^^^. It is sometimes necessary to build a precompiled header from headers; that are not yet in their final, installed locations. For example, one; might build a precompiled header within the build tree that is then; meant to be installed alongside the headers. Clang permits the creation; of ""relocatable"" precompiled headers, which are built with a given path; (into the build directory) and can later be used from an installed; location. To build a relocatable precompiled header, place your headers into a; subdirectory whose structure mimics the installed location. For example,; if you want to build a precompiled header for the header ``mylib.h``; that will be installed into ``/usr/include``, create a subdirectory; ``build/usr/include`` and place the header ``mylib.h`` into that; subdirectory. If ``mylib.h`` depends on other headers, then they can be; stored within ``build/usr/include`` in a way that mimics the installed; location. Building a relocatable precompiled header requires two additional; arguments. First, pass the ``--relocatable-pch`` flag to indicate that; the resulting PCH file should be relocatable. Second, pass; ``-isysroot /path/to/build``, which makes all inclu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:48096,install,installed,48096,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['install'],['installed']
Deployability,". .. _SpacesInParens:. **SpacesInParens** (``SpacesInParensStyle``) :versionbadge:`clang-format 17` :ref:`¶ <SpacesInParens>`; Defines in which cases spaces will be inserted after ``(`` and before; ``)``. Possible values:. * ``SIPO_Never`` (in configuration: ``Never``); Never put a space in parentheses. .. code-block:: c++. void f() {; if(true) {; f();; }; }. * ``SIPO_Custom`` (in configuration: ``Custom``); Configure each individual space in parentheses in; `SpacesInParensOptions`. .. _SpacesInParensOptions:. **SpacesInParensOptions** (``SpacesInParensCustom``) :versionbadge:`clang-format 17` :ref:`¶ <SpacesInParensOptions>`; Control of individual spaces in parentheses. If ``SpacesInParens`` is set to ``Custom``, use this to specify; how each individual space in parentheses case should be handled.; Otherwise, this is ignored. .. code-block:: yaml. # Example of usage:; SpacesInParens: Custom; SpacesInParensOptions:; InConditionalStatements: true; InEmptyParentheses: true. Nested configuration flags:. Precise control over the spacing in parentheses. .. code-block:: c++. # Should be declared this way:; SpacesInParens: Custom; SpacesInParensOptions:; InConditionalStatements: true; Other: true. * ``bool InConditionalStatements`` Put a space in parentheses only inside conditional statements; (``for/if/while/switch...``). .. code-block:: c++. true: false:; if ( a ) { ... } vs. if (a) { ... }; while ( i < 5 ) { ... } while (i < 5) { ... }. * ``bool InCStyleCasts`` Put a space in C style casts. .. code-block:: c++. true: false:; x = ( int32 )y vs. x = (int32)y. * ``bool InEmptyParentheses`` Put a space in parentheses only if the parentheses are empty i.e. '()'. .. code-block:: c++. true: false:; void f( ) { vs. void f() {; int x[] = {foo( ), bar( )}; int x[] = {foo(), bar()};; if (true) { if (true) {; f( ); f();; } }; } }. * ``bool Other`` Put a space in parentheses not covered by preceding options. .. code-block:: c++. true: false:; t f( Deleted & ) & = delete; vs. t f(Dele",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:126998,configurat,configuration,126998,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,". .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left uns",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:1476,install,installed,1476,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,1,['install'],['installed']
Deployability,". .. code-block:: c++. true: false:; int a[ 5 ]; vs. int a[5];; std::unique_ptr<int[]> foo() {} // Won't be affected. .. _Standard:. **Standard** (``LanguageStandard``) :versionbadge:`clang-format 3.7` :ref:`¶ <Standard>`; Parse and format C++ constructs compatible with this standard. .. code-block:: c++. c++03: latest:; vector<set<int> > x; vs. vector<set<int>> x;. Possible values:. * ``LS_Cpp03`` (in configuration: ``c++03``); Parse and format as C++03.; ``Cpp03`` is a deprecated alias for ``c++03``. * ``LS_Cpp11`` (in configuration: ``c++11``); Parse and format as C++11. * ``LS_Cpp14`` (in configuration: ``c++14``); Parse and format as C++14. * ``LS_Cpp17`` (in configuration: ``c++17``); Parse and format as C++17. * ``LS_Cpp20`` (in configuration: ``c++20``); Parse and format as C++20. * ``LS_Latest`` (in configuration: ``Latest``); Parse and format using the latest supported language version.; ``Cpp11`` is a deprecated alias for ``Latest``. * ``LS_Auto`` (in configuration: ``Auto``); Automatic detection based on the input. .. _StatementAttributeLikeMacros:. **StatementAttributeLikeMacros** (``List of Strings``) :versionbadge:`clang-format 12` :ref:`¶ <StatementAttributeLikeMacros>`; Macros which are ignored in front of a statement, as if they were an; attribute. So that they are not parsed as identifier, for example for Qts; emit. .. code-block:: c++. AlignConsecutiveDeclarations: true; StatementAttributeLikeMacros: []; unsigned char data = 'x';; emit signal(data); // This is parsed as variable declaration. AlignConsecutiveDeclarations: true; StatementAttributeLikeMacros: [emit]; unsigned char data = 'x';; emit signal(data); // Now it's fine again. .. _StatementMacros:. **StatementMacros** (``List of Strings``) :versionbadge:`clang-format 8` :ref:`¶ <StatementMacros>`; A vector of macros that should be interpreted as complete; statements. Typical macros are expressions, and require a semi-colon to be; added; sometimes this is not the case, and this allows to mak",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:129718,configurat,configuration,129718,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,". // create MIGRAD minimizer; MnMigrad migrad(theFCN, upar);. // minimize; FunctionMinimum min = migrad();. // output; std::cout<<""minimum: ""<<min<<std::endl;; }. {; // demonstrate full interaction with parameters over subsequent; // minimizations. // create Minuit parameters with names; MnUserParameters upar;; upar.add(""mean"", mean, 0.1);; upar.add(""sigma"", rms, 0.1);; upar.add(""area"", area, 0.1);. // access parameter by name to set limits...; upar.setLimits(""mean"", mean-0.01, mean+0.01);. // ... or access parameter by index; upar.setLimits(1, rms-0.1, rms+0.1);. // create Migrad minimizer; MnMigrad migrad(theFCN, upar);. // fix a parameter...; migrad.fix(""mean"");. // ... and minimize; FunctionMinimum min = migrad();. // output; std::cout<<""minimum: ""<<min<<std::endl;. // release a parameter...; migrad.release(""mean"");. // ... and fix another one; migrad.fix(1);. // and minimize again; FunctionMinimum min1 = migrad();. // output; std::cout<<""minimum1: ""<<min1<<std::endl;. // release the parameter...; migrad.release(1);. // ... and minimize with all three parameters; // (still with limits!); FunctionMinimum min2 = migrad();. // output; std::cout<<""minimum2: ""<<min2<<std::endl;. // remove all limits on parameters...; migrad.removeLimits(""mean"");; migrad.removeLimits(""sigma"");. // ... and minimize again with all three parameters; // (now without limits!); FunctionMinimum min3 = migrad();. // output; std::cout<<""minimum3: ""<<min3<<std::endl;; }. {; // demonstrate MINOS error analysis. // create Minuit parameters with names; MnUserParameters upar;; upar.add(""mean"", mean, 0.1);; upar.add(""sigma"", rms, 0.1);; upar.add(""area"", area, 0.1);. // create Migrad minimizer; MnMigrad migrad(theFCN, upar);. // minimize; FunctionMinimum min = migrad();. // create MINOS error factory; MnMinos minos(theFCN, min);. {; // 1-sigma MINOS errors; std::pair<double,double> e0 = minos(0);; std::pair<double,double> e1 = minos(1);; std::pair<double,double> e2 = minos(2);. // output; std::cout<<",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:80624,release,release,80624,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['release'],['release']
Deployability,". 3D Graphics Primitives; TPolyMarker3D. TPolyMarker3D::PaintH3 entered an infinite loop in case of huge; bin content . OpenGL; Major changes. GL in Pad: It is now possible to save a PadGL into a binary image file; (gif, png, jpg etc...).; Improve behaviour of TGLEventHandler and make it consistent:. Process only one mouse button (the first pressed) at any; time. ; All selections take effect on button release.; Precsion modifiers Shift and Control can thus be pressed at any; time for controlling rate of rotation, translation or zooming. Add support for multiple secondary-selection and partial; highlightning of secondary-selectable sub-items. This requires new; signals to be emitted from TGLViewer:. virtual void MouseOver (TObject *obj, UInt_t state); // *SIGNAL*; virtual void ReMouseOver(TObject *obj, UInt_t state); // *SIGNAL*; virtual void UnMouseOver(TObject *obj, UInt_t state); // *SIGNAL*. TGLEventHandler emits them when needed. For example see TEveDigitSet; and its sub-classes TEveQuadSet and TEveBoxSet. It is now possible to enforce all tesselations of geometry shapes; to only use triangles via static function void; TGLFaceSet::EnforceTriangles(). This is needed to export TGeo; shapes and CSG meshes to external triangle-mesh libraries that can; not handle arbitrary polygons.; Add support for full-scene anti-aliasing (the actual benefits; depend on graphics card / driver). It is controlled via rootrc,; e.g.:. OpenGL.Framebuffer.Multisample: 4. Minor changes. Extend configurability of GL event-handler to allow inversion of; controls from scene-centric to viewer-centric. The following rootrc; variables control the behaviour:. OpenGL.EventHandler.ViewerCentricControls: 1; OpenGL.EventHandler.ArrowKeyFactor: -1.0; OpenGL.EventHandler.MouseDragFactor: -1.0; OpenGL.EventHandler.MouseWheelFactor: -1.0. Add camera auto-rotation support. Controls are available from the; ""Extras"" tab of TGLViewer GUI editor. Implemented in class; TGLAutoRotator, can be sub-classed and at",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v528/index.html:405,release,release,405,graf3d/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v528/index.html,1,['release'],['release']
Deployability,". ; Networking. NET; ; TWebFile. Several pptimizations in TWebFile improving performance especially for TTree::Map() by about 35%. This has been achieved with a better caching strategy for request strings (especially avoiding to recalculate the auth base64 encoding), and with a drastic optimization in reading the response headers.; Fixes in the counting of the bytes read. TWebSystem. New implementation of TSystem allowing to use TSystem::AccessPathName() and GetPathInfo() to check if a web file exists and to get its size. Directory browsing is not available yet. NETX; ; TXNetFile. Several fixes and optimisations, mainly in the use of the cache; Fix an offset issue affecting the use of the cache with files in archives. TXNetSystem. A few optimizations in the use of retry mechanism, path locality checks, file online checks. XROOTD. Import a new version of XROOTD (20091202-0509); ; Fixes in bulk prepare and sync readv operations; Add support for 'make install' / 'make uninstall' and; other improvements in configure.classic; Several improvements / fixes:; ; reduced memory and CPU consumption;; extreme cp optimizations;; windows porting; new cache policies on the client side; new listing features implemented recently in the 'cns' module.; optimizations in cmsd and cnsd (performance improvements); support for openssl 1.0.0 (required by Fedora 12). Support for if/else if/else/fi constructs; Several portability fixes; ; Support 32-bit builds with icc on 64-bit platforms; Improved detection of libreadline and lib(n)curses. Increase the flexibility for configuring with an external xrootd; ; Add standard switches to disentangle lib and inc dirs;       --with-xrootd-incdir=<path_to dir_containing_XrdVersion.hh>;       --with-xrootd-libdir=<path_to_dir_containing_xrootd_plugins_and_libs>; ; When; passing a global xrootd dir with --with-xrootd, check both; src/XrdVersion.hh and include/xrootd/XrdVersion.hh so that both build; and install distributions are supported. Fix a problem ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v526/index.html:963,install,install,963,net/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v526/index.html,1,['install'],['install']
Deployability,". All libraries that you compile as part of your build will be; cross-compiled to your target, and your build system will probably; find them in the right place. But all dependencies that are; normally checked against (like ``libxml`` or ``libz`` etc) will match; against the host platform, not the target. So, if the build system is not aware that you want to cross-compile; your code, it will get every dependency wrong, and your compilation; will fail during build time, not configure time. Also, finding the libraries for your target are not as easy; as for your host machine. There aren't many cross-libraries available; as packages to most OS's, so you'll have to either cross-compile them; from source, or download the package for your target platform,; extract the libraries and headers, put them in specific directories; and add ``-I`` and ``-L`` pointing to them. Also, some libraries have different dependencies on different targets,; so configuration tools to find dependencies in the host can get the; list wrong for the target platform. This means that the configuration; of your build can get things wrong when setting their own library; paths, and you'll have to augment it via additional flags (configure,; Make, CMake, etc). Multilibs; ---------. When you want to cross-compile to more than one configuration, for; example hard-float-ARM and soft-float-ARM, you'll have to have multiple; copies of your libraries and (possibly) headers. Some Linux distributions have support for Multilib, which handle that; for you in an easier way, but if you're not careful and, for instance,; forget to specify ``-ccc-gcc-name armv7l-linux-gnueabihf-gcc`` (which; uses hard-float), Clang will pick the ``armv7l-linux-gnueabi-ld``; (which uses soft-float) and linker errors will happen. The same is true if you're compiling for different environments, like; ``gnueabi`` and ``androideabi``, and might even link and run, but produce; run-time errors, which are much harder to track down and fix.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CrossCompilation.rst:8659,configurat,configuration,8659,interpreter/llvm-project/clang/docs/CrossCompilation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CrossCompilation.rst,2,['configurat'],['configuration']
Deployability,". Clang - C Programming Language Status. C Support in Clang. Clang implements the following published and upcoming ISO C standards:. Language Standard; Flag; Available in Clang?. C89; -std=c89; Yes. C99; -std=c99; Almost certainly. C11; -std=c11; Probably. C17; -std=c17; Maybe?. C23; -std=c23; Partial. The implementation status for C99, C11, C17, and C23 are currently under; investigation. Any proposal whose status in Clang is currently unknown; will be marked in magenta.; The Clang community is continually striving to improve C standards; compliance between releases by submitting and tracking; C Defect Reports and implementing resolutions as; they become available.; The LLVM bug tracker uses; the ""c"", ""c99"", ""c11"", ""c17"", and ""c23"" labels to track known bugs with Clang's language; conformance.; C89 implementation status; Clang implements all of the ISO 9899:1990 (C89) standard.; You can use Clang in C89 mode with the -std=c89 or -std=c90 options.; C99 implementation status; Clang implements a significant portion of the ISO 9899:1999 (C99) standard, but the status of individual proposals is still under investigation.; Note, the list of C99 features comes from the C99 committee draft. Not all C99 documents are publicly available, so the documents referenced in this section may be inaccurate, unknown, or not linked. You can use Clang in C99 mode with the -std=c99 option. List of features and minimum Clang version with support. Language Feature; C99 Proposal; Available in Clang?. restricted character set support via digraphs and <iso646.h>; Unknown; Unknown. more precise aliasing rules via effective type; Unknown; Unknown. restricted pointers; N448; Unknown. variable length arrays; N683; Yes. flexible array members; Unknown; Yes. static and type qualifiers in parameter array declarators; Unknown; Yes. more precise aliasing rules via effective type; Unknown; Unknown. complex and imaginary support in <complex.h>. N620; Unknown. N638; Unknown. N657; Unknown. N694; Unknown.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_status.html:565,release,releases,565,interpreter/llvm-project/clang/www/c_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_status.html,1,['release'],['releases']
Deployability,". Clang - C++ Programming Language Status. C++ Support in Clang. Clang implements the following published and upcoming ISO C++ standards:. Language Standard; Flag; Available in Clang?. C++2c; -std=c++2c; Partial. C++23; -std=c++23; Partial. C++20; -std=c++20; Partial. C++17; -std=c++17; Clang 5. C++14; -std=c++14; Clang 3.4. C++11; -std=c++11; Clang 3.3. C++98 / C++03; -std=c++98; Yes (other than export). The Clang community is continually striving to improve C++ standards; compliance between releases by submitting and tracking C++ Defect Reports and implementing resolutions; as they become available.; Experimental work is also under way to implement C++ Technical; Specifications that will help drive the future of the C++ programming; language.; The LLVM bug tracker uses; the ""c++"" label, as well as mode-specific labels such as ""c++11"", ""c++14"",; and so on, to track known bugs with Clang's language conformance.; C++2c implementation status. Clang has support for some of the features of the C++ standard following; C++23, informally referred to as C++26.; You can use Clang in C++2c mode with the -std=c++2c option. List of features and minimum Clang version with support. Language Feature; C++26 Proposal; Available in Clang?. Remove undefined behavior from lexing; P2621R2 (DR); Clang 3.3. Making non-encodable string literals ill-formed; P1854R4 (DR); Clang 14. Unevaluated strings; P2361R6; Clang 18. Add @, $, and ` to the basic character set; P2558R2; Yes. constexpr cast from void*; P2738R1; Clang 17. On the ignorability of standard attributes; P2552R3 (DR); No. Static storage for braced initializers; P2752R3 (DR); No. User-generated static_assert messages; P2741R3; Clang 17. Placeholder variables with no name; P2169R4; Clang 18. Template parameter initialization; P2308R1 (DR); Clang 18. Pack Indexing; P2662R3; No. Remove Deprecated Arithmetic Conversion on Enumerations; P2864R2; Clang 18. C++23 implementation status. Clang has support for some of the features of the ISO",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_status.html:498,release,releases,498,interpreter/llvm-project/clang/www/cxx_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_status.html,1,['release'],['releases']
Deployability,". Clang - Get Involved. Getting Involved with the Clang Project; Once you have checked out and built clang and; played around with it, you might be wondering what you can do to make it better; and contribute to its development. Alternatively, maybe you just want to follow; the development of the project to see it progress. Contribute. See the hacking document for information on how; to author patches. Follow what's going on; Clang is a subproject of the LLVM Project; and has a Discourse forum and mailing list:. Clang Frontend Discourse forum -; This forum is for discussions related to Clang (questions and answers, design; discussions, RFCs, etc).; Discord chat - Real-time chat for; discussions related to Clang (primarily for questions and answers).; Regular meetings are held on the. first and third Wednesday of each month to discuss C and C++; standards-related activities happening within the Clang community. These; meetings are a way to coordinate efforts between implementers and provide; updates on how standards activities are going. Meeting agendas and minutes are; available. here. Clang office hours -; People within the community hold dedicated office hours at different points; during the month, which is a great way opportunity for getting questions; answered, having more in-depth design discussions, or learning about what's; going on in the community in general.; cfe-commits; - Historical record of commits to Clang and contains early community patch; review commentary. The most common way to talk with other developers on the project is through; the Clang Frontend Discourse forum; . The clang forum is a very friendly place and we welcome newcomers. The; forum is archived so you can browse through previous discussions or follow; development on the web if you prefer.; If you're looking for something to work on, check out our Open Projects page or look through the LLVM bug tracker.; Contributing Extensions to Clang; Clang is designed to support experimentation,; all",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/get_involved.html:396,patch,patches,396,interpreter/llvm-project/clang/www/get_involved.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/get_involved.html,2,"['patch', 'update']","['patches', 'updates']"
Deployability,". Clang - Getting Started. Getting Started: Building and Running Clang; This page gives you the shortest path to checking out Clang and demos a few; options. This should get you up and running with the minimum of muss and fuss.; If you like what you see, please consider getting; involved with the Clang community. If you run into problems, please file; bugs on the LLVM bug tracker.; Release Clang Versions; Clang is released as part of regular LLVM releases. You can download the release versions from https://llvm.org/releases/.; Clang is also provided in all major BSD or GNU/Linux distributions as part of their respective packaging systems. From Xcode 4.2, Clang is the default compiler for Mac OS X.; Building Clang and Working with the Code; On Unix-like Systems; If you would like to check out and build Clang, the current procedure is as; follows:. Get the required tools.; ; See; ; Getting Started with the LLVM System - Requirements.; Note also that Python is needed for running the test suite.; Get it at: ; https://www.python.org/downloads/; Standard build process uses CMake. Get it at:; ; https://cmake.org/download/. Check out the LLVM project:; ; Change directory to where you want the llvm directory placed.; git clone https://github.com/llvm/llvm-project.git; The above command is very slow. It can be made faster by creating a shallow clone. Shallow clone saves storage and speeds up the checkout time. This is done by using the command:; ; git clone --depth=1 https://github.com/llvm/llvm-project.git (using this only the latest version of llvm can be built); For normal users looking to just compile, this command works fine. But if someone later becomes a contributor, since they can't push code from a shallow clone, it needs to be converted into a full clone:; ; cd llvm-project; git fetch --unshallow. Build LLVM and Clang:; ; cd llvm-project; mkdir build (in-tree build is not supported); cd build; This builds both LLVM and Clang in release mode. Alternatively, if; you ne",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/get_started.html:418,release,released,418,interpreter/llvm-project/clang/www/get_started.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/get_started.html,4,['release'],"['release', 'released', 'releases']"
Deployability,". Clang C Language Family Frontend for LLVM. Clang: a C language family frontend for LLVM. The Clang project provides a language front-end and tooling infrastructure; for languages in the C language family (C, C++, Objective C/C++, OpenCL,; CUDA, and RenderScript) for the LLVM; project. Both a GCC-compatible compiler driver (clang) and an; MSVC-compatible compiler driver (clang-cl.exe) are provided. You; can get and build the source today. Features and Goals. Some of the goals for the project include the following:; End-User Features:. Fast compiles and low memory use; Expressive diagnostics (examples); GCC & MSVC compatibility. Utility and; Applications:. Modular library based architecture; Support diverse clients (refactoring, static analysis, code generation,; etc.); Allow tight integration with IDEs; Use the LLVM 'Apache 2'; License. Internal Design and; Implementation:. A real-world, production quality compiler; A simple and hackable code base; A single unified parser for C, Objective C, C++, and Objective C++; Conformance with C/C++/ObjC and their variants. Of course this is only a rough outline of the goals and features of; Clang. To get a true sense of what it is all about, see the Features section, which breaks; each of these down and explains them in more detail. Why?. Development of the new front-end was started out of a need; for a compiler that allows better diagnostics, better integration with; IDEs, a license that is compatible with commercial products, and a; nimble compiler that is easy to develop and maintain. All of these were; motivations for starting work on a new front-end that could; meet these needs. Current Status. Clang is considered to; be a production quality C, Objective-C, C++ and Objective-C++ compiler when; targeting any target supported by LLVM. As example, Clang is used in; production to build performance-critical software like Chrome or Firefox.; If you are looking for source analysis or source-to-source; transformation tools, Clang",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/index.html:793,integrat,integration,793,interpreter/llvm-project/clang/www/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/index.html,1,['integrat'],['integration']
Deployability,". Clang provides a mechanism to add the standard extension pragma; ``OPENCL EXTENSION`` by setting a dedicated flag in the extension list entry of; ``OpenCLExtensions.def``. Note that there is no default behavior for the; standard extension pragmas as it is not specified (for the standards up to and; including version 3.0) in a sufficient level of detail and, therefore,; there is no default functionality provided by clang. Pragmas without detailed information of their behavior (e.g. an explanation of; changes it triggers in the parsing) should not be added to clang. Moreover, the; pragmas should provide useful functionality to the user. For example, such; functionality should address a practical use case and not be redundant i.e.; cannot be achieved using existing features. Note that some legacy extensions (published prior to OpenCL 3.0) still; provide some non-conformant functionality for pragmas e.g. add diagnostics on; the use of types or functions. This functionality is not guaranteed to remain in; future releases. However, any future changes should not affect backward; compatibility. .. _opencl_addrsp:. Address spaces attribute; ------------------------. Clang has arbitrary address space support using the ``address_space(N)``; attribute, where ``N`` is an integer number in the range specified in the; Clang source code. This addresses spaces can be used along with the OpenCL; address spaces however when such addresses spaces converted to/from OpenCL; address spaces the behavior is not governed by OpenCL specification. An OpenCL implementation provides a list of standard address spaces using; keywords: ``private``, ``local``, ``global``, and ``generic``. In the AST and; in the IR each of the address spaces will be represented by unique number; provided in the Clang source code. The specific IDs for an address space do not; have to match between the AST and the IR. Typically in the AST address space; numbers represent logical segments while in the IR they represen",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenCLSupport.rst:11442,release,releases,11442,interpreter/llvm-project/clang/docs/OpenCLSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenCLSupport.rst,1,['release'],['releases']
Deployability,". Cling. Build Instructions; This page is shows how to download and build the project cling as a standalone C++ interpreter in few steps..; Build script . You can download and run this build script. Building with CMake ; Prerequisites; See Getting Started with the LLVM System - Requirements. Note also that Python is needed for running the test suite.; . And extra for Windows; cmake - http://www.cmake.org/cmake/resources/software.html; Python - http://www.python.org/download/; GnuWin32 Tools - http://getgnuwin32.sourceforge.net/; Visual Studio - VS Express should work as well. Start by checking out llvm, clang and cling: . git clone http://root.cern.ch/git/llvm.git src; cd src; git checkout cling-patches; cd tools; git clone http://root.cern.ch/git/cling.git; git clone http://root.cern.ch/git/clang.git; cd clang; git checkout cling-patches. Now follow the procedure described at the clang web page for ./configure --enable-cxx11; make- or CMake-based build instructions. ; Don't forget to make install. You will get a binary called cling: that's your interactive C++ interpreter!. Then use CMake to configure & build cling: . mkdir obj; cd obj; cmake -DCMAKE_INSTALL_PREFIX=[Install Path] ..\src; cmake --build . --config [Release/Debug] --target cling. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/build.html:705,patch,patches,705,interpreter/cling/www/build.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/build.html,3,"['install', 'patch']","['install', 'patches']"
Deployability,". Cling. Collaborate With Us . Every contribution is considered a donation and its copyright and any other; related rights become exclusive ownership of the person who merged the code or; in any other case the main developers of the ""Cling Project"". We warmly welcome external contributions to the Cling! By providing code,; you agree to transfer your copyright on the code to the ""Cling project"".; Of course you will be duly credited and your name will appear on the; contributors page, the release notes, and in the; CREDITS; shipped with every binary and source distribution. The copyright transfer is; necessary for us to be able to effectively defend the project in case of; litigation. You can send us a patch or a pull request with Github, provided that you follow these two simple rules:. Make sure you follow the Cling coding conventions in your code.; . Make sure you provide a set of tests for your feature/bug fix.; . Often it is useful to contact us first to discuss the code you want to develop or the bug you want to fix. Picking up an Idea . We maintain a set of ""ideas"" for talented scientists and developers to pick up. An ""idea"" can be a sketch of a development project, a functionality, a missing feature we would like to see in our tool.; A list that we propose is the following:. Ideas. Extending and improving the multiline input mode - The multiline mode has to figure out automatically whether the user's input is still incomplete. For example ""if (a < 0) {"" is not fully completed input. Cling should'n try to process the line but to be smart enough to understand that it should wait for continuation. Currently cling switches multiline mode only when there is trailing ""{"". It has to be extended to detect trailing +, unbalanced ',"" and so on. Implementing error recovery verifier - One of the most important parts in cling is the error recovery. The error recovery takes care of reverting clang's internal structures on error in the user input. For instance, user types int",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/contribute.html:492,release,release,492,interpreter/cling/www/contribute.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/contribute.html,2,"['patch', 'release']","['patch', 'release']"
Deployability,". Cling. Grammar; Cling is able to parse everything that clang can. Current clang status can be found here. At the moment, there are use cases only for C++ that's why cling is best in working with C++. Clang has support of C, objC, objC++ and we are looking forward to having more use-cases and extend our tool in that direction.; Cling has internal commands, which can change its behavior at runtime. Those commands usually start with dot (.):; .I <path> - Adds an include path;; .x <filename> - #include-s the filename; and calls function called filename(); ; .L <libname> - Loads libname or #include-s the libname if libname is file;; .@ - Cancels the multiline input;; .printAST - (DEBUG ONLY) Turns on the printing of the compiler's abstract syntax tree (AST);; .dynamicExtensions - Turns on cling's dynamic extensions. This in turn enables the dynamic lookup and the late resolving of the identifier. With that option cling tries to heal the compile-time failed lookups at runtime;. Details; Command line. The interactive prompt supports an emacs-like command line editor, just like bash terminal, which makes it easy to integrate and use. Cling uses TextInput and doesn't depend on ncurses.; . Autocompletion should be coming soon!; . ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/use.html:1127,integrat,integrate,1127,interpreter/cling/www/use.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/use.html,1,['integrat'],['integrate']
Deployability,". Cling. Jupyter Kernel ; Cling is now integrated with the Jupyter technology through the Jupyter kernel. You can take advantage of creating a Jupyter notebook on top of runtime interpretation, you have runtime visualisation!; . See also the [example notebook in cling's github repo](https://github.com/root-project/cling/blob/master/tools/Jupyter/kernel/cling.ipynb).; Prerequisites. ; ipykernel ≥ 4.0. Install ; To install the kernel with sources in src/tools/cling:. export PATH=/path/to/cling/bin:$PATH; cd src/tools/cling/tools/Jupyter/kernel/. pip install -e .; # or: pip3 install -e . # register the kernelspec:; jupyter-kernelspec install [--user] cling; # or: jupyter kernelspec install [--user] cling. To run it:. jupyter-notebook; # or: jupyter notebook. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/jupyter.html:39,integrat,integrated,39,interpreter/cling/www/jupyter.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/jupyter.html,6,"['install', 'integrat']","['install', 'integrated']"
Deployability,". Core Libraries; ROOT Error Handlers; There is a new rootrc variable which allows to control the; installation of the ROOT error handlers. By default the handlers; are activated:. Root.ErrorHandlers: 1. but setting the value to 0 result in no error handlers being installed; and the originals remaining in place. This can be useful if ROOT is used in; conjunction with other frameworks that already installed their own handlers. TString; TString::Hash() and thus also TMath::Hash() now use MurmurHash3_x64_128; from http://code.google.com/p/smhasher/ which is public domain.; To accelerate the hash in the case of pointers even further, pointers (and same-sized texts) are hashed using a simple bitwise xor.; This dramatically increases the hash performance for long texts, and still by a factor 5 for pointers.; The pointer case is most visible for certain I/O operations (TExMap).; TColor; Add the method SetAlpha() to set the alpha value (transparency; level) for an existing color. TStyle. The default font set by gStyle->SetLegendFont() was ignored. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v534/index.html:99,install,installation,99,core/doc/v534/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v534/index.html,3,['install'],"['installation', 'installed']"
Deployability,". Core. The ROOT source directory has been drastically reorganized and simplified.; Each source directory containing the code for a single library or plugin,; were all in the same top level directory, without logical grouping.; This made it difficult to see which libraries were related and belonged; together. In the new structure we've added a set of meta directories; that are used to group the sources of related libraries, and that also; reflects the ROOT team work package structure.; Note, the name and number of libraries has not been changed.; This new structure also facilitates the maintaining of the release notes; and other documentation items per meta package. On Linux, MacOS X and Windows, there is no need anymore to define the; environment variable ROOTSYS. Internally ROOTSYS is set depending on the; location of the ROOT libraries. ROOTSYS was never needed when ROOT was; configured using --prefix. On MacOS X when configure'ing with --enable-rpath (and not specifying; --prefix) the installation does not need (DY)LD_LIBRARY_PATH to be set; anymore. The installation is completely relocatable. The (DY)LD_LIBRARY_PATH; is determined relative to the location of the root executable. On Windows .root files are now associated with the most recently executed; ROOT installation, i.e. run ROOT once and .root files open with ROOT. Class TMessageHandler derives now from TQObject and does emit signals.; This allows for easier usage of this class. In this release xrootd and libAfterImage are managed in Subversion; via so called ""vendor branches"". This is completely transparent; except for people who do directly use svn. You will get the message:. $ svn up; svn: Failed to add directory 'xrootd/src/xrootd': object of the same name already exists; $ rm -rf xrootd/src/xrootd; $ svn up; svn: Failed to add directory 'asimage/src/libAfterImage': object of the same name already exists; $ rm -rf asimage/src/libAfterImage; $ svn up. Port to gcc 4.3.1. This version of gcc is much stric",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v520/index.html:612,release,release,612,core/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v520/index.html,2,"['install', 'release']","['installation', 'release']"
Deployability,". FAQ and How to Deal with Common False Positives. FAQ and How to Deal with Common False Positives. How do I tell the analyzer that I do not want the bug being; reported here since my custom error handler will safely end the execution before; the bug is reached?; The analyzer reports a null dereference, but I know that the; pointer is never null. How can I tell the analyzer that a pointer can never be; null?; How do I tell the static analyzer that I don't care about a specific dead store?; How do I tell the static analyzer that I don't care about a specific unused instance variable in Objective C?; How do I tell the static analyzer that I don't care about a specific unlocalized string?; How do I tell the analyzer that my instance variable does not need to be released in -dealloc under Manual Retain/Release?; How do I decide whether a method's return type should be _Nullable or _Nonnull?; How do I tell the analyzer that I am intentionally violating nullability?; The analyzer assumes that a loop body is never entered. How can I tell it that the loop body will be entered at least once?; How can I suppress a specific analyzer warning?; How can I selectively exclude code the analyzer examines?. Q: How do I tell the analyzer that I do not want the bug being; reported here since my custom error handler will safely end the execution before; the bug is reached?. You can tell the analyzer that this path is unreachable by teaching it about your custom assertion handlers. For example, you can modify the code segment as following. void customAssert() __attribute__((analyzer_noreturn));; int foo(int *b) {; if (!b); customAssert();; return *b;; }; Q: The analyzer reports a null dereference, but I know that the; pointer is never null. How can I tell the analyzer that a pointer can never be; null?. The reason the analyzer often thinks that a pointer can be null is because the preceding code checked compared it against null. So if you are absolutely sure that it cannot be null, remove",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/faq.html:769,release,released,769,interpreter/llvm-project/clang/www/analyzer/faq.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/faq.html,1,['release'],['released']
Deployability,". For a large, ATLAS-style Higgs-->bb workspace with > 100 systematic uncertainties and more than 10 channels, the run time for converting histograms to a fit model decreases by a factor 11 to 12. ### Faster, STL-like Collections in RooFit; RooFit's collections `RooArgSet` and `RooArgList` have been made more STL-like. The underlying implementation used to be the `RooLinkedList`, but now both collections work with `std::vector`. The collections have an STL-like interface concerning iterators such that iterations over the two collections that looked like; ```; TIterator* depIter = intDepList.createIterator() ;; RooAbsArg* arg;; while((arg=(RooAbsArg*)depIter->Next())) {; ...; }; delete depIter;; ```; now look like:; ```; for (auto arg : intDepList) {; ...; }; ```; Depending on how many elements are iterated, RooFit will be between 10 and 20% faster if the new iterators are used. Heavily using old iterators might slow it down by 5 to 10%. Iterators in key classes have been updated, such that many workflows in RooFit are 10 - 20% faster. #### Legacy iterators; The (three kinds) of legacy iterators in RooFit are still supported, such that old code will not break, but they are slower than `begin(), end()` and range-based for loops. **Important caveat**:; The old RooFit collections could be modified while iterating. The STL-like iterators do not support this (as for a *e.g.* std::vector)! Using the legacy iterators with the new collections (*i.e.* in existing code), mutating the collection is still possible in the following cases:; - Inserting/deleting elements **after** the current iterator.; - Changing an element at a position **other than** the current iterator; - **But not** inserting/deleting before/at the current iterator position. With a debug build (with assertions), the legacy iterators will check that the collection is not mutated. In a release build, elements might be skipped or be iterated twice. #### Moving away from the slower iterators; The legacy iterators",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:15565,update,updated,15565,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,1,['update'],['updated']
Deployability,". Forwards compatibility; ----------------------. As an author of a multilib configuration, it should be possible to design the; configuration in such a way that it is likely to work well with future Clang; versions. For example, if a future version of Clang is likely to add support; for newer versions of an architecture and the architecture is known to be; designed for backwards compatibility then it should be possible to express; compatibility for such architecture versions in the multilib configuration. Not GNU spec files; ------------------. The GNU spec files standard is large and complex and there's little desire to; import that complexity to LLVM. It's also heavily oriented towards processing; command line argument strings which is hard to do correctly, hence the large; amount of logic dedicated to that task in the Clang driver. While compatibility; with GNU would bring benefits, the cost in this case is deemed too high. Avoid re-inventing feature detection in the configuration; ---------------------------------------------------------. A large amount of logic in the Clang driver is dedicated to inferring which; architectural features are available based on the given command line options.; It is neither desirable nor practical to repeat such logic in each multilib; configuration. Instead the configuration should be able to benefit from the; heavy lifting Clang already does to detect features. Low maintenance; ---------------. Multilib is a relatively small feature in the scheme of things so supporting it; should accordingly take little time. Where possible this should be achieved by; implementing it in terms of existing features in the LLVM codebase. Minimal additional API surface; ------------------------------. The greater the API surface, the greater the difficulty of keeping it stable.; Where possible the additional API surface should be kept small by defining it; in relation to existing APIs. An example of this is keeping a simple; relationship between f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst:12071,configurat,configuration,12071,interpreter/llvm-project/clang/docs/Multilib.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst,1,['configurat'],['configuration']
Deployability,". GUI; TRootCanvas. In SetWindowSize the event queue is flushed to make sure; the window size change is really done. TRootContextMenu. When creating the dialog from the context menu, skip arguments that are pointers (but not char *) and have a default value. This should avoid confusing input fields in dialog.; Implemented online help in root dialogs (the dialog boxes used with contextual menus) via a new ""Online Help"" button. This opens a Root HTML browser at the right class/method location in the Root reference guide on the web.; The base url can be changed with the Browser.StartUrl option in system.rootrc (by default: http://root.cern.ch/root/html/ClassIndex.html); Added a small '?' on the right of the context menu entries, giving access to online help. TGMenu. Add possibility to add a right aligned shortcut by using a tab character ('\t') before the shortcut string, as shown below:; fMenuFile->AddEntry(""&Open...\tCtrl+O"", kOpenFile);; Use new way of adding right aligned shortcuts in the menu entries in most of the GUI classes using shortcuts in their menu. TGSlider. Added HandleConfigureNotify() to handle resizing events. New Browser. Automatically browse ROOT files if there is any open when starting the browser.; Correct system files manipulations (copy, rename, delete) and automatic update of the list tree. GUIHTML; TGHtmlBrowser. Added ability to display single picture from the web and to open pdf files with external viewer (Windows only); Implemented anchor navigation (e.g. http://root.cern.ch/root/html/TH1.html#TH1:Multiply). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/doc/v524/index.html:1309,update,update,1309,gui/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/doc/v524/index.html,1,['update'],['update']
Deployability,". GUI; TRootCanvas/TCanvas. Implement tooltip displaying information about the primitive below the mouse pointer in a canvas.; It is possible to enable/disable this optional feature with the ""Tooltip Info"" menu entry from the ""View"" menu of the canvas.; To change the default behaviour (off by default), a new option has been added in system.rootrc:; Canvas.ShowToolTips: false. TBrowser. Automatically switch to the tab containing the current canvas (if any) when e.g. drawing a histogram by double-clicking on its list tree item in a root file.; Automatically switch to (and update) the list of files in the file browser (left panel) when opening a ROOT file from the ""Open File"" menu. TGListView. Keyboard navigation is now fully working in the list view. TGMainFrame. Allow to save a snapshot of the GUI in a picture file. The supported formats are gif, jpg, png, tiff, and xpm. TGFileDialog. Allow to change directory by typing its name in the text entry field of the dialog. TProofProgressDialog. Added a speedometer widget (TGSpeedo) to display the processing rate; Added a check button to enable/disable smooth update of the speedometer (enabled by default). This could be useful in the case of slow displays (e.g. when using it via ssh); Several layout improvements. TRecorder. Improvements and consolidation of the cross-platform interoperability, allowing to record and replay sessions between different platforms with less side effects. NB: Using different OS/WM (Window Managers) and using different ROOT GUI settings (via e.g. system.rootrc) between recording and replaying may still produce a wrong behavior of the recorder.; New tutorial guitest_playback.C replaying a recorded session showing and validating the GUI (using guitest.C). GUI Builder; New features, new user interface; Several important features have been added to the builder, and its user interface has been redesigned.; Editing modes are now clearly distinguished with enabled and disabled layout mode. Possibility to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/doc/v526/index.html:577,update,update,577,gui/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/doc/v526/index.html,1,['update'],['update']
Deployability,". Geometry; . TGeoElement, TGeoIsotope ; New class TGeoIsotope inside the file TGeoElement.h/.cxx. This is done for compatibility with GEANT4 isotopes and elements. TGeoElement class now contains the number of nucleons and an array of possible isotopes (as in GEANT4). One can make isotopes of the same element:. TGeoIsotope *iso1 = new TGeoIsotope(""U235"", Z,N1,A1);. TGeoIsotope *iso2 = new TGeoIsotope(""U238"", Z,N2,A2);. then an element containing the 2 isotopes: . TGeoElement *elem = new TGeoElement(""U_nat"", ""U"", 2); elem->AddIsotope(iso1,abundance1_percent); elem->AddIsotope(iso2,abundance2_percent);. Then one can make normal materials based on such elements. Added getters for isotopes from elements, as well as an isotope table within TGeoElementTable with search method by name (and not supporting several isotopes with the same name). Existing material table updated to use the number of nucleons. Everything backward compatible. TGDMLParser ; Several fixes and support for new features:; Support for reading isotopes via the GDML parser. Interaction length now automatically computed using the algorithm from GEANT4. Fixed parsing of composite shapes. G4Ellipsoid is now supported in conversions.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/doc/v528/index.html:871,update,updated,871,geom/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/doc/v528/index.html,1,['update'],['updated']
Deployability,". Geometry; Improvement of the standard overlap checker. The previous method was checking points on the visual mesh of volume shape against all possible overlapping partners.; The new method checks more points (currently 1000, in future configurable) on the volume outline or surface. This minimizes the number of non-detectable overlap; configurations.; The interface to activate the new checking method is the same as before:; gGeoManager->CheckOverlaps(ovlp);; where ovlp is the overlap tolerance (default 0.01 cm); An example of overlap that was not detected before but is now:. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/doc/v522/index.html:338,configurat,configurations,338,geom/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/doc/v522/index.html,1,['configurat'],['configurations']
Deployability,". Graphical Output; PDF. The PDF file produced by the following macro was not readable by Acrobat; reader:; ; {; TCanvas* can = new TCanvas(""can"");; double margin = 1e-10;; can->Divide(2, 2, margin, margin);; TH1D* hist = new TH1D(""hist"" , """", 1, 0, 1);; hist->Draw();; can->SaveAs(""can.pdf"");; }; ; because Acrobat does not work when a PDF file contains reals with; exponents, which is the cavse with the file ""can.pdf"". This problem is; now fixed. Note that ""can.pdf"" could be read by ""ghostview"" and printed.; PDF file now use the fonts encoding WinAnsiEncoding. This allows; to print any characters with accent etc.. like on the screen. An similar; modification was done in the previous release for PostScript. SVG. Some SVG viewer need a more complete header: ""width"" and; ""height"" attributes; in the svg tag and a ""xml"" tag to start the file.; (Found by Hubert Degaudenzi <Hubert.Degaudenzi@cern.ch>). PostScript. Since the new font endocing (June release) the hyphen was longer than; before. Now fixed.; When drawn with an angle, the ""tilde"" character as an acceent was not; correctly placed in a PostScript file. For instance:. {; TCanvas *c1 = new TCanvas(""c1"", ""c1"",15,49,700,530);; TLatex *tex1 = new TLatex(0.5,0.5,""#tilde{C}"");; tex1->SetTextSize(0.2);; tex1->SetTextAngle(90);; tex1->Draw();; c1->Print(""tilde.ps"");; }. TASImage / libAfterImage. Synchronizing libAfterImage with Sasha'a latest version.; TASImage::Merge (const TImage im, const char op, Int_t x, Int_t y) ; with x and/or y not equal 0 did not clip the overlayed picture correctly.; Make sure a rectangle drawn will TAsimage::DrawRectangle appears; after calling gPad->Modified().; Images can be saved (canvas->Print) from within threads. Miscellaneous; TColor. CreateGradientColorTable now calls; TColor::InitializeColors(). This is needed because is some cases; TColor::InitializeColors() has not been called before and the; following erro messages were issued:; ; Warning in : color 1 already defined; Warning in : colo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v522/index.html:691,release,release,691,graf2d/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v522/index.html,2,['release'],['release']
Deployability,". Hacking on clang. Hacking on Clang. This document provides some hints for how to get started hacking; on Clang for developers who are new to the Clang and/or LLVM; codebases. Coding Standards; Developer Documentation; Debugging; Testing. Testing on Unix-like Systems; Testing using Visual Studio on Windows; Testing on the Command Line; Testing changes affecting libc++. Creating Patch Files; LLVM IR Generation. Coding Standards. Clang follows the; LLVM Coding; Standards. When submitting patches, please take care to follow these standards; and to match the style of the code to that present in Clang (for example, in; terms of indentation, bracing, and statement spacing).; Clang has a few additional coding standards:. cstdio is forbidden: library code should not output diagnostics; or other information using cstdio; debugging routines should; use llvm::errs(). Other uses of cstdio impose behavior; upon clients and block integrating Clang as a library. Libraries should; support raw_ostream based interfaces for textual; output. See Coding; Standards. Developer Documentation. Both Clang and LLVM use doxygen to provide API documentation. Their; respective web pages (generated nightly) are here:. Clang; LLVM. For work on the LLVM IR generation, the LLVM assembly language; reference manual is; also useful. Debugging. Inspecting data structures in a debugger:. Many LLVM and Clang data structures provide; a dump() method which will print a description of the; data structure to stderr.; The QualType; structure is used pervasively. This is a simple value class for; wrapping types with qualifiers; you can use; the isConstQualified(), for example, to get one of the; qualifiers, and the getTypePtr() method to get the; wrapped Type* which you can then dump.; For LLDB users there are; data formatters for clang data structures in; ; clang/utils/ClangDataFormat.py. Debugging using Visual Studio. The files; ; llvm/utils/LLVMVisualizers/llvm.natvis and; ; clang/utils/ClangVisualizers/clan",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/hacking.html:492,patch,patches,492,interpreter/llvm-project/clang/www/hacking.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/hacking.html,2,"['integrat', 'patch']","['integrating', 'patches']"
Deployability,". Histogram Libraries; TH1. Improve performances of TH1::Merge in case of histograms with same bin limits. Now an copy of the; initial histogram is not done. These improvements have been applied also in the TH2, TH3 and TProfile's classes.; . TH2. Add a new option ""S"" in FitSlice which performs a sliding merge: merge n consecutive bins along Y accordingly to what value in option Gn is given.; . TProfile2D and TProfile3D. Implement SetBins for variable bin sizes; ; Add support for variable bins in TProjectionXY. TH2Poly. The values set by SetMaximum() and SetMinimum() were not; taken into account by GetMaximum() and GetMinimum().; The Palette and the statistics box were not pickable when TH2Poly was drawn; with option COLZ.; TH2Poly was wrongly picked in the canvas area after a zoom along axis. TEfficiency. list holding the associated functions is created only on demand; default constructor creates two dummy histograms; can now be filled with weights (only Bayesian methods and the normal; approximation are supported) ; update TEfficiency::SavePrimitive to store also the set bits. TGraphAsymmErrors. add option to TGraphAsymmErrors::Divide for interpreting the given; histograms as ratio of Poisson means. TMultiGraph. The following macro did not show the x-axis in TimeDisplay mode. The; mg->GetYaxis()->UnZoom(); command erased the TimeDisplay attribute of; the axis. (fix from beischer@physik.rwth-aachen.de). {; TMultiGraph* mg = new TMultiGraph;; TGraph* g = new TGraph;; for (int i = 0; i < 100; i++) g->SetPoint(i, 1289420808+i, i+2);; mg->Add(g, ""P"");; mg->Draw(""AP"");; mg->GetXaxis()->SetTimeDisplay(1);; mg->GetYaxis()->UnZoom();; gPad->Modified();; gPad->Update();; }. TPaletteAxis. In TPaletteAxis::Paint() now makes sure the min and max of the; palette are not 0 when the histogram content is 0. on Ubuntu the following macro crashed. A char variable was too small. {; TCanvas *tmp = new TCanvas();; TH2F *h1 = new TH2F(""h1"",""h1"",40,0.,10.,40,1.e-2,1.e2);; h1->Fill(5,10);;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v532/index.html:1034,update,update,1034,hist/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v532/index.html,1,['update'],['update']
Deployability,". I/O Libraries; LZMA Compression and compression Level setting. ROOT I/O now support the LZMA compression algorithm to compress data in; addition to the ZLIB compression algorithm.; LZMA compression typically results in smaller files, but takes more; CPU time to compress data. To use the new feature, the external XZ; package must be installed when ROOT is configured and built:. Download 5.0.3 from here tukaani.org; and make sure to configure with fPIC:; ./configure CFLAGS='-fPIC'. Then the client C++ code must call routines to explicitly request LZMA; compression. ZLIB compression is still the default. Setting the Compression Level and Algorithm. There are three equivalent ways to set the compression level and; algorithm. For example, to set the compression to the LZMA algorithm; and compression level 5. TFile f(filename, option, title);; f.SetCompressionSettings(ROOT::CompressionSettings(ROOT::kLZMA, 5));. TFile f(filename, option, title, ROOT::CompressionSettings(ROOT::kLZMA, 5));. TFile f(filename, option, title);; f.SetCompressionAlgorithm(ROOT::kLZMA);; f.SetCompressionLevel(5);. These methods work for TFile, TBranch, TMessage, TSocket, and TBufferXML.; The compression algorithm and level settings only affect compression of; data after they have been set. TFile passes its settings to a TTree's branches; only at the time the branches are created. This can be overidden by; explicitly setting the level and algorithm for the branch. These classes; also have the following methods to access the algorithm and level for; compression. Int_t GetCompressionAlgorithm() const;; Int_t GetCompressionLevel() const;; Int_t GetCompressionSettings() const;. If the compression level is set to 0, then no compression will be; done. All of the currently supported algorithms allow the level to be; set to any value from 1 to 9. The higher the level, the larger the; compression factors will be (smaller compressed data size). The; tradeoff is that for higher levels more CPU time is used ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html:336,install,installed,336,io/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html,1,['install'],['installed']
Deployability,". I/O Libraries; TFileCacheRead. Support for multiple TFileCacheRead per TFile.; Multiple TFileCacheRead per TFile are supported by augmenting the existing TFile::SetCacheRead() function with an optional TObject* argument specifying the owner (i.e. tree) of the cache. This function will assign a TFileCacheRead to a TFile for the given TTree. A cache can be removed by setting the pointer TFileCacheRead to 0.; Similarly, in TFile::GetCacheRead() an optional TObject* argument was added to obtain the TFileCacheRead from a TFile.; In addition to the unassigned TFileCacheRead pointer, TFile will maintain a map of tree specific cache pointers.; Backward compatibility in both functions is handled by making the TObject* argument optional. If it is not specified in the TFile::SetCacheRead() call, only the unassigned TFileCacheRead pointer is updated, otherwise the map and the unassigned cache are updated. In TFile::GetCacheRead(), if an owner is not specified or doesn't exist in the file's cache map, the unassigned cache is returned, unless it is 0 and there is exactly one entry in the cache map.; Distinguish counter for bytes read and read calls for learning phase. TFileMerger. Improve efficiency of TFileMerger when merging a single file by doing a TFile::Cp rather than a load/write of the objects.; In TFileMerger and hadd when objects can not be merged do not overwrite the last object in the set with the first!; Renable warning about not being able to merge objects in TFileMerger and hadd.; Fix hadd problem where the incremental merging fails if the TTree are stored in sub-directories.; Improve the code used for forward compatibility (record the type as TDirectory even-though the class is now TDirectoryFile) by delaying the switching of the class name until it is written (to the buffer). This avoids problem where a TKey is created (by TFile::mkdir) and then immediately used for reading (this happens in the incremental file merger). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v534/index.html:844,update,updated,844,io/doc/v534/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v534/index.html,2,['update'],['updated']
Deployability,". I/O. Add support for the Chirp filesystem. To configure and build, chirp 3.2.2 must be installed.; When a TFile object is deleted, make sure that CINT also 'removes' any global variables that might point to it.; Fix support for the automatic addition to the current directory (for TTree and TH1 for example) in TKey::Read(TObject*).; In TKey, properly handle error in the I/O routines.; Explicitly check the validity of the zipped buffer before calling R__unzip, this allow for better error recovery.; When double checking whether a checksum difference is sustantial, ignore the std namespace. Use CompareContent also in the case of where; the class is versioned but the 'current' streamerInfo has not yet been built.; Prevent the I/O engine from mistakenly applying schema evolution to the TObject::fBits.; Make sure that when a streamer info of a base class is used to stream memberwise that is always not-optimized. If the StreamerInfo on file; has the same version as the StreamerInfo in memory but the one on file need to be 'not optimized' while the one in memory is not yet built, make; sure it will not be optimized.; Fix the reading of empty collection of object when reading without the library.; If the sequence of actions for streaming member-wise is not created correctly (i.e. where fReadMemberWise was null previously),; we now explicitly issue a Fatal error:. Fatal in <ReadSequence>: The sequence of actions to read AliESDVertex:7 member-wise was not initialized.; aborting. Add new optional parameter maxbuf to TXMLEngine::ParseFile() allowing the specification of the XML file size to be parsed. This fixes issue #78864.; Add function TBuffer::AutoExpand to centralize the automatic buffer extension policy. This enable the ability to tweak it later (for example instead of always doubling the size, increasing by only at most 2Mb or take hints from the number of entries already; in a TBasket).; Migrate the class TFileMerger from the proofplayer library to ROOT I/O library and ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v530/index.html:89,install,installed,89,io/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v530/index.html,1,['install'],['installed']
Deployability,". I/O. Fix the order of creation of the TStreamerInfo during the opening of a ROOT file to insure that the CollectionProxy are properly setup.; Fix problem: ""recover warning when opening an empty file; created with TXNetFile"" which was due to a bad check in TFile::Recover; (line TFile.cxx:1561) where the inheritance from TFile should be checked; instead of requiring the name to be TFile.; In TBranch::File, in the case of importing the data directly from; an external TBuffer, remove 80 char limit on reading the class name; Re-enable support for the; rootrc configuration Root.ZipMode. Data Model Evolution. First step in the implemantation of the infrastructure for the new Data Model Evolution Scheme.; This Data Model Evolution is brought to your courtesy of BNL/STAR/ATLAS/Fermi/Cern; Current Capabilities. Assign values to transient data members; Rename classes; Rename data members; Change the shape of the data structures or convert one class; structure to another; Change the meaning of data members; Ability to access the TBuffer directly when needed; Ensure that the objects in collections are handled in the same; way as the ones stored separately; Supported in object-wise, member-wise and split modes. Coming soon. Make things operational also in bare ROOT mode; Ability to transform data before writing; Support for changing the class type of nested object in a split; branch; Support for access to onfile version of nested objects from; within the parent rule. LinkDef rule syntax; Setting a transient member:; #pragma read sourceClass=""ACache"" targetClass=""ACache"" source=""""; version=""[1-]"" target=""zcalc"" \; code=""{ zcalc = false; }"". Setting a new member from 2 removed members:. #pragma read sourceClass=""ACache"" targetClass=""ACache""; source=""int x; int y; char c"" version=""[8]"" target=""z"" \; code=""{ z = onfile.x*1000 + onfile.y*10; }"". Renaming a class:. #pragma read sourceClass=""ACache"" version=""[8]""; targetClass=""Axis"" \; source=""int x; int y;"" target=""z"" \; code=""{ z = o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v522/index.html:562,configurat,configuration,562,io/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v522/index.html,1,['configurat'],['configuration']
Deployability,". I/O; Schema Evolution. Change TExMap hash, key and values from (U)Long_t to (U)Long64_t. This makes TExMap streamable in a portable way. On 64-bit platforms there is; no difference, but on 32-bit platforms all values will now be 64-bit. This fixes a big portability issue with THnSparse which uses TExMap internally; where the versions created on a 32-bit platform could not be read on a 64-bit platform and vice versa.; Avoid reporting I/O error for members of a class that is used only for a transient member; Concrete implementation of TClassGenerator needs to be updated to also avoid the warnings.; Fix the rule lookup based on checksum; Extend support of the schema evolution rules to fixed length array.; Prevent a process abort (due to a call to Fatal) when we are missing the dictionary for (one of) the; content of an STL collection when this collection is 'only' use has a transient member.; Fix the case where the source and target of a rule have the same name.; Avoid using the 'current' StreamerInfo to read an older streamerInfo that is missing (in case of corrupted files). Misc. New TFile plugin for the Hadoop Distributed File System (protocol hdfs:); Unregister stack objects from their TDirectory when the TList tries to delete them.; When streaming a base class without StreamerNVirtual() use an external streamer if it was set.; Many improvement to the I/O run-time performance.; DCache:; Increase readahead size from 8k to 128k and make it settable via DCACHE_RA_BUFFER env var.; dCap client does not ignore ?filetpye=raw and other options, so remove it. The function TFile::GetRelOffset is now public instead of protected.; Corrected the reading of the TFile record of large files.; MakeProject: several updates to improve support for CMS and Atlas data files (add support for auto_ptr, bitset, class name longer than 255 characters, etc.). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v526/index.html:569,update,updated,569,io/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v526/index.html,2,['update'],"['updated', 'updates']"
Deployability,". In the example below `x.value()` is accessed safely because it is guarded by the; `x.has_value()` check. ```c++; void Example(std::optional<int> &x) {; if (x.has_value()) {; use(x.value());; }; }; ```. While entering the if branch we deduce that `x.has_value()` is implied by the; flow condition. ```c++; void Example(std::optional<int> x) {; // Flow condition: true.; if (x.has_value()) {; // Flow condition: x.has_value() == true.; use(x.value());; }; // Flow condition: true.; }; ```. We also need to prove that `x` is not modified between check and value access.; The modification of `x` may be very subtle:. ```c++; void F(std::optional<int> &x);. void Example(std::optional<int> &x) {; if (x.has_value()) {; // Flow condition: x.has_value() == true.; unknown_function(x); // may change x.; // Flow condition: true.; use(x.value());; }; }; ```. ## Example: finding dead code behind A/B experiment flags. Finding dead code is a classic application of data flow analysis. Unused flags for A/B experiment hide dead code. However, this flavor of dead; code is invisible to the compiler because the flag can be turned on at any; moment. We could make a tool that deletes experiment flags. The user tells us which flag; they want to delete, and we assume that the it's value is a given constant. For example, the user could use the tool to remove `example_flag` from this; code:. ```c++; DEFINE_FLAG(std::string, example_flag, """", ""A sample flag."");. void Example() {; bool x = GetFlag(FLAGS_example_flag).empty();; f();; if (x) {; g();; } else {; h();; }; }; ```. The tool would simplify the code to:. ```c++; void Example() {; f();; g();; }; ```. We can solve this problem with a classic constant propagation lattice combined; with symbolic evaluation. ## Example: finding inefficient usages of associative containers. Real-world code often accidentally performs repeated lookups in associative; containers:. ```c++; map<int, Employee> xs;; xs[42]->name = ""..."";; xs[42]->title = ""..."";; ```. To f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:27995,A/B,A/B,27995,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['A/B'],['A/B']
Deployability,". LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if that person hasn't done so yet. Note that, if a reviewer has requested a particular community member to review,; and after a week that community member has yet to respond, feel free to ping; the patch (which literally means submitting a comment on the patch with the; word, ""Ping.""), or alternatively, ask the original reviewer for further; suggestions. If it is likely that others will want to review a recently-posted patch,; especially if there might be objections, but no one else has done so yet, it is; also polite to provide a qualified approval (e.g., ""LGTM, but please wait for a; couple of days in case others wish to review""). If approval is received very; quickly, a patch author may also elect to wait before committing (and this is; certainly considered polite for non-trivial patches). Especially given the; global nature of our community, this waiting time should be at least 24 hours.; Please also be mindful of weekends and major holidays. Our goal is to ensure community consensus around design decisions and; significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:7440,patch,patch,7440,interpreter/llvm-project/llvm/docs/CodeReview.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst,2,['patch'],['patch']
Deployability,". Latest News; Cling release 1.1 is out; Aug 28th, 2023; Read more. Cling release 1.0 is out; Dec 9th, 2023; Read more. Cling release 0.9 is out; May 4th, 2021; Read more. Cling release 0.8 is out; January 11th, 2021; Read more. Cling release 0.7 is out; August 21th, 2020; Read more. Cling release 0.6 is out; August 16th, 2019; Read more. Cling release 0.5 is out; November 02nd, 2017; Read more. Cling release 0.4 is out; June 06th, 2017; Read more. Cling release 0.3 is out; August 09th, 2016; Read more. Cling release 0.2 is out; July 06th, 2016; Read more. Cling goes public; July 25th, 2011; Cling was officially announced to the Clang community Read more. New website launched; July 1st, 2011; Welcome to the new website of the project. Read more; Useful Links. CERN. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/news.html:21,release,release,21,interpreter/cling/www/news.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/news.html,10,['release'],['release']
Deployability,". Math Libraries. MathCore. Various fixes have been applied in the fitting classes:. Fix issue #46006 for normalization of error resulting from fitting a TGraph; Fix a problem in Chi2 calculation in case of overflow; Fix issue #46601 for avoiding crashes when a linear fit fails.; Fix in the FitData classes the bug #45909 occurring when setting a function range outside histogram range; Fix default integration method to be Gauss algorithm of MathCore instead of the GSL method, when libMathmore is not built or when the plug-in manager fails to load it.; Add a protection against negative log when fitting using the Poisson log likelihood function; Improve calculation of derivative in x for fitted function. This fixes some problem observed when fitting using the error on the coordinates.; Fitter class: add new methods for calculating the error matrix after minimization, Fitter::CalculateHessErrors() and for calculating the Minos errors Fitter::CalculateMinosErrors; FitConfig: add in the configuration the possibility to select a sub-set of the parameters for calculating the Minos errors by using the method FitConfig::SetMinosErrors( listOfParameters ). If no list is passed, by default the Minos error will be computed on all parameters.; UnBinData class: add new constructor for creating a unbin data set passing a range to select the data and copy in the internal array; FitResult: the class now stores a map of the Minos error using as key the parameter index. If the Minos error has not been calculated for the parameter, FitResult::LowerError(i) and FitResult::UpperError(i) returns the parabolic error; ; Add a new class, MinimTransformFunction to perform a transformation of the function object to deal with limited and fixed variables.; This class uses the same transformation which are also used inside Minuit, a sin transformation for double bounded variables and a sqrt transformation for single bound variable defined in the class MinimizerVariableTransformation.; These classes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v524/index.html:400,integrat,integration,400,math/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v524/index.html,2,"['configurat', 'integrat']","['configuration', 'integration']"
Deployability,". Misc; Quick Look plugin for MacOS X. New Quick Look plugin that allows quick inspection of the content; of a ROOT file. Quick Look is available on MacOS X since version 10.5 (Leopard). To use QL; select an file icon in the Finder and hit the space bar. For all file types; supported by QL you will get a window showing the file content, for file types; not supported you will get a generic window showing some basic file info. The idea of QL is that file content can be shown without the heavy application; startup process. Generating a QL view of a ROOT file depends on the size of the; file, but generally it is a quick operation. Get the binary for the ROOTQL plugin from:. ftp://root.cern.ch/root/ROOTQL.tgz. To install the plugin, after untarring the above file, just drag the bundle; ROOTQL.qlgenerator to /Library/QuickLook (global, i.e. for all users on a; system) or to ~/Library/QuickLook (local, this user only) directory.; You may need to create that folder if it doesn't already exist. To build from source, get it from svn using:. svn co http://root.cern.ch/svn/root/trunk/misc/rootql rootql. Open the ROOTQL project in Xcode and click on ""Build"" (make sure the Active; Build Configuration is set the ""Release""). Copy the resulting; plugin from build/Release to the desired QuickLook directory. SpotLight plugin for MacOS X. This is a Spotlight plugin that allows ROOT files to be indexed by SL.; Once indexed SL can find ROOT files based on the names and titles of the; objects in the files. Spotlight is available on MacOS X since version 10.4 (Tiger). To use SL; select the SL icon on the top right of the menubar and type in a search text. Get the binary for the ROOTSL plugin from:. ftp://root.cern.ch/root/ROOTSL.tgz. To install the plugin, after untarring the above file, just drag the bundle; ROOTSL.mdimporter to /Library/Spotlight (global, i.e. for all users on a; system) or to ~/Library/Spotlight (local, this user only) directory.; You may need to create that folder if it",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/misc/doc/v524/index.html:718,install,install,718,misc/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/misc/doc/v524/index.html,1,['install'],['install']
Deployability,. NET release notes. XROOTD. Fixes:; . Fix race condition that would disable connections; . ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v522/index.html:6,release,release,6,net/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v522/index.html,1,['release'],['release']
Deployability,". Networking Libraries; New TSSLSocket class; The new TSSLSocket class wraps a TSocket with SSL encryption. This class; is used to provide support for reading TWebFiles over https. New TUDPSocket class; The new TUDPSocket uses UDP as protocol where TSocket uses TCP. This class; can be used to talk to UDP servers. XROOTD; Starting with this version (5.32/00) Xrootd is no longer distributed with ROOT.; The package is still needed to build the modules 'netx', 'proofx' and 'proofd' and must be; provided as external. Xrootd can be downloaded from the main web site and its installation; is straightforward. A script to automatize the installation process is provided at; build/unix/installxrootd.sh ; scripts to set-up the environment at; bin/setxrd.sh and bin/setxrd.csh .; Note that the Xrootd team has dropped support for Windows,; so the Xrootd-related components of ROOT will only be built on Unices (Linux, Solaris, MacOsX).; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v532/index.html:574,install,installation,574,net/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v532/index.html,3,['install'],"['installation', 'installxrootd']"
Deployability,". Obtaining the Static Analyzer. Obtaining the Static Analyzer; This page describes how to download and install the analyzer. Once; the analyzer is installed, follow the instructions on using scan-build to; get started analyzing your code.; Packaged Builds (Mac OS X); Semi-regular pre-built binaries of the analyzer are available on Mac; OS X. These are built to run on OS X 10.7 and later.; Builds are released frequently. Often the differences between build; numbers being a few bug fixes or minor feature improvements. When using; the analyzer, we recommend that you check back here occasionally for new; builds, especially if the build you are using is more than a couple; weeks old.; The latest build is:; . Packaged builds for other platforms may eventually be provided, but; we need volunteers who are willing to help provide such regular builds.; If you wish to help contribute regular builds of the analyzer on other; platforms, please email the Clang; Developers' mailing list.; Using Packaged Builds; To use a package build, simply unpack it anywhere. If the build; archive has the name checker-XXX.tar.bz2 then the; archive will expand to a directory called checker-XXX.; You do not need to place this directory or the contents of this; directory in any special place. Uninstalling the analyzer is as simple; as deleting this directory.; Most of the files in the checker-XXX directory will; be supporting files for the analyzer that you can simply ignore. Most; users will only care about two files, which are located at the top of; the checker-XXX directory:. scan-build: scan-build is the high-level command line utility for running the analyzer; scan-view: scan-view a companion command line; utility to scan-build, scan-view is used to view; analysis results generated by scan-build. There is an option; that one can pass to scan-build to cause scan-view to; run as soon as it the analysis of a build completes. Running scan-build; For specific details on using scan-build, please see",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/installation.html:104,install,install,104,interpreter/llvm-project/clang/www/analyzer/installation.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/installation.html,3,"['install', 'release']","['install', 'installed', 'released']"
Deployability,". PROOF release notes. PROOF. New functionality. PROOF-Lite2-tier; realization of PROOF intended for multi-core machines; the client; starts directly the workers; no daemon is required. To start a session; just use TProof::Open("""") or TProof::Open(""lite""). From there on; everything should be as in normal PROOF, though some functionality may; not have been ported yet. To start a standard PROOF; session (i.e. via daemons) on the localhost use; TProof::Open(""localhost"").XrdProofd plug-in. Possibility to define the list worker directly in the; xrootd config file (new directive xpd.worker, see Wiki reference pages); Support for automatic reconnections in the case xrootd; is restarted; Dedicated admin area (under <xrd.admin>/.xproofd.<port>) to; keep information about active and terminated sessions, and active; clients. This is used to reguraly check the client and session; activity, to cleanup orphalin sessions and to shutdown inactive client; connections. ; domain + level control of printout message. Dynamic ""per-query"" scheduling. Dynamic worker startup. It can be enabled by the cluster; administrator with the 'xpd.putrc Proof.DynamicStartup 1' directive; in the config file. The effect is that a session starts only on; the master. When a query is submitted (call to TProof::Process),; the session master contacts the scheduler.; In response it receives a list of workers and starts the worker; processes. The environment is copied from the master to the workers.; It consist of: the include and library paths, the set of enabled; packages as well as the macros loaded by the user. . Flexible and fault-tolerant workers. A packet resubmitting mechanism. When a worker dies all the; packets that it processed are resubmitted.; Added the possibility to handle dynamically removed workers and partly processed; packets (when a worker is stopped while processing a packet it finishes; the current event and the rest of the packet is reassigned to another workers).; It's done by a new meth",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:8,release,release,8,proof/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html,1,['release'],['release']
Deployability,". Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > **Source code:** [PoD download page](http://pod.gsi.de/download.html); > and [Installation; > instructions](http://pod.gsi.de/doc/3.12/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your so",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:5485,install,install,5485,proof/doc/confman/ConfigProofPoD.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md,1,['install'],['install']
Deployability,". PyROOT. Python 3 is now in principle supported: a problem remains with passing builtin; types by reference, since the internal object layout has changed.; There may be further problems with handling of char*: all strings are unicode in; p3, so if the C++ code is meant to see the char* as byte*, that won't work. Other significant feature improvements include:. Globally overloaded operators are now supported, and histogram unary; multiplication with scalar is mapped onto TH1.Scale.; Significant changes to equality and non-equality operators should make their; behavior more consistent across the board, and in particular globally overloaded; equality operators for STL iterators should work as expected (if a dictionary entry; is generated for them).; Global arrays of builtin types are now supported.; Added further mappings of operator converters for builtin types.; Individual methods can release the GIL, by setting the ""_threaded"" parameter; of the method to True.; Constructors need not be creators of new objects (controlled with their; ""_creates"" parameters).; Added access to TSelector protected data members in TPySelector.; Derivable Fitter base classes are added for use with ROOT::Fitter.; Special cases for RooFit are added to resolve a few specific overloading; problems.; A Python Warning is issued if a void* converter or executor is chosen out of; necessity (e.g. because dictionaries are missing).; A Python Warning is issued if keyword arguments are given (unsupported). Notable bug fixes include:. Object returns as a member of a temporary will keep a life line to that; temporary, to prevent it from being destroyed in a long expression.; Added ""_"" as a valid class name character.; Speed of the destruction of memory-regulated objects has been improved; (made linear, rather than quadratic). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/doc/v528/index.html:898,release,release,898,bindings/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/doc/v528/index.html,1,['release'],['release']
Deployability,". PyROOT. This release contains two big new features: the ability to use PROOF with; python, and the ability to pickle (python serialize) ROOT objects.; Pickling of ROOT objects is straightforward: just hand them to pickle (or; cPickle) like any other python object.; To use PROOF with python, derive your custom class from TPySelector, override; the methods that you want to specialize, and put it in a file that is shipped; to the worker nodes, e.g.:. from ROOT import TPySelector. class MyPySelector( TPySelector ):; def Begin( self ):; print 'py: beginning'. def SlaveBegin( self, tree ):; print 'py: slave beginning'. def Process( self, entry ):; self.fChain.GetEntry( entry ); print 'py: processing', self.fChain.ipi; return 1. def SlaveTerminate( self ):; print 'py: slave terminating'. def Terminate( self ):; print 'py: terminating'. The file containing the class (e.g. mymodule.py) will be treated as a; python module and should be loadable through PYTHONPATH (typically '.') at; the worker node.; Setup PROOF as normal, and call:. dataset.Process( 'TPySelector', 'mymodule' ). PROOF will instantiate a TPySelector instance, which will in turn pick up; the python class from module 'mymodule' and forward all calls. There are several improvements in language mappings, as well as cleanup of; the code for python2.2 (Py_ssize_t handling) and MacOS 10.3. Additionally,; there are code cleanups (removing use of CINT internals) that should be; fully transparent to the end-user. The language mapping improvements are:. Abstract classes can no longer be instantiated (__init__ will raise an exception); Looping over empty STL(-like) containers will yield an immediate StopIteration; Unknown& is favored over Unknown* in function overloading; Implemented unary-, unary+ (__neg__ and __pos__); Mapped operator bool() to __nonzero__; Support for templated member functions; Implemented __setitem__ for unsigned int& and unsigned long& returns. The python presentation of ROOT objects (ObjectProxy) ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/doc/v520/index.html:15,release,release,15,bindings/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/doc/v520/index.html,1,['release'],['release']
Deployability,". ROOT Version 5.20/00 Release Notes. ROOT Version 5.20/00 Release Notes. ROOT version 5.20/00 has been released June 25, 2008.; In case you are upgrading from version 5.14, please read the releases notes; of version 5.16 and version 5.18 in addition to these notes. Bindings - packages related to the interplay with other programming languages (Python, Ruby); Cint - the C++ interpreter; Core - the basic ROOT functionality; Geometry - building, representing and drawing geometrical objects; 2D Graphics - ROOT's two dimensional graphics interface; 3D Graphics - ROOT's three dimensional graphics interface; Graphical User Interface - from basic GUI elements to ROOT's own, complete dialogs; Histograming - counting values, spectra, and drawing them; HTML - the documentation generator; Input/Ouput - storing and reading data; Mathemathics - everything one can use to calculate: minimizers, matrixes, FFT, and much more; Miscellaneous - things that didn't make it into the other groups: table ; Monte Carlo - monte carlo and physics simulation interfaces; Networking - network-related parts, e.g. protocols and authentication interfaces; PROOF - parallel ROOT facility; RooFit - a fitting library; SQL - database interfaces; TMVA - multivariate analysis tools; Trees - ROOT's unique container class and related utilities. Binaries for all supported platforms are available at:. http://root.cern.ch/root/Version520.html; Versions for AFS have also been updated. See the list of supported; platforms:; http://root.cern.ch/Welcome.html. For more information, see:. http://root.cern.ch; The following people have contributed to this new version:; Ilka Antcheva,; Jean-Fran�ois Bastien, ; Bertrand Bellenot,; Rene Brun,; Philippe Canal,; Olivier Couet,; Valeri Fine,; Leo Franco, ; Gerri Ganis,; Andrei Gheata,; Mihaela Gheata,; David Gonzalez Maline, ; Andreas Hoecker, ; Jan Iwaszkiewicz, ; Lukasz Janyst, ; Anna Kreshuk, ; Wim Lavrijsen,; Sergei Linev,; Anar Manafov, ; Diego Marcos-Segura, ; Lorenzo M",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v520/index.html:104,release,released,104,doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v520/index.html,2,['release'],"['released', 'releases']"
Deployability,". ROOT Version 5.22/00 Release Notes. ROOT Version 5.22/00 Release Notes. ROOT version 5.22/00 has been released on December 18, 2008.; In case you are upgrading from an old version, please read the releases notes; of version 5.16, 5.18 and version 5.20 in addition to these notes. Bindings - packages related to the interplay with other programming languages (Python, Ruby); Cint - the C++ interpreter; Core - the basic ROOT functionality; Geometry - building, representing and drawing geometrical objects; 2D Graphics - ROOT's two dimensional graphics interface; 3D Graphics - ROOT's three dimensional graphics interface; Graphical User Interface - from basic GUI elements to ROOT's own, complete dialogs; Histograming - counting values, spectra, and drawing them; HTML - the documentation generator; Input/Ouput - storing and reading data; Mathemathics - everything one can use to calculate: minimizers, matrixes, FFT, and much more; Miscellaneous - things that didn't make it into the other groups: table ; Monte Carlo - monte carlo and physics simulation interfaces; Networking - network-related parts, e.g. protocols and authentication interfaces; PROOF - parallel ROOT facility; RooFit - a fitting library; SQL - database interfaces; TMVA - multivariate analysis tools; Trees - ROOT's unique container class and related utilities. Binaries for all supported platforms are available at:. http://root.cern.ch/root/Version521.html; Versions for AFS have also been updated. See the list of supported; platforms:; http://root.cern.ch/Welcome.html. For more information, see:. http://root.cern.ch; The following people have contributed to this new version:; Ilka Antcheva,; Jean-Fran�ois Bastien, ; Bertrand Bellenot,; Rene Brun,; Philippe Canal,; Olivier Couet,; Kyle Cranmer,; Valeri Fine,; Leo Franco, ; Gerri Ganis,; Andrei Gheata,; Mihaela Gheata,; David Gonzalez Maline, ; Andreas Hoecker, ; Jan Iwaszkiewicz, ; Lukasz Janyst, ; Anna Kreshuk, ; Wim Lavrijsen,; Josef Leydold,; Sergei Linev,; An",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v522/index.html:104,release,released,104,doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v522/index.html,2,['release'],"['released', 'releases']"
Deployability,". ROOT Version 5.24/00 Release Notes. ROOT Version 5.24/00 Release Notes. ROOT version 5.24/00 will be released end of June 2009.; In case you are upgrading from an old version, please read the releases notes; of version 5.16, 5.18, 5.20 and version 5.22 in addition to these notes. Bindings - packages related to the interplay with other programming languages (Python, Ruby); Cint - the C++ interpreter; Core - the basic ROOT functionality; Geometry - building, representing and drawing geometrical objects; 2D Graphics - ROOT's two dimensional graphics interface; 3D Graphics - ROOT's three dimensional graphics interface; Graphical User Interface - from basic GUI elements to ROOT's own, complete dialogs; Histograming - counting values, spectra, and drawing them; HTML - the documentation generator; Input/Ouput - storing and reading data; Mathemathics - everything one can use to calculate: minimizers, matrixes, FFT, and much more; Miscellaneous - things that didn't make it into the other groups: table ; Monte Carlo - monte carlo and physics simulation interfaces; Networking - network-related parts, e.g. protocols and authentication interfaces; PROOF - parallel ROOT facility; RooFit - a fitting library; SQL - database interfaces; TMVA - multivariate analysis tools; Trees - ROOT's unique container class and related utilities. Binaries for all supported platforms are available at:. http://root.cern.ch/root/Version521.html; Versions for AFS have also been updated. See the list of supported; platforms:; http://root.cern.ch/Welcome.html. For more information, see:. http://root.cern.ch; The following people have contributed to this new version:; Kevin Belasco, N/A, Princeton University for MCMC, ; Bertrand Bellenot, CERN/SFT,; Rene Brun, CERN/SFT,; Philippe Canal, FNAL,; Or Cohen, CERN & Weizmann, TMVA; Olivier Couet, CERN/SFT,; Kyle Cranmer, NYU/Atlas, RooStats; Dominik Dannheim, MPI-Munich/Atlas, TMVA ; Valeri Fine, BNL/STAR,; Gerri Ganis, CERN/SFT,; Andrei Gheata, CERN/Alice,; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v524/index.html:103,release,released,103,doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v524/index.html,2,['release'],"['released', 'releases']"
Deployability,". ROOT Version 5.26/00 Release Notes. Quick Links:; ROOT Homepage; Download; Reference Guide. Search. ROOT. » Download; » Release Notes. ROOT Version 5.26/00 Release Notes. ROOT version 5.26/00 will be released on December 15 2009.; In case you are upgrading from an old version, please read the releases notes; of version 5.16, 5.18, 5.20, 5.22 and version 5.24 in addition to these notes. Bindings - packages related to the interplay with other programming languages (Python, Ruby); Cint - the C++ interpreter; Core - the basic ROOT functionality; Geometry - building, representing and drawing geometrical objects; 2D Graphics - ROOT's two dimensional graphics interface; 3D Graphics - ROOT's three dimensional graphics interface; Graphical User Interface - from basic GUI elements to ROOT's own, complete dialogs; Histograming - counting values, spectra, and drawing them; HTML - the documentation generator; Input/Ouput - storing and reading data; Mathemathics - everything one can use to calculate: minimizers, matrixes, FFT, and much more; Miscellaneous - things that didn't make it into the other groups: table ; Monte Carlo - monte carlo and physics simulation interfaces; Networking - network-related parts, e.g. protocols and authentication interfaces; PROOF - parallel ROOT facility; RooFit - a fitting library; RooStats - a collection of statistical tools ; SQL - database interfaces; TMVA - multivariate analysis tools; Trees - ROOT's unique container class and related utilities. Binaries for all supported platforms are available at:. https://root.cern/releases/release-52600/. For more information, see:. http://root.cern.ch; The following people have contributed to this new version:; Bertrand Bellenot, CERN/SFT,; Brian Bockelman, UNL,; Rene Brun, CERN/SFT,; Philippe Canal, FNAL,; Olivier Couet, CERN/SFT,; Kyle Cranmer, NYU/Atlas, RooStats; Valeri Fine, BNL/STAR,; Lucie Flekova, CERN/SFT summer student,; Fabrizio Furano, CERN/IT, ; Gerri Ganis, CERN/SFT,; Andrei Gheata, CERN/Ali",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v526/index.html:202,release,released,202,doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v526/index.html,2,['release'],"['released', 'releases']"
Deployability,". ROOT Version 5.28/00 Release Notes. Quick Links:; ROOT Homepage; Download; Reference Guide. Search. ROOT. » Download; » Release Notes. ROOT Version 5.28/00 Release Notes. ROOT version 5.28/00 has been released on December 15 2010.; In case you are upgrading from an old version, please read the releases notes; of version 5.16, 5.18, 5.20, 5.22, 5.24 and version 5.26 in addition to these notes. Bindings - packages related to the interplay with other programming languages (Python, Ruby); Cint - the C++ interpreter; Core - the basic ROOT functionality; Geometry - building, representing and drawing geometrical objects; 2D Graphics - ROOT's two dimensional graphics interface; 3D Graphics - ROOT's three dimensional graphics interface; Graphical User Interface - from basic GUI elements to ROOT's own, complete dialogs; Histograming - counting values, spectra, and drawing them; HTML - the documentation generator; Input/Ouput - storing and reading data; Mathemathics - everything one can use to calculate: minimizers, matrixes, FFT, and much more; Miscellaneous - things that didn't make it into the other groups: table ; Monte Carlo - monte carlo and physics simulation interfaces; Networking - network-related parts, e.g. protocols and authentication interfaces; PROOF - parallel ROOT facility; RooFit - a fitting library; RooStats - a collection of statistical tools ; SQL - database interfaces; TMVA - multivariate analysis tools; Trees - ROOT's unique container class and related utilities; Tutorials - ROOT's Tutorials. Binaries for all supported platforms are available at:. https://root.cern/releases/release-52800/. For more information, see:. http://root.cern.ch; The following people have contributed to this new version:; Alberto Annovi, INFN, TH1, ; Kevin Belasco, Princeton University, RooStats,; Bertrand Bellenot, CERN/SFT,; Rene Brun, CERN/SFT,; Philippe Canal, FNAL,; Olivier Couet, CERN/SFT,; Kyle Cranmer, NYU, RooStats,; Jason Detwiler, LBL, TClonesArray, ; Valeri Fine, BNL/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v528/index.html:203,release,released,203,doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v528/index.html,2,['release'],"['released', 'releases']"
Deployability,". ROOT Version 5.30/00 Release Notes. Quick Links:; ROOT Homepage; Download; Reference Guide. Search. ROOT. » Download; » Release Notes. ROOT Version 5.30/00 Release Notes. ROOT version 5.28/00 has been released on December 15 2010.; In case you are upgrading from an old version, please read the releases notes; of version 5.16, 5.18, 5.20, 5.22, 5.24, 5,26 and version 5.28 in addition to these notes. The release of version 5.30 is scheduled for June 27, 2011. Bindings - packages related to the interplay with other programming languages (Python, Ruby); Cint - the C++ interpreter; Core - the basic ROOT functionality; Geometry - building, representing and drawing geometrical objects; 2D Graphics - ROOT's two dimensional graphics interface; 3D Graphics - ROOT's three dimensional graphics interface; Graphical User Interface - from basic GUI elements to ROOT's own, complete dialogs; Histograming - counting values, spectra, and drawing them; HTML - the documentation generator; Input/Ouput - storing and reading data; Mathemathics - everything one can use to calculate: minimizers, matrixes, FFT, and much more; Miscellaneous - things that didn't make it into the other groups: table ; Monte Carlo - monte carlo and physics simulation interfaces; Networking - network-related parts, e.g. protocols and authentication interfaces; PROOF - parallel ROOT facility; RooFit - a fitting library; RooStats - a collection of statistical tools ; SQL - database interfaces; TMVA - multivariate analysis tools; Trees - ROOT's unique container class and related utilities; Tutorials - ROOT's Tutorials. Binaries for all supported platforms are available at:. https://root.cern/releases/release-52800/. For more information, see:. http://root.cern.ch; The following people have contributed to this new version:; Bertrand Bellenot, CERN/SFT,; Dario Berzano, INFN and University of Torino, ALICE, Proof,; Rene Brun, CERN/SFT,; Philippe Canal, FNAL,; Olivier Couet, CERN/SFT,; Kyle Cranmer, NYU, RooStats,; Gerr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v530/index.html:203,release,released,203,doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v530/index.html,3,['release'],"['release', 'released', 'releases']"
Deployability,". ROOT Version 5.32/00 Release Notes. Quick Links:; ROOT Homepage; Download; Reference Guide. Search. ROOT. » Download; » Release Notes. ROOT Version 5.32/00 Release Notes. ROOT version 5.32/00 has been released on Nov 29, 2011.; In case you are upgrading from an old version, please read the releases notes; of version 5.26, 5,28 and version 5.30 in addition to these notes. The release of version 5.34 is scheduled for May 29, 2012. Bindings - packages related to the interplay with other programming languages (Python, Ruby); Cint - the C++ interpreter; Core - the basic ROOT functionality; Geometry - building, representing and drawing geometrical objects; 2D Graphics - ROOT's two dimensional graphics interface; 3D Graphics - ROOT's three dimensional graphics interface; Graphical User Interface - from basic GUI elements to ROOT's own, complete dialogs; Histograming - counting values, spectra, and drawing them; HTML - the documentation generator; Input/Ouput - storing and reading data; Mathemathics - everything one can use to calculate: minimizers, matrixes, FFT, and much more; Miscellaneous - things that didn't make it into the other groups: table ; Monte Carlo - monte carlo and physics simulation interfaces; Networking - network-related parts, e.g. protocols and authentication interfaces; PROOF - parallel ROOT facility; RooFit - a fitting library; RooStats - a collection of statistical tools ; SQL - database interfaces; TMVA - multivariate analysis tools; Trees - ROOT's unique container class and related utilities; Tutorials - ROOT's Tutorials. For more information, see:. http://root.cern.ch; The following people have contributed to this new version:; Bertrand Bellenot, CERN/SFT,; Rene Brun, CERN/SFT,; Philippe Canal, FNAL,; Olivier Couet, CERN/SFT,; Kyle Cranmer, NYU/ATLAS, RooStats,; Sven Kreiss, NYU/ATLAS, RooStats,; Gena Kukartsev, CERN and FNAL/CMS, ; Gerri Ganis, CERN/SFT,; Andrei Gheata, CERN/Alice,; Christian Gumpert, CERN and University Dresden/ATLAS, Math,; Wi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v532/index.html:203,release,released,203,doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v532/index.html,3,['release'],"['release', 'released', 'releases']"
Deployability,". ROOT Version 5.33/01 Release Notes. Quick Links:; ROOT Homepage; Download; Reference Guide. Search. ROOT. » Download; » Release Notes. ROOT Version 5.33/01 Release Notes. ROOT version 5.32/00 has been released on November 29, 2011.; In case you are upgrading from an old version, please read the releases notes; of version 5.26, 5,28 and version 5.30 in addition to these notes. The release of version 5.34 is scheduled for May 30, 2012. Bindings - packages related to the interplay with other programming languages (Python, Ruby); Cint - the C++ interpreter; Core - the basic ROOT functionality; Geometry - building, representing and drawing geometrical objects; 2D Graphics - ROOT's two dimensional graphics interface; 3D Graphics - ROOT's three dimensional graphics interface; Graphical User Interface - from basic GUI elements to ROOT's own, complete dialogs; Histograming - counting values, spectra, and drawing them; HTML - the documentation generator; Input/Ouput - storing and reading data; Mathemathics - everything one can use to calculate: minimizers, matrixes, FFT, and much more; Miscellaneous - things that didn't make it into the other groups: table ; Monte Carlo - monte carlo and physics simulation interfaces; Networking - network-related parts, e.g. protocols and authentication interfaces; PROOF - parallel ROOT facility; RooFit - a fitting library; RooStats - a collection of statistical tools ; SQL - database interfaces; TMVA - multivariate analysis tools; Trees - ROOT's unique container class and related utilities; Tutorials - ROOT's Tutorials. For more information, see:. http://root.cern.ch; The following people have contributed to this new version:; Bertrand Bellenot, CERN/SFT,; Rene Brun, CERN/SFT,; Philippe Canal, FNAL,; Olivier Couet, CERN/SFT,; Kyle Cranmer, NYU, RooStats,; Gerri Ganis, CERN/SFT,; Andrei Gheata, CERN/Alice,; Wim Lavrijsen, LBNL, PyRoot,; Lorenzo Moneta, CERN/SFT,; Axel Naumann, CERN/SFT,; Fons Rademakers, CERN/SFT,; Paul Russo, FNAL, ; Joerg ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v534/index.html:203,release,released,203,doc/v534/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v534/index.html,3,['release'],"['release', 'released', 'releases']"
Deployability,". Read this section and make sure your target follows all requirements. For; minor issues, your community will be responsible for making all necessary; adjustments soon after the initial merge.; 2. Send a request for comment (RFC) to the `LLVM Discourse forums`_ describing; your target and how it follows all the requirements and what work has been; done and will need to be done to accommodate the official target requirements.; Make sure to expose any and all controversial issues, changes needed in the; base code, table gen, etc.; 3. Once the response is positive, the LLVM community can start reviewing the; actual patches (but they can be prepared before, to support the RFC). Create; a sequence of N patches, numbered '1/N' to 'N/N' (make sure N is an actual; number, not the letter 'N'), that completes the basic structure of the target.; 4. The initial patch should add documentation, code owners and triple support in; clang and LLVM. The following patches add TableGen infrastructure to describe; the target and lower instructions to assembly. The final patch must show that; the target can lower correctly with extensive LIT tests (IR to MIR, MIR to; ASM, etc).; 5. Some patches may be approved before others, but only after *all* patches are; approved that the whole set can be merged in one go. This is to guarantee; that all changes are good as a single block.; 6. After the initial merge, the target community can stop numbering patches and; start working asynchronously on the target to complete support. They should; still seek review from those who helped them in the initial phase, to make; sure the progress is still consistent.; 7. Once all official requirements have been fulfilled (as above), the code owner; should request the target to be enabled by default by sending another RFC to; the `LLVM Discourse forums`_. Adding an Established Project To the LLVM Monorepo; --------------------------------------------------. The `LLVM monorepo <https://github.com/llvm/llvm-proje",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:44011,patch,patches,44011,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['patch'],['patches']
Deployability,". Release notes for checker-XXX builds. Release notes for checker-XXX builds; checker-279; built: November 14, 2016; download: checker-279.tar.bz2; highlights:. The analyzer includes new checks for:; ; Improper instance cleanup up in Objective-C -dealloc methods under manual retain/release.; Inadvertent comparisons of NSNumber, CFNumberRef, and other number object pointers against scalar values.; Unsafe usage of dispatch_once_t predicates stored in Objective-C instance variables and other heap-allocated memory.; Issues resulting from self-assignment in C++.; Incorrect usage of MPI APIs in C and C++. This check can be enabled by passing the following command to scan-build: ;   -enable-checker optin.mpi.MPI-Checker. The scan-build tool now supports a --force-analyze-debug-code flag that forces projects to analyze in debug mode. This flag leaves in assertions and so typically results in fewer false positives.; Additional miscellaneous improvements.; Now requires macOS 10.8 or later. checker-278; built: February 5, 2016; download: checker-278.tar.bz2; highlights:. Greatly improves analysis of C++ lambdas, including interprocedural analysis of lambda applications and reduced 'dead store'; false positives for variables captured by reference.; The analyzer now checks for misuse of 'vfork()'. This check is enabled by default.; The analyzer can now detect excessively-padded structs. This check can be enabled by passing the following; command to scan-build:;   -enable-checker optin.performance.Padding ; The checks to detect misuse of _Nonnull are now enabled by default.; The checks to detect misuse of Objective-C generics are now enabled by default.; Many miscellaneous improvements. checker-277; built: October 28, 2015; download: checker-277.tar.bz2; highlights:. Includes about 20 months of change to Clang itself.; New checker for C++ leaks is turned on by default.; Added various small checks and bug fixes.; Added experimental checkers for Objective-C:. New localizability chec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html:283,release,release,283,interpreter/llvm-project/clang/www/analyzer/release_notes.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html,1,['release'],['release']
Deployability,". RooFit. Assorted small bug fixes have been applied. No major new features have been introduced since 5.26; Normalization of RooRealSumPdf changed from sum of coefficients to sum of coefficients*integrals of input functions.; New PDF RooNonCentralChiSquare which is useful for asymptotic analysis of likelihood ratio tests -- like expected significance and error bands.; Ability to ""seal"" data in RooNLLVar, so that an experiment can publish likleihood functions without exposing the data necessary to evaluate the likelihood function. HistFactory. The ROOT release ships with a script prepareHistFactory and a binary hist2workspace in the $ROOTSYS/bin directories.; prepareHistFactory prepares a working area. It creates a results/, data/, and config/ directory. It also copies the HistFactorySchema.dtd and example XML files into the config/ directory. Additionally, it copies a root file into the data/ directory for use with the examples. Usage: hist2workspace input.xml; HistFactorySchema.dtd: This file is located in $ROOTSYS/etc/ specifies the XML schema. It is typically placed in the config/ direc-tory of a working area together with the top-level XML file and the individual channel XML files. The user should not modify this file. The HistFactorySchema.dtd is commented to specify exactly the meaning of the various options. Top-Level XML File. see for example $ROOTSYS/tutorials/histfactory/example.xml; This file is edited by the user. It specifies; ; A top level 'Combination' that is composed of:; 	; several 'Channels', which are described in separate XML files.; 	 several 'Measurements' (corresponding to a full fit of the model) each of which specifies; 	 ; a name for this measurement to be used in tables and files; what is the luminosity associated to the measurement in picobarns; which bins of the histogram should be used; what is the relative uncertainty on the luminosity; what is (are) the parameter(s) of interest that will be measured; which parameters should be fixed/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:559,release,release,559,roofit/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html,1,['release'],['release']
Deployability,". RooFit. This release of ROOT contains RooFit version 3.00. A summary of new features is listed below. RooFit Web documentation moved to ROOT web site; The starting point for online RooFit documentation (Users Manual,; tutorials, slides etc) is now moved to the ROOT website; https://root.cern/topical/#roofit; Error visualization; It is now possible to visualize the effect of the uncertainties on parameters from a fit; on any p.d.f. or function projection. To do so use the new VisualizeError() argument; in a plotOn call. RooFitResult* fr = pdf->fitTo(*data,Save(),...) ;; pdf->plotOn(frame,VisualizeError(*fr),...) ;. Two techniques for error visualization are implemented. The default is; linear error propagation, and results in an error band that is by; construction symmetric. The linear error is calculated as. error(x) = Z* F_a(x) * Corr(a,a') F_a'(x). where F_a(x) = [ f(x,a+da) - f(x,a-da) ] / 2,. with f(x) = the plotted curve; 'da' = error taken from the fit result; Corr(a,a') = the correlation matrix from the fit result; Z = requested significance 'Z sigma band'. The linear method is fast (requires 2*N evaluations of the curve,; where N is the number of parameters), but may not be accurate in the; presence of strong correlations (~>0.9) and at Z>2 due to linear and; Gaussian approximations made. Alternatively, errors can be visualized using a sampling method. In; this method a number of curves is calculated with variations of the; parameter values, as sampled from a multi-variate Gaussian p.d.f. that; is constructed from the fit results covariance matrix. The error(x); is determined by calculating a central interval that capture N% of the; variations for each value of x, where N% is controlled by Z (i.e. Z=1; gives N=68%). The number of sampling curves is chosen to be such that; at least 100 curves are expected to be outside the N% interval. Intervals from; the sampling method can be asymmetric, and may perform better in the; presence of strong correlations, but m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:15,release,release,15,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,1,['release'],['release']
Deployability,". RooFit; New infrastructure for toy MC studies. A new class RooStudyManager has been added that is intended; to replace the present RooMCStudy framework for toy MC; studies on the time scale of ROOT release 5.26. The present RooMCStudy is a small monolithic driver to; execute 'generate-and-fit' style MC studies for a given pdf. It; provides some room for customization, through modules inheriting from; RooAbsMCStudyModule that can modify the standard behavior, but its; design limits the amount of flexibility.; In the new RooStudyManager design, the functionality of; RooMCStudy has been split into two classes: class; RooStudyManager which manages the logistics of running; repetitive studies and class RooGenFitStudy which implements; the functionality of the 'generate-and-fit'-style study of RooMCStudy.; The new design has two big advantages:. Complete freedom in the design of studies, either by tailoring the behavior of RooGenFitStudy or; by using another study module that inherits from RooAbsStudy, and the data that they return.; More flexibility in the mode of execution. The new study manager can execute all study; modules inlines, as was done in RooMCStudy), but also parallelized through PROOF (at present; only PROOF-lite is support, as well as in batch. The code fragment below illustrates the use of the new study manager. // Create workspace with p.d.f; RooWorkspace* ww = new RooWorkspace(""ww"") ;; ww->factory(""Gaussian::g(x[-10,10],mean[-10,10],sigma[3,0.1,10])"") ;. RooGenFitStudy gfs ;; gfs.setGenConfig(""g"",""x"",NumEvents(1000)) ;; gfs.setFitConfig(""g"",""x"",PrintLevel(-1)) ;. RooStudyManager mgr(*ww,gfs) ;. mgr.run(1000) ; // execute 1000 toys inline; mgr.runProof(10000,"""") ; // execute 10000 toys through PROOF-lite. gfs.summaryData()->Print() ;. Workspace and factory improvements. The workspace class RooWorkspace has been augmented with several; new features. The import() method now supports a new argument RenameAllVariablesExcept(const char* suffix, const char ke",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:200,release,release,200,roofit/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html,1,['release'],['release']
Deployability,". RooFit; New tutorial macros available. A completely new set of 70(!) tutorial macros is now available in $ROOTSYS/tutorials/roofit; These macros are divided in several subjects and are all referenced as iluustrations of concepts explained in the forthcoming edition on RooFit Users Manual.; All macros are extensively documented and each is fully functional standalone. The accompanying update; of the Manual is expected mid-September. ; ; BASIC FUNCTIONALITY. rf101_basics.C - Fitting, plotting, toy data generation on one-dimensional p.d.f ; rf102_dataimport.C - Importing data from ROOT TTrees and THx histograms; rf103_interprfuncs.C - Interpreted functions and p.d.f.s; rf104_classfactory.C - The class factory for functions and p.d.f.s; rf105_funcbinding.C - Demonstration of binding ROOT Math functions as RooFit functions and pdfs; rf106_plotdecoration.C - Adding boxes with parameters, statistics to RooPlots.; rf107_plotstyles.C - Demonstration of various plotting styles of data, functions; rf108_plotbinning.C - Plotting unbinned data with alternate and variable binnings; rf109_chi2residpull.C - Calculating chi^2 from histograms and curves in RooPlots,; rf110_normintegration.C - Examples on normalization & integration of p.d.f.s, construction of cumulative distribution functions.; rf111_numintconfig.C - Configuration and customization of how numeric (partial) integrals. ; ADDITION AND CONVOLUTION. rf201_composite.C - Composite p.d.f with signal and background component; rf202_extendedmlfit.C - Setting up an extended maximum likelihood fit; rf203_ranges.C - Fitting and plotting in sub ranges; rf204_extrangefit.C - Extended maximum likelihood fit with alternate range definition; rf205_compplot.C - Options for plotting components of composite p.d.f.s.; rf206_treevistools.C - Tools for visualization of RooAbsArg expression trees; rf207_comptools.C - Tools and utilities for manipulation of composite objects; rf208_convolution.C - One-dimensional numeric convolution; rf209_a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:389,update,update,389,roofit/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html,1,['update'],['update']
Deployability,". Running the analyzer within Xcode. Running the analyzer within Xcode. What is it?; Since Xcode 3.2, users have been able to run the Clang Static Analyzer; directly; within Xcode.; It integrates directly with the Xcode build system and; presents analysis results directly within Xcode's editor.; Can I use the open source analyzer builds with Xcode?; Yes. Instructions are included below. Viewing static analyzer results in Xcode. Key features:. Integrated workflow: Results are integrated within Xcode. There is; no experience of using a separate tool, and activating the analyzer requires a; single keystroke or mouse click.; Transparency: Works effortlessly with Xcode projects (including iPhone projects).; Cons: Doesn't work well with non-Xcode projects. For those,; consider using scan-build. Getting Started; Xcode is available as a free download from Apple on the Mac; App Store, with instructions; available for using the analyzer.; Using open source analyzer builds with Xcode; By default, Xcode uses the version of clang that came bundled with; it to analyze your code. It is possible to change Xcode's behavior to use an; alternate version of clang for this purpose while continuing to use; the clang that came with Xcode for compiling projects.; Why try open source builds?; The advantage of using open source analyzer builds (provided on this website); is that they are often newer than the analyzer provided with Xcode, and thus can; contain bug fixes, new checks, or simply better analysis.; On the other hand, new checks can be experimental, with results of variable; quality. Users are encouraged to file bug reports; (for any version of the analyzer) where they encounter false positives or other; issues.; set-xcode-analyzer; Starting with analyzer build checker-234, analyzer builds contain a command; line utility called set-xcode-analyzer that allows users to change what; copy of clang that Xcode uses for analysis:. $ set-xcode-analyzer -h; Usage: set-xcode-analyzer [options",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/xcode.html:185,integrat,integrates,185,interpreter/llvm-project/clang/www/analyzer/xcode.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/xcode.html,2,['integrat'],"['integrated', 'integrates']"
Deployability,". TMVA Options Reference. TMVA Configuration Options Reference; Reference version: TMVA-v-unknown. TMVA-version @ ROOT. Reference for configuration options defined in the option string of each MVA method booking, and for the definition of data sets used for training and testing (Factory). Table fields:. Option:; The option identifier in the option string (given, e.g., in ""factory->BookMethod(...)"" call). Array:; Can the option be set individually for each input variable via the ""[i]"" tag, where ""i"" is the ith variable?. Default value:; Value used if option is not explicitly set in the configuration option string. Predefined values:; Options can be categories of predefined values among which the user must choose. Description:; Info about the option. Colour codes:. Greenish rows:; Options shared by all MVA methods (through common base class). Bluish rows:; Specific MVA options. Yellowish rows:; Configuration options for minimiser (fitter) classes. Redish rows:; Options for other configurable classes. Available MVA methods (1st row), minimisation tools (2nd row), and other configurables (3rd row):. [MVA::HMatrix] [MVA::Fisher] [MVA::PDERS] [MVA::FDA] [MVA::LD] [MVA::SVM] [MVA::CFMlpANN] [MVA::KNN] [MVA::BDT] [MVA::Boost] [MVA::RuleFit] [MVA::Likelihood] [MVA::MLP] [MVA::Cuts] [MVA::PDEFoam] [MVA::TMlpANN]. [Fitter_SA] [Fitter_MC] [Fitter_Minuit] [Fitter_GA]. [DataSetFactory] [PDF] [Factory]. Configuration options for MVA method :. Configuration options reference for MVA method: HMatrix. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:134,configurat,configuration,134,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['configurat'],['configuration']
Deployability,". TMVA. TMVA version 4.0.1 is included in this root release:. Main changes and new features introduced with TMVA 4. Reorganisation of internal data handling and constructors; of methods to allow to build arbitrary composite MVA methods,; and to deal with multi-class classification and multi-target; regression; ; Extended TMVA to multivariate multi-target regression; ; Any TMVA method can now be boosted (linearly or; non-linearly); ; Transformation of input variables can be chained as wished; ; Weight files are now in XML format; ; New MVA methods ""PDE-Foam"" and ""LD"", both featuring; classification and regression; ; ; Comments. On XML format:; ; The old text format is obsolete though still readable in the; application. Backward compatibility is NOT guaranteed. Please; contact the authors if you require the reading of old text weight; files in TMVA 4.; ; ; Standard macros:; ; The structure of the standard macros has changed: macros are; still in the ""$ROOTSYS/tmva/test"" directory, but distinguished for; classification and regression examples:; ; TMVAClassification.C, TMVAClassificationApplication.C TMVARegression.C, TMVARegressionApplication.C; ; Classification and regression analysis (training) is analysed as; usual via standard macros that can be called from dedicated; GUIs.; ; ; Regression:. Not yet available for all MVA methods. It exists for:; PDE-RS, PDE-Foam, K-NN, LD, FDA, MLP, BDT for single targets; (1D), and MLP for multiple targets (nD).; ; Not all transformation of input variables are available; (only ""Norm"" so far). Regression requires specific evaluation tools:. ; During the training we provide a ranking of input; variables, using various criteria: correlations, transposed; correlation, correlation ratio, and ""mutual information"" between; input variables and regression target. (Correlation ratio and; mutual information implmentations provided by Moritz Backes,; Geneva U); ; After the training, the trained MVA methods are ranked wrt.; the deviations betwe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:52,release,release,52,tmva/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html,1,['release'],['release']
Deployability,". TMVA. TMVA version 4.0.4 is included in this root release. Methods. A new Category method allowing the user to; separate the training data (and accordingly the application; data) into disjoint sub-populations exhibiting significantly; different properties. The separation into phase space regions is; done by applying requirements on the input and/or spectator; variables. In each of these disjoint regions (each event must; belong to one and only one region), an independent training is; performed using the most appropriate MVA method, training; options and set of training variables in that zone. The division; into categories in presence of distinct sub-populations reduces; the correlations between the training variables, improves the; modelling, and hence increases the classification and regression; performance. Presently, the Category method works for; classification only, but regression will follow soon. Please; contact us if urgently needed. An example scripts and data files illustrating how the new; Category method is configured and used. Please check the macros; test/TMVAClassificationCategory.C and; test/TMVAClassificationCategoryApplication.C or the; corresponding executables.; Regression functionality for gradient boosted trees using a Huber loss function. Comments. On Input Data: . New TMVA event vector building. The code for splitting the input; data into training and test samples for all classes and the; mixing of those samples to one training and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:52,release,release,52,tmva/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html,1,['release'],['release']
Deployability,". TMVA. TMVA version 4.1.2 is included in this root release. The changes with respect; to ROOT 5.28 / TMVA 4.1.0 are in detail:. Variable transformations. Variable transformations can now be applied to a user-defined subset; of variables (and regression targets).; Enable variable transformations for general boosting; Extended PDEFoam functionality:. Multiclass classification by training of one discriminator foam for each; variable.; The cell tree can now be plotted from the macro test/PlotFoams. This makes; it easyer to compare the PDEFoam structure to a decision tree.; Variable importance ranking by counting the number of cuts made in each; dimension. The variable, for which the most cuts were done is ranked highest. Fixed the size of the sampling box in PDEFoam:; In TMVA 4.1.0 the size of the PDEFoam sampling box in each dimension was; 2*VolFrac times the foam size. This was contrary to the intention and the; documentation in the UserGuide and is now corrected: In TMVA 4.1.1 the size; of the PDEFoam sampling box in each dimension is now VolFrac times the foam; size. This implies that in TMVA 4.1.1 the VolFrac value for training a PDEFoam; must be doubled in order to give the same results as in TMVA 4.1.0. The default; VolFrac value was also changed from 0.0333 to 0.0666.; New configuration variable ""NbinsMVAoutput"" defining the bins of the MVA output; variables in the TMVA training plots produced via the GUI. As always, Config; settings can be modified in the training script via, eg, the command. (TMVA::gConfig().GetVariablePlotting()).fNbinsMVAoutput = 50;. to be called AFTER initialising the TMVA Factory object. Bug fixes. Requested number of training and testing events was not; correct when pre-selection cuts were applied. Now the number of; requested events scales with the preselection efficiency and hence; does not need to be adjusted with the pre-selection. This also; corrects the problems seen in the Category classifierm, where; pre-selection is used to buil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html:52,release,release,52,tmva/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html,1,['release'],['release']
Deployability,". The covariance or the correlations can be printed and shown; via std::cout as the ostream operator operator$<<$ is overloaded. The; eigenvalues of the error matrix can be calculated using MnEigen, which; should all be positive if the matrix is positive-definite (see below on; $\mbox{MIGRAD}$ and positive-definiteness). The effect of correlations on the individual parameter errors can be; seen as follows. When parameter $\mbox{n}$ is fixed (e.g. via the; method MnMigrad::fix(n)), M inverts the error matrix, removes the row; and column corresponding to parameter $\mbox{n}$, and re-inverts the; result. The effect on the errors of the other parameters will in general; be to make them smaller, since the component due to the uncertainty in; parameter $\mbox{n}$ has now been removed. (In the limit that a; given parameter is uncorrelated with parameter $\mbox{n}$, its error; will not change when parameter $\mbox{n}$ is fixed.) However the; procedure is not reversible, since M forgets the original error matrix,; so if parameter $\mbox{n}$ is then released (e.g. via the method; MnMigrad::release(n)), the error matrix is considered as unknown and has; to be recalculated with appropriate commands. ### $\mbox{MINOS}$ errors ###. The M processor $\mbox{MINOS}$ (MnMinos, see [api:minos]) was; probably the first, and may still be the only, generally available; program to calculate parameter errors taking into account both parameter; correlations and non-linearities. The $\mbox{MINOS}$ error intervals; are in general asymmetric, and may be expensive to calculate,; especially if there are a lot of free parameters and the problem is very; non-linear. $\mbox{MINOS}$ can only operate after a good minimum has already; been found, and the error matrix has been calculated, so the; $\mbox{MINOS}$ error analysis will normally follow a; $\mbox{MIGRAD}$ minimization. The $\mbox{MINOS}$ error for a; given parameter is defined as the change in the value of that parameter; which causes ${\displa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:17313,release,released,17313,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['release'],['released']
Deployability,". The new multilib system does multilib selection based on only a limited set of; command line options, and limits which flags can be used for multilib; selection. This is in order to avoid committing to too large an interface.; Later LLVM versions can add support for multilib selection from more command; line options as needed. Extensible; ----------. It is likely that the configuration format will need to evolve in future to; adapt to new requirements.; Using a format like YAML that supports key-value pairs helps here as it's; trivial to add new keys alongside existing ones. Backwards compatibility; -----------------------. New versions of Clang should be able to use configuration written for earlier; Clang versions.; To avoid behaving in a way that may be subtly incorrect, Clang should be able; to detect if the configuration is too new and emit an error. Forwards compatibility; ----------------------. As an author of a multilib configuration, it should be possible to design the; configuration in such a way that it is likely to work well with future Clang; versions. For example, if a future version of Clang is likely to add support; for newer versions of an architecture and the architecture is known to be; designed for backwards compatibility then it should be possible to express; compatibility for such architecture versions in the multilib configuration. Not GNU spec files; ------------------. The GNU spec files standard is large and complex and there's little desire to; import that complexity to LLVM. It's also heavily oriented towards processing; command line argument strings which is hard to do correctly, hence the large; amount of logic dedicated to that task in the Clang driver. While compatibility; with GNU would bring benefits, the cost in this case is deemed too high. Avoid re-inventing feature detection in the configuration; ---------------------------------------------------------. A large amount of logic in the Clang driver is dedicated to inferring whi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst:11162,configurat,configuration,11162,interpreter/llvm-project/clang/docs/Multilib.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst,2,['configurat'],['configuration']
Deployability,". The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycles. In; this case, of the 610 simulated cycles, two instructions were retired during the; same cycle 399 times (65.4%) and there were 109 cycles where no instructions; were retired. The retire statistics are displayed by using the command option; ``-all-stats`` or ``-retire-stats``. The last table presented is *Register File statistics*. Each physical register; file (PRF) used by the pipeline is presented in this table. In the case of AMD; Jaguar, there are two register files, one for floating-point registers (JFpuPRF); and one for integer registers (JIntegerPRF). The table shows that of the 900; instructions processed, there were 900 mappings created. Since this dot-product; example utilized only floating point registers, the JFPuPRF was responsible for; creating the 900 mappings. However, we see that the pipeline only used a; maximum of 35 of 72 available register slots at any given time. We can conclude; that the floating point PRF was the only register file used for the example, and; that it was never resource constrained. The register file statistics are; displayed by using the command option ``-all-stats`` or; ``-register-file-stats``. In this example, we can conclude that the IPC is mostly limited by data; dependencies, and not by resource pressure. Instruction Flow; ^^^^^^^^^^^^^^^^; This section describes the instruction flow through the default pipeline of; :program:`llvm-mca`, as well as the functional units involved in the process. The default pipeline implements the following sequence of stages used to; process instructions. * Dispatch (Instruction is dispatched to the schedulers).; * Issue (Instruction is issued to the processor pipelines).; * Write Back (Instruction is executed, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipelin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:33347,pipeline,pipeline,33347,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['pipeline'],['pipeline']
Deployability,". These originate mainly from methods present previously in the implementation of the TF1 class. Now they can be used also outside this class. In addition, in order to have a common entry point, interfaces classes for these numerical algorithms have been; included.; These interfaces are as well implemented by classes using the GSL library and located in the MathMore library. The library can be loaded automatically using the ROOT plug-in manager.; In detail, the new classes containing implementations present previously in TF1 are:. ; GaussIntegrator and GaussLegendreIntegrator for numerical integration of one-dimensional functions. The first class uses Gaussian 8 and 16 point quadrature approximation, it provides the translation of the CERNLIB algorithm; DGAUSS by Sigfried Kolbig, and it is used by the TF1::Integral method. The second one uses the Gauss Legendre quadrature formula. It is used by the TF1::IntegralFast method.; These classes implement both the same virtual interface as the adaptive integration methods provided by the MathMore library. They can all be created and used easily via the common class ROOT::Math::IntegratorOneDim providing the interfaces for numerical integration.; New template methods have been also included in the common Integration class in order to be able to integrate automatically any C++ callable object. ROOT::Math::RichardsonDerivator implementing numerical derivation using the Richardson's extrapolation formula (use 2 derivative estimates to compute a third, more accurate estimation). This is used by the TD1::Derivative method. ; BrentRootFinder for finding the root of one-dimensional function using the Brent algorithm. The class inherits from a virtual interface, which is also implemented by the MathMore root finder methods. The user can instantiate, via the common ROOT::Math::RootFinder class, all the various root finder algorithms. The BrentRootFinder class is used by TF1::GetX . ; A similar class, BrentMinimizer1D, provides the po",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v520/index.html:7117,integrat,integration,7117,math/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v520/index.html,1,['integrat'],['integration']
Deployability,". Translating Function Calls; --------------------------. The ``IRTranslator`` also implements the ABI's calling convention by lowering; calls, returns, and arguments to the appropriate physical register usage and; instruction sequences. This is achieved using the ``CallLowering``; implementation,. .. _irtranslator-aggregates:. Aggregates; ^^^^^^^^^^. .. caution::. This has changed since it was written and is no longer accurate. It has not; been refreshed in this pass of improving the documentation as I haven't; worked much in this part of the codebase and it should have attention from; someone more knowledgeable about it. Aggregates are lowered into multiple virtual registers, similar to; SelectionDAG's multiple vregs via ``GetValueVTs``. ``TODO``:; As some of the bits are undef (padding), we should consider augmenting the; representation with additional metadata (in effect, caching computeKnownBits; information on vregs).; See `PR26161 <https://llvm.org/PR26161>`_: [GlobalISel] Value to vreg during; IR to MachineInstr translation for aggregate type. .. _irtranslator-constants:. Translation of Constants; ------------------------. Constant operands are translated as a use of a virtual register that is defined; by a ``G_CONSTANT`` or ``G_FCONSTANT`` instruction. These instructions are; placed in the entry block to allow them to be subject to the continuous CSE; implementation (``CSEMIRBuilder``). Their debug location information is removed; to prevent this from confusing debuggers. This is beneficial as it allows us to fold constants into immediate operands; during :ref:`instructionselect`, while still avoiding redundant materializations; for expensive non-foldable constants. However, this can lead to unnecessary; spills and reloads in an -O0 pipeline, as these virtual registers can have long; live ranges. This can be mitigated by running a `localizer <https://github.com/llvm/llvm-project/blob/main/llvm/lib/CodeGen/GlobalISel/Localizer.cpp>`_; after the translator.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst:2485,continuous,continuous,2485,interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst,2,"['continuous', 'pipeline']","['continuous', 'pipeline']"
Deployability,". Understanding Collections. Understanding Collections. A collection is a group of related objects. You will find it easier to; manage a large number of items as a collection. For example, collections of; points and lines might be managed by a graphics pad. A vertex will have a; collection of tracks. A detector geometry contains collections of shapes,; materials, rotation matrices and sub-detectors.; Collections act as flexible alternatives to traditional data structures; of computer science such as arrays, lists, and trees. Collections can be thought of as polymorphic containers that can contain; different types of elements. For this release of the ROOT system, elements; to be placed in collections must be instances of classes.; These may be classes defined by you or provided by ROOT. Collection elements; must be instances of classes descending from ; TObject. The dependence of collections on TObject may disappear; in the future when all C++ compilers used with the ROOT system fully; support templates. In the mean time, knowing the; role TObject plays in collections can be helpful. In general you don't need to worry about TObject. Many ROOT; classes have TObject as an ancestor. In fact, collections themselves; are descendants of TObject. This makes it possible for collections to; contain other collections (subcollections) in a tree structure. Such trees; are used in the ROOT system to implement components of the graphics system; (graphics pads containing pads), geometries (detectors in detectors), etc. The basic protocol TObject defines for collection elements is shown below:. IsEqual(); Compare(); IsSortable(); Hash(). How to use and override these member functions is shown in the; example program. Types of Collections. The ROOT system implements the following type of collections:; arrays, lists, sorted lists, B-trees, hashtables and maps.; The figure below shows the inheritance hierarchy for the primary; collection classes. Ordered Collections (Sequences). Sequenc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/cont/doc/Understanding_Collections.html:643,release,release,643,core/cont/doc/Understanding_Collections.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/cont/doc/Understanding_Collections.html,1,['release'],['release']
Deployability,". buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; follo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:358454,release,release,358454,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability,". code-block:: c++. auto &JD1 = ... ;; auto &JD2 = ... ;. // Make 'bar' in JD2 an alias for 'foo' from JD1.; JD2.define(; reexports(JD1, SymbolAliasMap({; { Mangle(""bar""), { Mangle(""foo""), JITSymbolFlags::Exported } }; });. The reexports utility can be handy for composing a single JITDylib interface by; re-exporting symbols from several other JITDylibs. .. _Laziness:. Laziness; ========. Laziness in ORC is provided by a utility called ""lazy reexports"". A lazy; reexport is similar to a regular reexport or alias: It provides a new name for; an existing symbol. Unlike regular reexports however, lookups of lazy reexports; do not trigger immediate materialization of the reexported symbol. Instead, they; only trigger materialization of a function stub. This function stub is; initialized to point at a *lazy call-through*, which provides reentry into the; JIT. If the stub is called at runtime then the lazy call-through will look up; the reexported symbol (triggering materialization for it if necessary), update; the stub (to call directly to the reexported symbol on subsequent calls), and; then return via the reexported symbol. By re-using the existing symbol lookup; mechanism, lazy reexports inherit the same concurrency guarantees: calls to lazy; reexports can be made from multiple threads concurrently, and the reexported; symbol can be any state of compilation (uncompiled, already in the process of; being compiled, or already compiled) and the call will succeed. This allows; laziness to be safely mixed with features like remote compilation, concurrent; compilation, concurrent JIT'd code, and speculative compilation. There is one other key difference between regular reexports and lazy reexports; that some clients must be aware of: The address of a lazy reexport will be; *different* from the address of the reexported symbol (whereas a regular; reexport is guaranteed to have the same address as the reexported symbol).; Clients who care about pointer equality will generally wa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:17205,update,update,17205,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['update'],['update']
Deployability,". contents::; :local:. .. only:: PreRelease. .. warning::; These are in-progress notes for the upcoming LLVM |version| release.; Release notes for previous releases can be found on; `the Download Page <https://releases.llvm.org/download.html>`_. Introduction; ============. This document contains the release notes for the LLVM Compiler Infrastructure,; release |release|. Here we describe the status of LLVM, including major improvements; from the previous release, improvements in various subprojects of LLVM, and; some of the current users of the code. All LLVM releases may be downloaded; from the `LLVM releases web site <https://llvm.org/releases/>`_. For more information about LLVM, including information about the latest; release, please check out the `main LLVM web site <https://llvm.org/>`_. If you; have questions or comments, the `Discourse forums; <https://discourse.llvm.org>`_ is a good place to ask; them. Note that if you are reading this file from a Git checkout or the main; LLVM web page, this document applies to the *next* release, not the current; one. To see the release notes for a specific release, please see the `releases; page <https://llvm.org/releases/>`_. Non-comprehensive list of changes in this release; =================================================; .. NOTE; For small 1-3 sentence descriptions, just add an entry at the end of; this list. If your description won't fit comfortably in one bullet; point (e.g. maybe you would like to give an example of the; functionality, or simply have a lot to talk about), see the `NOTE` below; for adding a new subsection. * ... Update on required toolchains to build LLVM; -------------------------------------------. Changes to the LLVM IR; ----------------------. * The `llvm.stacksave` and `llvm.stackrestore` intrinsics now use; an overloaded pointer type to support non-0 address spaces.; * The constant expression variants of the following instructions have been; removed:. * ``and``; * ``or``; * ``lshr``; * ``ash",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst:1138,release,release,1138,interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,1,['release'],['release']
Deployability,". define void @f() prefix i32 123 { ... }. The prefix data can be referenced as,. .. code-block:: llvm. %a = getelementptr inbounds i32, ptr @f, i32 -1; %b = load i32, ptr %a. Prefix data is laid out as if it were an initializer for a global variable; of the prefix data's type. The function will be placed such that the; beginning of the prefix data is aligned. This means that if the size; of the prefix data is not a multiple of the alignment size, the; function's entrypoint will not be aligned. If alignment of the; function's entrypoint is desired, padding must be added to the prefix; data. A function may have prefix data but no body. This has similar semantics; to the ``available_externally`` linkage in that the data may be used by the; optimizers but will not be emitted in the object file. .. _prologuedata:. Prologue Data; -------------. The ``prologue`` attribute allows arbitrary code (encoded as bytes) to; be inserted prior to the function body. This can be used for enabling; function hot-patching and instrumentation. To maintain the semantics of ordinary function calls, the prologue data must; have a particular format. Specifically, it must begin with a sequence of; bytes which decode to a sequence of machine instructions, valid for the; module's target, which transfer control to the point immediately succeeding; the prologue data, without performing any other visible action. This allows; the inliner and other passes to reason about the semantics of the function; definition without needing to reason about the prologue data. Obviously this; makes the format of the prologue data highly target dependent. A trivial example of valid prologue data for the x86 architecture is ``i8 144``,; which encodes the ``nop`` instruction:. .. code-block:: text. define void @f() prologue i8 144 { ... }. Generally prologue data can be formed by encoding a relative branch instruction; which skips the metadata, as in this example of valid prologue data for the; x86_64 architecture, w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:74140,patch,patching,74140,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['patch'],['patching']
Deployability,". {; // demonstrate standard minimization using MIGRAD; // create Minuit parameters with names; MnUserParameters upar;; upar.add(""mean"", mean, 0.1);; upar.add(""sigma"", rms, 0.1);; upar.add(""area"", area, 0.1);. // create MIGRAD minimizer; MnMigrad migrad(theFCN, upar);. // minimize; FunctionMinimum min = migrad();. // output; std::cout<<""minimum: ""<<min<<std::endl;; }. {; // demonstrate full interaction with parameters over subsequent; // minimizations. // create Minuit parameters with names; MnUserParameters upar;; upar.add(""mean"", mean, 0.1);; upar.add(""sigma"", rms, 0.1);; upar.add(""area"", area, 0.1);. // access parameter by name to set limits...; upar.setLimits(""mean"", mean-0.01, mean+0.01);. // ... or access parameter by index; upar.setLimits(1, rms-0.1, rms+0.1);. // create Migrad minimizer; MnMigrad migrad(theFCN, upar);. // fix a parameter...; migrad.fix(""mean"");. // ... and minimize; FunctionMinimum min = migrad();. // output; std::cout<<""minimum: ""<<min<<std::endl;. // release a parameter...; migrad.release(""mean"");. // ... and fix another one; migrad.fix(1);. // and minimize again; FunctionMinimum min1 = migrad();. // output; std::cout<<""minimum1: ""<<min1<<std::endl;. // release the parameter...; migrad.release(1);. // ... and minimize with all three parameters; // (still with limits!); FunctionMinimum min2 = migrad();. // output; std::cout<<""minimum2: ""<<min2<<std::endl;. // remove all limits on parameters...; migrad.removeLimits(""mean"");; migrad.removeLimits(""sigma"");. // ... and minimize again with all three parameters; // (now without limits!); FunctionMinimum min3 = migrad();. // output; std::cout<<""minimum3: ""<<min3<<std::endl;; }. {; // demonstrate MINOS error analysis. // create Minuit parameters with names; MnUserParameters upar;; upar.add(""mean"", mean, 0.1);; upar.add(""sigma"", rms, 0.1);; upar.add(""area"", area, 0.1);. // create Migrad minimizer; MnMigrad migrad(theFCN, upar);. // minimize; FunctionMinimum min = migrad();. // create MINOS error fac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:80417,release,release,80417,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['release'],['release']
Deployability,".. -*- mode: rst -*-. CPyCppyy: Python-C++ bindings interface based on Cling/LLVM; ===========================================================. CPyCppyy is the CPython equivalent of _cppyy in PyPy.; It provides dynamic Python-C++ bindings by leveraging the Cling C++; interpreter and LLVM.; Details and performance are described in; `this paper <http://conferences.computer.org/pyhpc/2016/papers/5220a027.pdf>`_. CPyCppyy is a CPython extension module built on top of the same backend API; as PyPy/_cppyy.; It thus requires the installation of the; `cppyy backend <https://pypi.python.org/pypi/cppyy-backend/>`_; for use, which will pull in Cling.; CPython/cppyy and PyPy/cppyy are designed to be compatible, although there; are differences due to the former being reference counted and the latter; being garbage collected, as well as temporary differences due to different; release cycles of the respective projects. ----. Find the cppyy documentation here:; http://cppyy.readthedocs.io. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/README.rst:528,install,installation,528,bindings/pyroot/cppyy/CPyCppyy/README.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/README.rst,2,"['install', 'release']","['installation', 'release']"
Deployability,".. -*- mode: rst -*-. cppyy: Python-C++ bindings interface based on Cling/LLVM; ========================================================. cppyy provides fully automatic, dynamic Python-C++ bindings by leveraging; the Cling C++ interpreter and LLVM.; It supports both PyPy (natively), CPython, and C++ language standards; through C++17 (and parts of C++20). Details and performance are described in; `this paper <http://cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf>`_,; originally presented at PyHPC'16, but since updated with improved performance; numbers. Full documentation: `cppyy.readthedocs.io <http://cppyy.readthedocs.io/>`_. Notebook-based tutorial: `Cppyy Tutorial <https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb>`_. For Anaconda/miniconda, install cppyy from `conda-forge <https://anaconda.org/conda-forge/cppyy>`_. ----. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/README.rst:514,update,updated,514,bindings/pyroot/cppyy/cppyy/README.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/README.rst,2,"['install', 'update']","['install', 'updated']"
Deployability,".. _changelog:. Changelog; =========. For convenience, this changelog keeps tracks of changes with version numbers; of the main cppyy package, but many of the actual changes are in the lower; level packages, which have their own releases.; See :doc:`packages <packages>`, for details on the package structure.; PyPy support lags CPython support. master; ------. * Fix buffering problems with std::string_view's on Python str objects; * Fix potential buffering problems in creation of initializer lists; * Improved overload selection for classes with deep hierarchies; * Fixed regression when calling static methods with default args on instances; * Fixed regression for pickling enums (in global scope only); * Auto-cast elements of std::vector<T*>, with T a class type; * Add a ``Sequence_Check()`` method to the public API; * Fix offset calculation of ``std::vector<unsigned>`` datamember on Mac arm. 2023-11-15: 3.1.2; -----------------. * Deprecate 3.1.1 b/c of an installation problem outside of virtualenv; * Fix installation problem when purelib and platlib differ; * Alt fix for ""failed to materialize symbols"" on some Linux systems. 2023-11-13: 3.1.0; -----------------. * Use xcrun to find header files on Mac as a last resort; * Fix for ""symbols failed to materialize"" with newer gcc on Linux; * Default to C++20 on all platforms; * Add C++20 standard headers to the PCH; * Fixes for new p11 and p12 type properties; * Fix std::span compatibility; * Look for ``__cast_cpp__`` for custom converters; * Add ``macro()`` helper for evaluation of preprocessor macros; * Extended support for int8_t/uint8_t array and pointer types; * Added ``cppyy.ll.as_memoryview()`` for byte-views of arrays of PODs; * Check for ``nullptr`` as ``false`` in ``operator bool()``; * Automatically array-ify std::vector<some struct>::data() results; * Use __name__ to stringify if an annotation object provides it; * Improve consistency of ``char[]`` arrays; * Extended Numba support; * Update to latest Cling rele",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:229,release,releases,229,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,1,['release'],['releases']
Deployability,".. _convergencectrl:. Convergence Control Operand Bundles; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. A ""convergencectrl"" operand bundle is only valid on a ``convergent`` operation.; When present, the operand bundle must contain exactly one value of token type.; See the :doc:`ConvergentOperations` document for details. .. _moduleasm:. Module-Level Inline Assembly; ----------------------------. Modules may contain ""module-level inline asm"" blocks, which corresponds; to the GCC ""file scope inline asm"" blocks. These blocks are internally; concatenated by LLVM and treated as a single unit, but may be separated; in the ``.ll`` file if desired. The syntax is very simple:. .. code-block:: llvm. module asm ""inline asm code goes here""; module asm ""more can go here"". The strings can contain any character by escaping non-printable; characters. The escape sequence used is simply ""\\xx"" where ""xx"" is the; two digit hex code for the number. Note that the assembly string *must* be parseable by LLVM's integrated assembler; (unless it is disabled), even when emitting a ``.s`` file. .. _langref_datalayout:. Data Layout; -----------. A module may specify a target specific data layout string that specifies; how data is to be laid out in memory. The syntax for the data layout is; simply:. .. code-block:: llvm. target datalayout = ""layout specification"". The *layout specification* consists of a list of specifications; separated by the minus sign character ('-'). Each specification starts; with a letter and may include other information after the letter to; define some aspect of the data layout. The specifications accepted are; as follows:. ``E``; Specifies that the target lays out data in big-endian form. That is,; the bits with the most significance have the lowest address; location.; ``e``; Specifies that the target lays out data in little-endian form. That; is, the bits with the least significance have the lowest address; location.; ``S<size>``; Specifies the natural alignment of the stack ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:130813,integrat,integrated,130813,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['integrat'],['integrated']
Deployability,".. _cuda:. CUDA support; ============. .. warning::. This is an **experimental** feature, available starting with release; 2.3.0.; It is still incomplete and has only been tested on Linux on x86_64. CUDA is supported by passing all JITed code through two pipelines: one for the; CPU and one for the GPU.; Use of the ``__CUDA__`` pre-processor macro enables more fine-grained control; over which pipeline sees what, which is used e.g. in the pre-compiled header:; the GPU pipeline has the CUDA headers included, the CPU pipeline does not.; Building the pre-compiled header will also pick up common CUDA libraries such; as cuBLAS, if installed. Each version of CUDA requires specific versions of Clang and the system; compiler (e.g. gcc) for proper functioning; it's therefore best to build the; backend (``cppyy-cling``) from source for the specific combination of; interest.; The 3.x series of cppyy uses Clang13, the 2.x series Clang9, and this may; limit the CUDA versions supported (especially since CUDA has changed the APIs; for launching kernels in v11). There are three environment variables to control Cling's handling of CUDA:. * ``CLING_ENABLE_CUDA`` (required): set to ``1`` to enable the CUDA; backend. * ``CLING_CUDA_PATH`` (optional): set to the local CUDA installation if not; in a standard location. * ``CLING_CUDA_ARCH`` (optional): set the architecture to target; default is; ``sm_35`` (Clang9 is limited to ``sm_75``). After enabling CUDA with ``CLING_ENABLE_CUDA=1`` CUDA code can be used and; kernels can be launched from JITed code by in ``cppyy.cppdef()``.; There is currently no syntax or helpers yet to launch kernels from Python.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst:114,release,release,114,bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst,7,"['install', 'pipeline', 'release']","['installation', 'installed', 'pipeline', 'pipelines', 'release']"
Deployability,".. _features:. Miscellaneous; =============. .. toctree::; :hidden:. cppyy_features_header. This is a collection of a few more features listed that do not have a proper; place yet in the rest of the documentation. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `Special variables`; -------------------. There are several conventional ""special variables"" that control behavior of; functions or provide (internal) information.; Often, these can be set/used in pythonizations to handle memory management or; Global Interpreter Lock (GIL) release. * ``__python_owns__``: a flag that every bound instance carries and determines; whether Python or C++ owns the C++ instance (and associated memory).; If Python owns the instance, it will be destructed when the last Python; reference to the proxy disappears.; You can check/change the ownership with the __python_owns__ flag that every; bound instance carries.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete(); >>> c.__python_owns__ # True: object created in Python; True; >>>. * ``__creates__``: a flag that every C++ overload carries and determines; whether the return value is owned by C++ or Python: if ``True``, Python owns; the return value, otherwise C++. * ``__set_lifeline__``: a flag that every C++ overload carries and determines; whether the return value should place a back-reference on ``self``, to; prevent the latter from going out of scope before the return value does.; The default is ``False``, but will be automatically set at run-time if a; return value's address is a C++ object pointing into the memory of ``this``,; or if ``self`` is a by-value return. * ``__release_gil__``: a flag that every C++ overload carries and determine",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:800,release,release,800,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,1,['release'],['release']
Deployability,".. _github-reviews:. ======================; LLVM GitHub User Guide; ======================. Introduction; ============; The LLVM Project uses `GitHub <https://github.com/>`_ for; `Source Code <https://github.com/llvm/llvm-project>`_,; `Releases <https://github.com/llvm/llvm-project/releases>`_,; `Issue Tracking <https://github.com/llvm/llvm-project/issues>`_., and; `Code Reviews <https://github.com/llvm/llvm-project/pulls>`_. This page describes how the LLVM Project users and developers can; participate in the project using GitHub. Branches; ========. It is possible to create branches that starts with `users/<username>/`, however this is; intended to be able to support ""stacked"" pull-request. Do not create any branches in the; llvm/llvm-project repository otherwise, please use a fork (see below). User branches that; aren't associated with a pull-request **will be deleted**. Pull Requests; =============; The LLVM project is using GitHub Pull Requests for Code Reviews. This document; describes the typical workflow of creating a Pull Request and getting it reviewed; and accepted. This is meant as an overview of the GitHub workflow, for complete; documentation refer to `GitHub's documentation <https://docs.github.com/pull-requests>`_. GitHub Tools; ------------; You can interact with GitHub in several ways: via git command line tools,; the web browser, `GitHub Desktop <https://desktop.github.com/>`_, or the; `GitHub CLI <https://cli.github.com>`_. This guide will cover the git command line; tools and the GitHub CLI. The GitHub CLI (`gh`) will be most like the `arc` workflow and; recommended. Creating Pull Requests; ----------------------; Keep in mind that when creating a pull request, it should generally only contain one; self-contained commit initially.; This makes it easier for reviewers to understand the introduced changes and; provide feedback. It also helps maintain a clear and organized commit history; for the project. If you have multiple changes you want to int",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitHub.rst:284,release,releases,284,interpreter/llvm-project/llvm/docs/GitHub.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitHub.rst,1,['release'],['releases']
Deployability,".. _gmir:. Generic Machine IR; ==================. .. contents::; :local:. Generic MIR (gMIR) is an intermediate representation that shares the same data; structures as :doc:`MachineIR (MIR) <../MIRLangRef>` but has more relaxed; constraints. As the compilation pipeline proceeds, these constraints are; gradually tightened until gMIR has become MIR. The rest of this document will assume that you are familiar with the concepts; in :doc:`MachineIR (MIR) <../MIRLangRef>` and will highlight the differences; between MIR and gMIR. .. _gmir-instructions:. Generic Machine Instructions; ----------------------------. .. note::. This section expands on :ref:`mir-instructions` from the MIR Language; Reference. Whereas MIR deals largely in Target Instructions and only has a small set of; target independent opcodes such as ``COPY``, ``PHI``, and ``REG_SEQUENCE``,; gMIR defines a rich collection of ``Generic Opcodes`` which are target; independent and describe operations which are typically supported by targets.; One example is ``G_ADD`` which is the generic opcode for an integer addition.; More information on each of the generic opcodes can be found at; :doc:`GenericOpcode`. The ``MachineIRBuilder`` class wraps the ``MachineInstrBuilder`` and provides; a convenient way to create these generic instructions. .. _gmir-gvregs:. Generic Virtual Registers; -------------------------. .. note::. This section expands on :ref:`mir-registers` from the MIR Language; Reference. Generic virtual registers are like virtual registers but they are not assigned a; Register Class constraint. Instead, generic virtual registers have less strict; constraints starting with a :ref:`gmir-llt` and then further constrained to a; :ref:`gmir-regbank`. Eventually they will be constrained to a register class; at which point they become normal virtual registers. Generic virtual registers can be used with all the virtual register API's; provided by ``MachineRegisterInfo``. In particular, the def-use chain API's can",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:262,pipeline,pipeline,262,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,1,['pipeline'],['pipeline']
Deployability,".. _history:. History; =======. .. toctree::; :hidden:. What is now called `cppyy` started life as `RootPython` from `CERN`_, but; cppyy is not associated with CERN (it is still used there, however,; underpinning `PyROOT`_). Back in late 2002, Pere Mato of CERN, had the idea of using the `CINT`_ C++; interpreter, which formed the interactive interface to `ROOT`_, to call from; Python into C++: this became RootPython.; This binder interfaced with Python through `boost.python`_ (v1), transpiling; Python code into C++ and interpreting the result with CINT.; In early 2003, I ported this code to boost.python v2, then recently released.; In practice, however, re-interpreting the transpiled code was unusably slow,; thus I modified the code to make direct use of CINT's internal reflection; system, gaining about 25x in performance.; I presented this work as `PyROOT` at the ROOT Users' Workshop in early 2004,; and, after removing the boost.python dependency by using the C-API directly; (gaining another factor 7 in speedup!), it was included in ROOT.; PyROOT was presented at the SciPy'06 conference, but was otherwise not; advocated outside of High Energy Physics (HEP). In 2010, the PyPy core developers and I held a `sprint at CERN`_ to use; `Reflex`, a standalone alternative to CINT's reflection of C++, to add; automatic C++ bindings, PyROOT-style, to `PyPy`_.; This is where the name ""cppyy"" originated.; Coined by Carl Friedrich Bolz, if you want to understand the meaning, just; pronounce it slowly: cpp-y-y. After the ROOT team replaced CINT with `Cling`_, PyROOT soon followed.; As part of Google's Summer of Code '16, Aditi Dutta moved PyPy/cppyy to Cling; as well, and packaged the code for use through `PyPI`_.; I continued this integration with the Python eco-system by forking PyROOT,; reducing its dependencies, and repackaging it as CPython/cppyy.; The combined result is the current cppyy project.; Mid 2018, version 1.0 was released. .. _`CERN`: https://cern.ch/; .. _`PyROOT`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst:629,release,released,629,bindings/pyroot/cppyy/cppyy/doc/source/history.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst,1,['release'],['released']
Deployability,".. _installation:. Installation; ============. cppyy requires a (modern) C++ compiler.; When installing through `conda-forge`_, ``conda`` will install the compiler; for you, to match the other conda-forge packages.; When using ``pip`` and the wheels from `PyPI`_, you minimally need gcc5,; clang5, or MSVC'17. .. note::. On Windows, a command prompt from which to run Python (or Python run; directly) needs to be opened from within an environment with MSVC setup,; otherwise the compiler will not be accessible. When installing from source, the only requirement is a compiler that supports; C++14, this in order to build LLVM. With CPython on Linux or MacOS, probably by far the easiest way to install; cppyy, is through conda-forge on `Anaconda`_ (or `miniconda`_).; A Windows recipe for ``conda`` is not available yet, but is forthcoming, so; use ``pip`` for that platform for now (see below).; PyPI always has the authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ vir",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:93,install,installing,93,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,5,"['install', 'release']","['install', 'installing', 'releases']"
Deployability,".. _numba:. Numba support; =============. .. caution::. This is an **experimental** feature, available starting with release; 2.4.0.; It is still incomplete (see listing below) and has only been tested on; Linux on x86_64. Numba `is a JIT compiler`_ for Python functions that can be statically typed; based on their input arguments.; Since C++ objects are always statically typed and already implemented at the; machine level, they can be dynamically integrated into the Numba type tracing; and lowering by exposing type details through C++ reflection at runtime. JIT-compiling traces of mixed Python/bound C++ code reduces, and in some; cases removes, the overhead of boxing/unboxing native data into their Python; proxies and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; woul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:117,release,release,117,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,2,"['integrat', 'release']","['integrated', 'release']"
Deployability,".. _packages:. PyPI Packages; =============. Cppyy; -----. The ``cppyy`` module is a frontend (see :ref:`Package Structure; <package-structure>`), and most of the code is elsewhere. However, it does; contain the docs for all of the modules, which are built using; Sphinx: http://www.sphinx-doc.org/en/stable/ and published to; http://cppyy.readthedocs.io/en/latest/index.html using a webhook. To create; the docs::. $ pip install sphinx_rtd_theme; Collecting sphinx_rtd_theme; ...; Successfully installed sphinx-rtd-theme-0.2.4; $ cd docs; $ make html. The Python code in this module supports:. * Interfacing to the correct backend for CPython or PyPy.; * Pythonizations (TBD). Cppyy-backend; -------------. The ``cppyy-backend`` module contains two areas:. * A patched copy of cling; * Wrapper code. Package structure; -----------------; .. _package-structure:. There are four PyPA packages involved in a full installation, with the; following structure::. (A) _cppyy (PyPy); / \; (1) cppyy (3) cppyy-backend -- (4) cppyy-cling; \ /; (2) CPyCppyy (CPython). The user-facing package is always ``cppyy`` (1).; It is used to select the other (versioned) required packages, based on the; python interpreter for which it is being installed. Below (1) follows a bifurcation based on interpreter.; This is needed for functionality and performance: for CPython, there is the; CPyCppyy package (2).; It is written in C++, makes use of the Python C-API, and installs as a Python; extension module.; For PyPy, there is the builtin module ``_cppyy`` (A).; This is not a PyPA package.; It is written in RPython as it needs access to low-level pointers, JIT hints,; and the ``_cffi_backend`` backend module (itself builtin). Shared again across interpreters is the backend, which is split in a small; wrapper (3) and a large package that contains Cling/LLVM (4).; The former is still under development and expected to be updated frequently.; It is small enough to download and build very quickly.; The latter, howe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst:422,install,install,422,bindings/pyroot/cppyy/cppyy/doc/source/packages.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst,4,"['install', 'patch']","['install', 'installation', 'installed', 'patched']"
Deployability,".. _phabricator-reviews:. =============================; Code Reviews with Phabricator; =============================. .. warning::. Phabricator is deprecated and will be switched to read-only mode in October; 2023, for new code contributions use :ref:`GitHub Pull Requests <github-reviews>`. .. contents::; :local:. If you prefer to use a web user interface for code reviews, you can now submit; your patches for Clang and LLVM at `LLVM's Phabricator`_ instance. While Phabricator is a useful tool for some, the relevant -commits mailing list; is the system of record for all LLVM code review. The mailing list should be; added as a subscriber on all reviews, and Phabricator users should be prepared; to respond to free-form comments in mail sent to the commits list. Sign up; -------. To get started with Phabricator, navigate to `https://reviews.llvm.org`_ and; click the power icon in the top right. You can register with a GitHub account,; a Google account, or you can create your own profile. Make *sure* that the email address registered with Phabricator is subscribed; to the relevant -commits mailing list. If you are not subscribed to the commit; list, all mail sent by Phabricator on your behalf will be held for moderation. Note that if you use your git user name as Phabricator user name,; Phabricator will automatically connect your submits to your Phabricator user in; the `Code Repository Browser`_. Requesting a review via the command line; ----------------------------------------. Phabricator has a tool called *Arcanist* to upload patches from; the command line. To get you set up, follow the; `Arcanist Quick Start`_ instructions. You can learn more about how to use arc to interact with; Phabricator in the `Arcanist User Guide`_.; The basic way of creating a revision for the current commit in your local; repository is to run:. ::. arc diff HEAD~. Sometime you may want to create a draft revision to show the proof of concept; or for experimental purposes, In that case you ca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst:402,patch,patches,402,interpreter/llvm-project/llvm/docs/Phabricator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst,1,['patch'],['patches']
Deployability,".. _pipeline:. Core Pipeline; =============. .. toctree::; :hidden:. IRTranslator; Legalizer; RegBankSelect; InstructionSelect. The core pipeline of GlobalISel is:. .. image:: pipeline-overview.png. The four passes shown in the diagram consist of:. :doc:`IRTranslator`. Converts :doc:`LLVM-IR <../LangRef>` into :doc:`gMIR (Generic MIR) <GMIR>`.; This is largely a direct translation and has little target customization.; It's somewhat analogous to SelectionDAGBuilder but builds a flavour of MIR; called gMIR instead of a specialized representation. gMIR uses exactly the; same data structures as MIR but has more relaxed constraints. For example,; a virtual register may be constrained to a particular type without also; constraining it to a specific register class. :doc:`Legalizer`. Replaces unsupported operations with supported ones. In other words, it shapes; the gMIR to suit what the backend can support. There is a very small set of; operations which targets are required to support but aside from that targets; can shape the MIR as they wish. :doc:`Register Bank Selector <RegBankSelect>`. Binds virtual registers to register banks. This pass is intended to minimize; cross-register-bank copies by clustering portions of the MIR together. :doc:`Instruction Select <InstructionSelect>`. Select target instructions using the gMIR. At this point, the gMIR has been; constrained enough that it becomes MIR. Although we tend to talk about them as distinct passes, it should be noted that; there's a good deal of flexibility here and it's ok for things to happen; earlier than described below. For example, it's not unusual for the legalizer to; legalize an intrinsic directly to a target instruction. The concrete; requirement is that the following additional constraints are preserved after; each of these passes:. IRTranslator. The representation must be gMIR, MIR, or a mixture of the two after this pass.; The majority will typically be gMIR to begin with but later passes will; gradually tr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:137,pipeline,pipeline,137,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,2,['pipeline'],"['pipeline', 'pipeline-overview']"
Deployability,".. _porting:. Porting GlobalISel to A New Target; ==================================. There are four major classes to implement by the target:. * :ref:`CallLowering <translator-call-lower>` --- lower calls, returns, and; arguments according to the ABI.; * :ref:`RegisterBankInfo <api-registerbankinfo>` --- describe; :ref:`gmir-regbank` coverage, cross-bank copy cost, and the mapping of; operands onto banks for each instruction.; * :ref:`LegalizerInfo <api-legalizerinfo>` --- describe what is legal, and how; to legalize what isn't.; * :ref:`InstructionSelector <api-instructionselector>` --- select generic MIR; to target-specific MIR. Additionally:. * ``TargetPassConfig`` --- create the passes constituting the pipeline,; including additional passes not included in the :ref:`pipeline`. Tutorials; =========. We'd recommend watching `this tutorial; <https://www.llvm.org/devmtg/2017-10/#tutorial2>`_ from the 2017 LLVM DevMeeting; which gave an overview of how to bring up a new backend in GlobalISel.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Porting.rst:717,pipeline,pipeline,717,interpreter/llvm-project/llvm/docs/GlobalISel/Porting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Porting.rst,2,['pipeline'],['pipeline']
Deployability,".. _testing:. Test suite; ==========. The cppyy tests live in the top-level cppyy package, can be run for; both CPython and PyPy, and exercises the full setup, including the backend.; Most tests are standalone and can be run independently, with a few exceptions; in the template tests (see file ``test_templates.py``). To run the tests, first install cppyy by any usual means, then clone the; cppyy repo, and enter the ``test`` directory::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy/test. Next, build the dictionaries, the manner of which depends on your platform.; On Linux or MacOS-X, run ``make``::. $ make all. On Windows, run the dictionary building script::. $ python make_dict_win32.py all. Next, make sure you have `pytest`_ installed, for example with ``pip``::. $ python -m pip install pytest. and finally run the tests::. $ python -m pytest -sv. On Linux and MacOS-X, all tests should succeed.; On MS Windows 32bit there are 4 failing tests, on 64bit there are 5 still; failing. .. _`pytest`: https://docs.pytest.org/en/latest/; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst:343,install,install,343,bindings/pyroot/cppyy/cppyy/doc/source/testing.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst,3,['install'],"['install', 'installed']"
Deployability,".. _utilities:. Utilities; =========. The ``cppyy-backend`` package brings in the following utilities to help; with repackaging and redistribution:. * cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class load",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:426,install,installed,426,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,3,"['configurat', 'install']","['configuration', 'installation', 'installed']"
Deployability,".. role:: raw-html(raw); :format: html. Libclang tutorial; =================; The C Interface to Clang provides a relatively small API that exposes facilities for parsing source code into an abstract syntax tree (AST), loading already-parsed ASTs, traversing the AST, associating physical source locations with elements within the AST, and other facilities that support Clang-based development tools.; This C interface to Clang will never provide all of the information representation stored in Clang's C++ AST, nor should it: the intent is to maintain an API that is relatively stable from one release to the next, providing only the basic functionality needed to support development tools.; The entire C interface of libclang is available in the file `Index.h`_. Essential types overview; -------------------------. All types of libclang are prefixed with ``CX``. CXIndex; ~~~~~~~; An Index that consists of a set of translation units that would typically be linked together into an executable or library. CXTranslationUnit; ~~~~~~~~~~~~~~~~~; A single translation unit, which resides in an index. CXCursor; ~~~~~~~~; A cursor representing a pointer to some element in the abstract syntax tree of a translation unit. Code example; """""""""""""""""""""""". .. code-block:: cpp. // file.cpp; struct foo{; int bar;; int* bar_pointer;; };. .. code-block:: cpp. #include <clang-c/Index.h>; #include <iostream>. int main(){; CXIndex index = clang_createIndex(0, 0); //Create index; CXTranslationUnit unit = clang_parseTranslationUnit(; index,; ""file.cpp"", nullptr, 0,; nullptr, 0,; CXTranslationUnit_None); //Parse ""file.cpp"". if (unit == nullptr){; std::cerr << ""Unable to parse translation unit. Quitting.\n"";; return 0;; }; CXCursor cursor = clang_getTranslationUnitCursor(unit); //Obtain a cursor at the root of the translation unit; }. Visiting elements of an AST; ~~~~~~~~~~~~~~~~~~~~~~~~~~~; The elements of an AST can be recursively visited with pre-order traversal with ``clang_visitChildren``. .. code-bloc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibClang.rst:595,release,release,595,interpreter/llvm-project/clang/docs/LibClang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibClang.rst,1,['release'],['release']
Deployability,"..; !!!!NOTE!!!!; This file is automatically generated, in part. Do not edit the style options; in this file directly. Instead, modify them in include/clang/Format/Format.h; and run the docs/tools/dump_format_style.py script to update this file. .. raw:: html. <style type=""text/css"">; .versionbadge { background-color: #1c913d; height: 20px; display: inline-block; min-width: 120px; text-align: center; border-radius: 5px; color: #FFFFFF; font-family: ""Verdana,Geneva,DejaVu Sans,sans-serif""; }; </style>. .. role:: versionbadge. ==========================; Clang-Format Style Options; ==========================. :doc:`ClangFormatStyleOptions` describes configurable formatting style options; supported by :doc:`LibFormat` and :doc:`ClangFormat`. When using :program:`clang-format` command line utility or; ``clang::format::reformat(...)`` functions from code, one can either use one of; the predefined styles (LLVM, Google, Chromium, Mozilla, WebKit, Microsoft) or; create a custom style by configuring specific style options. Configuring Style with clang-format; ===================================. :program:`clang-format` supports two ways to provide custom style options:; directly specify style configuration in the ``-style=`` command line option or; use ``-style=file`` and put style configuration in the ``.clang-format`` or; ``_clang-format`` file in the project directory. When using ``-style=file``, :program:`clang-format` for each input file will; try to find the ``.clang-format`` file located in the closest parent directory; of the input file. When the standard input is used, the search is started from; the current directory. When using ``-style=file:<format_file_path>``, :program:`clang-format` for; each input file will use the format file located at `<format_file_path>`.; The path may be absolute or relative to the working directory. The ``.clang-format`` file uses YAML format:. .. code-block:: yaml. key1: value1; key2: value2; # A comment.; ... The configuration file can",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:228,update,update,228,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['update'],['update']
Deployability,"..; 0 2 4 6 8 10 12 14 16 18 ; >>> . Yes, that is perfectly functional, but it is also very clunky.; Contrast this to the (automatic) pythonization:. .. code-block:: python. >>> for key, value in m:; ... print(value, end=' '); ...; 0 2 4 6 8 10 12 14 16 18; >>>. Such a pythonization can be written completely in Python using the bound C++; methods, with no intermediate language necessary.; Since it is written on abstract features, there is also only one such; pythonization that works for all STL map instantiations. Python callbacks; ----------------. Since bound C++ entities are fully functional Python ones, pythonization can; be done explicitly in an end-user facing Python module.; However, that would prevent lazy installation of pythonizations, so instead a; callback mechanism is provided. A callback is a function or callable object taking two arguments: the Python; proxy class to be pythonized and its C++ name.; The latter is provided to allow easy filtering.; This callback is then installed through ``cppyy.py.add_pythonization`` and; ideally only for the relevant namespace (installing callbacks for classes in; the global namespace is supported, but beware of name clashes). Pythonization is most effective of well-structured C++ libraries that have; idiomatic behaviors.; It is then straightforward to use Python reflection to write rules.; For example, consider this callback that looks for the conventional C++; function ``GetLength`` and replaces it with Python's ``__len__``:. .. code-block:: python. >>> import cppyy; >>>; >>> def replace_getlength(klass, name):; ... try:; ... klass.__len__ = klass.__dict__['GetLength']; ... del klass.GetLength; ... except KeyError:; ... pass; ...; >>> cppyy.py.add_pythonization(replace_getlength, 'MyNamespace'); >>>; >>> cppyy.cppdef(""""""; ... namespace MyNamespace {; ... class MyClass {; ... public:; ... MyClass(int i) : fInt(i) {}; ... int GetLength() { return fInt; }; ... ; ... private:; ... int fInt;; ... };; ... }""""""); True; >>",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst:1741,install,installed,1741,bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst,1,['install'],['installed']
Deployability,".20 in addition to these notes. Bindings - packages related to the interplay with other programming languages (Python, Ruby); Cint - the C++ interpreter; Core - the basic ROOT functionality; Geometry - building, representing and drawing geometrical objects; 2D Graphics - ROOT's two dimensional graphics interface; 3D Graphics - ROOT's three dimensional graphics interface; Graphical User Interface - from basic GUI elements to ROOT's own, complete dialogs; Histograming - counting values, spectra, and drawing them; HTML - the documentation generator; Input/Ouput - storing and reading data; Mathemathics - everything one can use to calculate: minimizers, matrixes, FFT, and much more; Miscellaneous - things that didn't make it into the other groups: table ; Monte Carlo - monte carlo and physics simulation interfaces; Networking - network-related parts, e.g. protocols and authentication interfaces; PROOF - parallel ROOT facility; RooFit - a fitting library; SQL - database interfaces; TMVA - multivariate analysis tools; Trees - ROOT's unique container class and related utilities. Binaries for all supported platforms are available at:. http://root.cern.ch/root/Version521.html; Versions for AFS have also been updated. See the list of supported; platforms:; http://root.cern.ch/Welcome.html. For more information, see:. http://root.cern.ch; The following people have contributed to this new version:; Ilka Antcheva,; Jean-Fran�ois Bastien, ; Bertrand Bellenot,; Rene Brun,; Philippe Canal,; Olivier Couet,; Kyle Cranmer,; Valeri Fine,; Leo Franco, ; Gerri Ganis,; Andrei Gheata,; Mihaela Gheata,; David Gonzalez Maline, ; Andreas Hoecker, ; Jan Iwaszkiewicz, ; Lukasz Janyst, ; Anna Kreshuk, ; Wim Lavrijsen,; Josef Leydold,; Sergei Linev,; Anar Manafov, ; Diego Marcos-Segura, ; Lorenzo Moneta,; Axel Naumann,; Eddy Offermann, ; Timur Pocheptsov,; Fons Rademakers,; Paul Russo, ; Gregory Schott,; Stefan Schmitt,; Alja Tadel, ; Matevz Tadel, ; Wouter Verkerke, ; Hady Zalek ; Igor Smirnov . ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v522/index.html:1468,update,updated,1468,doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v522/index.html,1,['update'],['updated']
Deployability,".4.1 Stack Operations; ##########################. .. note::. This section replaces DWARF Version 5 section 2.5.1.3. The following operations manipulate the DWARF stack. Operations that index the; stack assume that the top of the stack (most recently added entry) has index 0.; They allow the stack entries to be either a value or location description. If any stack entry accessed by a stack operation is an incomplete composite; location description (see; :ref:`amdgpu-dwarf-composite-location-description-operations`), then the DWARF; expression is ill-formed. .. note::. These operations now support stack entries that are values and location; descriptions. .. note::. If it is desired to also make them work with incomplete composite location; descriptions, then would need to define that the composite location storage; specified by the incomplete composite location description is also replicated; when a copy is pushed. This ensures that each copy of the incomplete composite; location description can update the composite location storage they specify; independently. 1. ``DW_OP_dup``. ``DW_OP_dup`` duplicates the stack entry at the top of the stack. 2. ``DW_OP_drop``. ``DW_OP_drop`` pops the stack entry at the top of the stack and discards it. 3. ``DW_OP_pick``. ``DW_OP_pick`` has a single unsigned 1-byte operand that represents an index; I. A copy of the stack entry with index I is pushed onto the stack. 4. ``DW_OP_over``. ``DW_OP_over`` pushes a copy of the entry with index 1. *This is equivalent to a* ``DW_OP_pick 1`` *operation.*. 5. ``DW_OP_swap``. ``DW_OP_swap`` swaps the top two stack entries. The entry at the top of the; stack becomes the second stack entry, and the second stack entry becomes the; top of the stack. 6. ``DW_OP_rot``. ``DW_OP_rot`` rotates the first three stack entries. The entry at the top of; the stack becomes the third stack entry, the second entry becomes the top of; the stack, and the third entry becomes the second entry. *Examples illustrating ma",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:69362,update,update,69362,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['update'],['update']
Deployability,".; - Ensures any; following global; data read is no; older than the load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vm/vscnt(0). - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 4. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; st",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:367679,release,released,367679,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['released']
Deployability,".; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; atomicrmw rele",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:260482,release,released,260482,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['released']
Deployability,".; 3. If the `XDG_RUNTIME_DIR` environment variable is set, then take the token from the contents of `$XDG_RUNTIME_DIR/bt_u$ID`(this additional location is intended to provide improved security for shared login environments as `$XDG_RUNTIME_DIR` is defined to be user-specific as opposed to a system-wide directory.).; 4. Otherwise, take the token from `/tmp/bt_u$ID`. ## GUI Libraries. ### RBrowser improvements. - central factory methods to handle browsing, editing and drawing of different classes; - simple possibility to extend RBrowser on user-defined classes; - support of web-based geometry viewer; - better support of TTree drawing; - server-side handling of code editor and image viewer widgets; - rbrowser content is fully recovered when web-browser is reloaded; - load of widgets code only when really required (shorter startup time for RBrowser). ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ## JavaScript ROOT. ### Major JSROOT update to version 6. - update all used libraries `d3.js`, `three.js`, `MathJax.js`, openui5; - change to Promise based interface for all async methods, remove call-back arguments; - change scripts names, core scripts name now `JSRoot.core.js`; - unify function/methods naming conventions, many changes in method names; - provide central code loader via `JSROOT.require`, supporting 4 different loading engines; - many nice features and many bug fixes; see JSROOT v6 release notes. ## Tutorials. ## Class Reference Guide. ## Build, Configuration and Testing Infrastructure. - a new cmake variable, `CMAKE_INSTALL_PYTHONDIR`, has been added: it allows customization of the installation directory of ROOT's python modules; - the developer build option `asserts` is introduced to enable/disable asserts via the `NDEBUG` C/CXX flag. Asserts are always enabled for `CMAKE_BUILD_TYPE=Debug` and `dev=ON`. The previous behavior of the builds set via the `CMAKE_BUILD_TYPE` variable has not changed.; - `CMAKE_CXX_STANDARD`, i.e. the C++ standard",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:27393,update,update,27393,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['update'],['update']
Deployability,".; 5. One could enable status line where current tooltip info will be shown; 6. Improve enlarge functionality - now works with all layouts; 7. Do not display all canvas tool buttons by default - provide toggle button instead; 8. Let move TAxis title, its position now similar to ROOT graphics; 9. Support 'col0' option for TH2Poly class to suppress empty bins; 10. Implement for TH3 'box2', 'box3', 'glbox2', 'glcol' draw options; 11. Support more superscript/subscript letters in normal text output; 12. Correctly handle unzoom with logx/logy scales; 13. Let disable stamp parameter in file url with ""-"" sign at the end of file name; 14. Let use quotes in the URL parameters to protect complex arguments with special symbols; 15. Introduce direct streamers - like TBasket or TRef; Benefit - one can add custom streamers of such kind or reuse existing; 16. Handle TMatrixTSym classes in I/O; 17. Correctly count TH3 statistic in TTree::Draw; 18. Recognize bower installation when ""bower_components/jsroot/scripts"" string; appears in the script path (#120). ## Changes in 5.0.3; 1. Fix - prevent exception when discover HTML element position (#121); 2. Fix - prevent I/O failure when server automatically gzip response (#119); 3. Fix - lego drawing for stacked TH1 histograms; 4. Fix - when change global tooltips settings, also change for each sub-pad. ## Changes in 5.0.2; 1. Fix - read branch entries as arrays; 2. Fix - command submission to THttpServer; 3. Fix - let refill statbox also for empty histogram; 4. Fix - problem with online TTree::Draw and ROOT6. ## Changes in 5.0.1; 1. Support older ROOT files, created before 2010; 2. Support TBranchObject - appears in old files; 3. Correctly set TBasket buffer position for the entry; 4. Fix - problem with empty STL containers; 5. Fix - empty baskets at the end of branch store; 6. Fix - problem with zooming in THStack. ## Changes in 5.0.0; 1. Reading TTree data; - all kinds of branches, including split STL containers; - branches with several",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:45721,install,installation,45721,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['install'],['installation']
Deployability,.; ; DATA AND CATEGORIES. rf401_importttreethx.C -Overview of advanced option for importing data from ROOT TTree and THx histograms; rf402_datahandling.C - Tools for manipulation of (un)binned datasets; rf403_weightedevts.C - Using weights in unbinned datasets; rf404_categories.C - Working with RooCategory objects to describe discrete variables; rf405_realtocatfuncs.C - Demonstration of real-->discrete mapping functions; rf406_cattocatfuncs.C - Demonstration of discrete-->discrete (invertable) functions; rf407_latextables.C - Latex printing of lists and sets of RooArgSets; ; ORGANIZATION AND SIMULTANEOUS FITS. rf501_simultaneouspdf.C - Using simultaneous p.d.f.s to describe simultaneous fits to multiple datasets; rf502_wspacewrite.C - Creating and writing a workspace; rf503_wspaceread.C - Reading and using a workspace; rf504_simwstool.C - Using RooSimWSTool to construct a simultaneous p.d.f that is built of variations of an input p.d.f; rf505_asciicfg.C - Reading and writing ASCII configuration files; rf506_msgservice.C - Tuning and customizing the RooFit message logging facility; rf507_debugtools.C - Using the RooFit memory tracing debug tool; rf508_listsetmanip.C - RooArgSet and RooArgList tools and tricks; ; LIKELIHOOD AND MINIMIZATION. rf601_intminuit.C - Interactive minimization with MINUIT; rf602_chi2fit.C - Setting up a binning chi^2 fit; rf603_multicpu.C - Setting up a multi-core parallelized unbinned maximum likelihood fit; rf604_constraints.C - Fitting with constraints; rf605_profilell.C - Working with the profile likelihood estimator; rf606_nllerrorhandling.C - Understanding and customizing error handling in likelihood evaluations; rf607_fitresult.C - Demonstration of options of the RooFitResult class; ; SPECIAL PDFS. rf701_efficiencyfit.C - Unbinned maximum likelihood fit of an efficiency eff(x) function; rf702_efficiencyfit_2D.C - Unbinned maximum likelihood fit of an efficiency eff(x) function to; rf703_effpdfprod.C - Using a product of an (acceptance),MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:4535,configurat,configuration,4535,roofit/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html,1,['configurat'],['configuration']
Deployability,".; Add support for full-scene anti-aliasing (the actual benefits; depend on graphics card / driver). It is controlled via rootrc,; e.g.:. OpenGL.Framebuffer.Multisample: 4. Minor changes. Extend configurability of GL event-handler to allow inversion of; controls from scene-centric to viewer-centric. The following rootrc; variables control the behaviour:. OpenGL.EventHandler.ViewerCentricControls: 1; OpenGL.EventHandler.ArrowKeyFactor: -1.0; OpenGL.EventHandler.MouseDragFactor: -1.0; OpenGL.EventHandler.MouseWheelFactor: -1.0. Add camera auto-rotation support. Controls are available from the; ""Extras"" tab of TGLViewer GUI editor. Implemented in class; TGLAutoRotator, can be sub-classed and attached to a viewer via; TGLViewer::SetAutoRotator() method.; Added new overlay element class TGLCameraGuide that shows the; orientation of major axes. To use, call this on a TGLViewer object:. gl_viewer->AddOverlayElement(new TGLCameraGuide(0.9, 0.1, 0.08));. Fix an issue with GL-clip object not being properly updated after; a scene update.; Hide / show menu-bar with a time-out (default 400ms). This can be; adjusted by calling static method:; TGLSAViewer::SetMenuHidingTimeout(200);; To disable menu hiding for Eve viewers, where it is enabled by; default, set the following rootrc variable:; Eve.Viewer.HideMenus: off. EVE; Major changes. Implement central infractructure to allow eve-elements to support; internal multiple selection and highlightning of their sub-parts. Use this in TEveDigitSet and its sub-classes TEveQuadSet and; TEveBoxSet. TEveSecondarySelectable: New secondary base-class for elements; supporting internal multiple selection / highlight.; TEveViewer - Add functions to handle additional mouse-over signals; from TGLViewer.; TEveElement - Add 3 new functions:; virtual TString GetHighlightTooltip();; virtual void UnSelected();; virtual void UnHighlighted();. TEveDigitSet, TEveQuadSet, TEveBoxSet. Sub-class TEveDigitSet from TEveSecondarySelectable.; Implement functions ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v528/index.html:2313,update,updated,2313,graf3d/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v528/index.html,2,['update'],"['update', 'updated']"
Deployability,".; The list, called _BOOTSTRAP_DEFAULT_PASSTHROUGH, is defined in clang/CMakeLists.txt.; To force the passing of the variables between stages, use the -DCLANG_BOOTSTRAP_PASSTHROUGH; CMake option, each variable separated by a "";"". As example:. .. code-block:: console. $ cmake -G Ninja -DCMAKE_BUILD_TYPE=Release \; -DCLANG_ENABLE_BOOTSTRAP=On \; -DCLANG_BOOTSTRAP_PASSTHROUGH=""CMAKE_INSTALL_PREFIX;CMAKE_VERBOSE_MAKEFILE"" \; -DLLVM_ENABLE_PROJECTS=""clang"" \; <path to source>/llvm; $ ninja stage2. CMake options starting by ``BOOTSTRAP_`` will be passed only to the stage2 build.; This gives the opportunity to use Clang specific build flags.; For example, the following CMake call will enabled '-fno-addrsig' only during; the stage2 build for C and C++. .. code-block:: console. $ cmake [..] -DBOOTSTRAP_CMAKE_CXX_FLAGS='-fno-addrsig' -DBOOTSTRAP_CMAKE_C_FLAGS='-fno-addrsig' [..]. The clang build system refers to builds as stages. A stage1 build is a standard; build using the compiler installed on the host, and a stage2 build is built; using the stage1 compiler. This nomenclature holds up to more stages too. In; general a stage*n* build is built using the output from stage*n-1*. Apple Clang Builds (A More Complex Bootstrap); =============================================. Apple's Clang builds are a slightly more complicated example of the simple; bootstrapping scenario. Apple Clang is built using a 2-stage build. The stage1 compiler is a host-only compiler with some options set. The stage1; compiler is a balance of optimization vs build time because it is a throwaway.; The stage2 compiler is the fully optimized compiler intended to ship to users. Setting up these compilers requires a lot of options. To simplify the; configuration the Apple Clang build settings are contained in CMake Cache files.; You can build an Apple Clang compiler using the following commands:. .. code-block:: console. $ cmake -G Ninja -C <path to source>/clang/cmake/caches/Apple-stage1.cmake <path to source",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst:3101,install,installed,3101,interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,1,['install'],['installed']
Deployability,".; While loadScript and AssertPrerequisites functions moved to JSROOT, one; can easily build many different kinds of GUIs, reusing provided JSRootCore.js functions.; 8. In example.htm also use AssertPrerequisites to load necessary scripts.; This helps to keep code up-to-date even by big changes in JavaScript code.; 9. Provide monitoring of online THttpServer with similar interface as for ROOT files.; 10. Fix several errors in TKey Streamer, use member names as in ROOT itself.; 11. Keep the only version identifier JSROOT.version for JS code; 12. One can specify in JSROOT.AssertPrerequisites functionality which is required.; One could specify '2d', 'io' (default) or '3d'.; 13. Use new AssertPrerequisites functionality to load only required functionality.; 14. When displaying single element, one could specify draw options and monitor property like:; <http://localhost:8080/Files/job1.root/hpxpy/draw.htm?opt=col&monitor=2000>; Such link is best possibility to integrate display into different HTML pages,; using `<iframe/>` tag like:; `<iframe src=""http://localhost:8080/Files/job1.root/hpx/draw.htm""`; `style=""width: 800px; height:600px""></iframe>`; 15. Remove 'JSROOTIO.' prefix from _typename. Now real class name is used.; 16. Use in all scripts JSROOT as central 'namespace'; 17. Introduce context menu in 3D, use it for switch between 2D/3D modes; 18. Use own code to generate hierarchical structure in HTML, replace dtree.js which is; extremely slow for complex hierarchies. Dramatically improve performance for; structures with large (~1000) number of items.; 19. Deliver to the server title of the objects, display it as hint in the browser.; 20. Better handling of special characters in the hierarchies - allows to display; symbols like ' or "" in the file structure. ### July 2014; 1. Migration to d3.v3.js and jQuery v2.1.1; 2. Fix errors in filling of histogram statbox; 3. Possibility of move and resize of statbox, title, color palete; 4. Remove many (not all) global variables",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:75585,integrat,integrate,75585,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['integrat'],['integrate']
Deployability,".assign(metadata i32 %a, metadata !14, metadata !DIExpression(), metadata !16, metadata i32* %a.addr, metadata !DIExpression()), !dbg !15; %0 = load i32, i32* %a.addr, align 4, !dbg !17; ret i32 %0, !dbg !18; }. ...; !13 = distinct !DIAssignID(); !14 = !DILocalVariable(name: ""a"", ...); ...; !16 = distinct !DIAssignID(); ```. The first `llvm.dbg.assign` refers to the `alloca` through `!DIAssignID !13`,; and the second refers to the `store` through `!DIAssignID !16`. ### Store-like instructions. In the absence of a linked `llvm.dbg.assign`, a store to an address that is; known to be the backing storage for a variable is considered to represent an; assignment to that variable. This gives us a safe fall-back in cases where `llvm.dbg.assign` intrinsics have; been deleted, the `DIAssignID` attachment on the store has been dropped, or the; optimiser has made a once-indirect store (not tracked with Assignment Tracking); direct. ### Middle-end: Considerations for pass-writers. #### Non-debug instruction updates. **Cloning** an instruction: nothing new to do. Cloning automatically clones a; `DIAssignID` attachment. Multiple instructions may have the same `DIAssignID`; instruction. In this case, the assignment is considered to take place in; multiple positions in the program. **Moving** a non-debug instruction: nothing new to do. Instructions linked to an; `llvm.dbg.assign` have their initial IR position marked by the position of the; `llvm.dbg.assign`. **Deleting** a non-debug instruction: nothing new to do. Simple DSE does not; require any change; it’s safe to delete an instruction with a `DIAssignID`; attachment. An `llvm.dbg.assign` that uses a `DIAssignID` that is not attached; to any instruction indicates that the memory location isn’t valid. **Merging** stores: In many cases no change is required as `DIAssignID`; attachments are automatically merged if `combineMetadata` is called. One way or; another, the `DIAssignID` attachments must be merged such that new store; beco",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:5735,update,updates,5735,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md,1,['update'],['updates']
Deployability,".com; D: Loop Vectorizer. N: Sundeep Kushwaha; E: sundeepk@codeaurora.org; D: Implemented DFA-based target independent VLIW packetizer. N: Christopher Lamb; E: christopher.lamb@gmail.com; D: aligned load/store support, parts of noalias and restrict support; D: vreg subreg infrastructure, X86 codegen improvements based on subregs; D: address spaces. N: Jim Laskey; E: jlaskey@apple.com; D: Improvements to the PPC backend, instruction scheduling; D: Debug and Dwarf implementation; D: Auto upgrade mangler; D: llvm-gcc4 svn wrangler. N: Chris Lattner; E: sabre@nondot.org; W: http://nondot.org/~sabre/; D: Primary architect of LLVM. N: Tanya Lattner (Tanya Brethour); E: tonic@nondot.org; W: http://nondot.org/~tonic/; D: The initial llvm-ar tool, converted regression testsuite to dejagnu; D: Modulo scheduling in the SparcV9 backend; D: Release manager (1.7+). N: Sylvestre Ledru; E: sylvestre@debian.org; W: http://sylvestre.ledru.info/; W: https://apt.llvm.org/; D: Debian and Ubuntu packaging; D: Continuous integration with jenkins. N: Andrew Lenharth; E: alenhar2@cs.uiuc.edu; W: http://www.lenharth.org/~andrewl/; D: Alpha backend; D: Sampling based profiling. N: Nick Lewycky; E: nicholas@mxc.ca; D: PredicateSimplifier pass. N: Tony Linthicum, et. al.; E: tlinth@codeaurora.org; D: Backend for Qualcomm's Hexagon VLIW processor. N: Bruno Cardoso Lopes; E: bruno.cardoso@gmail.com; I: bruno; W: http://brunocardoso.cc; D: Mips backend; D: Random ARM integrated assembler and assembly parser improvements; D: General X86 AVX1 support. N: Weining Lu; E: luweining@loongson.cn; D: LoongArch backend. N: Duraid Madina; E: duraid@octopus.com.au; W: http://kinoko.c.u-tokyo.ac.jp/~duraid/; D: IA64 backend, BigBlock register allocator. N: John McCall; E: rjmccall@apple.com; D: Clang semantic analysis and IR generation. N: Michael McCracken; E: michael.mccracken@gmail.com; D: Line number support for llvmgcc. N: Fanbo Meng; E: fanbo.meng@ibm.com; D: z/OS support. N: Vladimir Merzliakov; E: wand",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT:7735,integrat,integration,7735,interpreter/llvm-project/llvm/CREDITS.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT,1,['integrat'],['integration']
Deployability,".cpp. Alternatively, a test name can be specified as the full test name; reported in LIT output. For example, we can adjust the previous; example not to treat the ``nvptx64-nvidia-cuda`` version of; ``offloading/memory_manager.cpp`` as XFAIL:. .. code-block:: none. LIT_XFAIL=""affinity/kmp-hw-subset.c;libomptarget :: x86_64-pc-linux-gnu :: offloading/memory_manager.cpp"". .. option:: --xfail-not=LIST. Do not treat the specified tests as ``XFAIL``. The environment variable; ``LIT_XFAIL_NOT`` can also be used in place of this option. The syntax is the; same as for :option:`--xfail` and ``LIT_XFAIL``. :option:`--xfail-not` and; ``LIT_XFAIL_NOT`` always override all other ``XFAIL`` specifications,; including an :option:`--xfail` appearing later on the command line. The; primary purpose is to suppress an ``XPASS`` result without modifying a test; case that uses the ``XFAIL`` directive. ADDITIONAL OPTIONS; ------------------. .. option:: --debug. Run :program:`lit` in debug mode, for debugging configuration issues and; :program:`lit` itself. .. option:: --show-suites. List the discovered test suites and exit. .. option:: --show-tests. List all of the discovered tests and exit. EXIT STATUS; -----------. :program:`lit` will exit with an exit code of 1 if there are any FAIL or XPASS; results. Otherwise, it will exit with the status 0. Other exit codes are used; for non-test related failures (for example a user error or an internal program; error). .. _test-discovery:. TEST DISCOVERY; --------------. The inputs passed to :program:`lit` can be either individual tests, or entire; directories or hierarchies of tests to run. When :program:`lit` starts up, the; first thing it does is convert the inputs into a complete list of tests to run; as part of *test discovery*. In the :program:`lit` model, every test must exist inside some *test suite*.; :program:`lit` resolves the inputs specified on the command line to test suites; by searching upwards from the input path until it finds a :f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:10479,configurat,configuration,10479,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['configurat'],['configuration']
Deployability,".followup_fallback``. This avoids that the; fallback version (which is likely never executed) is further optimized; which would increase the code size. Versioning LICM; ---------------. The pass hoists code out of loops that are only loop-invariant when; dynamic conditions apply. For instance, it transforms the loop. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; A[i] = B[0];. into:. .. code-block:: c. if (rtc) {; auto b = B[0];; for (int i = 0; i < n; i+=1) // versioned loop; A[i] = b;; } else {; for (int i = 0; i < n; i+=1) // unversioned loop; A[i] = B[0];; }. The runtime condition (``rtc``) checks that the array ``A`` and the; element `B[0]` do not alias. Currently, this transformation does not support followup-attributes. Loop Interchange; ----------------. Currently, the ``LoopInterchange`` pass does not use any metadata. Ambiguous Transformation Order; ==============================. If there multiple transformations defined, the order in which they are; executed depends on the order in LLVM's pass pipeline, which is subject; to change. The default optimization pipeline (anything higher than; ``-O0``) has the following order. When using the legacy pass manager:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - VersioningLICM (if enabled); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). When using the legacy pass manager with LTO:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopVectorizer; - LoopUnroll (partial and runtime unrolling). When using the new pass manager:. - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). Leftover Transformations; ========================. Forced transformations that have not been applied after the last; transfor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:13633,pipeline,pipeline,13633,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst,1,['pipeline'],['pipeline']
Deployability,".g.: multiplication on 2; and 'shl 1'). It could happen due to several reasons: mainly, the usage of; templates and automatic code generators. Though, sometimes the user itself could; write the same thing twice :-). The main purpose of this pass is to recognize such functions and merge them. This document is the extension to pass comments and describes the pass logic. It; describes the algorithm that is used in order to compare functions and; explains how we could combine equal functions correctly to keep the module; valid. Material is brought in a top-down form, so the reader could start to learn pass; from high level ideas and end with low-level algorithm details, thus preparing; him or her for reading the sources. The main goal is to describe the algorithm and logic here and the concept. If; you *don't want* to read the source code, but want to understand pass; algorithms, this document is good for you. The author tries not to repeat the; source-code and covers only common cases to avoid the cases of needing to; update this document after any minor code changes. What should I know to be able to follow along with this document?; -----------------------------------------------------------------. The reader should be familiar with common compile-engineering principles and; LLVM code fundamentals. In this article, we assume the reader is familiar with; `Single Static Assignment; <http://en.wikipedia.org/wiki/Static_single_assignment_form>`_; concept and has an understanding of; `IR structure <https://llvm.org/docs/LangRef.html#high-level-structure>`_. We will use terms such as; ""`module <https://llvm.org/docs/LangRef.html#high-level-structure>`_"",; ""`function <https://llvm.org/docs/ProgrammersManual.html#the-function-class>`_"",; ""`basic block <http://en.wikipedia.org/wiki/Basic_block>`_"",; ""`user <https://llvm.org/docs/ProgrammersManual.html#the-user-class>`_"",; ""`value <https://llvm.org/docs/ProgrammersManual.html#the-value-class>`_"",; ""`instruction; <https://llvm.o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst:1325,update,update,1325,interpreter/llvm-project/llvm/docs/MergeFunctions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst,1,['update'],['update']
Deployability,".local` file (create it if it does not; exists) with the following configuration bits:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_QUOTA_LIMIT=50000; ```. You need to properly specify your closest HTTP caching proxy:; separate many of them via commas. The last fallback value, `DIRECT`,; tells cvmfs to connect directly without using any proxy at all. Among the list of repositories (comma-separated), always specify; `sft.cern.ch` and the one containing the software to your experiment; (e.g., `cms.cern.ch`). The quota limit is, in Megabytes, the amount of local disk space to; use as cache. - Check the configuration and repositories with:. # cvmfs_config chksetup; OK; # cvmfs_config probe; Probing /cvmfs/cms.cern.ch... OK; Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.gsi.de/) is very flexible in handling; various cases of network topologies. The best solution would be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:3682,configurat,configuration,3682,proof/doc/confman/ConfigProofPoD.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md,1,['configurat'],['configuration']
Deployability,".py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation ins",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9157,configurat,configuration,9157,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,1,['configurat'],['configuration']
Deployability,".rstudio.com/')"";; ~~~. Then create a macro named GlobalMinimization.C with the next code. ~~~{.cxx}; #include<TRInterface.h>; #include<TBenchmark.h>; #include<math.h>; #include<stdlib.h>; //In the next function the *double pointer should be changed by a TVectorD datatype,; //because the pointer has no meaning in the R environment.; //This is a generalization of the RosenBrock function, with the min xi=1 and i>0.; Double_t GenRosenBrock(const TVectorD xx ); {; int length=xx.GetNoElements();. Double_t result=0;; for(int i=0;i<(length-1);i++); {; result+=pow(1-xx[i],2)+100*pow(xx[i+1]-pow(xx[i],2),2);; }; return result;; }. //the min xi=0 i>0; Double_t Rastrigin(const TVectorD xx); {; int length=xx.GetNoElements();; Double_t result=10*length;; for(int i=0;i<length;i++); {; result+=xx[i]*xx[i]-10*cos(6.2831853*xx[i]);; }; return result;; }. void GlobalMinimization(); {; TBenchmark bench;; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();. Bool_t installed=r.Eval(""is.element('DEoptim', installed.packages()[,1])"");; if(!installed); {; std::cout<<""Package DEoptim no installed in R""<<std::endl;; std::cout<<""Run install.packages('DEoptim') in R's environment""<<std::endl;; return;; }. //loading DEoptim; r<<""suppressMessages(library(DEoptim, quietly = TRUE))"";. // passing RosenBrock function to R; r[""GenRosenBrock""]<<GenRosenBrock;. //maximun number of iterations; r[""MaxIter""]<<5000;; //n = size of vector that is an argument for GenRosenBrock; r[""n""]<<3;; //lower limits; r<<""ll<-rep(-25, n)"";; //upper limits; r<<""ul<-rep(25, n)"";. bench.Start(""GlobalMinimizationRosenBrock"");; //calling minimization and timing it.; r<<""result1<-DEoptim(fn=GenRosenBrock,lower=ll,upper=ul,control=list(NP=10*n,itermax=MaxIter,trace=FALSE))"";; std::cout<<""-----------------------------------------""<<std::endl;; std::cout<<""RosenBrock's minimum in: ""<<std::endl;; r<<""print(result1$optim$bestmem)"";; std::cout<<""Bechmark Times""<<std::endl;; // printing times; bench.Show(""GlobalMinimizationRosen",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:18354,install,installed,18354,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['install'],['installed']
Deployability,"// version 2. The TZIPFile compressed archive reader now supports the Zip64 format for; archives and file members greater than 2 and 4 GB, respectively. MakeProject. Add support for the case when the requested project/files in path that in not under the current directory; Generate the code/dictonary only for pair type that do not already have a dictionary. Object Merging; We introduced a new explicit interface for providing merging; capability. If a class has a method with the name and; signature:. Long64_t Merge(TCollection *input, TFileMergeInfo*);. it will be used by a TFileMerger (and thus by PROOF) to merge one or more; other objects into the current object. Merge should; return a negative value if the merging failed. If this method does not exist, the TFileMerger will use; a method with the name and signature:. Long64_t Merge(TCollection *input);. TClass now provides a quick access to these merging; function via TClass::GetMerge. The wrapper function; is automatically created by rootcint and can be installed; via TClass::SetMerge. The wrapper function should have; the signature/type ROOT::MergeFunc_t:. Long64_t (*)(void *thisobj, TCollection *input, TFileMergeInfo*);. We added the new Merge function to TTree and THStack.; We also added the new Merge function to TQCommand as the; existing TQCommand::Merge does not have the right; semantic (in part because TQCommand is a collection). In TFileMerger, we added a PrintLevel to allow hadd to request; more output than regular TFileMerger. We removed all hard dependencies of TFileMerger on TH1 and TTree.; (Soft dependencies still exist to be able to disable the; merging of TTrees and to be able to disable the AutoAdd; behavior of TH1). The object TFileMergeInfo can be used inside the Merge; function to pass information between runs of the Merge; (see below). In particular it contains:. TDirectory *fOutputDirectory; // Target directory where the merged object will be written.; Bool_t fIsFirst; // True if this is the fir",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v530/index.html:3221,install,installed,3221,io/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v530/index.html,1,['install'],['installed']
Deployability,"//===-- README.txt - Notes for WebAssembly code gen -----------------------===//. The object format emitted by the WebAssembly backed is documented in:. * https://github.com/WebAssembly/tool-conventions/blob/main/Linking.md. The C ABI is described in:. * https://github.com/WebAssembly/tool-conventions/blob/main/BasicCABI.md. For more information on WebAssembly itself, see the home page:. * https://webassembly.github.io/. Emscripten provides a C/C++ compilation environment based on clang which; includes standard libraries, tools, and packaging for producing WebAssembly; applications that can run in browsers and other environments. wasi-sdk provides a more minimal C/C++ SDK based on clang, llvm and a libc based; on musl, for producing WebAssembly applications that use the WASI ABI. Rust provides WebAssembly support integrated into Cargo. There are two; main options:; - wasm32-unknown-unknown, which provides a relatively minimal environment; that has an emphasis on being ""native""; - wasm32-unknown-emscripten, which uses Emscripten internally and; provides standard C/C++ libraries, filesystem emulation, GL and SDL; bindings; For more information, see:; * https://www.hellorust.com/. The following documents contain some information on the semantics and binary; encoding of WebAssembly itself:; * https://github.com/WebAssembly/design/blob/main/Semantics.md; * https://github.com/WebAssembly/design/blob/main/BinaryEncoding.md. Some notes on ways that the generated code could be improved follow:. //===---------------------------------------------------------------------===//. Br, br_if, and br_table instructions can support having a value on the value; stack across the jump (sometimes). We should (a) model this, and (b) extend; the stackifier to utilize it. //===---------------------------------------------------------------------===//. The min/max instructions aren't exactly a<b?a:b because of NaN and negative zero; behavior. The ARM target has the same kind of min/max instruc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt:825,integrat,integrated,825,interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt,1,['integrat'],['integrated']
Deployability,"//===----------------------------------------------------------------------===//; // Clang Installation Instructions; //===----------------------------------------------------------------------===//. These instructions describe how to build and install Clang. //===----------------------------------------------------------------------===//; // Step 1: Organization; //===----------------------------------------------------------------------===//. Clang is designed to be built as part of an LLVM build. Assuming that the LLVM; source code is located at $LLVM_SRC_ROOT, then the clang source code should be; installed as:. $LLVM_SRC_ROOT/tools/clang. The directory is not required to be called clang, but doing so will allow the; LLVM build system to automatically recognize it and build it along with LLVM. //===----------------------------------------------------------------------===//; // Step 2: Configure and Build LLVM; //===----------------------------------------------------------------------===//. Configure and build your copy of LLVM (see $LLVM_SRC_ROOT/GettingStarted.html; for more information). Assuming you installed clang at $LLVM_SRC_ROOT/tools/clang then Clang will; automatically be built with LLVM. Otherwise, run 'make' in the Clang source; directory to build Clang. //===----------------------------------------------------------------------===//; // Step 3: (Optional) Verify Your Build; //===----------------------------------------------------------------------===//. It is a good idea to run the Clang tests to make sure your build works; correctly. From inside the Clang build directory, run 'make test' to run the; tests. //===----------------------------------------------------------------------===//; // Step 4: Install Clang; //===----------------------------------------------------------------------===//. From inside the Clang build directory, run 'make install' to install the Clang; compiler and header files into the prefix directory selected when LLVM was; co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/INSTALL.txt:245,install,install,245,interpreter/llvm-project/clang/INSTALL.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/INSTALL.txt,2,['install'],"['install', 'installed']"
Deployability,"//===----------------------------------------------------------------------===/; // Kaleidoscope with MCJIT; //===----------------------------------------------------------------------===//. The files in this directory are meant to accompany the first blog in a series of; three blog posts that describe the process of porting the Kaleidoscope tutorial; to use the MCJIT execution engine instead of the older JIT engine. The link of blog post-; https://blog.llvm.org/posts/2013-07-22-using-mcjit-with-kaleidoscope-tutorial/. The source code in this directory demonstrates the initial working version of; the program before subsequent performance improvements are applied. To build the program you will need to have 'clang++' and 'llvm-config' in your ; path. If you attempt to build using the LLVM 3.3 release, some minor ; modifications will be required, as mentioned in the blog posts.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/examples/Kaleidoscope/MCJIT/initial/README.txt:802,release,release,802,interpreter/llvm-project/llvm/examples/Kaleidoscope/MCJIT/initial/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/examples/Kaleidoscope/MCJIT/initial/README.txt,1,['release'],['release']
Deployability,"//===----------------------------------------------------------------------===/; // Kaleidoscope with MCJIT; //===----------------------------------------------------------------------===//. The files in this directory are meant to accompany the first in a series of; three blog posts that describe the process of porting the Kaleidoscope tutorial; to use the MCJIT execution engine instead of the older JIT engine. The source code in this directory combines all previous versions, including the; old JIT-based implementation, into a single file for easy comparison with; command line options to select between the various possibilities. To build the program you will need to have 'clang++' and 'llvm-config' in your ; path. If you attempt to build using the LLVM 3.3 release, some minor ; modifications will be required. This directory also contains a Python script that may be used to generate random; input for the program and test scripts to capture data for rough performance; comparisons. Another Python script will split generated input files into; definitions and function calls for the purpose of testing the IR input and; caching facilities.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/examples/Kaleidoscope/MCJIT/complete/README.txt:768,release,release,768,interpreter/llvm-project/llvm/examples/Kaleidoscope/MCJIT/complete/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/examples/Kaleidoscope/MCJIT/complete/README.txt,1,['release'],['release']
Deployability,"//===----------------------------------------------------------------------===/; // Kaleidoscope with MCJIT; //===----------------------------------------------------------------------===//. The files in this directory are meant to accompany the second blog in a series of; three blog posts that describe the process of porting the Kaleidoscope tutorial; to use the MCJIT execution engine instead of the older JIT engine. The link of blog post-; https://blog.llvm.org/posts/2013-07-29-kaleidoscope-performance-with-mcjit/. The source code in this directory demonstrates the second version of the; program, now modified to implement a sort of 'lazy' compilation. The toy-jit.cpp file contains a version of the original JIT-based source code; that has been modified to disable most stderr output for timing purposes. To build the program you will need to have 'clang++' and 'llvm-config' in your ; path. If you attempt to build using the LLVM 3.3 release, some minor ; modifications will be required. This directory also contains a Python script that may be used to generate random; input for the program and test scripts to capture data for rough performance; comparisons.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/examples/Kaleidoscope/MCJIT/lazy/README.txt:945,release,release,945,interpreter/llvm-project/llvm/examples/Kaleidoscope/MCJIT/lazy/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/examples/Kaleidoscope/MCJIT/lazy/README.txt,1,['release'],['release']
Deployability,"//===----------------------------------------------------------------------===/; // Kaleidoscope with MCJIT; //===----------------------------------------------------------------------===//. The files in this directory are meant to accompany the third blog in a series of; three blog posts that describe the process of porting the Kaleidoscope tutorial; to use the MCJIT execution engine instead of the older JIT engine. The link of blog post-; https://blog.llvm.org/posts/2013-08-02-object-caching-with-kaleidoscope/. The source code in this directory demonstrates the third version of the; program, now modified to accept an input IR file on the command line and,; optionally, to use a basic caching mechanism to store generated object images. The toy-jit.cpp file contains a version of the original JIT-based source code; that has been modified to support the input IR file command line option. To build the program you will need to have 'clang++' and 'llvm-config' in your ; path. If you attempt to build using the LLVM 3.3 release, some minor ; modifications will be required. This directory also contains a Python script that may be used to generate random; input for the program and test scripts to capture data for rough performance; comparisons. Another Python script will split generated input files into; definitions and function calls for the purpose of testing the IR input and; caching facilities.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/examples/Kaleidoscope/MCJIT/cached/README.txt:1028,release,release,1028,interpreter/llvm-project/llvm/examples/Kaleidoscope/MCJIT/cached/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/examples/Kaleidoscope/MCJIT/cached/README.txt,1,['release'],['release']
Deployability,"//===---------------------------------------------------------------------===//; // Random ideas for the X86 backend.; //===---------------------------------------------------------------------===//. Improvements to the multiply -> shift/add algorithm:; http://gcc.gnu.org/ml/gcc-patches/2004-08/msg01590.html. //===---------------------------------------------------------------------===//. Improve code like this (occurs fairly frequently, e.g. in LLVM):; long long foo(int x) { return 1LL << x; }. http://gcc.gnu.org/ml/gcc-patches/2004-09/msg01109.html; http://gcc.gnu.org/ml/gcc-patches/2004-09/msg01128.html; http://gcc.gnu.org/ml/gcc-patches/2004-09/msg01136.html. Another useful one would be ~0ULL >> X and ~0ULL << X. One better solution for 1LL << x is:; xorl %eax, %eax; xorl %edx, %edx; testb $32, %cl; sete %al; setne %dl; sall %cl, %eax; sall %cl, %edx. But that requires good 8-bit subreg support. Also, this might be better. It's an extra shift, but it's one instruction; shorter, and doesn't stress 8-bit subreg support.; (From http://gcc.gnu.org/ml/gcc-patches/2004-09/msg01148.html,; but without the unnecessary and.); movl %ecx, %eax; shrl $5, %eax; movl %eax, %edx; xorl $1, %edx; sall %cl, %eax; sall %cl. %edx. 64-bit shifts (in general) expand to really bad code. Instead of using; cmovs, we should expand to a conditional branch like GCC produces. //===---------------------------------------------------------------------===//. Some isel ideas:. 1. Dynamic programming based approach when compile time is not an; issue.; 2. Code duplication (addressing mode) during isel.; 3. Other ideas from ""Register-Sensitive Selection, Duplication, and; Sequencing of Instructions"".; 4. Scheduling for reduced register pressure. E.g. ""Minimum Register; Instruction Sequence Problem: Revisiting Optimal Code Generation for DAGs""; and other related papers.; http://citeseer.ist.psu.edu/govindarajan01minimum.html. //===---------------------------------------------------------------------=",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:280,patch,patches,280,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,4,['patch'],['patches']
Deployability,"//===---------------------------------------------------------------------===//; // Random ideas for the X86 backend: FP stack related stuff; //===---------------------------------------------------------------------===//. //===---------------------------------------------------------------------===//. Some targets (e.g. athlons) prefer freep to fstp ST(0):; http://gcc.gnu.org/ml/gcc-patches/2004-04/msg00659.html. //===---------------------------------------------------------------------===//. This should use fiadd on chips where it is profitable:; double foo(double P, int *I) { return P+*I; }. We have fiadd patterns now but the followings have the same cost and; complexity. We need a way to specify the later is more profitable. def FpADD32m : FpI<(ops RFP:$dst, RFP:$src1, f32mem:$src2), OneArgFPRW,; [(set RFP:$dst, (fadd RFP:$src1,; (extloadf64f32 addr:$src2)))]>;; // ST(0) = ST(0) + [mem32]. def FpIADD32m : FpI<(ops RFP:$dst, RFP:$src1, i32mem:$src2), OneArgFPRW,; [(set RFP:$dst, (fadd RFP:$src1,; (X86fild addr:$src2, i32)))]>;; // ST(0) = ST(0) + [mem32int]. //===---------------------------------------------------------------------===//. The FP stackifier should handle simple permutates to reduce number of shuffle; instructions, e.g. turning:. fld P	->		fld Q; fld Q			fld P; fxch. or:. fxch	->		fucomi; fucomi			jl X; jg X. Ideas:; http://gcc.gnu.org/ml/gcc-patches/2004-11/msg02410.html. //===---------------------------------------------------------------------===//. Add a target specific hook to DAG combiner to handle SINT_TO_FP and; FP_TO_SINT when the source operand is already in memory. //===---------------------------------------------------------------------===//. Open code rint,floor,ceil,trunc:; http://gcc.gnu.org/ml/gcc-patches/2004-08/msg02006.html; http://gcc.gnu.org/ml/gcc-patches/2004-08/msg02011.html. Opencode the sincos[f] libcall. //===---------------------------------------------------------------------===//. None of the FPStack instructions are ha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-FPStack.txt:387,patch,patches,387,interpreter/llvm-project/llvm/lib/Target/X86/README-FPStack.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-FPStack.txt,1,['patch'],['patches']
Deployability,//sourceforge.net/projects/civetweb/). Developers can contribute to CivetWeb via GitHub; [https://github.com/civetweb/civetweb](https://github.com/civetweb/civetweb). Due to a [bug in Git for Windows V2.24](https://github.com/git-for-windows/git/issues/2435); CivetWeb must be used with an earlier or later version (see also [here](https://github.com/civetweb/civetweb/issues/812)). Trouble tickets should be filed on GitHub; [https://github.com/civetweb/civetweb/issues](https://github.com/civetweb/civetweb/issues). New releases are announced at Google Groups; [https://groups.google.com/d/forum/civetweb](https://groups.google.com/d/forum/civetweb). Formerly some support question and discussion threads have been at [Google groups](https://groups.google.com/d/forum/civetweb).; Recent questions and discussions use [GitHub issues](https://github.com/civetweb/civetweb/issues). Source releases can be found on GitHub; [https://github.com/civetweb/civetweb/releases](https://github.com/civetweb/civetweb/releases). A very brief overview can be found on GitHub Pages; [http://civetweb.github.io/civetweb/](http://civetweb.github.io/civetweb/). Getting The Source; ------------------; Download the source code by running the following code in your command prompt:. $ git clone https://github.com/civetweb/civetweb.git; or simply grab a copy of the source code as a ZIP or TGZ file. Quick start documentation; --------------------------. - [docs/Installing.md](https://github.com/civetweb/civetweb/blob/master/docs/Installing.md) - Install Guide (for end users using pre-built binaries); - [docs/UserManual.md](https://github.com/civetweb/civetweb/blob/master/docs/UserManual.md) - End User Guide; - [docs/Building.md](https://github.com/civetweb/civetweb/blob/master/docs/Building.md) - Building the Server (quick start guide); - [docs/Embedding.md](https://github.com/civetweb/civetweb/blob/master/docs/Embedding.md) - Embedding (how to add HTTP support to an existing application); - [docs/OpenSSL.,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:3492,release,releases,3492,net/http/civetweb/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md,1,['release'],['releases']
Deployability,/11653)] - TFile plugins :: pass meta4 extension files to TNetXNGFile and process it; * [[#11596](https://github.com/root-project/root/issues/11596)] - cppyy does not retrieve correct size of type when pythonizing vector; * [[#11484](https://github.com/root-project/root/issues/11484)] - roottest/root/meta/genreflex/ROOT-5768 needs to be enabled; * [[#11411](https://github.com/root-project/root/issues/11411)] - [PyROOT] Python list of strings -> std::initializer_list< std::string > conversion is broken; * [[#11395](https://github.com/root-project/root/issues/11395)] - Migrate to pcre2; * [[#11353](https://github.com/root-project/root/issues/11353)] - Compiled program with libNew.so crash; * [[#11304](https://github.com/root-project/root/issues/11304)] - WW option for fit functions as the W option; * [[#11238](https://github.com/root-project/root/issues/11238)] - an old bug in ROOT v6 TAB completion ?; * [[#11197](https://github.com/root-project/root/issues/11197)] - Build github release into version release procedure; * [[#11190](https://github.com/root-project/root/issues/11190)] - ROOT compiled with `-Ddev=ON` crashes when type `#` in ROOT session; * [[#11021](https://github.com/root-project/root/issues/11021)] - [Fit Panel] Fitting to Gaus + Pol0 in two steps is unnecessarily hard; * [[#10891](https://github.com/root-project/root/issues/10891)] - [RF] Deletion order of objects in RooFit/RooStats tutorials should not matter in Python; * [[#10871](https://github.com/root-project/root/issues/10871)] - [DF][ntuple] Better task splitting with RDF+RNTuple; * [[#10866](https://github.com/root-project/root/issues/10866)] - ACLiC flags parsing for compiler command line options broken in certain cases; * [[#10684](https://github.com/root-project/root/issues/10684)] - [PyROOT] Cannot use SofieFunctor in Python; * [[#10664](https://github.com/root-project/root/issues/10664)] - [ntuple] Expose fixed-size arrays as RVecs in RDF datasource; * [[#10395](https://github.com/root-pro,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:43953,release,release,43953,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,2,['release'],['release']
Deployability,"/; // Random ideas for the X86 backend.; //===---------------------------------------------------------------------===//. Improvements to the multiply -> shift/add algorithm:; http://gcc.gnu.org/ml/gcc-patches/2004-08/msg01590.html. //===---------------------------------------------------------------------===//. Improve code like this (occurs fairly frequently, e.g. in LLVM):; long long foo(int x) { return 1LL << x; }. http://gcc.gnu.org/ml/gcc-patches/2004-09/msg01109.html; http://gcc.gnu.org/ml/gcc-patches/2004-09/msg01128.html; http://gcc.gnu.org/ml/gcc-patches/2004-09/msg01136.html. Another useful one would be ~0ULL >> X and ~0ULL << X. One better solution for 1LL << x is:; xorl %eax, %eax; xorl %edx, %edx; testb $32, %cl; sete %al; setne %dl; sall %cl, %eax; sall %cl, %edx. But that requires good 8-bit subreg support. Also, this might be better. It's an extra shift, but it's one instruction; shorter, and doesn't stress 8-bit subreg support.; (From http://gcc.gnu.org/ml/gcc-patches/2004-09/msg01148.html,; but without the unnecessary and.); movl %ecx, %eax; shrl $5, %eax; movl %eax, %edx; xorl $1, %edx; sall %cl, %eax; sall %cl. %edx. 64-bit shifts (in general) expand to really bad code. Instead of using; cmovs, we should expand to a conditional branch like GCC produces. //===---------------------------------------------------------------------===//. Some isel ideas:. 1. Dynamic programming based approach when compile time is not an; issue.; 2. Code duplication (addressing mode) during isel.; 3. Other ideas from ""Register-Sensitive Selection, Duplication, and; Sequencing of Instructions"".; 4. Scheduling for reduced register pressure. E.g. ""Minimum Register; Instruction Sequence Problem: Revisiting Optimal Code Generation for DAGs""; and other related papers.; http://citeseer.ist.psu.edu/govindarajan01minimum.html. //===---------------------------------------------------------------------===//. Should we promote i16 to i32 to avoid partial register update stalls?. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:1071,patch,patches,1071,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['patch'],['patches']
Deployability,"/Final Major Release* Patches should be limited to critical; bugs or regressions. #. *Bug fix releases* Patches should be limited to bug fixes or very safe; and critical performance improvements. Patches must maintain both API and; ABI compatibility with the previous major release. Release Final Tasks; -------------------. The final stages of the release process involves tagging the ""final"" release; branch, updating documentation that refers to the release, and updating the; demo page. Update Documentation; ^^^^^^^^^^^^^^^^^^^^. Review the documentation in the release branch and ensure that it is up; to date. The ""Release Notes"" must be updated to reflect new features, bug; fixes, new known issues, and changes in the list of supported platforms.; The ""Getting Started Guide"" should be updated to reflect the new release; version number tag available from Subversion and changes in basic system; requirements. .. _tag:. Tag the LLVM Final Release; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Tag the final release sources:. ::. $ git tag -sa llvmorg-X.Y.Z; $ git push https://github.com/llvm/llvm-project.git llvmorg-X.Y.Z. Update the LLVM Website; ^^^^^^^^^^^^^^^^^^^^^^^. The website must be updated before the release announcement is sent out. Here; is what to do:. #. Check out the ``www-releases`` module from GitHub. #. Create a new sub-directory ``X.Y.Z`` in the releases directory. #. Copy and commit the ``llvm/docs`` and ``LICENSE.txt`` files into this new; directory. #. Update the ``releases/download.html`` file with links to the release; binaries on GitHub. #. Update the ``releases/index.html`` with the new release and link to release; documentation. #. After you push the changes to the www-releases repo, someone with admin; access must login to prereleases-origin.llvm.org and manually pull the new; changes into /data/www-releases/. This is where the website is served from. #. Finally checkout the llvm-www repo and update the main page; (``index.html`` and sidebar) to point to the new",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:14409,release,release,14409,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['release'],['release']
Deployability,"/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:5834,install,installed,5834,proof/doc/confman/ConfigProofPoD.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md,2,['install'],"['installations', 'installed']"
Deployability,"/clang++. It should have no new regressions, compared to the previous release or release; candidate. You don't need to fix all the bugs in the test-suite, since they're; not necessarily meant to pass on all architectures all the time. This is; due to the nature of the result checking, which relies on direct comparison,; and most of the time, the failures are related to bad output checking, rather; than bad code generation. If the errors are in LLVM itself, please report every single regression found; as blocker, and all the other bugs as important, but not necessarily blocking; the release to proceed. They can be set as ""known failures"" and to be; fix on a future date. .. _pre-release-process:. Pre-Release Process; ===================. .. contents::; :local:. When the release process is announced on the mailing list, you should prepare; for the testing, by applying the same testing you'll do on the release; candidates, on the previous release. You should:. * Download the previous release sources from; https://llvm.org/releases/download.html. * Run the test-release.sh script on ``final`` mode (change ``-rc 1`` to; ``-final``). * Once all three stages are done, it'll test the final stage. * Using the ``Phase3/Release+Asserts/llvmCore-MAJ.MIN-final.install`` base,; run the test-suite. If the final phase's ``make check-all`` failed, it's a good idea to also test; the intermediate stages by going on the obj directory and running; ``make check-all`` to find if there's at least one stage that passes (helps; when reducing the error for bug report purposes). .. _release-process:. Release Process; ===============. .. contents::; :local:. When the Release Manager sends you the release candidate, download all sources,; unzip on the same directory (there will be sym-links from the appropriate places; to them), and run the release test as above. You should:. * Download the current candidate sources from where the release manager points; you (ex. https://llvm.org/pre-releases/3.3/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst:5062,release,release,5062,interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,1,['release'],['release']
Deployability,"/compiler-rt.llvm.org/ for more information about the dependencies; on clang and LLVM. See https://llvm.org/docs/GettingStarted.html for information about obtaining; the source for LLVM and compiler-rt. Note that the getting started guide; places compiler-rt in the projects subdirectory, but this is not essential and; if you are using the BaremetalARM.cmake cache for v6-M, v7-M and v7-EM then; compiler-rt must be placed in the runtimes directory. ``qemu-arm`` should be available as a package for your Linux distribution. The most complicated of the prerequisites to satisfy is the arm-linux-gnueabihf; sysroot. In theory it is possible to use the Linux distributions multiarch; support to fulfill the dependencies for building but unfortunately due to; /usr/local/include being added some host includes are selected. The easiest way; to supply a sysroot is to download the arm-linux-gnueabihf toolchain. This can; be found at:; * https://developer.arm.com/open-source/gnu-toolchain/gnu-a/downloads for gcc 8 and above; * https://releases.linaro.org/components/toolchain/binaries/ for gcc 4.9 to 7.3. Building compiler-rt builtins for Arm; =====================================; We will be doing a standalone build of compiler-rt using the following cmake; options. * ``path/to/compiler-rt``; * ``-G Ninja``; * ``-DCMAKE_AR=/path/to/llvm-ar``; * ``-DCMAKE_ASM_COMPILER_TARGET=""arm-linux-gnueabihf""``; * ``-DCMAKE_ASM_FLAGS=""build-c-flags""``; * ``-DCMAKE_C_COMPILER=/path/to/clang``; * ``-DCMAKE_C_COMPILER_TARGET=""arm-linux-gnueabihf""``; * ``-DCMAKE_C_FLAGS=""build-c-flags""``; * ``-DCMAKE_EXE_LINKER_FLAGS=""-fuse-ld=lld""``; * ``-DCMAKE_NM=/path/to/llvm-nm``; * ``-DCMAKE_RANLIB=/path/to/llvm-ranlib``; * ``-DCOMPILER_RT_BUILD_BUILTINS=ON``; * ``-DCOMPILER_RT_BUILD_LIBFUZZER=OFF``; * ``-DCOMPILER_RT_BUILD_MEMPROF=OFF``; * ``-DCOMPILER_RT_BUILD_PROFILE=OFF``; * ``-DCOMPILER_RT_BUILD_SANITIZERS=OFF``; * ``-DCOMPILER_RT_BUILD_XRAY=OFF``; * ``-DCOMPILER_RT_DEFAULT_TARGET_ONLY=ON``; * ``-DLLVM_CON",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToCrossCompileBuiltinsOnArm.rst:2354,release,releases,2354,interpreter/llvm-project/llvm/docs/HowToCrossCompileBuiltinsOnArm.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToCrossCompileBuiltinsOnArm.rst,1,['release'],['releases']
Deployability,"/gcc/x86_64-linux-gnu/5.4.0/../../../../\; include/c++/5.4.0. # other config files may be included; @linux.options. Files included by ``@file`` directives in configuration files are resolved; relative to the including file. For example, if a configuration file; ``~/.llvm/target.cfg`` contains the directive ``@os/linux.opts``, the file; ``linux.opts`` is searched for in the directory ``~/.llvm/os``. Another way to; include a file content is using the command line option ``--config=``. It works; similarly but the included file is searched for using the rules for configuration; files. To generate paths relative to the configuration file, the ``<CFGDIR>`` token may; be used. This will expand to the absolute path of the directory containing the; configuration file. In cases where a configuration file is deployed alongside SDK contents, the; SDK directory can remain fully portable by using ``<CFGDIR>`` prefixed paths.; In this way, the user may only need to specify a root configuration file with; ``--config=`` to establish every aspect of the SDK with the compiler:. ::. --target=foo; -isystem <CFGDIR>/include; -L <CFGDIR>/lib; -T <CFGDIR>/ldscripts/link.ld. Language and Target-Independent Features; ========================================. Controlling Errors and Warnings; -------------------------------. Clang provides a number of ways to control which code constructs cause; it to emit errors and warning messages, and how they are displayed to; the console. Controlling How Clang Displays Diagnostics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. When Clang emits a diagnostic, it includes rich information in the; output, and gives you fine-grain control over which information is; printed. Clang has the ability to print this information, and these are; the options that control it:. #. A file/line/column indicator that shows exactly where the diagnostic; occurs in your code [:ref:`-fshow-column <opt_fshow-column>`,; :ref:`-fshow-source-location <opt_fshow-source-location>`].; #",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:35480,configurat,configuration,35480,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['configurat'],['configuration']
Deployability,"/libcxx.git; cd libcxx; git svn init https://llvm.org/svn/llvm-project/libcxx/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l; git checkout `git svn find-rev -B r258109`. Note that the list would be longer with more sub-projects. .. _workflow-monocheckout-multicommit:. Monorepo Variant; ^^^^^^^^^^^^^^^^. The repository contains natively the source for every sub-projects at the right; revision, which makes this straightforward::. git clone https://github.com/llvm/llvm-project.git; cd llvm-projects; git checkout $REVISION. As before, at this point clang, llvm, and libcxx are stored in directories; alongside each other. .. _workflow-cross-repo-commit:. Commit an API Change in LLVM and Update the Sub-projects; --------------------------------------------------------. Today this is possible, even though not common (at least not documented) for; subversion users and for git-svn users. For example, few Git users try to update; LLD or Clang in the same commit as they change an LLVM API. The multirepo variant does not address this: one would have to commit and push; separately in every individual repository. It would be possible to establish a; protocol whereby users add a special token to their commit messages that causes; the umbrella repo's updater bot to group all of them into a single revision. The monorepo variant handles this natively. Branching/Stashing/Updating for Local Development or Experiments; ----------------------------------------------------------------. Currently; ^^^^^^^^^. SVN does not allow this use case, but developers that are currently using; git-svn can do it. Let's look in practice what it means when dealing with; multiple sub-projects. To update the repository to tip of trunk::. git pull; cd tools/clang; git pull; cd ../../projects/libcxx; git pull. To create a new branch::. git checkout -b MyBranch; cd tools/clang; git checkout -b MyBranch; cd ../../projects/libcxx; git checkout -b MyBranc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:17219,update,update,17219,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['update'],['update']
Deployability,"/releases/download/2.2.2/xthead-2023-01-30-2.2.2.pdf>`_ by T-HEAD of Alibaba. Instructions are prefixed with `th.` as described in the specification. ``XTHeadSync``; LLVM implements `the THeadSync (multi-core synchronization instructions) vendor-defined instructions specified in <https://github.com/T-head-Semi/thead-extension-spec/releases/download/2.2.2/xthead-2023-01-30-2.2.2.pdf>`_ by T-HEAD of Alibaba. Instructions are prefixed with `th.` as described in the specification. ``XTHeadVdot``; LLVM implements `version 1.0.0 of the THeadV-family custom instructions specification <https://github.com/T-head-Semi/thead-extension-spec/releases/download/2.2.0/xthead-2022-12-04-2.2.0.pdf>`_ by T-HEAD of Alibaba. All instructions are prefixed with `th.` as described in the specification, and the riscv-toolchain-convention document linked above. ``XVentanaCondOps``; LLVM implements `version 1.0.0 of the VTx-family custom instructions specification <https://github.com/ventanamicro/ventana-custom-extensions/releases/download/v1.0.0/ventana-custom-extensions-v1.0.0.pdf>`_ by Ventana Micro Systems. All instructions are prefixed with `vt.` as described in the specification, and the riscv-toolchain-convention document linked above. These instructions are only available for riscv64 at this time. ``XSfvcp``; LLVM implements `version 1.0.0 of the SiFive Vector Coprocessor Interface (VCIX) Software Specification <https://sifive.cdn.prismic.io/sifive/c3829e36-8552-41f0-a841-79945784241b_vcix-spec-software.pdf>`_ by SiFive. All instructions are prefixed with `sf.vc.` as described in the specification, and the riscv-toolchain-convention document linked above. ``XCVbitmanip``; LLVM implements `version 1.0.0 of the CORE-V Bit Manipulation custom instructions specification <https://github.com/openhwgroup/cv32e40p/blob/62bec66b36182215e18c9cf10f723567e23878e9/docs/source/instruction_set_extensions.rst>`_ by OpenHW Group. All instructions are prefixed with `cv.` as described in the specificati",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/RISCVUsage.rst:17062,release,releases,17062,interpreter/llvm-project/llvm/docs/RISCVUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/RISCVUsage.rst,1,['release'],['releases']
Deployability,"/root*); foreach(rawUtilName ${utils}); get_filename_component(utilName ${rawUtilName} NAME); if(NOT WIN32); # We need the .py only on Windows; string(REPLACE "".py"" """" utilName ${utilName}); set(python python3); else(); set(python python); endif(); configure_file(${rawUtilName} ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_BINDIR}/${utilName} @ONLY). install(FILES ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_BINDIR}/${utilName}; DESTINATION ${CMAKE_INSTALL_BINDIR}; RENAME ${utilName}; PERMISSIONS OWNER_EXECUTE OWNER_WRITE OWNER_READ; GROUP_EXECUTE GROUP_READ; WORLD_EXECUTE WORLD_READ; COMPONENT applications); endforeach(). install(FILES python/cmdLineUtils.py DESTINATION ${runtimedir}); if(IS_ABSOLUTE ${runtimedir}); set(absruntimedir ${runtimedir}); else(); set(absruntimedir \${CMAKE_INSTALL_PREFIX}/${runtimedir}); endif(); install(CODE ""execute_process(COMMAND ${Python3_EXECUTABLE} -m py_compile \$ENV{DESTDIR}${absruntimedir}/cmdLineUtils.py)""); install(CODE ""execute_process(COMMAND ${Python3_EXECUTABLE} -O -m py_compile \$ENV{DESTDIR}${absruntimedir}/cmdLineUtils.py)""); configure_file(python/cmdLineUtils.py ${localruntimedir}/cmdLineUtils.py @ONLY). set_source_files_properties(src/rootcling.cxx PROPERTIES; COMPILE_FLAGS ""${CLING_CXXFLAGS}""; VISIBILITY_INLINES_HIDDEN ""ON""; ). ROOT_EXECUTABLE(rootcling src/rootcling.cxx LIBRARIES RIO Cling Core Rint). # rootcling includes the ROOT complex header which would build the complex; # dictionary with modules. To make sure that rootcling_stage1 builds this; # dict before we use it, we add a dependency here.; add_dependencies(rootcling complexDict). target_include_directories(rootcling PRIVATE; ${CMAKE_SOURCE_DIR}/core/metacling/res; ${CMAKE_SOURCE_DIR}/core/dictgen/res; ${CMAKE_SOURCE_DIR}/io/rootpcm/res); set_property(TARGET rootcling PROPERTY ENABLE_EXPORTS 1); if(WIN32); set_target_properties(rootcling PROPERTIES WINDOWS_EXPORT_ALL_SYMBOLS 1); set_property(TARGET rootcling APPEND_STRING PROPERTY LINK_FLAGS "" -STACK:4000000""); endif(). # C",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/main/CMakeLists.txt:3341,install,install,3341,main/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/main/CMakeLists.txt,1,['install'],['install']
Deployability,"/root/branches/dev/cling cling. Allow Cling to hook into LLVM's build system:; cat tools/cling/patches/*.diff | patch -p0. Configure in your build folder (preferably out of the source code). For example:; cd ../../obj; ../src/configure --prefix=Where\to\be\installed\. Now compile and install:; make && make install. The executables could be found in your installation folder.; ; Using Visual Studio; Prerequisites; Subversion client - http://subversion.tigris.org/getting.html; cmake - http://www.cmake.org/cmake/resources/software.html; Python - http://www.python.org/download/; GnuWin32 Tools - http://getgnuwin32.sourceforge.net/; Visual Studio - VS Express should work as well. Checkout LLVM; svn co http://llvm.org/svn/llvm-project/llvm/trunk llvm/src/. Checkout Clang; cd llvm\src\tools\; svn co http://llvm.org/svn/llvm-project/cfe/trunk clang. Checkout Cling (next to Clang); ; svn co http://root.cern.ch/svn/root/branches/dev/cling cling. Allow Cling to hook into LLVM's build system: apply the two patches located in the cling\patches folder.; . Open up cmake and enter the path to the 'src' folder in the 'Where is the source code' field and the path to the 'build' folder in the 'Where to build the binaries' field (mkdir llvm\obj - next to src).; . Click the Configure button and in the newly popped up window choose Visual Studio version that you have, then click Finish.; . After the configuring completes many red entries should appear in the Cmake window. You may want to change CMAKE_INSTALL_PREFIX to 'inst' (next to next to src and obj, otherwise the default is Program Files). Click Generate. Note: You may have to do it twice (on 2.8.5) in case after clicking Generate the box is still red.; . Navigate to your 'build' folder and open LLVM.sln using Visual Studio and build it.; . Navigate to CMakePredefined project in Visual Studio and right click INSTALL. Choose Project Only -> Build only INSTALL.; . The executables could be found in your CMAKE_INSTALL_PREFIX/bin/; ; More ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/old/download.html:2125,patch,patches,2125,interpreter/cling/www/old/download.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/old/download.html,2,['patch'],['patches']
Deployability,"/tinyspec-cling>`_; - Noah Weninger 2020; - A tiny C++ live-coded overlap-add (re)synthesizer for Linux, which uses Cling to add REPL-like functionality for C++ code.; * - `Interactive C++ for Data Science <https://blog.llvm.org/posts/2020-12-21-interactive-cpp-for-data-science/>`_; - *Vassil Vassilev,* *David Lange,* *Simeon Ehrig,* *Sylvain Corlay* 2020 The LLVM Project Blog; - Cling enables eval-style programming for Data Science applications. Examples of ROOT and Xeus-Cling for data science are shown.; * - `Interactive C++ with Cling <https://blog.llvm.org/posts/2020-11-30-interactive-cpp-with-cling/>`_; - *Vassil Vassilev* 2020 The LLVM Project Blog; - This blog page briefly discusses the concept of interactive C++ by presenting Cling’s main features, such as wrapper functions, entity redefinition, error recovery. ; * - `Using the Cling C++ Interpreter on the Bela Platform <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_; - Jack Armitage 2019; - Cling has been installed on a BeagleBoard to bring live coding to the Bela interactive audio platform.; * - `Implementation of GlobalModuleIndex in ROOT and Cling <https://indico.cern.ch/event/840376/contributions/3525646/attachments/1895398/3127159/GSoC_Presentation__GMI.pdf>`_; - *Arpitha Raghunandan* 2012 Google Summer of Code GSoC; - GlobalModuleIndex can be used for improving ROOT’s and Cling’s performance ; * - `Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - *Mika* 2015 Youtube; - In this tutorial, a developer tries Cling for the first time by uploading a few simple C++ user-cases onto Cling, involving also the loading of external files; * - `Building an Order Book in C++ <https://www.youtube.com/w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:3959,install,installed,3959,interpreter/cling/docs/chapters/references.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst,1,['install'],['installed']
Deployability,"0 -DLLVM_ENABLE_RTTI=0 -DLLVM_ENABLE_TERMINFO=0 -DLLVM_ENABLE_ASSERTIONS=0 -Dminimal=ON -Druntime_cxxmodules=OFF -Dbuiltin_zlib=ON -Dbuiltin_cling=ON -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_INSTALL_PREFIX=<path to environment python site-packages>; $ make -j <N> install. where the ``cmake`` command needs to be given the full path to; `site-packages/cppyy_backend` in the virtual environment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to pypi.org and creating a local ""clean"" build environment from the; cached or remote wheels.; Instead, by skipping PEP 517, the local installation will be used.; This is imperative if there was a change in public headers or if the version; of ``cppyy-cling`` was locally updated and is thus not available on PyPI. Upgrading ``CPyCppyy`` (if on CPython; it's not needed for PyPy) and ``cppyy``; is very similar::. $ git clone https://github.com/wlav/CPyCppyy.git; $ cd CPyCppyy; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Just like ``cppyy-cling``, ``CPyCppyy`` has ``cmake`` scripts which are the; recommended way for development, as incremental builds are faster::. $ mkdir build; $ cmake ../CPyCppyy; $ make -j <N>. then simply point the ``PYTHONPATH`` envar to the `build` directory above to; pick up the local `cppyy.so` module. Finally, the top-level package ``cppyy``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:5533,upgrade,upgrade,5533,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,1,['upgrade'],['upgrade']
Deployability,"0 vmulps	%xmm0, %xmm1, %xmm2; 1 4 1.00 4 c5 eb 7c da vhaddps	%xmm2, %xmm2, %xmm3; 1 4 1.00 4 c5 e3 7c e3 vhaddps	%xmm3, %xmm3, %xmm4. The `Encoding Size` column shows the size in bytes of instructions. The; `Encodings` column shows the actual instruction encodings (byte sequences in; hex). The third section is the *Resource pressure view*. This view reports; the average number of resource cycles consumed every iteration by instructions; for every processor resource unit available on the target. Information is; structured in two tables. The first table reports the number of resource cycles; spent on average every iteration. The second table correlates the resource; cycles to the machine instruction in the sequence. For example, every iteration; of the instruction vmulps always executes on resource unit [6]; (JFPU1 - floating point pipeline #1), consuming an average of 1 resource cycle; per iteration. Note that on AMD Jaguar, vector floating-point multiply can; only be issued to pipeline JFPU1, while horizontal floating-point additions can; only be issued to pipeline JFPU0. The resource pressure view helps with identifying bottlenecks caused by high; usage of specific hardware resources. Situations with resource pressure mainly; concentrated on a few resources should, in general, be avoided. Ideally,; pressure should be uniformly distributed between multiple resources. Timeline View; ^^^^^^^^^^^^^; The timeline view produces a detailed report of each instruction's state; transitions through an instruction pipeline. This view is enabled by the; command line option ``-timeline``. As instructions transition through the; various stages of the pipeline, their states are depicted in the view report.; These states are represented by the following characters:. * D : Instruction dispatched.; * e : Instruction executing.; * E : Instruction executed.; * R : Instruction retired.; * = : Instruction already dispatched, waiting to be executed.; * \- : Instruction executed, waiting t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:20626,pipeline,pipeline,20626,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['pipeline'],['pipeline']
Deployability,"0.; GFX11; Number of instruction bytes to prefetch, starting at the kernel's entry; point instruction, before wavefront starts execution. The value is 0..63; with a granularity of 128 bytes.; 10 1 bit TRAP_ON_START GFX10; Reserved, must be 0.; GFX11; Must be 0. If 1, wavefront starts execution by trapping into the trap handler. CP is responsible for filling in the trap on start bit in; ``COMPUTE_PGM_RSRC3.TRAP_ON_START`` according to what the runtime; requests.; 11 1 bit TRAP_ON_END GFX10; Reserved, must be 0.; GFX11; Must be 0. If 1, wavefront execution terminates by trapping into the trap handler. CP is responsible for filling in the trap on end bit in; ``COMPUTE_PGM_RSRC3.TRAP_ON_END`` according to what the runtime requests.; 30:12 19 bits Reserved, must be 0.; 31 1 bit IMAGE_OP GFX10; Reserved, must be 0.; GFX11; If 1, the kernel execution contains image instructions. If executed as; part of a graphics pipeline, image read instructions will stall waiting; for any necessary ``WAIT_SYNC`` fence to be performed in order to; indicate that earlier pipeline stages have completed writing to the; image. Not used for compute kernels that are not part of a graphics pipeline and; must be 0.; 32 **Total size 4 bytes.**; ======= ===================================================================================================================. .. .. table:: compute_pgm_rsrc3 for GFX12; :name: amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table. ======= ======= =============================== ===========================================================================; Bits Size Field Name Description; ======= ======= =============================== ===========================================================================; 3:0 4 bits RESERVED Reserved, must be 0.; 11:4 8 bits INST_PREF_SIZE Number of instruction bytes to prefetch, starting at the kernel's entry; point instruction, before wavefront starts execution. The value is 0..255; with a granularity of 128 bytes.; 12 1 bit RESE",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:177894,pipeline,pipeline,177894,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['pipeline'],['pipeline']
Deployability,"00>`). Clang also supports :ref:`the C++ for OpenCL kernel language <cxx_for_opencl_impl>`. There are also other :ref:`new and experimental features <opencl_experimenal>`; available. Details about usage of clang for OpenCL can be found in :doc:`UsersManual`. Missing features or with limited support; ========================================. - For general issues and bugs with OpenCL in clang refer to `the GitHub issue; list; <https://github.com/llvm/llvm-project/issues?q=is%3Aopen+is%3Aissue+label%3Aopencl>`__. - Command-line flag :option:`-cl-ext` (used to override extensions/; features supported by a target) is missing support of some functionality i.e. that is; implemented fully through libraries (see :ref:`library-based features and; extensions <opencl_ext_libs>`). Internals Manual; ================. This section acts as internal documentation for OpenCL features design; as well as some important implementation aspects. It is primarily targeted; at the advanced users and the toolchain developers integrating frontend; functionality as a component. OpenCL Metadata; ---------------. Clang uses metadata to provide additional OpenCL semantics in IR needed for; backends and OpenCL runtime. Each kernel will have function metadata attached to it, specifying the arguments.; Kernel argument metadata is used to provide source level information for querying; at runtime, for example using the `clGetKernelArgInfo; <https://www.khronos.org/registry/OpenCL/specs/opencl-1.2.pdf#167>`_; call. Note that ``-cl-kernel-arg-info`` enables more information about the original; kernel code to be added e.g. kernel parameter names will appear in the OpenCL; metadata along with other information. The IDs used to encode the OpenCL's logical address spaces in the argument info; metadata follows the SPIR address space mapping as defined in the SPIR; specification `section 2.2; <https://www.khronos.org/registry/spir/specs/spir_spec-2.0.pdf#18>`_. OpenCL Specific Options; -----------------------. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenCLSupport.rst:1444,integrat,integrating,1444,interpreter/llvm-project/clang/docs/OpenCLSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenCLSupport.rst,1,['integrat'],['integrating']
Deployability,"012; highlights:; Adds basic interprocedural analysis support for blocks.; checker-266; built: May 23, 2012; highlights:; Contains numerous stability fixes over checker-266, especially when analyzing C++11 code.; checker-265; built: May 8, 2012; highlights:; This release contains a fix for a major crasher introduced in checker-264, and various refinements to; improve the precision and reduce the false positive rate of the analyzer. It also enables a new unix.MallocSizeof check, which reports; inconsistencies between the casted type of the return value of a 'malloc/calloc/realloc' call and the operand; of sizeof expressions contained within its argument(s).; checker-264; built: April 26, 2012; highlights:; This release contains misc. bug fixes and performance enhancements over checker-263, including; a reduction of some kinds of false positives related to the malloc() checker.; checker-263; built: March 22, 2012; highlights:. Fixes several serious bugs with inter-procedural analysis, including a case where retain/releases would be ""double-counted"". checker-262; built: March 15, 2012; highlights:. Enables experimental interprocedural analysis (within a file), which greatly amplifies the analyzer's ability to find issues.; Many bug fixes to the malloc/free checker.; Support for new Objective-C NSArray/NSDictionary/NSNumber literals syntax, and Objective-C container subscripting. NOTE: This build contains new interprocedural analysis that allows the analyzer to find more complicated bugs that span function boundaries. It may have problems, performance issues, etc. We'd like to hear about them. checker-261; built: February 22, 2012; highlights:. Contains a new experimental malloc/free checker.; Better support for projects using ARC.; Warns about null pointers passed as arguments to C string functions.; Warns about common anti-patterns in 'strncat' size argument, which can lead to buffer overflows.; set-xcode-analyzer now supports self-contained Xcode.app (Xcode 4.3 and la",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html:8187,release,releases,8187,interpreter/llvm-project/clang/www/analyzer/release_notes.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html,1,['release'],['releases']
Deployability,"080;ro;noglobal""); ```. ## Registering objects. At any time, one could register other objects with the command:. ```cpp; TGraph* gr = new TGraph(10);; gr->SetName(""gr1"");; serv->Register(""graphs/subfolder"", gr);; ```. One should specify sub-folder name, where objects will be registered.; If sub-folder name does not starts with slash `/`, than top-name folder `/Objects/` will be prepended.; At any time one could unregister objects:. ```cpp; serv->Unregister(gr);; ```. THttpServer does not take ownership over registered objects - they should be deleted by user. If the objects content is changing in the application, one could enable monitoring flag in the browser - then objects view will be regularly updated. ## Accessing file system. THttpServer provides partial access to the files from file system.; First of all, JSROOT scripts and files can be accessed via ""jsrootsys/"" path like ""http://localhost:8080/jsrootsys/modules/core.mjs"".; Files from ROOT install directory can be get via ""rootsys/"" path like ""http://localhost:8080/rootsys/icons/about.xpm"".; Also files from current directory where ROOT is running can be accessed via ""currentdir/"" path like ""http://localhost:8080/currentdir/file.txt"". If necessary, one can add custom path as well, using [THttpServer::AddLocation](https://root.cern/doc/master/classTHttpServer.html#a5322c3bbfddb8eb6849297d83ccaf87f) method:. ```cpp; serv->AddLocation(""mydir/"", ""/home/user/specials"");; ```. Then files from that directory could be addressed via URL like ""http://localhost:8080/mydir/myfile.root"". ## Command interface. THttpServer class provide simple interface to invoke command from web browser.; One just register command like:. ```cpp; serv->RegisterCommand(""/DoSomething"", ""SomeFunction()"");; ```. Element with name `DoSomething` will appear in the web browser and can be clicked.; It will result in `gROOT->ProcessLineSync(""SomeFunction()"")` call. One could configure argument(s) for the command.; For that one should use `%arg1`, `%ar",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:4290,install,install,4290,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['install'],['install']
Deployability,1.0:; * Initial release.; ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/misc/rootql/ChangeLog.txt:16,release,release,16,misc/rootql/ChangeLog.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/misc/rootql/ChangeLog.txt,2,['release'],['release']
Deployability,"16 weeks after branch**; **X.1.6 (if necessary)** **18 weeks after branch**; =============================== =========================. Release Process Summary; -----------------------. * Announce release schedule to the LLVM community and update the website. Do; this at least 3 weeks before the -rc1 release. * Create release branch and begin release process. * Send out release candidate sources for first round of testing. Testing lasts; 6 weeks. During the first round of testing, any regressions found should be; fixed. Patches are merged from mainline into the release branch. Also, all; features need to be completed during this time. Any features not completed at; the end of the first round of testing will be removed or disabled for the; release. * Generate and send out the second release candidate sources. Only *critical*; bugs found during this testing phase will be fixed. Any bugs introduced by; merged patches will be fixed. If so a third round of testing is needed. * The release notes are updated. * Finally, release!. * Announce bug fix release schedule to the LLVM community and update the website. * Do bug-fix releases every two weeks until X.1.5 or X.1.6 (if necessary). Release Process; ===============. .. contents::; :local:. Release Administrative Tasks; ----------------------------. This section describes a few administrative tasks that need to be done for the; release process to begin. Specifically, it involves:. * Updating version numbers,. * Creating the release branch, and. * Tagging release candidates for the release team to begin testing. Create Release Branch; ^^^^^^^^^^^^^^^^^^^^^. Branch the Git trunk using the following procedure:. #. Remind developers that the release branching is imminent and to refrain from; committing patches that might break the build. E.g., new features, large; patches for works in progress, an overhaul of the type system, an exciting; new TableGen feature, etc. #. Verify that the current git trunk is in decent shape by; exa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:2876,release,release,2876,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,2,"['release', 'update']","['release', 'updated']"
Deployability,"19. Getting Started; ===============; Here's the short story for getting up and running quickly with LLVM.; These instruction were tested with Visual Studio 2019 and Python 3.9.6:. 1. Download and install `Visual Studio <https://visualstudio.microsoft.com/>`_.; 2. In the Visual Studio installer, Workloads tab, select the; **Desktop development with C++** workload. Under Individual components tab,; select **Git for Windows**.; 3. Complete the Visual Studio installation.; 4. Download and install the latest `Python 3 release <http://www.python.org/>`_.; 5. In the first install screen, select both **Install launcher for all users**; and **Add Python to the PATH**. This will allow installing psutil for all; users for the regression tests and make Python available from the command; line.; 6. In the second install screen, select (again) **Install for all users** and; if you want to develop `lldb <https://lldb.llvm.org/>`_, selecting; **Download debug binaries** is useful.; 7. Complete the Python installation.; 8. Run a ""Developer Command Prompt for VS 2019"" **as administrator**. This command; prompt provides correct path and environment variables to Visual Studio and; the installed tools.; 9. In the terminal window, type the commands:. .. code-block:: bat. c:; cd \. You may install the llvm sources in other location than ``c:\llvm`` but do not; install into a path containing spaces (e.g. ``c:\Documents and Settings\...``); as it will fail. 10. Register the Microsoft Debug Interface Access (DIA) DLLs. .. code-block:: bat. regsvr32 ""%VSINSTALLDIR%\DIA SDK\bin\msdia140.dll""; regsvr32 ""%VSINSTALLDIR%\DIA SDK\bin\amd64\msdia140.dll"". The DIA library is required for LLVM PDB tests and; `LLDB development <https://lldb.llvm.org/resources/build.html>`_. 11. Install psutil and obtain LLVM source code:. .. code-block:: bat. pip install psutil; git clone https://github.com/llvm/llvm-project.git llvm. Instead of ``git clone`` you may download a compressed source distribution; from the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst:3714,install,installation,3714,interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,1,['install'],['installation']
Deployability,"1; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The stack map now indicates the location of the %ptr argument and; return value:. .. code-block:: none. Stack Map: ID=78, Loc0=%r9 Loc1=%r8. The patch code sequence may now use the argument that happened to be; allocated in %r8 and return a value allocated in %r9:. .. code-block:: none. 0x00 movslq 4(%r8) %r9 <--- patched code at patch point address; 0x03 nop; ...; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %r9; 0x10 movl %r9, 8(%rsp). .. _stackmap-format:. Stack Map Format; ================. The existence of a stack map or patch point intrinsic within an LLVM; Module forces code emission to create a :ref:`stackmap-section`. The; format of this section follows:. .. code-block:: none. Header {; uint8 : Stack Map Version (current version is 3); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; uint32 : NumConstants; uint32 : NumRecords; StkSizeRecord[NumFunctions] {; uint64 : Function Address; uint64 : Stack Size (or UINT64_MAX if not statically known); uint64 : Record Count; }; Constants[NumConstants] {; uint64 : LargeConstant; }; StkMapRecord[NumRecords] {; uint64 : PatchPoint ID; uint32 : Instruction Offset; uint16 : Reserved (record flags); uint16 : NumLocations; Location[NumLocations] {; uint8 : Register | Direct | Indirect | Constant | ConstantIndex; uint8 : Reserved (expected to be 0); uint16 : Location Size; uint16 : Dwarf RegNum; uint16 : Reserved (expected to be 0); int32 : Offset or SmallConstant; }; uint32 : Padding (only if required to align to 8 byte); uint16 : Padding; uint16 ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:11940,patch,patch,11940,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['patch'],['patch']
Deployability,"1` reference as an argument, that will be wrapped with the interfaces of a `ROOT::Math::IParametricGradFunctionOneDim`.; Example:; ```{.cpp}; #include ""TF1.h""; #include ""Math/WrappedTF1.h"". int main(); {. TF1 f(""Sin Function"", ""sin(x)+y"",0,3);. ROOT::Math::WrappedTF1 wf1(f);. cout << f(1) << endl;; cout << wf1(1) << endl;. return 0;; }; ```. For a TF1 defining a multidimensional function or in case we need to wrap in a multi-dimensional function interface, the class to use is `ROOT::Math::WrappedMultiTF1`.; Following the usual procedure, setting the `TF1` though the constructor, will wrap it into a `ROOT::Math::IParametricGradFunctionMultiDim`.; Example:. ```{.cpp}; #include ""TF1.h""; #include ""Math/WrappedMultiTF1.h"". int main(); {. TF2 f(""Sin Function"", ""sin(x) + y"",0,3,0,2);. ROOT::Math::WrappedMultiTF1 wf1(f);. double x[] = {1,2};. cout << f(x) << endl;; cout << wf1(x) << endl;. return 0;; }; ```. ## Numerical Integration. The algorithms provided by ROOT for numerical integration are implemented following the hierarchy shown in the next image.; `ROOT::Math::VirtualIntegrator` defines the most basic functionality while the specific behaviours for one or multiple dimensions are implemented in; `ROOT::Math::VirtualIntegratorOneDim` and `ROOT::Math::VirtualIntegratorMultiDim`.; These interfaces define the integrator functionality with abstract methods to set the function, to compute the integral or to set the integration tolerance.; These methods must be implemented in the concrete classes existing for the different integration algorithms.; The user cannot create directly these virtual integrator interfaces. He needs to create the; `ROOT::Math::IntegratorOneDim` class for integrating one-dimensional functions and `ROOT::Math::IntegratorMultiDim` for multi-dimensional functions.; Through the ROOT Plug-In Manager, the user can initialize `ROOT::Math::IntegratorOneDim` or `ROOT::Math::IntegratorMultiDim` with; any of the concrete integration classes without dealing with ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:48314,integrat,integration,48314,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['integrat'],['integration']
Deployability,"2**; Depends on stage2-instrumented-generate-profdata and will use the stage1; compiler with the stage2 profdata to build a PGO-optimized compiler. **stage2-check-llvm**; Depends on stage2 and runs check-llvm using the stage2 compiler. **stage2-check-clang**; Depends on stage2 and runs check-clang using the stage2 compiler. **stage2-check-all**; Depends on stage2 and runs check-all using the stage2 compiler. **stage2-test-suite**; Depends on stage2 and runs the test-suite using the stage2 compiler (requires; in-tree test-suite). BOLT; ====. `BOLT <https://github.com/llvm/llvm-project/blob/main/bolt/README.md>`_; (Binary Optimization and Layout Tool) is a tool that optimizes binaries; post-link by profiling them at runtime and then using that information to; optimize the layout of the final binary among other optimizations performed; at the binary level. There are also CMake caches available to build; LLVM/Clang with BOLT. To configure a single-stage build that builds LLVM/Clang and then optimizes; it with BOLT, use the following CMake configuration:. .. code-block:: console. $ cmake <path to source>/llvm -C <path to source>/clang/cmake/caches/BOLT.cmake. Then, build the BOLT-optimized binary by running the following ninja command:. .. code-block:: console. $ ninja clang-bolt. If you're seeing errors in the build process, try building with a recent; version of Clang/LLVM by setting the CMAKE_C_COMPILER and; CMAKE_CXX_COMPILER flags to the appropriate values. It is also possible to use BOLT on top of PGO and (Thin)LTO for an even more; significant runtime speedup. To configure a three stage PGO build with ThinLTO; that optimizes the resulting binary with BOLT, use the following CMake; configuration command:. .. code-block:: console. $ cmake -G Ninja <path to source>/llvm \; -C <path to source>/clang/cmake/caches/BOLT-PGO.cmake \; -DBOOTSTRAP_LLVM_ENABLE_LLD=ON \; -DBOOTSTRAP_BOOTSTRAP_LLVM_ENABLE_LLD=ON \; -DPGO_INSTRUMENT_LTO=Thin. Then, to build the final optimized b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst:10327,configurat,configuration,10327,interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,1,['configurat'],['configuration']
Deployability,"2, p); : bar(p, 2, q);; }. Running scan-build over this source produces the following; output:. Mac OS X API Annotations. Cocoa & Core Foundation Memory Management; Annotations. The analyzer supports the proper management of retain counts for; both Cocoa and Core Foundation objects. This checking is largely based on; enforcing Cocoa and Core Foundation naming conventions for Objective-C methods; (Cocoa) and C functions (Core Foundation). Not strictly following these; conventions can cause the analyzer to miss bugs or flag false positives.; One can educate the analyzer (and others who read your code) about methods or; functions that deviate from the Cocoa and Core Foundation conventions using the; attributes described here. However, you should consider using proper naming; conventions or the objc_method_family; attribute, if applicable.; Attribute 'ns_returns_retained'; (Clang-specific); The GCC-style (Clang-specific) attribute 'ns_returns_retained' allows one to; annotate an Objective-C method or C function as returning a retained Cocoa; object that the caller is responsible for releasing (via sending a; release message to the object). The Foundation framework defines a; macro NS_RETURNS_RETAINED that is functionally equivalent to the; one shown below.; Placing on Objective-C methods: For Objective-C methods, this; annotation essentially tells the analyzer to treat the method as if its name; begins with ""alloc"" or ""new"" or contains the word; ""copy"".; Placing on C functions: For C functions returning Cocoa objects, the; analyzer typically does not make any assumptions about whether or not the object; is returned retained. Explicitly adding the 'ns_returns_retained' attribute to C; functions allows the analyzer to perform extra checking.; Example. $ cat test.m; #import <Foundation/Foundation.h>. #ifndef __has_feature // Optional.; #define __has_feature(x) 0 // Compatibility with non-clang compilers.; #endif. #ifndef NS_RETURNS_RETAINED; #if __has_feature(attribute_ns_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html:3521,release,release,3521,interpreter/llvm-project/clang/www/analyzer/annotations.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html,1,['release'],['release']
Deployability,"2022-10-03: 2.4.1; -----------------. * Drop Numba extension entry point. 2022-06-29: 2.4.0; -----------------. * Support for free (templated) functions in Numba; * Basic support for unboxing C++ public data members in Numba; * Basic support for calling methods of C++ structs in Numba; * Added conventional `__cpp_reflex__` method for inspection in Numba; * Support for globally overloaded ordering operators; * Special cases for `__repr__`/`__str__` returning C++ stringy types; * Fix lookup of templates of function with template args; * Correct typing of int8_t/uint8_t enums; * Basic support for hidden enums; * Support function pointer returns and optimize function point variables; * Fix reuse of CPPOverload proxies in vector calls from different threads; * Use `-march=native` instead of checking the cpu for avx; * Workaround for handling exceptions from JITed code on ARM; * Drop ``from cppyy.interactive import *`` from CPython 3.11; * Fix regression in converting `std::vector<T*` to `list`; * Update to the latest patch version of Cling (from 6.26.04). 2022-04-03: 2.3.1; -----------------; * Use portable type Py_ssize_t instead of ssize_t. 2022-03-08: 2.3.0; -----------------. * CUDA support (up to version 10.2); * Allow `std::string_view<char>` initialization from Python `str` (copies); * Provide access to extern ""C"" declared functions in namespaces; * Support for (multiple and nested) anonymous structs; * Pull forward upstream patch for PPC; * Only apply system_dirs patch (for asan) on Linux; * Add not-yet loaded classes to namespaces in dir(); * Fix lookup of templates of function with template args; * Fix lookup of templates types with << in name; * Fix regression for accessing `char16_t` data member arrays; * Add custom `__reshape__` method to CPPInstance to allow array cast; * Prioritize callee exceptions over bindings exceptions; * Prevent infinite recursion when instantiating class with no constructors. 2021-11-14: 2.2.0; -----------------. * Migrated repos to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:4228,patch,patch,4228,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,1,['patch'],['patch']
Deployability,"245 (2020) 06007](https://www.epj-conferences.org/articles/epjconf/abs/2020/21/epjconf_chep2020_06007/epjconf_chep2020_06007.html),; [arxiv:2012.02746](https://arxiv.org/abs/2012.02746). #### RooBatchCompute Library. The library that contains the optimised computation functions is called `RooBatchCompute`. The PDFs contained in this library are highly optimized, and there is currently work in progress for further optimization using CUDA and multi-threaded computations. If you use PDFs that are not part of the official RooFit, you are very well invited to add them to RooFit by [submitting a ticket](https://github.com/root-project/root/issues/new) or a [pull request](https://github.com/root-project/root/pulls). #### Benefiting from batch computations by overriding `evaluateSpan()`. For PDFs that are not part of RooFit, it is possible to benefit from batch computations without vector extensions. To do so, consult the [RooBatchCompute readme](https://github.com/root-project/root/tree/v6-24-00-patches/roofit/batchcompute). #### Migrating PDFs that override the deprecated `evaluateBatch()`. In case you have created a custom PDF which overrides `evaluateBatch()`, please follow these steps to update your code to the newest version:. 1. Change the signature of the function both in the source and header file:; ```diff; - RooSpan<double> RooGaussian::evaluateBatch(std::size_t begin, std::size_t batchSize) const; + RooSpan<double> evaluateSpan(RooBatchCompute::RunContext& evalData, const RooArgSet* normSet) const; ```; 2. Include `RunContext.h` and `BracketAdapter.h`.; 3. Use `getValues()` instead of `getValBatch()` to retrieve a RooSpan for the data of every value.; ```diff; - auto xData = x.getValBatch(begin, batchSize);; + auto xData = x->getValues(evalData,normSet);; ```; 4. Retrieve the number of events by getting the maximum size of the input spans.; ```c++; size_t nEvents=0;; for (auto& i:{xData,meanData,sigmaData}); nEvents = std::max(nEvents,i.size());; ```; 5. Create t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:17068,patch,patches,17068,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['patch'],['patches']
Deployability,"2`"" draw a fill area poly line connecting the center of bins. - ""`A`"" Axis are drawn around the graph. - ""`C`"" A smooth curve is drawn. - ""`*`"" A star is plotted at each point. - ""`P`"" The current marker of the graph is plotted at each point. - ""`B`"" A bar chart is drawn at each point. - ""`[]` "" Only the end vertical/horizontal lines of the error bars; are drawn. This option only applies to the; **`TGraphAsymmErrors`**. - ""`1`"" `ylow` `=` `rwymin`. The options are not case sensitive and they can be concatenated in; most cases. Let us look at some examples. #### Continuous Line, Axis and Stars (AC\*). ![A graph drawn with axis, \* markers and continuous line (option AC\*)](pictures/0300004B.png). ``` {.cpp}; {; Int_t n = 20;; Double_t x[n], y[n];; for (Int_t i=0;i<n;i++) {; x[i] = i*0.1;; y[i] = 10*sin(x[i]+0.2);; }. // create graph; TGraph *gr = new TGraph(n,x,y);; TCanvas *c1 = new TCanvas(""c1"",""Graph Draw Options"",; 200,10,600,400);. // draw the graph with axis, continuous line, and put; // a * at each point; gr->Draw(""AC*"");; }; ```. #### Bar Graphs (AB). ![A graph drawn with axis and bar (option AB)](pictures/0300004C.png). ``` {.cpp}; root[] TGraph *gr1 = new TGraph(n,x,y);; root[] gr1->SetFillColor(40);; root[] gr1->Draw(""AB"");; ```. This code will only work if n, x, and y is defined. The previous; example defines these. You need to set the fill color, because by; default the fill color is white and will not be visible on a white; canvas. You also need to give it an axis, or the bar chart will not be; displayed properly. #### Filled Graphs (AF). ![A graph drawn with axis and fill (option AF)](pictures/0300004D.png). ``` {.cpp}; root[] TGraph *gr3 = new TGraph(n,x,y);; root[] gr3->SetFillColor(45);; root[] gr3->Draw(""AF""); ```. This code will only work if `n`, `x`, `y `are defined. The first; example defines them. You need to set the fill color, because by; default the fill color is white and will not be visible on a white; canvas. You also need to give it an ax",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphs.md:2300,continuous,continuous,2300,documentation/users-guide/Graphs.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphs.md,1,['continuous'],['continuous']
Deployability,"3. Fix - in log scales replace 10^1 label by 10; 4. Fix - vertical align of log labels on X axis; 5. Fix - second click of the same item in hierarchy painter. ## Changes in 7.5.0; 1. Correctly implement `TH2` projections like MERCATOR or PARABOLIC, add MOLLWEIDE; 2. Support ""pol"", ""cyl"", ""sph"" and ""psr"" coordinates systems for lego and surf plots; 3. Support orthographic camera for lego and surface plots; 4. Implement ""tri1"", ""tri2"", ""triw"" draw options for `TGraph2D` with Delaunay algorithm; 5. Add support of `TProfile3D` and `TPaveClass` classes; 6. Use ""col"" as default draw option for `TH2`, ""box2"" for `TH3`; 7. Draw axes grids in front of objects - making it equivalent to original ROOT; 8. Change `TF1` and `TF2` drawing - always convert into histogram, support TWebCanvas, handle log scales; 9. Provide ""Bring to front"" menu command for different objects like pave, box, marker, ...; 10. Provide ""Build legend"" context menu command for the pad; 11. Let toggle vertical/horizontal flag for color palette via context menu; 12. Support canvas grayscale, let toggle via context menu; 13. Basic latex support when drawing axes labels and titles in 3D; 14. Handle ""dark mode"" in geom painter - automatically adjust background; 15. Let configure material and scene properties in geom control gui; 16. Reset pad enlarge state when pressing ""Escape"" key #265; 17. Scale special fill patterns like 3244 to pad size; 18. Add ""Superimpose"" menu command in hierarchy - let select draw option when append item to pad; 19. Support `inspectN` draw option, allows automatically expand object content to specified level; 20. Implement `allfunc` draw option for histograms, force drawing disregard of TF1::kNotDraw bit; 21. Use `eslint` for static code checking, add testing of interactive features; 22. Upgrade three.js r151 -> r155; 23. Use https://github.com/georgealways/lil-gui/ instead of dat.GUI in geom painter; 24. Put `gl` in ""devDependencies"" of package.json; one can skip it installation with ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:9655,toggle,toggle,9655,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['toggle'],['toggle']
Deployability,"3.7` :ref:`¶ <KeepEmptyLinesAtTheStartOfBlocks>`; If true, the empty line at the start of blocks is kept. .. code-block:: c++. true: false:; if (foo) { vs. if (foo) {; bar();; bar(); }; }. .. _LambdaBodyIndentation:. **LambdaBodyIndentation** (``LambdaBodyIndentationKind``) :versionbadge:`clang-format 13` :ref:`¶ <LambdaBodyIndentation>`; The indentation style of lambda bodies. ``Signature`` (the default); causes the lambda body to be indented one additional level relative to; the indentation level of the signature. ``OuterScope`` forces the lambda; body to be indented one additional level relative to the parent scope; containing the lambda signature. Possible values:. * ``LBI_Signature`` (in configuration: ``Signature``); Align lambda body relative to the lambda signature. This is the default. .. code-block:: c++. someMethod(; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; });. * ``LBI_OuterScope`` (in configuration: ``OuterScope``); For statements within block scope, align lambda body relative to the; indentation level of the outer scope the lambda signature resides in. .. code-block:: c++. someMethod(; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; });. someMethod(someOtherMethod(; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; }));. .. _Language:. **Language** (``LanguageKind``) :versionbadge:`clang-format 3.5` :ref:`¶ <Language>`; Language, this format style is targeted at. Possible values:. * ``LK_None`` (in configuration: ``None``); Do not use. * ``LK_Cpp`` (in configuration: ``Cpp``); Should be used for C, C++. * ``LK_CSharp`` (in configuration: ``CSharp``); Should be used for C#. * ``LK_Java`` (in configuration: ``Java``); Should be used for Java. * ``LK_JavaScript`` (in configuration: ``JavaScript``); Should be used for JavaScript. * ``LK_Json`` (in configuration: ``Json``); Should be used for JSON. * ``LK_ObjC`` (in configuration: ``ObjC``); Should be used for Objective-C, Objective-C++. * ``LK_Proto`` (in configuration: ``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:82729,configurat,configuration,82729,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"3D type= 0, offset= 0, len=1, method=142684688; i= 2, m_KFcode type= 23, offset= 16, len=5, method=0; i= 3, m_Eta type= 25, offset= 36, len=3, method=0; i= 4, m_Trigger type= 3, offset= 48, len=1, method=0; ```. `MakeProject` has three parameters:. ``` {.cpp}; MakeProject(const char *dirname,const char *classes,Option_t *option); ```. The first is the directory name in which to place the generated header; files. The second parameter is the name of the classes to include in the; project. By default, all classes are included. It recognizes the wild; card character \*, for example, ""ATLF\*"" includes all classes beginning; with ATLF. The third parameter is an option with the following values:. - ""`new`"" If the directory does not exist, it is created. - ""`recreate`"" If the directory does not exist, it is creates as in; ""new"", in addition if the directory does exist, all existing files; are deleted before creating the new files. - ""`update`"" The new classes are added to the existing directory and; the existing classes are replaced with the new definition. If the; directory does not exist, it creates it as in ""new"". - ""+"": This option can be used in combination with the other three. It; will create the necessary files to easily build a shared library; containing the class definitions.Specifically it will:. - Generate a script called `MAKE` that builds the shared library; containing the definition of all classes in the directory. - Generate a `LinkDef.h `files to use with `rootcling` in `MAKE`. - Run `rootcling` to generate a `<dirname>ProjectDict.cxx` file. - Compile the \<`dirname>ProjectDict.cxx `with the current options in; `compiledata.h`. - Build a shared library` <dirname>.so`. - ""++"":This option can be used instead of the single ""+"". It does; everything the single ""+"" does, and dynamically loads the shared; library `<dirname>.so`. This example makes a directory called `MyProject` that will contain all; class definitions from the `atlfast.root` file. The necessary `ma",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:88376,update,update,88376,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['update'],['update']
Deployability,"4(void) {; printf(""Foo4"");; }. .. code-block:: bash. --- command lines ---; $ clang -flto a.c -c -o a.o # <-- a.o is LLVM bitcode file; $ ar q a.a a.o # <-- a.a is an archive with LLVM bitcode; $ clang b.c -c -o b.o # <-- b.o is native object file; $ clang -flto a.a b.o -o main # <-- link with LLVMgold plugin. Gold informs the plugin that foo3 is never referenced outside the IR,; leading LLVM to delete that function. However, unlike in the :ref:`libLTO; example <libLTO-example>` gold does not currently eliminate foo4. Quickstart for using LTO with autotooled projects; =================================================. Once your system ``ld``, ``ar``, and ``nm`` all support LLVM bitcode,; everything is in place for an easy to use LTO build of autotooled projects:. * Follow the instructions :ref:`on how to build LLVMgold.so; <lto-how-to-build>`. * Install the newly built binutils to ``$PREFIX``. * Copy ``Release/lib/LLVMgold.so`` to ``$PREFIX/lib/bfd-plugins/``. * Set environment variables (``$PREFIX`` is where you installed clang and; binutils):. .. code-block:: bash. export CC=""$PREFIX/bin/clang -flto""; export CXX=""$PREFIX/bin/clang++ -flto""; export AR=""$PREFIX/bin/ar""; export NM=""$PREFIX/bin/nm""; export RANLIB=/bin/true #ranlib is not needed, and doesn't support .bc files in .a. * Or you can just set your path:. .. code-block:: bash. export PATH=""$PREFIX/bin:$PATH""; export CC=""clang -flto""; export CXX=""clang++ -flto""; export RANLIB=/bin/true; * Configure and build the project as usual:. .. code-block:: bash. % ./configure && make && make check. The environment variable settings may work for non-autotooled projects too,; but you may need to set the ``LD`` environment variable as well. Licensing; =========. Gold is licensed under the GPLv3. LLVMgold uses the interface file; ``plugin-api.h`` from gold which means that the resulting ``LLVMgold.so``; binary is also GPLv3. This can still be used to link non-GPLv3 programs; just as much as gold could without the plugin.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GoldPlugin.rst:5211,install,installed,5211,interpreter/llvm-project/llvm/docs/GoldPlugin.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GoldPlugin.rst,1,['install'],['installed']
Deployability,"4.; * ``always`` - Always emit DWARF unwind regardless.; * ``default`` - Use the platform-specific default (``always`` for all; non-arm64-platforms). ``no-compact-unwind`` is a performance optimization -- Clang will emit smaller; object files that are more quickly processed by the linker. This may cause; binary compatibility issues on older x86_64 targets, however, so use it with; caution. .. _configuration-files:. Configuration files; -------------------. Configuration files group command-line options and allow all of them to be; specified just by referencing the configuration file. They may be used, for; example, to collect options required to tune compilation for particular; target, such as ``-L``, ``-I``, ``-l``, ``--sysroot``, codegen options, etc. Configuration files can be either specified on the command line or loaded; from default locations. If both variants are present, the default configuration; files are loaded first. The command line option ``--config=`` can be used to specify explicit; configuration files in a Clang invocation. If the option is used multiple times,; all specified files are loaded, in order. For example:. ::. clang --config=/home/user/cfgs/testing.txt; clang --config=debug.cfg --config=runtimes.cfg. If the provided argument contains a directory separator, it is considered as; a file path, and options are read from that file. Otherwise the argument is; treated as a file name and is searched for sequentially in the directories:. - user directory,; - system directory,; - the directory where Clang executable resides. Both user and system directories for configuration files are specified during; clang build using CMake parameters, ``CLANG_CONFIG_FILE_USER_DIR`` and; ``CLANG_CONFIG_FILE_SYSTEM_DIR`` respectively. The first file found is used.; It is an error if the required file cannot be found. The default configuration files are searched for in the same directories; following the rules described in the next paragraphs. Loading default; conf",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:31107,configurat,configuration,31107,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['configurat'],['configuration']
Deployability,"5 movl $0xffff, %rax <--- patched code at stack map address; 0x0a callq *%rax <---- end of 8-byte shadow. This way, after the normal call to the runtime returns, the code will; execute a patched call to a special entry point that can rebuild a; stack frame from the values located by the stack map. '``llvm.experimental.patchpoint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.patchpoint.void(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...); declare i64; @llvm.experimental.patchpoint.i64(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.patchpoint.*``' intrinsics creates a function; call to the specified ``<target>`` and records the location of specified; values in the stack map. Operands:; """""""""""""""""". The first operand is an ID, the second operand is the number of bytes; reserved for the patchable region, the third operand is the target; address of a function (optionally null), and the fourth operand; specifies how many of the following variable operands are considered; function call arguments. The remaining variable number of operands are; the ``live values`` for which locations will be recorded in the stack; map. Semantics:; """""""""""""""""""". The patch point intrinsic generates a stack map. It also emits a; function call to the address specified by ``<target>`` if the address; is not a constant null. The function call and its arguments are; lowered according to the calling convention specified at the; intrinsic's callsite. Variants of the intrinsic with non-void return; type also return a value according to calling convention. On PowerPC, note that ``<target>`` must be the ABI function pointer for the; intended target of the indirect call. Specifically, when compiling for the; ELF V1 ABI, ``<target>`` is the function-descriptor address normally used as; the C/C++ function-pointer representation. Requesting zero patch point arguments",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:7965,patch,patchable,7965,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['patch'],['patchable']
Deployability,"600);; c->SetFillColor(38);; gs->Draw();; return c;; }; . This new funtionnality relies on the graphivz package.; This package can be downloaded from; http://www.graphviz.org/. At installation time, to find graphviz, the ROOT's configure file looks in; standard locations. It is possible to define a specific location using the; configure flags:. --with-gviz-incdir=""the directory where gvc.h is""; --with-gviz-libdir=""the directory where the libgvc library is"". To install graphviz (if needed) it is recommended to use the following configure flags:. --enable-static=yes --enable-shared=no --with-pic --prefix=""graphviz installed here"". On 64 bits machines, the ROOT sources are compiled with the option -m64. In; that case graphviz should be also compiled in 64 bits mode. It might be the; default option, but on some machine it is not. In that case the environment; variable CC should be defined as:. CC=""gcc -m64"". before doing configure. On Windows machines it recommended to not install graphviz but to download the; pre-installed version from http://www.graphviz.org/. The ROOT configure command; remains the same.; Graphics Primitives; New class TGraphTime; TGraphTime is used to draw a set of objects evolving with nsteps in time between tmin and tmax.; each time step has a new list of objects. This list can be identical to; the list of objects in the previous steps, but with different attributes.; see example of use in $ROOTSYS/tutorials/graphs/gtime.C. TLatex. In the following macro the #int and #sum symbols had; wrong limits placement if the character just before started with ""#"".; ; {; TCanvas *c1 = new TCanvas(""c1"",""c1"",500,500);; TLatex l;; l.SetTextSize(0.1);. l.DrawLatex(0.1,0.6,""#nu#int^{1-x}_{2#pi}"");; l.DrawLatex(0.1,0.2,""a#int^{1-x}_{2#pi}"");. l.DrawLatex(0.5,0.6,""#nu#sum^{1-x}_{2#pi}"");; l.DrawLatex(0.5,0.2,""a#sum^{1-x}_{2#pi}"");; }; . This problem is there since the 1st version of TLatex. It is fixed by:; ; Giving ""^"" and ""_"" a lower precedence than special and gre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v526/index.html:4238,install,install,4238,graf2d/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v526/index.html,2,['install'],"['install', 'installed']"
Deployability,"64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The stack map now indicates the location of the %ptr argument and; return value:. .. code-block:: none. Stack Map: ID=78, Loc0=%r9 Loc1=%r8. The patch code sequence may now use the argument that happened to be; allocated in %r8 and return a value allocated in %r9:. .. code-block:: none. 0x00 movslq 4(%r8) %r9 <--- patched code at patch point address; 0x03 nop; ...; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %r9; 0x10 movl %r9, 8(%rsp). .. _stackmap-format:. Stack Map Format; ================. The existence of a stack map or patch point intrinsic within an LLVM; Module forces code emission to create a :ref:`stackmap-section`. The; format of this section follows:. .. code-block:: none. Header {; uint8 : Stack Map Version (current version is 3); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; uint32 : NumConstants; uint32 : NumRecords; StkSizeRecord[NumFunctions] {; uint64 : Function Address; uint64 : Stack Size (or UINT64_MAX if not statically known); uint64 : Record Count; }; Constants[NumConstants] {; uint64 : LargeConstant; }; StkMapRecord[NumRecords] {; uint64 : PatchPoint ID; uint32 : Instruction Offset; uint16 : Reserved (record flags); uint16 : NumLocations; Location[NumLocations] {; uint8 : Register | Direct | Indirect | Constant | Co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:11713,patch,patched,11713,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,2,['patch'],"['patch', 'patched']"
Deployability,"8 bits are reserved; for the system usage; the low 24 bits are user settable. `fUniqueID` is; a data member used to give a unique identification number to an object.; It is initialized to zero by the **`TObject`** constructor. ROOT does; not use this data member. The two data members (`fBits` and `fUniqueID`); are streamed out when writing an object to disk. If you do not use them,; you can save some space and time by specifying:. ``` {.cpp}; MyClass::Class()->IgnoreTObjectStreamer();; ```. This sets a bit in the **`TClass`** object. If the file is compressed,; the savings are minimal since most values are zero; however, it saves; some space when the file is not compressed. A call; to` IgnoreTObjectStreamer` also prevents the creation of two additional; branches when splitting the object. If left alone, two branches called; `fBits` and `fUniqueID` will appear. ## Motivation. If you want to integrate and use your classes with ROOT, to enjoy; features like, extensive RTTI (Run Time Type Information) and ROOT; object I/O and inspection, you have to add the following line to your; class header files:. ``` {.cpp}; ClassDef(ClassName,ClassVersionID); //The class title; ```. For example in `TLine.h` we have:. ``` {.cpp}; ClassDef(TLine,1); //A line segment; ```. The **`ClassVersionID`** is used by the ROOT I/O system. It is written; on the output stream and during reading you can check this version ID; and take appropriate action depending on the value of the ID. See; ""Streamers"". Every time you change the data members of a class, you; should increase its `ClassVersionID` by one. The `ClassVersionID` should; be `>=1`. Set `ClassVersionID=0` in case you don't need object I/O. To; be able to generate properly documentation for your classes using; **`THtml`** you must add the statement:. ``` {.cpp}; ClassImp(ClassName); ```. For example in `TLine.cxx`:. ``` {.cpp}; ClassImp(TLine); ```. Note that you should provide a default constructor for your classes,; i.e. a constructor wi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md:7764,integrat,integrate,7764,documentation/users-guide/AddingaClass.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md,1,['integrat'],['integrate']
Deployability,"872c9feff40f); or by passing the appropriate parameter to executors' constructors, as in; [`TThreadExecutor::TThreadExecutor`](https://root.cern/doc/master/classROOT_1_1TThreadExecutor.html#ac7783d52c56cc7875d3954cf212247bb). See the discussion at [ROOT-11014](https://sft.its.cern.ch/jira/browse/ROOT-11014) for more context. ### Dynamic Path: `ROOT_LIBRARY_PATH`. A new way to set ROOT's ""Dynamic Path"" was added: the; environment variable `ROOT_LIBRARY_PATH`. On Unix it should contain a colon; separated list of paths, on Windows a semicolon separated list. It is; intended to be cross platform and to be specific to ROOT (and thus not; interfere with the system's shared linker).; The final ""Dynamic Path"" is now composed of these sources in order:; 1. `ROOT_LIBRARY_PATH` environment variable; 2. System specific shared linker environment variables like; `LD_LIBRARY_PATH`, `LIBPATH`, or `PATH`.; 3. Setting from rootrc; 4. ROOT's builtin library directory. ### Interpreter. - cling's LLVM is upgraded to version 9.0; - New interface to enable/disable optional cling features. Currently, it can be used to enable/disable support for redefinitions. See [this](https://github.com/root-project/cling/issues/360) issue for more information. ### Multithreading. - Fix an uninitialized variable in global read-write lock which could have caused deadlocks or crashes in some rare cases.; - Default global read-write lock transitioned to new implementation based on TBB thread local storage when TBB is available on supported platforms (all except Windows). This gives an O(10%) performance improvement for some typical RDataFrame scenarios with 256 threads due to reduced lock contention. ## I/O Libraries. - Exclusive use of the global lock is reduced or migrated to finer grained read and write locks in a few hotspots that occur during file opening/closing or task initialization in RDataFrame. This can lead to O(100x) improvements for some typical RDataFrame scenarios with 256 threads due to mass",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:3588,upgrade,upgraded,3588,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['upgrade'],['upgraded']
Deployability,"9"". The possible GFX major generation numbers are presented in; :ref:`amdgpu-processors`. .option.machine_version_minor; +++++++++++++++++++++++++++++. Set to the GFX minor generation number of the target being assembled for. For; example, when assembling for a ""GFX810"" target this will be set to the integer; value ""1"". The possible GFX minor generation numbers are presented in; :ref:`amdgpu-processors`. .option.machine_version_stepping; ++++++++++++++++++++++++++++++++. Set to the GFX stepping generation number of the target being assembled for.; For example, when assembling for a ""GFX704"" target this will be set to the; integer value ""4"". The possible GFX stepping generation numbers are presented; in :ref:`amdgpu-processors`. .kernel.vgpr_count; ++++++++++++++++++. Set to zero each time a; :ref:`amdgpu-amdhsa-assembler-directive-amdgpu_hsa_kernel` directive is; encountered. At each instruction, if the current value of this symbol is less; than or equal to the maximum VGPR number explicitly referenced within that; instruction then the symbol value is updated to equal that VGPR number plus; one. .kernel.sgpr_count; ++++++++++++++++++. Set to zero each time a; :ref:`amdgpu-amdhsa-assembler-directive-amdgpu_hsa_kernel` directive is; encountered. At each instruction, if the current value of this symbol is less; than or equal to the maximum VGPR number explicitly referenced within that; instruction then the symbol value is updated to equal that SGPR number plus; one. .. _amdgpu-amdhsa-assembler-directives-v2:. Code Object V2 Directives; ~~~~~~~~~~~~~~~~~~~~~~~~~. .. warning::; Code object V2 generation is no longer supported by this version of LLVM. AMDGPU ABI defines auxiliary data in output code object. In assembly source,; one can specify them with assembler directives. .hsa_code_object_version major, minor; +++++++++++++++++++++++++++++++++++++. *major* and *minor* are integers that specify the version of the HSA code; object that will be generated by the assembler.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:431767,update,updated,431767,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['update'],['updated']
Deployability,"9);; n7->SetFillColor(kViolet-9);. // some edges ...; gs->AddEdge(n0,n1)->SetLineColor(kRed);; TGraphEdge *e06 = gs->AddEdge(n0,n6);; e06->SetLineColor(kRed-3);; e06->SetLineWidth(4);; gs->AddEdge(n1,n7);; gs->AddEdge(n4,n6);; gs->AddEdge(n3,n9);; gs->AddEdge(n6,n8);; gs->AddEdge(n7,n2);; gs->AddEdge(n8,n3);; gs->AddEdge(n2,n3);; gs->AddEdge(n9,n0);; gs->AddEdge(n1,n4);; gs->AddEdge(n1,n6);; gs->AddEdge(n2,n5);; gs->AddEdge(n3,n6);; gs->AddEdge(n4,n5);. TCanvas *c = new TCanvas(""c"",""c"",800,600);; c->SetFillColor(38);; gs->Draw();; return c;; }; . This new funtionnality relies on the graphivz package.; This package can be downloaded from; http://www.graphviz.org/. At installation time, to find graphviz, the ROOT's configure file looks in; standard locations. It is possible to define a specific location using the; configure flags:. --with-gviz-incdir=""the directory where gvc.h is""; --with-gviz-libdir=""the directory where the libgvc library is"". To install graphviz (if needed) it is recommended to use the following configure flags:. --enable-static=yes --enable-shared=no --with-pic --prefix=""graphviz installed here"". On 64 bits machines, the ROOT sources are compiled with the option -m64. In; that case graphviz should be also compiled in 64 bits mode. It might be the; default option, but on some machine it is not. In that case the environment; variable CC should be defined as:. CC=""gcc -m64"". before doing configure. On Windows machines it recommended to not install graphviz but to download the; pre-installed version from http://www.graphviz.org/. The ROOT configure command; remains the same.; Graphics Primitives; New class TGraphTime; TGraphTime is used to draw a set of objects evolving with nsteps in time between tmin and tmax.; each time step has a new list of objects. This list can be identical to; the list of objects in the previous steps, but with different attributes.; see example of use in $ROOTSYS/tutorials/graphs/gtime.C. TLatex. In the following macro the #int",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v526/index.html:3719,install,install,3719,graf2d/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v526/index.html,1,['install'],['install']
Deployability,": Auto upgrade mangler; D: llvm-gcc4 svn wrangler. N: Chris Lattner; E: sabre@nondot.org; W: http://nondot.org/~sabre/; D: Primary architect of LLVM. N: Tanya Lattner (Tanya Brethour); E: tonic@nondot.org; W: http://nondot.org/~tonic/; D: The initial llvm-ar tool, converted regression testsuite to dejagnu; D: Modulo scheduling in the SparcV9 backend; D: Release manager (1.7+). N: Sylvestre Ledru; E: sylvestre@debian.org; W: http://sylvestre.ledru.info/; W: https://apt.llvm.org/; D: Debian and Ubuntu packaging; D: Continuous integration with jenkins. N: Andrew Lenharth; E: alenhar2@cs.uiuc.edu; W: http://www.lenharth.org/~andrewl/; D: Alpha backend; D: Sampling based profiling. N: Nick Lewycky; E: nicholas@mxc.ca; D: PredicateSimplifier pass. N: Tony Linthicum, et. al.; E: tlinth@codeaurora.org; D: Backend for Qualcomm's Hexagon VLIW processor. N: Bruno Cardoso Lopes; E: bruno.cardoso@gmail.com; I: bruno; W: http://brunocardoso.cc; D: Mips backend; D: Random ARM integrated assembler and assembly parser improvements; D: General X86 AVX1 support. N: Weining Lu; E: luweining@loongson.cn; D: LoongArch backend. N: Duraid Madina; E: duraid@octopus.com.au; W: http://kinoko.c.u-tokyo.ac.jp/~duraid/; D: IA64 backend, BigBlock register allocator. N: John McCall; E: rjmccall@apple.com; D: Clang semantic analysis and IR generation. N: Michael McCracken; E: michael.mccracken@gmail.com; D: Line number support for llvmgcc. N: Fanbo Meng; E: fanbo.meng@ibm.com; D: z/OS support. N: Vladimir Merzliakov; E: wanderer@rsu.ru; D: Test suite fixes for FreeBSD. N: Scott Michel; E: scottm@aero.org; D: Added STI Cell SPU backend. N: Kai Nacke; E: kai@redstar.de; D: Support for implicit TLS model used with MS VC runtime; D: Dumping of Win64 EH structures. N: Takumi Nakamura; I: chapuni; E: geek4civic@gmail.com; E: chapuni@hf.rim.or.jp; D: Maintaining the Git monorepo; W: https://github.com/llvm-project/; S: Ebina, Japan. N: Edward O'Callaghan; E: eocallaghan@auroraux.org; W: http://www.aurorau",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT:8181,integrat,integrated,8181,interpreter/llvm-project/llvm/CREDITS.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT,1,['integrat'],['integrated']
Deployability,": Sparse bitmap. N: Geoff Berry; E: gberry@codeaurora.org; E: gcb@acm.org; D: AArch64 backend improvements; D: Added EarlyCSE MemorySSA support; D: CodeGen improvements. N: David Blaikie; E: dblaikie@gmail.com; D: General bug fixing/fit & finish, mostly in Clang. N: Neil Booth; E: neil@daikokuya.co.uk; D: APFloat implementation. N: Alex Bradbury; E: asb@igalia.com; D: RISC-V backend. N: Misha Brukman; E: brukman+llvm@uiuc.edu; W: http://misha.brukman.net; D: Portions of X86 and Sparc JIT compilers, PowerPC backend; D: Incremental bitcode loader. N: Cameron Buschardt; E: buschard@uiuc.edu; D: The `mem2reg' pass - promotes values stored in memory to registers. N: Brendon Cahoon; E: bcahoon@codeaurora.org; D: Loop unrolling with run-time trip counts. N: Chandler Carruth; E: chandlerc@gmail.com; E: chandlerc@google.com; D: Hashing algorithms and interfaces; D: Inline cost analysis; D: Machine block placement pass; D: SROA. N: Casey Carter; E: ccarter@uiuc.edu; D: Fixes to the Reassociation pass, various improvement patches. N: Evan Cheng; E: evan.cheng@apple.com; D: ARM and X86 backends; D: Instruction scheduler improvements; D: Register allocator improvements; D: Loop optimizer improvements; D: Target-independent code generator improvements. N: Dan Villiom Podlaski Christiansen; E: danchr@gmail.com; E: danchr@cs.au.dk; W: http://villiom.dk; D: LLVM Makefile improvements; D: Clang diagnostic & driver tweaks; S: Aarhus, Denmark. N: Jeff Cohen; E: jeffc@jolt-lang.org; W: http://jolt-lang.org; D: Native Win32 API portability layer. N: John T. Criswell; E: criswell@uiuc.edu; D: Original Autoconf support, documentation improvements, bug fixes. N: Anshuman Dasgupta; E: adasgupt@codeaurora.org; D: Deterministic finite automaton based infrastructure for VLIW packetization. N: Stefanus Du Toit; E: stefanus.du.toit@intel.com; D: Bug fixes and minor improvements. N: Rafael Avila de Espindola; E: rafael@espindo.la; D: MC and LLD work. N: Dave Estes; E: cestes@codeaurora.org; D: AArc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT:2334,patch,patches,2334,interpreter/llvm-project/llvm/CREDITS.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT,1,['patch'],['patches']
Deployability,": [result] ""=r""(result); : ""r""(test), ""r""(new), ""[result]""(old));. * ``BBIAS_Always`` (in configuration: ``Always``); Always break before inline ASM colon. .. code-block:: c++. asm volatile(""string"",; :; : val);. .. _BreakBeforeTernaryOperators:. **BreakBeforeTernaryOperators** (``Boolean``) :versionbadge:`clang-format 3.7` :ref:`¶ <BreakBeforeTernaryOperators>`; If ``true``, ternary operators will be placed after line breaks. .. code-block:: c++. true:; veryVeryVeryVeryVeryVeryVeryVeryVeryVeryVeryLongDescription; ? firstValue; : SecondValueVeryVeryVeryVeryLong;. false:; veryVeryVeryVeryVeryVeryVeryVeryVeryVeryVeryLongDescription ?; firstValue :; SecondValueVeryVeryVeryVeryLong;. .. _BreakConstructorInitializers:. **BreakConstructorInitializers** (``BreakConstructorInitializersStyle``) :versionbadge:`clang-format 5` :ref:`¶ <BreakConstructorInitializers>`; The break constructor initializers style to use. Possible values:. * ``BCIS_BeforeColon`` (in configuration: ``BeforeColon``); Break constructor initializers before the colon and after the commas. .. code-block:: c++. Constructor(); : initializer1(),; initializer2(). * ``BCIS_BeforeComma`` (in configuration: ``BeforeComma``); Break constructor initializers before the colon and commas, and align; the commas with the colon. .. code-block:: c++. Constructor(); : initializer1(); , initializer2(). * ``BCIS_AfterColon`` (in configuration: ``AfterColon``); Break constructor initializers after the colon and commas. .. code-block:: c++. Constructor() :; initializer1(),; initializer2(). .. _BreakInheritanceList:. **BreakInheritanceList** (``BreakInheritanceListStyle``) :versionbadge:`clang-format 7` :ref:`¶ <BreakInheritanceList>`; The inheritance list style to use. Possible values:. * ``BILS_BeforeColon`` (in configuration: ``BeforeColon``); Break inheritance list before the colon and after the commas. .. code-block:: c++. class Foo; : Base1,; Base2; {};. * ``BILS_BeforeComma`` (in configuration: ``BeforeComma``); Break in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:54349,configurat,configuration,54349,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,": ``Proto``); Should be used for Protocol Buffers; (https://developers.google.com/protocol-buffers/). * ``LK_TableGen`` (in configuration: ``TableGen``); Should be used for TableGen code. * ``LK_TextProto`` (in configuration: ``TextProto``); Should be used for Protocol Buffer messages in text format; (https://developers.google.com/protocol-buffers/). * ``LK_Verilog`` (in configuration: ``Verilog``); Should be used for Verilog and SystemVerilog.; https://standards.ieee.org/ieee/1800/6700/; https://sci-hub.st/10.1109/IEEESTD.2018.8299595. .. _LineEnding:. **LineEnding** (``LineEndingStyle``) :versionbadge:`clang-format 16` :ref:`¶ <LineEnding>`; Line ending style (``\n`` or ``\r\n``) to use. Possible values:. * ``LE_LF`` (in configuration: ``LF``); Use ``\n``. * ``LE_CRLF`` (in configuration: ``CRLF``); Use ``\r\n``. * ``LE_DeriveLF`` (in configuration: ``DeriveLF``); Use ``\n`` unless the input has more lines ending in ``\r\n``. * ``LE_DeriveCRLF`` (in configuration: ``DeriveCRLF``); Use ``\r\n`` unless the input has more lines ending in ``\n``. .. _MacroBlockBegin:. **MacroBlockBegin** (``String``) :versionbadge:`clang-format 3.7` :ref:`¶ <MacroBlockBegin>`; A regular expression matching macros that start a block. .. code-block:: c++. # With:; MacroBlockBegin: ""^NS_MAP_BEGIN|\; NS_TABLE_HEAD$""; MacroBlockEnd: ""^\; NS_MAP_END|\; NS_TABLE_.*_END$"". NS_MAP_BEGIN; foo();; NS_MAP_END. NS_TABLE_HEAD; bar();; NS_TABLE_FOO_END. # Without:; NS_MAP_BEGIN; foo();; NS_MAP_END. NS_TABLE_HEAD; bar();; NS_TABLE_FOO_END. .. _MacroBlockEnd:. **MacroBlockEnd** (``String``) :versionbadge:`clang-format 3.7` :ref:`¶ <MacroBlockEnd>`; A regular expression matching macros that end a block. .. _Macros:. **Macros** (``List of Strings``) :versionbadge:`clang-format 17` :ref:`¶ <Macros>`; A list of macros of the form ``<definition>=<expansion>`` . Code will be parsed with macros expanded, in order to determine how to; interpret and format the macro arguments. For example, the code:. .. code-bl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:84764,configurat,configuration,84764,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,":. * ``-mdefault-visibility-export-mapping=none``: no additional export; information is created for entities with default visibility.; * ``-mdefault-visibility-export-mapping=explicit``: mark entities for export; if they have explicit (e.g. via an attribute) default visibility from the; source, including RTTI.; * ``-mdefault-visibility-export-mapping=all``: set XCOFF exported visibility; for all entities with default visibility from any source. This gives a; export behavior similar to ELF platforms where all entities with default; visibility are exported. .. _spir-v:. SPIR-V support; --------------. Clang supports generation of SPIR-V conformant to `the OpenCL Environment; Specification; <https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_Env.html>`_. To generate SPIR-V binaries, Clang uses the external ``llvm-spirv`` tool from the; `SPIRV-LLVM-Translator repo; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator>`_. Prior to the generation of SPIR-V binary with Clang, ``llvm-spirv``; should be built or installed. Please refer to `the following instructions; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator#build-instructions>`_; for more details. Clang will expect the ``llvm-spirv`` executable to; be present in the ``PATH`` environment variable. Clang uses ``llvm-spirv``; with `the widely adopted assembly syntax package; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator/#build-with-spirv-tools>`_. `The versioning; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator/releases>`_ of; ``llvm-spirv`` is aligned with Clang major releases. The same applies to the; main development branch. It is therefore important to ensure the ``llvm-spirv``; version is in alignment with the Clang version. For troubleshooting purposes; ``llvm-spirv`` can be `tested in isolation; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator#test-instructions>`_. Example usage for OpenCL kernel compilation:. .. code-block:: console. $ clang --target=spirv32 -c tes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:165752,install,installed,165752,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['install'],['installed']
Deployability,":. _foo:; 	and r1, r0, #127; 	ldr r2, LCPI1_0; 	ldr r2, [r2]; 	ldr r1, [r2, +r1, lsl #2]; 	mov r2, r1, lsr #2; 	tst r0, #128; 	moveq r2, r1; 	ldr r0, LCPI1_1; 	and r0, r2, r0; 	bx lr. It would be better to do something like this, to fold the shift into the; conditional move:. 	and r1, r0, #127; 	ldr r2, LCPI1_0; 	ldr r2, [r2]; 	ldr r1, [r2, +r1, lsl #2]; 	tst r0, #128; 	movne r1, r1, lsr #2; 	ldr r0, LCPI1_1; 	and r0, r1, r0; 	bx lr. it saves an instruction and a register. //===---------------------------------------------------------------------===//. It might be profitable to cse MOVi16 if there are lots of 32-bit immediates; with the same bottom half. //===---------------------------------------------------------------------===//. Robert Muth started working on an alternate jump table implementation that; does not put the tables in-line in the text. This is more like the llvm; default jump table implementation. This might be useful sometime. Several; revisions of patches are on the mailing list, beginning at:; http://lists.llvm.org/pipermail/llvm-dev/2009-June/022763.html. //===---------------------------------------------------------------------===//. Make use of the ""rbit"" instruction. //===---------------------------------------------------------------------===//. Take a look at test/CodeGen/Thumb2/machine-licm.ll. ARM should be taught how; to licm and cse the unnecessary load from cp#1. //===---------------------------------------------------------------------===//. The CMN instruction sets the flags like an ADD instruction, while CMP sets; them like a subtract. Therefore to be able to use CMN for comparisons other; than the Z bit, we'll need additional logic to reverse the conditionals; associated with the comparison. Perhaps a pseudo-instruction for the comparison,; with a post-codegen pass to clean up and handle the condition codes?; See PR5694 for testcase. //===---------------------------------------------------------------------===//. Given the followin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:16878,patch,patches,16878,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,1,['patch'],['patches']
Deployability,":. ```c++; #include ""example_output.hxx""; float input[INPUT_SIZE];; std::vector<float> out = TMVA_SOFIE_example_model::infer(input);. // Generated header file shall contain a Session class which requires initialization to load the corresponding weights.; TMVA_SOFIE_example_model::Session s(""example_model.dat""). // Once instantiated the session object's infer method can be used; std::vector<float> out = s.infer(input);; ```. With the default settings, the weights are contained in a separate binary file, but if the user instead wants them to be in the generated header file itself, they can use approproiate generation options. ```c++; model.Generate(Options::kNoWeightFile);; ```. Other such options includes `Options::kNoSession` (for not generating the Session class, and instead keeping the infer function independent).; SOFIE also supports generating inference code with RDataFrame as inputs, refer to the tutorials below for examples. ## Supported ONNX operators. Here is the updated list of supported ONNX operators. - [x] Add; - [x] AveragePool; - [x] BatchNormalization; - [x] Cast; - [x] Concat; - [x] Constant; - [x] ConstantOfShape; - [x] Conv; - [x] ConvTranspose; - [x] Elu; - [x] Equal; - [x] Erf; - [x] Exp; - [x] Expand; - [x] EyeLike; - [x] Flatten; - [x] Gather; - [x] Gemm; - [x] GlobalAveragePool; - [x] Greater; - [x] GreaterOrEqual; - [x] GRU; - [x] Identity; - [x] If; - [x] LayerNormalization; - [x] LeakyRelu; - [x] Less; - [x] LessOrEqual; - [x] Log; - [x] LSTM; - [x] MatMul; - [x] Max; - [x] MaxPool; - [x] Mean; - [x] Min; - [x] Mul; - [x] Neg; - [x] Pool; - [x] Pow; - [x] Range; - [x] Reciprocal; - [x] ReduceMean; - [x] ReduceProd; - [x] ReduceSum; - [x] ReduceSumSquare; - [x] Relu; - [x] Reshape; - [x] RNN; - [x] Selu; - [x] Sigmoid; - [x] Slice; - [x] Softmax; - [x] Split; - [x] Sqrt; - [x] Squeeze; - [x] Tanh; - [x] Tile; - [x] TopK; - [x] Transpose; - [x] Unsqueeze. The above operators are supported for tensors of the following types:. - [x] float; - [x",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/sofie/README.md:2888,update,updated,2888,tmva/sofie/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/sofie/README.md,1,['update'],['updated']
Deployability,"://github.com/wlav/CPyCppyy; * PyPy intermediate (module _cppyy): https://foss.heptapod.net/pypy; * Backend, cppyy: https://github.com/wlav/cppyy-backend. The backend repo contains both the cppyy-cling (under ""cling"") and; cppyy-backend (under ""clingwrapper"") packages. .. _building_from_source:. Building from source; --------------------. Except for cppyy-cling, the structure in the repositories follows a normal; PyPA package and they are thus ready to build with `setuptools`_: simply; clone the package and either run ``python setup.py``, or use ``pip``. It is highly recommended to follow the dependency chain when manually; upgrading packages individually (i.e. ``cppyy-cling``, ``cppyy-backend``,; ``CPyCppyy`` if on CPython, and then finally ``cppyy``), because upstream; packages expose headers that are used by the ones downstream.; Of course, if only building for a patch/point release, there is no need to; re-install the full chain (or follow the order).; Always run the local updates from the package directories (i.e. where the; ``setup.py`` file is located), as some tools rely on the package structure. The ``STDCXX`` envar can be used to control the C++ standard version; use; ``MAKE`` to change the ``make`` command; and ``MAKE_NPROCS`` to control the; maximum number of parallel jobs.; Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled). On MS Windows, some temporary path names may be too long, causing the build to; fail.; To resolve this issue, point the ``TMP`` and ``TEMP`` envars to an existing; directory with a short name before the build:; For example::. > set TMP=C:\TMP; > set TEMP=C:\TMP. The first package to build is ``cppyy-cling``.; It may take a long time, especially on a laptop (Mac ARM being a notable; exception), since Cling comes with a builtin version of LLVM/Clang.; Consider therefore for a moment your reasons for bu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:1457,update,updates,1457,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,1,['update'],['updates']
Deployability,"://itanium-cxx-abi.github.io/cxx-abi/abi.html#mangle.encoding>`_>s,; respectively.; Blank lines and lines starting with ``#`` are ignored. For convenience, built-in <substitution>s such as ``St`` and ``Ss``; are accepted as <name>s (even though they technically are not <name>s). For example, to specify that ``absl::string_view`` and ``std::string_view``; should be treated as equivalent when matching profile data, the following; remapping file could be used:. .. code-block:: text. # absl::string_view is considered equivalent to std::string_view; type N4absl11string_viewE St17basic_string_viewIcSt11char_traitsIcEE. # std:: might be std::__1:: in libc++ or std::__cxx11:: in libstdc++; name 3std St3__1; name 3std St7__cxx11. Matching profile data using a profile remapping file is supported on a; best-effort basis. For example, information regarding indirect call targets is; currently not remapped. For best results, you are encouraged to generate new; profile data matching the updated program, or to remap the profile data; using the ``llvm-cxxmap`` and ``llvm-profdata merge`` tools. .. note::. Profile data remapping is currently only supported for C++ mangled names; following the Itanium C++ ABI mangling scheme. This covers all C++ targets; supported by Clang other than Windows. GCOV-based Profiling; --------------------. GCOV is a test coverage program, it helps to know how often a line of code; is executed. When instrumenting the code with ``--coverage`` option, some; counters are added for each edge linking basic blocks. At compile time, gcno files are generated containing information about; blocks and edges between them. At runtime the counters are incremented and at; exit the counters are dumped in gcda files. The tool ``llvm-cov gcov`` will parse gcno, gcda and source files to generate; a report ``.c.gcov``. .. option:: -fprofile-filter-files=[regexes]. Define a list of regexes separated by a semi-colon.; If a file name matches any of the regexes then the file is i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:122206,update,updated,122206,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['update'],['updated']
Deployability,"://www.sphinx-doc.org/en/stable/ and published to; http://cppyy.readthedocs.io/en/latest/index.html using a webhook. To create; the docs::. $ pip install sphinx_rtd_theme; Collecting sphinx_rtd_theme; ...; Successfully installed sphinx-rtd-theme-0.2.4; $ cd docs; $ make html. The Python code in this module supports:. * Interfacing to the correct backend for CPython or PyPy.; * Pythonizations (TBD). Cppyy-backend; -------------. The ``cppyy-backend`` module contains two areas:. * A patched copy of cling; * Wrapper code. Package structure; -----------------; .. _package-structure:. There are four PyPA packages involved in a full installation, with the; following structure::. (A) _cppyy (PyPy); / \; (1) cppyy (3) cppyy-backend -- (4) cppyy-cling; \ /; (2) CPyCppyy (CPython). The user-facing package is always ``cppyy`` (1).; It is used to select the other (versioned) required packages, based on the; python interpreter for which it is being installed. Below (1) follows a bifurcation based on interpreter.; This is needed for functionality and performance: for CPython, there is the; CPyCppyy package (2).; It is written in C++, makes use of the Python C-API, and installs as a Python; extension module.; For PyPy, there is the builtin module ``_cppyy`` (A).; This is not a PyPA package.; It is written in RPython as it needs access to low-level pointers, JIT hints,; and the ``_cffi_backend`` backend module (itself builtin). Shared again across interpreters is the backend, which is split in a small; wrapper (3) and a large package that contains Cling/LLVM (4).; The former is still under development and expected to be updated frequently.; It is small enough to download and build very quickly.; The latter, however, takes a long time to build, but since it is very stable,; splitting it off allows the creation of binary wheels that need updating; only infrequently (expected about twice a year). All code is publicly available; see the; :doc:`section on repositories <repositories>`.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst:1449,install,installs,1449,bindings/pyroot/cppyy/cppyy/doc/source/packages.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst,2,"['install', 'update']","['installs', 'updated']"
Deployability,":: c++. true:; void myFunction(; int a, int b, int c, int d, int e);. false:; void myFunction(int a,; int b,; int c,; int d,; int e);. .. _AllowBreakBeforeNoexceptSpecifier:. **AllowBreakBeforeNoexceptSpecifier** (``BreakBeforeNoexceptSpecifierStyle``) :versionbadge:`clang-format 18` :ref:`¶ <AllowBreakBeforeNoexceptSpecifier>`; Controls if there could be a line break before a ``noexcept`` specifier. Possible values:. * ``BBNSS_Never`` (in configuration: ``Never``); No line break allowed. .. code-block:: c++. void foo(int arg1,; double arg2) noexcept;. void bar(int arg1, double arg2) noexcept(; noexcept(baz(arg1)) &&; noexcept(baz(arg2)));. * ``BBNSS_OnlyWithParen`` (in configuration: ``OnlyWithParen``); For a simple ``noexcept`` there is no line break allowed, but when we; have a condition it is. .. code-block:: c++. void foo(int arg1,; double arg2) noexcept;. void bar(int arg1, double arg2); noexcept(noexcept(baz(arg1)) &&; noexcept(baz(arg2)));. * ``BBNSS_Always`` (in configuration: ``Always``); Line breaks are allowed. But note that because of the associated; penalties ``clang-format`` often prefers not to break before the; ``noexcept``. .. code-block:: c++. void foo(int arg1,; double arg2) noexcept;. void bar(int arg1, double arg2); noexcept(noexcept(baz(arg1)) &&; noexcept(baz(arg2)));. .. _AllowShortBlocksOnASingleLine:. **AllowShortBlocksOnASingleLine** (``ShortBlockStyle``) :versionbadge:`clang-format 3.5` :ref:`¶ <AllowShortBlocksOnASingleLine>`; Dependent on the value, ``while (true) { continue; }`` can be put on a; single line. Possible values:. * ``SBS_Never`` (in configuration: ``Never``); Never merge blocks into a single line. .. code-block:: c++. while (true) {; }; while (true) {; continue;; }. * ``SBS_Empty`` (in configuration: ``Empty``); Only merge empty blocks. .. code-block:: c++. while (true) {}; while (true) {; continue;; }. * ``SBS_Always`` (in configuration: ``Always``); Always merge short blocks into a single line. .. code-block:: c++. whil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:26421,configurat,configuration,26421,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"::Add` globbing; It is now possible to add files from multiple subdirectories with `TChain::Add` globbing. For example,; ```; TChain::Add(""/path/to/tree/*/*.root""); ```; grabs all the root files with the path `/path/to/tree/somedir/file.root` (but not `/path/to/tree/file.root` and `/path/to/tree/somedir/anotherdir/file.root`). Another example:; ```; TChain::Add(""/path/to/tree/subdir[0-9]/*.root""); ```; This grabs all the root files in subdirectories that have a name starting with `subdir` and ending with some digit. ### Improved efficiency of TTree friends with indices. `TTreeIndex` and `TChainIndex` classes now implement the `Clone` method such that it does not use the ROOT I/O to clone the; index but just does a copy in memory. Notably, this improves processing efficiency for RDataFrame in multithreaded; execution since the same index must be copied over to all the threads and attached to the current tree for proper; event matching. ## RNTuple; ROOT's experimental successor of TTree has seen a number of updates since the last release. Specifically, 6.32 includes the following changes:. - A major refactoring of the interface, improving consistency across different parts and improving overall robustness. **Note that this is a breaking change with regard to 6.30!**; - The on-disk format has been updated to release candidate 2. **It will not be possible to read RNTuples written in the previous format anymore.**; - Support has been added for several new field types: `std::unordered_set<T>`, `std::map<K,V>`, `std::unordered_map<K,V>`; - Support has been added for on-disk half-precision (IEEE 754-2008 16-bit) float fields. This can be enabled through `RField<float>::SetHalfPrecision()`. On reading, values of such fields are represented as regular, 32-bit floats.; - A new `RNTupleInspector` utility class has been added, to provide information about the on-disk metadata of an RNTuple.; - A new `RNTupleParallelWriter` class has been added, providing (initial) support for pa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:4352,update,updates,4352,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,2,"['release', 'update']","['release', 'updates']"
Deployability,"::Math::Integrator ig2(ROOT::Math::IntegrationOneDim::kNONADAPTIVE);; ig2.SetFunction(wf);; val = ig2.Integral(0,1);; std::cout << ""integral result is "" << val << std::endl;; status += std::fabs(val-RESULT) > ERRORLIMIT;. ROOT::Math::Integrator ig3(wf, ROOT::Math::IntegrationOneDim::kADAPTIVE);; val = ig3.Integral(0,1);; std::cout << ""integral result is "" << val << std::endl;; status += std::fabs(val-RESULT) > ERRORLIMIT;. ROOT::Math::Integrator ig4(ROOT::Math::IntegrationOneDim::kGAUSS);; ig4.SetFunction(wf);; val = ig4.Integral(0,1);; std::cout << ""integral result is "" << val << std::endl;; status += std::fabs(val-RESULT) > ERRORLIMIT;. ROOT::Math::Integrator ig4(ROOT::Math::IntegrationOneDim::kLEGENDRE);; ig4.SetFunction(wf);; val = ig4.Integral(0,1);; std::cout << ""integral result is "" << val << std::endl;; status += std::fabs(val-RESULT) > ERRORLIMIT;. return status;; }; ```. ### One-dimensional Integration Algorithms. Here we provide a brief description of the different integration algorithms, which are also; implemented as separate classes. The algorithms can be instantiated using the following enumeration values:. | **Enumeration name**| **Integrator class** |; |------------------------------------ |-------------------------------|; | `ROOT::Math::IntegratorOneDim::kGAUSS` | `ROOT::Math::GaussianIntegrator` |; | `ROOT::Math::IntegratorOneDim::kLEGENDRE` | `ROOT::Math:::GausLegendreIntegrator` |; | `ROOT::Math::Integration::kNONADAPTIVE` | `ROOT::Math:::GSLIntegrator` |; | `ROOT::Math::Integration::kADAPTIVE` | `ROOT::Math:::GSLIntegrator` |; | `ROOT::Math::Integration::kADAPTIVESINGULAR` | `ROOT::Math:::GSLIntegrator` |. #### ROOT::Math:::GaussIntegrator. It uses the most basic Gaussian integration algorithm, it uses the 8-point and the 16-point Gaussian; quadrature approximations. It is derived from the `DGAUSS` routine of the *CERNLIB* by S. Kolbig.; This class; Here is an example of using directly the `GaussIntegrator` class. ```{.cpp}; #include ""TF1.h""; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:52709,integrat,integration,52709,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['integrat'],['integration']
Deployability,":Draw()`; - `var1 = majorname`; - `var2 = minorname`; - `sel = ` $2^{31} \times majorname + minorname$; - for each entry in the tree the sel expression is evaluated and the; results array is sorted into `fIndexValues`. Once the index is computed, using the; `TTree::GetEntryWithIndex(majornumber, minornumber)` one entry can be; retrieved. Example:. ``` {.cpp}; // to create an index using leaves Run and Event; tree.BuildIndex(""Run"",""Event"");; // to read entry corresponding to Run=1234 and Event=56789; tree.GetEntryWithIndex(1234,56789);; ```. Note that `majorname` and `minorname` may be expressions using original; tree variables e.g.: ""`run-90000`"", ""`event +3*xx`"". In case an; expression is specified, the equivalent expression must be computed when; calling `GetEntryWithIndex()`. To build an index with only `majorname`,; specify `minorname=""0""` (default). Note that once the index is built, it can be saved with the **`TTree`**; object with:. ``` {.cpp}; tree.Write(); //if the file has been open in ""update"" mode; ```. The most convenient place to create the index is at the end of the; filling process just before saving the tree header. If a previous index; was computed, it is redefined by this new call. Note that this function can also be applied to a **`TChain`**. The; return value is the number of entries in the Index (\< 0 indicates; failure). ## Branches. The organization of branches allows the designer to optimize the data; for the anticipated use. The class for a branch is called **`TBranch`**.; If two variables are independent, and the designer knows the variables; will not be used together, they should be placed on separate branches.; If, however, the variables are related, such as the coordinates of a; point, it is most efficient to create one branch with both coordinates; on it. A variable on a **`TBranch`** is called a leaf (yes -; **`TLeaf`**). Another point to keep in mind when designing trees is that; branches of the same **`TTree`** can be written to sepa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:17641,update,update,17641,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['update'],['update']
Deployability,":Math:::GSLIntegrator` |. #### ROOT::Math:::GaussIntegrator. It uses the most basic Gaussian integration algorithm, it uses the 8-point and the 16-point Gaussian; quadrature approximations. It is derived from the `DGAUSS` routine of the *CERNLIB* by S. Kolbig.; This class; Here is an example of using directly the `GaussIntegrator` class. ```{.cpp}; #include ""TF1.h""; #include ""Math/WrappedTF1.h""; #include ""Math/GaussIntegrator.h"". int main(); {; TF1 f(""Sin Function"", ""sin(x)"", 0, TMath::Pi());; ROOT::Math::WrappedTF1 wf1(f);. ROOT::Math::GaussIntegrator ig;. ig.SetFunction(wf1, false);; ig.SetRelTolerance(0.001);. cout << ig.Integral(0, TMath::PiOver2()) << endl;. return 0;; }; ```; #### ROOT::Math::GaussLegendreIntegrator. This class implementes the Gauss-Legendre quadrature formulas. This sort of numerical methods requieres that the user specifies the number of intermediate function points; used in the calculation of the integral. It will automatically determine the coordinates and weights of such points before performing the integration.; We can use the example above, but replacing the creation of a `ROOT::Math::GaussIntegrator` object with `ROOT::Math::GaussLegendreIntegrator`. #### ROOT::Math::GSLIntegrator. This is a wrapper for the *QUADPACK* integrator implemented in the GSL library. It supports several integration methods that can be chosen in construction time.; The default type is adaptive integration with singularity applying a Gauss-Kronrod 21-point integration rule. For a detail description of the GSL methods visit the GSL user guide; This class implements the best algorithms for numerical integration for one dimensional functions. We encourage the use it as the main option, bearing in mind that it uses code from the; GSL library, wich is provided in the *MathMore* library of ROOT. The interface to use is the same as above. We have now the possibility to specify a different integration algorithm in the constructor of the `ROOT::Math::GSLIntegrator` clas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:54392,integrat,integration,54392,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['integrat'],['integration']
Deployability,":`commit message <commit messages>`.; * Add reviewers (see below for advice). (If you set the Repository field; correctly, llvm-commits or cfe-commits will be subscribed automatically;; otherwise, you will have to manually subscribe them.); * In the Repository field, enter ""rG LLVM Github Monorepo"".; * Click *Save*. To submit an updated patch:. * Click *Differential*.; * Click *+ Create Diff*.; * Paste the updated diff or browse to the updated patch file. Click *Create Diff*.; * Select the review you want to from the *Attach To* dropdown and click; *Continue*.; * Leave the Repository field blank. (We previously filled out the Repository; for the review request.); * Add comments about the changes in the new diff. Click *Save*. Choosing reviewers: You typically pick one or two people as initial reviewers.; This choice is not crucial, because you are merely suggesting and not requiring; them to participate. Many people will see the email notification on cfe-commits; or llvm-commits, and if the subject line suggests the patch is something they; should look at, they will. .. _creating-a-patch-series:. Creating a patch series; -----------------------. Chaining reviews together requires some manual work. There are two ways to do it; (these are also described `here <https://moz-conduit.readthedocs.io/en/latest/arcanist-user.html#series-of-commits>`_; along with some screenshots of what to expect). .. _using-the-web-interface:. Using the web interface; ^^^^^^^^^^^^^^^^^^^^^^^. This assumes that you've already created a Phabricator review for each commit,; using `arc` or the web interface. * Go to what will be the last review in the series (the most recent).; * Click ""Edit Related Revisions"" then ""Edit Parent Revisions"".; * This will open a dialog where you will enter the patch number of the parent patch; (or patches). The patch number is of the form D<number> and you can find it by; looking at the URL for the review e.g. reviews.llvm/org/D12345.; * Click ""Save Parent Revisio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst:5054,patch,patch,5054,interpreter/llvm-project/llvm/docs/Phabricator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst,1,['patch'],['patch']
Deployability,":arc-term:`bridged cast` is a C-style cast annotated with one of three; keywords:. * ``(__bridge T) op`` casts the operand to the destination type ``T``. If; ``T`` is a retainable object pointer type, then ``op`` must have a; non-retainable pointer type. If ``T`` is a non-retainable pointer type,; then ``op`` must have a retainable object pointer type. Otherwise the cast; is ill-formed. There is no transfer of ownership, and ARC inserts no retain; operations.; * ``(__bridge_retained T) op`` casts the operand, which must have retainable; object pointer type, to the destination type, which must be a non-retainable; pointer type. ARC retains the value, subject to the usual optimizations on; local values, and the recipient is responsible for balancing that +1.; * ``(__bridge_transfer T) op`` casts the operand, which must have; non-retainable pointer type, to the destination type, which must be a; retainable object pointer type. ARC will release the value at the end of; the enclosing full-expression, subject to the usual optimizations on local; values. These casts are required in order to transfer objects in and out of ARC; control; see the rationale in the section on :ref:`conversion of retainable; object pointers <arc.objects.restrictions.conversion>`. Using a ``__bridge_retained`` or ``__bridge_transfer`` cast purely to convince; ARC to emit an unbalanced retain or release, respectively, is poor form. .. _arc.objects.restrictions:. Restrictions; ------------. .. _arc.objects.restrictions.conversion:. Conversion of retainable object pointers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In general, a program which attempts to implicitly or explicitly convert a; value of retainable object pointer type to any non-retainable type, or; vice-versa, is ill-formed. For example, an Objective-C object pointer shall; not be converted to ``void*``. As an exception, cast to ``intptr_t`` is; allowed because such casts are not transferring ownership. The :ref:`bridged; casts <arc.objec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:23768,release,release,23768,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['release']
Deployability,":local:. Release Administrative Tasks; ----------------------------. This section describes a few administrative tasks that need to be done for the; release process to begin. Specifically, it involves:. * Updating version numbers,. * Creating the release branch, and. * Tagging release candidates for the release team to begin testing. Create Release Branch; ^^^^^^^^^^^^^^^^^^^^^. Branch the Git trunk using the following procedure:. #. Remind developers that the release branching is imminent and to refrain from; committing patches that might break the build. E.g., new features, large; patches for works in progress, an overhaul of the type system, an exciting; new TableGen feature, etc. #. Verify that the current git trunk is in decent shape by; examining nightly tester and buildbot results. #. Bump the version in trunk to N.0.0git and tag the commit with llvmorg-N-init.; If ``X`` is the version to be released, then ``N`` is ``X + 1``. ::. $ git tag -sa llvmorg-N-init. #. Clear the release notes in trunk. #. Create the release branch from the last known good revision from before the; version bump. The branch's name is release/X.x where ``X`` is the major version; number and ``x`` is just the letter ``x``. #. On the newly-created release branch, immediately bump the version; to X.1.0git (where ``X`` is the major version of the branch.). #. All tags and branches need to be created in both the llvm/llvm-project and; llvm/llvm-test-suite repos. Update LLVM Version; ^^^^^^^^^^^^^^^^^^^. After creating the LLVM release branch, update the release branches'; version with the script in ``llvm/utils/release/bump-version.py``. Tagging the LLVM Release Candidates; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Tag release candidates:. ::. $ git tag -sa llvmorg-X.Y.Z-rcN. The Release Manager must supply pre-packaged source tarballs for users. This can; be done with the export.sh script in utils/release. Tarballs, release binaries, or any other release artifacts must be uploaded to; GitHub. T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:4124,release,release,4124,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['release'],['release']
Deployability,":ref:`ELF Header; <amdgpu-elf-header>`). See DWARF Version 5 section 6.2.2. .. TODO::. Should the ``isa`` state machine register be used to indicate if the code is; in wavefront32 or wavefront64 mode? Or used to specify the architecture ISA?. For AMDGPU the line number program header fields have the following values (see; DWARF Version 5 section 6.2.4):. ``address_size`` (ubyte); Matches the address size for the ``Global`` address space defined in; :ref:`amdgpu-dwarf-address-space-identifier`. ``segment_selector_size`` (ubyte); AMDGPU does not use a segment selector so this is 0. ``minimum_instruction_length`` (ubyte); For GFX9-GFX11 this is 4. ``maximum_operations_per_instruction`` (ubyte); For GFX9-GFX11 this is 1. Source text for online-compiled programs (for example, those compiled by the; OpenCL language runtime) may be embedded into the DWARF Version 5 line table.; See DWARF Version 5 section 6.2.4.1 which is updated by *DWARF Extensions For; Heterogeneous Debugging* section :ref:`DW_LNCT_LLVM_source; <amdgpu-dwarf-line-number-information-dw-lnct-llvm-source>`. The Clang option used to control source embedding in AMDGPU is defined in; :ref:`amdgpu-clang-debug-options-table`. .. table:: AMDGPU Clang Debug Options; :name: amdgpu-clang-debug-options-table. ==================== ==================================================; Debug Flag Description; ==================== ==================================================; -g[no-]embed-source Enable/disable embedding source text in DWARF; debug sections. Useful for environments where; source cannot be written to disk, such as; when performing online compilation.; ==================== ==================================================. For example:. ``-gembed-source``; Enable the embedded source. ``-gno-embed-source``; Disable the embedded source. 32-Bit and 64-Bit DWARF Formats; -------------------------------. See DWARF Version 5 section 7.4 and; :ref:`amdgpu-dwarf-32-bit-and-64-bit-dwarf-formats`. For AMDGPU:. *",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:115177,update,updated,115177,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['update'],['updated']
Deployability,":ref:`amdgpu-dwarf-call-frame-information`. *Although the value of the* ``DW_AT_frame_base`` *attribute of the debugger; information entry corresponding to the current subprogram can be computed; using a location list expression, in some cases this would require an; extensive location list because the values of the registers used in; computing the CFA change during a subprogram execution. If the call frame; information is present, then it already encodes such changes, and it is; space efficient to reference that using the* ``DW_OP_call_frame_cfa``; *operation.*. 6. ``DW_OP_fbreg``. ``DW_OP_fbreg`` has a single signed LEB128 integer operand that represents a; byte displacement B. The location description L for the *frame base* of the current subprogram is; obtained from the ``DW_AT_frame_base`` attribute of the debugger information; entry corresponding to the current subprogram as described in; :ref:`amdgpu-dwarf-low-level-information`. The location description L is updated as if the ``DW_OP_LLVM_offset_uconst; B`` operation was applied. The updated L is pushed on the stack. 7. ``DW_OP_breg0``, ``DW_OP_breg1``, ..., ``DW_OP_breg31``. The ``DW_OP_breg<N>`` operations encode the numbers of up to 32 registers,; numbered from 0 through 31, inclusive. The register number R corresponds to; the N in the operation name. They have a single signed LEB128 integer operand that represents a byte; displacement B. The address space identifier AS is defined as the one corresponding to the; target architecture specific default address space. The address size S is defined as the address bit size of the target; architecture specific address space corresponding to AS. The contents of the register specified by R are retrieved as if a; ``DW_OP_regval_type R, DR`` operation was performed where DR is the offset; of a hypothetical debug information entry in the current compilation unit; for an unsigned integral base type of size S bits. B is added and the least; significant S bits are treated",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:115122,update,updated,115122,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['update'],['updated']
Deployability,":ref:`¶ <SpaceBeforeJsonColon>`; If ``true``, a space will be added before a JSON colon. For other; languages, e.g. JavaScript, use ``SpacesInContainerLiterals`` instead. .. code-block:: c++. true: false:; { {; ""key"" : ""value"" vs. ""key"": ""value""; } }. .. _SpaceBeforeParens:. **SpaceBeforeParens** (``SpaceBeforeParensStyle``) :versionbadge:`clang-format 3.5` :ref:`¶ <SpaceBeforeParens>`; Defines in which cases to put a space before opening parentheses. Possible values:. * ``SBPO_Never`` (in configuration: ``Never``); This is **deprecated** and replaced by ``Custom`` below, with all; ``SpaceBeforeParensOptions`` but ``AfterPlacementOperator`` set to; ``false``. * ``SBPO_ControlStatements`` (in configuration: ``ControlStatements``); Put a space before opening parentheses only after control statement; keywords (``for/if/while...``). .. code-block:: c++. void f() {; if (true) {; f();; }; }. * ``SBPO_ControlStatementsExceptControlMacros`` (in configuration: ``ControlStatementsExceptControlMacros``); Same as ``SBPO_ControlStatements`` except this option doesn't apply to; ForEach and If macros. This is useful in projects where ForEach/If; macros are treated as function calls instead of control statements.; ``SBPO_ControlStatementsExceptForEachMacros`` remains an alias for; backward compatibility. .. code-block:: c++. void f() {; Q_FOREACH(...) {; f();; }; }. * ``SBPO_NonEmptyParentheses`` (in configuration: ``NonEmptyParentheses``); Put a space before opening parentheses only if the parentheses are not; empty i.e. '()'. .. code-block:: c++. void() {; if (true) {; f();; g (x, y, z);; }; }. * ``SBPO_Always`` (in configuration: ``Always``); Always put a space before opening parentheses, except when it's; prohibited by the syntax rules (in function-like macro definitions) or; when determined by other style rules (after unary operators, opening; parentheses, etc.). .. code-block:: c++. void f () {; if (true) {; f ();; }; }. * ``SBPO_Custom`` (in configuration: ``Custom``); Config",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:117007,configurat,configuration,117007,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"; ## Platform Support. Temporarily for version 6.00/00, ROOT has a reduced set of supported; platforms. Most notably Windows is not supported until at least 6.02.; 6.00/00 supports only. - Linux 32 bit and 64 bit, i32 and x86-64 and x32 (see below).; - OSX 64 bit on x86-64. More platforms are expected to be available later; the lack of support; stems from Cling and Clang/LLVM not being ported to these platforms yet. To aleviate the pain for Windows users who want to try ROOT 6 we provide; a recipe on how to run ROOT 6 in a VM on Windows. Building ROOT also requires a C++11 compatible compiler, so one needs to either have installed gcc >= 4.8 or Clang >= 3.4. On most lecagy platforms these newer compilers are available via a special install.; See the [build prerequisites](https://root.cern/install/dependencies/) page. Despite that, an additional platform as been added: the [x32; psAPI](https://sites.google.com/site/x32abi/), called linuxx32gcc. It is; a regular x86-64 ABI but with shorter pointers (4 bytes instead of 8).; This reduces the addressable memory per process to 4GB - but that is; usally sufficient. The advantages are reduced memory consumption (due to; the smaller pointers) and increased performance compared to 32 bit; applications due to the availability of the 64 bit instructions. The; Clang developers mailing list archive [contains a good; comparison](http://clang-developers.42468.n3.nabble.com/Re-PATCH-add-x32-psABI-support-td4024297.html). To build and run binaries compiled in x32, toolchain support is needed.; That is available in the in binutils (2.22), GCC (4.8), glibc (2.16),; Linux kernel (3.4) and even GDB (7.5). These versions are not available; in regular distributions yet (except for [this beta Gentoo; distro](http://dev.gentoo.org/~vapier/x32/stage3-amd64-x32-20120605.tar.xz); built in x32); once they are, building and running x86-64 and x32; side-by-side will be possible. ## Build System; ROOT 6.00/00 can be built either using the classic "".",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md:629,install,installed,629,core/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md,3,['install'],"['install', 'installed']"
Deployability,"; #endif. .. _PackConstructorInitializers:. **PackConstructorInitializers** (``PackConstructorInitializersStyle``) :versionbadge:`clang-format 14` :ref:`¶ <PackConstructorInitializers>`; The pack constructor initializers style to use. Possible values:. * ``PCIS_Never`` (in configuration: ``Never``); Always put each constructor initializer on its own line. .. code-block:: c++. Constructor(); : a(),; b(). * ``PCIS_BinPack`` (in configuration: ``BinPack``); Bin-pack constructor initializers. .. code-block:: c++. Constructor(); : aaaaaaaaaaaaaaaaaaaa(), bbbbbbbbbbbbbbbbbbbb(),; cccccccccccccccccccc(). * ``PCIS_CurrentLine`` (in configuration: ``CurrentLine``); Put all constructor initializers on the current line if they fit.; Otherwise, put each one on its own line. .. code-block:: c++. Constructor() : a(), b(). Constructor(); : aaaaaaaaaaaaaaaaaaaa(),; bbbbbbbbbbbbbbbbbbbb(),; ddddddddddddd(). * ``PCIS_NextLine`` (in configuration: ``NextLine``); Same as ``PCIS_CurrentLine`` except that if all constructor initializers; do not fit on the current line, try to fit them on the next line. .. code-block:: c++. Constructor() : a(), b(). Constructor(); : aaaaaaaaaaaaaaaaaaaa(), bbbbbbbbbbbbbbbbbbbb(), ddddddddddddd(). Constructor(); : aaaaaaaaaaaaaaaaaaaa(),; bbbbbbbbbbbbbbbbbbbb(),; cccccccccccccccccccc(). * ``PCIS_NextLineOnly`` (in configuration: ``NextLineOnly``); Put all constructor initializers on the next line if they fit.; Otherwise, put each one on its own line. .. code-block:: c++. Constructor(); : a(), b(). Constructor(); : aaaaaaaaaaaaaaaaaaaa(), bbbbbbbbbbbbbbbbbbbb(), ddddddddddddd(). Constructor(); : aaaaaaaaaaaaaaaaaaaa(),; bbbbbbbbbbbbbbbbbbbb(),; cccccccccccccccccccc(). .. _PenaltyBreakAssignment:. **PenaltyBreakAssignment** (``Unsigned``) :versionbadge:`clang-format 5` :ref:`¶ <PenaltyBreakAssignment>`; The penalty for breaking around an assignment operator. .. _PenaltyBreakBeforeFirstCallParameter:. **PenaltyBreakBeforeFirstCallParameter** (``Unsigned``) :v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:92856,configurat,configuration,92856,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"; %d = call float @fabsf(float %x); ret float %d; }. //===---------------------------------------------------------------------===//. This IR (from PR6194):. target datalayout = ""e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-v64:64:64-v128:128:128-a0:0:64-s0:64:64-f80:128:128-n8:16:32:64-S128""; target triple = ""x86_64-apple-darwin10.0.0"". %0 = type { double, double }; %struct.float3 = type { float, float, float }. define void @test(%0, %struct.float3* nocapture %res) nounwind noinline ssp {; entry:; %tmp18 = extractvalue %0 %0, 0 ; <double> [#uses=1]; %tmp19 = bitcast double %tmp18 to i64 ; <i64> [#uses=1]; %tmp20 = zext i64 %tmp19 to i128 ; <i128> [#uses=1]; %tmp10 = lshr i128 %tmp20, 32 ; <i128> [#uses=1]; %tmp11 = trunc i128 %tmp10 to i32 ; <i32> [#uses=1]; %tmp12 = bitcast i32 %tmp11 to float ; <float> [#uses=1]; %tmp5 = getelementptr inbounds %struct.float3* %res, i64 0, i32 1 ; <float*> [#uses=1]; store float %tmp12, float* %tmp5; ret void; }. Compiles to:. _test: ## @test; 	movd	%xmm0, %rax; 	shrq	$32, %rax; 	movl	%eax, 4(%rdi); 	ret. This would be better kept in the SSE unit by treating XMM0 as a 4xfloat and; doing a shuffle from v[1] to v[0] then a float store. //===---------------------------------------------------------------------===//. [UNSAFE FP]. void foo(double, double, double);; void norm(double x, double y, double z) {; double scale = __builtin_sqrt(x*x + y*y + z*z);; foo(x/scale, y/scale, z/scale);; }. We currently generate an sqrtsd and 3 divsd instructions. This is bad, fp div is; slow and not pipelined. In -ffast-math mode we could compute ""1.0/scale"" first; and emit 3 mulsd in place of the divs. This can be done as a target-independent; transform. If we're dealing with floats instead of doubles we could even replace the sqrtss; and inversion with an rsqrtss instruction, which computes 1/sqrt faster at the; cost of reduced accuracy. //===---------------------------------------------------------------------===//; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:22263,pipeline,pipelined,22263,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,1,['pipeline'],['pipelined']
Deployability,"; - ""CPN"" for TCanvas to create color palette from N last colors; - ""line"" for TGraph2D; 3. New features:; - support LZ4 compression; - tooltips and zooming in TGraphPolar drawings; - TPavesText with multiple underlying paves; - implement all fill styles; - draw borders for TWbox; - draw all objects from TList/TObjArray as they appear in list of primitives; - let enable/disable highlight of extra objects in geometry viewer; - draw axis labels on both sides when pad.fTick[x/y] > 1; - make drawing of TCanvas with many primitives smoother; - add fOptTitle, fOptLogx/y/z fields in JSROOT.gStyle; 4. Behavior changes:; - disable automatic frame adjustment, can be enabled with ""&adjframe"" parameter in URL; - when drawing TH2/TH3 scatter plots, always generate same ""random"" pattern; - use barwidth/baroffset parameters in lego plots; 5. Bug fixes:; - use same number of points to draw lines and markers on the TGraph; - correctly draw filled TArrow endings; - let combine ""L"" or ""C"" TGraph draw option with others; - correct positioning of custom axis labels; - correctly toggle lin/log axes in lego plot; - let correctly change marker attributes interactively. ## Changes in 5.3.5; 1. Fix - correctly show histogram with negative bins and fill attributes (#143); 2. Fix - correct animation for status line (when visible); 3. Fix - correctly set lin/log settings back top TPad object; 4. Fix - correctly use preloaded d3.js in notebooks/require.js environment; 5. Cached Latex regex to improve drawing speed (#145). ## Changes in 5.3.4; 1. Fix - several problem in TLatex preprocessing for MathJax.js; 2. Fix - use ""E"" draw options for THStack only when no any other specified. ## Changes in 5.3.3; 1. Use latest jsdom and mathjax-node packages (Node.js only). ## Changes in 5.3.2; 1. Fix - use FontSize when draw TLegend entries; 2. Fix - correctly show TH2 overflow stats; 3. Fix - tooltips handling for TH1 hbar drawings; 4. Implement JSROOT.toJSON() function to produce ROOT JSON string. ## Chan",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:36916,toggle,toggle,36916,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['toggle'],['toggle']
Deployability,"; - [cmake](https://cmake.org/download/). To compile with cmake added into ~/.profile. ~~~{.sh}; export PATH=$PATH:/Applications/CMake.app/Contents/bin/; ~~~; and. ~~~{.sh}; source ~/.profile; ~~~. Install needed R packages, open R and in the prompt type. ~~~{.sh}; install.packages(c('Rcpp','RInside')); ~~~; select a mirror and install. Install the next additional packages for R TMVA interface. ~~~{.sh}; install.packages(c('C50','RSNNS','e1071','xgboost')); ~~~. Download code from git repo. ~~~{.sh}; git clone http://root.cern.ch/git/root.git; ~~~. To compile ROOTR lets to create a compilation directory and to activate it use cmake -Dr=ON .. ~~~{.sh}; mkdir compile; cd compile; cmake -Dr=ON ..; make -j 5; ~~~. ### Compiling ROOTR on Gnu/Linux with CMake:; **NOTE:** Tested on Gnu/Linux Debian Jessie with gcc 4.9. **Prerequisities**; install; (For debian-based distros). ~~~{.sh}; apt-get install r-base r-base-dev; ~~~; Install needed R packages, open R and in the prompt type. ~~~{.sh}; install.packages(c('Rcpp','RInside')); ~~~; select a mirror and install. Install the next additional packages for R TMVA interface. ~~~{.sh}; install.packages(c('C50','RSNNS','e1071','xgboost')); ~~~. Download code from git repo. ~~~{.sh}; git clone http://root.cern.ch/git/root.git; ~~~. To compile ROOTR lets to create a compilation directory and to activate it use cmake -Dr=ON .. ~~~{.sh}; mkdir compile; cd compile; cmake -Dr=ON ..; make -j 5; ~~~. ## How does it work ?; There is a class called TRInterface which is located at the header TRInterface.h and uses the namespace `ROOT::R`, it is in charge; of making calls to R to give and obtain data. This class has a series of overcharged operators which ease the passing and obtaining of data; and code from R to C++ and vice versa. To create an object of this class the user must use the static methods `ROOT::R::TRInterface::Instance`; and `ROOT::R::TRInterface::InstancePtr` which return a reference object and a pointer object respectively. ~",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:2630,install,install,2630,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['install'],['install']
Deployability,"; ----------------------. As a community, we strongly value having the tip of tree in a good state while; allowing rapid iterative development. As such, we tend to make much heavier; use of reverts to keep the tree healthy than some other open source projects,; and our norms are a bit different. How should you respond if someone reverted your change?. * Remember, it is normal and healthy to have patches reverted. Having a patch; reverted does not necessarily mean you did anything wrong.; * We encourage explicitly thanking the person who reverted the patch for doing; the task on your behalf.; * If you need more information to address the problem, please follow up in the; original commit thread with the reverting patch author. When should you revert your own change?. * Any time you learn of a serious problem with a change, you should revert it.; We strongly encourage ""revert to green"" as opposed to ""fixing forward"". We; encourage reverting first, investigating offline, and then reapplying the; fixed patch - possibly after another round of review if warranted.; * If you break a buildbot in a way which can't be quickly fixed, please revert.; * If a test case that demonstrates a problem is reported in the commit thread,; please revert and investigate offline.; * If you receive substantial :ref:`post-commit review <post_commit_review>`; feedback, please revert and address said feedback before recommitting.; (Possibly after another round of review.); * If you are asked to revert by another contributor, please revert and discuss; the merits of the request offline (unless doing so would further destabilize; tip of tree). When should you revert someone else's change?. * In general, if the author themselves would revert the change per these; guidelines, we encourage other contributors to do so as a courtesy to the; author. This is one of the major cases where our norms differ from others;; we generally consider reverting a normal part of development. We don't; expect contribut",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:19502,patch,patch,19502,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['patch'],['patch']
Deployability,"; --sandbox sandbox \; --test-suite ~/devel/llvm/test/test-suite \; --cc ~/devel/llvm/install/bin/clang \; --cxx ~/devel/llvm/install/bin/clang++. It should have no new regressions, compared to the previous release or release; candidate. You don't need to fix all the bugs in the test-suite, since they're; not necessarily meant to pass on all architectures all the time. This is; due to the nature of the result checking, which relies on direct comparison,; and most of the time, the failures are related to bad output checking, rather; than bad code generation. If the errors are in LLVM itself, please report every single regression found; as blocker, and all the other bugs as important, but not necessarily blocking; the release to proceed. They can be set as ""known failures"" and to be; fix on a future date. .. _pre-release-process:. Pre-Release Process; ===================. .. contents::; :local:. When the release process is announced on the mailing list, you should prepare; for the testing, by applying the same testing you'll do on the release; candidates, on the previous release. You should:. * Download the previous release sources from; https://llvm.org/releases/download.html. * Run the test-release.sh script on ``final`` mode (change ``-rc 1`` to; ``-final``). * Once all three stages are done, it'll test the final stage. * Using the ``Phase3/Release+Asserts/llvmCore-MAJ.MIN-final.install`` base,; run the test-suite. If the final phase's ``make check-all`` failed, it's a good idea to also test; the intermediate stages by going on the obj directory and running; ``make check-all`` to find if there's at least one stage that passes (helps; when reducing the error for bug report purposes). .. _release-process:. Release Process; ===============. .. contents::; :local:. When the Release Manager sends you the release candidate, download all sources,; unzip on the same directory (there will be sym-links from the appropriate places; to them), and run the release test as above.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst:4846,release,release,4846,interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,3,['release'],['release']
Deployability,"; .. _tblgen-mirpats:. ========================; MIR Patterns in TableGen; ========================. .. contents::; :local:. User's Guide; ============. This section is intended for developers who want to use MIR patterns in their; TableGen files. ``NOTE``:; This feature is still in active development. This document may become outdated; over time. If you see something that's incorrect, please update it. Use Cases; ---------. MIR patterns are supported in the following places:. * GlobalISel ``GICombineRule``; * GlobalISel ``GICombinePatFrag``. Syntax; ------. MIR patterns use the DAG datatype in TableGen. .. code-block:: text. (inst operand0, operand1, ...). ``inst`` must be a def which inherits from ``Instruction`` (e.g. ``G_FADD``); or ``GICombinePatFrag``. Operands essentially fall into one of two categories:. * immediates. * untyped, unnamed: ``0``; * untyped, named: ``0:$y``; * typed, unnamed: ``(i32 0)``; * typed, named: ``(i32 0):$y``. * machine operands. * untyped: ``$x``; * typed: ``i32:$x``. Semantics:. * A typed operand always adds an operand type check to the matcher.; * There is a trivial type inference system to propagate types. * e.g. You only need to use ``i32:$x`` once in any pattern of a; ``GICombinePatFrag`` alternative or ``GICombineRule``, then all; other patterns in that rule/alternative can simply use ``$x``; (``i32:$x`` is redundant). * A named operand's behavior depends on whether the name has been seen before. * For match patterns, reusing an operand name checks that the operands; are identical (see example 2 below).; * For apply patterns, reusing an operand name simply copies that operand into; the new instruction (see example 2 below). Operands are ordered just like they would be in a MachineInstr: the defs (outs); come first, then the uses (ins). Patterns are generally grouped into another DAG datatype with a dummy operator; such as ``match``, ``apply`` or ``pattern``. Finally, any DAG datatype in TableGen can be named. This also holds for",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:396,update,update,396,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,1,['update'],['update']
Deployability,"; // the pad has changed; root[] pad1->Modified(); // recursively update all modified pads:; root[] c1->Update(); ```. A subsequent call to `TCanvas::Update()` scans the list of sub-pads; and repaints the pads declared modified. In compiled code or in a long macro, you may want to access an object; created during the paint process. To do so, you can force the painting; with a `TCanvas::Update()`. For example, a **`TGraph`** creates a; histogram (**`TH1`**) to paint itself. In this case the internal; histogram obtained with `TGraph::GetHistogram()` is created only after; the pad is painted. The pad is painted automatically after the script is; finished executing or if you force the painting with `TPad::Modified()`; followed by a `TCanvas::Update()`. Note that it is not necessary to call; `TPad::Modified()` after a call to `Draw()`. The ""bit-modified"" is set; automatically by `Draw()`. A note about the ""bit-modified"" in sub pads:; when you want to update a sub pad in your canvas, you need to call; `pad->Modified()` rather than `canvas->Modified()`, and follow it with a; `canvas->Update()`. If you use `canvas->Modified()`, followed by a call; to `canvas->Update()`, the sub pad has not been declared modified and it; will not be updated. Also note that a call to `pad->Update()` where pad; is a sub pad of canvas, calls `canvas->Update()` and recursively updates; all the pads on the canvas. ### Making a Pad Transparent. As we will see in the paragraph ""Fill Attributes"", a fill style (type of; hatching) may be set for a pad. ``` {.cpp}; root[] pad1->SetFillStyle(istyle); ```. This is done with the `SetFillStyle` method where `istyle` is a style; number, defined in ""Fill Attributes"". A special set of styles allows; handling of various levels of transparency. These are styles number 4000; to 4100, 4000 being fully transparent and 4100 fully opaque. So, suppose; you have an existing canvas with several pads. You create a new pad; (transparent) covering for example the entire c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:27697,update,update,27697,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['update'],['update']
Deployability,"; /Zp<value> Specify the default maximum struct packing alignment; /Zs Run the preprocessor, parser and semantic analysis stages. OPTIONS:; -### Print (but do not run) the commands to run for this compilation; --analyze Run the static analyzer; -faddrsig Emit an address-significance table; -fansi-escape-codes Use ANSI escape codes for diagnostics; -fblocks Enable the 'blocks' language feature; -fcf-protection=<value> Instrument control-flow architecture protection. Options: return, branch, full, none.; -fcf-protection Enable cf-protection in 'full' mode; -fcolor-diagnostics Use colors in diagnostics; -fcomplete-member-pointers; Require member pointer base types to be complete if they would be significant under the Microsoft ABI; -fcoverage-mapping Generate coverage mapping to enable code coverage analysis; -fcrash-diagnostics-dir=<dir>; Put crash-report files in <dir>; -fdebug-macro Emit macro debug information; -fdelayed-template-parsing; Parse templated function definitions at the end of the translation unit; -fdiagnostics-absolute-paths; Print absolute paths in diagnostics; -fdiagnostics-parseable-fixits; Print fix-its in machine parseable form; -flto=<value> Set LTO mode to either 'full' or 'thin'; -flto Enable LTO in 'full' mode; -fmerge-all-constants Allow merging of constants; -fms-compatibility-version=<value>; Dot-separated value representing the Microsoft compiler version; number to report in _MSC_VER (0 = don't define it; default is same value as installed cl.exe, or 1933); -fms-compatibility Enable full Microsoft Visual C++ compatibility; -fms-extensions Accept some non-standard constructs supported by the Microsoft compiler; -fmsc-version=<value> Microsoft compiler version number to report in _MSC_VER; (0 = don't define it; default is same value as installed cl.exe, or 1933); -fno-addrsig Don't emit an address-significance table; -fno-builtin-<value> Disable implicit builtin knowledge of a specific function; -fno-builtin Disable implicit builtin knowledg",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:178973,install,installed,178973,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['install'],['installed']
Deployability,"; 1). der Path der im svn co example gegeben wir existiert nicht. es gibt KEIN. hvoss@hvlhcb01:~/TMVA$ svn list https://root.cern.ch/svn/root/branches/dev/tmvapatches; v5-26-00-patches/; hvoss@hvlhcb01:~/TMVA$ svn list https://root.cern.ch/svn/root/branches/dev/tmvapatches/v5-26-00-patches; tmva/; hvoss@hvlhcb01:~/TMVA$ svn list https://root.cern.ch/svn/root/branches/dev/tmvapatches/v5-26-00-patches/tmva; Makefile; Makefile.arch; Module.mk; doc/; inc/; src/; test/. das eine Versions nummer mit TMVA Version hat !! Es gibt nur ROOT Versionsnummern und; darunter ein tmva subdirectory. SCHADE eigentlich !!; --------------------; sollen/koennen wir das aendern? Wenn ja, wie ?. 2) Was mache ich mit der arXiv und CERN-Report Nummer im updated UsersGuide ?. 3) Kann irgendjemand der weis wie's implementiert ist, die ""NumEvent"" ""EqualNumEvents"" Geschichte und wie das gehandhabt wird (i.e. relative etc..) so formulieren dass man das versteht?. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/MyQuestions.txt:177,patch,patches,177,documentation/tmva/UsersGuide/MyQuestions.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/MyQuestions.txt,4,"['patch', 'update']","['patches', 'updated']"
Deployability,"; 2 integers are defined by *Util::Abi::PipelineMetadata(Major|Minor)Version*.; ""amdpal.pipelines"" sequence of Required Per-pipeline metadata. See; map :ref:`amdgpu-amdpal-code-object-pipeline-metadata-map-table` for the; definition of the keys included in that map.; =================== ============== ========= ======================================================================. .. .. table:: AMDPAL Code Object Pipeline Metadata Map; :name: amdgpu-amdpal-code-object-pipeline-metadata-map-table. ====================================== ============== ========= ===================================================; String Key Value Type Required? Description; ====================================== ============== ========= ===================================================; "".name"" string Source name of the pipeline.; "".type"" string Pipeline type, e.g. VsPs. Values include:. - ""VsPs""; - ""Gs""; - ""Cs""; - ""Ngg""; - ""Tess""; - ""GsTess""; - ""NggTess"". "".internal_pipeline_hash"" sequence of Required Internal compiler hash for this pipeline. Lower; 2 integers 64 bits is the ""stable"" portion of the hash, used; for e.g. shader replacement lookup. Upper 64 bits; is the ""unique"" portion of the hash, used for; e.g. pipeline cache lookup. The value is; implementation defined, and can not be relied on; between different builds of the compiler.; "".shaders"" map Per-API shader metadata. See; :ref:`amdgpu-amdpal-code-object-shader-map-table`; for the definition of the keys included in that; map.; "".hardware_stages"" map Per-hardware stage metadata. See; :ref:`amdgpu-amdpal-code-object-hardware-stage-map-table`; for the definition of the keys included in that; map.; "".shader_functions"" map Per-shader function metadata. See; :ref:`amdgpu-amdpal-code-object-shader-function-map-table`; for the definition of the keys included in that; map.; "".registers"" map Required Hardware register configuration. See; :ref:`amdgpu-amdpal-code-object-register-map-table`; for the definition of the keys included i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:403778,pipeline,pipeline,403778,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['pipeline'],['pipeline']
Deployability,"; 3. Remember that you were warned twice about reading the documentation. Test LLVM on the command line:; ------------------------------; The LLVM tests can be run by changing directory to the llvm source; directory and running:. .. code-block:: bat. c:\llvm> python ..\build\Release\bin\llvm-lit.py llvm\test. This example assumes that Python is in your PATH variable, which would be; after **Add Python to the PATH** was selected during Python installation.; If you had opened a command window prior to Python installation, you would; have to close and reopen it to get the updated PATH. A specific test or test directory can be run with:. .. code-block:: bat. c:\llvm> python ..\build\Release\bin\llvm-lit.py llvm\test\Transforms\Util. Build the LLVM Suite:; ---------------------; * The projects may still be built individually, but to build them all do; not just select all of them in batch build (as some are meant as; configuration projects), but rather select and build just the; ``ALL_BUILD`` project to build everything, or the ``INSTALL`` project,; which first builds the ``ALL_BUILD`` project, then installs the LLVM; headers, libs, and other useful things to the directory set by the; ``CMAKE_INSTALL_PREFIX`` setting when you first configured CMake.; * The Fibonacci project is a sample program that uses the JIT. Modify the; project's debugging properties to provide a numeric command line argument; or run it from the command line. The program will print the; corresponding fibonacci value. Links; =====; This document is just an **introduction** to how to use LLVM to do some simple; things... there are many more interesting and complicated things that you can; do that aren't documented here (but we'll gladly accept a patch if you want to; write something up!). For more information about LLVM, check out:. * `LLVM homepage <https://llvm.org/>`_; * `LLVM doxygen tree <https://llvm.org/doxygen/>`_; * Additional information about the LLVM directory structure and tool chain; can be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst:9732,configurat,configuration,9732,interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,2,"['configurat', 'install']","['configuration', 'installs']"
Deployability,"; :local:. When the release process is announced on the mailing list, you should prepare; for the testing, by applying the same testing you'll do on the release; candidates, on the previous release. You should:. * Download the previous release sources from; https://llvm.org/releases/download.html. * Run the test-release.sh script on ``final`` mode (change ``-rc 1`` to; ``-final``). * Once all three stages are done, it'll test the final stage. * Using the ``Phase3/Release+Asserts/llvmCore-MAJ.MIN-final.install`` base,; run the test-suite. If the final phase's ``make check-all`` failed, it's a good idea to also test; the intermediate stages by going on the obj directory and running; ``make check-all`` to find if there's at least one stage that passes (helps; when reducing the error for bug report purposes). .. _release-process:. Release Process; ===============. .. contents::; :local:. When the Release Manager sends you the release candidate, download all sources,; unzip on the same directory (there will be sym-links from the appropriate places; to them), and run the release test as above. You should:. * Download the current candidate sources from where the release manager points; you (ex. https://llvm.org/pre-releases/3.3/rc1/). * Repeat the steps above with ``-rc 1``, ``-rc 2`` etc modes and run the; test-suite the same way. * Compare the results, report all errors on Bugzilla and publish the binary blob; where the release manager can grab it. Once the release manages announces that the latest candidate is the good one,; you have to pack the ``Release`` (no Asserts) install directory on ``Phase3``; and that will be the official binary. * Rename (or link) ``clang+llvm-REL-ARCH-ENV`` to the .install directory. * Tar that into the same name with ``.tar.gz`` extension from outside the; directory. * Make it available for the release manager to download. .. _bug-reporting:. Bug Reporting Process; =====================. .. contents::; :local:. If you found regressions or f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst:5762,release,release,5762,interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,2,['release'],['release']
Deployability,"; ======================; Thread Safety Analysis; ======================. Introduction; ============. Clang Thread Safety Analysis is a C++ language extension which warns about; potential race conditions in code. The analysis is completely static (i.e.; compile-time); there is no run-time overhead. The analysis is still; under active development, but it is mature enough to be deployed in an; industrial setting. It is being developed by Google, in collaboration with; CERT/SEI, and is used extensively in Google's internal code base. Thread safety analysis works very much like a type system for multi-threaded; programs. In addition to declaring the *type* of data (e.g. ``int``, ``float``,; etc.), the programmer can (optionally) declare how access to that data is; controlled in a multi-threaded environment. For example, if ``foo`` is; *guarded by* the mutex ``mu``, then the analysis will issue a warning whenever; a piece of code reads or writes to ``foo`` without first locking ``mu``.; Similarly, if there are particular routines that should only be called by; the GUI thread, then the analysis will warn if other threads call those; routines. Getting Started; ----------------. .. code-block:: c++. #include ""mutex.h"". class BankAccount {; private:; Mutex mu;; int balance GUARDED_BY(mu);. void depositImpl(int amount) {; balance += amount; // WARNING! Cannot write balance without locking mu.; }. void withdrawImpl(int amount) REQUIRES(mu) {; balance -= amount; // OK. Caller must have locked mu.; }. public:; void withdraw(int amount) {; mu.Lock();; withdrawImpl(amount); // OK. We've locked mu.; } // WARNING! Failed to unlock mu. void transferFrom(BankAccount& b, int amount) {; mu.Lock();; b.withdrawImpl(amount); // WARNING! Calling withdrawImpl() requires locking b.mu.; depositImpl(amount); // OK. depositImpl() has no requirements.; mu.Unlock();; }; };. This example demonstrates the basic concepts behind the analysis. The; ``GUARDED_BY`` attribute declares that a thread must lo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:379,deploy,deployed,379,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['deploy'],['deployed']
Deployability,"; DW_OP_deref_type 64, %__uint_64;; DW_OP_LLVM_select_bit_piece 64, 64;; ];; ];; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc, DIExpression[; DW_OP_call_ref %__divergent_lane_pc_1_else;; DW_OP_call_ref %__active_lane_pc;; ];; f;; EXEC = %1;; $lex_1_end:; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_call_ref %__active_lane_pc;; ];; g;; $lex_end:. The DWARF procedure ``%__active_lane_pc`` is used to update the lane pc elements; that are active, with the current program location. Artificial variables %__lex_1_save_exec and %__lex_1_1_save_exec are created for; the execution masks saved on entry to a region. Using the ``DBG_VALUE`` pseudo; instruction, location list entries will be created that describe where the; artificial variables are allocated at any given program location. The compiler; may allocate them to registers or spill them to memory. The DWARF procedures for each region use the values of the saved execution mask; artificial variables to only update the lanes that are active on entry to the; region. All other lanes retain the value of the enclosing region where they were; last active. If they were not active on entry to the subprogram, then will have; the undefined location description. Other structured control flow regions can be handled similarly. For example,; loops would set the divergent program location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subpr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:108375,update,update,108375,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['update'],['update']
Deployability,; EXCLUDE_FROM_ALL; COMPONENT x86-resource-headers). if(NOT CLANG_ENABLE_HLSL); set(EXCLUDE_HLSL EXCLUDE_FROM_ALL); endif(). install(; FILES ${hlsl_h}; DESTINATION ${header_install_dir}; ${EXCLUDE_HLSL}; COMPONENT hlsl-resource-headers). install(; FILES ${hlsl_subdir_files}; DESTINATION ${header_install_dir}/hlsl; ${EXCLUDE_HLSL}; COMPONENT hlsl-resource-headers). install(; FILES ${opencl_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT opencl-resource-headers). install(; FILES ${openmp_wrapper_files}; DESTINATION ${header_install_dir}/openmp_wrappers; EXCLUDE_FROM_ALL; COMPONENT openmp-resource-headers). install(; FILES ${openmp_wrapper_files}; DESTINATION ${header_install_dir}/openmp_wrappers; EXCLUDE_FROM_ALL; COMPONENT openmp-resource-headers). install(; FILES ${utility_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT utility-resource-headers). install(; FILES ${windows_only_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT windows-resource-headers); #############################################################. if (NOT LLVM_ENABLE_IDE); add_llvm_install_targets(install-clang-resource-headers; DEPENDS clang-resource-headers; COMPONENT clang-resource-headers). add_llvm_install_targets(install-core-resource-headers; DEPENDS core-resource-headers; COMPONENT core-resource-headers); add_llvm_install_targets(install-arm-common-resource-headers; DEPENDS arm-common-resource-headers; COMPONENT arm-common-resource-headers); add_llvm_install_targets(install-arm-resource-headers; DEPENDS arm-resource-headers; COMPONENT arm-resource-headers); add_llvm_install_targets(install-aarch64-resource-headers; DEPENDS aarch64-resource-headers; COMPONENT aarch64-resource-headers); add_llvm_install_targets(install-cuda-resource-headers; DEPENDS cuda-resource-headers; COMPONENT cuda-resource-headers); add_llvm_install_targets(install-hexagon-resource-headers; DEPENDS hexagon-resource-headers; COMPONENT hexagon-resource-head,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt:16406,install,install,16406,interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,1,['install'],['install']
Deployability,"; Error.h; FitMethodFunction.h; Functor.h; GenAlgoOptions.h; IFunction.h; IFunctionfwd.h; IOptions.h; Minimizer.h; MinimizerOptions.h; Util.h; WrappedFunction.h; WrappedParamFunction.h; ). set(MATH_SOURCES; GenAlgoOptions.cxx; IOptions.cxx; Minimizer.cxx; MinimizerOptions.cxx; ParameterSettings.cxx; ). copy_standalone(SOURCE ../../../mathcore/inc/Fit DESTINATION ../../inc/Fit; OUTPUT FIT_HEADERS; FILES ${FIT_HEADERS}); copy_standalone(SOURCE ../../../mathcore/inc/Math DESTINATION ../../inc/Math; OUTPUT MATH_HEADERS; FILES ${MATH_HEADERS}); copy_standalone(SOURCE ../../../mathcore/src DESTINATION .; OUTPUT MATH_SOURCES; FILES ${MATH_SOURCES}). # Adding the headers helps IDEs show the correct headers on targets; add_library(Minuit2Math; ${MATH_SOURCES}; ${MATH_HEADERS}; ${FIT_HEADERS}; ). # Add alias for direct inclusion; add_library(Minuit2::Math ALIAS Minuit2Math). # Build and install directories are different, using CMake Generator expression; target_include_directories(; Minuit2Math; PUBLIC; $<BUILD_INTERFACE:${Minuit2_SOURCE_DIR}/inc>; $<INSTALL_INTERFACE:include/Minuit2>; ). # We need to add the ROOT mathcore directories if build inside of ROOT without standalone); if(minuit2_inroot AND NOT minuit2_standalone); target_include_directories(; Minuit2Math; PUBLIC; $<BUILD_INTERFACE:${Minuit2_SOURCE_DIR}/../mathcore/inc>; ); endif(). target_compile_definitions(; Minuit2Math; PRIVATE; MATH_NO_PLUGIN_MANAGER; ). target_compile_definitions(; Minuit2Math; PUBLIC; ROOT_Math_VecTypes; MATHCORE_STANDALONE; ). target_link_libraries(Minuit2Math PUBLIC Minuit2Common). target_compile_features(Minuit2Math PUBLIC cxx_auto_type cxx_static_assert); set_target_properties(Minuit2Math PROPERTIES CXX_EXTENSIONS OFF). install(TARGETS Minuit2Math; EXPORT Minuit2Targets; LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}; ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR}; ). install(FILES ${FIT_HEADERS} DESTINATION include/Minuit2/Fit); install(FILES ${MATH_HEADERS} DESTINATION include/Minuit2/Math); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/math/CMakeLists.txt:1979,install,install,1979,math/minuit2/src/math/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/math/CMakeLists.txt,3,['install'],['install']
Deployability,"; Generate build targets for the LLVM benchmarks. Defaults to ON. **LLVM_INCLUDE_EXAMPLES**:BOOL; Generate build targets for the LLVM examples. Defaults to ON. You can use this; option to disable the generation of build targets for the LLVM examples. **LLVM_INCLUDE_TESTS**:BOOL; Generate build targets for the LLVM unit tests. Defaults to ON. You can use; this option to disable the generation of build targets for the LLVM unit; tests. **LLVM_INCLUDE_TOOLS**:BOOL; Generate build targets for the LLVM tools. Defaults to ON. You can use this; option to disable the generation of build targets for the LLVM tools. **LLVM_INSTALL_BINUTILS_SYMLINKS**:BOOL; Install symlinks from the binutils tool names to the corresponding LLVM tools.; For example, ar will be symlinked to llvm-ar. **LLVM_INSTALL_CCTOOLS_SYMLINKS**:BOOL; Install symliks from the cctools tool names to the corresponding LLVM tools.; For example, lipo will be symlinked to llvm-lipo. **LLVM_INSTALL_OCAMLDOC_HTML_DIR**:STRING; The path to install OCamldoc-generated HTML documentation to. This path can; either be absolute or relative to the CMAKE_INSTALL_PREFIX. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/ocaml-html``. **LLVM_INSTALL_SPHINX_HTML_DIR**:STRING; The path to install Sphinx-generated HTML documentation to. This path can; either be absolute or relative to the CMAKE_INSTALL_PREFIX. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/html``. **LLVM_INSTALL_UTILS**:BOOL; If enabled, utility binaries like ``FileCheck`` and ``not`` will be installed; to CMAKE_INSTALL_PREFIX. **LLVM_INTEGRATED_CRT_ALLOC**:PATH; On Windows, allows embedding a different C runtime allocator into the LLVM; tools and libraries. Using a lock-free allocator such as the ones listed below; greatly decreases ThinLTO link time by about an order of magnitude. It also; midly improves Clang build times, by about 5-10%. At the moment, rpmalloc,; snmalloc and mimalloc are supported. Use the path to `git clone` to select; the respective allocator, for ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:28974,install,install,28974,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['install'],['install']
Deployability,"; In this case, the StreamerInfo for that class might not be used. In any case, if the; composition/decomposition of the class is explicitly coded, the user should include; the byte count, class information, and version number of the class before the data on; disk as shown in \ref dobject. The special method used for streaming a TClonesArray is described in the TClonesArray; section below. More information on the StreamerInfo record and its use is found in the; [Input/Output chapter of the Root Manual](https://root.cern/manual/storing_root_objects/). NOTE: Some of the classes used internally in ROOTIO (e.g. TObject, TRef, TRefArray); have explicitly coded (de)compositions, and do not use the information in the; StreamerInfo record to do the (de)composition. In this case, the StreamerInfo for; the class may still be present in the StreamerInfo record, but may not match what is; actually written to disk for those objects. \anchor ptpo; ## Pointers to persistent objects. These were introduced in release 3.02, so there is not yet a description in the current; Root Users Guide, which is for a version release 3.1. Here we discuss only the information; on disk. A ROOT file contains zero or more TProcessID records. Each such record contains a globally; unique ID defining a given ROOT job that wrote a referenced object (see \ref tprocessid).; Each referenced object contains a ""pidf"" field referencing the corresponding TProcessID; record and an ""fUniqueID"" field uniquely identifying the referenced object among those; written by that process (see \ref tobject). Similarly, every persistent reference to that; object (a TRef Object, see \ref tref) also contains ""pidf"" and ""fUniqueID"" fields with the; same value, thereby uniquely determining the referenced object (which need not even be in the; same file). In the case of an array of references (a TRefArray object, see \ref trefarray),; there is one ""pidf"" value for the entire array, and a separate ""fUniqueID"" value for each; refer",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:10763,release,release,10763,io/doc/TFile/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md,1,['release'],['release']
Deployability,"; Inter-Procedural Optimization. Refers to any variety of code optimization; that occurs between procedures, functions or compilation units (modules). **ISel**; Instruction Selection. L; -. **LCSSA**; Loop-Closed Static Single Assignment Form. **LGTM**; ""Looks Good To Me"". In a review thread, this indicates that the; reviewer thinks that the patch is okay to commit. **LICM**; Loop Invariant Code Motion. **LSDA**; Language Specific Data Area. C++ ""zero cost"" unwinding is built on top a; generic unwinding mechanism. As the unwinder walks each frame, it calls; a ""personality"" function to do language specific analysis. Each function's; FDE points to an optional LSDA which is passed to the personality function.; For C++, the LSDA contain info about the type and location of catch; statements in that function. **Load-VN**; Load Value Numbering. **LTO**; Link-Time Optimization. M; -. **MC**; Machine Code. N; -; .. _nfc:. **NFC**; ""No functional change"". Used in a commit message to indicate that a patch; is a pure refactoring/cleanup.; Usually used in the first line, so it is visible without opening the; actual commit email. O; -; .. _object pointer:; .. _object pointers:. **Object Pointer**; A pointer to an object such that the garbage collector is able to trace; references contained within the object. This term is used in opposition to; `derived pointer`_. P; -. **PGO**; Profile-Guided Optimization. **PR**; Problem report. A bug filed on `the LLVM Bug Tracking System; <https://bugs.llvm.org/enter_bug.cgi>`_. **PRE**; Partial Redundancy Elimination. R; -. **RAUW**. Replace All Uses With. The functions ``User::replaceUsesOfWith()``,; ``Value::replaceAllUsesWith()``, and; ``Constant::replaceUsesOfWithOnConstant()`` implement the replacement of one; Value with another by iterating over its def/use chain and fixing up all of; the pointers to point to the new value. See; also `def/use chains <ProgrammersManual.html#iterating-over-def-use-use-def-chains>`_. **Reassociation**; Rea",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Lexicon.rst:5790,patch,patch,5790,interpreter/llvm-project/llvm/docs/Lexicon.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Lexicon.rst,1,['patch'],['patch']
Deployability,"; MnContours::operator() returns a; std::vector$<$std::pair$<$double,double$> >$ of (x,y) points. Using; MnPlot::operator() will generate a text graphics plot in the terminal. # M installation #. ## M releases ##. To follow the current release process the user is referred to the M; homepage @bib-C++MINUIT. M was re–implemented in from 2002–2004, but the functionality is largely; compatible with the one of the version. The usage is different in the; sense that the re–write from to was done by its signification and not; literally (with minor exceptions). Applications such as; $\mbox{MIGRAD}$ have a corresponding class MnMigrad, M ""commands""; became classes or methods of classes according to their purpose. Users; familiar with the version of M , who have not yet used releases from the; version, should however read this manual, in order to adapt to the; changes as well as to discover the new features and easier ways of using; old features. ## Install M using autoconf/make ##. For each release of M a tar.gz file is provided for downloading from the; M homepage @bib-C++MINUIT. For non-UNIX platforms please refer to the M; homepage. The necessary steps to follow are:. 1. download the tar.gz by clicking on it from the release page. 2. unzip it:. $ unzip Minuit-x.x.x.tar.gz. 3. untar it:. $ tar xvf Minuit-x.x.x.tar. 4. step down to the created Minuit-x.x.x directory:. $ cd Minuit-x.x.x/. 5. run the ""configure"" script:. $ ./configure. 6. run ""make"" to compile the source code:. $ make. 7. run ""make check"" to create the executable example:. $ make check. 8. run the executable example:. $ tests/MnTutorial/Quad4FMain.C. The output should look like that:. Minuit did successfully converge. # of function calls: 74; minimum function value: 1.12392e-09; minimum edm: 1.12392e-09; minimum internal state vector: LAVector parameters:. -1.82079e-05; -1.20794e-05; 6.22382e-06; -3.0465e-05. minimum internal covariance matrix: LASymMatrix parameters:. 4 1 2 2.70022e-18; 1 5 3 1.87754e-17; 2 3 ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:22145,release,release,22145,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['release'],['release']
Deployability,"; N2524; No. Digit separators; N2626; Clang 13. Missing +(x) in table; N2641; Yes. Add support for preprocessing directives elifdef and elifndef; N2645; Clang 13. [[maybe_unused]] for labels; N2662; Clang 16. Zeros compare equal; N2670; Yes. Negative values; N2671; Yes. 5.2.4.2.2	cleanup; N2672; Yes. Towards Integer Safety; N2683; Clang 18. Adding Fundamental Type for N-bit Integers. ; N2763; Clang 15. ; N2775; Clang 15. ; N2969; Clang 15. ; N3035; Clang 15. #warning directive; N2686; Yes. Sterile characters; N2686; Yes. Numerically equal; N2716; Yes. char16_t & char32_t string literals shall be UTF-16 & UTF-32; N2728; Yes. IEC 60559 binding; N2749; Unknown. __has_include for C; N2799; Yes. Annex F overflow and underflow; N2747; Yes. Remove UB from Incomplete Types in Function Parameters; N2770; Yes. Variably-modified types; N2778; Yes. Types do not have types; N2781; Yes. 5.2.4.2.2	cleanup (N2672 update); N2806; Yes. Allow 16-bit ptrdiff_t; N2808; Yes. Proposal to update CFP freestanding requirements; N2823; Unknown. Types and sizes; N2838; Yes. Clarifying integer terms; N2837; Yes. Clarification for max exponent macros; N2843; Unknown. Clarification about expression transformations; N2846; Unknown. Contradiction about INFINITY macro; N2848; Unknown. Require exact-width integer type interfaces; N2872; Yes. @, $, and ‘ in the source/execution character set; N2701; Yes. Quantum exponent of NaN (version 2); N2754; Unknown. The noreturn attribute; N2764; Clang 15. *_HAS_SUBNORM==0 implies what?; N2797; Yes. Disambiguate the storage class of some compound literals; N2819; Unknown. Add annotations for unreachable control flow v2; N2826; Clang 17. Unicode Sequences More Than 21 Bits are a Constraint Violation r0; N2828; Clang 3.6. Identifier Syntax using Unicode Standard Annex 31; N2836; Clang 15. No function declarators without prototypes; N2841; Clang 15. Remove default argument promotions for _FloatN types; N2844; No. Revised Suggestions of Change for Numerically Equal",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_status.html:10650,update,update,10650,interpreter/llvm-project/clang/www/c_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_status.html,1,['update'],['update']
Deployability,"; National Science Foundation grants PHY-1450377 and PHY-1624356, and by the U.S.; Department of Energy, Office of Science. # References; (1): [Vassilev, V., 2017, October. Optimizing ROOT's Performance Using C++ Modules. In Journal of Physics: Conference Series (Vol. 898, No. 7, p. 072023). IOP Publishing.][1]. (2): [Clang Modules, Official Documentation][2]. (3): [Manuel Klimek, Deploying C++ Modules to 100s of Millions of Lines of Code, 2016, CppCon][3]. (4): [Precompiled Header and Modules Internals, Official Documentation][4]. (5): [Bloom Filter][5]. (6): [C++ Modules support (based on Clang), GitHub Repo][5]. (7): [Make your third party libraries modular][6]. (8): [Vassilev, V., Shadura, O., Takahashi, Y., IPCC-ROOT Showcase Presentation, Nov, 2018][7]. (9): [ROOT Continuous Performance Monitoring System][8]. [//]: # (Links); [1]: https://www.researchgate.net/profile/Vassil_Vassilev3/publication/319717664_Optimizing_ROOT%27s_Performance_Using_C_Modules/links/59bad690aca272aff2d01c1c/Optimizing-ROOTs-Performance-Using-C-Modules.pdf ""Vassilev, V., 2017, October. Optimizing ROOT’s Performance Using C++ Modules. In Journal of Physics: Conference Series (Vol. 898, No. 7, p. 072023). IOP Publishing."". [2]: https://clang.llvm.org/docs/Modules.html ""Clang Modules"". [3]: https://cppcon2016.sched.com/event/7nM2/deploying-c-modules-to-100s-of-millions-of-lines-of-code ""Deploying C++ Modules to 100s of Millions of Lines of Code"". [4]: https://clang.llvm.org/docs/PCHInternals.html ""Precompiled Header and Modules Internals"". [5]: https://en.wikipedia.org/wiki/Bloom_filter ""Bloom Filter"". [6]: https://github.com/cms-sw/cmssw/issues/15248 ""C++ Modules support (based on Clang)"". [7]: https://github.com/Teemperor/ClangAutoModules ""Make your third party libraries modular"". [8]: https://ipcc-root.github.io/downloads/20181108-ipcc-princeton-showcase-presentation.pdf ""IPCC-ROOT Showcase Presentation"". [9]: http://root-bench.cern.ch/ ""ROOT Continuous Performance Monitoring System"". ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:21766,deploy,deploying-c-modules-to-,21766,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['deploy'],['deploying-c-modules-to-']
Deployability,"; Release+Asserts), so use screen or nohup to avoid headaches, since it'll take; a long time. Use the ``--help`` option to see all the options and chose it according to; your needs. findRegressions-nightly.py; --------------------------. TODO. .. _test-suite:. Test Suite; ==========. .. contents::; :local:. Follow the `LNT Quick Start Guide; <https://llvm.org/docs/lnt/quickstart.html>`__ link on how to set-up the; test-suite. The binary location you'll have to use for testing is inside the; ``rcN/Phase3/Release+Asserts/llvmCore-REL-RC.install``.; Link that directory to an easier location and run the test-suite. An example on the run command line, assuming you created a link from the correct; install directory to ``~/devel/llvm/install``::. ./sandbox/bin/python sandbox/bin/lnt runtest \; nt \; -j4 \; --sandbox sandbox \; --test-suite ~/devel/llvm/test/test-suite \; --cc ~/devel/llvm/install/bin/clang \; --cxx ~/devel/llvm/install/bin/clang++. It should have no new regressions, compared to the previous release or release; candidate. You don't need to fix all the bugs in the test-suite, since they're; not necessarily meant to pass on all architectures all the time. This is; due to the nature of the result checking, which relies on direct comparison,; and most of the time, the failures are related to bad output checking, rather; than bad code generation. If the errors are in LLVM itself, please report every single regression found; as blocker, and all the other bugs as important, but not necessarily blocking; the release to proceed. They can be set as ""known failures"" and to be; fix on a future date. .. _pre-release-process:. Pre-Release Process; ===================. .. contents::; :local:. When the release process is announced on the mailing list, you should prepare; for the testing, by applying the same testing you'll do on the release; candidates, on the previous release. You should:. * Download the previous release sources from; https://llvm.org/releases/download.htm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst:4137,release,release,4137,interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,2,['release'],['release']
Deployability,"; TF1 f(""Sin Function"", ""sin(x)"", 0, TMath::Pi());; ROOT::Math::WrappedTF1 wf1(f);. ROOT::Math::GaussIntegrator ig;. ig.SetFunction(wf1, false);; ig.SetRelTolerance(0.001);. cout << ig.Integral(0, TMath::PiOver2()) << endl;. return 0;; }; ```; #### ROOT::Math::GaussLegendreIntegrator. This class implementes the Gauss-Legendre quadrature formulas. This sort of numerical methods requieres that the user specifies the number of intermediate function points; used in the calculation of the integral. It will automatically determine the coordinates and weights of such points before performing the integration.; We can use the example above, but replacing the creation of a `ROOT::Math::GaussIntegrator` object with `ROOT::Math::GaussLegendreIntegrator`. #### ROOT::Math::GSLIntegrator. This is a wrapper for the *QUADPACK* integrator implemented in the GSL library. It supports several integration methods that can be chosen in construction time.; The default type is adaptive integration with singularity applying a Gauss-Kronrod 21-point integration rule. For a detail description of the GSL methods visit the GSL user guide; This class implements the best algorithms for numerical integration for one dimensional functions. We encourage the use it as the main option, bearing in mind that it uses code from the; GSL library, wich is provided in the *MathMore* library of ROOT. The interface to use is the same as above. We have now the possibility to specify a different integration algorithm in the constructor of the `ROOT::Math::GSLIntegrator` class.; ```{.cpp}; // create the adaptive integrator with the 51 point rule; ROOT::Math::GSLIntegrator ig(ROOT::Math::Integration::kADAPTIVE, ROOT::Math::Integration::kGAUSS51);; ig.SetRelTolerance(1.E-6); // set relative tolerance; ig.SetAbsTolerance(1.E-6); // set absoulte tolerance; ```. The algorithm is controlled by the given absolute and relative tolerance. The iterations are continued until the following condition is satisfied; $$; absErr <=",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:54772,integrat,integration,54772,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,2,['integrat'],['integration']
Deployability,"; TProof::Open.; Add the possibility to save the perfomance information shown; by the dialog into a small ntuple included in the output list. The; ntuple contains 5 floats (processing time, number of active workers,; event rate, MBytes read, number of effective sessions on the cluster); and it is filled each time the number of active workers changes or at; max 100 regular intervals at least 5 secs apart; in this way the ntuple; has at most O(100 entries + number of workers). To enable the saving of; the ntuple execute the following:;         proof->SetParameter(""PROOF_SaveProgressPerf"", ""yes"");; before running the query. The ntuple is called 'PROOF_ProgressPerfNtuple'.; Add support for worker autodiscovery in PROOF using the; Avahi/Bonjour technology. The new functionality is supported on Mac; (MacOsX >= 10.4; no need of additional installs) and linux (requires; the Avahi framework, available by default on most of the; distributions). To use this functionality (instead-of or in-addition-to; the the static worker configuration via proof.conf or xpd.worker) the; new directive 'xpd.bonjour' must be used. Improvements. Improve support for valgrind runs in PROOF-Lite; Add the possibility to add files to a dataset. This is; achieved with a new option 'U' (for update) to RegisterDataSet.; Add; methof TProof::GetStatistics to allow the client to retrieve the; correct values of fBytesRead, fRealTime and fCpuTime at any moment;; this will be used to setup a sort of ROOTmarks in stressProof .; Several improvements in the test program 'stressProof'; and in the tutorials under 'tutorials/proof'; Avoid; contacting the DNS when initializing TProofMgr as base class of; TProofMgrLite: it is not needed and it may introduce long startup; delays.; Make TProof::LogViewer("""") start the viewer for; a Lite session, in parallel to whats happen for TProof::Open("""").; Several; improvements in the handling of wild cards in the dataset manager; for; example, issuing a GetDataSet(...) on a datas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:4026,configurat,configuration,4026,proof/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html,1,['configurat'],['configuration']
Deployability,"; The advantage of using open source analyzer builds (provided on this website); is that they are often newer than the analyzer provided with Xcode, and thus can; contain bug fixes, new checks, or simply better analysis.; On the other hand, new checks can be experimental, with results of variable; quality. Users are encouraged to file bug reports; (for any version of the analyzer) where they encounter false positives or other; issues.; set-xcode-analyzer; Starting with analyzer build checker-234, analyzer builds contain a command; line utility called set-xcode-analyzer that allows users to change what; copy of clang that Xcode uses for analysis:. $ set-xcode-analyzer -h; Usage: set-xcode-analyzer [options]. Options:; -h, --help show this help message and exit; --use-checker-build=PATH; Use the Clang located at the provided absolute path,; e.g. /Users/foo/checker-1; --use-xcode-clang Use the Clang bundled with Xcode. Operationally, set-xcode-analyzer edits Xcode's configuration files; to point it to use the version of clang you specify for static; analysis. Within this model it provides you two basic modes:. --use-xcode-clang: Switch Xcode (back) to using the clang that came bundled with it for static analysis.; --use-checker-build: Switch Xcode to using the clang provided by the specified analyzer build. Things to keep in mind. You should quit Xcode prior to running set-xcode-analyzer. You will need to run set-xcode-analyzer under; sudo in order to have write privileges to modify the Xcode; configuration files. Examples; Example 1: Telling Xcode to use checker-235:. $ pwd; /tmp; $ tar xjf checker-235.tar.bz2; $ sudo checker-235/set-xcode-analyzer --use-checker-build=/tmp/checker-235. Note that you typically won't install an analyzer build in /tmp, but; the point of this example is that set-xcode-analyzer just wants a full; path to an untarred analyzer build.; Example 2: Telling Xcode to use a very specific version of clang:. $ sudo set-xcode-analyzer --use-checker-bu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/xcode.html:2265,configurat,configuration,2265,interpreter/llvm-project/clang/www/analyzer/xcode.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/xcode.html,1,['configurat'],['configuration']
Deployability,"; [2]: Latency; [3]: RThroughput; [4]: MayLoad; [5]: MayStore; [6]: HasSideEffects (U); [7]: Encoding Size. [1] [2] [3] [4] [5] [6] [7] Encodings: Instructions:; 1 2 1.00 4 c5 f0 59 d0 vmulps	%xmm0, %xmm1, %xmm2; 1 4 1.00 4 c5 eb 7c da vhaddps	%xmm2, %xmm2, %xmm3; 1 4 1.00 4 c5 e3 7c e3 vhaddps	%xmm3, %xmm3, %xmm4. The `Encoding Size` column shows the size in bytes of instructions. The; `Encodings` column shows the actual instruction encodings (byte sequences in; hex). The third section is the *Resource pressure view*. This view reports; the average number of resource cycles consumed every iteration by instructions; for every processor resource unit available on the target. Information is; structured in two tables. The first table reports the number of resource cycles; spent on average every iteration. The second table correlates the resource; cycles to the machine instruction in the sequence. For example, every iteration; of the instruction vmulps always executes on resource unit [6]; (JFPU1 - floating point pipeline #1), consuming an average of 1 resource cycle; per iteration. Note that on AMD Jaguar, vector floating-point multiply can; only be issued to pipeline JFPU1, while horizontal floating-point additions can; only be issued to pipeline JFPU0. The resource pressure view helps with identifying bottlenecks caused by high; usage of specific hardware resources. Situations with resource pressure mainly; concentrated on a few resources should, in general, be avoided. Ideally,; pressure should be uniformly distributed between multiple resources. Timeline View; ^^^^^^^^^^^^^; The timeline view produces a detailed report of each instruction's state; transitions through an instruction pipeline. This view is enabled by the; command line option ``-timeline``. As instructions transition through the; various stages of the pipeline, their states are depicted in the view report.; These states are represented by the following characters:. * D : Instruction dispatched.; * e : ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:20476,pipeline,pipeline,20476,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['pipeline'],['pipeline']
Deployability,"; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; });. * ``LBI_OuterScope`` (in configuration: ``OuterScope``); For statements within block scope, align lambda body relative to the; indentation level of the outer scope the lambda signature resides in. .. code-block:: c++. someMethod(; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; });. someMethod(someOtherMethod(; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; }));. .. _Language:. **Language** (``LanguageKind``) :versionbadge:`clang-format 3.5` :ref:`¶ <Language>`; Language, this format style is targeted at. Possible values:. * ``LK_None`` (in configuration: ``None``); Do not use. * ``LK_Cpp`` (in configuration: ``Cpp``); Should be used for C, C++. * ``LK_CSharp`` (in configuration: ``CSharp``); Should be used for C#. * ``LK_Java`` (in configuration: ``Java``); Should be used for Java. * ``LK_JavaScript`` (in configuration: ``JavaScript``); Should be used for JavaScript. * ``LK_Json`` (in configuration: ``Json``); Should be used for JSON. * ``LK_ObjC`` (in configuration: ``ObjC``); Should be used for Objective-C, Objective-C++. * ``LK_Proto`` (in configuration: ``Proto``); Should be used for Protocol Buffers; (https://developers.google.com/protocol-buffers/). * ``LK_TableGen`` (in configuration: ``TableGen``); Should be used for TableGen code. * ``LK_TextProto`` (in configuration: ``TextProto``); Should be used for Protocol Buffer messages in text format; (https://developers.google.com/protocol-buffers/). * ``LK_Verilog`` (in configuration: ``Verilog``); Should be used for Verilog and SystemVerilog.; https://standards.ieee.org/ieee/1800/6700/; https://sci-hub.st/10.1109/IEEESTD.2018.8299595. .. _LineEnding:. **LineEnding** (``LineEndingStyle``) :versionbadge:`clang-format 16` :ref:`¶ <LineEnding>`; Line ending style (``\n`` or ``\r\n``) to use. Possible values:. * ``LE_LF`` (in configuration: ``LF``); Use ``\n``. * ``LE_CRLF`` (in configuration: ``CRLF``); Use ``\r\n``. * ``LE_DeriveLF",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:83624,configurat,configuration,83624,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"; `the Download Page <https://releases.llvm.org/download.html>`_. Introduction; ============. This document contains the release notes for the LLVM Compiler Infrastructure,; release |release|. Here we describe the status of LLVM, including major improvements; from the previous release, improvements in various subprojects of LLVM, and; some of the current users of the code. All LLVM releases may be downloaded; from the `LLVM releases web site <https://llvm.org/releases/>`_. For more information about LLVM, including information about the latest; release, please check out the `main LLVM web site <https://llvm.org/>`_. If you; have questions or comments, the `Discourse forums; <https://discourse.llvm.org>`_ is a good place to ask; them. Note that if you are reading this file from a Git checkout or the main; LLVM web page, this document applies to the *next* release, not the current; one. To see the release notes for a specific release, please see the `releases; page <https://llvm.org/releases/>`_. Non-comprehensive list of changes in this release; =================================================; .. NOTE; For small 1-3 sentence descriptions, just add an entry at the end of; this list. If your description won't fit comfortably in one bullet; point (e.g. maybe you would like to give an example of the; functionality, or simply have a lot to talk about), see the `NOTE` below; for adding a new subsection. * ... Update on required toolchains to build LLVM; -------------------------------------------. Changes to the LLVM IR; ----------------------. * The `llvm.stacksave` and `llvm.stackrestore` intrinsics now use; an overloaded pointer type to support non-0 address spaces.; * The constant expression variants of the following instructions have been; removed:. * ``and``; * ``or``; * ``lshr``; * ``ashr``; * ``zext``; * ``sext``; * ``fptrunc``; * ``fpext``; * ``fptoui``; * ``fptosi``; * ``uitofp``; * ``sitofp``. * Added `llvm.exp10` intrinsic. * Added a ``code_model`` attribute f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst:1267,release,releases,1267,interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,1,['release'],['releases']
Deployability,"; address. All modification orders must be compatible with the; happens-before order. There is no guarantee that the modification; orders can be combined to a global total order for the whole program; (and this often will not be possible). The read in an atomic; read-modify-write operation (:ref:`cmpxchg <i_cmpxchg>` and; :ref:`atomicrmw <i_atomicrmw>`) reads the value in the modification; order immediately before the value it writes. If one atomic read; happens before another atomic read of the same address, the later; read must see the same value or a later value in the address's; modification order. This disallows reordering of ``monotonic`` (or; stronger) operations on the same address. If an address is written; ``monotonic``-ally by one thread, and other threads ``monotonic``-ally; read that address repeatedly, the other threads must eventually see; the write. This corresponds to the C/C++ ``memory_order_relaxed``.; ``acquire``; In addition to the guarantees of ``monotonic``, a; *synchronizes-with* edge may be formed with a ``release`` operation.; This is intended to model C/C++'s ``memory_order_acquire``.; ``release``; In addition to the guarantees of ``monotonic``, if this operation; writes a value which is subsequently read by an ``acquire``; operation, it *synchronizes-with* that operation. Furthermore,; this occurs even if the value written by a ``release`` operation; has been modified by a read-modify-write operation before being; read. (Such a set of operations comprises a *release; sequence*). This corresponds to the C/C++; ``memory_order_release``.; ``acq_rel`` (acquire+release); Acts as both an ``acquire`` and ``release`` operation on its; address. This corresponds to the C/C++ ``memory_order_acq_rel``.; ``seq_cst`` (sequentially consistent); In addition to the guarantees of ``acq_rel`` (``acquire`` for an; operation that only reads, ``release`` for an operation that only; writes), there is a global total order on all; sequentially-consistent operatio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:154591,release,release,154591,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['release'],['release']
Deployability,"; algorithms to the spectrum with the peaks with `sigma` changing from 1 to; 10 (see Figure 3.6). ![Robustness of the proposed algorithms to the spectrum with the peaks with sigma changing from 1 to 10](figures/image068.png). We applied peak searching algorithm based on Markov approach. We changed; `sigma` in the interval from 1 to 10. The spectra for averaging windows 3,; 5, 10 are shown in Figure 3.7. ![Spectra for averaging windows 3, 5, 10](figures/image070.png). When we applied peak searching function to the Markov spectrum averaged; with the `window=10`, we obtained correct estimate of all 10 peak; positions for `sigma=2,3,4,5,6,7,8`. It was not the case when we made the; same experiment with the original spectrum. For all sigmas some peaks; were not discovered. ## 2-DIMENSIONAL SPECTRA. The basic function of the 2-dimensional peak searching is described in; details in [4]. It automatically identifies the peaks in a; spectrum with the presence of the continuous background, statistical; fluctuations as well as coincidences of background in one dimension and; peak in the other one-ridges. The form of the basic function of; 2-dimensional peak searching is. ```{.cpp}; Int_t Search2(const float **source,; int sizex,; int sizey,; double sigma);; ```. This function searches for peaks in the source spectrum. The number of found; peaks and their positions are written into the structure pointed by; `two_dim_peak` structure pointer. Function parameters:. - **`source`**: pointer to the vector of the source spectrum; - **`sizex`**: x length of the source spectrum; - **`sizey`**: y length of the source spectrum; - **`sigma`**: sigma of searched peaks. An example of the two-dimensional spectrum with the identified peaks is; shown in Figure 3.8. ![Two-dimensional spectrum with the identified peaks](figures/image072.png). We have also generalized the peak searching function similarly to one-dimensional data. The generalized peak searching function for two-dimensional spectra ha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md:21453,continuous,continuous,21453,documentation/spectrum/Spectrum.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md,1,['continuous'],['continuous']
Deployability,"; and :option:`-rpath` can be combined in an invocation only if they do not share; the same `<rpath>` value. .. option:: -add_rpath <rpath>. Add an rpath named ``<rpath>`` to the specified binary. Can be specified multiple; times to add multiple rpaths. Throws an error if ``<rpath>`` is already listed in; the binary. .. option:: -change <old_install_name> <new_install_name>. Change an install name ``<old_install_name>`` to ``<new_install_name>`` in the; specified binary. Can be specified multiple times to change multiple dependent shared; library install names. Option is ignored if ``<old_install_name>`` is not listed; in the specified binary. .. option:: -delete_rpath <rpath>. Delete an rpath named ``<rpath>`` from the specified binary. Can be specified multiple; times to delete multiple rpaths. Throws an error if ``<rpath>`` is not listed in; the binary. .. option:: -delete_all_rpaths. Deletes all rpaths from the binary. .. option:: --help, -h. Print a summary of command line options. .. option:: -id <name>. Change shared library's identification name under LC_ID_DYLIB to ``<name>`` in the; specified binary. If specified multiple times, only the last :option:`-id` option is; selected. Option is ignored if the specified Mach-O binary is not a dynamic shared library. .. option:: -rpath <old_rpath> <new_rpath>. Change an rpath named ``<old_rpath>`` to ``<new_rpath>`` in the specified binary. Can be specified; multiple times to change multiple rpaths. Throws an error if ``<old_rpath>`` is not listed; in the binary or ``<new_rpath>`` is already listed in the binary. .. option:: --version, -V. Display the version of the :program:`llvm-install-name-tool` executable. EXIT STATUS; -----------. :program:`llvm-install-name-tool` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-objcopy/strip/>. SEE ALSO; --------. :manpage:`llvm-objcopy(1)`; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-install-name-tool.rst:2363,install,install-name-tool,2363,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-install-name-tool.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-install-name-tool.rst,2,['install'],['install-name-tool']
Deployability,"; case 1: { case 1:; bar(); {; } break; bar();; default: { }; plop(); break;; } default:; } {; plop();; }; }. .. _IndentCaseLabels:. **IndentCaseLabels** (``Boolean``) :versionbadge:`clang-format 3.3` :ref:`¶ <IndentCaseLabels>`; Indent case labels one level from the switch statement. When ``false``, use the same indentation level as for the switch; statement. Switch statement body is always indented one level more than; case labels (except the first block following the case label, which; itself indents the code - unless IndentCaseBlocks is enabled). .. code-block:: c++. false: true:; switch (fool) { vs. switch (fool) {; case 1: case 1:; bar(); bar();; break; break;; default: default:; plop(); plop();; } }. .. _IndentExternBlock:. **IndentExternBlock** (``IndentExternBlockStyle``) :versionbadge:`clang-format 11` :ref:`¶ <IndentExternBlock>`; IndentExternBlockStyle is the type of indenting of extern blocks. Possible values:. * ``IEBS_AfterExternBlock`` (in configuration: ``AfterExternBlock``); Backwards compatible with AfterExternBlock's indenting. .. code-block:: c++. IndentExternBlock: AfterExternBlock; BraceWrapping.AfterExternBlock: true; extern ""C""; {; void foo();; }. .. code-block:: c++. IndentExternBlock: AfterExternBlock; BraceWrapping.AfterExternBlock: false; extern ""C"" {; void foo();; }. * ``IEBS_NoIndent`` (in configuration: ``NoIndent``); Does not indent extern blocks. .. code-block:: c++. extern ""C"" {; void foo();; }. * ``IEBS_Indent`` (in configuration: ``Indent``); Indents extern blocks. .. code-block:: c++. extern ""C"" {; void foo();; }. .. _IndentGotoLabels:. **IndentGotoLabels** (``Boolean``) :versionbadge:`clang-format 10` :ref:`¶ <IndentGotoLabels>`; Indent goto labels. When ``false``, goto labels are flushed left. .. code-block:: c++. true: false:; int f() { vs. int f() {; if (foo()) { if (foo()) {; label1: label1:; bar(); bar();; } }; label2: label2:; return 1; return 1;; } }. .. _IndentPPDirectives:. **IndentPPDirectives** (``PPDirectiveIndentSt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:71993,configurat,configuration,71993,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"; compatible with all other existing Windows toolchains. There are more LLVM projects which this document does not discuss. Requirements; ============; Before you begin to use the LLVM system, review the requirements given; below. This may save you some trouble by knowing ahead of time what hardware; and software you will need. Hardware; --------; Any system that can adequately run Visual Studio 2019 is fine. The LLVM; source tree including the git index consumes approximately 3GB.; Object files, libraries and executables consume approximately 5GB in; Release mode and much more in Debug mode. SSD drive and >16GB RAM are; recommended. Software; --------; You will need `Visual Studio <https://visualstudio.microsoft.com/>`_ 2019 or; later, with the latest Update installed. Visual Studio Community Edition; suffices. You will also need the `CMake <http://www.cmake.org/>`_ build system since it; generates the project files you will use to build with. CMake is bundled with; Visual Studio 2019 so separate installation is not required. If you do install; CMake separately, Visual Studio 2022 will require CMake Version 3.21 or later. If you would like to run the LLVM tests you will need `Python; <http://www.python.org/>`_. Version 3.6 and newer are known to work. You can; install Python with Visual Studio 2019, from the Microsoft store or from; the `Python web site <http://www.python.org/>`_. We recommend the latter since it; allows you to adjust installation options. You will need `Git for Windows <https://git-scm.com/>`_ with bash tools, too.; Git for Windows is also bundled with Visual Studio 2019. Getting Started; ===============; Here's the short story for getting up and running quickly with LLVM.; These instruction were tested with Visual Studio 2019 and Python 3.9.6:. 1. Download and install `Visual Studio <https://visualstudio.microsoft.com/>`_.; 2. In the Visual Studio installer, Workloads tab, select the; **Desktop development with C++** workload. Under Individual co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst:2109,install,installation,2109,interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,1,['install'],['installation']
Deployability,"; configuration for the LLVM project which will build the fastest or; **RelWithDebInfo** which is also several time larger than Release.; Another technique is to build all of LLVM in Release mode and change; compiler flags, disabling optimization and enabling debug information, only; for specific libraries or source files you actually need to debug. 14. Test LLVM in Visual Studio:. You can run LLVM tests by merely building the project ""check-all"". The test; results will be shown in the VS output window. Once the build succeeds, you; have verified a working LLVM development environment!. You should not see any unexpected failures, but will see many unsupported; tests and expected failures:. ::. 114>Testing Time: 1124.66s; 114> Skipped : 39; 114> Unsupported : 21649; 114> Passed : 51615; 114> Expectedly Failed: 93; ========== Build: 114 succeeded, 0 failed, 321 up-to-date, 0 skipped ==========``. Alternatives to manual installation; ===================================; Instead of the steps above, to simplify the installation procedure you can use; `Chocolatey <https://chocolatey.org/>`_ as package manager.; After the `installation <https://chocolatey.org/install>`_ of Chocolatey,; run these commands in an admin shell to install the required tools:. .. code-block:: bat. choco install -y git cmake python3; pip3 install psutil. There is also a Windows; `Dockerfile <https://github.com/llvm/llvm-zorg/blob/main/buildbot/google/docker/windows-base-vscode2019/Dockerfile>`_; with the entire build tool chain. This can be used to test the build with a; tool chain different from your host installation or to create build servers. Next steps; ==========; 1. Read the documentation.; 2. Seriously, read the documentation.; 3. Remember that you were warned twice about reading the documentation. Test LLVM on the command line:; ------------------------------; The LLVM tests can be run by changing directory to the llvm source; directory and running:. .. code-block:: bat. c:\llvm> python ..",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst:8006,install,installation,8006,interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,2,['install'],['installation']
Deployability,"; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `sizeof(llvm_blake3_hasher)` itself is relatively large, currently 1912 bytes; on x86-64. This size can be reduced by restricting the maximum input; length, as described in Section 5.4 of [the BLAKE3; spec](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf),; but this implementation doesn't currently support that strategy. ## Common API Functions. ```c++; BLAKE3::BLAKE3();. void BLAKE3::init();; ```; ```c; void llvm_blake3_hasher_init(; llvm_blake3_hasher *self);; ```. Initialize a `llvm_blake3_hasher` in the default hashing mode. ---. ```c++; void BLAKE3::update(ArrayRef<uint8_t> Data);. void BLAKE3::update(StringRef Str);; ```; ```c; void llvm_blake3_hasher_update(; llvm_blake3_hasher *self,; const void *input,; size_t input_len);; ```. Add input to the hasher. This can be called any number of times. ---. ```c++; template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; using BLAKE3Result = std::array<uint8_t, NumBytes>;. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; void BLAKE3::final(BLAKE3Result<NumBytes> &Result);. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; BLAKE3Result<NumBytes> BLAKE3::final();; ```; ```c; void llvm_blake3_hasher_finalize(; const llvm_blake3_hasher *self,; uint8_t *out,; size_t out_len);; ```. Finalize the hasher and return an output of any length, given in bytes.; This doesn't modify the hasher itself, and it's possible to finalize; again after adding more input. The constant `LLVM_BLAKE3_OUT_LEN` provides; the default output length, 32 bytes, which is recommended for most; callers. Outputs shorter than the defaul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:2733,update,update,2733,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,1,['update'],['update']
Deployability,"; if (DOXYGEN_FOUND); if (LLVM_ENABLE_DOXYGEN); set(abs_srcdir ${CMAKE_CURRENT_SOURCE_DIR}); set(abs_builddir ${CMAKE_CURRENT_BINARY_DIR}). if (HAVE_DOT); set(DOT ${LLVM_PATH_DOT}); endif(). if (LLVM_DOXYGEN_EXTERNAL_SEARCH); set(enable_searchengine ""YES""); set(searchengine_url ""${LLVM_DOXYGEN_SEARCHENGINE_URL}""); set(enable_server_based_search ""YES""); set(enable_external_search ""YES""); set(extra_search_mappings ""${LLVM_DOXYGEN_SEARCH_MAPPINGS}""); else(); set(enable_searchengine ""NO""); set(searchengine_url """"); set(enable_server_based_search ""NO""); set(enable_external_search ""NO""); set(extra_search_mappings """"); endif(). configure_file(${CMAKE_CURRENT_SOURCE_DIR}/doxygen.cfg.in; ${CMAKE_CURRENT_BINARY_DIR}/doxygen.cfg @ONLY). set(abs_top_srcdir); set(abs_top_builddir); set(DOT); set(enable_searchengine); set(searchengine_url); set(enable_server_based_search); set(enable_external_search); set(extra_search_mappings); set(cling_doxygen_generate_qhp); set(cling_doxygen_qch_filename); set(cling_doxygen_qhp_namespace); set(cling_doxygen_qhelpgenerator_path); set(cling_doxygen_qhp_cust_filter_name); set(cling_doxygen_qhp_cust_filter_attrs). add_custom_target(doxygen-cling; COMMAND ${DOXYGEN_EXECUTABLE} ${CMAKE_CURRENT_BINARY_DIR}/doxygen.cfg; WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}; COMMENT ""Generating cling doxygen documentation."" VERBATIM). if (LLVM_BUILD_DOCS); add_dependencies(doxygen doxygen-cling); endif(). if (NOT LLVM_INSTALL_TOOLCHAIN_ONLY); install(DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/doxygen/html; DESTINATION docs/html); endif(); endif(); endif(). if (LLVM_ENABLE_SPHINX); include(AddSphinxTarget); if (SPHINX_FOUND); if (${SPHINX_OUTPUT_HTML}); add_sphinx_target(html cling); endif(); endif(); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/CMakeLists.txt:1474,install,install,1474,interpreter/cling/docs/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/CMakeLists.txt,1,['install'],['install']
Deployability,"; if (LLVM_BUILTIN_TARGETS); set(builtins_dep_name ""${builtins_dep}-${name}""); else(); set(builtins_dep_name ${builtins_dep}); endif(); endif(). check_apple_target(${name} runtime). runtime_register_target(${name}; DEPENDS ${builtins_dep_name} ${hdrgen_deps}; CMAKE_ARGS -DLLVM_DEFAULT_TARGET_TRIPLE=${name} ${libc_cmake_args}; EXTRA_ARGS TARGET_TRIPLE ${name}); endforeach(). foreach(multilib ${LLVM_RUNTIME_MULTILIBS}); foreach(name ${LLVM_RUNTIME_MULTILIB_${multilib}_TARGETS}); runtime_register_target(${name}+${multilib}; DEPENDS runtimes-${name}; CMAKE_ARGS -DLLVM_DEFAULT_TARGET_TRIPLE=${name}; -DLLVM_RUNTIMES_PREFIX=${name}/; -DLLVM_RUNTIMES_LIBDIR_SUBDIR=${multilib}; BASE_NAME ${name}; EXTRA_ARGS TARGET_TRIPLE ${name}); endforeach(); endforeach(); endif(). if(NOT LLVM_BUILD_INSTRUMENTED AND CLANG_ENABLE_BOOTSTRAP); # TODO: This is a hack needed because the libcxx headers are copied into the; # build directory during configuration. Without that step the clang in the; # build directory cannot find the C++ headers in certain configurations.; # I need to build a mechanism for runtime projects to provide CMake code; # that executes at LLVM configuration time to handle this case.; add_dependencies(clang-bootstrap-deps runtimes-configure); # We need to add the runtimes as a dependency because compiler-rt can be; # built as part of runtimes and we need the profile runtime for PGO; add_dependencies(clang-bootstrap-deps runtimes); endif(). if(LLVM_INCLUDE_TESTS); set_property(GLOBAL APPEND PROPERTY LLVM_ALL_ADDITIONAL_TEST_DEPENDS runtimes-test-depends). set(RUNTIMES_TEST_DEPENDS; FileCheck; count; llvm-cov; llvm-lto; llvm-nm; llvm-objdump; llvm-profdata; llvm-size; llvm-xray; not; obj2yaml; opt; sancov; sanstats; llvm_gtest_main; llvm_gtest; split-file; ); foreach(target ${test_targets} ${SUB_CHECK_TARGETS}); add_dependencies(${target} ${RUNTIMES_TEST_DEPENDS}); endforeach(). set_property(GLOBAL APPEND PROPERTY LLVM_ALL_ADDITIONAL_TEST_TARGETS runtimes ${RUNTIMES_TEST_DEPEN",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/runtimes/CMakeLists.txt:18459,configurat,configurations,18459,interpreter/llvm-project/llvm/runtimes/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/runtimes/CMakeLists.txt,1,['configurat'],['configurations']
Deployability,"; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local. 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); Must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not nee",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:375319,release,release,375319,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,4,['release'],['release']
Deployability,"; mode, omit.; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. 4. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - If OpenCL omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atom",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:365154,release,released,365154,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['released']
Deployability,"; numeric string value for how many instructions should be in the function before; it gets instrumented. .. code-block:: llvm. define i32 @maybe_instrument() uwtable ""xray-instruction-threshold""=""2"" {; ; ...; }. Special Case File; -----------------. Attributes can be imbued through the use of special case files instead of; adding them to the original source files. You can use this to mark certain; functions and classes to be never, always, or instrumented with first-argument; logging from a file. The file's format is described below:. .. code-block:: bash. # Comments are supported; [always]; fun:always_instrument; fun:log_arg1=arg1 # Log the first argument for the function. [never]; fun:never_instrument. These files can be provided through the ``-fxray-attr-list=`` flag to clang.; You may have multiple files loaded through multiple instances of the flag. XRay Runtime Library; --------------------. The XRay Runtime Library is part of the compiler-rt project, which implements; the runtime components that perform the patching and unpatching of inserted; instrumentation points. When you use ``clang`` to link your binaries and the; ``-fxray-instrument`` flag, it will automatically link in the XRay runtime. The default implementation of the XRay runtime will enable XRay instrumentation; before ``main`` starts, which works for applications that have a short; lifetime. This implementation also records all function entry and exit events; which may result in a lot of records in the resulting trace. Also by default the filename of the XRay trace is ``xray-log.XXXXXX`` where the; ``XXXXXX`` part is randomly generated. These options can be controlled through the ``XRAY_OPTIONS`` environment; variable, where we list down the options and their defaults below. +-------------------+-----------------+---------------+------------------------+; | Option | Type | Default | Description |; +===================+=================+===============+========================+; | patch_premain | ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:4704,patch,patching,4704,interpreter/llvm-project/llvm/docs/XRay.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst,1,['patch'],['patching']
Deployability,"; patent claims become licensed as a result of subsequent combinations of your; contribution with any other software. Note, however, that licensable patent; claims include those that you acquire in the future, as long as they read on; your original contribution as made at the original time. Once a patent claim; is subject to Apache's Grant of Patent License, it is licensed under the; terms of that Grant to the ASF and to recipients of any software distributed; by the ASF for any Apache software product whatsoever. .. _legacy:. Legacy License Structure; ------------------------. .. note::; The code base was previously licensed under the Terms described here.; We are in the middle of relicensing to a new approach (described above), but; until this effort is complete, the code is also still available under these; terms. Once we finish the relicensing project, new versions of the code will; not be available under these terms. However, nothing takes away your right; to use old versions under the licensing terms under which they were; originally released. We intend to keep LLVM perpetually open source and to use a permissive open; source license. The code in; LLVM is available under the `University of Illinois/NCSA Open Source License; <http://www.opensource.org/licenses/UoI-NCSA.php>`_, which boils down to; this:. * You can freely distribute LLVM.; * You must retain the copyright notice if you redistribute LLVM.; * Binaries derived from LLVM must reproduce the copyright notice (e.g. in an; included README file).; * You can't use our names to promote your LLVM derived products.; * There's no warranty on LLVM at all. We believe this fosters the widest adoption of LLVM because it **allows; commercial products to be derived from LLVM** with few restrictions and without; a requirement for making any derived works also open source (i.e. LLVM's; license is not a ""copyleft"" license like the GPL). We suggest that you read the; `License <http://www.opensource.org/licenses/UoI-NCSA",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:61381,release,released,61381,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['release'],['released']
Deployability,"; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; befor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:229883,release,release,229883,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability,"; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. fence acq_rel - system *none* 1. buffer_wbl2. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:277541,release,release,277541,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability,"; sandbox file removal; file upload, download. TProofDraw. Allow to set a color, size, size, width for lines,; area, markers; the attributes are transmitted via the input list and; automatically derived from the ones of the chain. Support automatic creation of a dataset out of files; created on the worker nodes by worker processes. The implementation is; an extension of the functionality of the class TProofOutputFile used; for merging via file.; Add the possibility to enable/disable the tree cache and; to change its size on per-query base; two new parameters are available:. PROOF_UseTreeCache   ; Int_t       ; Enable (0) or Disable (1) the tree cache (default 1); PROOF_CacheSize      ; Long64_t     Cache size in bytes; (default 10000000). Examples:;        ; a) to disable the cache for the next run enter:;                                 ; proof->SetParameter(""PROOF_UseTreeCache"", 0);        ; b) to set the cache size to 20M;                                 ; proof->SetParameter(""PROOF_CacheSize"", 20000000);  Add the parameter; PROOF_UseParallelUnzip to toggle the use of the parallel unzip; (default off for now); to enable it add the following call;            ;            ;        ;  proof->SetParameter(""PROOF_UseParallelUnzip"", 1).  Add the possibility to give indications about; the number of workers at startup.;  E.g.;        1. To; start max 5 workers;             ; TProof::Open(""<master>"",""workers=5"");        2. To; start max 2 workers per physical machine;             ; TProof::Open(""<master>"",""workers=2x"");      This is useful in general when; running tests (equivalent but quicker then full startup;      followed by; TProof::SetParallel(n) or TProof::DeactivateWorker(...)).; Add support for the worker SysInfo_t in TSlaveInfo; (obtained via TProof::GetListOfSlaveInfos()); Add new submerger functionality to speed up the merging; phase. At the end of the query, a set of workers are promoted; submergers and assigned a sub-set of workers to merge. Once each; sub-me",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:1190,toggle,toggle,1190,proof/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html,1,['toggle'],['toggle']
Deployability,"; the indentation level of the signature. ``OuterScope`` forces the lambda; body to be indented one additional level relative to the parent scope; containing the lambda signature. Possible values:. * ``LBI_Signature`` (in configuration: ``Signature``); Align lambda body relative to the lambda signature. This is the default. .. code-block:: c++. someMethod(; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; });. * ``LBI_OuterScope`` (in configuration: ``OuterScope``); For statements within block scope, align lambda body relative to the; indentation level of the outer scope the lambda signature resides in. .. code-block:: c++. someMethod(; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; });. someMethod(someOtherMethod(; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; }));. .. _Language:. **Language** (``LanguageKind``) :versionbadge:`clang-format 3.5` :ref:`¶ <Language>`; Language, this format style is targeted at. Possible values:. * ``LK_None`` (in configuration: ``None``); Do not use. * ``LK_Cpp`` (in configuration: ``Cpp``); Should be used for C, C++. * ``LK_CSharp`` (in configuration: ``CSharp``); Should be used for C#. * ``LK_Java`` (in configuration: ``Java``); Should be used for Java. * ``LK_JavaScript`` (in configuration: ``JavaScript``); Should be used for JavaScript. * ``LK_Json`` (in configuration: ``Json``); Should be used for JSON. * ``LK_ObjC`` (in configuration: ``ObjC``); Should be used for Objective-C, Objective-C++. * ``LK_Proto`` (in configuration: ``Proto``); Should be used for Protocol Buffers; (https://developers.google.com/protocol-buffers/). * ``LK_TableGen`` (in configuration: ``TableGen``); Should be used for TableGen code. * ``LK_TextProto`` (in configuration: ``TextProto``); Should be used for Protocol Buffer messages in text format; (https://developers.google.com/protocol-buffers/). * ``LK_Verilog`` (in configuration: ``Verilog``); Should be used for Verilog and SystemVerilog.; https://standards.ieee.org/ieee/1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:83272,configurat,configuration,83272,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"; this works adding the beginning of a path in the name; defining a new TFileNode (e.g. 'host://disk1' instead of 'host' only as; it was so far). These feature can be enabled by defining the rootrc; variable 'Packetizer.Partitions', e.g.;            Packetizer.Partitions  /disk1,/disk2,/disk3; Add to the output list the parameters used by the active packetizer. . In the PrintProgress function used to display a text progress; bar, show also the average reading rate in [k,M,G}bytes/s in addition; to the event processing rate. This is useful to have a feeling of the; rate when running of a remote machine in batch mode.; Add the possibility to control the resident and virtual; memory of a proofserv using 'ulimit', which has less limitations and; more flexibility than setrlimit.; Deactivate workers when the requested packages could not be enabled properly.; Add support for reconfiguring the group manager and the; {env,rootrc} settings. The related configuration files are checked for; changes during the regular checks done by the XrdProofdManager.; Add support for selective definition of env and rootrc; variables. Different values can be set for different users, groups, SVN; versions or ROOT versions.; Improve the diagnostic in case of exceptions. Information; about the event and file being processed at the moment the exception; was raised is sent to the client, e.g.;    0.5: caught exception triggered by signal '1' while; processing dset:'EventTree',; file:'http://root.cern.ch/files/data/event_3.root', event:1 - check; logs for possible stacktrace; The patch also fixes a problem with submergers observed when a worker; was stopped because above the memory limits: this worker was; established as merger but could not do the work, for obvious reasons,; freezing the session.; Add two new methods to TProof: ShowMissingFiles() to facilitate; the display of the list of missing files; and GetMissingFiles() to get; a TFileCollection (dataset) with the missing files for further; pro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:8409,configurat,configuration,8409,proof/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html,1,['configurat'],['configuration']
Deployability,"; those of :doc:`llc <CommandGuide/llc>` and the triple is required. For example,; the following command would fuzz AArch64 with :doc:`GlobalISel/index`:. .. code-block:: shell. % bin/llvm-isel-fuzzer <corpus-dir> -ignore_remaining_args=1 -mtriple aarch64 -global-isel -O0. Some flags can also be specified in the binary name itself in order to support; OSS Fuzz, which has trouble with required arguments. To do this, you can copy; or move ``llvm-isel-fuzzer`` to ``llvm-isel-fuzzer--x-y-z``, separating options; from the binary name using ""--"". The valid options are architecture names; (``aarch64``, ``x86_64``), optimization levels (``O0``, ``O2``), or specific; keywords, like ``gisel`` for enabling global instruction selection. In this; mode, the same example could be run like so:. .. code-block:: shell. % bin/llvm-isel-fuzzer--aarch64-O0-gisel <corpus-dir>. llvm-opt-fuzzer; ---------------. A |LLVM IR fuzzer| aimed at finding bugs in optimization passes. It receives optimization pipeline and runs it for each fuzzer input. Interface of this fuzzer almost directly mirrors ``llvm-isel-fuzzer``. Both; ``mtriple`` and ``passes`` arguments are required. Passes are specified in a; format suitable for the new pass manager. You can find some documentation about; this format in the doxygen for ``PassBuilder::parsePassPipeline``. .. code-block:: shell. % bin/llvm-opt-fuzzer <corpus-dir> -ignore_remaining_args=1 -mtriple x86_64 -passes instcombine. Similarly to the ``llvm-isel-fuzzer`` arguments in some predefined configurations; might be embedded directly into the binary file name:. .. code-block:: shell. % bin/llvm-opt-fuzzer--x86_64-instcombine <corpus-dir>. llvm-mc-assemble-fuzzer; -----------------------. A |generic fuzzer| that fuzzes the MC layer's assemblers by treating inputs as; target specific assembly. Note that this fuzzer has an unusual command line interface which is not fully; compatible with all of libFuzzer's features. Fuzzer arguments must be passed; after ``--f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:3432,pipeline,pipeline,3432,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,1,['pipeline'],['pipeline']
Deployability,"; to ``LD_LIBRARY_PATH`` (Mac, Linux; ``PATH`` for both on MS Windows).; Thus, you get the conda compilers and your system libraries mixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PREFIX/lib``.; Note that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been modified, which can can lead to parsing problems if; your system C library does not support C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard with pip; ---------------------. The C++20 standard is the default on all systems as of release 3.0.1 (both; PyPI and conda-forge); it is C++17 for older releases.; When installing from PyPI using ``pip``, you can control the standard; selection by setting the ``STDCXX`` envar to '20', '17', or '14' (for Linux,; the backend does not need to be recompiled) for the 3.x releases; '17', '14',; or '11' for the 2.x releases.; Note that the build will automatically lower your choice if the compiler used; does not support a newer standard. Install from source; -------------------; .. _installation_from_source:. To build an existing release from source, tell ``pip`` to not download any; binary wheels.; Build-time only dependencies are ``cmake`` (for general build), ``python``; (obviously, but also for LLVM), and a modern C++ compiler (one that supports; at least C++14).; Use the envar ``STDCXX`` to control the C++ standard version; ``MAKE`` to; change the ``make`` command, ``MAKE_NPROCS`` to control the maximum number of; parallel jobs allowed, and ``VERBOSE=1`` to see full build/compile commands.; Example (using ``--verbos",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:4937,release,releases,4937,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,1,['release'],['releases']
Deployability,"; value is allowed. The location of the arguments are not normally recorded in the stack; map because they are already fixed by the calling convention. The; remaining ``live values`` will have their location recorded, which; could be a register, stack location, or constant. A special calling; convention has been introduced for use with stack maps, anyregcc,; which forces the arguments to be loaded into registers but allows; those register to be dynamically allocated. These argument registers; will have their register locations recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a call to the target address on the; supported targets. If the call target is constant null, then there is; no minimum requirement. A zero-byte null target patchpoint is; valid. The runtime may patch the code emitted for the patch point, including; the call sequence and nops. However, the runtime may not assume; anything about the code LLVM emits within the reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:10202,patch,patch,10202,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,2,['patch'],['patch']
Deployability,"; we generally consider reverting a normal part of development. We don't; expect contributors to be always available, and the assurance that a; problematic patch will be reverted and we can return to it at our next; opportunity enables this. What are the expectations around a revert?. * Use your best judgment. If you're uncertain, please start an email on; the commit thread asking for assistance. We aren't trying to enumerate; every case, but rather give a set of guidelines.; * You should be sure that reverting the change improves the stability of tip; of tree. Sometimes reverting one change in a series can worsen things; instead of improving them. We expect reasonable judgment to ensure that; the proper patch or set of patches is being reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following along; is critical.; * It is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:21395,patch,patch,21395,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['patch'],['patch']
Deployability,"; {; enum E; {; E1,; E2,; };. class C; {; public:; C();; };. bool baz(int i); {; try; {; do; {; switch (i); {; case 1:; {; foobar();; break;; }; default:; {; break;; }; }; } while (--i);; return true;; }; catch (...); {; handleError();; return false;; }; }. void foo(bool b); {; if (b); {; baz(2);; }; else; {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_Whitesmiths`` (in configuration: ``Whitesmiths``); Like ``Allman`` but always indent braces and line up code with braces. .. code-block:: c++. namespace N; {; enum E; {; E1,; E2,; };. class C; {; public:; C();; };. bool baz(int i); {; try; {; do; {; switch (i); {; case 1:; {; foobar();; break;; }; default:; {; break;; }; }; } while (--i);; return true;; }; catch (...); {; handleError();; return false;; }; }. void foo(bool b); {; if (b); {; baz(2);; }; else; {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_GNU`` (in configuration: ``GNU``); Always break before braces and add an extra level of indentation to; braces of control statements, not to those of class, function; or other definitions. .. code-block:: c++. namespace N; {; enum E; {; E1,; E2,; };. class C; {; public:; C();; };. bool baz(int i); {; try; {; do; {; switch (i); {; case 1:; {; foobar();; break;; }; default:; {; break;; }; }; }; while (--i);; return true;; }; catch (...); {; handleError();; return false;; }; }. void foo(bool b); {; if (b); {; baz(2);; }; else; {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_WebKit`` (in configuration: ``WebKit``); Like ``Attach``, but break before functions. .. code-block:: c++. namespace N {; enum E {; E1,; E2,; };. class C {; public:; C();; };. bool baz(int i); {; try {; do {; switch (i) {; case 1: {; foobar();; break;; }; default: {; break;; }; }; } while (--i);; return true;; } catch (...) {; handleError();; return false;; }; }. void foo(bool b); {; if (b) {; baz(2);; } else {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_Custom`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:50805,configurat,configuration,50805,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"; | | runtimes to build. (Only effective when using the |; | | full monorepo layout). The default list is empty. |; | | Can include: compiler-rt, libc, libcxx, libcxxabi, |; | | libunwind, or openmp. |; +-------------------------+----------------------------------------------------+; | LLVM_ENABLE_SPHINX | Build sphinx-based documentation from the source |; | | code. This is disabled by default because it is |; | | slow and generates a lot of output. Sphinx version |; | | 1.5 or later recommended. |; +-------------------------+----------------------------------------------------+; | LLVM_BUILD_LLVM_DYLIB | Generate libLLVM.so. This library contains a |; | | default set of LLVM components that can be |; | | overridden with ``LLVM_DYLIB_COMPONENTS``. The |; | | default contains most of LLVM and is defined in |; | | ``tools/llvm-shlib/CMakelists.txt``. This option is|; | | not available on Windows. |; +-------------------------+----------------------------------------------------+; | LLVM_OPTIMIZED_TABLEGEN | Builds a release tablegen that gets used during |; | | the LLVM build. This can dramatically speed up |; | | debug builds. |; +-------------------------+----------------------------------------------------+. To configure LLVM, follow these steps:. #. Change directory into the object root directory:. .. code-block:: console. % cd OBJ_ROOT. #. Run the ``cmake``:. .. code-block:: console. % cmake -G ""Unix Makefiles"" -DCMAKE_BUILD_TYPE=<type> -DCMAKE_INSTALL_PREFIX=/install/path; [other options] SRC_ROOT. Compiling the LLVM Suite Source Code; ------------------------------------. Unlike with autotools, with CMake your build type is defined at configuration.; If you want to change your build type, you can re-run cmake with the following; invocation:. .. code-block:: console. % cmake -G ""Unix Makefiles"" -DCMAKE_BUILD_TYPE=<type> SRC_ROOT. Between runs, CMake preserves the values set for all options. CMake has the; following build types defined:. Debug. These builds are ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:27924,release,release,27924,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['release'],['release']
Deployability,"; }. core.uninitialized.Branch; (C); Check for uninitialized values used as branch conditions. void test() {; int x;; if (x) // warn; return;; }. core.uninitialized.CapturedBlockVariable; (C); Check for blocks that capture uninitialized values. void test() {; int x;; ^{ int y = x; }(); // warn; }. core.uninitialized.UndefReturn; (C); Check for uninitialized values being returned to the caller. int test() {; int x;; return x; // warn; }. C++ Checkers. Name, DescriptionExample. cplusplus.NewDelete; (C++); Check for double-free, use-after-free and offset problems involving C++ ; delete. void f(int *p);. void testUseMiddleArgAfterDelete(int *p) {; delete p;; f(p); // warn: use after free; }. class SomeClass {; public:; void f();; };. void test() {; SomeClass *c = new SomeClass;; delete c;; c->f(); // warn: use after free; }. void test() {; int *p = (int *)__builtin_alloca(sizeof(int));; delete p; // warn: deleting memory allocated by alloca; }. void test() {; int *p = new int;; delete p;; delete p; // warn: attempt to free released; }. void test() {; int i;; delete &i; // warn: delete address of local; }. void test() {; int *p = new int[1];; delete[] (++p);; // warn: argument to 'delete[]' is offset by 4 bytes; // from the start of memory allocated by 'new[]'; }. cplusplus.NewDeleteLeaks; (C++); Check for memory leaks. Traces memory managed by new/; delete. void test() {; int *p = new int;; } // warn. Dead Code Checkers. Name, DescriptionExample. deadcode.DeadStores; (C); Check for values stored to variables that are never read afterwards. void test() {; int x;; x = 1; // warn; }. Nullability Checkers. Name, DescriptionExample. nullability.NullPassedToNonnull; (ObjC); Warns when a null pointer is passed to a pointer which has a; _Nonnull type. if (name != nil); return;; // Warning: nil passed to a callee that requires a non-null 1st parameter; NSString *greeting = [@""Hello "" stringByAppendingString:name];. nullability.NullReturnedFromNonnull; (ObjC); Warns when a null po",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/available_checks.html:5634,release,released,5634,interpreter/llvm-project/clang/www/analyzer/available_checks.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/available_checks.html,1,['release'],['released']
Deployability,";; while (i); } while (i);. .. _InsertNewlineAtEOF:. **InsertNewlineAtEOF** (``Boolean``) :versionbadge:`clang-format 16` :ref:`¶ <InsertNewlineAtEOF>`; Insert a newline at end of file if missing. .. _InsertTrailingCommas:. **InsertTrailingCommas** (``TrailingCommaStyle``) :versionbadge:`clang-format 11` :ref:`¶ <InsertTrailingCommas>`; If set to ``TCS_Wrapped`` will insert trailing commas in container; literals (arrays and objects) that wrap across multiple lines.; It is currently only available for JavaScript; and disabled by default ``TCS_None``.; ``InsertTrailingCommas`` cannot be used together with ``BinPackArguments``; as inserting the comma disables bin-packing. .. code-block:: c++. TSC_Wrapped:; const someArray = [; aaaaaaaaaaaaaaaaaaaaaaaaaa,; aaaaaaaaaaaaaaaaaaaaaaaaaa,; aaaaaaaaaaaaaaaaaaaaaaaaaa,; // ^ inserted; ]. Possible values:. * ``TCS_None`` (in configuration: ``None``); Do not insert trailing commas. * ``TCS_Wrapped`` (in configuration: ``Wrapped``); Insert trailing commas in container literals that were wrapped over; multiple lines. Note that this is conceptually incompatible with; bin-packing, because the trailing comma is used as an indicator; that a container should be formatted one-per-line (i.e. not bin-packed).; So inserting a trailing comma counteracts bin-packing. .. _IntegerLiteralSeparator:. **IntegerLiteralSeparator** (``IntegerLiteralSeparatorStyle``) :versionbadge:`clang-format 16` :ref:`¶ <IntegerLiteralSeparator>`; Format integer literal separators (``'`` for C++ and ``_`` for C#, Java,; and JavaScript). Nested configuration flags:. Separator format of integer literals of different bases. If negative, remove separators. If ``0``, leave the literal as is. If; positive, insert separators between digits starting from the rightmost; digit. For example, the config below will leave separators in binary literals; alone, insert separators in decimal literals to separate the digits into; groups of 3, and remove separators in hexadecimal lit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:76837,configurat,configuration,76837,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"<T>; void bar(T t) {... template <typename T>; void baz(T t); requires C<T>; {... * ``RCPS_WithPreceding`` (in configuration: ``WithPreceding``); Try to put the clause together with the preceding part of a declaration.; For class templates: stick to the template declaration.; For function templates: stick to the template declaration.; For function declaration followed by a requires clause: stick to the; parameter list. .. code-block:: c++. template <typename T> requires C<T>; struct Foo {... template <typename T> requires C<T>; void bar(T t) {... template <typename T>; void baz(T t) requires C<T>; {... * ``RCPS_WithFollowing`` (in configuration: ``WithFollowing``); Try to put the ``requires`` clause together with the class or function; declaration. .. code-block:: c++. template <typename T>; requires C<T> struct Foo {... template <typename T>; requires C<T> void bar(T t) {... template <typename T>; void baz(T t); requires C<T> {... * ``RCPS_SingleLine`` (in configuration: ``SingleLine``); Try to put everything in the same line if possible. Otherwise normal; line breaking rules take over. .. code-block:: c++. // Fitting:; template <typename T> requires C<T> struct Foo {... template <typename T> requires C<T> void bar(T t) {... template <typename T> void bar(T t) requires C<T> {... // Not fitting, one possible example:; template <typename LongName>; requires C<LongName>; struct Foo {... template <typename LongName>; requires C<LongName>; void bar(LongName ln) {. template <typename LongName>; void bar(LongName ln); requires C<LongName> {. .. _RequiresExpressionIndentation:. **RequiresExpressionIndentation** (``RequiresExpressionIndentationKind``) :versionbadge:`clang-format 16` :ref:`¶ <RequiresExpressionIndentation>`; The indentation used for requires expression bodies. Possible values:. * ``REI_OuterScope`` (in configuration: ``OuterScope``); Align requires expression body relative to the indentation level of the; outer scope the requires expression resides in.; This",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:105548,configurat,configuration,105548,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"<make program> install``. More information on standalone builds can be found in the build documentation for; the respective libraries. The next section discuss the salient options and modifications; required for building and installing the libraries using standalone builds. This assumes; that we are building libunwind and ibc++ as DLLs and statically linking libc++abi into; libc++. Other build configurations are possible, but they are not discussed here. Common CMake configuration options:; -----------------------------------. * ``-D_LIBCPP_ABI_FORCE_ITANIUM'``. Tell the libc++ headers that the Itanium C++ ABI is being used. * ``-DCMAKE_C_FLAGS=""-lmsvcrt -llegacy_stdio_definitions -D_NO_CRT_STDIO_INLINE""``. Supply CRT definitions including stdio definitions that have been removed from the MS VS CRT.; We don't want the stdio functions declared inline as they will cause multiple definition; errors when the same symbols are pulled in from legacy_stdio_definitions.ib. * ``-DCMAKE_INSTALL_PREFIX=<install path>``. Where to install the library and headers. Building libunwind:; -------------------. * ``-DLIBUNWIND_ENABLE_SHARED=ON``; * ``-DLIBUNWIND_ENABLE_STATIC=OFF``. libunwind can be built as a DLL. It is not dependent on other projects. * ``-DLIBUNWIND_USE_COMPILER_RT=OFF``. We use the MS runtime. The CMake files will need to be edited to prevent them adding GNU specific libraries to the link line. Building libc++abi:; -------------------. * ``-DLIBCXXABI_ENABLE_SHARED=OFF``; * ``-DLIBCXXABI_ENABLE_STATIC=ON``; * ``-DLIBCXX_ENABLE_SHARED=ON'``; * ``-DLIBCXX_ENABLE_STATIC_ABI_LIBRARY=ON``. To break the symbol dependency between libc++abi and libc++ we; build libc++abi as a static library and then statically link it; into the libc++ DLL. This necessitates setting the CMake file; to ensure that the visibility macros (which expand to dllexport/import); are expanded as they will be needed when creating the final libc++; DLL later, see: https://reviews.llvm.org/D90021. * ``-DL",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildWindowsItaniumPrograms.rst:4621,install,install,4621,interpreter/llvm-project/llvm/docs/HowToBuildWindowsItaniumPrograms.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildWindowsItaniumPrograms.rst,1,['install'],['install']
Deployability,"=<dir>][--with-python-libdir=>dir>]`. For details on `<arch>` see the official build pages, the Python include; directory should point to the directory that contains `Python.h` and the; library directory should point to the directory containing; `libpythonx.y.so`, where '`x`' and '`y`' are the major and minor version; number, respectively. If you do not specify include and library; directories explicitly, the configuration process will try the; `PYTHONDIR` environment variable or, alternatively, the standard; locations. A recent distribution of Python is required: version 2.4.3 is preferred,; but the older 2.2.x and 2.3.x versions suffice and are supported as; well. Versions older than 2.2 are not supported and will not work. Note; that one problem with 2.2 is that the shared library of the `Python`; interpreter core is not build by default and the '--enable-shared' flag; should thus be used when building `Python` from source. If the `Python`; interpreter that is installed on your system is too old, please obtain a; new version from <http://www.python.org>. Once configured, you continue the build process the normal way:. `$ make`. `$ make install`. After some time, a library called `libPyROOT.so` (or `libPyROOT.dll`, on; Windows) will be created in the; `$ROOTSYS/lib `(`$ROOTSYS/bin on Windows`) directory and a top Python; module, `ROOT.py`, will be copied into the same place. The final step is; to setup the shell environment, which is similar to what is described in; the chapter ‘Environment Settings'. Note that the `$ROOTSYS` entries are; probably already there if you followed the standard instructions, and; that the `PYTHONDIR` entries should be replaced as appropriate by your; choice at configuration time, or be left out if you had the; configuration script pick up them up from a default location. ### Using PyROOT. Since it is an extension module, the usage of `PyROOT` probably comes; naturally if you're used to Python. In general, `PyROOT` attempts to; allow wor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:8131,install,installed,8131,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['install'],['installed']
Deployability,"==. .. contents::; :local:. Description; ===========. LLVM features powerful intermodular optimizations which can be used at link; time. Link Time Optimization (LTO) is another name for intermodular; optimization when performed during the link stage. This document describes the; interface and design between the LTO optimizer and the linker. Design Philosophy; =================. The LLVM Link Time Optimizer provides complete transparency, while doing; intermodular optimization, in the compiler tool chain. Its main goal is to let; the developer take advantage of intermodular optimizations without making any; significant changes to the developer's makefiles or build system. This is; achieved through tight integration with the linker. In this model, the linker; treats LLVM bitcode files like native object files and allows mixing and; matching among them. The linker uses `libLTO`_, a shared object, to handle LLVM; bitcode files. This tight integration between the linker and LLVM optimizer; helps to do optimizations that are not possible in other models. The linker; input allows the optimizer to avoid relying on conservative escape analysis. .. _libLTO-example:. Example of link time optimization; ---------------------------------. The following example illustrates the advantages of LTO's integrated approach; and clean interface. This example requires a system linker which supports LTO; through the interface described in this document. Here, clang transparently; invokes system linker. * Input source file ``a.c`` is compiled into LLVM bitcode form.; * Input source file ``main.c`` is compiled into native object code. .. code-block:: c++. --- a.h ---; extern int foo1(void);; extern void foo2(void);; extern void foo4(void);. --- a.c ---; #include ""a.h"". static signed int i = 0;. void foo2(void) {; i = -1;; }. static int foo3() {; foo4();; return 10;; }. int foo1(void) {; int data = 0;. if (i < 0); data = foo3();. data = data + 42;; return data;; }. --- main.c ---; #include <std",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:1113,integrat,integration,1113,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['integrat'],['integration']
Deployability,"===. The Cling Packaging Tool is a command-line utility written in Python to build; Cling from source and generate installer bundles for a wide range of platforms. Cling maintains its own vendor clones of LLVM and Clang (part of ROOT's trunk); on which it is based. This tool is the easiest way to build Cling for your favorite; platorm and bundle it into an installer. If you want to manually compile Cling; from source, go through the [README] of Cling or the build instructions [here]. [README]:https://github.com/root-project/cling/blob/master/README.md; [here]:https://root.cern/cling/cling_build_instructions/. Below is a list of platforms currently supported by CPT:; * Ubuntu and distros based on Debian - *DEB packages*; * Windows - *NSIS installers*; * Distros based on Red Hat Linux (Fedora/Scientific Linux CERN) - *RPM packages*; * Mac OS X - *Apple Disk Images*; * Virtually any UNIX-like platform which supports Bash - *Tarballs*. ### Requirements; Before using this tool, make sure you have the required packages installed on; your system. Detailed information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:1080,install,installed,1080,interpreter/cling/tools/packaging/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md,1,['install'],['installed']
Deployability,"==== ==========================================. .. note::. #. Only needed if you want to run the automated test suite in the; ``llvm/test`` directory.; #. Optional, adds compression / uncompression capabilities to selected LLVM; tools.; #. Optional, you can use any other build tool supported by CMake. Additionally, your compilation host is expected to have the usual plethora of; Unix utilities. Specifically:. * **ar** --- archive library builder; * **bzip2** --- bzip2 command for distribution generation; * **bunzip2** --- bunzip2 command for distribution checking; * **chmod** --- change permissions on a file; * **cat** --- output concatenation utility; * **cp** --- copy files; * **date** --- print the current date/time; * **echo** --- print to standard output; * **egrep** --- extended regular expression search utility; * **find** --- find files/dirs in a file system; * **grep** --- regular expression search utility; * **gzip** --- gzip command for distribution generation; * **gunzip** --- gunzip command for distribution checking; * **install** --- install directories/files; * **mkdir** --- create a directory; * **mv** --- move (rename) files; * **ranlib** --- symbol table builder for archive libraries; * **rm** --- remove (delete) files and directories; * **sed** --- stream editor for transforming output; * **sh** --- Bourne shell for make build scripts; * **tar** --- tape archive for distribution generation; * **test** --- test things in file system; * **unzip** --- unzip command for distribution checking; * **zip** --- zip command for distribution generation. .. _below:; .. _check here:. Host C++ Toolchain, both Compiler and Standard Library; ------------------------------------------------------. LLVM is very demanding of the host C++ compiler, and as such tends to expose; bugs in the compiler. We also attempt to follow improvements and developments in; the C++ language and library reasonably closely. As such, we require a modern; host C++ toolchain, both compile",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:12114,install,install,12114,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,2,['install'],['install']
Deployability,"====== ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved after the; seq_cst.; - If a store atomic then the same constraints as release, plus; no following sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved before the; seq_cst.; - If an atomicrmw/fence then same constraints as acq_rel.; ============ ==============================================================. The code sequences used to implement the memory model are defined in the; following sections:. * :ref:`amdgpu-amdhsa-memory-model-gfx6-gfx9`; * :ref:`amdgpu-amdhsa-memory-model-gfx90a`; * :ref:`amdgpu-amdhsa-memory-model-gfx942`; * :ref:`amdgpu-amdhsa-memory-model-gfx10-gfx11`. .. _amdgpu-amdhsa-memory-model-gfx6-gfx9:. Memory Model GFX6-GFX9; ++++++++++++++++++++++. For GFX6-GFX9:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it.; * All LDS operations of a C",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:205588,release,release,205588,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability,"=======. One of the first things that you should do when designing a new pass is to; decide what class you should subclass for your pass. The :ref:`Hello World; <writing-an-llvm-pass-basiccode>` example uses the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` class for its implementation, but we did; not discuss why or when this should occur. Here we talk about the classes; available, from the most general to the most specific. When choosing a superclass for your ``Pass``, you should choose the **most; specific** class possible, while still being able to meet the requirements; listed. This gives the LLVM Pass Infrastructure information necessary to; optimize how passes are run, so that the resultant compiler isn't unnecessarily; slow. The ``ImmutablePass`` class; ---------------------------. The most plain and boring type of pass is the ""`ImmutablePass; <https://llvm.org/doxygen/classllvm_1_1ImmutablePass.html>`_"" class. This pass; type is used for passes that do not have to be run, do not change state, and; never need to be updated. This is not a normal type of transformation or; analysis, but can provide information about the current compiler configuration. Although this pass class is very infrequently used, it is important for; providing information about the current target machine being compiled for, and; other static information that can affect the various transformations. ``ImmutablePass``\ es never invalidate other transformations, are never; invalidated, and are never ""run"". .. _writing-an-llvm-pass-ModulePass:. The ``ModulePass`` class; ------------------------. The `ModulePass <https://llvm.org/doxygen/classllvm_1_1ModulePass.html>`_ class; is the most general of all superclasses that you can use. Deriving from; ``ModulePass`` indicates that your pass uses the entire program as a unit,; referring to function bodies in no predictable order, or adding and removing; functions. Because nothing is known about the behavior of ``ModulePass``; subclasses, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:12153,update,updated,12153,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['update'],['updated']
Deployability,"=======; Remarks; =======. .. contents::; :local:. Introduction to the LLVM remark diagnostics; ===========================================. LLVM is able to emit diagnostics from passes describing whether an optimization; has been performed or missed for a particular reason, which should give more; insight to users about what the compiler did during the compilation pipeline. There are three main remark types:. ``Passed``. Remarks that describe a successful optimization performed by the compiler. :Example:. ::. foo inlined into bar with (cost=always): always inline attribute. ``Missed``. Remarks that describe an attempt to an optimization by the compiler that; could not be performed. :Example:. ::. foo not inlined into bar because it should never be inlined; (cost=never): noinline function attribute. ``Analysis``. Remarks that describe the result of an analysis, that can bring more; information to the user regarding the generated code. :Example:. ::. 16 stack bytes in function. ::. 10 instructions in function. Enabling optimization remarks; =============================. There are two modes that are supported for enabling optimization remarks in; LLVM: through remark diagnostics, or through serialized remarks. Remark diagnostics; ------------------. Optimization remarks can be emitted as diagnostics. These diagnostics will be; propagated to front-ends if desired, or emitted by tools like :doc:`llc; <CommandGuide/llc>` or :doc:`opt <CommandGuide/opt>`. .. option:: -pass-remarks=<regex>. Enables optimization remarks from passes whose name match the given (POSIX); regular expression. .. option:: -pass-remarks-missed=<regex>. Enables missed optimization remarks from passes whose name match the given; (POSIX) regular expression. .. option:: -pass-remarks-analysis=<regex>. Enables optimization analysis remarks from passes whose name match the given; (POSIX) regular expression. Serialized remarks; ------------------. While diagnostics are useful during development, it is oft",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst:368,pipeline,pipeline,368,interpreter/llvm-project/llvm/docs/Remarks.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst,1,['pipeline'],['pipeline']
Deployability,"======== ========= ======================================================================; ""amdpal.version"" sequence of Required PAL code object metadata (major, minor) version. The current values; 2 integers are defined by *Util::Abi::PipelineMetadata(Major|Minor)Version*.; ""amdpal.pipelines"" sequence of Required Per-pipeline metadata. See; map :ref:`amdgpu-amdpal-code-object-pipeline-metadata-map-table` for the; definition of the keys included in that map.; =================== ============== ========= ======================================================================. .. .. table:: AMDPAL Code Object Pipeline Metadata Map; :name: amdgpu-amdpal-code-object-pipeline-metadata-map-table. ====================================== ============== ========= ===================================================; String Key Value Type Required? Description; ====================================== ============== ========= ===================================================; "".name"" string Source name of the pipeline.; "".type"" string Pipeline type, e.g. VsPs. Values include:. - ""VsPs""; - ""Gs""; - ""Cs""; - ""Ngg""; - ""Tess""; - ""GsTess""; - ""NggTess"". "".internal_pipeline_hash"" sequence of Required Internal compiler hash for this pipeline. Lower; 2 integers 64 bits is the ""stable"" portion of the hash, used; for e.g. shader replacement lookup. Upper 64 bits; is the ""unique"" portion of the hash, used for; e.g. pipeline cache lookup. The value is; implementation defined, and can not be relied on; between different builds of the compiler.; "".shaders"" map Per-API shader metadata. See; :ref:`amdgpu-amdpal-code-object-shader-map-table`; for the definition of the keys included in that; map.; "".hardware_stages"" map Per-hardware stage metadata. See; :ref:`amdgpu-amdpal-code-object-hardware-stage-map-table`; for the definition of the keys included in that; map.; "".shader_functions"" map Per-shader function metadata. See; :ref:`amdgpu-amdpal-code-object-shader-function-map-table`; for the definition",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:403560,pipeline,pipeline,403560,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['pipeline'],['pipeline']
Deployability,"========. Building the SelectionDAG; -------------------------. The function SelectionDAGBuilder::visitConstrainedFPIntrinsic builds DAG nodes; using mappings specified in ConstrainedOps.def. If however this default build is; not sufficient, the build can be modified, see how it is implemented for; STRICT_FP_ROUND. The new STRICT node will eventually be converted; to the matching non-STRICT node. For this reason it should have the same; operands and values as the non-STRICT version but should also use the chain.; This makes subsequent sharing of code for STRICT and non-STRICT code paths; easier::. lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp. Most of the STRICT nodes get legalized the same as their matching non-STRICT; counterparts. A new STRICT node with this property must get added to the; switch in SelectionDAGLegalize::LegalizeOp().::. lib/CodeGen/SelectionDAG/LegalizeDAG.cpp. Other parts of the legalizer may need to be updated as well. Look for; places where the non-STRICT counterpart is legalized and update as needed.; Be careful of the chain since STRICT nodes use it but their counterparts; often don't. The code to do the conversion or mutation of the STRICT node to a non-STRICT; version of the node happens in SelectionDAG::mutateStrictFPToFP(). In most cases; the function can do the conversion using information from ConstrainedOps.def. Be; careful updating this function since some nodes have the same return type; as their input operand, but some are different. Both of these cases must; be properly handled::. lib/CodeGen/SelectionDAG/SelectionDAG.cpp. Whether the mutation may happens or not, depends on how the new node has been; registered in TargetLoweringBase::initActions(). By default all strict nodes are; registered with Expand action::. lib/CodeGen/TargetLoweringBase.cpp. To make debug logs readable it is helpful to update the SelectionDAG's; debug logger:::. lib/CodeGen/SelectionDAG/SelectionDAGDumper.cpp. Add documentation and tests; ===============",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AddingConstrainedIntrinsics.rst:2135,update,update,2135,interpreter/llvm-project/llvm/docs/AddingConstrainedIntrinsics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AddingConstrainedIntrinsics.rst,1,['update'],['update']
Deployability,"=========; LibFormat; =========. LibFormat is a library that implements automatic source code formatting based; on Clang. This documents describes the LibFormat interface and design as well; as some basic style discussions. If you just want to use `clang-format` as a tool or integrated into an editor,; checkout :doc:`ClangFormat`. Design; ------. FIXME: Write up design. Interface; ---------. The core routine of LibFormat is ``reformat()``:. .. code-block:: c++. tooling::Replacements reformat(const FormatStyle &Style, Lexer &Lex,; SourceManager &SourceMgr,; std::vector<CharSourceRange> Ranges);. This reads a token stream out of the lexer ``Lex`` and reformats all the code; ranges in ``Ranges``. The ``FormatStyle`` controls basic decisions made during; formatting. A list of options can be found under :ref:`style-options`. The style options are described in :doc:`ClangFormatStyleOptions`. .. _style-options:. Style Options; -------------. The style options describe specific formatting options that can be used in; order to make `ClangFormat` comply with different style guides. Currently,; several style guides are hard-coded:. .. code-block:: c++. /// Returns a format style complying with the LLVM coding standards:; /// https://llvm.org/docs/CodingStandards.html.; FormatStyle getLLVMStyle();. /// Returns a format style complying with Google's C++ style guide:; /// http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml.; FormatStyle getGoogleStyle();. /// Returns a format style complying with Chromium's style guide:; /// https://chromium.googlesource.com/chromium/src/+/refs/heads/main/styleguide/styleguide.md; FormatStyle getChromiumStyle();. /// Returns a format style complying with the GNU coding standards:; /// https://www.gnu.org/prep/standards/standards.html; FormatStyle getGNUStyle();. /// Returns a format style complying with Mozilla's style guide; /// https://firefox-source-docs.mozilla.org/code-quality/coding-style/index.html; FormatStyle getMozillaStyle();",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibFormat.rst:276,integrat,integrated,276,interpreter/llvm-project/clang/docs/LibFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibFormat.rst,1,['integrat'],['integrated']
Deployability,"==========. Clang Tooling provides infrastructure to write tools that need syntactic; and semantic information about a program. This term also relates to a set; of specific tools using this infrastructure (e.g. ``clang-check``). This; document provides information on how to set up and use Clang Tooling for; the LLVM source code. Introduction; ============. Clang Tooling needs a compilation database to figure out specific build; options for each file. Currently it can create a compilation database; from the ``compile_commands.json`` file, generated by CMake. When; invoking clang tools, you can either specify a path to a build directory; using a command line parameter ``-p`` or let Clang Tooling find this; file in your source tree. In either case you need to configure your; build using CMake to use clang tools. Setup Clang Tooling Using CMake and Make; ========================================. If you intend to use make to build LLVM, you should have CMake 2.8.6 or; later installed (can be found `here <https://cmake.org>`_). First, you need to generate Makefiles for LLVM with CMake. You need to; make a build directory and run CMake from it:. .. code-block:: console. $ mkdir your/build/directory; $ cd your/build/directory; $ cmake -DCMAKE_EXPORT_COMPILE_COMMANDS=ON path/to/llvm/sources. If you want to use clang instead of GCC, you can add; ``-DCMAKE_C_COMPILER=/path/to/clang -DCMAKE_CXX_COMPILER=/path/to/clang++``.; You can also use ``ccmake``, which provides a curses interface to configure; CMake variables. As a result, the new ``compile_commands.json`` file should appear in the; current directory. You should link it to the LLVM source tree so that; Clang Tooling is able to use it:. .. code-block:: console. $ ln -s $PWD/compile_commands.json path/to/llvm/source/. Now you are ready to build and test LLVM using make:. .. code-block:: console. $ make check-all. Setup Clang Tooling Using CMake on Windows; ==========================================. For Windows developers, t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HowToSetupToolingForLLVM.rst:1083,install,installed,1083,interpreter/llvm-project/clang/docs/HowToSetupToolingForLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HowToSetupToolingForLLVM.rst,1,['install'],['installed']
Deployability,"===========. In the common case, a value is available in a register, and the; ``Offset`` field will be zero. Values spilled to the stack are encoded; as ``Indirect`` locations. The runtime must load those values from a; stack address, typically in the form ``[BP + Offset]``. If an; ``alloca`` value is passed directly to a stack map intrinsic, then; LLVM may fold the frame index into the stack map as an optimization to; avoid allocating a register or stack slot. These frame indices will be; encoded as ``Direct`` locations in the form ``BP + Offset``. LLVM may; also optimize constants by emitting them directly in the stack map,; either in the ``Offset`` of a ``Constant`` location or in the constant; pool, referred to by ``ConstantIndex`` locations. At each callsite, a ""liveout"" register list is also recorded. These; are the registers that are live across the stackmap and therefore must; be saved by the runtime. This is an important optimization when the; patchpoint intrinsic is used with a calling convention that by default; preserves most registers as callee-save. Each entry in the liveout register list contains a DWARF register; number and size in bytes. The stackmap format deliberately omits; specific subregister information. Instead the runtime must interpret; this information conservatively. For example, if the stackmap reports; one byte at ``%rax``, then the value may be in either ``%al`` or; ``%ah``. It doesn't matter in practice, because the runtime will; simply save ``%rax``. However, if the stackmap reports 16 bytes at; ``%ymm0``, then the runtime can safely optimize by saving only; ``%xmm0``. The stack map format is a contract between an LLVM SVN revision and; the runtime. It is currently experimental and may change in the short; term, but minimizing the need to update the runtime is; important. Consequently, the stack map design is motivated by; simplicity and extensibility. Compactness of the representation is; secondary because the runtime is expected to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:14672,patch,patchpoint,14672,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['patch'],['patchpoint']
Deployability,"===========; ClangFormat; ===========. `ClangFormat` describes a set of tools that are built on top of; :doc:`LibFormat`. It can support your workflow in a variety of ways including a; standalone tool and editor integrations. Standalone Tool; ===============. :program:`clang-format` is located in `clang/tools/clang-format` and can be used; to format C/C++/Java/JavaScript/JSON/Objective-C/Protobuf/C# code. .. START_FORMAT_HELP. .. code-block:: console. $ clang-format --help; OVERVIEW: A tool to format C/C++/Java/JavaScript/JSON/Objective-C/Protobuf/C# code. If no arguments are specified, it formats the code from standard input; and writes the result to the standard output.; If <file>s are given, it reformats the files. If -i is specified; together with <file>s, the files are edited in-place. Otherwise, the; result is written to the standard output. USAGE: clang-format [options] [@<file>] [<file> ...]. OPTIONS:. Clang-format options:. --Werror - If set, changes formatting warnings to errors; --Wno-error=<value> - If set don't error out on the specified warning type.; =unknown - If set, unknown format options are only warned about.; This can be used to enable formatting, even if the; configuration contains unknown (newer) options.; Use with caution, as this might lead to dramatically; differing format depending on an option being; supported or not.; --assume-filename=<string> - Set filename used to determine the language and to find; .clang-format file.; Only used when reading from stdin.; If this is not passed, the .clang-format file is searched; relative to the current working directory when reading stdin.; Unrecognized filenames are treated as C++.; supported:; CSharp: .cs; Java: .java; JavaScript: .mjs .js .ts; Json: .json; Objective-C: .m .mm; Proto: .proto .protodevel; TableGen: .td; TextProto: .textpb .pb.txt .textproto .asciipb; Verilog: .sv .svh .v .vh; --cursor=<uint> - The position of the cursor when invoking; clang-format from an editor integration; --dry-ru",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst:212,integrat,integrations,212,interpreter/llvm-project/clang/docs/ClangFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst,1,['integrat'],['integrations']
Deployability,"============. LLVM supports (to various degrees) a number of experimental extensions. All experimental extensions have ``experimental-`` as a prefix. There is explicitly no compatibility promised between versions of the toolchain, and regular users are strongly advised *not* to make use of experimental extensions before they reach ratification. The primary goal of experimental support is to assist in the process of ratification by providing an existence proof of an implementation, and simplifying efforts to validate the value of a proposed extension against large code bases. Experimental extensions are expected to either transition to ratified status, or be eventually removed. The decision on whether to accept an experimental extension is currently done on an entirely case by case basis; if you want to propose one, attending the bi-weekly RISC-V sync-up call is strongly advised. ``experimental-zacas``; LLVM implements the `1.0-rc1 draft specification <https://github.com/riscv/riscv-zacas/releases/tag/v1.0-rc1>`_. ``experimental-zfbfmin``, ``experimental-zvfbfmin``, ``experimental-zvfbfwma``; LLVM implements assembler support for the `1.0.0-rc2 specification <https://github.com/riscv/riscv-bfloat16/releases/tag/v59042fc71c31a9bcb2f1957621c960ed36fac401>`_. ``experimental-zicfilp``, ``experimental-zicfiss``; LLVM implements the `0.4 draft specification <https://github.com/riscv/riscv-cfi/releases/tag/v0.4.0>`__. ``experimental-ztso``; LLVM implements the `v0.1 proposed specification <https://github.com/riscv/riscv-isa-manual/releases/download/draft-20220723-10eea63/riscv-spec.pdf>`__ (see Chapter 25). The mapping from the C/C++ memory model to Ztso has not yet been ratified in any standards document. There are multiple possible mappings, and they are *not* mutually ABI compatible. The mapping LLVM implements is ABI compatible with the default WMO mapping. This mapping may change and there is *explicitly* no ABI stability offered while the extension remains in experime",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/RISCVUsage.rst:10470,release,releases,10470,interpreter/llvm-project/llvm/docs/RISCVUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/RISCVUsage.rst,1,['release'],['releases']
Deployability,"============; 0 1 bit ENABLE_PRIVATE_SEGMENT * Enable the setup of the; private segment.; * If the *Target Properties*; column of; :ref:`amdgpu-processor-table`; does not specify; *Architected flat; scratch* then enable the; setup of the SGPR; wavefront scratch offset; system register (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`).; * If the *Target Properties*; column of; :ref:`amdgpu-processor-table`; specifies *Architected; flat scratch* then enable; the setup of the; FLAT_SCRATCH register; pair (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). Used by CP to set up; ``COMPUTE_PGM_RSRC2.SCRATCH_EN``.; 5:1 5 bits USER_SGPR_COUNT The total number of SGPR; user data; registers requested. This; number must be greater than; or equal to the number of user; data registers enabled. Used by CP to set up; ``COMPUTE_PGM_RSRC2.USER_SGPR``.; 6 1 bit ENABLE_TRAP_HANDLER GFX6-GFX11; Must be 0. This bit represents; ``COMPUTE_PGM_RSRC2.TRAP_PRESENT``,; which is set by the CP if; the runtime has installed a; trap handler.; GFX12; Reserved, must be 0.; 7 1 bit ENABLE_SGPR_WORKGROUP_ID_X Enable the setup of the; system SGPR register for; the work-group id in the X; dimension (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). Used by CP to set up; ``COMPUTE_PGM_RSRC2.TGID_X_EN``.; 8 1 bit ENABLE_SGPR_WORKGROUP_ID_Y Enable the setup of the; system SGPR register for; the work-group id in the Y; dimension (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). Used by CP to set up; ``COMPUTE_PGM_RSRC2.TGID_Y_EN``.; 9 1 bit ENABLE_SGPR_WORKGROUP_ID_Z Enable the setup of the; system SGPR register for; the work-group id in the Z; dimension (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). Used by CP to set up; ``COMPUTE_PGM_RSRC2.TGID_Z_EN``.; 10 1 bit ENABLE_SGPR_WORKGROUP_INFO Enable the setup of the; system SGPR register for; work-group information (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). Used by CP to set up; ``COMPUTE_PGM_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:171810,install,installed,171810,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['install'],['installed']
Deployability,============= ===============================================================================; Value Name Description; ========== ================= ===============================================================================; 0..127 *User Data Entry* 32-bit value of user_data_entry[N] as specified via *CmdSetUserData()*; 0x10000000 GlobalTable 32-bit pointer to GPU memory containing the global internal table (should; always point to *user data register* 0).; 0x10000001 PerShaderTable 32-bit pointer to GPU memory containing the per-shader internal table. See; :ref:`amdgpu-amdpal-code-object-metadata-user-data-per-shader-table-section`; for more detail (should always point to *user data register* 1).; 0x10000002 SpillTable 32-bit pointer to GPU memory containing the user data spill table. See; :ref:`amdgpu-amdpal-code-object-metadata-user-data-spill-table-section` for; more detail.; 0x10000003 BaseVertex Vertex offset (32-bit unsigned integer). Not needed if the pipeline doesn't; reference the draw index in the vertex shader. Only supported by the first; stage in a graphics pipeline.; 0x10000004 BaseInstance Instance offset (32-bit unsigned integer). Only supported by the first stage in; a graphics pipeline.; 0x10000005 DrawIndex Draw index (32-bit unsigned integer). Only supported by the first stage in a; graphics pipeline.; 0x10000006 Workgroup Thread group count (32-bit unsigned integer). Low half of a 64-bit address of; a buffer containing the grid dimensions for a Compute dispatch operation. The; high half of the address is stored in the next sequential user-SGPR. Only; supported by compute pipelines.; 0x1000000A EsGsLdsSize Indicates that PAL will program this user-SGPR to contain the amount of LDS; space used for the ES/GS pseudo-ring-buffer for passing data between shader; stages.; 0x1000000B ViewId View id (32-bit unsigned integer) identifies a view of graphic; pipeline instancing.; 0x1000000C StreamOutTable 32-bit pointer to GPU memory containing the strea,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:416159,pipeline,pipeline,416159,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['pipeline'],['pipeline']
Deployability,"=============; Hwreg Value Syntax Description; ==================================== ===============================================================================; hwreg({0..63}) All bits of a register indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_REG_STATUS Shader read-only status.; HW_REG_TRAPSTS Trap status.; HW_REG_HW_ID1 Id of wave, simd, compute unit, etc.; HW_REG_HW_ID2 Id of queue, pipeline, etc.; HW_REG_GPR_ALLOC Per-wave SGPR and VGPR allocation.; HW_REG_LDS_ALLOC Per-wave LDS allocation.; HW_REG_IB_STS Counters of outstanding instructions.; HW_REG_SH_MEM_BASES Memory aperture.; HW_REG_FLAT_SCR_LO flat_scratch_lo register.; HW_REG_FLAT_SCR_HI flat_scratch_hi register.; ============================== ==========================================. Examples:. .. parsed-literal::. reg = 1; offset = 2; size = 4; hwreg_enc = reg | (offset << 6) | ((size - 1) << 11). s_getreg_b32 s2, 0x1881; s_getreg_b32 s2, hwreg_enc // the same as above; s_getreg_b32 s2, hwreg(1, 2, 4) // the same as above; s_getreg_b32 s2, hwreg(reg, offset, size) // the same as above. s_getreg_b32 s2, hwreg(15); s_getreg_b32 s2, hwreg(51, 1, 31); s_getreg_b32 s2, hwreg(HW_REG_LDS_ALLOC, 0, 1); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_hwreg.rst:2146,pipeline,pipeline,2146,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_hwreg.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_hwreg.rst,1,['pipeline'],['pipeline']
Deployability,"==============. .. .. table:: compute_pgm_rsrc3 for GFX12; :name: amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table. ======= ======= =============================== ===========================================================================; Bits Size Field Name Description; ======= ======= =============================== ===========================================================================; 3:0 4 bits RESERVED Reserved, must be 0.; 11:4 8 bits INST_PREF_SIZE Number of instruction bytes to prefetch, starting at the kernel's entry; point instruction, before wavefront starts execution. The value is 0..255; with a granularity of 128 bytes.; 12 1 bit RESERVED Reserved, must be 0.; 13 1 bit GLG_EN If 1, group launch guarantee will be enabled for this dispatch; 30:14 17 bits RESERVED Reserved, must be 0.; 31 1 bit IMAGE_OP If 1, the kernel execution contains image instructions. If executed as; part of a graphics pipeline, image read instructions will stall waiting; for any necessary ``WAIT_SYNC`` fence to be performed in order to; indicate that earlier pipeline stages have completed writing to the; image. Not used for compute kernels that are not part of a graphics pipeline and; must be 0.; 32 **Total size 4 bytes.**; ======= ===================================================================================================================. .. .. table:: Floating Point Rounding Mode Enumeration Values; :name: amdgpu-amdhsa-floating-point-rounding-mode-enumeration-values-table. ====================================== ===== ==============================; Enumeration Name Value Description; ====================================== ===== ==============================; FLOAT_ROUND_MODE_NEAR_EVEN 0 Round Ties To Even; FLOAT_ROUND_MODE_PLUS_INFINITY 1 Round Toward +infinity; FLOAT_ROUND_MODE_MINUS_INFINITY 2 Round Toward -infinity; FLOAT_ROUND_MODE_ZERO 3 Round Toward 0; ====================================== ===== ==============================. .. table:: Extended FLT_ROUNDS En",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:179235,pipeline,pipeline,179235,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['pipeline'],['pipeline']
Deployability,"==============; MyFirstTypoFix; ==============. .. contents::; :local:. Introduction; ============. This tutorial will guide you through the process of making a change to; LLVM, and contributing it back to the LLVM project. We'll be making a; change to Clang, but the steps for other parts of LLVM are the same.; Even though the change we'll be making is simple, we're going to cover; steps like building LLVM, running the tests, and code review. This is; good practice, and you'll be prepared for making larger changes. We'll assume you:. - know how to use an editor,. - have basic C++ knowledge,. - know how to install software on your system,. - are comfortable with the command line,. - have basic knowledge of git. The change we're making; -----------------------. Clang has a warning for infinite recursion:. .. code:: console. $ echo ""void foo() { foo(); }"" > ~/test.cc; $ clang -c -Wall ~/test.cc; input.cc:1:14: warning: all paths through this function will call; itself [-Winfinite-recursion]. This is clear enough, but not exactly catchy. Let's improve the wording; a little:. .. code:: console. input.cc:1:14: warning: to understand recursion, you must first; understand recursion [-Winfinite-recursion]. Dependencies; ------------. We're going to need some tools:. - git: to check out the LLVM source code,. - a C++ compiler: to compile LLVM source code. You'll want `a recent; version <https://llvm.org/docs/GettingStarted.html#host-c-toolchain-both-compiler-and-standard-library>`__; of Clang, GCC, or Visual Studio. - CMake: used to configure how LLVM should be built on your system,. - ninja: runs the C++ compiler to (re)build specific parts of LLVM,. - python: to run the LLVM tests,. As an example, on Ubuntu:. .. code:: console. $ sudo apt-get install git clang cmake ninja-build python arcanist. Building LLVM; =============. Checkout; --------. The source code is stored `on; Github <https://github.com/llvm/llvm-project>`__ in one large repository; (""the monorepo""). It may tak",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst:613,install,install,613,interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst,1,['install'],['install']
Deployability,"==============; lit Examples; ==============. This directory contains examples of 'lit' test suite configurations. The test; suites they define can be run with 'lit examples/example-name', for more details; see the README in each example.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/lit/examples/README.txt:99,configurat,configurations,99,interpreter/llvm-project/llvm/utils/lit/examples/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/lit/examples/README.txt,1,['configurat'],['configurations']
Deployability,"================ =========================; *release branch: even releases* *4th Tue in January*; *release branch: odd releases* *4th Tue in July*; X.1.0-rc1 3 days after branch.; X.1.0-rc2 2 weeks after branch.; X.1.0-rc3 4 weeks after branch; **X.1.0-final** **6 weeks after branch**; **X.1.1** **8 weeks after branch**; **X.1.2** **10 weeks after branch**; **X.1.3** **12 weeks after branch**; **X.1.4** **14 weeks after branch**; **X.1.5** **16 weeks after branch**; **X.1.6 (if necessary)** **18 weeks after branch**; =============================== =========================. Release Process Summary; -----------------------. * Announce release schedule to the LLVM community and update the website. Do; this at least 3 weeks before the -rc1 release. * Create release branch and begin release process. * Send out release candidate sources for first round of testing. Testing lasts; 6 weeks. During the first round of testing, any regressions found should be; fixed. Patches are merged from mainline into the release branch. Also, all; features need to be completed during this time. Any features not completed at; the end of the first round of testing will be removed or disabled for the; release. * Generate and send out the second release candidate sources. Only *critical*; bugs found during this testing phase will be fixed. Any bugs introduced by; merged patches will be fixed. If so a third round of testing is needed. * The release notes are updated. * Finally, release!. * Announce bug fix release schedule to the LLVM community and update the website. * Do bug-fix releases every two weeks until X.1.5 or X.1.6 (if necessary). Release Process; ===============. .. contents::; :local:. Release Administrative Tasks; ----------------------------. This section describes a few administrative tasks that need to be done for the; release process to begin. Specifically, it involves:. * Updating version numbers,. * Creating the release branch, and. * Tagging release candidates for the rele",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:2453,release,release,2453,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['release'],['release']
Deployability,"================; AddressSanitizer; ================. .. contents::; :local:. Introduction; ============. AddressSanitizer is a fast memory error detector. It consists of a compiler; instrumentation module and a run-time library. The tool can detect the; following types of bugs:. * Out-of-bounds accesses to heap, stack and globals; * Use-after-free; * Use-after-return (clang flag ``-fsanitize-address-use-after-return=(never|runtime|always)`` default: ``runtime``); * Enable with: ``ASAN_OPTIONS=detect_stack_use_after_return=1`` (already enabled on Linux).; * Disable with: ``ASAN_OPTIONS=detect_stack_use_after_return=0``.; * Use-after-scope (clang flag ``-fsanitize-address-use-after-scope``); * Double-free, invalid free; * Memory leaks (experimental). Typical slowdown introduced by AddressSanitizer is **2x**. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>` and enable; the ``compiler-rt`` runtime. An example CMake configuration that will allow; for the use/testing of AddressSanitizer:. .. code-block:: console. $ cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_ENABLE_RUNTIMES=""compiler-rt"" <path to source>/llvm. Usage; =====. Simply compile and link your program with ``-fsanitize=address`` flag. The; AddressSanitizer run-time library should be linked to the final executable, so; make sure to use ``clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:970,configurat,configuration,970,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst,1,['configurat'],['configuration']
Deployability,"================; Initializer List; ================; This discussion took place in https://reviews.llvm.org/D35216; ""Escape symbols when creating std::initializer_list"". It touches problems of modelling C++ standard library constructs in general,; including modelling implementation-defined fields within C++ standard library; objects, in particular constructing objects into pointers held by such fields,; and separation of responsibilities between analyzer's core and checkers. **Artem:**. I've seen a few false positives that appear because we construct; C++11 std::initializer_list objects with brace initializers, and such; construction is not properly modeled. For instance, if a new object is; constructed on the heap only to be put into a brace-initialized STL container,; the object is reported to be leaked. Approach (0): This can be trivially fixed by this patch, which causes pointers; passed into initializer list expressions to immediately escape. This fix is overly conservative though. So i did a bit of investigation as to; how model std::initializer_list better. According to the standard, ``std::initializer_list<T>`` is an object that has; methods ``begin(), end(), and size()``, where ``begin()`` returns a pointer to continuous; array of ``size()`` objects of type T, and end() is equal to begin() plus size().; The standard does hint that it should be possible to implement; ``std::initializer_list<T>`` as a pair of pointers, or as a pointer and a size; integer, however specific fields that the object would contain are an; implementation detail. Ideally, we should be able to model the initializer list's methods precisely.; Or, at least, it should be possible to explain to the analyzer that the list; somehow ""takes hold"" of the values put into it. Initializer lists can also be; copied, which is a separate story that i'm not trying to address here. The obvious approach to modeling ``std::initializer_list`` in a checker would be to; construct a SymbolMetadata for the m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst:869,patch,patch,869,interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,1,['patch'],['patch']
Deployability,"================; LeakSanitizer; ================. .. contents::; :local:. Introduction; ============. LeakSanitizer is a run-time memory leak detector. It can be combined with; :doc:`AddressSanitizer` to get both memory error and leak detection, or; used in a stand-alone mode. LSan adds almost no performance overhead; until the very end of the process, at which point there is an extra leak; detection phase. Usage; =====. :doc:`AddressSanitizer`: integrates LeakSanitizer and enables it by default on; supported platforms. .. code-block:: console. $ cat memory-leak.c; #include <stdlib.h>; void *p;; int main() {; p = malloc(7);; p = 0; // The memory is leaked here.; return 0;; }; % clang -fsanitize=address -g memory-leak.c ; ASAN_OPTIONS=detect_leaks=1 ./a.out; ==23646==ERROR: LeakSanitizer: detected memory leaks; Direct leak of 7 byte(s) in 1 object(s) allocated from:; #0 0x4af01b in __interceptor_malloc /projects/compiler-rt/lib/asan/asan_malloc_linux.cc:52:3; #1 0x4da26a in main memory-leak.c:4:7; #2 0x7f076fd9cec4 in __libc_start_main libc-start.c:287; SUMMARY: AddressSanitizer: 7 byte(s) leaked in 1 allocation(s). To use LeakSanitizer in stand-alone mode, link your program with; ``-fsanitize=leak`` flag. Make sure to use ``clang`` (not ``ld``) for the; link step, so that it would link in proper LeakSanitizer run-time library; into the final executable. Supported Platforms; ===================. * Android aarch64/i386/x86_64; * Fuchsia aarch64/x86_64; * Linux arm/aarch64/mips64/ppc64/ppc64le/riscv64/s390x/i386/x86\_64; * macOS aarch64/i386/x86\_64; * NetBSD i386/x86_64. More Information; ================. `<https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer>`_; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LeakSanitizer.rst:451,integrat,integrates,451,interpreter/llvm-project/clang/docs/LeakSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LeakSanitizer.rst,1,['integrat'],['integrates']
Deployability,"==================. .. program:: llvm-config. SYNOPSIS; --------. **llvm-config** *option* [*components*...]. DESCRIPTION; -----------. **llvm-config** makes it easier to build applications that use LLVM. It can; print the compiler flags, linker flags and object libraries needed to link; against LLVM. EXAMPLES; --------. To link against the JIT:. .. code-block:: sh. g++ `llvm-config --cxxflags` -o HowToUseJIT.o -c HowToUseJIT.cpp; g++ `llvm-config --ldflags` -o HowToUseJIT HowToUseJIT.o \; `llvm-config --libs engine bcreader scalaropts`. OPTIONS; -------. **--assertion-mode**. Print the assertion mode used when LLVM was built (ON or OFF). **--bindir**. Print the installation directory for LLVM binaries. **--build-mode**. Print the build mode used when LLVM was built (e.g. Debug or Release). **--build-system**. Print the build system used to build LLVM (e.g. `cmake` or `gn`). **--cflags**. Print the C compiler flags needed to use LLVM headers. **--cmakedir**. Print the installation directory for LLVM CMake modules. **--components**. Print all valid component names. **--cppflags**. Print the C preprocessor flags needed to use LLVM headers. **--cxxflags**. Print the C++ compiler flags needed to use LLVM headers. **--has-rtti**. Print whether or not LLVM was built with rtti (YES or NO). **--help**. Print a summary of **llvm-config** arguments. **--host-target**. Print the target triple used to configure LLVM. **--ignore-libllvm**. Ignore libLLVM and link component libraries instead. **--includedir**. Print the installation directory for LLVM headers. **--ldflags**. Print the flags needed to link against LLVM libraries. **--libdir**. Print the installation directory for LLVM libraries. **--libfiles**. Similar to **--libs**, but print the full path to each library file. This is; useful when creating makefile dependencies, to ensure that a tool is relinked if; any library it uses changes. **--libnames**. Similar to **--libs**, but prints the bare filenames of the libraries;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-config.rst:1055,install,installation,1055,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-config.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-config.rst,1,['install'],['installation']
Deployability,"===================. .. contents::; :local:. Introduction; ============. This document describes how to compile CUDA code with clang, and gives some; details about LLVM and clang's CUDA implementations. This document assumes a basic familiarity with CUDA. Information about CUDA; programming can be found in the; `CUDA programming guide; <http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html>`_. Compiling CUDA Code; ===================. Prerequisites; -------------. CUDA is supported since llvm 3.9. Clang currently supports CUDA 7.0 through; 12.1. If clang detects a newer CUDA version, it will issue a warning and will; attempt to use detected CUDA SDK it as if it were CUDA 12.1. Before you build CUDA code, you'll need to have installed the CUDA SDK. See; `NVIDIA's CUDA installation guide; <https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html>`_ for; details. Note that clang `maynot support; <https://bugs.llvm.org/show_bug.cgi?id=26966>`_ the CUDA toolkit as installed by; some Linux package managers. Clang does attempt to deal with specific details of; CUDA installation on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following commands, filling in the parts in angle; brackets as described",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:1057,install,installed,1057,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,1,['install'],['installed']
Deployability,"===================; FatLTO; ===================; .. contents::; :local:; :depth: 2. .. toctree::; :maxdepth: 1. Introduction; ============. FatLTO objects are a special type of `fat object file; <https://en.wikipedia.org/wiki/Fat_binary>`_ that contain LTO compatible IR in; addition to generated object code, instead of containing object code for; multiple target architectures. This allows users to defer the choice of whether; to use LTO or not to link-time, and has been a feature available in other; compilers, like `GCC; <https://gcc.gnu.org/onlinedocs/gccint/LTO-Overview.html>`_, for some time. Under FatLTO the compiler can emit standard object files which contain both the; machine code in the ``.text`` section and LLVM bitcode in the ``.llvm.lto``; section. Overview; ========. Within LLVM, FatLTO is supported by choosing the ``FatLTODefaultPipeline``.; This pipeline will:. #) Run the pre-link (Thin)LTO pipeline on the current module.; #) Embed the pre-link bitcode in a special ``.llvm.lto`` section.; #) Finish optimizing the module using the ModuleOptimization pipeline.; #) Emit the object file, including the new ``.llvm.lto`` section. .. NOTE. Previously, we conservatively ran independent pipelines on separate copies; of the LLVM module to generate the bitcode section and the object code,; which happen to be identical to those used outside of FatLTO. While that; resulted in compiled artifacts that were identical to those produced by the; default and (Thin)LTO pipelines, module cloning led to some cases of; miscompilation, and we have moved away from trying to keep bitcode; generation and optimization completely disjoint. Bit-for-bit compatibility is not (and never was) a guarantee, and we reserve; the right to change this at any time. Explicitly, users should not rely on; the produced bitcode or object code to match their non-LTO counterparts; precisely. They will exhibit similar performance characteristics, but may; not be bit-for-bit the same. Internally, the `",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst:873,pipeline,pipeline,873,interpreter/llvm-project/llvm/docs/FatLTO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst,2,['pipeline'],['pipeline']
Deployability,"===================; LLVM Security Group; ===================. The LLVM Security Group has the following goals:. 1. Allow LLVM contributors and security researchers to disclose security-related issues affecting the LLVM project to members of the LLVM community.; 2. Organize fixes, code reviews, and release management for said issues.; 3. Allow distributors time to investigate and deploy fixes before wide dissemination of vulnerabilities or mitigation shortcomings.; 4. Ensure timely notification and release to vendors who package and distribute LLVM-based toolchains and projects.; 5. Ensure timely notification to users of LLVM-based toolchains whose compiled code is security-sensitive, through the `CVE process`_.; 6. Strive to improve security over time, for example by adding additional testing, fuzzing, and hardening after fixing issues. *Note*: these goals ensure timely action, provide disclosure timing when issues are reported, and respect vendors' / packagers' / users' constraints. The LLVM Security Group is private. It is composed of trusted LLVM contributors. Its discussions remain within the Security Group (plus issue reporter and key experts) while an issue is being investigated. After an issue becomes public, the entirety of the group’s discussions pertaining to that issue also become public. .. _report-security-issue:. How to report a security issue?; ===============================. To report a security issue in the LLVM Project, please `open a new issue`_ in the LLVM project page, on the chromium issue tracker. Be sure to use the ""Security bug report"" template. We aim to acknowledge your report within two business days since you first reach out. If you do not receive any response by then, you can escalate by posting on the `Discourse forums`_ asking to get in touch with someone from the LLVM Security Group. **The escalation mailing list is public**: avoid discussing or mentioning the specific issue when posting on it. Group Composition; =================. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:300,release,release,300,interpreter/llvm-project/llvm/docs/Security.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst,3,"['deploy', 'release']","['deploy', 'release']"
Deployability,"====================; Clang |release| |ReleaseNotesTitle|; ===========================================. .. contents::; :local:; :depth: 2. Written by the `LLVM Team <https://llvm.org/>`_. .. only:: PreRelease. .. warning::; These are in-progress notes for the upcoming Clang |version| release.; Release notes for previous releases can be found on; `the Releases Page <https://llvm.org/releases/>`_. Introduction; ============. This document contains the release notes for the Clang C/C++/Objective-C; frontend, part of the LLVM Compiler Infrastructure, release |release|. Here we; describe the status of Clang in some detail, including major; improvements from the previous release and new feature work. For the; general LLVM release notes, see `the LLVM; documentation <https://llvm.org/docs/ReleaseNotes.html>`_. For the libc++ release notes,; see `this page <https://libcxx.llvm.org/ReleaseNotes.html>`_. All LLVM releases; may be downloaded from the `LLVM releases web site <https://llvm.org/releases/>`_. For more information about Clang or LLVM, including information about the; latest release, please see the `Clang Web Site <https://clang.llvm.org>`_ or the; `LLVM Web Site <https://llvm.org>`_. Potentially Breaking Changes; ============================; These changes are ones which we think may surprise users when upgrading to; Clang |release| because of the opportunity they pose for disruption to existing; code bases. - Fix a bug in reversed argument for templated operators.; This breaks code in C++20 which was previously accepted in C++17.; Clang did not properly diagnose such casese in C++20 before this change. Eg:. .. code-block:: cpp. struct P {};; template<class S> bool operator==(const P&, const S&);. struct A : public P {};; struct B : public P {};. // This equality is now ambiguous in C++20.; bool ambiguous(A a, B b) { return a == b; }. template<class S> bool operator!=(const P&, const S&);; // Ok. Found a matching operator!=.; bool fine(A a, B b) { return a == b; }. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:1019,release,releases,1019,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['release'],['releases']
Deployability,"====================; Objective-C Literals; ====================. Introduction; ============. Three new features were introduced into clang at the same time:; *NSNumber Literals* provide a syntax for creating ``NSNumber`` from; scalar literal expressions; *Collection Literals* provide a short-hand; for creating arrays and dictionaries; *Object Subscripting* provides a; way to use subscripting with Objective-C objects. Users of Apple; compiler releases can use these features starting with the Apple LLVM; Compiler 4.0. Users of open-source LLVM.org compiler releases can use; these features starting with clang v3.1. These language additions simplify common Objective-C programming; patterns, make programs more concise, and improve the safety of; container creation. This document describes how the features are implemented in clang, and; how to use them in your own programs. NSNumber Literals; =================. The framework class ``NSNumber`` is used to wrap scalar values inside; objects: signed and unsigned integers (``char``, ``short``, ``int``,; ``long``, ``long long``), floating point numbers (``float``,; ``double``), and boolean values (``BOOL``, C++ ``bool``). Scalar values; wrapped in objects are also known as *boxed* values. In Objective-C, any character, numeric or boolean literal prefixed with; the ``'@'`` character will evaluate to a pointer to an ``NSNumber``; object initialized with that value. C's type suffixes may be used to; control the size of numeric literals. Examples; --------. The following program illustrates the rules for ``NSNumber`` literals:. .. code-block:: objc. void main(int argc, const char *argv[]) {; // character literals.; NSNumber *theLetterZ = @'Z'; // equivalent to [NSNumber numberWithChar:'Z']. // integral literals.; NSNumber *fortyTwo = @42; // equivalent to [NSNumber numberWithInt:42]; NSNumber *fortyTwoUnsigned = @42U; // equivalent to [NSNumber numberWithUnsignedInt:42U]; NSNumber *fortyTwoLong = @42L; // equivalent to [NSNumber n",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ObjectiveCLiterals.rst:447,release,releases,447,interpreter/llvm-project/clang/docs/ObjectiveCLiterals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ObjectiveCLiterals.rst,2,['release'],['releases']
Deployability,"======================; Control Flow Integrity; ======================. .. toctree::; :hidden:. ControlFlowIntegrityDesign. .. contents::; :local:. Introduction; ============. Clang includes an implementation of a number of control flow integrity (CFI); schemes, which are designed to abort the program upon detecting certain forms; of undefined behavior that can potentially allow attackers to subvert the; program's control flow. These schemes have been optimized for performance,; allowing developers to enable them in release builds. To enable Clang's available CFI schemes, use the flag ``-fsanitize=cfi``.; You can also enable a subset of available :ref:`schemes <cfi-schemes>`.; As currently implemented, all schemes rely on link-time optimization (LTO);; so it is required to specify ``-flto``, and the linker used must support LTO,; for example via the `gold plugin`_. To allow the checks to be implemented efficiently, the program must; be structured such that certain object files are compiled with CFI; enabled, and are statically linked into the program. This may preclude; the use of shared libraries in some cases. The compiler will only produce CFI checks for a class if it can infer hidden; LTO visibility for that class. LTO visibility is a property of a class that; is inferred from flags and attributes. For more details, see the documentation; for :doc:`LTO visibility <LTOVisibility>`. The ``-fsanitize=cfi-{vcall,nvcall,derived-cast,unrelated-cast}`` flags; require that a ``-fvisibility=`` flag also be specified. This is because the; default visibility setting is ``-fvisibility=default``, which would disable; CFI checks for classes without visibility attributes. Most users will want; to specify ``-fvisibility=hidden``, which enables CFI checks for such classes. Experimental support for :ref:`cross-DSO control flow integrity; <cfi-cross-dso>` exists that does not require classes to have hidden LTO; visibility. This cross-DSO support has unstable ABI at this time. .. _g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst:522,release,release,522,interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst,1,['release'],['release']
Deployability,======================; Value Name Description; ========== ================= ===============================================================================; 0..127 *User Data Entry* 32-bit value of user_data_entry[N] as specified via *CmdSetUserData()*; 0x10000000 GlobalTable 32-bit pointer to GPU memory containing the global internal table (should; always point to *user data register* 0).; 0x10000001 PerShaderTable 32-bit pointer to GPU memory containing the per-shader internal table. See; :ref:`amdgpu-amdpal-code-object-metadata-user-data-per-shader-table-section`; for more detail (should always point to *user data register* 1).; 0x10000002 SpillTable 32-bit pointer to GPU memory containing the user data spill table. See; :ref:`amdgpu-amdpal-code-object-metadata-user-data-spill-table-section` for; more detail.; 0x10000003 BaseVertex Vertex offset (32-bit unsigned integer). Not needed if the pipeline doesn't; reference the draw index in the vertex shader. Only supported by the first; stage in a graphics pipeline.; 0x10000004 BaseInstance Instance offset (32-bit unsigned integer). Only supported by the first stage in; a graphics pipeline.; 0x10000005 DrawIndex Draw index (32-bit unsigned integer). Only supported by the first stage in a; graphics pipeline.; 0x10000006 Workgroup Thread group count (32-bit unsigned integer). Low half of a 64-bit address of; a buffer containing the grid dimensions for a Compute dispatch operation. The; high half of the address is stored in the next sequential user-SGPR. Only; supported by compute pipelines.; 0x1000000A EsGsLdsSize Indicates that PAL will program this user-SGPR to contain the amount of LDS; space used for the ES/GS pseudo-ring-buffer for passing data between shader; stages.; 0x1000000B ViewId View id (32-bit unsigned integer) identifies a view of graphic; pipeline instancing.; 0x1000000C StreamOutTable 32-bit pointer to GPU memory containing the stream out target SRD table. This; can only appear for one shader stage per ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:416273,pipeline,pipeline,416273,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['pipeline'],['pipeline']
Deployability,"=======================; External Clang Examples; =======================. Introduction; ============. This page provides some examples of the kinds of things that people have; done with Clang that might serve as useful guides (or starting points) from; which to develop your own tools. They may be helpful even for something as; banal (but necessary) as how to set up your build to integrate Clang. Clang's library-based design is deliberately aimed at facilitating use by; external projects, and we are always interested in improving Clang to; better serve our external users. Some typical categories of applications; where Clang is used are:. - Static analysis.; - Documentation/cross-reference generation. If you know of (or wrote!) a tool or project using Clang, please post on; `the Discourse forums (Clang Frontend category); <https://discourse.llvm.org/c/clang/6>`_ to have it added.; (or if you are already a Clang contributor, feel free to directly commit; additions). Since the primary purpose of this page is to provide examples; that can help developers, generally they must have code available. List of projects and tools; ==========================. `<https://github.com/Andersbakken/rtags/>`_; ""RTags is a client/server application that indexes c/c++ code and keeps; a persistent in-memory database of references, symbolnames, completions; etc."". `<https://rprichard.github.io/CxxCodeBrowser/>`_; ""A C/C++ source code indexer and navigator"". `<https://github.com/etaoins/qconnectlint>`_; ""qconnectlint is a Clang tool for statically verifying the consistency; of signal and slot connections made with Qt's ``QObject::connect``."". `<https://github.com/woboq/woboq_codebrowser>`_; ""The Woboq Code Browser is a web-based code browser for C/C++ projects.; Check out `<https://code.woboq.org/>`_ for an example!"". `<https://github.com/mozilla/dxr>`_; ""DXR is a source code cross-reference tool that uses static analysis; data collected by instrumented compilers."". `<https://github.com/esch",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ExternalClangExamples.rst:383,integrat,integrate,383,interpreter/llvm-project/clang/docs/ExternalClangExamples.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ExternalClangExamples.rst,1,['integrat'],['integrate']
Deployability,"=======================; LLVM Common CMake Utils; =======================. What goes here; --------------. These are CMake modules to be shared between LLVM projects strictly at build; time. In other words, they must not be included from an installed CMake module,; such as the ``Add*.cmake`` ones. Modules that are reachable from installed; modules should instead go in ``${project}/cmake/modules`` of the most upstream; project that uses them. The advantage of not putting these modules in an existing location like; ``llvm/cmake/modules`` is two-fold:. - Since they are not installed, we don't have to worry about any out-of-tree; downstream usage, and thus there is no need for stability. - Since they are available as part of the source at build-time, we don't have; to do the usual stand-alone vs combined-build dances, avoiding much; complexity. How to use; ----------. For tools, please do:. .. code-block:: cmake. if(NOT DEFINED LLVM_COMMON_CMAKE_UTILS); set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake); endif(). # Add path for custom modules.; list(INSERT CMAKE_MODULE_PATH 0; # project-specific module dirs first; ""${LLVM_COMMON_CMAKE_UTILS}/Modules""; ). Notes:. - The ``if(NOT DEFINED ...)`` guard is there because in combined builds, LLVM; will set this variable. This is useful for legacy builds where projects are; found in ``llvm/tools`` instead. - ``INSERT ... 0`` ensures these new entries are prepended to the front of the; module path, so nothing might shadow them by mistake. For runtime libs, we skip the ``if(NOT DEFINED`` part:. .. code-block:: cmake. set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake). ... # same as before. If ``llvm/tools`` legacy-style combined builds are deprecated, we should then; skip it everywhere, bringing the tools and runtimes boilerplate back in line.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst:241,install,installed,241,interpreter/llvm-project/cmake/README.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst,3,['install'],['installed']
Deployability,"=======================; Writing an LLVM Backend; =======================. .. toctree::; :hidden:. HowToUseInstrMappings. .. contents::; :local:. Introduction; ============. This document describes techniques for writing compiler backends that convert; the LLVM Intermediate Representation (IR) to code for a specified machine or; other languages. Code intended for a specific machine can take the form of; either assembly code or binary code (usable for a JIT compiler). The backend of LLVM features a target-independent code generator that may; create output for several types of target CPUs --- including X86, PowerPC,; ARM, and SPARC. The backend may also be used to generate code targeted at SPUs; of the Cell processor or GPUs to support the execution of compute kernels. The document focuses on existing examples found in subdirectories of; ``llvm/lib/Target`` in a downloaded LLVM release. In particular, this document; focuses on the example of creating a static compiler (one that emits text; assembly) for a SPARC target, because SPARC has fairly standard; characteristics, such as a RISC instruction set and straightforward calling; conventions. Audience; --------. The audience for this document is anyone who needs to write an LLVM backend to; generate code for a specific hardware or software target. Prerequisite Reading; --------------------. These essential documents must be read before reading this document:. * `LLVM Language Reference Manual <LangRef.html>`_ --- a reference manual for; the LLVM assembly language. * :doc:`CodeGenerator` --- a guide to the components (classes and code; generation algorithms) for translating the LLVM internal representation into; machine code for a specified target. Pay particular attention to the; descriptions of code generation stages: Instruction Selection, Scheduling and; Formation, SSA-based Optimization, Register Allocation, Prolog/Epilog Code; Insertion, Late Machine Code Optimizations, and Code Emission. * :doc:`TableGen/index` --",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:889,release,release,889,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['release'],['release']
Deployability,"========================. .. contents::; :local:. Introduction; ============. `CMake <http://www.cmake.org/>`_ is a cross-platform build-generator tool. CMake; does not build the project, it generates the files needed by your build tool; (GNU make, Visual Studio, etc.) for building LLVM. If **you are a new contributor**, please start with the :doc:`GettingStarted` or; :doc:`CMake` pages. This page is intended for users doing more complex builds. Many of the examples below are written assuming specific CMake Generators.; Unless otherwise explicitly called out these commands should work with any CMake; generator. Many of the build configurations mentioned on this documentation page can be; utilized by using a CMake cache. A CMake cache is essentially a configuration; file that sets the necessary flags for a specific build configuration. The caches; for Clang are located in :code:`/clang/cmake/caches` within the monorepo. They; can be passed to CMake using the :code:`-C` flag as demonstrated in the examples; below along with additional configuration flags. Bootstrap Builds; ================. The Clang CMake build system supports bootstrap (aka multi-stage) builds. At a; high level a multi-stage build is a chain of builds that pass data from one; stage into the next. The most common and simple version of this is a traditional; bootstrap build. In a simple two-stage bootstrap build, we build clang using the system compiler,; then use that just-built clang to build clang again. In CMake this simplest form; of a bootstrap build can be configured with a single option,; CLANG_ENABLE_BOOTSTRAP. .. code-block:: console. $ cmake -G Ninja -DCMAKE_BUILD_TYPE=Release \; -DCLANG_ENABLE_BOOTSTRAP=On \; -DLLVM_ENABLE_PROJECTS=""clang"" \; <path to source>/llvm; $ ninja stage2. This command itself isn't terribly useful because it assumes default; configurations for each stage. The next series of examples utilize CMake cache; scripts to provide more complex options. By default, only a few",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst:1116,configurat,configuration,1116,interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,1,['configurat'],['configuration']
Deployability,"========================. .. contents::; :local:; :depth: 2. Introduction; ============. Clang is only one component in a complete tool chain for C family; programming languages. In order to assemble a complete toolchain,; additional tools and runtime libraries are required. Clang is designed; to interoperate with existing tools and libraries for its target; platforms, and the LLVM project provides alternatives for a number; of these components. This document describes the required and optional components in a; complete toolchain, where to find them, and the supported versions; and limitations of each option. .. warning::. This document currently describes Clang configurations on POSIX-like; operating systems with the GCC-compatible ``clang`` driver. When; targeting Windows with the MSVC-compatible ``clang-cl`` driver, some; of the details are different. Tools; =====. .. FIXME: Describe DWARF-related tools. A complete compilation of C family programming languages typically; involves the following pipeline of tools, some of which are omitted; in some compilations:. * **Preprocessor**: This performs the actions of the C preprocessor:; expanding #includes and #defines.; The ``-E`` flag instructs Clang to stop after this step. * **Parsing**: This parses and semantically analyzes the source language and; builds a source-level intermediate representation (""AST""), producing a; :ref:`precompiled header (PCH) <usersmanual-precompiled-headers>`,; preamble, or; :doc:`precompiled module file (PCM) <Modules>`,; depending on the input.; The ``-precompile`` flag instructs Clang to stop after this step. This is; the default when the input is a header file. * **IR generation**: This converts the source-level intermediate representation; into an optimizer-specific intermediate representation (IR); for Clang, this; is LLVM IR.; The ``-emit-llvm`` flag instructs Clang to stop after this step. If combined; with ``-S``, Clang will produce textual LLVM IR; otherwise, it will produce; LLVM",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Toolchain.rst:1085,pipeline,pipeline,1085,interpreter/llvm-project/clang/docs/Toolchain.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Toolchain.rst,1,['pipeline'],['pipeline']
Deployability,"========================. .. contents::; :local:; :depth: 2. Written by the `LLVM Team <https://llvm.org/>`_. .. only:: PreRelease. .. warning::; These are in-progress notes for the upcoming Clang |version| release.; Release notes for previous releases can be found on; `the Releases Page <https://llvm.org/releases/>`_. Introduction; ============. This document contains the release notes for the Clang C/C++/Objective-C; frontend, part of the LLVM Compiler Infrastructure, release |release|. Here we; describe the status of Clang in some detail, including major; improvements from the previous release and new feature work. For the; general LLVM release notes, see `the LLVM; documentation <https://llvm.org/docs/ReleaseNotes.html>`_. For the libc++ release notes,; see `this page <https://libcxx.llvm.org/ReleaseNotes.html>`_. All LLVM releases; may be downloaded from the `LLVM releases web site <https://llvm.org/releases/>`_. For more information about Clang or LLVM, including information about the; latest release, please see the `Clang Web Site <https://clang.llvm.org>`_ or the; `LLVM Web Site <https://llvm.org>`_. Potentially Breaking Changes; ============================; These changes are ones which we think may surprise users when upgrading to; Clang |release| because of the opportunity they pose for disruption to existing; code bases. - Fix a bug in reversed argument for templated operators.; This breaks code in C++20 which was previously accepted in C++17.; Clang did not properly diagnose such casese in C++20 before this change. Eg:. .. code-block:: cpp. struct P {};; template<class S> bool operator==(const P&, const S&);. struct A : public P {};; struct B : public P {};. // This equality is now ambiguous in C++20.; bool ambiguous(A a, B b) { return a == b; }. template<class S> bool operator!=(const P&, const S&);; // Ok. Found a matching operator!=.; bool fine(A a, B b) { return a == b; }. To reduce such widespread breakages, as an extension, Clang accepts this code",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:1115,release,release,1115,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['release'],['release']
Deployability,"========================. .. program:: llvm-install-name-tool. SYNOPSIS; --------. :program:`llvm-install-name-tool` [*options*] *input*. DESCRIPTION; -----------. :program:`llvm-install-name-tool` is a tool to manipulate dynamic shared library; install names and rpaths listed in a Mach-O binary. For most scenarios, it works as a drop-in replacement for Apple's; :program:`install_name_tool`. OPTIONS; --------; At least one of the following options are required, and some options can be; combined with other options. Options :option:`-add_rpath`, :option:`-delete_rpath`,; and :option:`-rpath` can be combined in an invocation only if they do not share; the same `<rpath>` value. .. option:: -add_rpath <rpath>. Add an rpath named ``<rpath>`` to the specified binary. Can be specified multiple; times to add multiple rpaths. Throws an error if ``<rpath>`` is already listed in; the binary. .. option:: -change <old_install_name> <new_install_name>. Change an install name ``<old_install_name>`` to ``<new_install_name>`` in the; specified binary. Can be specified multiple times to change multiple dependent shared; library install names. Option is ignored if ``<old_install_name>`` is not listed; in the specified binary. .. option:: -delete_rpath <rpath>. Delete an rpath named ``<rpath>`` from the specified binary. Can be specified multiple; times to delete multiple rpaths. Throws an error if ``<rpath>`` is not listed in; the binary. .. option:: -delete_all_rpaths. Deletes all rpaths from the binary. .. option:: --help, -h. Print a summary of command line options. .. option:: -id <name>. Change shared library's identification name under LC_ID_DYLIB to ``<name>`` in the; specified binary. If specified multiple times, only the last :option:`-id` option is; selected. Option is ignored if the specified Mach-O binary is not a dynamic shared library. .. option:: -rpath <old_rpath> <new_rpath>. Change an rpath named ``<old_rpath>`` to ``<new_rpath>`` in the specified binary. Can be speci",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-install-name-tool.rst:1092,install,install,1092,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-install-name-tool.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-install-name-tool.rst,1,['install'],['install']
Deployability,"========================; Advice on Packaging LLVM; ========================. .. contents::; :local:. Overview; ========. LLVM sets certain default configure options to make sure our developers don't; break things for constrained platforms. These settings are not optimal for most; desktop systems, and we hope that packagers (e.g., Redhat, Debian, MacPorts,; etc.) will tweak them. This document lists settings we suggest you tweak. LLVM's API changes with each release, so users are likely to want, for example,; both LLVM-2.6 and LLVM-2.7 installed at the same time to support apps developed; against each. Compile Flags; =============. LLVM runs much more quickly when it's optimized and assertions are removed.; However, such a build is currently incompatible with users who build without; defining ``NDEBUG``, and the lack of assertions makes it hard to debug problems; in user code. We recommend allowing users to install both optimized and debug; versions of LLVM in parallel. The following configure flags are relevant:. ``--disable-assertions``; Builds LLVM with ``NDEBUG`` defined. Changes the LLVM ABI. Also available; by setting ``DISABLE_ASSERTIONS=0|1`` in ``make``'s environment. This; defaults to enabled regardless of the optimization setting, but it slows; things down. ``--enable-debug-symbols``; Builds LLVM with ``-g``. Also available by setting ``DEBUG_SYMBOLS=0|1`` in; ``make``'s environment. This defaults to disabled when optimizing, so you; should turn it back on to let users debug their programs. ``--enable-optimized``; (For git checkouts) Builds LLVM with ``-O2`` and, by default, turns off; debug symbols. Also available by setting ``ENABLE_OPTIMIZED=0|1`` in; ``make``'s environment. This defaults to enabled when not in a; checkout. C++ Features; ============. RTTI; LLVM disables RTTI by default. Add ``REQUIRES_RTTI=1`` to your environment; while running ``make`` to re-enable it. This will allow users to build with; RTTI enabled and still inherit from LLVM class",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Packaging.rst:463,release,release,463,interpreter/llvm-project/llvm/docs/Packaging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Packaging.rst,3,"['install', 'release']","['install', 'installed', 'release']"
Deployability,"========================; Creating an LLVM Project; ========================. .. contents::; :local:. Overview; ========. The LLVM build system is designed to facilitate the building of third party; projects that use LLVM header files, libraries, and tools. In order to use; these facilities, a ``Makefile`` from a project must do the following things:. * Set ``make`` variables. There are several variables that a ``Makefile`` needs; to set to use the LLVM build system:. * ``PROJECT_NAME`` - The name by which your project is known.; * ``LLVM_SRC_ROOT`` - The root of the LLVM source tree.; * ``LLVM_OBJ_ROOT`` - The root of the LLVM object tree.; * ``PROJ_SRC_ROOT`` - The root of the project's source tree.; * ``PROJ_OBJ_ROOT`` - The root of the project's object tree.; * ``PROJ_INSTALL_ROOT`` - The root installation directory.; * ``LEVEL`` - The relative path from the current directory to the; project's root ``($PROJ_OBJ_ROOT)``. * Include ``Makefile.config`` from ``$(LLVM_OBJ_ROOT)``. * Include ``Makefile.rules`` from ``$(LLVM_SRC_ROOT)``. There are two ways that you can set all of these variables:. * You can write your own ``Makefiles`` which hard-code these values. * You can use the pre-made LLVM sample project. This sample project includes; ``Makefiles``, a configure script that can be used to configure the location; of LLVM, and the ability to support multiple object directories from a single; source directory. If you want to devise your own build system, studying other projects and LLVM; ``Makefiles`` will probably provide enough information on how to write your own; ``Makefiles``. Source Tree Layout; ==================. In order to use the LLVM build system, you will want to organize your source; code so that it can benefit from the build system's features. Mainly, you want; your source tree layout to look similar to the LLVM source tree layout. Underneath your top level directory, you should have the following directories:. **lib**. This subdirectory should contain",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Projects.rst:809,install,installation,809,interpreter/llvm-project/llvm/docs/Projects.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Projects.rst,1,['install'],['installation']
Deployability,"========================; LLVM Programmer's Manual; ========================. .. contents::; :local:. .. warning::; This is always a work in progress. .. _introduction:. Introduction; ============. This document is meant to highlight some of the important classes and interfaces; available in the LLVM source-base. This manual is not intended to explain what; LLVM is, how it works, and what LLVM code looks like. It assumes that you know; the basics of LLVM and are interested in writing transformations or otherwise; analyzing or manipulating the code. This document should get you oriented so that you can find your way in the; continuously growing source code that makes up the LLVM infrastructure. Note; that this manual is not intended to serve as a replacement for reading the; source code, so if you think there should be a method in one of these classes to; do something, but it's not listed, check the source. Links to the `doxygen; <https://llvm.org/doxygen/>`__ sources are provided to make this as easy as; possible. The first section of this document describes general information that is useful; to know when working in the LLVM infrastructure, and the second describes the; Core LLVM classes. In the future this manual will be extended with information; describing how to use extension libraries, such as dominator information, CFG; traversal routines, and useful utilities like the ``InstVisitor`` (`doxygen; <https://llvm.org/doxygen/InstVisitor_8h_source.html>`__) template. .. _general:. General Information; ===================. This section contains general information that is useful if you are working in; the LLVM source-base, but that isn't specific to any particular API. .. _stl:. The C++ Standard Template Library; ---------------------------------. LLVM makes heavy use of the C++ Standard Template Library (STL), perhaps much; more than you are used to, or have seen before. Because of this, you might want; to do a little background reading in the techniques used and c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:631,continuous,continuously,631,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['continuous'],['continuously']
Deployability,========================; Many Tests lit Example; ========================. This directory contains a trivial lit test suite configuration that defines a; custom test format which just generates a large (N=10000) number of tests that; do a small amount of work in the Python test execution code. This test suite is useful for testing the performance of lit on large numbers of; tests.; ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/lit/examples/many-tests/README.txt:125,configurat,configuration,125,interpreter/llvm-project/llvm/utils/lit/examples/many-tests/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/lit/examples/many-tests/README.txt,1,['configurat'],['configuration']
Deployability,"=========================; Compiling CUDA with clang; =========================. .. contents::; :local:. Introduction; ============. This document describes how to compile CUDA code with clang, and gives some; details about LLVM and clang's CUDA implementations. This document assumes a basic familiarity with CUDA. Information about CUDA; programming can be found in the; `CUDA programming guide; <http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html>`_. Compiling CUDA Code; ===================. Prerequisites; -------------. CUDA is supported since llvm 3.9. Clang currently supports CUDA 7.0 through; 12.1. If clang detects a newer CUDA version, it will issue a warning and will; attempt to use detected CUDA SDK it as if it were CUDA 12.1. Before you build CUDA code, you'll need to have installed the CUDA SDK. See; `NVIDIA's CUDA installation guide; <https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html>`_ for; details. Note that clang `maynot support; <https://bugs.llvm.org/show_bug.cgi?id=26966>`_ the CUDA toolkit as installed by; some Linux package managers. Clang does attempt to deal with specific details of; CUDA installation on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following com",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:804,install,installed,804,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,3,['install'],"['installation', 'installation-guide-linux', 'installed']"
Deployability,"==========================; Vector Predication Roadmap; ==========================. .. contents:: Table of Contents; :depth: 3; :local:. Motivation; ==========. This proposal defines a roadmap towards native vector predication in LLVM,; specifically for vector instructions with a mask and/or an explicit vector; length. LLVM currently has no target-independent means to model predicated; vector instructions for modern SIMD ISAs such as AVX512, ARM SVE, the RISC-V V; extension and NEC SX-Aurora. Only some predicated vector operations, such as; masked loads and stores, are available through intrinsics [MaskedIR]_. The Vector Predication (VP) extensions is a concrete RFC and prototype; implementation to achieve native vector predication in LLVM. The VP prototype; and all related discussions can be found in the VP patch on Phabricator; [VPRFC]_. Roadmap; =======. 1. IR-level VP intrinsics; -------------------------. - There is a consensus on the semantics/instruction set of VP.; - VP intrinsics and attributes are available on IR level.; - TTI has capability flags for VP (``supportsVP()``?,; ``haveActiveVectorLength()``?). Result: VP usable for IR-level vectorizers (LV, VPlan, RegionVectorizer),; potential integration in Clang with builtins. 2. CodeGen support; ------------------. - VP intrinsics translate to first-class SDNodes; (eg ``llvm.vp.fdiv.* -> vp_fdiv``).; - VP legalization (legalize explicit vector length to mask (AVX512), legalize VP; SDNodes to pre-existing ones (SSE, NEON)). Result: Backend development based on VP SDNodes. 3. Lift InstSimplify/InstCombine/DAGCombiner to VP; --------------------------------------------------. - Introduce PredicatedInstruction, PredicatedBinaryOperator, .. helper classes; that match standard vector IR and VP intrinsics.; - Add a matcher context to PatternMatch and context-aware IR Builder APIs.; - Incrementally lift DAGCombiner to work on VP SDNodes as well as on regular; vector instructions.; - Incrementally lift InstCombine/In",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VectorPredication.rst:820,patch,patch,820,interpreter/llvm-project/llvm/docs/Proposals/VectorPredication.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VectorPredication.rst,1,['patch'],['patch']
Deployability,"============================; LLVM |release| Release Notes; ============================. .. contents::; :local:. .. only:: PreRelease. .. warning::; These are in-progress notes for the upcoming LLVM |version| release.; Release notes for previous releases can be found on; `the Download Page <https://releases.llvm.org/download.html>`_. Introduction; ============. This document contains the release notes for the LLVM Compiler Infrastructure,; release |release|. Here we describe the status of LLVM, including major improvements; from the previous release, improvements in various subprojects of LLVM, and; some of the current users of the code. All LLVM releases may be downloaded; from the `LLVM releases web site <https://llvm.org/releases/>`_. For more information about LLVM, including information about the latest; release, please check out the `main LLVM web site <https://llvm.org/>`_. If you; have questions or comments, the `Discourse forums; <https://discourse.llvm.org>`_ is a good place to ask; them. Note that if you are reading this file from a Git checkout or the main; LLVM web page, this document applies to the *next* release, not the current; one. To see the release notes for a specific release, please see the `releases; page <https://llvm.org/releases/>`_. Non-comprehensive list of changes in this release; =================================================; .. NOTE; For small 1-3 sentence descriptions, just add an entry at the end of; this list. If your description won't fit comfortably in one bullet; point (e.g. maybe you would like to give an example of the; functionality, or simply have a lot to talk about), see the `NOTE` below; for adding a new subsection. * ... Update on required toolchains to build LLVM; -------------------------------------------. Changes to the LLVM IR; ----------------------. * The `llvm.stacksave` and `llvm.stackrestore` intrinsics now use; an overloaded pointer type to support non-0 address spaces.; * The constant expression variants o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst:36,release,release,36,interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,12,['release'],"['release', 'releases']"
Deployability,"============================; Taint Analysis Configuration; ============================. The Clang Static Analyzer uses taint analysis to detect security-related issues in code.; The backbone of taint analysis in the Clang SA is the `GenericTaintChecker`, which the user can access via the :ref:`alpha-security-taint-TaintPropagation` checker alias and this checker has a default taint-related configuration.; The built-in default settings are defined in code, and they are always in effect once the checker is enabled, either directly or via the alias.; The checker also provides a configuration interface for extending the default settings by providing a configuration file in `YAML <http://llvm.org/docs/YamlIO.html#introduction-to-yaml>`_ format.; This documentation describes the syntax of the configuration file and gives the informal semantics of the configuration options. .. contents::; :local:. .. _clangsa-taint-configuration-overview:. Overview; ________. Taint analysis works by checking for the occurrence of special operations during the symbolic execution of the program.; Taint analysis defines sources, sinks, and propagation rules. It identifies errors by detecting a flow of information that originates from a taint source, reaches a taint sink, and propagates through the program paths via propagation rules.; A source, sink, or an operation that propagates taint is mainly domain-specific knowledge, but there are some built-in defaults provided by :ref:`alpha-security-taint-TaintPropagation`.; It is possible to express that a statement sanitizes tainted values by providing a ``Filters`` section in the external configuration (see :ref:`clangsa-taint-configuration-example` and :ref:`clangsa-taint-filter-details`).; There are no default filters defined in the built-in settings.; The checker's documentation also specifies how to provide a custom taint configuration with command-line options. .. _clangsa-taint-configuration-example:. Example configuration file; __________",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst:395,configurat,configuration,395,interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst,6,['configurat'],"['configuration', 'configuration-overview']"
Deployability,"============================= =========================. Release Process Summary; -----------------------. * Announce release schedule to the LLVM community and update the website. Do; this at least 3 weeks before the -rc1 release. * Create release branch and begin release process. * Send out release candidate sources for first round of testing. Testing lasts; 6 weeks. During the first round of testing, any regressions found should be; fixed. Patches are merged from mainline into the release branch. Also, all; features need to be completed during this time. Any features not completed at; the end of the first round of testing will be removed or disabled for the; release. * Generate and send out the second release candidate sources. Only *critical*; bugs found during this testing phase will be fixed. Any bugs introduced by; merged patches will be fixed. If so a third round of testing is needed. * The release notes are updated. * Finally, release!. * Announce bug fix release schedule to the LLVM community and update the website. * Do bug-fix releases every two weeks until X.1.5 or X.1.6 (if necessary). Release Process; ===============. .. contents::; :local:. Release Administrative Tasks; ----------------------------. This section describes a few administrative tasks that need to be done for the; release process to begin. Specifically, it involves:. * Updating version numbers,. * Creating the release branch, and. * Tagging release candidates for the release team to begin testing. Create Release Branch; ^^^^^^^^^^^^^^^^^^^^^. Branch the Git trunk using the following procedure:. #. Remind developers that the release branching is imminent and to refrain from; committing patches that might break the build. E.g., new features, large; patches for works in progress, an overhaul of the type system, an exciting; new TableGen feature, etc. #. Verify that the current git trunk is in decent shape by; examining nightly tester and buildbot results. #. Bump the version in trunk to N.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:2943,release,release,2943,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,2,"['release', 'update']","['release', 'update']"
Deployability,=============================; 0..127 *User Data Entry* 32-bit value of user_data_entry[N] as specified via *CmdSetUserData()*; 0x10000000 GlobalTable 32-bit pointer to GPU memory containing the global internal table (should; always point to *user data register* 0).; 0x10000001 PerShaderTable 32-bit pointer to GPU memory containing the per-shader internal table. See; :ref:`amdgpu-amdpal-code-object-metadata-user-data-per-shader-table-section`; for more detail (should always point to *user data register* 1).; 0x10000002 SpillTable 32-bit pointer to GPU memory containing the user data spill table. See; :ref:`amdgpu-amdpal-code-object-metadata-user-data-spill-table-section` for; more detail.; 0x10000003 BaseVertex Vertex offset (32-bit unsigned integer). Not needed if the pipeline doesn't; reference the draw index in the vertex shader. Only supported by the first; stage in a graphics pipeline.; 0x10000004 BaseInstance Instance offset (32-bit unsigned integer). Only supported by the first stage in; a graphics pipeline.; 0x10000005 DrawIndex Draw index (32-bit unsigned integer). Only supported by the first stage in a; graphics pipeline.; 0x10000006 Workgroup Thread group count (32-bit unsigned integer). Low half of a 64-bit address of; a buffer containing the grid dimensions for a Compute dispatch operation. The; high half of the address is stored in the next sequential user-SGPR. Only; supported by compute pipelines.; 0x1000000A EsGsLdsSize Indicates that PAL will program this user-SGPR to contain the amount of LDS; space used for the ES/GS pseudo-ring-buffer for passing data between shader; stages.; 0x1000000B ViewId View id (32-bit unsigned integer) identifies a view of graphic; pipeline instancing.; 0x1000000C StreamOutTable 32-bit pointer to GPU memory containing the stream out target SRD table. This; can only appear for one shader stage per pipeline.; 0x1000000D PerShaderPerfData 32-bit pointer to GPU memory containing the per-shader performance data buffer.; 0x1000,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:416400,pipeline,pipeline,416400,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['pipeline'],['pipeline']
Deployability,"=============================; Advanced Build Configurations; =============================. .. contents::; :local:. Introduction; ============. `CMake <http://www.cmake.org/>`_ is a cross-platform build-generator tool. CMake; does not build the project, it generates the files needed by your build tool; (GNU make, Visual Studio, etc.) for building LLVM. If **you are a new contributor**, please start with the :doc:`GettingStarted` or; :doc:`CMake` pages. This page is intended for users doing more complex builds. Many of the examples below are written assuming specific CMake Generators.; Unless otherwise explicitly called out these commands should work with any CMake; generator. Many of the build configurations mentioned on this documentation page can be; utilized by using a CMake cache. A CMake cache is essentially a configuration; file that sets the necessary flags for a specific build configuration. The caches; for Clang are located in :code:`/clang/cmake/caches` within the monorepo. They; can be passed to CMake using the :code:`-C` flag as demonstrated in the examples; below along with additional configuration flags. Bootstrap Builds; ================. The Clang CMake build system supports bootstrap (aka multi-stage) builds. At a; high level a multi-stage build is a chain of builds that pass data from one; stage into the next. The most common and simple version of this is a traditional; bootstrap build. In a simple two-stage bootstrap build, we build clang using the system compiler,; then use that just-built clang to build clang again. In CMake this simplest form; of a bootstrap build can be configured with a single option,; CLANG_ENABLE_BOOTSTRAP. .. code-block:: console. $ cmake -G Ninja -DCMAKE_BUILD_TYPE=Release \; -DCLANG_ENABLE_BOOTSTRAP=On \; -DLLVM_ENABLE_PROJECTS=""clang"" \; <path to source>/llvm; $ ninja stage2. This command itself isn't terribly useful because it assumes default; configurations for each stage. The next series of examples utilize CMake cac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst:704,configurat,configurations,704,interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,3,['configurat'],"['configuration', 'configurations']"
Deployability,"=============================; How To Validate a New Release; =============================. .. contents::; :local:; :depth: 1. Introduction; ============. This document contains information about testing the release candidates that; will ultimately be the next LLVM release. For more information on how to; manage the actual release, please refer to :doc:`HowToReleaseLLVM`. Overview of the Release Process; -------------------------------. Once the release process starts, the Release Manager will ask for volunteers,; and it'll be the role of each volunteer to:. * Test and benchmark the previous release. * Test and benchmark each release candidate, comparing to the previous release; and candidates. * Identify, reduce and report every regression found during tests and benchmarks. * Make sure the critical bugs get fixed and merged to the next release candidate. Not all bugs or regressions are show-stoppers and it's a bit of a grey area what; should be fixed before the next candidate and what can wait until the next; release. It'll depend on:. * The severity of the bug, how many people it affects and if it's a regression; or a known bug. Known bugs are ""unsupported features"" and some bugs can be; disabled if they have been implemented recently. * The stage in the release. Less critical bugs should be considered to be; fixed between RC1 and RC2, but not so much at the end of it. * If it's a correctness or a performance regression. Performance regression; tends to be taken more lightly than correctness. .. _scripts:. Scripts; =======. The scripts are in the ``utils/release`` directory. test-release.sh; ---------------. This script will check-out, configure and compile LLVM+Clang (+ most add-ons,; like ``compiler-rt``, ``libcxx``, ``libomp`` and ``clang-extra-tools``) in; three stages, and will test the final stage.; It'll have installed the final binaries on the Phase3/Releasei(+Asserts); directory, and that's the one you should use for the test-suite and other; external tes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst:209,release,release,209,interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,9,['release'],['release']
Deployability,"=============================; LLVM Community Support Policy; =============================. As a compilation infrastructure, LLVM has multiple types of users, both; downstream and upstream, of many combinations of its projects, tools and; libraries. There is a core part of it that encompass the implementation of the compiler; (front/middle/back ends), run-time libraries (RT, C++, OpenMP, etc) and; associated tools (debugger, linker, object file manipulation, etc). These; components are present in the public release on our supported architectures; and operating systems and the whole community must maintain and care about. There are, however, other components within the main repository that either; cater to a specific sub-community of LLVM (upstream or downstream) or; help parts of the community to integrate LLVM into their own development tools; or external projects. Those parts of the main repository don't always have; rigorous testing like the core parts, nor are they validated and shipped with; our public upstream releases. Even not being a core part of the project, we have enough sub-communities; needing those changes with enough overlap that having them in the main; repository is beneficial to minimise the repetition of those changes in all; the external repositories that need them. But the maintenance costs of such diverse ecosystem is non trivial, so we divide; the level of support in two tiers: core and peripheral, with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libra",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:514,release,release,514,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst,3,"['integrat', 'release']","['integrate', 'release', 'releases']"
Deployability,"=============================; User Guide for RISC-V Target; =============================. .. contents::; :local:. Introduction; ============. The RISC-V target provides code generation for processors implementing; supported variations of the RISC-V specification. It lives in the; ``llvm/lib/Target/RISCV`` directory. Specification Documents; =======================. There have been a number of revisions to the RISC-V specifications. LLVM aims; to implement the most recent ratified version of the standard RISC-V base ISAs; and ISA extensions with pragmatic variances. The most recent specification can; be found at: https://github.com/riscv/riscv-isa-manual/releases/. `The official RISC-V International specification page; <https://riscv.org/technical/specifications/>`_. is also worth checking, but; tends to significantly lag the specifications linked above. Make sure to check; the `wiki for not yet integrated extensions; <https://wiki.riscv.org/display/HOME/Recently+Ratified+Extensions>`_ and note; that in addition, we sometimes carry support for extensions that have not yet; been ratified (these will be marked as experimental - see below) and support; various vendor-specific extensions (see below). The current known variances from the specification are:. * Unconditionally allowing instructions from zifencei, zicsr, zicntr, and; zihpm without gating them on the extensions being enabled. Previous; revisions of the specification included these instructions in the base; ISA, and we preserve this behavior to avoid breaking existing code. If; a future revision of the specification reuses these opcodes for other; extensions, we may need to reevaluate this choice, and thus recommend; users migrate build systems so as not to rely on this.; * Allowing CSRs to be named without gating on specific extensions. This; applies to all CSR names, not just those in zicsr, zicntr, and zihpm.; * The ordering of ``z*``, ``s*``, and ``x*`` prefixed extension names is not; enforced in user-sp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/RISCVUsage.rst:664,release,releases,664,interpreter/llvm-project/llvm/docs/RISCVUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/RISCVUsage.rst,2,"['integrat', 'release']","['integrated', 'releases']"
Deployability,"==============================; Moving LLVM Projects to GitHub; ==============================. Current Status; ==============. We are planning to complete the transition to GitHub by Oct 21, 2019. See; the GitHub migration `status page <https://llvm.org/GitHubMigrationStatus.html>`_; for the latest updates and instructions for how to migrate your workflows. .. contents:: Table of Contents; :depth: 4; :local:. Introduction; ============. This is a proposal to move our current revision control system from our own; hosted Subversion to GitHub. Below are the financial and technical arguments as; to why we are proposing such a move and how people (and validation; infrastructure) will continue to work with a Git-based LLVM. What This Proposal is *Not* About; =================================. Changing the development policy. This proposal relates only to moving the hosting of our source-code repository; from SVN hosted on our own servers to Git hosted on GitHub. We are not proposing; using GitHub's issue tracker, pull-requests, or code-review. Contributors will continue to earn commit access on demand under the Developer; Policy, except that that a GitHub account will be required instead of SVN; username/password-hash. Why Git, and Why GitHub?; ========================. Why Move At All?; ----------------. This discussion began because we currently host our own Subversion server; and Git mirror on a voluntary basis. The LLVM Foundation sponsors the server and; provides limited support, but there is only so much it can do. Volunteers are not sysadmins themselves, but compiler engineers that happen; to know a thing or two about hosting servers. We also don't have 24/7 support,; and we sometimes wake up to see that continuous integration is broken because; the SVN server is either down or unresponsive. We should take advantage of one of the services out there (GitHub, GitLab,; and BitBucket, among others) that offer better service (24/7 stability, disk; space, Git server, cod",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:301,update,updates,301,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['update'],['updates']
Deployability,"===============================. Introduction; ------------. Using PROOF on Demand is our current recommended way of running a PROOF; cluster. The usage of PoD is in particular helpful for the following; reasons:. - **Sandboxing.** Each user get their own personal PROOF cluster,; separated from the others: a problem occurring on one personal; cluster does not affect the workflow of other users. - **Easier administration and self-servicing.** A user can restart their; personal PROOF cluster in case of troubles without waiting for a; system administrator's intervention. - **Efficient multiuser scheduling.** PROOF on Demand makes PROOF run on; top of an existing resource management system, moving the problem of; scheduling many concurrent users outside of PROOF. This guide particularly refers to the setup of a static PROOF cluster; running on physical hosts: the recommended setup is in practice the same; as the ready-to-go Virtual Analysis Facility. If you want to use PROOF; on the clouds there is no configuration to go through. Setup a resource management system; ----------------------------------. Although PROOF on Demand can run on a cluster of nodes without using a; resource management system (using `pod-ssh`), it is recommended to setup a; dedicated one to benefit from the scheduling in a multiuser environment, or a; dedicated queue on an existing one. As there's a variety of resource management systems, this guide does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the latest CernVM-FS can be found; > [here](http://cernvm.cern.ch/portal",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:1082,configurat,configuration,1082,proof/doc/confman/ConfigProofPoD.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md,1,['configurat'],['configuration']
Deployability,"===============================; Assembling a Complete Toolchain; ===============================. .. contents::; :local:; :depth: 2. Introduction; ============. Clang is only one component in a complete tool chain for C family; programming languages. In order to assemble a complete toolchain,; additional tools and runtime libraries are required. Clang is designed; to interoperate with existing tools and libraries for its target; platforms, and the LLVM project provides alternatives for a number; of these components. This document describes the required and optional components in a; complete toolchain, where to find them, and the supported versions; and limitations of each option. .. warning::. This document currently describes Clang configurations on POSIX-like; operating systems with the GCC-compatible ``clang`` driver. When; targeting Windows with the MSVC-compatible ``clang-cl`` driver, some; of the details are different. Tools; =====. .. FIXME: Describe DWARF-related tools. A complete compilation of C family programming languages typically; involves the following pipeline of tools, some of which are omitted; in some compilations:. * **Preprocessor**: This performs the actions of the C preprocessor:; expanding #includes and #defines.; The ``-E`` flag instructs Clang to stop after this step. * **Parsing**: This parses and semantically analyzes the source language and; builds a source-level intermediate representation (""AST""), producing a; :ref:`precompiled header (PCH) <usersmanual-precompiled-headers>`,; preamble, or; :doc:`precompiled module file (PCM) <Modules>`,; depending on the input.; The ``-precompile`` flag instructs Clang to stop after this step. This is; the default when the input is a header file. * **IR generation**: This converts the source-level intermediate representation; into an optimizer-specific intermediate representation (IR); for Clang, this; is LLVM IR.; The ``-emit-llvm`` flag instructs Clang to stop after this step. If combined; with ``-S",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Toolchain.rst:744,configurat,configurations,744,interpreter/llvm-project/clang/docs/Toolchain.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Toolchain.rst,1,['configurat'],['configurations']
Deployability,"===============================; lit - A Software Testing Tool; ===============================. About; =====. *lit* is a portable tool for executing LLVM and Clang style test suites,; summarizing their results, and providing indication of failures. *lit* is; designed to be a lightweight testing tool with as simple a user interface as; possible. Features; ========. * Portable!; * Flexible test discovery.; * Parallel test execution.; * Support for multiple test formats and test suite designs. Documentation; =============. The official *lit* documentation is in the man page, available online at the LLVM; Command Guide: http://llvm.org/cmds/lit.html. Source; ======. The *lit* source is available as part of LLVM, in the LLVM source repository:; https://github.com/llvm/llvm-project/tree/main/llvm/utils/lit. Contributing to lit; ===================. Please browse the issues labeled *tools:llvm-lit* in LLVM's issue tracker for; ideas on what to work on:; https://github.com/llvm/llvm-project/labels/tools%3Allvm-lit. Before submitting patches, run the test suite to ensure nothing has regressed::. # From within your LLVM source directory.; utils/lit/lit.py \; --path /path/to/your/llvm/build/bin \; utils/lit/tests. Note that lit's tests depend on ``not`` and ``FileCheck``, LLVM utilities.; You will need to have built LLVM tools in order to run lit's test suite; successfully. You'll also want to confirm that lit continues to work when testing LLVM.; Follow the instructions in http://llvm.org/docs/TestingGuide.html to run the; regression test suite:. make check-llvm. And be sure to run the llvm-lit wrapper script as well:. /path/to/your/llvm/build/bin/llvm-lit utils/lit/tests. Finally, make sure lit works when installed via setuptools:. python utils/lit/setup.py install; lit --path /path/to/your/llvm/build/bin utils/lit/tests. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/lit/README.rst:1042,patch,patches,1042,interpreter/llvm-project/llvm/utils/lit/README.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/lit/README.rst,3,"['install', 'patch']","['install', 'installed', 'patches']"
Deployability,"================================; LLVM Tutorial: Table of Contents; ================================. Kaleidoscope: Implementing a Language with LLVM; ===============================================. .. toctree::; :hidden:. MyFirstLanguageFrontend/index. :doc:`MyFirstLanguageFrontend/index`; This is the ""Kaleidoscope"" Language tutorial, showing how to implement a simple; language using LLVM components in C++. .. toctree::; :titlesonly:; :glob:; :numbered:. MyFirstLanguageFrontend/LangImpl*. Building a JIT in LLVM; ===============================================. .. toctree::; :titlesonly:; :glob:; :numbered:. BuildingAJIT*. External Tutorials; ==================. `Tutorial: Creating an LLVM Backend for the Cpu0 Architecture <http://jonathan2251.github.io/lbd/>`_; A step-by-step tutorial for developing an LLVM backend. Under; active development at `<https://github.com/Jonathan2251/lbd>`_ (please; contribute!). `Howto: Implementing LLVM Integrated Assembler`_; A simple guide for how to implement an LLVM integrated assembler for an; architecture. .. _`Howto: Implementing LLVM Integrated Assembler`: http://www.embecosm.com/appnotes/ean10/ean10-howto-llvmas-1.0.html. Advanced Topics; ===============. #. `Writing an Optimization for LLVM <https://llvm.org/pubs/2004-09-22-LCPCLLVMTutorial.html>`_. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/index.rst:1017,integrat,integrated,1017,interpreter/llvm-project/llvm/docs/tutorial/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/index.rst,1,['integrat'],['integrated']
Deployability,"=================================; How To Release LLVM To The Public; =================================. Introduction; ============. This document contains information about successfully releasing LLVM ---; including sub-projects: e.g., ``clang`` and ``compiler-rt`` --- to the public.; It is the Release Manager's responsibility to ensure that a high quality build; of LLVM is released. If you're looking for the document on how to test the release candidates and; create the binary packages, please refer to the :doc:`ReleaseProcess` instead. .. _timeline:. Release Timeline; ================. LLVM is released on a time based schedule --- with major releases roughly; every 6 months. In between major releases there may be dot releases.; The release manager will determine if and when to make a dot release based; on feedback from the community. Typically, dot releases should be made if; there are large number of bug-fixes in the stable branch or a critical bug; has been discovered that affects a large number of users. Unless otherwise stated, dot releases will follow the same procedure as; major releases. Annual Release Schedule; -----------------------. Here is the annual release schedule for LLVM. This is meant to be a; guide, and release managers are not required to follow this exactly.; Releases should be tagged on Tuesdays. =============================== =========================; Release Approx. Date; =============================== =========================; *release branch: even releases* *4th Tue in January*; *release branch: odd releases* *4th Tue in July*; X.1.0-rc1 3 days after branch.; X.1.0-rc2 2 weeks after branch.; X.1.0-rc3 4 weeks after branch; **X.1.0-final** **6 weeks after branch**; **X.1.1** **8 weeks after branch**; **X.1.2** **10 weeks after branch**; **X.1.3** **12 weeks after branch**; **X.1.4** **14 weeks after branch**; **X.1.5** **16 weeks after branch**; **X.1.6 (if necessary)** **18 weeks after branch**; =============================== =======",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:378,release,released,378,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,9,['release'],"['release', 'released', 'releases']"
Deployability,"=================================; User Guide for the DirectX Target; =================================. .. warning::; Disclaimer: The DirectX backend is experimental and under active development.; It is not yet feature complete or ready to be used outside of experimental or; demonstration contexts. .. contents::; :local:. .. toctree::; :hidden:. Introduction; ============. The DirectX target implements the DirectX programmability interfaces. These; interfaces are documented in the `DirectX Specifications. <https://github.com/Microsoft/DirectX-Specs>`_. Initially the backend is aimed at supporting DirectX 12, and support for DirectX; 11 is planned at a later date. The DirectX backend is currently experimental and is not shipped with any; release builds of LLVM tools. To enable building the DirectX backend locally add; ``DirectX`` to the ``LLVM_EXPERIMENTAL_TARGETS_TO_BUILD`` CMake option. For more; information on building LLVM see the :doc:`CMake` documentation. .. _dx-target-triples:. Target Triples; ==============. At present the DirectX target only supports the ``dxil`` architecture, which; generates code for the; `DirectX Intermediate Language. <https://github.com/microsoft/DirectXShaderCompiler/blob/main/docs/DXIL.rst>`_. In addition to target architecture, the DirectX backend also needs to know the; target runtime version and pipeline stage. These are expressed using the OS and; Environment triple component. Presently the DirectX backend requires targeting the ``shadermodel`` OS, and; supports versions 6.0+ (at time of writing the latest announced version is 6.7). .. table:: DirectX Environments. ================== ========================================================; Environment Description; ================== ========================================================; ``pixel`` Pixel shader; ``vertex`` Vertex shader; ``geometry`` Geometry shader; ``hull`` Hull shader (tesselation); ``domain`` Domain shader (tesselation); ``compute`` Compute kernel; ``librar",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DirectXUsage.rst:748,release,release,748,interpreter/llvm-project/llvm/docs/DirectXUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DirectXUsage.rst,1,['release'],['release']
Deployability,"==================================; Benchmarking tips; ==================================. Introduction; ============. For benchmarking a patch we want to reduce all possible sources of; noise as much as possible. How to do that is very OS dependent. Note that low noise is required, but not sufficient. It does not; exclude measurement bias. See; https://www.cis.upenn.edu/~cis501/papers/producing-wrong-data.pdf for; example. General; ================================. * Use a high resolution timer, e.g. perf under linux. * Run the benchmark multiple times to be able to recognize noise. * Disable as many processes or services as possible on the target system. * Disable frequency scaling, turbo boost and address space; randomization (see OS specific section). * Static link if the OS supports it. That avoids any variation that; might be introduced by loading dynamic libraries. This can be done; by passing ``-DLLVM_BUILD_STATIC=ON`` to cmake. * Try to avoid storage. On some systems you can use tmpfs. Putting the; program, inputs and outputs on tmpfs avoids touching a real storage; system, which can have a pretty big variability. To mount it (on linux and freebsd at least)::. mount -t tmpfs -o size=<XX>g none dir_to_mount. Linux; =====. * Disable address space randomization::. echo 0 > /proc/sys/kernel/randomize_va_space. * Set scaling_governor to performance::. for i in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; do; echo performance > /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; done. * Use https://github.com/lpechacek/cpuset to reserve cpus for just the; program you are benchmarking. If using perf, leave at least 2 cores; so that perf runs in one and your program in another::. cset shield -c N1,N2 -k on. This will move all threads out of N1 and N2. The ``-k on`` means; that even kernel threads are moved out. * Disable the SMT pair of the cpus you will use for the benchmark. The; pair of cpu N can be found in; ``/sys/devices/system/cpu/cpuN/topology/t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Benchmarking.rst:138,patch,patch,138,interpreter/llvm-project/llvm/docs/Benchmarking.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Benchmarking.rst,1,['patch'],['patch']
Deployability,"===================================. :program:`clang-format` supports two ways to provide custom style options:; directly specify style configuration in the ``-style=`` command line option or; use ``-style=file`` and put style configuration in the ``.clang-format`` or; ``_clang-format`` file in the project directory. When using ``-style=file``, :program:`clang-format` for each input file will; try to find the ``.clang-format`` file located in the closest parent directory; of the input file. When the standard input is used, the search is started from; the current directory. When using ``-style=file:<format_file_path>``, :program:`clang-format` for; each input file will use the format file located at `<format_file_path>`.; The path may be absolute or relative to the working directory. The ``.clang-format`` file uses YAML format:. .. code-block:: yaml. key1: value1; key2: value2; # A comment.; ... The configuration file can consist of several sections each having different; ``Language:`` parameter denoting the programming language this section of the; configuration is targeted at. See the description of the **Language** option; below for the list of supported languages. The first section may have no; language set, it will set the default style options for all languages.; Configuration sections for specific language will override options set in the; default section. When :program:`clang-format` formats a file, it auto-detects the language using; the file name. When formatting standard input or a file that doesn't have the; extension corresponding to its language, ``-assume-filename=`` option can be; used to override the file name :program:`clang-format` uses to detect the; language. An example of a configuration file for multiple languages:. .. code-block:: yaml. ---; # We'll use defaults from the LLVM style, but with 4 columns indentation.; BasedOnStyle: LLVM; IndentWidth: 4; ---; Language: Cpp; # Force pointers to the type for C++.; DerivePointerAlignment: false; Point",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:1979,configurat,configuration,1979,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,2,['configurat'],['configuration']
Deployability,"===================================; Stack maps and patch points in LLVM; ===================================. .. contents::; :local:; :depth: 2. Definitions; ===========. In this document we refer to the ""runtime"" collectively as all; components that serve as the LLVM client, including the LLVM IR; generator, object code consumer, and code patcher. A stack map records the location of ``live values`` at a particular; instruction address. These ``live values`` do not refer to all the; LLVM values live across the stack map. Instead, they are only the; values that the runtime requires to be live at this point. For; example, they may be the values the runtime will need to resume; program execution at that point independent of the compiled function; containing the stack map. LLVM emits stack map data into the object code within a designated; :ref:`stackmap-section`. This stack map data contains a record for; each stack map. The record stores the stack map's instruction address; and contains an entry for each mapped value. Each entry encodes a; value's location as a register, stack offset, or constant. A patch point is an instruction address at which space is reserved for; patching a new instruction sequence at run time. Patch points look; much like calls to LLVM. They take arguments that follow a calling; convention and may return a value. They also imply stack map; generation, which allows the runtime to locate the patchpoint and; find the location of ``live values`` at that point. Motivation; ==========. This functionality is currently experimental but is potentially useful; in a variety of settings, the most obvious being a runtime (JIT); compiler. Example applications of the patchpoint intrinsics are; implementing an inline call cache for polymorphic method dispatch or; optimizing the retrieval of properties in dynamically typed languages; such as JavaScript. The intrinsics documented here are currently used by the JavaScript; compiler within the open source WebKit pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:52,patch,patch,52,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,2,['patch'],"['patch', 'patcher']"
Deployability,"====================================; JITLink and ORC's ObjectLinkingLayer; ====================================. .. contents::; :local:. Introduction; ============. This document aims to provide a high-level overview of the design and API; of the JITLink library. It assumes some familiarity with linking and; relocatable object files, but should not require deep expertise. If you know; what a section, symbol, and relocation are you should find this document; accessible. If it is not, please submit a patch (:doc:`Contributing`) or file a; bug (:doc:`HowToSubmitABug`). JITLink is a library for :ref:`jit_linking`. It was built to support the :doc:`ORC JIT; APIs<ORCv2>` and is most commonly accessed via ORC's ObjectLinkingLayer API. JITLink was; developed with the aim of supporting the full set of features provided by each; object format; including static initializers, exception handling, thread local; variables, and language runtime registration. Supporting these features enables; ORC to execute code generated from source languages which rely on these features; (e.g. C++ requires object format support for static initializers to support; static constructors, eh-frame registration for exceptions, and TLV support for; thread locals; Swift and Objective-C require language runtime registration for; many features). For some object format features support is provided entirely; within JITLink, and for others it is provided in cooperation with the; (prototype) ORC runtime. JITLink aims to support the following features, some of which are still under; development:. 1. Cross-process and cross-architecture linking of single relocatable objects; into a target *executor* process. 2. Support for all object format features. 3. Open linker data structures (``LinkGraph``) and pass system. JITLink and ObjectLinkingLayer; ==============================. ``ObjectLinkingLayer`` is ORCs wrapper for JITLink. It is an ORC layer that; allows objects to be added to a ``JITDylib``, or emitted from",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:505,patch,patch,505,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['patch'],['patch']
Deployability,"=====================================; Coroutines in LLVM; =====================================. .. contents::; :local:; :depth: 3. .. warning::; Compatibility across LLVM releases is not guaranteed. Introduction; ============. .. _coroutine handle:. LLVM coroutines are functions that have one or more `suspend points`_.; When a suspend point is reached, the execution of a coroutine is suspended and; control is returned back to its caller. A suspended coroutine can be resumed; to continue execution from the last suspend point or it can be destroyed. In the following example, we call function `f` (which may or may not be a; coroutine itself) that returns a handle to a suspended coroutine; (**coroutine handle**) that is used by `main` to resume the coroutine twice and; then destroy it:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); call void @llvm.coro.resume(ptr %hdl); call void @llvm.coro.resume(ptr %hdl); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. .. _coroutine frame:. In addition to the function stack frame which exists when a coroutine is; executing, there is an additional region of storage that contains objects that; keep the coroutine state when a coroutine is suspended. This region of storage; is called the **coroutine frame**. It is created when a coroutine is called; and destroyed when a coroutine either runs to completion or is destroyed; while suspended. LLVM currently supports two styles of coroutine lowering. These styles; support substantially different sets of features, have substantially; different ABIs, and expect substantially different patterns of frontend; code generation. However, the styles also have a great deal in common. In all cases, an LLVM coroutine is initially represented as an ordinary LLVM; function that has calls to `coroutine intrinsics`_ defining the structure of; the coroutine. The coroutine function is then, in the most general case,; rewritten by the coroutine lowering passes to become t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:173,release,releases,173,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['release'],['releases']
Deployability,"=====================================; Cross Translation Unit (CTU) Analysis; =====================================. Normally, static analysis works in the boundary of one translation unit (TU).; However, with additional steps and configuration we can enable the analysis to inline the definition of a function from; another TU. .. contents::; :local:. Overview; ________; CTU analysis can be used in a variety of ways. The importing of external TU definitions can work with pre-dumped PCH; files or generating the necessary AST structure on-demand, during the analysis of the main TU. Driving the static; analysis can also be implemented in multiple ways. The most direct way is to specify the necessary commandline options; of the Clang frontend manually (and generate the prerequisite dependencies of the specific import method by hand). This; process can be automated by other tools, like `CodeChecker <https://github.com/Ericsson/codechecker>`_ and scan-build-py; (preference for the former). PCH-based analysis; __________________; The analysis needs the PCH dumps of all the translations units used in the project.; These can be generated by the Clang Frontend itself, and must be arranged in a specific way in the filesystem.; The index, which maps symbols' USR names to PCH dumps containing them must also be generated by the; `clang-extdef-mapping`. Entries in the index *must* have an `.ast` suffix if the goal; is to use PCH-based analysis, as the lack of that extension signals that the entry is to be used as a source-file, and parsed on-demand.; This tool uses a :doc:`compilation database <../../JSONCompilationDatabase>` to; determine the compilation flags used.; The analysis invocation must be provided with the directory which contains the dumps and the mapping files. Manual CTU Analysis; ###################; Let's consider these source files in our minimal example:. .. code-block:: cpp. // main.cpp; int foo();. int main() {; return 3 / foo();; }. .. code-block:: cpp. // foo.c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/CrossTranslationUnit.rst:231,configurat,configuration,231,interpreter/llvm-project/clang/docs/analyzer/user-docs/CrossTranslationUnit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/CrossTranslationUnit.rst,1,['configurat'],['configuration']
Deployability,"=====================================; Garbage Collection with LLVM; =====================================. .. contents::; :local:. Abstract; ========. This document covers how to integrate LLVM into a compiler for a language which; supports garbage collection. **Note that LLVM itself does not provide a; garbage collector.** You must provide your own. Quick Start; ============. First, you should pick a collector strategy. LLVM includes a number of built; in ones, but you can also implement a loadable plugin with a custom definition.; Note that the collector strategy is a description of how LLVM should generate; code such that it interacts with your collector and runtime, not a description; of the collector itself. Next, mark your generated functions as using your chosen collector strategy.; From c++, you can call:. .. code-block:: c++. F.setGC(<collector description name>);. This will produce IR like the following fragment:. .. code-block:: llvm. define void @foo() gc ""<collector description name>"" { ... }. When generating LLVM IR for your functions, you will need to:. * Use ``@llvm.gcread`` and/or ``@llvm.gcwrite`` in place of standard load and; store instructions. These intrinsics are used to represent load and store; barriers. If you collector does not require such barriers, you can skip; this step. * Use the memory allocation routines provided by your garbage collector's; runtime library. * If your collector requires them, generate type maps according to your; runtime's binary interface. LLVM is not involved in the process. In; particular, the LLVM type system is not suitable for conveying such; information though the compiler. * Insert any coordination code required for interacting with your collector.; Many collectors require running application code to periodically check a; flag and conditionally call a runtime function. This is often referred to; as a safepoint poll. You will need to identify roots (i.e. references to heap objects your collector; needs to kno",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:180,integrat,integrate,180,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['integrat'],['integrate']
Deployability,"========================================; Kaleidoscope: Code generation to LLVM IR; ========================================. .. contents::; :local:. Chapter 3 Introduction; ======================. Welcome to Chapter 3 of the ""`Implementing a language with; LLVM <index.html>`_"" tutorial. This chapter shows you how to transform; the `Abstract Syntax Tree <LangImpl02.html>`_, built in Chapter 2, into; LLVM IR. This will teach you a little bit about how LLVM does things, as; well as demonstrate how easy it is to use. It's much more work to build; a lexer and parser than it is to generate LLVM IR code. :). **Please note**: the code in this chapter and later require LLVM 3.7 or; later. LLVM 3.6 and before will not work with it. Also note that you; need to use a version of this tutorial that matches your LLVM release:; If you are using an official LLVM release, use the version of the; documentation included with your release or on the `llvm.org releases; page <https://llvm.org/releases/>`_. Code Generation Setup; =====================. In order to generate LLVM IR, we want some simple setup to get started.; First we define virtual code generation (codegen) methods in each AST; class:. .. code-block:: c++. /// ExprAST - Base class for all expression nodes.; class ExprAST {; public:; virtual ~ExprAST() = default;; virtual Value *codegen() = 0;; };. /// NumberExprAST - Expression class for numeric literals like ""1.0"".; class NumberExprAST : public ExprAST {; double Val;. public:; NumberExprAST(double Val) : Val(Val) {}; Value *codegen() override;; };; ... The codegen() method says to emit IR for that AST node along with all; the things it depends on, and they all return an LLVM Value object.; ""Value"" is the class used to represent a ""`Static Single Assignment; (SSA) <http://en.wikipedia.org/wiki/Static_single_assignment_form>`_; register"" or ""SSA value"" in LLVM. The most distinct aspect of SSA values; is that their value is computed as the related instruction executes, and; i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl03.rst:815,release,release,815,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl03.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl03.rst,5,['release'],"['release', 'releases']"
Deployability,"==========================================; How to build Windows Itanium applications.; ==========================================. Introduction; ============. This document contains information describing how to create a Windows Itanium toolchain. Windows Itanium allows you to deploy Itanium C++ ABI applications on top of the MS VS CRT.; This environment can use the Windows SDK headers directly and does not required additional; headers or additional runtime machinery (such as is used by mingw). Windows Itanium Stack:. * Uses the Itanium C++ abi.; * libc++.; * libc++-abi.; * libunwind.; * The MS VS CRT.; * Is compatible with MS Windows SDK include headers.; * COFF/PE file format.; * LLD. Note: compiler-rt is not used. This functionality is supplied by the MS VCRT. Prerequisites; =============. * The MS SDK is installed as part of MS Visual Studio.; * Clang with support for the windows-itanium triple.; * COFF LLD with support for the -autoimport switch. Known issues:; =============. SJLJ exceptions, ""-fsjlj-exceptions"", are the only currently supported model. link.exe (the MS linker) is unsuitable as it doesn't support auto-importing which; is currently required to link correctly. However, if that limitation is removed; then there are no other known issues with using link.exe. Currently, there is a lack of a usable Windows compiler driver for Windows Itanium.; A reasonable work-around is to build clang with a windows-msvc default target and; then override the triple with e.g. ""-Xclang -triple -Xclang x86_64-unknown-windows-itanium"".; The linker can be specified with: ""-fuse-ld=lld"". In the Itanium C++ ABI the first member of an object is a pointer to the vtable; for its class. The vtable is often emitted into the object file with the key function; and must be imported for classes marked dllimport. The pointers must be globally; unique. Unfortunately, the COFF/PE file format does not provide a mechanism to; store a runtime address from another DLL into this pointer (al",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildWindowsItaniumPrograms.rst:279,deploy,deploy,279,interpreter/llvm-project/llvm/docs/HowToBuildWindowsItaniumPrograms.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildWindowsItaniumPrograms.rst,2,"['deploy', 'install']","['deploy', 'installed']"
Deployability,"===========================================; Clang |release| |ReleaseNotesTitle|; ===========================================. .. contents::; :local:; :depth: 2. Written by the `LLVM Team <https://llvm.org/>`_. .. only:: PreRelease. .. warning::; These are in-progress notes for the upcoming Clang |version| release.; Release notes for previous releases can be found on; `the Releases Page <https://llvm.org/releases/>`_. Introduction; ============. This document contains the release notes for the Clang C/C++/Objective-C; frontend, part of the LLVM Compiler Infrastructure, release |release|. Here we; describe the status of Clang in some detail, including major; improvements from the previous release and new feature work. For the; general LLVM release notes, see `the LLVM; documentation <https://llvm.org/docs/ReleaseNotes.html>`_. For the libc++ release notes,; see `this page <https://libcxx.llvm.org/ReleaseNotes.html>`_. All LLVM releases; may be downloaded from the `LLVM releases web site <https://llvm.org/releases/>`_. For more information about Clang or LLVM, including information about the; latest release, please see the `Clang Web Site <https://clang.llvm.org>`_ or the; `LLVM Web Site <https://llvm.org>`_. Potentially Breaking Changes; ============================; These changes are ones which we think may surprise users when upgrading to; Clang |release| because of the opportunity they pose for disruption to existing; code bases. - Fix a bug in reversed argument for templated operators.; This breaks code in C++20 which was previously accepted in C++17.; Clang did not properly diagnose such casese in C++20 before this change. Eg:. .. code-block:: cpp. struct P {};; template<class S> bool operator==(const P&, const S&);. struct A : public P {};; struct B : public P {};. // This equality is now ambiguous in C++20.; bool ambiguous(A a, B b) { return a == b; }. template<class S> bool operator!=(const P&, const S&);; // Ok. Found a matching operator!=.; bool fine(A a, B ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:52,release,release,52,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,12,['release'],"['release', 'releases']"
Deployability,"=============================================; Building a JIT: Per-function Lazy Compilation; =============================================. .. contents::; :local:. **This tutorial is under active development. It is incomplete and details may; change frequently.** Nonetheless we invite you to try it out as it stands, and; we welcome any feedback. Chapter 3 Introduction; ======================. **Warning: This text is currently out of date due to ORC API updates.**. **The example code has been updated and can be used. The text will be updated; once the API churn dies down.**. Welcome to Chapter 3 of the ""Building an ORC-based JIT in LLVM"" tutorial. This; chapter discusses lazy JITing and shows you how to enable it by adding an ORC; CompileOnDemand layer the JIT from `Chapter 2 <BuildingAJIT2.html>`_. Lazy Compilation; ================. When we add a module to the KaleidoscopeJIT class from Chapter 2 it is; immediately optimized, compiled and linked for us by the IRTransformLayer,; IRCompileLayer and RTDyldObjectLinkingLayer respectively. This scheme, where all the; work to make a Module executable is done up front, is simple to understand and; its performance characteristics are easy to reason about. However, it will lead; to very high startup times if the amount of code to be compiled is large, and; may also do a lot of unnecessary compilation if only a few compiled functions; are ever called at runtime. A truly ""just-in-time"" compiler should allow us to; defer the compilation of any given function until the moment that function is; first called, improving launch times and eliminating redundant work. In fact,; the ORC APIs provide us with a layer to lazily compile LLVM IR:; *CompileOnDemandLayer*. The CompileOnDemandLayer class conforms to the layer interface described in; Chapter 2, but its addModule method behaves quite differently from the layers; we have seen so far: rather than doing any work up front, it just scans the; Modules being added and arranges for each",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst:458,update,updates,458,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst,3,['update'],"['updated', 'updates']"
Deployability,"==============================================; Control Flow Verification Tool Design Document; ==============================================. .. contents::; :local:. Objective; =========. This document provides an overview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:590,continuous,continuous,590,interpreter/llvm-project/llvm/docs/CFIVerify.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst,2,"['continuous', 'integrat']","['continuous', 'integration']"
Deployability,"==============================================; LLVM Atomic Instructions and Concurrency Guide; ==============================================. .. contents::; :local:. Introduction; ============. LLVM supports instructions which are well-defined in the presence of threads and; asynchronous signals. The atomic instructions are designed specifically to provide readable IR and; optimized code generation for the following:. * The C++ ``<atomic>`` header and C ``<stdatomic.h>`` headers. These; were originally added in C++11 and C11. The memory model has been; subsequently adjusted to correct errors in the initial; specification, so LLVM currently intends to implement the version; specified by C++20. (See the `C++20 draft standard; <https://isocpp.org/files/papers/N4860.pdf>`_ or the unofficial; `latest C++ draft <https://eel.is/c++draft/>`_. A `C2x draft; <https://www.open-std.org/jtc1/sc22/wg14/www/docs/n3047.pdf>`_ is; also available, though the text has not yet been updated with the; errata corrected by C++20.). * Proper semantics for Java-style memory, for both ``volatile`` and regular; shared variables. (`Java Specification; <http://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html>`_). * gcc-compatible ``__sync_*`` builtins. (`Description; <https://gcc.gnu.org/onlinedocs/gcc/_005f_005fsync-Builtins.html>`_). * Other scenarios with atomic semantics, including ``static`` variables with; non-trivial constructors in C++. Atomic and volatile in the IR are orthogonal; ""volatile"" is the C/C++ volatile,; which ensures that every volatile load and store happens and is performed in the; stated order. A couple examples: if a SequentiallyConsistent store is; immediately followed by another SequentiallyConsistent store to the same; address, the first store can be erased. This transformation is not allowed for a; pair of volatile stores. On the other hand, a non-volatile non-atomic load can; be moved across a volatile load freely, but not an Acquire load. This document is int",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:979,update,updated,979,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['update'],['updated']
Deployability,"==================================================; How To Add A Constrained Floating-Point Intrinsic; ==================================================. .. contents::; :local:. .. warning::; This is a work in progress. Add the intrinsic; =================. Multiple files need to be updated when adding a new constrained intrinsic. Add the new intrinsic to the table of intrinsics::. include/llvm/IR/Intrinsics.td. Add SelectionDAG node types; ===========================. Add the new STRICT version of the node type to the ISD::NodeType enum::. include/llvm/CodeGen/ISDOpcodes.h. Strict version name must be a concatenation of prefix ``STRICT_`` and the name; of corresponding non-strict node name. For instance, strict version of the; node FADD must be STRICT_FADD. Update mappings; ===============. Add new record to the mapping of instructions to constrained intrinsic and; DAG nodes::. include/llvm/IR/ConstrainedOps.def. Follow instructions provided in this file. Update IR components; ====================. Update the IR verifier::. lib/IR/Verifier.cpp. Update Selector components; ==========================. Building the SelectionDAG; -------------------------. The function SelectionDAGBuilder::visitConstrainedFPIntrinsic builds DAG nodes; using mappings specified in ConstrainedOps.def. If however this default build is; not sufficient, the build can be modified, see how it is implemented for; STRICT_FP_ROUND. The new STRICT node will eventually be converted; to the matching non-STRICT node. For this reason it should have the same; operands and values as the non-STRICT version but should also use the chain.; This makes subsequent sharing of code for STRICT and non-STRICT code paths; easier::. lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp. Most of the STRICT nodes get legalized the same as their matching non-STRICT; counterparts. A new STRICT node with this property must get added to the; switch in SelectionDAGLegalize::LegalizeOp().::. lib/CodeGen/SelectionDAG/LegalizeDAG",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AddingConstrainedIntrinsics.rst:285,update,updated,285,interpreter/llvm-project/llvm/docs/AddingConstrainedIntrinsics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AddingConstrainedIntrinsics.rst,1,['update'],['updated']
Deployability,"======================================================; How To Add Your Build Configuration To LLVM Buildbot Infrastructure; ===================================================================. Introduction; ============. This document contains information about adding a build configuration and; buildbot-worker to private worker builder to LLVM Buildbot Infrastructure. Buildmasters; ============. There are two buildmasters running. * The main buildmaster at `<https://lab.llvm.org/buildbot>`_. All builders; attached to this machine will notify commit authors every time they break; the build.; * The staging buildmaster at `<https://lab.llvm.org/staging>`_. All builders; attached to this machine will be completely silent by default when the build; is broken. This buildmaster is reconfigured every two hours with any new; commits from the llvm-zorg repository. In order to remain connected to the main buildmaster (and thus notify; developers of failures), a builbot must:. * Be building a supported configuration. Builders for experimental backends; should generally be attached to staging buildmaster.; * Be able to keep up with new commits to the main branch, or at a minimum; recover to tip of tree within a couple of days of falling behind. Additionally, we encourage all bot owners to point their bots towards the; staging master during maintenance windows, instability troubleshooting, and; such. Roles & Expectations; ====================. Each buildbot has an owner who is the responsible party for addressing problems; which arise with said buildbot. We generally expect the bot owner to be; reasonably responsive. For some bots, the ownership responsibility is split between a ""resource owner""; who provides the underlying machine resource, and a ""configuration owner"" who; maintains the build configuration. Generally, operational responsibility lies; with the ""config owner"". We do expect ""resource owners"" - who are generally; the contact listed in a workers attributes - to proxy",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:1020,configurat,configuration,1020,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['configurat'],['configuration']
Deployability,"======================================================; LLVM Link Time Optimization: Design and Implementation; ======================================================. .. contents::; :local:. Description; ===========. LLVM features powerful intermodular optimizations which can be used at link; time. Link Time Optimization (LTO) is another name for intermodular; optimization when performed during the link stage. This document describes the; interface and design between the LTO optimizer and the linker. Design Philosophy; =================. The LLVM Link Time Optimizer provides complete transparency, while doing; intermodular optimization, in the compiler tool chain. Its main goal is to let; the developer take advantage of intermodular optimizations without making any; significant changes to the developer's makefiles or build system. This is; achieved through tight integration with the linker. In this model, the linker; treats LLVM bitcode files like native object files and allows mixing and; matching among them. The linker uses `libLTO`_, a shared object, to handle LLVM; bitcode files. This tight integration between the linker and LLVM optimizer; helps to do optimizations that are not possible in other models. The linker; input allows the optimizer to avoid relying on conservative escape analysis. .. _libLTO-example:. Example of link time optimization; ---------------------------------. The following example illustrates the advantages of LTO's integrated approach; and clean interface. This example requires a system linker which supports LTO; through the interface described in this document. Here, clang transparently; invokes system linker. * Input source file ``a.c`` is compiled into LLVM bitcode form.; * Input source file ``main.c`` is compiled into native object code. .. code-block:: c++. --- a.h ---; extern int foo1(void);; extern void foo2(void);; extern void foo4(void);. --- a.c ---; #include ""a.h"". static signed int i = 0;. void foo2(void) {; i = -1;; }. static ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:876,integrat,integration,876,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['integrat'],['integration']
Deployability,"=======================================================; Building a JIT: Starting out with KaleidoscopeJIT; =======================================================. .. contents::; :local:. Chapter 1 Introduction; ======================. **Warning: This tutorial is currently being updated to account for ORC API; changes. Only Chapters 1 and 2 are up-to-date.**. **Example code from Chapters 3 to 5 will compile and run, but has not been; updated**. Welcome to Chapter 1 of the ""Building an ORC-based JIT in LLVM"" tutorial. This; tutorial runs through the implementation of a JIT compiler using LLVM's; On-Request-Compilation (ORC) APIs. It begins with a simplified version of the; KaleidoscopeJIT class used in the; `Implementing a language with LLVM <LangImpl01.html>`_ tutorials and then; introduces new features like concurrent compilation, optimization, lazy; compilation and remote execution. The goal of this tutorial is to introduce you to LLVM's ORC JIT APIs, show how; these APIs interact with other parts of LLVM, and to teach you how to recombine; them to build a custom JIT that is suited to your use-case. The structure of the tutorial is:. - Chapter #1: Investigate the simple KaleidoscopeJIT class. This will; introduce some of the basic concepts of the ORC JIT APIs, including the; idea of an ORC *Layer*. - `Chapter #2 <BuildingAJIT2.html>`_: Extend the basic KaleidoscopeJIT by adding; a new layer that will optimize IR and generated code. - `Chapter #3 <BuildingAJIT3.html>`_: Further extend the JIT by adding a; Compile-On-Demand layer to lazily compile IR. - `Chapter #4 <BuildingAJIT4.html>`_: Improve the laziness of our JIT by; replacing the Compile-On-Demand layer with a custom layer that uses the ORC; Compile Callbacks API directly to defer IR-generation until functions are; called. - `Chapter #5 <BuildingAJIT5.html>`_: Add process isolation by JITing code into; a remote process with reduced privileges using the JIT Remote APIs. To provide input for our JIT we will us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst:281,update,updated,281,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst,2,['update'],['updated']
Deployability,"=======================================================; How to Update Debug Info: A Guide for LLVM Pass Authors; =======================================================. .. contents::; :local:. Introduction; ============. Certain kinds of code transformations can inadvertently result in a loss of; debug info, or worse, make debug info misrepresent the state of a program. This document specifies how to correctly update debug info in various kinds of; code transformations, and offers suggestions for how to create targeted debug; info tests for arbitrary transformations. For more on the philosophy behind LLVM debugging information, see; :doc:`SourceLevelDebugging`. Rules for updating debug locations; ==================================. .. _WhenToPreserveLocation:. When to preserve an instruction location; ----------------------------------------. A transformation should preserve the debug location of an instruction if the; instruction either remains in its basic block, or if its basic block is folded; into a predecessor that branches unconditionally. The APIs to use are; ``IRBuilder``, or ``Instruction::setDebugLoc``. The purpose of this rule is to ensure that common block-local optimizations; preserve the ability to set breakpoints on source locations corresponding to; the instructions they touch. Debugging, crash logs, and SamplePGO accuracy; would be severely impacted if that ability were lost. Examples of transformations that should follow this rule include:. * Instruction scheduling. Block-local instruction reordering should not drop; source locations, even though this may lead to jumpy single-stepping; behavior. * Simple jump threading. For example, if block ``B1`` unconditionally jumps to; ``B2``, *and* is its unique predecessor, instructions from ``B2`` can be; hoisted into ``B1``. Source locations from ``B2`` should be preserved. * Peephole optimizations that replace or expand an instruction, like ``(add X; X) => (shl X 1)``. The location of the ``shl`` instru",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst:416,update,update,416,interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,1,['update'],['update']
Deployability,"============================================================; Extending LLVM: Adding instructions, intrinsics, types, etc.; ============================================================. Introduction and Warning; ========================. During the course of using LLVM, you may wish to customize it for your research; project or for experimentation. At this point, you may realize that you need to; add something to LLVM, whether it be a new fundamental type, a new intrinsic; function, or a whole new instruction. When you come to this realization, stop and think. Do you really need to extend; LLVM? Is it a new fundamental capability that LLVM does not support at its; current incarnation or can it be synthesized from already pre-existing LLVM; elements? If you are not sure, ask on the `LLVM forums; <https://discourse.llvm.org>`_. The reason is that; extending LLVM will get involved as you need to update all the different passes; that you intend to use with your extension, and there are ``many`` LLVM analyses; and transformations, so it may be quite a bit of work. Adding an `intrinsic function`_ is far easier than adding an; instruction, and is transparent to optimization passes. If your added; functionality can be expressed as a function call, an intrinsic function is the; method of choice for LLVM extension. Before you invest a significant amount of effort into a non-trivial extension,; **ask on the list** if what you are looking to do can be done with; already-existing infrastructure, or if maybe someone else is already working on; it. You will save yourself a lot of time and effort by doing so. .. _intrinsic function:. Adding a new intrinsic function; ===============================. Adding a new intrinsic function to LLVM is much easier than adding a new; instruction. Almost all extensions to LLVM should start as an intrinsic; function and then be turned into an instruction if warranted. #. ``llvm/docs/LangRef.html``:. Document the intrinsic. Decide whether it is cod",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:906,update,update,906,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,1,['update'],['update']
Deployability,"===================================================================; How To Add Your Build Configuration To LLVM Buildbot Infrastructure; ===================================================================. Introduction; ============. This document contains information about adding a build configuration and; buildbot-worker to private worker builder to LLVM Buildbot Infrastructure. Buildmasters; ============. There are two buildmasters running. * The main buildmaster at `<https://lab.llvm.org/buildbot>`_. All builders; attached to this machine will notify commit authors every time they break; the build.; * The staging buildmaster at `<https://lab.llvm.org/staging>`_. All builders; attached to this machine will be completely silent by default when the build; is broken. This buildmaster is reconfigured every two hours with any new; commits from the llvm-zorg repository. In order to remain connected to the main buildmaster (and thus notify; developers of failures), a builbot must:. * Be building a supported configuration. Builders for experimental backends; should generally be attached to staging buildmaster.; * Be able to keep up with new commits to the main branch, or at a minimum; recover to tip of tree within a couple of days of falling behind. Additionally, we encourage all bot owners to point their bots towards the; staging master during maintenance windows, instability troubleshooting, and; such. Roles & Expectations; ====================. Each buildbot has an owner who is the responsible party for addressing problems; which arise with said buildbot. We generally expect the bot owner to be; reasonably responsive. For some bots, the ownership responsibility is split between a ""resource owner""; who provides the underlying machine resource, and a ""configuration owner"" who; maintains the build configuration. Generally, operational responsibility lies; with the ""config owner"". We do expect ""resource owners"" - who are generally; the contact listed in a workers attribut",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:291,configurat,configuration,291,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['configurat'],['configuration']
Deployability,"===================================================================; How to Cross Compile Compiler-rt Builtins For Arm; ===================================================================. Introduction; ============. This document contains information about building and testing the builtins part; of compiler-rt for an Arm target, from an x86_64 Linux machine. While this document concentrates on Arm and Linux the general principles should; apply to other targets supported by compiler-rt. Further contributions for other; targets are welcome. The instructions in this document depend on libraries and programs external to; LLVM, there are many ways to install and configure these dependencies so you; may need to adapt the instructions here to fit your own local situation. Prerequisites; =============. In this use case we'll be using cmake on a Debian-based Linux system,; cross-compiling from an x86_64 host to a hard-float Armv7-A target. We'll be; using as many of the LLVM tools as we can, but it is possible to use GNU; equivalents. * ``A build of LLVM/clang for the llvm-tools and llvm-config``; * ``A clang executable with support for the ARM target``; * ``compiler-rt sources``; * ``The qemu-arm user mode emulator``; * ``An arm-linux-gnueabihf sysroot``. In this example we will be using ninja. See https://compiler-rt.llvm.org/ for more information about the dependencies; on clang and LLVM. See https://llvm.org/docs/GettingStarted.html for information about obtaining; the source for LLVM and compiler-rt. Note that the getting started guide; places compiler-rt in the projects subdirectory, but this is not essential and; if you are using the BaremetalARM.cmake cache for v6-M, v7-M and v7-EM then; compiler-rt must be placed in the runtimes directory. ``qemu-arm`` should be available as a package for your Linux distribution. The most complicated of the prerequisites to satisfy is the arm-linux-gnueabihf; sysroot. In theory it is possible to use the Linux distributions multiarch",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToCrossCompileBuiltinsOnArm.rst:655,install,install,655,interpreter/llvm-project/llvm/docs/HowToCrossCompileBuiltinsOnArm.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToCrossCompileBuiltinsOnArm.rst,1,['install'],['install']
Deployability,"=====================================================================; Building a JIT: Adding Optimizations -- An introduction to ORC Layers; =====================================================================. .. contents::; :local:. **This tutorial is under active development. It is incomplete and details may; change frequently.** Nonetheless we invite you to try it out as it stands, and; we welcome any feedback. Chapter 2 Introduction; ======================. **Warning: This tutorial is currently being updated to account for ORC API; changes. Only Chapters 1 and 2 are up-to-date.**. **Example code from Chapters 3 to 5 will compile and run, but has not been; updated**. Welcome to Chapter 2 of the ""Building an ORC-based JIT in LLVM"" tutorial. In; `Chapter 1 <BuildingAJIT1.html>`_ of this series we examined a basic JIT; class, KaleidoscopeJIT, that could take LLVM IR modules as input and produce; executable code in memory. KaleidoscopeJIT was able to do this with relatively; little code by composing two off-the-shelf *ORC layers*: IRCompileLayer and; ObjectLinkingLayer, to do much of the heavy lifting. In this layer we'll learn more about the ORC layer concept by using a new layer,; IRTransformLayer, to add IR optimization support to KaleidoscopeJIT. Optimizing Modules using the IRTransformLayer; =============================================. In `Chapter 4 <LangImpl04.html>`_ of the ""Implementing a language with LLVM""; tutorial series the llvm *FunctionPassManager* is introduced as a means for; optimizing LLVM IR. Interested readers may read that chapter for details, but; in short: to optimize a Module we create an llvm::FunctionPassManager; instance, configure it with a set of optimizations, then run the PassManager on; a Module to mutate it into a (hopefully) more optimized but semantically; equivalent form. In the original tutorial series the FunctionPassManager was; created outside the KaleidoscopeJIT and modules were optimized before being; added to it. In thi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst:513,update,updated,513,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,2,['update'],['updated']
Deployability,"===========================================================================; Bits Size Field Name Description; ======= ======= =============================== ===========================================================================; 3:0 4 bits RESERVED Reserved, must be 0.; 11:4 8 bits INST_PREF_SIZE Number of instruction bytes to prefetch, starting at the kernel's entry; point instruction, before wavefront starts execution. The value is 0..255; with a granularity of 128 bytes.; 12 1 bit RESERVED Reserved, must be 0.; 13 1 bit GLG_EN If 1, group launch guarantee will be enabled for this dispatch; 30:14 17 bits RESERVED Reserved, must be 0.; 31 1 bit IMAGE_OP If 1, the kernel execution contains image instructions. If executed as; part of a graphics pipeline, image read instructions will stall waiting; for any necessary ``WAIT_SYNC`` fence to be performed in order to; indicate that earlier pipeline stages have completed writing to the; image. Not used for compute kernels that are not part of a graphics pipeline and; must be 0.; 32 **Total size 4 bytes.**; ======= ===================================================================================================================. .. .. table:: Floating Point Rounding Mode Enumeration Values; :name: amdgpu-amdhsa-floating-point-rounding-mode-enumeration-values-table. ====================================== ===== ==============================; Enumeration Name Value Description; ====================================== ===== ==============================; FLOAT_ROUND_MODE_NEAR_EVEN 0 Round Ties To Even; FLOAT_ROUND_MODE_PLUS_INFINITY 1 Round Toward +infinity; FLOAT_ROUND_MODE_MINUS_INFINITY 2 Round Toward -infinity; FLOAT_ROUND_MODE_ZERO 3 Round Toward 0; ====================================== ===== ==============================. .. table:: Extended FLT_ROUNDS Enumeration Values; :name: amdgpu-rounding-mode-enumeration-values-table. +------------------------+---------------+-------------------+--------------------+----",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:179493,pipeline,pipeline,179493,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['pipeline'],['pipeline']
Deployability,"=x=9.09989, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=6.04652, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=2.48563, mean=m=-7.39713, sigma=sx=0.1. The new-style error logging is active whenever MINUIT is operating on such a p.d.f. The default value for N is 3.; Outside the MINUIT context the evaluation error each evualuation error will generate a separate message through; RooMsgService; Other new features. The RooAddPdf constructor has been augmented with an additional boolean argument that allows to; interpret the supplied fraction parameters as recursive fractions rather than plain fractions.; If activated, an example RooAddPdf with three input p.d.f. A,B,C and two fractions fA and fB will; result in the expression; fA*A + (1-fA)(fB*B + 1-fB*C) rather than fA*A + fB*B + (1-fA-fB)*C. Recursive fraction have the advantage that all fraction can be defined to be in the range [0-1]; without resulting in configuration where the sum of all fractions exceeds 1.; The low-level object printing interface printToStream() has been deprecated in favor of a new; printStream() method which allows much greater control over the information printed. ; The printing of almost all RooFit objects has been reworked to present a more uniform look and feel.; The standard one-line result of the high-level Print() method without option now looks like. // Variable; x.Print() ;; RooRealVar::x = 0 L(-10 - 10) . // Function or p.d.f; gx.Print() ;; RooGaussian::gx[ x=x mean=m sigma=sx ] = 1. // Dataset; d.Print() ;; RooDataSet::gData[x,y] = 1000 entries. // RooPlot; frame.Print() ;; framex[x] = (RooHist::h_gData,RooCurve::g_Int[y]_Norm[x,y]_Comp[g]). Inside class RooPlot the default name of contained curves and histograms has been ; reworked in something more self descriptive as is shown in the above example. A usual,; a user supplied name can always be set by supplying the Name(c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:18118,configurat,configuration,18118,roofit/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html,1,['configurat'],['configuration']
Deployability,">`; and `<platform>` as appropriate. Note that the latest version of Python; is 2.4.1. #### Building from Source. The standard installation instructions for building ROOT from source; apply, with the addition that the build of `PyROOT` needs to be enabled; at the configuration step. First, follow the instructions for obtaining; and unpacking the source, and setting up the build environment. Then, use the following command to configure the build process (of; course, feel free to add any additional flags you may need):. `$ ./configure <arch> [--with-python-incdir=<dir>][--with-python-libdir=>dir>]`. For details on `<arch>` see the official build pages, the Python include; directory should point to the directory that contains `Python.h` and the; library directory should point to the directory containing; `libpythonx.y.so`, where '`x`' and '`y`' are the major and minor version; number, respectively. If you do not specify include and library; directories explicitly, the configuration process will try the; `PYTHONDIR` environment variable or, alternatively, the standard; locations. A recent distribution of Python is required: version 2.4.3 is preferred,; but the older 2.2.x and 2.3.x versions suffice and are supported as; well. Versions older than 2.2 are not supported and will not work. Note; that one problem with 2.2 is that the shared library of the `Python`; interpreter core is not build by default and the '--enable-shared' flag; should thus be used when building `Python` from source. If the `Python`; interpreter that is installed on your system is too old, please obtain a; new version from <http://www.python.org>. Once configured, you continue the build process the normal way:. `$ make`. `$ make install`. After some time, a library called `libPyROOT.so` (or `libPyROOT.dll`, on; Windows) will be created in the; `$ROOTSYS/lib `(`$ROOTSYS/bin on Windows`) directory and a top Python; module, `ROOT.py`, will be copied into the same place. The final step is; to setup the s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:7566,configurat,configuration,7566,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['configurat'],['configuration']
Deployability,">`_. Introduction; ============. This document contains the release notes for the LLVM Compiler Infrastructure,; release |release|. Here we describe the status of LLVM, including major improvements; from the previous release, improvements in various subprojects of LLVM, and; some of the current users of the code. All LLVM releases may be downloaded; from the `LLVM releases web site <https://llvm.org/releases/>`_. For more information about LLVM, including information about the latest; release, please check out the `main LLVM web site <https://llvm.org/>`_. If you; have questions or comments, the `Discourse forums; <https://discourse.llvm.org>`_ is a good place to ask; them. Note that if you are reading this file from a Git checkout or the main; LLVM web page, this document applies to the *next* release, not the current; one. To see the release notes for a specific release, please see the `releases; page <https://llvm.org/releases/>`_. Non-comprehensive list of changes in this release; =================================================; .. NOTE; For small 1-3 sentence descriptions, just add an entry at the end of; this list. If your description won't fit comfortably in one bullet; point (e.g. maybe you would like to give an example of the; functionality, or simply have a lot to talk about), see the `NOTE` below; for adding a new subsection. * ... Update on required toolchains to build LLVM; -------------------------------------------. Changes to the LLVM IR; ----------------------. * The `llvm.stacksave` and `llvm.stackrestore` intrinsics now use; an overloaded pointer type to support non-0 address spaces.; * The constant expression variants of the following instructions have been; removed:. * ``and``; * ``or``; * ``lshr``; * ``ashr``; * ``zext``; * ``sext``; * ``fptrunc``; * ``fpext``; * ``fptoui``; * ``fptosi``; * ``uitofp``; * ``sitofp``. * Added `llvm.exp10` intrinsic. * Added a ``code_model`` attribute for the `global variable <LangRef.html#global-variables>`_. C",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst:1323,release,release,1323,interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,1,['release'],['release']
Deployability,">`_. Version 3.6 and newer are known to work. You can; install Python with Visual Studio 2019, from the Microsoft store or from; the `Python web site <http://www.python.org/>`_. We recommend the latter since it; allows you to adjust installation options. You will need `Git for Windows <https://git-scm.com/>`_ with bash tools, too.; Git for Windows is also bundled with Visual Studio 2019. Getting Started; ===============; Here's the short story for getting up and running quickly with LLVM.; These instruction were tested with Visual Studio 2019 and Python 3.9.6:. 1. Download and install `Visual Studio <https://visualstudio.microsoft.com/>`_.; 2. In the Visual Studio installer, Workloads tab, select the; **Desktop development with C++** workload. Under Individual components tab,; select **Git for Windows**.; 3. Complete the Visual Studio installation.; 4. Download and install the latest `Python 3 release <http://www.python.org/>`_.; 5. In the first install screen, select both **Install launcher for all users**; and **Add Python to the PATH**. This will allow installing psutil for all; users for the regression tests and make Python available from the command; line.; 6. In the second install screen, select (again) **Install for all users** and; if you want to develop `lldb <https://lldb.llvm.org/>`_, selecting; **Download debug binaries** is useful.; 7. Complete the Python installation.; 8. Run a ""Developer Command Prompt for VS 2019"" **as administrator**. This command; prompt provides correct path and environment variables to Visual Studio and; the installed tools.; 9. In the terminal window, type the commands:. .. code-block:: bat. c:; cd \. You may install the llvm sources in other location than ``c:\llvm`` but do not; install into a path containing spaces (e.g. ``c:\Documents and Settings\...``); as it will fail. 10. Register the Microsoft Debug Interface Access (DIA) DLLs. .. code-block:: bat. regsvr32 ""%VSINSTALLDIR%\DIA SDK\bin\msdia140.dll""; regsvr32 ""%VSINSTALLDI",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst:3283,install,install,3283,interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,1,['install'],['install']
Deployability,"A compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directly accesses the; kernel argument memory in the same way constant memory is accessed. (Note; that the HSA specification allows an implementation to copy the kernel; argument contents to another location that is accessed by the kernel.); 5. An AQL kernel dispatch packet is created on the AQL queue. The HSA compatible; runtime api uses 64-bit atomic operations to reserve space in the AQL queue; for the packet. The packet must be set up, and the final write must use an; atomic store release to set the packet kind to ensure the packet contents are; visible to the kernel agent. AQL defines a doorbell signal mechanism to; notify the kernel agent that the AQL queue has been updated. These rules, and; the layout of the AQL queue and kernel dispatch packet is defined in the *HSA; System Architecture Specification* [HSA]_.; 6. A kernel dispatch packet includes information about the actual dispatch,; such as grid and work-group size, together with information from the code; object about the kernel, such as segment sizes. The HSA compatible runtime; queries on the kernel symbol can be used to obtain the code object values; which are recorded in the :ref:`amdgpu-amdhsa-code-object-metadata`.; 7. CP executes micro-code and is responsible for detecting and setting up the; GPU to execute the wavefronts of a kernel dispatch.; 8. CP ensures that when the a wavefront starts executing the kernel machine; code, the scalar general purpose registers (SGPR) and vector general purpose; registers",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:151217,release,release,151217,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability,"ADERS ""${_cxx_inc_join}""); if (NOT CLING_CXX_HEADERS); MESSAGE(WARNING ""Cannot determine location of C++ headers for runtime.""); endif(); endif(). MESSAGE(STATUS ""Cling will look for C++ headers in '${CLING_CXX_HEADERS}' at runtime.""). # In modules builds we 'mount' our own stl modulemap for libstdc++. In order to do this,; # we need to know where is ROOT/cling STL.; set_property(GLOBAL PROPERTY ROOT_CLING_CXX_HEADERS_LOCATION ""${CLING_CXX_HEADERS}""). # FIXME: We should use file(GENERATE) cmake command.; file(WRITE ${CMAKE_CURRENT_BINARY_DIR}/cling-compiledata.h.in; ""; #define CLING_CXX_INCL \""${CLING_CXX_HEADERS}\""; #define CLING_INCLUDE_PATHS \""${CLING_INCLUDE_PATHS}\""; ""); if (CMAKE_OSX_SYSROOT); # CMAKE_OSX_SYSROOT hardcodes the concrete version of the sdk; # (eg .../MacOSX11.1.sdk) which changes after every update of XCode. We use; # the assumption that in the parent folder there is a symlink MacOSX.sdk; # which points to the current active sdk. This change allows releases; # to work when the users update their sdks.; # FIXME: That is a horrible hack and we should teach CIFactory to pick up; # the SDK directory at runtime, just as we do for the include paths to C++.; set (OSX_SYSROOT_DEFAULT_SDK ${CMAKE_OSX_SYSROOT}); if (${OSX_SYSROOT_DEFAULT_SDK} MATCHES ""MacOSX[.0-9]+\.sdk""); get_filename_component(OSX_SYSROOT_DEFAULT_SDK ${OSX_SYSROOT_DEFAULT_SDK} DIRECTORY); set (OSX_SYSROOT_DEFAULT_SDK ${OSX_SYSROOT_DEFAULT_SDK}/MacOSX.sdk/); endif(). file(APPEND ${CMAKE_CURRENT_BINARY_DIR}/cling-compiledata.h.in; ""; #define CLING_OSX_SYSROOT \""${OSX_SYSROOT_DEFAULT_SDK}\""; ""); endif(); if (CLING_CXX_PATH); MESSAGE(STATUS ""And if not found, will invoke: '${CLING_CXX_PATH}' for them.""); file(APPEND ${CMAKE_CURRENT_BINARY_DIR}/cling-compiledata.h.in; ""; #define CLING_CXX_PATH \""${CLING_CXX_PATH} ${CMAKE_CXX_FLAGS_NO_I} ${CMAKE_CXX_FLAGS_${uppercase_CMAKE_BUILD_TYPE}}\""; ""); endif(); if (CLING_CXX_RLTV); MESSAGE(STATUS ""And then fallback to: '${CLING_CXX_RLTV}'""); file(APPEND",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/CMakeLists.txt:9181,release,releases,9181,interpreter/cling/lib/Interpreter/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/CMakeLists.txt,2,"['release', 'update']","['releases', 'update']"
Deployability,"AFTER`` are attributes on member; declarations, specifically declarations of mutexes or other capabilities.; These declarations enforce a particular order in which the mutexes must be; acquired, in order to prevent deadlock. .. code-block:: c++. Mutex m1;; Mutex m2 ACQUIRED_AFTER(m1);. // Alternative declaration; // Mutex m2;; // Mutex m1 ACQUIRED_BEFORE(m2);. void foo() {; m2.Lock();; m1.Lock(); // Warning! m2 must be acquired after m1.; m1.Unlock();; m2.Unlock();; }. CAPABILITY(<string>); --------------------. *Previously*: ``LOCKABLE``. ``CAPABILITY`` is an attribute on classes, which specifies that objects of the; class can be used as a capability. The string argument specifies the kind of; capability in error messages, e.g. ``""mutex""``. See the ``Container`` example; given above, or the ``Mutex`` class in :ref:`mutexheader`. SCOPED_CAPABILITY; -----------------. *Previously*: ``SCOPED_LOCKABLE``. ``SCOPED_CAPABILITY`` is an attribute on classes that implement RAII-style; locking, in which a capability is acquired in the constructor, and released in; the destructor. Such classes require special handling because the constructor; and destructor refer to the capability via different names; see the; ``MutexLocker`` class in :ref:`mutexheader`, below. Scoped capabilities are treated as capabilities that are implicitly acquired; on construction and released on destruction. They are associated with; the set of (regular) capabilities named in thread safety attributes on the; constructor or function returning them by value (using C++17 guaranteed copy; elision). Acquire-type attributes on other member functions are treated as; applying to that set of associated capabilities, while ``RELEASE`` implies that; a function releases all associated capabilities in whatever mode they're held. TRY_ACQUIRE(<bool>, ...), TRY_ACQUIRE_SHARED(<bool>, ...); ---------------------------------------------------------. *Previously:* ``EXCLUSIVE_TRYLOCK_FUNCTION``, ``SHARED_TRYLOCK_FUNCTION`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:13352,release,released,13352,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['release'],['released']
Deployability,"AKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:6404,install,install,6404,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['install'],['install']
Deployability,"AL PROPERTY CLINGETCPCH); get_property(__pch_dependencies GLOBAL PROPERTY ROOT_PCH_DEPENDENCIES); get_property(__pch_dictionaries GLOBAL PROPERTY ROOT_PCH_DICTIONARIES). add_custom_command(OUTPUT etc/allDict.cxx.pch; BYPRODUCTS; etc/dictpch/allCppflags.txt; etc/dictpch/allHeaders.h; etc/dictpch/allLinkDefs.h; COMMAND; ${Python3_EXECUTABLE} ${CMAKE_SOURCE_DIR}/cmake/unix/makepchinput.py; ${CMAKE_SOURCE_DIR} . ${pyroot_legacy} ${__cling_pch}; COMMAND; ${CMAKE_COMMAND} -E env ROOTIGNOREPREFIX=1 ${Python3_EXECUTABLE}; ${CMAKE_SOURCE_DIR}/etc/dictpch/makepch.py etc/allDict.cxx.pch; ${__allIncludes} -I${CMAKE_BINARY_DIR}/include -I${CMAKE_SOURCE_DIR}/core; DEPENDS; rootcling ${__pch_dependencies} ${__pch_dictionaries}; ${CMAKE_SOURCE_DIR}/cmake/unix/makepchinput.py; ${CMAKE_SOURCE_DIR}/etc/dictpch/makepch.py; ); add_custom_target(onepcm ALL DEPENDS etc/allDict.cxx.pch); install(FILES ${CMAKE_BINARY_DIR}/etc/allDict.cxx.pch DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}); install(DIRECTORY ${CMAKE_BINARY_DIR}/etc/dictpch DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}); endif(). # FIXME: move installation of PCMS in ROOT_GENERATE_DICTIONARY().; # We are excluding directories, which are accidentaly copied via unxpected behaviour of install(DIRECTORY ..); install(; DIRECTORY ${CMAKE_BINARY_DIR}/lib/; DESTINATION ${CMAKE_INSTALL_LIBDIR}; FILES_MATCHING; PATTERN ""*.pcm""; PATTERN ""modules.idx""; PATTERN ""JupyROOT"" EXCLUDE; PATTERN ""JsMVA"" EXCLUDE; PATTERN ""python*"" EXCLUDE; PATTERN ""cmake"" EXCLUDE; PATTERN ""pkgconfig"" EXCLUDE; ). if(Vc_INCLUDE_DIR); set(MODULES_ROOT_INCPATH ""ROOT_INCLUDE_PATH=${Vc_INCLUDE_DIR}:${ROOT_INCLUDE_PATH}""); endif(). # modules.idx; if(runtime_cxxmodules); ROOT_GET_LIBRARY_OUTPUT_DIR(library_output_dir); get_property(modules_idx_deps GLOBAL PROPERTY modules_idx_deps_property); if(WIN32); set(modules_idx_cmd COMMAND ${CMAKE_COMMAND} -E env PATH=""${library_output_dir}\\\;%PATH%""; ROOTIGNOREPREFIX=1 ROOT_HIST=0 $<TARGET_FILE:root.exe> -l -q -b); else(); set(modules_idx_cm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt:21115,install,install,21115,CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt,1,['install'],['install']
Deployability,"ALL 1; CMAKE_ARGS; # We shouldn't need to set this here, but INSTALL_DIR doesn't; # seem to work, so instead I'm passing this through; -DCMAKE_INSTALL_PREFIX=${CMAKE_INSTALL_PREFIX}; ${PASSTHROUGH_VARIABLES}; ${CLANG_BOOTSTRAP_CMAKE_ARGS}; -DCLANG_STAGE=${NEXT_CLANG_STAGE}; ${COMPILER_OPTIONS}; ${${CLANG_STAGE}_TABLEGEN}; ${LTO_LIBRARY} ${verbose} ${PGO_OPT}; ${${CLANG_STAGE}_LINKER}; ${${CLANG_STAGE}_AR}; ${${CLANG_STAGE}_RANLIB}; ${${CLANG_STAGE}_OBJCOPY}; ${${CLANG_STAGE}_STRIP}; BUILD_COMMAND ${CMAKE_COMMAND} --build ${BINARY_DIR}; --config ${build_configuration}; ${build_tool_args}; INSTALL_COMMAND """"; STEP_TARGETS configure build; USES_TERMINAL_CONFIGURE 1; USES_TERMINAL_BUILD 1; USES_TERMINAL_INSTALL 1; LIST_SEPARATOR |; ). # exclude really-install from main target; set_target_properties(${NEXT_CLANG_STAGE} PROPERTIES _EP_really-install_EXCLUDE_FROM_MAIN On); ExternalProject_Add_Step(${NEXT_CLANG_STAGE} really-install; COMMAND ${CMAKE_COMMAND} --build <BINARY_DIR> --target install; COMMENT ""Performing install step for '${NEXT_CLANG_STAGE}'""; DEPENDEES build; USES_TERMINAL 1; ); ExternalProject_Add_StepTargets(${NEXT_CLANG_STAGE} really-install); add_custom_target(${NEXT_CLANG_STAGE}-install DEPENDS ${NEXT_CLANG_STAGE}-really-install). if(NOT CLANG_BOOTSTRAP_TARGETS); set(CLANG_BOOTSTRAP_TARGETS check-llvm check-clang check-all); endif(); foreach(target ${CLANG_BOOTSTRAP_TARGETS}); # Install targets have side effects, so we always want to execute them.; # ""install"" is reserved by CMake and can't be used as a step name for; # ExternalProject_Add_Step, so we can match against ""^install-"" instead of; # ""^install"" to get a tighter match. CMake's installation scripts already; # skip up-to-date files, so there's no behavior change if you install to the; # same destination multiple times.; if(target MATCHES ""^install-""); set(step_always ON); else(); set(step_always OFF); endif(). ExternalProject_Add_Step(${NEXT_CLANG_STAGE} ${target}; COMMAND ${CMAKE_COMMAND} --build ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt:28968,install,install,28968,interpreter/llvm-project/clang/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt,7,['install'],['install']
Deployability,"ALL; ALWAYS_CLEAN); endif(); add_subdirectory(utils/lit); add_subdirectory(test); add_subdirectory(unittests). if (WIN32); # This utility is used to prevent crashing tests from calling Dr. Watson on; # Windows.; add_subdirectory(utils/KillTheDoctor); endif(). umbrella_lit_testsuite_end(check-all); get_property(LLVM_ALL_LIT_DEPENDS GLOBAL PROPERTY LLVM_ALL_LIT_DEPENDS); get_property(LLVM_ALL_ADDITIONAL_TEST_DEPENDS; GLOBAL PROPERTY LLVM_ALL_ADDITIONAL_TEST_DEPENDS); add_custom_target(test-depends; DEPENDS ${LLVM_ALL_LIT_DEPENDS} ${LLVM_ALL_ADDITIONAL_TEST_DEPENDS}); set_target_properties(test-depends PROPERTIES FOLDER ""Tests""); add_dependencies(check-all test-depends); endif(). if (LLVM_INCLUDE_DOCS); add_subdirectory(docs); endif(). add_subdirectory(cmake/modules). # Do this last so that all lit targets have already been created.; if (LLVM_INCLUDE_UTILS); add_subdirectory(utils/llvm-lit); endif(). if (NOT LLVM_INSTALL_TOOLCHAIN_ONLY); install(DIRECTORY include/llvm include/llvm-c; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT llvm-headers; FILES_MATCHING; PATTERN ""*.def""; PATTERN ""*.h""; PATTERN ""*.td""; PATTERN ""*.inc""; PATTERN ""LICENSE.TXT""; ). install(DIRECTORY ${LLVM_INCLUDE_DIR}/llvm ${LLVM_INCLUDE_DIR}/llvm-c; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT llvm-headers; FILES_MATCHING; PATTERN ""*.def""; PATTERN ""*.h""; PATTERN ""*.gen""; PATTERN ""*.inc""; # Exclude include/llvm/CMakeFiles/intrinsics_gen.dir, matched by ""*.def""; PATTERN ""CMakeFiles"" EXCLUDE; PATTERN ""config.h"" EXCLUDE; ). if (LLVM_INSTALL_MODULEMAPS); install(DIRECTORY include; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT llvm-headers; FILES_MATCHING; PATTERN ""module.modulemap""; ); install(FILES include/module.install.modulemap; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT llvm-headers; RENAME ""module.extern.modulemap""; ); endif(LLVM_INSTALL_MODULEMAPS). # Installing the headers needs to depend on generating any public; # tablegen'd headers.; add_custom_target(llvm-headers",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:51589,install,install,51589,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['install'],['install']
Deployability,"AMES`` to ``clGetProgramInfo`` (OpenCL v2.0; s5.8.7) and then checking whether any kernel name matches the naming scheme of; global constructor initialization kernel above. Note that if multiple files are compiled and linked into libraries, multiple; kernels that initialize global objects for multiple modules would have to be; invoked. Applications are currently required to run initialization of global objects; manually before running any kernels in which the objects are used. .. code-block:: console. clang -cl-std=clc++ test.cl. If there are any global objects to be initialized, the final binary will; contain the ``_GLOBAL__sub_I_test.cl`` kernel to be enqueued. Note that the manual workaround only applies to objects declared at the; program scope. There is no manual workaround for the construction of static; objects with non-trivial constructors inside functions. Global destructors can not be invoked manually in the OpenCL v2.0 drivers.; However, all memory used for program scope objects should be released on; ``clReleaseProgram``. Libraries; ^^^^^^^^^; Limited experimental support of C++ standard libraries for OpenCL is; described in :doc:`OpenCLSupport` page. .. _target_features:. Target-Specific Features and Limitations; ========================================. CPU Architectures Features and Limitations; ------------------------------------------. X86; ^^^. The support for X86 (both 32-bit and 64-bit) is considered stable on; Darwin (macOS), Linux, FreeBSD, and Dragonfly BSD: it has been tested; to correctly compile many large C, C++, Objective-C, and Objective-C++; codebases. On ``x86_64-mingw32``, passing i128(by value) is incompatible with the; Microsoft x64 calling convention. You might need to tweak; ``WinX86_64ABIInfo::classify()`` in lib/CodeGen/Targets/X86.cpp. For the X86 target, clang supports the `-m16` command line; argument which enables 16-bit code output. This is broadly similar to; using ``asm("".code16gcc"")`` with the GNU toolchain. The generate",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:156214,release,released,156214,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['release'],['released']
Deployability,"AME}.cfg` and :file:`{NAME}.site.cfg` when searching for; test suites, instead of :file:`lit.cfg` and :file:`lit.site.cfg`. .. option:: -D NAME[=VALUE], --param NAME[=VALUE]. Add a user defined parameter ``NAME`` with the given ``VALUE`` (or the empty; string if not given). The meaning and use of these parameters is test suite; dependent. .. _output-options:. OUTPUT OPTIONS; --------------. .. option:: -q, --quiet. Suppress any output except for test failures. .. option:: -s, --succinct. Show less output, for example don't show information on tests that pass.; Also show a progress bar, unless ``--no-progress-bar`` is specified. .. option:: -v, --verbose. Show more information on test failures, for example the entire test output; instead of just the test result. Each command is printed before it is executed. This can be valuable for; debugging test failures, as the last printed command is the one that failed.; Moreover, :program:`lit` inserts ``'RUN: at line N'`` before each; command pipeline in the output to help you locate the source line of; the failed command. .. option:: -vv, --echo-all-commands. Deprecated alias for -v. .. option:: -a, --show-all. Enable -v, but for all tests not just failed tests. .. option:: --no-progress-bar. Do not use curses based progress bar. .. option:: --show-unsupported. Show the names of unsupported tests. .. option:: --show-xfail. Show the names of tests that were expected to fail. .. _execution-options:. EXECUTION OPTIONS; -----------------. .. option:: --path=PATH. Specify an additional ``PATH`` to use when searching for executables in tests. .. option:: --vg. Run individual tests under valgrind (using the memcheck tool). The; ``--error-exitcode`` argument for valgrind is used so that valgrind failures; will cause the program to exit with a non-zero status. When this option is enabled, :program:`lit` will also automatically provide a; ""``valgrind``"" feature that can be used to conditionally disable (or expect; failure in) certain ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:3618,pipeline,pipeline,3618,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['pipeline'],['pipeline']
Deployability,"ARD=${CMAKE_CXX_STANDARD}); endif(CMAKE_CXX_STANDARD). if (Clang_DIR); list(APPEND _clad_extra_cmake_args -DClang_DIR=${Clang_DIR} -DClang_CONFIG_EXTRA_PATH_HINTS=${Clang_Config_ExtraPathHints}); endif(Clang_DIR). if (LLVM_FORCE_USE_OLD_TOOLCHAIN); list(APPEND _clad_extra_cmake_args -DLLVM_FORCE_USE_OLD_TOOLCHAIN=${LLVM_FORCE_USE_OLD_TOOLCHAIN}); endif(LLVM_FORCE_USE_OLD_TOOLCHAIN). list(APPEND _clad_extra_cmake_args -DCLAD_BUILD_STATIC_ONLY=ON). # Wrap download, configure and build steps in a script to log output; set(_clad_extra_settings; LOG_DOWNLOAD ON; LOG_CONFIGURE ON; LOG_BUILD ON; LOG_INSTALL ON; LOG_OUTPUT_ON_FAILURE ON; ). # If the CLAD_SOURCE_DIR variable is defined in the CMake configuration, we're; # skipping the download of the repository and use the passed directory.; if (DEFINED CLAD_SOURCE_DIR); list(APPEND _clad_extra_settings DOWNLOAD_COMMAND """"); list(APPEND _clad_extra_settings SOURCE_DIR ${CLAD_SOURCE_DIR}); endif(). #list(APPEND _clad_patches_list ""patch1.patch"" ""patch2.patch""); #set(_clad_patch_command; # ${CMAKE_COMMAND} -E copy_directory; # ${CMAKE_SOURCE_DIR}/interpreter/cling/tools/plugins/clad/patches <SOURCE_DIR>; # && git checkout <SOURCE_DIR>; # && git apply --ignore-space-change --ignore-whitespace ${_clad_patches_list}; # ). ExternalProject_Add(; clad; GIT_REPOSITORY https://github.com/vgvassilev/clad.git; GIT_TAG v1.7; UPDATE_COMMAND """"; PATCH_COMMAND ${_clad_patch_command}; CMAKE_ARGS -G ${CMAKE_GENERATOR}; -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE}; -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}; -DCMAKE_C_FLAGS=${CMAKE_C_FLAGS}; -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER}; -DCMAKE_CXX_FLAGS=${CLAD_CXX_FLAGS}; -DCMAKE_INSTALL_PREFIX=${clad_install_dir}/plugins; -DLLVM_DIR=${LLVM_BINARY_DIR}; -DCLANG_INCLUDE_DIRS=${CLANG_INCLUDE_DIRS}; ${_clad_extra_cmake_args}; # FIXME; # Building with 1 core is a temporary workaround for #16654 and has to be ; # there until the behaviour of the clad build on ubuntu 24.10 is understood.; # The performance pena",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/plugins/clad/CMakeLists.txt:2676,patch,patch,2676,interpreter/cling/tools/plugins/clad/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/plugins/clad/CMakeLists.txt,1,['patch'],['patch']
Deployability,"ARD_LIBRARY_PACKAGE` now *require* the header to; be found at configuration time. We have seen too many cases where the header location was mis-stated, and as a consequence,; CMake did not generate the proper dependencies. If the header should not be taken into account for dependencies and / or if; the header will not be found (e.g. the standard library's `vector`) please pass the header through the `NODEPHEADERS` option; to `ROOT_GENERATE_DICTIONARY` or `ROOT_STANDARD_LIBRARY_PACKAGE`. We believe that this simplification / regularization of behavior, and the additional checks are worth the possible changes; on the user side. ## PyROOT. If the fix or new feature is a pythonization related to a C++ class, the change is added to the respective section above. ### Current PyROOT. - Fix compatibility with Python3.7 (ROOT-9922, ROOT-9871, ROOT-9809); - Fix lookup for templated methods (ROOT-9789); - Fix lookup for templated free functions (ROOT-9836). ### Experimental PyROOT. - All pythonisations from current PyROOT already migrated (`TTree` and subclasses, `TDirectory` and subclasses,; `TCollection` and subclasses, `TObject`, `TClass`, `TString`, `TObjString`, `TIter`, `TStyle`, `TH1`, `TFX`, `TMinuit`, `TVector3`,; `TVectorT`, `TArray`, `TCollection`, `TSeqCollection`, `TClonesArray`, `TComplex`, `TGraph`, `RooDataHist`) - ROOT-9510; - Cppyy updated to cppyy 1.4.7, cppyy-backend 1.8.1 (clingwrapper), CPyCppyy 1.7.1; * Includes fixed template support, fixed overload resolution, Windows fixes and other; - Merged Cppyy's patch to support using namespace declarations (PR-3579); - Add `DeclareCppCallable` decorator, which allows to call Python callables from C++, e.g., in an RDataFrame workflow:; ~~~ {.python}; @ROOT.DeclareCppCallable([""float""], ""float""). def f(x):; return 2.0 * x. ROOT.CppCallable.f(21.0); # Returns 42.0. df = ROOT.ROOT.RDataFrame(4).Define(""x"", ""CppCallable::f(rdfentry_)""). df.AsNumpy(); # Returns {'x': numpy.array([0., 2., 4., 6.], dtype=float32)}; ~~~. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:26629,update,updated,26629,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,2,"['patch', 'update']","['patch', 'updated']"
Deployability,"ASCIIbetical or case sensitive fashion. .. code-block:: c++. #include ""A/B.h""; #include ""A/b.h""; #include ""B/A.h""; #include ""B/a.h""; #include ""a/b.h"". * ``SI_CaseInsensitive`` (in configuration: ``CaseInsensitive``); Includes are sorted in an alphabetical or case insensitive fashion. .. code-block:: c++. #include ""A/B.h""; #include ""A/b.h""; #include ""a/b.h""; #include ""B/A.h""; #include ""B/a.h"". .. _SortJavaStaticImport:. **SortJavaStaticImport** (``SortJavaStaticImportOptions``) :versionbadge:`clang-format 12` :ref:`¶ <SortJavaStaticImport>`; When sorting Java imports, by default static imports are placed before; non-static imports. If ``JavaStaticImportAfterImport`` is ``After``,; static imports are placed after non-static imports. Possible values:. * ``SJSIO_Before`` (in configuration: ``Before``); Static imports are placed before non-static imports. .. code-block:: java. import static org.example.function1;. import org.example.ClassA;. * ``SJSIO_After`` (in configuration: ``After``); Static imports are placed after non-static imports. .. code-block:: java. import org.example.ClassA;. import static org.example.function1;. .. _SortUsingDeclarations:. **SortUsingDeclarations** (``SortUsingDeclarationsOptions``) :versionbadge:`clang-format 5` :ref:`¶ <SortUsingDeclarations>`; Controls if and how clang-format will sort using declarations. Possible values:. * ``SUD_Never`` (in configuration: ``Never``); Using declarations are never sorted. .. code-block:: c++. using std::chrono::duration_cast;; using std::move;; using boost::regex;; using boost::regex_constants::icase;; using std::string;. * ``SUD_Lexicographic`` (in configuration: ``Lexicographic``); Using declarations are sorted in the order defined as follows:; Split the strings by ""::"" and discard any initial empty strings. Sort; the lists of names lexicographically, and within those groups, names are; in case-insensitive lexicographic order. .. code-block:: c++. using boost::regex;; using boost::regex_constants::icas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:110455,configurat,configuration,110455,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"ATER 1); message(FATAL_ERROR ""Found more than one version of clang. CLANG_RESOURCE_DIR_VERSION contains: '${CHILDREN}'."" ); endif(). list(GET CHILDREN 0 CLANG_RESOURCE_DIR_VERSION); endif(); endif(). set(CLANG_RESOURCE_DIR ${CLANG_RESOURCE_DIR_STEM}/${CLANG_RESOURCE_DIR_VERSION}/include). #---Deal with clang resource here----------------------------------------------; install(DIRECTORY ${CMAKE_BINARY_DIR}/etc/cling/lib/clang/${CLANG_RESOURCE_DIR_VERSION}/include/; DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}/cling/lib/clang/${CLANG_RESOURCE_DIR_VERSION}/include USE_SOURCE_PERMISSIONS). #---Install a bunch of files to /etc/cling------------------------------------; set(clinginclude ${CMAKE_SOURCE_DIR}/interpreter/cling/include). set(custom_modulemaps); if (runtime_cxxmodules); set(custom_modulemaps boost.modulemap tinyxml2.modulemap cuda.modulemap module.modulemap.build); # FIXME: We should install vc.modulemap only when Vc is found (Vc_FOUND) but; # some systems install it under /usr/include/Vc/Vc which allows rootcling to; # discover it and assert that the modulemap is not found.; set(custom_modulemaps ${custom_modulemaps} vc.modulemap). # We need to override the default modulemap because instead of producing a; # single std.pcm, produces hundreds of pcms. This changed with MacOSX14.4.sdk; # To support macOS 13 with LLVM 18, we need to patch the modulemap from; # MacOSX14.2.sdk; if (APPLE); if (CMAKE_CXX_COMPILER_VERSION VERSION_LESS 15.0.0.15000309); set(custom_modulemaps ${custom_modulemaps} std_darwin.MacOSX14.2.sdk.modulemap); else(); set(custom_modulemaps ${custom_modulemaps} std_darwin.modulemap); endif(); endif(). if (NOT libcxx); if (MSVC); set(custom_modulemaps ${custom_modulemaps} vcruntime.modulemap); set(custom_modulemaps ${custom_modulemaps} services_msvc.modulemap); set(custom_modulemaps ${custom_modulemaps} std_msvc.modulemap); else(); set(custom_modulemaps ${custom_modulemaps} std.modulemap); endif(); endif(); # Handle libc. Apple's libc is modularized.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/clingutils/CMakeLists.txt:4327,install,install,4327,core/clingutils/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/clingutils/CMakeLists.txt,1,['install'],['install']
Deployability,"About; ========. .. warning::. If you are using a released version of LLVM, see `the download page; <https://llvm.org/releases/>`_ to find your documentation. The LLVM compiler infrastructure supports a wide range of projects, from; industrial strength compilers to specialized JIT applications to small; research projects. Similarly, documentation is broken down into several high-level groupings; targeted at different audiences:. LLVM Design & Overview; ======================. Several introductory papers and presentations. .. toctree::; :hidden:. FAQ; Lexicon. `Introduction to the LLVM Compiler`__; Presentation providing a users introduction to LLVM. .. __: https://llvm.org/pubs/2008-10-04-ACAT-LLVM-Intro.html. `Intro to LLVM`__; A chapter from the book ""The Architecture of Open Source Applications"" that; describes high-level design decisions that shaped LLVM. .. __: http://www.aosabook.org/en/llvm.html. `LLVM: A Compilation Framework for Lifelong Program Analysis & Transformation`__; Design overview. .. __: https://llvm.org/pubs/2004-01-30-CGO-LLVM.html. `LLVM: An Infrastructure for Multi-Stage Optimization`__; More details (quite old now). .. __: https://llvm.org/pubs/2002-12-LattnerMSThesis.html. Documentation; =============. Getting Started, How-tos, Developer Guides, and Tutorials. .. toctree::; :hidden:. GettingStartedTutorials; Reference; UserGuides; DiscourseMigrationGuide. :doc:`GettingStartedTutorials`; For those new to the LLVM system. :doc:`UserGuides`; User guides and How-tos. :doc:`Reference`; LLVM and API reference documentation. :doc:`DiscourseMigrationGuide`; Guide for users to migrate to Discourse. Community; =========. LLVM welcomes contributions of all kinds. To learn more, see the following articles:. .. toctree::; :hidden:. GettingInvolved. * :doc:`GettingInvolved`; * :ref:`development-process`; * :ref:`lists-forums`; * :ref:`meetups-social-events`; * :ref:`community-proposals`. Reporting a security issue. * :ref:`report-security-issue`. Indices ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/index.rst:50,release,released,50,interpreter/llvm-project/llvm/docs/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/index.rst,2,['release'],"['released', 'releases']"
Deployability,"AccessModifier:. **EmptyLineBeforeAccessModifier** (``EmptyLineBeforeAccessModifierStyle``) :versionbadge:`clang-format 12` :ref:`¶ <EmptyLineBeforeAccessModifier>`; Defines in which cases to put empty line before access modifiers. Possible values:. * ``ELBAMS_Never`` (in configuration: ``Never``); Remove all empty lines before access modifiers. .. code-block:: c++. struct foo {; private:; int i;; protected:; int j;; /* comment */; public:; foo() {}; private:; protected:; };. * ``ELBAMS_Leave`` (in configuration: ``Leave``); Keep existing empty lines before access modifiers. * ``ELBAMS_LogicalBlock`` (in configuration: ``LogicalBlock``); Add empty line only when access modifier starts a new logical block.; Logical block is a group of one or more member fields or functions. .. code-block:: c++. struct foo {; private:; int i;. protected:; int j;; /* comment */; public:; foo() {}. private:; protected:; };. * ``ELBAMS_Always`` (in configuration: ``Always``); Always add empty line before access modifiers unless access modifier; is at the start of struct or class definition. .. code-block:: c++. struct foo {; private:; int i;. protected:; int j;; /* comment */. public:; foo() {}. private:. protected:; };. .. _ExperimentalAutoDetectBinPacking:. **ExperimentalAutoDetectBinPacking** (``Boolean``) :versionbadge:`clang-format 3.7` :ref:`¶ <ExperimentalAutoDetectBinPacking>`; If ``true``, clang-format detects whether function calls and; definitions are formatted with one parameter per line. Each call can be bin-packed, one-per-line or inconclusive. If it is; inconclusive, e.g. completely on one line, but a decision needs to be; made, clang-format analyzes whether there are other bin-packed cases in; the input file and act accordingly. .. note::. This is an experimental flag, that might go away or be renamed. Do; not use this in config files, etc. Use at your own risk. .. _FixNamespaceComments:. **FixNamespaceComments** (``Boolean``) :versionbadge:`clang-format 5` :ref:`¶ <FixNam",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:62543,configurat,configuration,62543,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"Additional; functionality exists to work with multiple prototype p.d.f.s simultaneously. ; Improved infrastructure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special cond",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:14386,integrat,integration,14386,roofit/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html,1,['integrat'],['integration']
Deployability,"All proposals should be brought to the bi-weekly RISCV sync calls for discussion. For a general idea of the factors likely to be considered, please see the `Clang documentation <https://clang.llvm.org/get_involved.html>`_. It is our intention to follow the naming conventions described in `riscv-non-isa/riscv-toolchain-conventions <https://github.com/riscv-non-isa/riscv-toolchain-conventions#conventions-for-vendor-extensions>`_. Exceptions to this naming will need to be strongly motivated. The current vendor extensions supported are:. ``XTHeadBa``; LLVM implements `the THeadBa (address-generation) vendor-defined instructions specified in <https://github.com/T-head-Semi/thead-extension-spec/releases/download/2.2.2/xthead-2023-01-30-2.2.2.pdf>`_ by T-HEAD of Alibaba. Instructions are prefixed with `th.` as described in the specification. ``XTHeadBb``; LLVM implements `the THeadBb (basic bit-manipulation) vendor-defined instructions specified in <https://github.com/T-head-Semi/thead-extension-spec/releases/download/2.2.2/xthead-2023-01-30-2.2.2.pdf>`_ by T-HEAD of Alibaba. Instructions are prefixed with `th.` as described in the specification. ``XTHeadBs``; LLVM implements `the THeadBs (single-bit operations) vendor-defined instructions specified in <https://github.com/T-head-Semi/thead-extension-spec/releases/download/2.2.2/xthead-2023-01-30-2.2.2.pdf>`_ by T-HEAD of Alibaba. Instructions are prefixed with `th.` as described in the specification. ``XTHeadCondMov``; LLVM implements `the THeadCondMov (conditional move) vendor-defined instructions specified in <https://github.com/T-head-Semi/thead-extension-spec/releases/download/2.2.2/xthead-2023-01-30-2.2.2.pdf>`_ by T-HEAD of Alibaba. Instructions are prefixed with `th.` as described in the specification. ``XTHeadCmo``; LLVM implements `the THeadCmo (cache management operations) vendor-defined instructions specified in <https://github.com/T-head-Semi/thead-extension-spec/releases/download/2.2.2/xthead-2023-01-30-2.2.2.p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/RISCVUsage.rst:13796,release,releases,13796,interpreter/llvm-project/llvm/docs/RISCVUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/RISCVUsage.rst,1,['release'],['releases']
Deployability,"Args: [0]; DstArgs: [-1]. Sinks:; # Sink functions; # If taint reaches any of the arguments specified, a warning is emitted. # Sink function; # int system(const char* command); #; # Result example:; # const char* command = read_command();; # system(command); // emit diagnostic if command is tainted; - Name: system; Args: [0]. In the example file above, the entries under the `Propagation` key implement the conceptual sources and propagations, and sinks have their dedicated `Sinks` key.; The user can define operations (function calls) where the tainted values should be cleansed by listing entries under the `Filters` key.; Filters model the sanitization of values done by the programmer, and providing these is key to avoiding false-positive findings. Configuration file syntax and semantics; _______________________________________. The configuration file should have valid `YAML <http://llvm.org/docs/YamlIO.html#introduction-to-yaml>`_ syntax. The configuration file can have the following top-level keys:; - Filters; - Propagations; - Sinks. Under the `Filters` key, the user can specify a list of operations that remove taint (see :ref:`clangsa-taint-filter-details` for details). Under the `Propagations` key, the user can specify a list of operations that introduce and propagate taint (see :ref:`clangsa-taint-propagation-details` for details).; The user can mark taint sources with a `SrcArgs` key in the `Propagation` key, while propagations have none.; The lack of the `SrcArgs` key means unconditional propagation, which is how sources are modeled.; The semantics of propagations are such, that if any of the source arguments are tainted (specified by indexes in `SrcArgs`) then all of the destination arguments (specified by indexes in `DstArgs`) also become tainted. Under the `Sinks` key, the user can specify a list of operations where the checker should emit a bug report if tainted data reaches it (see :ref:`clangsa-taint-sink-details` for details). .. _clangsa-taint-filter-de",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst:4240,configurat,configuration,4240,interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst,1,['configurat'],['configuration']
Deployability,"At any step made by the current track, one is able to add control points; to either primary or secondary:. ~~~{.cpp}; track->AddPoint(x,y,z,t);; ~~~. After tracks were defined and filled during tracking, one will be able; to browse directly the list of tracks held by the manager class. Any; track can be drawn using its `Draw()` and `Animate()` methods, but there; are also global methods for drawing or animation that can be accessed; from TGeoManager context menu:. ~~~{.cpp}; TGeoManager::DrawTracks(Option_t *option);; TGeoManager::AnimateTracks(Double_t tmin=0.,Double_t tmax=1E-8,; Int_t nframes=200,Option_t *option="""");; ~~~. The drawing/animation time range is a global variable that can be; directly set:. ~~~{.cpp}; gGeoManager->SetTminTmax(tmin, tmax);; // without arguments resets the time range to the maximum value; ~~~. Once set, the time range will be active both for individual or global; track drawing. For animation, this range is divided to the desired; number of frames and will be automatically updated at each frame in; order to get the animation effect. The option provided to all track-drawing methods can trigger different; track selections:. `default: `A track (or all primary tracks) drawn without daughters. `/D:` Track and first level descendents only are drawn. `/*: ` Track and all descendents are drawn. `/Ntype:` All tracks having `name=type` are drawn. Generally several options can be concatenated in the same string (E.g.; `""/D /Npion-""`). For animating tracks, additional options can be added:. `/G:`Geometry animate. Generally when drawing or animating tracks, one; has to first perform a normal drawing of the geometry as convenient. The; tracks will be drawn over the geometry. The geometry itself will be; animated (camera moving and rotating in order to ""catch"" the majority of; current track segments.). `/S:`Save all frames in gif format in the current folder. This option; allows creating a movie based on individual frames. \anchor GP03; ## Checking th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:88826,update,updated,88826,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['update'],['updated']
Deployability,"BI only; #. To use LLVM modules on Win32-based system, you may configure LLVM; with ``-DBUILD_SHARED_LIBS=On``. Note that Debug builds require a lot of time and disk space. An LLVM-only build; will need about 1-3 GB of space. A full build of LLVM and Clang will need around; 15-20 GB of disk space. The exact space requirements will vary by system. (It; is so large because of all the debugging information and the fact that the; libraries are statically linked into multiple tools). If you are space-constrained, you can build only selected tools or only; selected targets. The Release build requires considerably less space. The LLVM suite *may* compile on other platforms, but it is not guaranteed to do; so. If compilation is successful, the LLVM utilities should be able to; assemble, disassemble, analyze, and optimize LLVM bitcode. Code generation; should work as well, although the generated native code may not work on your; platform. Software; --------. Compiling LLVM requires that you have several software packages installed. The; table below lists those required packages. The Package column is the usual name; for the software package that LLVM depends on. The Version column provides; ""known to work"" versions of the package. The Notes column describes how LLVM; uses the package and provides other details. =========================================================== ============ ==========================================; Package Version Notes; =========================================================== ============ ==========================================; `CMake <http://cmake.org/>`__ >=3.20.0 Makefile/workspace generator; `python <http://www.python.org/>`_ >=3.6 Automated test suite\ :sup:`1`; `zlib <http://zlib.net>`_ >=1.2.3.4 Compression library\ :sup:`2`; `GNU Make <http://savannah.gnu.org/projects/make>`_ 3.79, 3.79.1 Makefile/build processor\ :sup:`3`; =========================================================== ============ =====================================",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:10132,install,installed,10132,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['install'],['installed']
Deployability,"BXML2_FOUND 0); find_package(LibXml2 2.5.3 QUIET); if (LIBXML2_FOUND); set(CLANG_HAVE_LIBXML 1); endif(); endif(); endif(). include(CheckIncludeFile); check_include_file(sys/resource.h CLANG_HAVE_RLIMITS). # This check requires _GNU_SOURCE on linux; check_include_file(dlfcn.h CLANG_HAVE_DLFCN_H); if( CLANG_HAVE_DLFCN_H ); include(CheckLibraryExists); include(CheckSymbolExists); check_library_exists(dl dlopen """" HAVE_LIBDL); if( HAVE_LIBDL ); list(APPEND CMAKE_REQUIRED_LIBRARIES dl); endif(); list(APPEND CMAKE_REQUIRED_DEFINITIONS -D_GNU_SOURCE); check_symbol_exists(dladdr dlfcn.h CLANG_HAVE_DLADDR); list(REMOVE_ITEM CMAKE_REQUIRED_DEFINITIONS -D_GNU_SOURCE); if( HAVE_LIBDL ); list(REMOVE_ITEM CMAKE_REQUIRED_LIBRARIES dl); endif(); endif(). set(CLANG_RESOURCE_DIR """" CACHE STRING; ""Relative directory from the Clang binary to its resource files.""). set(C_INCLUDE_DIRS """" CACHE STRING; ""Colon separated list of directories clang will search for headers.""). set(GCC_INSTALL_PREFIX """" CACHE PATH ""Directory where gcc is installed."" ); set(DEFAULT_SYSROOT """" CACHE STRING; ""Default <path> to all compiler invocations for --sysroot=<path>."" ); if(GCC_INSTALL_PREFIX); message(WARNING ""GCC_INSTALL_PREFIX is deprecated and will be removed. Use ""; ""configuration files (https://clang.llvm.org/docs/UsersManual.html#configuration-files)""; ""to specify the default --gcc-install-dir= or --gcc-triple=. --gcc-toolchain= is discouraged. ""; ""See https://github.com/llvm/llvm-project/pull/77537 for detail.""); endif(). set(ENABLE_LINKER_BUILD_ID OFF CACHE BOOL ""pass --build-id to ld""). set(ENABLE_X86_RELAX_RELOCATIONS ON CACHE BOOL; ""enable x86 relax relocations by default""). set(PPC_LINUX_DEFAULT_IEEELONGDOUBLE OFF CACHE BOOL; ""Enable IEEE binary128 as default long double format on PowerPC Linux.""). set(CLANG_SPAWN_CC1 OFF CACHE BOOL; ""Whether clang should use a new process for the CC1 invocation""). option(CLANG_DEFAULT_PIE_ON_LINUX ""Default to -fPIE and -pie on linux-gnu"" ON). set(CLANG_DEFAULT",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt:6712,install,installed,6712,interpreter/llvm-project/clang/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt,1,['install'],['installed']
Deployability,"BinContent(1,100000);; h->SetBinContent(2,10000);; h->SetBinContent(3,1000);; h->SetBinContent(4,100);; h->SetBinContent(5,10);; h->SetMinimum(50.);; h->SetMaximum(40000);; h->Draw(""L*"");; gPad->SetLogy();; ~~~; - `ChangeLabel` is now available for alphanumeric axis.; - Implement transparency for lines, texts and markers in the TeX output. ## 3D Graphics Libraries. - Make sure a TF3 is painted the same way in GL and non-GL mode.; The mismatch was reported in [this post](https://root-forum.cern.ch/t/how-to-specify-the-level-value-in-isosurface-drawing-with-tf3-and-gl/32179). ## Geometry Libraries. ## Database Libraries. The CMake module `FindOracle.cmake` was updated to support version 18.x; of the Oracle client libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ## JavaScript ROOT. ### New functionality from 5.7.0 release. - Add support of `TProfile2Poly` class; - Add support of `TGeoOverlap` class; - Add support of `TGeoHalfSpace` for composites; - Implement update of `TF2` drawings, see `tutorials/graphics/anim.C`; - Improve windows handling in flex(ible) layout; - Provide special widget for object inspector; - Use `requestAnimationFrame` when do monitoring, improves performance; - Better position for text in `TH2Poly` drawings; - Support eve7 geometry viewer - render data generated in ROOT itself; - Provide initial WebVR support, thanks to Diego Marcos; - Use `gStyle` attributes to draw histogram title; - Enable projections drawing also with `TH2` lego plots; - Many adjustment with new `TWebCanvas` - interactivity, attributes/position updates, context menus; - Upgrade three.js 86 -> 102, use `SoftwareRenderer` instead of `CanvasRenderer`; - Upgrade d3.js 4.4.4 -> 5.7.0; - Fix - support clipping for tracks and points in geo painter; - Fix - drawing of TGeoNode with finder; - Fix - key press events processed only in active pad (ROOT-9128); - Fix - use X0/Y0 in xtru shape, thanks to @altavir. ### Ne",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:20501,update,update,20501,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,1,['update'],['update']
Deployability,"C must be; run after SSA construction (i.e. mem2ref). RewriteStatepointsForGC will ensure that appropriate base pointers are listed; for every relocation created. It will do so by duplicating code as needed to; propagate the base pointer associated with each pointer being relocated to; the appropriate safepoints. The implementation assumes that the following; IR constructs produce base pointers: loads from the heap, addresses of global; variables, function arguments, function return values. Constant pointers (such; as null) are also assumed to be base pointers. In practice, this constraint; can be relaxed to producing interior derived pointers provided the target; collector can find the associated allocation from an arbitrary interior; derived pointer. By default RewriteStatepointsForGC passes in ``0xABCDEF00`` as the statepoint; ID and ``0`` as the number of patchable bytes to the newly constructed; ``gc.statepoint``. These values can be configured on a per-callsite; basis using the attributes ``""statepoint-id""`` and; ``""statepoint-num-patch-bytes""``. If a call site is marked with a; ``""statepoint-id""`` function attribute and its value is a positive; integer (represented as a string), then that value is used as the ID; of the newly constructed ``gc.statepoint``. If a call site is marked; with a ``""statepoint-num-patch-bytes""`` function attribute and its; value is a positive integer, then that value is used as the 'num patch; bytes' parameter of the newly constructed ``gc.statepoint``. The; ``""statepoint-id""`` and ``""statepoint-num-patch-bytes""`` attributes; are not propagated to the ``gc.statepoint`` call or invoke if they; could be successfully parsed. In practice, RewriteStatepointsForGC should be run much later in the pass; pipeline, after most optimization is already done. This helps to improve; the quality of the generated code when compiled with garbage collection support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:28356,patch,patch-bytes,28356,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['patch'],['patch-bytes']
Deployability,"C++ code; for computing derivatives of the function. It supports both forward-mode and; reverse-mode AD. 4. **Cling for live coding music and musical instruments:**. The artistic live coding community has been growing steadily since around the; year 2000. The Temporary Organisation for the Permanence of Live Art Programming; (TOPLAP) has been around since 2004, Algorave (algorithmic rave parties); recently celebrated its tenth birthday, and six editions of the International; Conference on Live Coding (ICLC) have been held. A great many live coding; systems have been developed during this time, many of them exhibiting exotic and; culturally specific features that professional software developers are mostly; unaware of. In this framework, Cling has been used as the basis for a C++ based; live coding synthesiser (`TinySpec-Cling; <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_). In another example,; Cling has been installed on a BeagleBoard to bring live coding to the Bela; interactive audio platform (`Using the Cling C++ Interpreter on the Bela; Platform; <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_). These; two examples show the potential mutual benefits for increased engagement between; the Cling community and the artistic live coding community. 5. **Clion:** The `CLion <https://www.jetbrains.com/clion/>`_ platform is a; Integrating Development Environment (`IDE; <https://en.wikipedia.org/wiki/Integrated_development_environment>`_) for C and; C++ by `JetBrains <https://www.jetbrains.com/>`_. It was developed with the aim; to enhance developer's productivity with a smart editor, code quality assurance,; automated refactorings and deep integration with the CMake build system. CLion; integrates Cling, which can be found by clicking on Tool. Cling enables; prototyping and learning C++ in CLion. You can find more information on `CLion's; building instructions; <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:3923,integrat,integration,3923,interpreter/cling/docs/chapters/applications.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst,4,"['install', 'integrat']","['install-cling', 'integrates', 'integration']"
Deployability,"C++ compilers used with the ROOT system fully; support templates. In the mean time, knowing the; role TObject plays in collections can be helpful. In general you don't need to worry about TObject. Many ROOT; classes have TObject as an ancestor. In fact, collections themselves; are descendants of TObject. This makes it possible for collections to; contain other collections (subcollections) in a tree structure. Such trees; are used in the ROOT system to implement components of the graphics system; (graphics pads containing pads), geometries (detectors in detectors), etc. The basic protocol TObject defines for collection elements is shown below:. IsEqual(); Compare(); IsSortable(); Hash(). How to use and override these member functions is shown in the; example program. Types of Collections. The ROOT system implements the following type of collections:; arrays, lists, sorted lists, B-trees, hashtables and maps.; The figure below shows the inheritance hierarchy for the primary; collection classes. Ordered Collections (Sequences). Sequences are collections that are externally ordered because they; maintain internal elements according to the order in which they; were added. The following sequence collections are available:. TList; THashList; TOrdCollection; TObjArray; TClonesArray. Both a TObjArray as well as a TOrdCollection can be sorted; using their Sort() member function (assuming the stored items are; sortable). Sorted Collections. Sorted collections are ordered by an internal (automatic) sorting mechanism.; The following sorted collections are available:. TSortedList; TBtree. Unordered Collections. Unordered collections don't maintain the order in which the elements were added.; I.e. when you iterate over an unordered collection, you are not likely to; retrieve elements in the same order they were added to the collection.; The following unordered collections are available:. THashTable; TMap. Using Collections. Rene Brun,; Fons Rademakers. Last update 24/11/95 by FR. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/cont/doc/Understanding_Collections.html:2930,update,update,2930,core/cont/doc/Understanding_Collections.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/cont/doc/Understanding_Collections.html,1,['update'],['update']
Deployability,"CERN/RCS-PRJ-FC,; Pavlo Svirin, National Technical University of Ukraine,\; Maciej Szymanski, Argonne,\; Christian Tacke, Darmstadt University,\; Matevz Tadel, UCSD/CMS,\; Alvaro Tolosa Delgado, CERN/RCS-PRJ-FC,\; Devajith Valaparambil Sreeramaswamy, CERN/EP-SFT,\; Peter Van Gemmeren, Argonne,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/ATLAS,; Stefan Wunsch. ## Deprecation and Removal; - The RooFit legacy iterators are deprecated and will be removed in ROOT 6.34 (see section ""RooFit libraries""); - Some memory-unsafe RooFit interfaces were removed; - Some redundant **RooDataSet** constructors are deprecated and will be removed in ROOT 6.34.; Please use the RooDataSet constructors that take RooFit command arguments instead; - ROOT does not longer support Python 2. The minimum required Python version to build ROOT is 3.8.; - Support for wildcard imports like `from ROOT import *` is dropped from PyROOT; - Support for external (ie. non-builtin) libAfterImage is now deprecated and it will be removed in next release 6.34.; - The `TList::TList(TObject*)` constructor is deprecated and will be removed in ROOT 6.34; - The deprecated `TProofOutputList::TProofOutputList(TObject *o)` constructor was removed. ## Core Libraries. The Cling interpreter now relies on LLVM version 16. ## I/O Libraries. ### hadd respects compression settings. Fixed a bug that was previously changing the compression settings to a single digit number instead of the full value; (by default 101). ## TTree Libraries; ### Add files from subdirectories with `TChain::Add` globbing; It is now possible to add files from multiple subdirectories with `TChain::Add` globbing. For example,; ```; TChain::Add(""/path/to/tree/*/*.root""); ```; grabs all the root files with the path `/path/to/tree/somedir/file.root` (but not `/path/to/tree/file.root` and `/path/to/tree/somedir/anotherdir/file.root`). Another example:; ```; TChain::Add(""/path/to/tree/subdir[0-9]/*.root""); ```; This grabs all the root files in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:2802,release,release,2802,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['release'],['release']
Deployability,"CMake Caches; ============. This directory contains CMake cache scripts that pre-populate the CMakeCache in; a build directory with commonly used settings. You can use the caches files with the following CMake invocation:. cmake -G <build system>; -C <path to cache file>; [additional CMake options (i.e. -DCMAKE_INSTALL_PREFIX=<install path>)]; <path to llvm>. Options specified on the command line will override options in the cache files. The following cache files exist. Apple-stage1; ------------. The Apple stage1 cache configures a two stage build similar to how Apple builds; the clang shipped with Xcode. The build files generated from this invocation has; a target named ""stage2"" which performs an LTO build of clang. The Apple-stage2 cache can be used directly to match the build settings Apple; uses in shipping builds without doing a full bootstrap build. PGO; ---. The PGO CMake cache can be used to generate a multi-stage instrumented compiler.; You can configure your build directory with the following invocation of CMake:. cmake -G <generator> -C <path_to_clang>/cmake/caches/PGO.cmake <source dir>. After configuration the following additional targets will be generated:. stage2-instrumented:; Builds a stage1 x86 compiler, runtime, and required tools (llvm-config,; llvm-profdata) then uses that compiler to build an instrumented stage2 compiler. stage2-instrumented-generate-profdata:; Depends on ""stage2-instrumented"" and will use the instrumented compiler to; generate profdata based on the training files in <clang>/utils/perf-training. stage2:; Depends on ""stage2-instrumented-generate-profdata"" and will use the stage1; compiler with the stage2 profdata to build a PGO-optimized compiler. stage2-check-llvm:; Depends on stage2 and runs check-llvm using the stage3 compiler. stage2-check-clang:; Depends on stage2 and runs check-clang using the stage3 compiler. stage2-check-all:; Depends on stage2 and runs check-all using the stage3 compiler. stage2-test-suite:; Depends on ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/cmake/caches/README.txt:329,install,install,329,interpreter/llvm-project/clang/cmake/caches/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/cmake/caches/README.txt,1,['install'],['install']
Deployability,"Canvas` - interactivity, attributes/position updates, context menus; - Upgrade three.js 86 -> 102, use `SoftwareRenderer` instead of `CanvasRenderer`; - Upgrade d3.js 4.4.4 -> 5.7.0; - Fix - support clipping for tracks and points in geo painter; - Fix - drawing of TGeoNode with finder; - Fix - key press events processed only in active pad (ROOT-9128); - Fix - use X0/Y0 in xtru shape, thanks to @altavir. ### New files location. JSROOT sources were moved from `etc/http/` into `js/` subfolder in ROOT sources tree.; OpenUI5 files were moved to `ui5/` subfolder. After ROOT compilation they can be found in; `$ROOTSYS/js/` and `$ROOTSYS/ui5/` subfolders respectively. ## Tutorials; - Add `RSqliteDS` examples.; - Make RCsvDS and RLazyDS tutorials standalone, i.e. downloading input csv directly using `TFile::Cp` rather than relying on CMake. ## Class Reference Guide. ## Build, Configuration and Testing Infrastructure. ### CMake build system requirements and updates. The minimum required version of CMake has been updated to 3.9 or newer to be; able to take advantage of new features such as native support for the CUDA; language, among other things. Please refer to CMake's release notes for further; information. The method to select the C++ standard has changed. Now the recommended way; to select the C++ standard is via the option `-DCMAKE_CXX_STANDARD=XX`, which; is the idiomatic way to do it in CMake. The old options still work, but have; been deprecated and will be removed in a future release. Build option descriptions have been updated to indicate which builtins require; an active network connection during the build. You can inspect the list of; options and their descriptions by running `cmake -LH $PWD` in the build; directory. The build system has been updated to remove most file globbing to improve; the reliability of incremental builds when source files are added or removed. A new check has been added to make ROOT fail during the configuration step; if incompatible version",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:22064,update,updated,22064,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,1,['update'],['updated']
Deployability,"Clang.; Consider therefore for a moment your reasons for building from source: there; being no pre-built wheel for the platform that you're interested in or simply; needing the latest version from the repository; or perhaps you are planning; to develop/modify the sources. If the former, clone the repository, check out a specific tagged release as; needed, then run the following steps to add Cling and build a wheel.; Once built, install the wheel as appropriate::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ python setup.py bdist_wheel; $ python -m pip install dist/cppyy_cling-* --upgrade. .. note::; ``cppyy-cling`` wheels do not depend on the Python interpreter and can; thus be re-used for any version of Python or PyPy. The ``egg_info`` setup command is needed for ``create_src_directory.py`` to; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA package; and can be used/installed as expected, here done with ``pip``. By default, the setup script will use all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MAKE_NPROCS`` envar to the; desired number of allowable sub jobs. If on the other hand you are building from source to develop/modify; ``cppyy-cling``, consider using the ``cmake`` interface.; The first installation will still be just as slow, but subsequent builds can; be incremental and thus much faster.; For this use, first install the latest version from a pre-built wheel, which; will setup the proper directory structure, then use cmake to build and; install the latest or modified version of ``cppyy-cling`` into that::. $ python -m pip install cppyy-cling; $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:3380,release,release,3380,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,3,"['install', 'patch', 'release']","['installs', 'patches', 'release']"
Deployability,"Cling Packaging Tool (CPT); ==========================. The Cling Packaging Tool is a command-line utility written in Python to build; Cling from source and generate installer bundles for a wide range of platforms. Cling maintains its own vendor clones of LLVM and Clang (part of ROOT's trunk); on which it is based. This tool is the easiest way to build Cling for your favorite; platorm and bundle it into an installer. If you want to manually compile Cling; from source, go through the [README] of Cling or the build instructions [here]. [README]:https://github.com/root-project/cling/blob/master/README.md; [here]:https://root.cern/cling/cling_build_instructions/. Below is a list of platforms currently supported by CPT:; * Ubuntu and distros based on Debian - *DEB packages*; * Windows - *NSIS installers*; * Distros based on Red Hat Linux (Fedora/Scientific Linux CERN) - *RPM packages*; * Mac OS X - *Apple Disk Images*; * Virtually any UNIX-like platform which supports Bash - *Tarballs*. ### Requirements; Before using this tool, make sure you have the required packages installed on; your system. Detailed information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, ch",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:166,install,installer,166,interpreter/cling/tools/packaging/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md,3,['install'],"['installer', 'installers']"
Deployability,"Cling interprets C++; ====================. .. figure:: images/fig1.jpeg. **Cling** is an interactive C++ interpreter built on top of `Clang; <https://clang.llvm.org/>`_ and `LLVM <https://llvm.org/>`_. It uses LLVM's; *Just-In-Time* (`JIT <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_); compiler to provide a fast and optimized compilation pipeline. Cling uses the; `read-eval-print-loop; <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) approach, making rapid application development in C++ possible,; avoiding the classic edit-compile-run-debug cycle approach. Cling's last release, download instructions, dependencies, and any other useful; information for developers can be found on `Cling's GitHub webpage; <https://github.com/vgvassilev/cling>`_. Find out more about **Interpreting C++** on the `Compiler Research Group; <https://compiler-research.org/>`_'s webpage.; . Table of Contents; -----------------. .. toctree::; :numbered:; ; chapters/background; chapters/interactivity; chapters/why_interpreting; chapters/implementation; chapters/REPL; chapters/grammar; chapters/applications; chapters/conclusion; chapters/references; . .. note::. This project is under active development.; Cling has its documentation hosted on Read the Docs. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/index.rst:354,pipeline,pipeline,354,interpreter/cling/docs/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/index.rst,2,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"Collection of policies around the git repositories. .. _development-process:. Development Process; -------------------. Information about LLVM's development process. .. toctree::; :hidden:. Projects; HowToReleaseLLVM; Packaging; ReleaseProcess; HowToAddABuilder; ReleaseNotes. :doc:`Projects`; How-to guide and templates for new projects that *use* the LLVM; infrastructure. The templates (directory organization, Makefiles, and test; tree) allow the project code to be located outside (or inside) the ``llvm/``; tree, while using LLVM header files and libraries. :doc:`HowToReleaseLLVM`; This is a guide to preparing LLVM releases. Most developers can ignore it. :doc:`ReleaseProcess`; This is a guide to validate a new release, during the release process. Most developers can ignore it. :doc:`HowToAddABuilder`; Instructions for adding new builder to LLVM buildbot master. :doc:`Packaging`; Advice on packaging LLVM into a distribution. :doc:`Release notes for the current release <ReleaseNotes>`; This describes new features, known bugs, and other limitations. .. _lists-forums:. Forums & Mailing Lists; ----------------------. If you can't find what you need in these docs, try consulting the; Discourse forums. There are also commit mailing lists for all commits to the LLVM Project.; The :doc:`CodeOfConduct` applies to all these forums and mailing lists. `LLVM Discourse`__; The forums for all things LLVM and related sub-projects. There are categories and subcategories for a wide variety of areas within LLVM. You can also view tags or search for a specific topic. .. __: https://discourse.llvm.org/. `Commits Archive (llvm-commits)`__; This list contains all commit messages that are made when LLVM developers; commit code changes to the repository. It also serves as a forum for; patch review (i.e. send patches here). It is useful for those who want to; stay on the bleeding edge of LLVM development. This list is very high; volume. .. __: http://lists.llvm.org/pipermail/llvm-commits/. `B",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingInvolved.rst:2275,release,release,2275,interpreter/llvm-project/llvm/docs/GettingInvolved.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingInvolved.rst,1,['release'],['release']
Deployability,"Config/TargetMCAs.def.in; ${LLVM_INCLUDE_DIR}/llvm/Config/TargetMCAs.def; ); configure_file(; ${LLVM_MAIN_INCLUDE_DIR}/llvm/Config/TargetExegesis.def.in; ${LLVM_INCLUDE_DIR}/llvm/Config/TargetExegesis.def; ). # They are not referenced. See set_output_directory().; set( CMAKE_RUNTIME_OUTPUT_DIRECTORY ${LLVM_TOOLS_BINARY_DIR} ); set( CMAKE_LIBRARY_OUTPUT_DIRECTORY ${LLVM_LIBRARY_DIR} ); set( CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${LLVM_LIBRARY_DIR} ). # For up-to-date instructions for installing the TFLite dependency, refer to; # the bot setup script: https://github.com/google/ml-compiler-opt/blob/main/buildbot/buildbot_init.sh; set(LLVM_HAVE_TFLITE """" CACHE BOOL ""Use tflite""); if (LLVM_HAVE_TFLITE); find_package(tensorflow-lite REQUIRED); endif(). # For up-to-date instructions for installing the Tensorflow dependency, refer to; # the bot setup script: https://github.com/google/ml-compiler-opt/blob/main/buildbot/buildbot_init.sh; # Specifically, assuming python3 is installed:; # python3 -m pip install --upgrade pip && python3 -m pip install --user tf_nightly==2.3.0.dev20200528; # Then set TENSORFLOW_AOT_PATH to the package install - usually it's ~/.local/lib/python3.7/site-packages/tensorflow; #; set(TENSORFLOW_AOT_PATH """" CACHE PATH ""Path to TensorFlow pip install dir""). if (NOT TENSORFLOW_AOT_PATH STREQUAL """"); set(LLVM_HAVE_TF_AOT ""ON"" CACHE BOOL ""Tensorflow AOT available""); set(TENSORFLOW_AOT_COMPILER; ""${TENSORFLOW_AOT_PATH}/../../../../bin/saved_model_cli""; CACHE PATH ""Path to the Tensorflow AOT compiler""); include_directories(${TENSORFLOW_AOT_PATH}/include); add_subdirectory(${TENSORFLOW_AOT_PATH}/xla_aot_runtime_src; ${CMAKE_ARCHIVE_OUTPUT_DIRECTORY}/tf_runtime); install(TARGETS tf_xla_runtime EXPORT LLVMExports; ARCHIVE DESTINATION lib${LLVM_LIBDIR_SUFFIX} COMPONENT tf_xla_runtime); set_property(GLOBAL APPEND PROPERTY LLVM_EXPORTS tf_xla_runtime); # Once we add more modules, we should handle this more automatically.; if (DEFINED LLVM_OVERRIDE_MODEL_HEADER_INLINERSIZ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:43138,install,installed,43138,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,4,"['install', 'upgrade']","['install', 'installed', 'upgrade']"
Deployability,"Constructor(); : a(),; b(). * ``PCIS_BinPack`` (in configuration: ``BinPack``); Bin-pack constructor initializers. .. code-block:: c++. Constructor(); : aaaaaaaaaaaaaaaaaaaa(), bbbbbbbbbbbbbbbbbbbb(),; cccccccccccccccccccc(). * ``PCIS_CurrentLine`` (in configuration: ``CurrentLine``); Put all constructor initializers on the current line if they fit.; Otherwise, put each one on its own line. .. code-block:: c++. Constructor() : a(), b(). Constructor(); : aaaaaaaaaaaaaaaaaaaa(),; bbbbbbbbbbbbbbbbbbbb(),; ddddddddddddd(). * ``PCIS_NextLine`` (in configuration: ``NextLine``); Same as ``PCIS_CurrentLine`` except that if all constructor initializers; do not fit on the current line, try to fit them on the next line. .. code-block:: c++. Constructor() : a(), b(). Constructor(); : aaaaaaaaaaaaaaaaaaaa(), bbbbbbbbbbbbbbbbbbbb(), ddddddddddddd(). Constructor(); : aaaaaaaaaaaaaaaaaaaa(),; bbbbbbbbbbbbbbbbbbbb(),; cccccccccccccccccccc(). * ``PCIS_NextLineOnly`` (in configuration: ``NextLineOnly``); Put all constructor initializers on the next line if they fit.; Otherwise, put each one on its own line. .. code-block:: c++. Constructor(); : a(), b(). Constructor(); : aaaaaaaaaaaaaaaaaaaa(), bbbbbbbbbbbbbbbbbbbb(), ddddddddddddd(). Constructor(); : aaaaaaaaaaaaaaaaaaaa(),; bbbbbbbbbbbbbbbbbbbb(),; cccccccccccccccccccc(). .. _PenaltyBreakAssignment:. **PenaltyBreakAssignment** (``Unsigned``) :versionbadge:`clang-format 5` :ref:`¶ <PenaltyBreakAssignment>`; The penalty for breaking around an assignment operator. .. _PenaltyBreakBeforeFirstCallParameter:. **PenaltyBreakBeforeFirstCallParameter** (``Unsigned``) :versionbadge:`clang-format 3.7` :ref:`¶ <PenaltyBreakBeforeFirstCallParameter>`; The penalty for breaking a function call after ``call(``. .. _PenaltyBreakComment:. **PenaltyBreakComment** (``Unsigned``) :versionbadge:`clang-format 3.7` :ref:`¶ <PenaltyBreakComment>`; The penalty for each line break introduced inside a comment. .. _PenaltyBreakFirstLessLess:. **PenaltyBreakFirst",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:93274,configurat,configuration,93274,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"D = ES.createJITDylib(""libFoo.dylib"");. The JITDylib is owned by the ``ExecutionEngine`` instance and will be freed; when it is destroyed. How to remove code; ------------------. To remove an individual module from a JITDylib it must first be added using an; explicit ``ResourceTracker``. The module can then be removed by calling; ``ResourceTracker::remove``:. .. code-block:: c++. auto &JD = ... ;; auto M = ... ;. auto RT = JD.createResourceTracker();; Layer.add(RT, std::move(M)); // Add M to JD, tracking resources with RT. RT.remove(); // Remove M from JD. Modules added directly to a JITDylib will be tracked by that JITDylib's default; resource tracker. All code can be removed from a JITDylib by calling ``JITDylib::clear``. This; leaves the cleared JITDylib in an empty but usable state. JITDylibs can be removed by calling ``ExecutionSession::removeJITDylib``. This; clears the JITDylib and then puts it into a defunct state. No further operations; can be performed on the JITDylib, and it will be destroyed as soon as the last; handle to it is released. An example of how to use the resource management APIs can be found at; ``llvm/examples/OrcV2Examples/LLJITRemovableCode``. How to add the support for custom program representation; --------------------------------------------------------; In order to add the support for a custom program representation, a custom ``MaterializationUnit``; for the program representation, and a custom ``Layer`` are needed. The Layer will have two; operations: ``add`` and ``emit``. The ``add`` operation takes an instance of your program; representation, builds one of your custom ``MaterializationUnits`` to hold it, then adds it; to a ``JITDylib``. The emit operation takes a ``MaterializationResponsibility`` object and an; instance of your program representation and materializes it, usually by compiling it and handing; the resulting object off to an ``ObjectLinkingLayer``. Your custom ``MaterializationUnit`` will have two operations: ``materiali",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:24436,release,released,24436,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['release'],['released']
Deployability,"D to auto-import; references to __cxxabiv1::__class_type_info pointers (see: https://reviews.llvm.org/D43184; for a related discussion). This allows for linking; but, code that actually uses; such fields will not work as they these will not be fixed up at runtime. See; _pei386_runtime_relocator which handles the runtime component of the autoimporting; scheme used for mingw and comments in https://reviews.llvm.org/D43184 and; https://reviews.llvm.org/D89518 for more. Assembling a Toolchain:; =======================. The procedure is:. # Build an LLVM toolchain with support for Windows Itanium.; # Use the toolchain from step 1. to build libc++, libc++abi, and libunwind. It is also possible to cross-compile from Linux. One method of building the libraries in step 2. is to build them ""stand-alone"".; A stand-alone build doesn't involve the rest of the LLVM tree. The steps are:. * ``cd build-dir``; * ``cmake -DLLVM_PATH=<path to llvm checkout e.g. /llvm-project/> -DCMAKE_INSTALL_PREFIX=<install path> <other options> <path to project e.g. /llvm-project/libcxxabi>``; * ``<make program e.g. ninja>``; * ``<make program> install``. More information on standalone builds can be found in the build documentation for; the respective libraries. The next section discuss the salient options and modifications; required for building and installing the libraries using standalone builds. This assumes; that we are building libunwind and ibc++ as DLLs and statically linking libc++abi into; libc++. Other build configurations are possible, but they are not discussed here. Common CMake configuration options:; -----------------------------------. * ``-D_LIBCPP_ABI_FORCE_ITANIUM'``. Tell the libc++ headers that the Itanium C++ ABI is being used. * ``-DCMAKE_C_FLAGS=""-lmsvcrt -llegacy_stdio_definitions -D_NO_CRT_STDIO_INLINE""``. Supply CRT definitions including stdio definitions that have been removed from the MS VS CRT.; We don't want the stdio functions declared inline as they will cause multip",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildWindowsItaniumPrograms.rst:3497,install,install,3497,interpreter/llvm-project/llvm/docs/HowToBuildWindowsItaniumPrograms.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildWindowsItaniumPrograms.rst,1,['install'],['install']
Deployability,"DDEFINE1 -DDEFINE2; string (REPLACE "";"" "" -D"" LLVM_DEFS "";${LLVM_DEFS}""); endif(). # FIXME: Reduce the usage of CLING_CXXFLAGS by adding a cmake routine in; # RootMacros.cmake for all cling-dependent libraries; if(MSVC); set(CLING_CXXFLAGS "" ${LLVM_DEFS} -DNOMINMAX -D_XKEYCHECK_H""); else(); # FIXME: Work hard to remove -Wno-shadow and -Wno-unused-parameter; set(CLING_CXXFLAGS "" ${LLVM_DEFS} -fno-strict-aliasing -Wwrite-strings -Wno-shadow -Wno-unused-parameter -Wno-deprecated-declarations""); endif(). # Set the flags in the parent scope for the rest of the cling-based libraries in ROOT.; set(CLING_CXXFLAGS ${CLING_CXXFLAGS} PARENT_SCOPE). string(APPEND CMAKE_CXX_FLAGS ${CLING_CXXFLAGS}); if (LLVM_ENABLE_PIC AND NOT MSVC); # FIXME: LLVM_ENABLE_PIC is ON by default, however not propagated to cling.; # FIXME: fPIC is required by the linker for libCling. Can we do that using; # cmake: set_property(TARGET clingInterpreter PROPERTY POSITION_INDEPENDENT_CODE ON)?; string(APPEND CMAKE_CXX_FLAGS "" -fPIC""); string(APPEND CMAKE_C_FLAGS "" -fPIC""); endif(LLVM_ENABLE_PIC AND NOT MSVC); # Avoid cling being installed under ROOTSYS/include.; set(CLING_ROOT_BUILD ON); add_subdirectory(cling EXCLUDE_FROM_ALL); add_dependencies(CLING ${CLING_LIBRARIES}). set(CLING_INCLUDE_DIRS ${CMAKE_SOURCE_DIR}/interpreter/cling/include CACHE STRING """"). #---These are the libraries that we link ROOT with CLING---------------------------; if (builtin_llvm); add_dependencies(CLING intrinsics_gen); endif(); if (builtin_clang); add_dependencies(CLING clang-headers clang-resource-headers); # Windows (and some other LLVM setups) do not have that target available.; if (TARGET clang-cmake-exports); add_dependencies(CLING clang-cmake-exports); endif(); endif(); else(); set(Cling_DIR ${LLVM_BINARY_DIR}/lib/cmake/cling/); find_package(Cling REQUIRED CONFIG PATHS ${Cling_DIR} ""${Cling_DIR}/lib/cmake/cling"" ""${Cling_DIR}/cmake"" NO_DEFAULT_PATH); find_package(Clang REQUIRED CONFIG PATHS ${Cling_DIR} ""${Cling_DIR}/li",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/CMakeLists.txt:22151,install,installed,22151,interpreter/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/CMakeLists.txt,1,['install'],['installed']
Deployability,"DFs is to request their addition to the official RooFit by submitting a ticket [here](https://github.com/root-project/root/issues/new). The ROOT team will gladly assist you and take care of the details. While your code is integrated, you are able to significantly improve the speed of fitting (but not take full advantage of the RooBatchCompute library), at least by using the batch evaluation feature.; To make use of it, one should override `RooAbsReal::computeBatch()`; ``` {.cpp}; void RooMyPDF::computeBatch(RooBatchCompute::RooBatchComputeInterface*, double* output, size_t nEvents, RooBatchCompute::DataMap& dataMap) const; ```; This method must be implemented so that it fills the `output` array with the **normalized** probabilities computed for `nEvents` events, the data of which can be retrieved from `dataMap`. `dataMap` is a simple `std::map<RooRealVar*, std::span<const double>>`. Note that it is not necessary to evaluate any of the objects that the PDF relies to, because they have already been evaluated by the RooFitDriver, so that their updated results are always present in `dataMap`. The `RooBatchCompute::RooBatchComputeInterface` pointer should be ignored. ``` {.cpp}; void RooMyPDF::computeBatch(RooBatchCompute::RooBatchComputeInterface*, double* output, size_t nEvents, RooBatchCompute::DataMap& dataMap) const; {; // Retrieve `std::span`s for each parameter of the PDF; std::span<const double> span1 = dataMap.at(&*proxyVar1);; // or: auto span1 = dataMap.at(&*proxyVar1);; std::span<const double> span2 = dataMap.at(&*proxyVar2);. // let's assume c is a scalar parameter of the PDF. In this case the dataMap contains a std::span with only one value.; std::span<const double> scalar = dataMap.at(&*c);. // Perform computations in a for-loop; // Use VDT if possible to facilitate auto-vectorization; for (size_t i=0; i<nEvents; ++i) {; output[i] = RooBatchCompute::fast_log(span1[i]+span2[i]) + scalar[0]; //scalar is a std::span of length 1; }; }; ```; Make sure to add th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/batchcompute.md:4693,update,updated,4693,roofit/doc/developers/batchcompute.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/batchcompute.md,1,['update'],['updated']
Deployability,"DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE; GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION); HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT; LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY; OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF; SUCH DAMAGE. You are under no obligation whatsoever to provide any bug fixes,; patches, or upgrades to the features, functionality or performance of; the source code (""Enhancements"") to anyone; however, if you choose to; make your Enhancements available either publicly, or directly to; Lawrence Berkeley National Laboratory, without imposing a separate; written license agreement for such Enhancements, then you hereby grant; the following license: a non-exclusive, royalty-free perpetual license; to install, use, modify, prepare derivative works, incorporate into; other computer software, distribute, and sublicense such Enhancements; or derivative works thereof, in binary and source code form. Additional copyright holders; ----------------------------. In addition to LBNL/UC Berkeley, this package contains files copyrighted by; one or more of the following people and organizations, and licensed under; the same conditions (except for some compatible licenses as retained in the; source code):. CERN; Simone Bacchio; Robert Bradshaw; Ellis Breen; Antonio Cuni; Aditi Dutta; Shaheed Haque; Jonsomi; Alvaro Moran; Tarmo Pikaro; Matti Picus; Camille Scott. External code; -------------. The create_src_directory.py script will pull in ROOT and LLVM sources, which; are licensed differently:. LLVM: distributed under University of Illinois/NCSA Open Source License; https://opensource.org/licenses/UoI-NCSA.php; ROOT: distributed under LGPL 2.1; https://root.cern.ch/license. The ROOT and LLVM/Clang codes are modified/patched, as part of the build; process.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/LICENSE.txt:3245,patch,patched,3245,bindings/pyroot/cppyy/cppyy-backend/cling/LICENSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/LICENSE.txt,1,['patch'],['patched']
Deployability,"DISCOVERY; --------------. The inputs passed to :program:`lit` can be either individual tests, or entire; directories or hierarchies of tests to run. When :program:`lit` starts up, the; first thing it does is convert the inputs into a complete list of tests to run; as part of *test discovery*. In the :program:`lit` model, every test must exist inside some *test suite*.; :program:`lit` resolves the inputs specified on the command line to test suites; by searching upwards from the input path until it finds a :file:`lit.cfg` or; :file:`lit.site.cfg` file. These files serve as both a marker of test suites; and as configuration files which :program:`lit` loads in order to understand; how to find and run the tests inside the test suite. Once :program:`lit` has mapped the inputs into test suites it traverses the; list of inputs adding tests for individual files and recursively searching for; tests in directories. This behavior makes it easy to specify a subset of tests to run, while still; allowing the test suite configuration to control exactly how tests are; interpreted. In addition, :program:`lit` always identifies tests by the test; suite they are in, and their relative path inside the test suite. For; appropriately configured projects, this allows :program:`lit` to provide; convenient and flexible support for out-of-tree builds. .. _test-status-results:. TEST STATUS RESULTS; -------------------. Each test ultimately produces one of the following eight results:. **PASS**. The test succeeded. **FLAKYPASS**. The test succeeded after being re-run more than once. This only applies to; tests containing an ``ALLOW_RETRIES:`` annotation. **XFAIL**. The test failed, but that is expected. This is used for test formats which allow; specifying that a test does not currently work, but wish to leave it in the test; suite. **XPASS**. The test succeeded, but it was expected to fail. This is used for tests which; were specified as expected to fail, but are now succeeding (generally bec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:11987,configurat,configuration,11987,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['configurat'],['configuration']
Deployability,"DOCS); add_subdirectory(docs); endif(). add_subdirectory(cmake/modules). # Do this last so that all lit targets have already been created.; if (LLVM_INCLUDE_UTILS); add_subdirectory(utils/llvm-lit); endif(). if (NOT LLVM_INSTALL_TOOLCHAIN_ONLY); install(DIRECTORY include/llvm include/llvm-c; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT llvm-headers; FILES_MATCHING; PATTERN ""*.def""; PATTERN ""*.h""; PATTERN ""*.td""; PATTERN ""*.inc""; PATTERN ""LICENSE.TXT""; ). install(DIRECTORY ${LLVM_INCLUDE_DIR}/llvm ${LLVM_INCLUDE_DIR}/llvm-c; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT llvm-headers; FILES_MATCHING; PATTERN ""*.def""; PATTERN ""*.h""; PATTERN ""*.gen""; PATTERN ""*.inc""; # Exclude include/llvm/CMakeFiles/intrinsics_gen.dir, matched by ""*.def""; PATTERN ""CMakeFiles"" EXCLUDE; PATTERN ""config.h"" EXCLUDE; ). if (LLVM_INSTALL_MODULEMAPS); install(DIRECTORY include; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT llvm-headers; FILES_MATCHING; PATTERN ""module.modulemap""; ); install(FILES include/module.install.modulemap; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT llvm-headers; RENAME ""module.extern.modulemap""; ); endif(LLVM_INSTALL_MODULEMAPS). # Installing the headers needs to depend on generating any public; # tablegen'd headers.; add_custom_target(llvm-headers DEPENDS intrinsics_gen omp_gen); set_target_properties(llvm-headers PROPERTIES FOLDER ""Misc""). if (NOT LLVM_ENABLE_IDE); add_llvm_install_targets(install-llvm-headers; DEPENDS llvm-headers; COMPONENT llvm-headers); endif(). # Custom target to install all libraries.; add_custom_target(llvm-libraries); set_target_properties(llvm-libraries PROPERTIES FOLDER ""Misc""). if (NOT LLVM_ENABLE_IDE); add_llvm_install_targets(install-llvm-libraries; DEPENDS llvm-libraries; COMPONENT llvm-libraries); endif(). get_property(LLVM_LIBS GLOBAL PROPERTY LLVM_LIBS); if(LLVM_LIBS); list(REMOVE_DUPLICATES LLVM_LIBS); foreach(lib ${LLVM_LIBS}); add_dependencies(llvm-libraries ${lib}); if (NOT LLVM_ENABLE_IDE); add_de",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:52336,install,install,52336,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['install'],['install']
Deployability,"DTTests, IRTests, SupportTests, etc. (Search for ``add_llvm_unittest`` in; the subdirectories of *unittests* for a complete list of unit tests.) It is; possible to build all unit tests with the target *UnitTests*. **LLVM_BUILD_TOOLS**:BOOL; Build LLVM tools. Defaults to ON. Targets for building each tool are generated; in any case. You can build a tool separately by invoking its target. For; example, you can build *llvm-as* with a Makefile-based system by executing *make; llvm-as* at the root of your build directory. **LLVM_CCACHE_BUILD**:BOOL; If enabled and the ``ccache`` program is available, then LLVM will be; built using ``ccache`` to speed up rebuilds of LLVM and its components.; Defaults to OFF. The size and location of the cache maintained; by ``ccache`` can be adjusted via the LLVM_CCACHE_MAXSIZE and LLVM_CCACHE_DIR; options, which are passed to the CCACHE_MAXSIZE and CCACHE_DIR environment; variables, respectively. **LLVM_CREATE_XCODE_TOOLCHAIN**:BOOL; macOS Only: If enabled CMake will generate a target named; 'install-xcode-toolchain'. This target will create a directory at; $CMAKE_INSTALL_PREFIX/Toolchains containing an xctoolchain directory which can; be used to override the default system tools. **LLVM_<target>_LINKER_FLAGS**:STRING; Defines the set of linker flags that should be applied to a <target>. **LLVM_DEFAULT_TARGET_TRIPLE**:STRING; LLVM target to use for code generation when no target is explicitly specified.; It defaults to ""host"", meaning that it shall pick the architecture; of the machine where LLVM is being built. If you are building a cross-compiler,; set it to the target triple of your desired architecture. **LLVM_DOXYGEN_QCH_FILENAME**:STRING; The filename of the Qt Compressed Help file that will be generated when; ``-DLLVM_ENABLE_DOXYGEN=ON`` and; ``-DLLVM_ENABLE_DOXYGEN_QT_HELP=ON`` are given. Defaults to; ``org.llvm.qch``.; This option is only useful in combination with; ``-DLLVM_ENABLE_DOXYGEN_QT_HELP=ON``;; otherwise it has no effe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:17943,install,install-xcode-toolchain,17943,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['install'],['install-xcode-toolchain']
Deployability,Data()*; 0x10000000 GlobalTable 32-bit pointer to GPU memory containing the global internal table (should; always point to *user data register* 0).; 0x10000001 PerShaderTable 32-bit pointer to GPU memory containing the per-shader internal table. See; :ref:`amdgpu-amdpal-code-object-metadata-user-data-per-shader-table-section`; for more detail (should always point to *user data register* 1).; 0x10000002 SpillTable 32-bit pointer to GPU memory containing the user data spill table. See; :ref:`amdgpu-amdpal-code-object-metadata-user-data-spill-table-section` for; more detail.; 0x10000003 BaseVertex Vertex offset (32-bit unsigned integer). Not needed if the pipeline doesn't; reference the draw index in the vertex shader. Only supported by the first; stage in a graphics pipeline.; 0x10000004 BaseInstance Instance offset (32-bit unsigned integer). Only supported by the first stage in; a graphics pipeline.; 0x10000005 DrawIndex Draw index (32-bit unsigned integer). Only supported by the first stage in a; graphics pipeline.; 0x10000006 Workgroup Thread group count (32-bit unsigned integer). Low half of a 64-bit address of; a buffer containing the grid dimensions for a Compute dispatch operation. The; high half of the address is stored in the next sequential user-SGPR. Only; supported by compute pipelines.; 0x1000000A EsGsLdsSize Indicates that PAL will program this user-SGPR to contain the amount of LDS; space used for the ES/GS pseudo-ring-buffer for passing data between shader; stages.; 0x1000000B ViewId View id (32-bit unsigned integer) identifies a view of graphic; pipeline instancing.; 0x1000000C StreamOutTable 32-bit pointer to GPU memory containing the stream out target SRD table. This; can only appear for one shader stage per pipeline.; 0x1000000D PerShaderPerfData 32-bit pointer to GPU memory containing the per-shader performance data buffer.; 0x1000000F VertexBufferTable 32-bit pointer to GPU memory containing the vertex buffer SRD table. This can; only appear for o,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:416519,pipeline,pipeline,416519,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['pipeline'],['pipeline']
Deployability,"Date: Fri, 1 Jun 2001 17:08:44 -0500 (CDT); From: Chris Lattner <sabre@nondot.org>; To: Vikram S. Adve <vadve@cs.uiuc.edu>; Subject: RE: Interesting: GCC passes. > That is very interesting. I agree that some of these could be done on LLVM; > at link-time, but it is the extra time required that concerns me. Link-time; > optimization is severely time-constrained. If we were to reimplement any of these optimizations, I assume that we; could do them a translation unit at a time, just as GCC does now. This; would lead to a pipeline like this:. Static optimizations, xlation unit at a time:; .c --GCC--> .llvm --llvmopt--> .llvm . Link time optimizations:; .llvm --llvm-ld--> .llvm --llvm-link-opt--> .llvm . Of course, many optimizations could be shared between llvmopt and; llvm-link-opt, but the wouldn't need to be shared... Thus compile time; could be faster, because we are using a ""smarter"" IR (SSA based). > BTW, about SGI, ""borrowing"" SSA-based optimizations from one compiler and; > putting it into another is not necessarily easier than re-doing it.; > Optimization code is usually heavily tied in to the specific IR they use. Understood. The only reason that I brought this up is because SGI's IR is; more similar to LLVM than it is different in many respects (SSA based,; relatively low level, etc), and could be easily adapted. Also their; optimizations are written in C++ and are actually somewhat; structured... of course it would be no walk in the park, but it would be; much less time consuming to adapt, say, SSA-PRE than to rewrite it. > But your larger point is valid that adding SSA based optimizations is; > feasible and should be fun. (Again, link time cost is the issue.). Assuming linktime cost wasn't an issue, the question is: ; Does using GCC's backend buy us anything?. > It also occurs to me that GCC is probably doing quite a bit of back-end; > optimization (step 16 in your list). Do you have a breakdown of that?. Not really. The irritating part of GCC is that it mix",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt:524,pipeline,pipeline,524,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,1,['pipeline'],['pipeline']
Deployability,"Date: Tue, 13 Feb 2001 13:29:52 -0600 (CST); From: Chris Lattner <sabre@nondot.org>; To: Vikram S. Adve <vadve@cs.uiuc.edu>; Subject: LLVM Concerns... I've updated the documentation to include load store and allocation; instructions (please take a look and let me know if I'm on the right; track):. file:/home/vadve/lattner/llvm/docs/LangRef.html#memoryops. I have a couple of concerns I would like to bring up:. 1. Reference types; Right now, I've spec'd out the language to have a pointer type, which; works fine for lots of stuff... except that Java really has; references: constrained pointers that cannot be manipulated: added and; subtracted, moved, etc... Do we want to have a type like this? It; could be very nice for analysis (pointer always points to the start of; an object, etc...) and more closely matches Java semantics. The; pointer type would be kept for C++ like semantics. Through analysis,; C++ pointers could be promoted to references in the LLVM; representation. 2. Our ""implicit"" memory references in assembly language:; After thinking about it, this model has two problems:; A. If you do pointer analysis and realize that two stores are; independent and can share the same memory source object, there is; no way to represent this in either the bytecode or assembly.; B. When parsing assembly/bytecode, we effectively have to do a full; SSA generation/PHI node insertion pass to build the dependencies; when we don't want the ""pinned"" representation. This is not; cool.; I'm tempted to make memory references explicit in both the assembly and; bytecode to get around this... what do you think?. -Chris. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-13-Reference-Memory.txt:156,update,updated,156,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-13-Reference-Memory.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-13-Reference-Memory.txt,1,['update'],['updated']
Deployability,"Deploying the Virtual Analysis Facility; =======================================. Introduction; ------------. Thanks to CernVM and PROOF on Demand, it is possible to deploy a ready; to use Virtual Analysis Facility on your cloud (either public, private; or even your desktop computer). On the server side, ""configuring"" the Virtual Analysis Facility is; simply a matter of starting a certain number of CernVM virtual machines; that will become part of your PROOF cluster. CernVM uses; contextualization to specialize each virtual machine to be either a head; node or a worker node. The Virtual Analysis Facility comes with many preconfigured things:. - a HTCondor cluster capable of running PROOF on Demand. - certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:166,deploy,deploy,166,proof/doc/confman/DeployVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md,1,['deploy'],['deploy']
Deployability,"Download ROOT sources, strip and patch them:. $ python setup.py egg_info; $ python create_src_directory.py. Build wheel (optional: use --keep-temp during development):. $ MAKE_NPROCS=32 python setup.py bdist_wheel. Build source distribution:. $ python setup.py sdist. Sign:. $ gpg --detach-sign -a dist/*cppyy*.tar.gz. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/INSTALL.txt:33,patch,patch,33,bindings/pyroot/cppyy/cppyy-backend/cling/INSTALL.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/INSTALL.txt,1,['patch'],['patch']
Deployability,"E ""${CLANG_VENDOR} clang""); else(); set(TOOL_INFO_NAME ""clang""); endif(). set(TOOL_INFO_UTI ""${CLANG_VENDOR_UTI}""); set(TOOL_INFO_VERSION ""${CLANG_VERSION}""); set(TOOL_INFO_BUILD_VERSION ""${LLVM_VERSION_MAJOR}.${LLVM_VERSION_MINOR}""). set(TOOL_INFO_PLIST_OUT ""${CMAKE_CURRENT_BINARY_DIR}/${TOOL_INFO_PLIST}""). if(LLVM_TOOL_LLVM_DRIVER_BUILD AND clang IN_LIST LLVM_DRIVER_TOOLS); set(TARGET_NAME llvm-driver); else(); set(TARGET_NAME clang); endif(). target_link_libraries(${TARGET_NAME}; PRIVATE; ""-Wl,-sectcreate,__TEXT,__info_plist,\""${TOOL_INFO_PLIST_OUT}\""""); configure_file(""${TOOL_INFO_PLIST}.in"" ""${TOOL_INFO_PLIST_OUT}"" @ONLY). set(TOOL_INFO_UTI); set(TOOL_INFO_NAME); set(TOOL_INFO_VERSION); set(TOOL_INFO_BUILD_VERSION); endif(). if(CLANG_ORDER_FILE AND; (LLVM_LINKER_IS_APPLE OR LLVM_LINKER_IS_GOLD OR LLVM_LINKER_IS_LLD)); include(LLVMCheckLinkerFlag). if (LLVM_LINKER_IS_APPLE OR (LLVM_LINKER_IS_LLD AND APPLE)); set(LINKER_ORDER_FILE_OPTION ""-Wl,-order_file,${CLANG_ORDER_FILE}""); elseif (LLVM_LINKER_IS_GOLD); set(LINKER_ORDER_FILE_OPTION ""-Wl,--section-ordering-file,${CLANG_ORDER_FILE}""); elseif (LLVM_LINKER_IS_LLD); set(LINKER_ORDER_FILE_OPTION ""-Wl,--symbol-ordering-file,${CLANG_ORDER_FILE}""); endif(). # This is a test to ensure the actual order file works with the linker.; llvm_check_linker_flag(CXX ${LINKER_ORDER_FILE_OPTION} LINKER_ORDER_FILE_WORKS). # Passing an empty order file disables some linker layout optimizations.; # To work around this and enable workflows for re-linking when the order file; # changes we check during configuration if the file is empty, and make it a; # configuration dependency.; file(READ ${CLANG_ORDER_FILE} ORDER_FILE LIMIT 20); if(""${ORDER_FILE}"" STREQUAL ""\n""); set_property(DIRECTORY APPEND PROPERTY CMAKE_CONFIGURE_DEPENDS ${CLANG_ORDER_FILE}); elseif(LINKER_ORDER_FILE_WORKS); target_link_libraries(clang PRIVATE ${LINKER_ORDER_FILE_OPTION}); set_target_properties(clang PROPERTIES LINK_DEPENDS ${CLANG_ORDER_FILE}); endif(); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/driver/CMakeLists.txt:2918,configurat,configuration,2918,interpreter/llvm-project/clang/tools/driver/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/driver/CMakeLists.txt,2,['configurat'],['configuration']
Deployability,"E!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run mul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:2017,install,installed,2017,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,1,['install'],['installed']
Deployability,"E, DATA, OR PROFITS; OR BUSINESS INTERRUPTION); HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT; LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY; OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF; SUCH DAMAGE. You are under no obligation whatsoever to provide any bug fixes,; patches, or upgrades to the features, functionality or performance of; the source code (""Enhancements"") to anyone; however, if you choose to; make your Enhancements available either publicly, or directly to; Lawrence Berkeley National Laboratory, without imposing a separate; written license agreement for such Enhancements, then you hereby grant; the following license: a non-exclusive, royalty-free perpetual license; to install, use, modify, prepare derivative works, incorporate into; other computer software, distribute, and sublicense such Enhancements; or derivative works thereof, in binary and source code form. Additional copyright holders; ----------------------------. In addition to LBNL/UC Berkeley, this package contains files copyrighted by; one or more of the following people and organizations, and licensed under; the same conditions (except for some compatible licenses as retained in the; source code):. * CERN; * Lucio Asnaghi; * Simone Bacchio; * Robert Bradshaw; * Ellis Breen; * Antonio Cuni; * Aditi Dutta; * Shaheed Haque; * Jonsomi; * Max Kolin; * Alvaro Moran; * Tarmo Pikaro; * Matti Picus; * Camille Scott; * Toby StClere-Smithe; * Stefan Wunsch. Conda-forge recipes were provided by Julian Rueth and Isuru Fernando. External code; -------------. The create_src_directory.py script will pull in ROOT and LLVM sources, which; are licensed differently:. LLVM: distributed under University of Illinois/NCSA Open Source License; https://opensource.org/licenses/UoI-NCSA.php; ROOT: distributed under LGPL 2.1; https://root.cern.ch/license. The ROOT and LLVM/Clang codes are modified/patched, as part of the build; process.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/license.rst:3455,patch,patched,3455,bindings/pyroot/cppyy/cppyy/doc/source/license.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/license.rst,1,['patch'],['patched']
Deployability,"E.TXT""; ). install(DIRECTORY ${LLVM_INCLUDE_DIR}/llvm ${LLVM_INCLUDE_DIR}/llvm-c; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT llvm-headers; FILES_MATCHING; PATTERN ""*.def""; PATTERN ""*.h""; PATTERN ""*.gen""; PATTERN ""*.inc""; # Exclude include/llvm/CMakeFiles/intrinsics_gen.dir, matched by ""*.def""; PATTERN ""CMakeFiles"" EXCLUDE; PATTERN ""config.h"" EXCLUDE; ). if (LLVM_INSTALL_MODULEMAPS); install(DIRECTORY include; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT llvm-headers; FILES_MATCHING; PATTERN ""module.modulemap""; ); install(FILES include/module.install.modulemap; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT llvm-headers; RENAME ""module.extern.modulemap""; ); endif(LLVM_INSTALL_MODULEMAPS). # Installing the headers needs to depend on generating any public; # tablegen'd headers.; add_custom_target(llvm-headers DEPENDS intrinsics_gen omp_gen); set_target_properties(llvm-headers PROPERTIES FOLDER ""Misc""). if (NOT LLVM_ENABLE_IDE); add_llvm_install_targets(install-llvm-headers; DEPENDS llvm-headers; COMPONENT llvm-headers); endif(). # Custom target to install all libraries.; add_custom_target(llvm-libraries); set_target_properties(llvm-libraries PROPERTIES FOLDER ""Misc""). if (NOT LLVM_ENABLE_IDE); add_llvm_install_targets(install-llvm-libraries; DEPENDS llvm-libraries; COMPONENT llvm-libraries); endif(). get_property(LLVM_LIBS GLOBAL PROPERTY LLVM_LIBS); if(LLVM_LIBS); list(REMOVE_DUPLICATES LLVM_LIBS); foreach(lib ${LLVM_LIBS}); add_dependencies(llvm-libraries ${lib}); if (NOT LLVM_ENABLE_IDE); add_dependencies(install-llvm-libraries install-${lib}); add_dependencies(install-llvm-libraries-stripped install-${lib}-stripped); endif(); endforeach(); endif(); endif(). # This must be at the end of the LLVM root CMakeLists file because it must run; # after all targets are created.; llvm_distribution_add_targets(); process_llvm_pass_plugins(GEN_CONFIG); include(CoverageReport). # This allows us to deploy the Universal CRT DLLs by passing -DCMAKE_INSTALL_UC",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:52787,install,install-llvm-headers,52787,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['install'],['install-llvm-headers']
Deployability,"E1,; E2,; };. class C; {; public:; C();; };. bool baz(int i); {; try; {; do; {; switch (i); {; case 1:; {; foobar();; break;; }; default:; {; break;; }; }; } while (--i);; return true;; }; catch (...); {; handleError();; return false;; }; }. void foo(bool b); {; if (b); {; baz(2);; }; else; {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_GNU`` (in configuration: ``GNU``); Always break before braces and add an extra level of indentation to; braces of control statements, not to those of class, function; or other definitions. .. code-block:: c++. namespace N; {; enum E; {; E1,; E2,; };. class C; {; public:; C();; };. bool baz(int i); {; try; {; do; {; switch (i); {; case 1:; {; foobar();; break;; }; default:; {; break;; }; }; }; while (--i);; return true;; }; catch (...); {; handleError();; return false;; }; }. void foo(bool b); {; if (b); {; baz(2);; }; else; {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_WebKit`` (in configuration: ``WebKit``); Like ``Attach``, but break before functions. .. code-block:: c++. namespace N {; enum E {; E1,; E2,; };. class C {; public:; C();; };. bool baz(int i); {; try {; do {; switch (i) {; case 1: {; foobar();; break;; }; default: {; break;; }; }; } while (--i);; return true;; } catch (...) {; handleError();; return false;; }; }. void foo(bool b); {; if (b) {; baz(2);; } else {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_Custom`` (in configuration: ``Custom``); Configure each individual brace in ``BraceWrapping``. .. _BreakBeforeConceptDeclarations:. **BreakBeforeConceptDeclarations** (``BreakBeforeConceptDeclarationsStyle``) :versionbadge:`clang-format 12` :ref:`¶ <BreakBeforeConceptDeclarations>`; The concept declaration style to use. Possible values:. * ``BBCDS_Never`` (in configuration: ``Never``); Keep the template declaration line together with ``concept``. .. code-block:: c++. template <typename T> concept C = ...;. * ``BBCDS_Allowed`` (in configuration: ``All",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:51408,configurat,configuration,51408,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"ECUTABLE_SUFFIX}; AND EXISTS ${LLVM_TOOLS_BINARY_DIR}/count${CMAKE_EXECUTABLE_SUFFIX}; AND EXISTS ${LLVM_TOOLS_BINARY_DIR}/not${CMAKE_EXECUTABLE_SUFFIX}); set(LLVM_UTILS_PROVIDED ON); endif(). # Seek installed Lit.; find_program(LLVM_LIT; NAMES llvm-lit lit.py lit; PATHS ""${LLVM_MAIN_SRC_DIR}/utils/lit""; DOC ""Path to lit.py""). if(EXISTS ${LLVM_MAIN_SRC_DIR}/utils/lit/lit.py); # Note: path not really used, except for checking if lit was found; if(EXISTS ${LLVM_MAIN_SRC_DIR}/utils/llvm-lit); add_subdirectory(${LLVM_MAIN_SRC_DIR}/utils/llvm-lit utils/llvm-lit); endif(); if(NOT LLVM_UTILS_PROVIDED); add_subdirectory(${LLVM_MAIN_SRC_DIR}/utils/FileCheck utils/FileCheck); add_subdirectory(${LLVM_MAIN_SRC_DIR}/utils/count utils/count); add_subdirectory(${LLVM_MAIN_SRC_DIR}/utils/not utils/not); set(LLVM_UTILS_PROVIDED ON); set(CLANG_TEST_DEPS FileCheck count not); endif(); endif(). if (NOT TARGET llvm_gtest); message(FATAL_ERROR ""llvm-gtest not found. Please install llvm-gtest or disable tests with -DLLVM_INCLUDE_TESTS=OFF""); endif(). if(LLVM_LIT); # Define the default arguments to use with 'lit', and an option for the user; # to override.; set(LIT_ARGS_DEFAULT ""-sv""); if (MSVC OR XCODE); set(LIT_ARGS_DEFAULT ""${LIT_ARGS_DEFAULT} --no-progress-bar""); endif(); set(LLVM_LIT_ARGS ""${LIT_ARGS_DEFAULT}"" CACHE STRING ""Default options for lit""). get_errc_messages(LLVM_LIT_ERRC_MESSAGES). # On Win32 hosts, provide an option to specify the path to the GnuWin32 tools.; if( WIN32 AND NOT CYGWIN ); set(LLVM_LIT_TOOLS_DIR """" CACHE PATH ""Path to GnuWin32 tools""); endif(); else(); set(LLVM_INCLUDE_TESTS OFF); endif(). umbrella_lit_testsuite_begin(check-all); endif() # LLVM_INCLUDE_TESTS; endif() # standalone. # Make sure that our source directory is on the current cmake module path so that; # we can include cmake files from this directory.; list(INSERT CMAKE_MODULE_PATH 0; ""${CMAKE_CURRENT_SOURCE_DIR}/cmake/modules""; ""${LLVM_COMMON_CMAKE_UTILS}/Modules""; ). # This allows disabling clang's",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt:4222,install,install,4222,interpreter/llvm-project/clang/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt,1,['install'],['install']
Deployability,"EFAULT_OPENMP_RUNTIME ""libomp"" CACHE STRING; ""Default OpenMP runtime used by -fopenmp.""). set(CLANG_SYSTEMZ_DEFAULT_ARCH ""z10"" CACHE STRING ""SystemZ Default Arch""). set(CLANG_VENDOR ${PACKAGE_VENDOR} CACHE STRING; ""Vendor-specific text for showing with version information.""). set(CLANG_REPOSITORY_STRING """" CACHE STRING; ""Vendor-specific text for showing the repository the source is taken from.""). if(CLANG_REPOSITORY_STRING); add_definitions(-DCLANG_REPOSITORY_STRING=""${CLANG_REPOSITORY_STRING}""); endif(). set(CLANG_VENDOR_UTI ""org.llvm.clang"" CACHE STRING; ""Vendor-specific uti.""). set(CLANG_PYTHON_BINDINGS_VERSIONS """" CACHE STRING; ""Python versions to install libclang python bindings for""). set(CLANG_LINK_CLANG_DYLIB ${LLVM_LINK_LLVM_DYLIB} CACHE BOOL; ""Link tools against libclang-cpp.so""). if (NOT LLVM_LINK_LLVM_DYLIB AND CLANG_LINK_CLANG_DYLIB); message(FATAL_ERROR ""Cannot set CLANG_LINK_CLANG_DYLIB=ON when ""; ""LLVM_LINK_LLVM_DYLIB=OFF""); endif(). # The libdir suffix must exactly match whatever LLVM's configuration used.; set(CLANG_LIBDIR_SUFFIX ""${LLVM_LIBDIR_SUFFIX}""). set(CLANG_TOOLS_INSTALL_DIR ""${CMAKE_INSTALL_BINDIR}"" CACHE PATH; ""Path for binary subdirectory (defaults to '${CMAKE_INSTALL_BINDIR}')""); mark_as_advanced(CLANG_TOOLS_INSTALL_DIR). set(CLANG_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}); set(CLANG_BINARY_DIR ${CMAKE_CURRENT_BINARY_DIR}). if( CMAKE_SOURCE_DIR STREQUAL CMAKE_BINARY_DIR AND NOT MSVC_IDE ); message(FATAL_ERROR ""In-source builds are not allowed. ""; ""Please create a directory and run cmake ""; ""from there, passing the path to this source directory as the last argument. ""; ""This process created the file `CMakeCache.txt' and the directory ""; ""`CMakeFiles'. Please delete them.""); endif(). # If CLANG_VERSION_* is specified, use it, if not use LLVM_VERSION_*.; if(NOT DEFINED CLANG_VERSION_MAJOR); set(CLANG_VERSION_MAJOR ${LLVM_VERSION_MAJOR}); endif(); if(NOT DEFINED CLANG_VERSION_MINOR); set(CLANG_VERSION_MINOR ${LLVM_VERSION_MINOR}); endif(); if(",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt:10642,configurat,configuration,10642,interpreter/llvm-project/clang/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt,1,['configurat'],['configuration']
Deployability,ENDS clang-resource-headers; COMPONENT clang-resource-headers). add_llvm_install_targets(install-core-resource-headers; DEPENDS core-resource-headers; COMPONENT core-resource-headers); add_llvm_install_targets(install-arm-common-resource-headers; DEPENDS arm-common-resource-headers; COMPONENT arm-common-resource-headers); add_llvm_install_targets(install-arm-resource-headers; DEPENDS arm-resource-headers; COMPONENT arm-resource-headers); add_llvm_install_targets(install-aarch64-resource-headers; DEPENDS aarch64-resource-headers; COMPONENT aarch64-resource-headers); add_llvm_install_targets(install-cuda-resource-headers; DEPENDS cuda-resource-headers; COMPONENT cuda-resource-headers); add_llvm_install_targets(install-hexagon-resource-headers; DEPENDS hexagon-resource-headers; COMPONENT hexagon-resource-headers); add_llvm_install_targets(install-hip-resource-headers; DEPENDS hip-resource-headers; COMPONENT hip-resource-headers); add_llvm_install_targets(install-mips-resource-headers; DEPENDS mips-resource-headers; COMPONENT mips-resource-headers); add_llvm_install_targets(install-ppc-resource-headers; DEPENDS ppc-resource-headers; COMPONENT ppc-resource-headers); add_llvm_install_targets(install-ppc-htm-resource-headers; DEPENDS ppc-htm-resource-headers; COMPONENT ppc-htm-resource-headers); add_llvm_install_targets(install-riscv-resource-headers; DEPENDS riscv-resource-headers; COMPONENT riscv-resource-headers); add_llvm_install_targets(install-systemz-resource-headers; DEPENDS systemz-resource-headers; COMPONENT systemz-resource-headers); add_llvm_install_targets(install-ve-resource-headers; DEPENDS ve-resource-headers; COMPONENT ve-resource-headers); add_llvm_install_targets(install-x86-resource-headers; DEPENDS x86-resource-headers; COMPONENT x86-resource-headers); add_llvm_install_targets(install-webassembly-resource-headers; DEPENDS webassembly-resource-headers; COMPONENT webassembly-resource-headers). add_llvm_install_targets(install-hlsl-resource-headers; DEPEND,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt:16773,install,install-core-resource-headers,16773,interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,15,['install'],"['install-', 'install-arm-common-resource-headers', 'install-arm-resource-headers', 'install-core-resource-headers', 'install-cuda-resource-headers', 'install-hexagon-resource-headers', 'install-hip-resource-headers', 'install-mips-resource-headers', 'install-ppc-htm-resource-headers', 'install-ppc-resource-headers', 'install-riscv-resource-headers', 'install-systemz-resource-headers', 'install-ve-resource-headers', 'install-webassembly-resource-headers']"
Deployability,ENT clang-resource-headers). install(; FILES ${cuda_wrapper_bits_files}; DESTINATION ${header_install_dir}/cuda_wrappers/bits; COMPONENT clang-resource-headers). install(; FILES ${ppc_wrapper_files}; DESTINATION ${header_install_dir}/ppc_wrappers; COMPONENT clang-resource-headers). install(; FILES ${llvm_libc_wrapper_files}; DESTINATION ${header_install_dir}/llvm_libc_wrappers; COMPONENT clang-resource-headers). install(; FILES ${openmp_wrapper_files}; DESTINATION ${header_install_dir}/openmp_wrappers; COMPONENT clang-resource-headers). #############################################################; # Install rules for separate header lists; install(; FILES ${core_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT core-resource-headers). install(; FILES ${arm_common_files} ${arm_common_generated_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT arm-common-resource-headers). install(; FILES ${arm_only_files} ${arm_only_generated_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT arm-resource-headers). install(; FILES ${aarch64_only_files} ${aarch64_only_generated_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT aarch64-resource-headers). install(; FILES ${cuda_wrapper_files}; DESTINATION ${header_install_dir}/cuda_wrappers; EXCLUDE_FROM_ALL; COMPONENT cuda-resource-headers). install(; FILES ${cuda_wrapper_bits_files}; DESTINATION ${header_install_dir}/cuda_wrappers/bits; EXCLUDE_FROM_ALL; COMPONENT cuda-resource-headers). install(; FILES ${cuda_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT cuda-resource-headers). install(; FILES ${hexagon_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT hexagon-resource-headers). install(; FILES ${hip_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT hip-resource-headers). install(; FILES ${loongarch_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT loongarch-resourc,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt:13233,install,install,13233,interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,1,['install'],['install']
Deployability,"ENT_DIR ON). include_directories(BEFORE; ${CMAKE_CURRENT_BINARY_DIR}/include; ${CMAKE_CURRENT_SOURCE_DIR}/include; ). if (NOT LLVM_INSTALL_TOOLCHAIN_ONLY); install(DIRECTORY include/clang include/clang-c; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT clang-headers; FILES_MATCHING; PATTERN ""*.def""; PATTERN ""*.h""; PATTERN ""config.h"" EXCLUDE; ). install(DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/include/clang; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT clang-headers; FILES_MATCHING; PATTERN ""CMakeFiles"" EXCLUDE; PATTERN ""*.inc""; PATTERN ""*.h""; ). # Installing the headers needs to depend on generating any public; # tablegen'd headers.; add_custom_target(clang-headers DEPENDS clang-tablegen-targets); set_target_properties(clang-headers PROPERTIES FOLDER ""Misc""); if(NOT LLVM_ENABLE_IDE); add_llvm_install_targets(install-clang-headers; DEPENDS clang-headers; COMPONENT clang-headers); endif(). add_custom_target(bash-autocomplete DEPENDS utils/bash-autocomplete.sh); install(FILES utils/bash-autocomplete.sh; DESTINATION ""${CMAKE_INSTALL_DATADIR}/clang""; COMPONENT bash-autocomplete); if(NOT LLVM_ENABLE_IDE); add_llvm_install_targets(install-bash-autocomplete; DEPENDS bash-autocomplete; COMPONENT bash-autocomplete); endif(); endif(). option(CLANG_BUILD_TOOLS; ""Build the Clang tools. If OFF, just generate build targets."" ON). if(LLVM_ENABLE_PLUGINS OR LLVM_EXPORT_SYMBOLS_FOR_PLUGINS); set(HAVE_CLANG_PLUGIN_SUPPORT ON); else(); set(HAVE_CLANG_PLUGIN_SUPPORT OFF); endif(); CMAKE_DEPENDENT_OPTION(CLANG_PLUGIN_SUPPORT; ""Build clang with plugin support"" ON; ""HAVE_CLANG_PLUGIN_SUPPORT"" OFF). # If libstdc++ is statically linked, clang-repl needs to statically link libstdc++; # itself, which is not possible in many platforms because of current limitations in; # JIT stack. (more platforms need to be supported by JITLink); if(NOT LLVM_STATIC_LINK_CXX_STDLIB); set(HAVE_CLANG_REPL_SUPPORT ON); endif(). option(CLANG_ENABLE_ARCMT ""Build ARCMT."" ON); option(CLANG_ENABLE_STATIC_ANALY",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt:14613,install,install,14613,interpreter/llvm-project/clang/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt,1,['install'],['install']
Deployability,"ENT_SOURCE_DIR}/ClangConfigVersion.cmake.in; ${clang_cmake_builddir}/ClangConfigVersion.cmake; @ONLY); set(CLANG_CONFIG_CMAKE_DIR); set(CLANG_CONFIG_LLVM_CMAKE_DIR). # For compatibility with projects that include(ClangConfig); # via CMAKE_MODULE_PATH, place API modules next to it.; # Copy without source permissions because the source could be read-only,; # but we need to write into the copied folder.; file(COPY .; DESTINATION ${clang_cmake_builddir}; NO_SOURCE_PERMISSIONS; FILES_MATCHING PATTERN *.cmake; PATTERN CMakeFiles EXCLUDE; ). # Generate ClangConfig.cmake for the install tree.; find_prefix_from_config(CLANG_CONFIG_CODE CLANG_INSTALL_PREFIX ""${CLANG_INSTALL_PACKAGE_DIR}""); extend_path(CLANG_CONFIG_CMAKE_DIR ""\${CLANG_INSTALL_PREFIX}"" ""${CLANG_INSTALL_PACKAGE_DIR}""); extend_path(CLANG_CONFIG_LLVM_CMAKE_DIR ""\${CLANG_INSTALL_PREFIX}"" ""${LLVM_INSTALL_PACKAGE_DIR}""); get_config_exports_includes(Clang CLANG_CONFIG_INCLUDE_EXPORTS); extend_path(base_includedir ""\${CLANG_INSTALL_PREFIX}"" ""${CMAKE_INSTALL_INCLUDEDIR}""); set(CLANG_CONFIG_INCLUDE_DIRS; ""${base_includedir}""; ); configure_file(; ${CMAKE_CURRENT_SOURCE_DIR}/ClangConfig.cmake.in; ${CMAKE_CURRENT_BINARY_DIR}/CMakeFiles/ClangConfig.cmake; @ONLY); configure_file(; ${CMAKE_CURRENT_SOURCE_DIR}/ClangConfigVersion.cmake.in; ${CMAKE_CURRENT_BINARY_DIR}/CMakeFiles/ClangConfigVersion.cmake; @ONLY); set(CLANG_CONFIG_CODE); set(CLANG_CONFIG_CMAKE_DIR). if (NOT LLVM_INSTALL_TOOLCHAIN_ONLY); install_distribution_exports(Clang). install(FILES; ${CMAKE_CURRENT_BINARY_DIR}/CMakeFiles/ClangConfig.cmake; ${CMAKE_CURRENT_BINARY_DIR}/CMakeFiles/ClangConfigVersion.cmake; ${CMAKE_CURRENT_SOURCE_DIR}/AddClang.cmake; DESTINATION ${CLANG_INSTALL_PACKAGE_DIR}; COMPONENT clang-cmake-exports). if(NOT LLVM_ENABLE_IDE); # Add a dummy target so this can be used with LLVM_DISTRIBUTION_COMPONENTS; add_custom_target(clang-cmake-exports); add_llvm_install_targets(install-clang-cmake-exports; COMPONENT clang-cmake-exports); endif(); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/cmake/modules/CMakeLists.txt:3246,install,install,3246,interpreter/llvm-project/clang/cmake/modules/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/cmake/modules/CMakeLists.txt,2,['install'],"['install', 'install-clang-cmake-exports']"
Deployability,"EOF_VOID_P EQUAL 8); # new/delete variants needed when linking to static msvc runtime (esp. Debug); set(cling_exports ${cling_exports}; ??2@YAPEAX_K@Z; ??3@YAXPEAX@Z; ??_U@YAPEAX_K@Z; ??_V@YAXPEAX@Z; ??3@YAXPEAX_K@Z; ??2@YAPEAX_KAEBUnothrow_t@std@@@Z; ??_U@YAPEAX_KAEBUnothrow_t@std@@@Z; ??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@H@Z; ??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@M@Z; ??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@N@Z; ??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@PEBX@Z; ??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@P6AAEAV01@AEAV01@@Z@Z; ??$?6U?$char_traits@D@std@@@std@@YAAEAV?$basic_ostream@DU?$char_traits@D@std@@@0@AEAV10@D@Z; ??$?6U?$char_traits@D@std@@@std@@YAAEAV?$basic_ostream@DU?$char_traits@D@std@@@0@AEAV10@PEBD@Z; ?_Facet_Register@std@@YAXPEAV_Facet_base@1@@Z; ); else(); set(cling_exports ${cling_exports}; ??2@YAPAXI@Z; ??3@YAXPAX@Z; ??3@YAXPAXI@Z; ??_U@YAPAXI@Z; ??_V@YAXPAX@Z; ??_V@YAXPAXI@Z; ??2@YAPAXIABUnothrow_t@std@@@Z; ??_U@YAPAXIABUnothrow_t@std@@@Z; ??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QAEAAV01@H@Z; ??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QAEAAV01@M@Z; ??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QAEAAV01@N@Z; ??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QAEAAV01@PBX@Z; ??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QAEAAV01@P6AAAV01@AAV01@@Z@Z; ??$?6U?$char_traits@D@std@@@std@@YAAAV?$basic_ostream@DU?$char_traits@D@std@@@0@AAV10@D@Z; ??$?6U?$char_traits@D@std@@@std@@YAAAV?$basic_ostream@DU?$char_traits@D@std@@@0@AAV10@PBD@Z; ?_Facet_Register@std@@YAXPAV_Facet_base@1@@Z; ); endif(). # List to '/EXPORT:sym0 /EXPORT:sym1 /EXPORT:sym2 ...'; foreach(sym ${cling_exports}); set(cling_link_str ""${cling_link_str} /EXPORT:${sym}""); endforeach(sym ${cling_exports}). set_property(TARGET cling APPEND_STRING PROPERTY LINK_FLAGS ${cling_link_str}). endif(MSVC). target_link_libraries(cling PUBLIC ${LIBS}). install(TARGETS cling; RUNTIME DESTINATION bin); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/driver/CMakeLists.txt:3385,install,install,3385,interpreter/cling/tools/driver/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/driver/CMakeLists.txt,1,['install'],['install']
Deployability,"ES XROOTD_UTILS_LIBRARIES). ExternalProject_Add(; BUILTIN_XROOTD; URL http://lcgpackages.web.cern.ch/lcgpackages/tarFiles/sources/xrootd-${XROOTD_VERSION}.tar.gz; URL_HASH SHA256=c28c9dc0a2f5d0134e803981be8b1e8b1c9a6ec13b49f5fa3040889b439f4041; INSTALL_DIR ${XROOTD_PREFIX}; CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR>; -DCMAKE_PREFIX_PATH:STRING=${OPENSSL_PREFIX}; -DCMAKE_BUILD_TYPE=Release; -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}; -DCMAKE_C_FLAGS=${CMAKE_C_FLAGS}; -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER}; -DCMAKE_CXX_FLAGS=${ROOT_EXTERNAL_CXX_FLAGS}; -DCMAKE_OSX_SYSROOT=${CMAKE_OSX_SYSROOT}; -DCMAKE_OSX_DEPLOYMENT_TARGET=${CMAKE_OSX_DEPLOYMENT_TARGET}; -DCMAKE_INSTALL_LIBDIR=<INSTALL_DIR>/lib; -DENABLE_PYTHON=OFF; -DENABLE_CEPH=OFF; -DXRDCL_LIB_ONLY=ON; -DCMAKE_INSTALL_RPATH:STRING=${XROOTD_PREFIX}/lib; -DOPENSSL_ROOT_DIR=${OPENSSL_ROOT_DIR}; INSTALL_COMMAND ${CMAKE_COMMAND} --build . --target install; LOG_DOWNLOAD 1 LOG_CONFIGURE 1 LOG_BUILD 1 LOG_INSTALL 1 LOG_OUTPUT_ON_FAILURE 1; BUILD_BYPRODUCTS ${XROOTD_CLIENT_LIBRARIES} ${XROOTD_UTILS_LIBRARIES}; TIMEOUT 600; ). # CMake checks for existence when a target is linked to XRootD; file(MAKE_DIRECTORY ${XROOTD_PREFIX}/include/xrootd). if(builtin_openssl); add_dependencies(BUILTIN_XROOTD OPENSSL); endif(). list(APPEND XROOTD_CLIENT_LIBRARIES OpenSSL::SSL); list(REMOVE_DUPLICATES XROOTD_CLIENT_LIBRARIES); list(APPEND XROOTD_UTILS_LIBRARIES OpenSSL::SSL); list(REMOVE_DUPLICATES XROOTD_UTILS_LIBRARIES). set(XROOTD_INCLUDE_DIRS ${XROOTD_PREFIX}/include/xrootd CACHE INTERNAL """" FORCE); set(XROOTD_CLIENT_LIBRARIES ${XROOTD_CLIENT_LIBRARIES} CACHE INTERNAL """" FORCE); set(XROOTD_UTILS_LIBRARIES ${XROOTD_UTILS_LIBRARIES} CACHE INTERNAL """" FORCE). list(APPEND CMAKE_BUILD_RPATH ${XROOTD_PREFIX}/lib); add_dependencies(XRootD BUILTIN_XROOTD). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS BUILTIN_XROOTD). install(DIRECTORY ${XROOTD_PREFIX}/lib/ DESTINATION ${CMAKE_INSTALL_LIBDIR} COMPONENT libraries FILES_MATCHI",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/builtins/xrootd/CMakeLists.txt:1766,install,install,1766,builtins/xrootd/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/builtins/xrootd/CMakeLists.txt,1,['install'],['install']
Deployability,"EV] ...""; or ""[OpenMP] ..."". This helps email filters and searches for post-commit; reviews. * The body, if it exists, should be separated from the title by an empty line. * The body should be concise, but explanatory, including a complete; reasoning. Unless it is required to understand the change, examples,; code snippets and gory details should be left to bug comments, web; review or the mailing list. * Text formatting and spelling should follow the same rules as documentation; and in-code comments, ex. capitalization, full stop, etc. * If the commit is a bug fix on top of another recently committed patch, or a; revert or reapply of a patch, include the git commit hash of the prior; related commit. This could be as simple as ""Revert commit NNNN because it; caused PR#"". * If the patch has been reviewed, add a link to its review page, as shown; `here <https://www.llvm.org/docs/Phabricator.html#committing-a-change>`__.; If the patch fixes a bug in GitHub Issues, we encourage adding a reference to; the issue being closed, as described; `here <https://llvm.org/docs/BugLifeCycle.html#resolving-closing-bugs>`__. * It is also acceptable to add other metadata to the commit message to automate; processes, including for downstream consumers. This metadata can include; links to resources that are not available to the entire community. However,; such links and/or metadata should not be used in place of making the commit; message self-explanatory. Note that such non-public links should not be; included in the submitted code. For minor violations of these recommendations, the community normally favors; reminding the contributor of this policy over reverting. Minor corrections and; omissions can be handled by sending a reply to the commits mailing list. .. _revert_policy:. Patch reversion policy; ----------------------. As a community, we strongly value having the tip of tree in a good state while; allowing rapid iterative development. As such, we tend to make much heavier; use of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:17617,patch,patch,17617,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['patch'],['patch']
Deployability,"E_CXX_STANDARD=XX`, which; is the idiomatic way to do it in CMake. The old options still work, but have; been deprecated and will be removed in a future release. Build option descriptions have been updated to indicate which builtins require; an active network connection during the build. You can inspect the list of; options and their descriptions by running `cmake -LH $PWD` in the build; directory. The build system has been updated to remove most file globbing to improve; the reliability of incremental builds when source files are added or removed. A new check has been added to make ROOT fail during the configuration step; if incompatible versions of the Python interpreter and its libraries are; selected. The `all=ON` option now tries to enable more options. Some options had their; default value toggled to disabled, which affected `all=ON`. Now all options; are listed explicitly so that they are enabled regardless of their default; value. ### Builtins. The following builtins had their versions updated for this release:. * VecCore 0.5.2; * Vc 1.4.1; * XRootD 4.8.5; * OpenSSL 1.0.2q; * PCRE 8.42. ### Header location and `ROOT_GENERATE_DICTIONARY` / `ROOT_STANDARD_LIBRARY_PACKAGE`. A change in the argument handling of `ROOT_GENERATE_DICTIONARY` and `ROOT_STANDARD_LIBRARY_PACKAGE` might need your attention:; these macros now respect whether a header file was passed with its full relative path (the common case), or with a full path.; The latter allows to find headers at runtime - at the cost of a loss of relocatability: you cannot move the library containing; that dictionary to a different directory, because the header location is stored in the dictionary. This case is used by roottest; but should likely not be used by anything but test suites. Instead pass relative paths, together with a `-I` option to find the headers, plus setting `ROOT_INCLUDE_PATH` for finding the; headers back at runtime. The ROOT stress suite is now updated to follow this behavior; see for instance",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:23402,update,updated,23402,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,2,"['release', 'update']","['release', 'updated']"
Deployability,"E_C_COMPILER=/path/to/clang -DCMAKE_CXX_COMPILER=/path/to/clang++``.; You can also use ``ccmake``, which provides a curses interface to configure; CMake variables. As a result, the new ``compile_commands.json`` file should appear in the; current directory. You should link it to the LLVM source tree so that; Clang Tooling is able to use it:. .. code-block:: console. $ ln -s $PWD/compile_commands.json path/to/llvm/source/. Now you are ready to build and test LLVM using make:. .. code-block:: console. $ make check-all. Setup Clang Tooling Using CMake on Windows; ==========================================. For Windows developers, the Visual Studio project generators in CMake do; not support `CMAKE_EXPORT_COMPILE_COMMANDS; <https://cmake.org/cmake/help/latest/variable/CMAKE_EXPORT_COMPILE_COMMANDS.html>`_.; However, the Ninja generator does support this variable and can be used; on Windows to generate a suitable ``compile_commands.json`` that invokes; the MSVC compiler. First, you will need to install `Ninja`_. Once installed, the Ninja; executable will need to be in your search path for CMake to locate it. Next, assuming you already have Visual Studio installed on your machine, you; need to have the appropriate environment variables configured so that CMake; will locate the MSVC compiler for the Ninja generator. The `documentation; <https://docs.microsoft.com/en-us/cpp/build/building-on-the-command-line?view=msvc-170#path_and_environment>`_; describes the necessary environment variable settings, but the simplest thing; is to use a `developer command-prompt window; <https://docs.microsoft.com/en-us/cpp/build/building-on-the-command-line?view=msvc-170#developer_command_prompt_shortcuts>`_; or call a `developer command file; <https://docs.microsoft.com/en-us/cpp/build/building-on-the-command-line?view=msvc-170#developer_command_file_locations>`_; to set the environment variables appropriately. Now you can run CMake with the Ninja generator to export a compilation; database",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HowToSetupToolingForLLVM.rst:2469,install,install,2469,interpreter/llvm-project/clang/docs/HowToSetupToolingForLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HowToSetupToolingForLLVM.rst,1,['install'],['install']
Deployability,"ErrcMessages); include(LLVMDistributionSupport). set(PACKAGE_VERSION ""${LLVM_PACKAGE_VERSION}""); set(BUG_REPORT_URL ""${LLVM_PACKAGE_BUGREPORT}"" CACHE STRING; ""Default URL where bug reports are to be submitted.""). if (NOT DEFINED LLVM_INCLUDE_TESTS); set(LLVM_INCLUDE_TESTS ON); endif(). include_directories(${LLVM_INCLUDE_DIRS}); link_directories(""${LLVM_LIBRARY_DIR}""). set( CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin ); set( CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib${LLVM_LIBDIR_SUFFIX} ); set( CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib${LLVM_LIBDIR_SUFFIX} ). find_package(Python3 ${LLVM_MINIMUM_PYTHON_VERSION} REQUIRED; COMPONENTS Interpreter). if(LLVM_INCLUDE_TESTS); # Check prebuilt llvm/utils.; if(EXISTS ${LLVM_TOOLS_BINARY_DIR}/FileCheck${CMAKE_EXECUTABLE_SUFFIX}; AND EXISTS ${LLVM_TOOLS_BINARY_DIR}/count${CMAKE_EXECUTABLE_SUFFIX}; AND EXISTS ${LLVM_TOOLS_BINARY_DIR}/not${CMAKE_EXECUTABLE_SUFFIX}); set(LLVM_UTILS_PROVIDED ON); endif(). # Seek installed Lit.; find_program(LLVM_LIT; NAMES llvm-lit lit.py lit; PATHS ""${LLVM_MAIN_SRC_DIR}/utils/lit""; DOC ""Path to lit.py""). if(EXISTS ${LLVM_MAIN_SRC_DIR}/utils/lit/lit.py); # Note: path not really used, except for checking if lit was found; if(EXISTS ${LLVM_MAIN_SRC_DIR}/utils/llvm-lit); add_subdirectory(${LLVM_MAIN_SRC_DIR}/utils/llvm-lit utils/llvm-lit); endif(); if(NOT LLVM_UTILS_PROVIDED); add_subdirectory(${LLVM_MAIN_SRC_DIR}/utils/FileCheck utils/FileCheck); add_subdirectory(${LLVM_MAIN_SRC_DIR}/utils/count utils/count); add_subdirectory(${LLVM_MAIN_SRC_DIR}/utils/not utils/not); set(LLVM_UTILS_PROVIDED ON); set(CLANG_TEST_DEPS FileCheck count not); endif(); endif(). if (NOT TARGET llvm_gtest); message(FATAL_ERROR ""llvm-gtest not found. Please install llvm-gtest or disable tests with -DLLVM_INCLUDE_TESTS=OFF""); endif(). if(LLVM_LIT); # Define the default arguments to use with 'lit', and an option for the user; # to override.; set(LIT_ARGS_DEFAULT ""-sv""); if (MSVC OR XCODE); se",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt:3456,install,installed,3456,interpreter/llvm-project/clang/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt,1,['install'],['installed']
Deployability,"ExcessCharacter:. **PenaltyExcessCharacter** (``Unsigned``) :versionbadge:`clang-format 3.7` :ref:`¶ <PenaltyExcessCharacter>`; The penalty for each character outside of the column limit. .. _PenaltyIndentedWhitespace:. **PenaltyIndentedWhitespace** (``Unsigned``) :versionbadge:`clang-format 12` :ref:`¶ <PenaltyIndentedWhitespace>`; Penalty for each character of whitespace indentation; (counted relative to leading non-whitespace column). .. _PenaltyReturnTypeOnItsOwnLine:. **PenaltyReturnTypeOnItsOwnLine** (``Unsigned``) :versionbadge:`clang-format 3.7` :ref:`¶ <PenaltyReturnTypeOnItsOwnLine>`; Penalty for putting the return type of a function onto its own line. .. _PointerAlignment:. **PointerAlignment** (``PointerAlignmentStyle``) :versionbadge:`clang-format 3.7` :ref:`¶ <PointerAlignment>`; Pointer and reference alignment style. Possible values:. * ``PAS_Left`` (in configuration: ``Left``); Align pointer to the left. .. code-block:: c++. int* a;. * ``PAS_Right`` (in configuration: ``Right``); Align pointer to the right. .. code-block:: c++. int *a;. * ``PAS_Middle`` (in configuration: ``Middle``); Align pointer in the middle. .. code-block:: c++. int * a;. .. _QualifierAlignment:. **QualifierAlignment** (``QualifierAlignmentStyle``) :versionbadge:`clang-format 14` :ref:`¶ <QualifierAlignment>`; Different ways to arrange specifiers and qualifiers (e.g. const/volatile). .. warning::. Setting ``QualifierAlignment`` to something other than ``Leave``, COULD; lead to incorrect code formatting due to incorrect decisions made due to; clang-formats lack of complete semantic information.; As such extra care should be taken to review code changes made by the use; of this option. Possible values:. * ``QAS_Leave`` (in configuration: ``Leave``); Don't change specifiers/qualifiers to either Left or Right alignment; (default). .. code-block:: c++. int const a;; const int *a;. * ``QAS_Left`` (in configuration: ``Left``); Change specifiers/qualifiers to be left-aligned. .. code-blo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:96245,configurat,configuration,96245,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"Extended Regular Expression (where ``*`` is translated to ``.*``) by default.; Search for ``|`` to find patterns that may have different meanings now, and; replace ``a|b`` with ``{a,b}``. Changes to the Profile Runtime; ------------------------------. * Public header ``profile/instr_prof_interface.h`` is added to declare four; API functions to fine tune profile collection. Other Changes; -------------. * The ``Flags`` field of ``llvm::opt::Option`` has been split into ``Flags``; and ``Visibility`` to simplify option sharing between various drivers (such; as ``clang``, ``clang-cl``, or ``flang``) that rely on Clang's Options.td.; Overloads of ``llvm::opt::OptTable`` that use ``FlagsToInclude`` have been; deprecated. There is a script and instructions on how to resolve conflicts -; see https://reviews.llvm.org/D157150 and https://reviews.llvm.org/D157151 for; details. * On Linux, FreeBSD, and NetBSD, setting the environment variable; ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` causes tools to print stacktraces using; :doc:`Symbolizer Markup <SymbolizerMarkupFormat>`.; This works even if the tools have no embedded symbol information (i.e. are; fully stripped); :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` can; symbolize the markup afterwards using ``debuginfod``. External Open Source Projects Using LLVM 15; ===========================================. * A project... Additional Information; ======================. A wide variety of additional information is available on the `LLVM web page; <https://llvm.org/>`_, in particular in the `documentation; <https://llvm.org/docs/>`_ section. The web page also contains versions of the; API documentation which is up-to-date with the Git version of the source; code. You can access versions of these documents specific to this release by; going into the ``llvm/docs/`` directory in the LLVM tree. If you have any questions or comments about LLVM, please feel free to contact; us via the `Discourse forums <https://discourse.llvm.org>`_.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst:19611,release,release,19611,interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,1,['release'],['release']
Deployability,"F', 'LIST']. For example: OpenSSL STACK_OF, BSD LIST_ENTRY. .. _UseCRLF:. **UseCRLF** (``Boolean``) :versionbadge:`clang-format 10` :ref:`¶ <UseCRLF>`; This option is **deprecated**. See ``LF`` and ``CRLF`` of ``LineEnding``. .. _UseTab:. **UseTab** (``UseTabStyle``) :versionbadge:`clang-format 3.7` :ref:`¶ <UseTab>`; The way to use tab characters in the resulting file. Possible values:. * ``UT_Never`` (in configuration: ``Never``); Never use tab. * ``UT_ForIndentation`` (in configuration: ``ForIndentation``); Use tabs only for indentation. * ``UT_ForContinuationAndIndentation`` (in configuration: ``ForContinuationAndIndentation``); Fill all leading whitespace with tabs, and use spaces for alignment that; appears within a line (e.g. consecutive assignments and declarations). * ``UT_AlignWithSpaces`` (in configuration: ``AlignWithSpaces``); Use tabs for line continuation and indentation, and spaces for; alignment. * ``UT_Always`` (in configuration: ``Always``); Use tabs whenever we need to fill whitespace that spans at least from; one tab stop to the next one. .. _VerilogBreakBetweenInstancePorts:. **VerilogBreakBetweenInstancePorts** (``Boolean``) :versionbadge:`clang-format 17` :ref:`¶ <VerilogBreakBetweenInstancePorts>`; For Verilog, put each port on its own line in module instantiations. .. code-block:: c++. true:; ffnand ff1(.q(),; .qbar(out1),; .clear(in1),; .preset(in2));. false:; ffnand ff1(.q(), .qbar(out1), .clear(in1), .preset(in2));. .. _WhitespaceSensitiveMacros:. **WhitespaceSensitiveMacros** (``List of Strings``) :versionbadge:`clang-format 11` :ref:`¶ <WhitespaceSensitiveMacros>`; A vector of macros which are whitespace-sensitive and should not; be touched. These are expected to be macros of the form:. .. code-block:: c++. STRINGIZE(...). In the .clang-format configuration file, this can be configured like:. .. code-block:: yaml. WhitespaceSensitiveMacros: ['STRINGIZE', 'PP_STRINGIZE']. For example: BOOST_PP_STRINGIZE. .. END_FORMAT_STYLE_OPTIONS. Addi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:132648,configurat,configuration,132648,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"FILE}"" ""${CMAKE_CURRENT_BINARY_DIR}"" PATH_START); if(PATH_START EQUAL 0); file(WRITE ${CLANG_ORDER_FILE} ""\n""); else(); message(FATAL_ERROR ""Specified order file '${CLANG_ORDER_FILE}' does not exist.""); endif(); endif(); endif(). if( CLANG_INCLUDE_TESTS ); add_subdirectory(unittests); list(APPEND CLANG_TEST_DEPS ClangUnitTests); list(APPEND CLANG_TEST_PARAMS; clang_unit_site_config=${CMAKE_CURRENT_BINARY_DIR}/test/Unit/lit.site.cfg; ); add_subdirectory(test); add_subdirectory(bindings/python/tests). if(CLANG_BUILT_STANDALONE); umbrella_lit_testsuite_end(check-all); endif(); add_subdirectory(utils/perf-training); endif(). option(CLANG_INCLUDE_DOCS ""Generate build targets for the Clang docs.""; ${LLVM_INCLUDE_DOCS}); if( CLANG_INCLUDE_DOCS ); add_subdirectory(docs); endif(). # Custom target to install all clang libraries.; add_custom_target(clang-libraries); set_target_properties(clang-libraries PROPERTIES FOLDER ""Misc""). if(NOT LLVM_ENABLE_IDE); add_llvm_install_targets(install-clang-libraries; DEPENDS clang-libraries; COMPONENT clang-libraries); endif(). get_property(CLANG_LIBS GLOBAL PROPERTY CLANG_LIBS); if(CLANG_LIBS); list(REMOVE_DUPLICATES CLANG_LIBS); foreach(lib ${CLANG_LIBS}); add_dependencies(clang-libraries ${lib}); if(NOT LLVM_ENABLE_IDE); add_dependencies(install-clang-libraries install-${lib}); add_dependencies(install-clang-libraries-stripped install-${lib}-stripped); endif(); endforeach(); endif(). add_subdirectory(cmake/modules). if(CLANG_STAGE); message(STATUS ""Setting current clang stage to: ${CLANG_STAGE}""); endif(). if (CLANG_ENABLE_BOOTSTRAP); include(ExternalProject). add_custom_target(clang-bootstrap-deps DEPENDS clang). if(NOT CLANG_STAGE); set(CLANG_STAGE stage1); endif(). string(REGEX MATCH ""stage([0-9]*)"" MATCHED_STAGE ""${CLANG_STAGE}""); if(MATCHED_STAGE); if(NOT LLVM_BUILD_INSTRUMENTED); math(EXPR STAGE_NUM ""${CMAKE_MATCH_1} + 1""); set(NEXT_CLANG_STAGE stage${STAGE_NUM}); else(); set(NEXT_CLANG_STAGE stage${CMAKE_MATCH_1}); endif(); else();",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt:19471,install,install-clang-libraries,19471,interpreter/llvm-project/clang/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt,1,['install'],['install-clang-libraries']
Deployability,"FIx; a few issues in libXrdProofd.so with handling of connection used for; admin operation: this should solve some cases where the daemon was not; responding. ; Fix a few memory leaks showing up when; running several queries in the same session; Fix a few issues affecting the new sub-merging option; Fix an issue preventing proper real-time notification; during VerifyDataSet; Fix an issue with TQueryResult ordering (was causing; random 'stressProof' failures); Fix; an issue with TProof::AskStatistics (fBytesRead, fRealTime and fCpuTime; were not correctly filled on the client; the values on the master,; displayed by TProof::Print were correct).; Fix several small issues affecting the handling of global; package directories; Fix an issue with socket handling in the main event-loop; while sendign or receiving files via TProofMgr.; Fix; a problem counting valid nodes in sequential or 'masteronly' mode,; generating the fake error message ""GoParallel: attaching to candidate!""; Fix a few issues with the length of Unix socket paths; affecting PROOF-Lite and xproofd on MacOsX ; Fix an issue with the release of file descriptors when; recovering sessions .; Fix an issue with a fake error message (""Error in; <TROOT::cd>: No such file root:/"") in PROOF-Lite when; issuing TProof::SetParallel().; Fix a problem with negative values for 'workers still; sending' in PROOF-Lite .; Fix locking issue while building packages locally.; Fix issue setting permission and ownership of the dataset; user directories.Fix; a subtle bug affecting the (possibly rare) case when not all entries; are required and # entries does not correspond to an complete subset of; files (e.g. # entries = 1001000 with files of 100000 entries each). The; effect was uncomplete processing (skipped events, magenta bar) or a; session freeze.; Fix problem with packet re-assignment in case of a worker death (some packets were processed twice or more times).; Fix problem with the transmission of non-default file; attributes ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:10661,release,release,10661,proof/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html,1,['release'],['release']
Deployability,"FROM_MAIN On); ExternalProject_Add_Step(${NEXT_CLANG_STAGE} really-install; COMMAND ${CMAKE_COMMAND} --build <BINARY_DIR> --target install; COMMENT ""Performing install step for '${NEXT_CLANG_STAGE}'""; DEPENDEES build; USES_TERMINAL 1; ); ExternalProject_Add_StepTargets(${NEXT_CLANG_STAGE} really-install); add_custom_target(${NEXT_CLANG_STAGE}-install DEPENDS ${NEXT_CLANG_STAGE}-really-install). if(NOT CLANG_BOOTSTRAP_TARGETS); set(CLANG_BOOTSTRAP_TARGETS check-llvm check-clang check-all); endif(); foreach(target ${CLANG_BOOTSTRAP_TARGETS}); # Install targets have side effects, so we always want to execute them.; # ""install"" is reserved by CMake and can't be used as a step name for; # ExternalProject_Add_Step, so we can match against ""^install-"" instead of; # ""^install"" to get a tighter match. CMake's installation scripts already; # skip up-to-date files, so there's no behavior change if you install to the; # same destination multiple times.; if(target MATCHES ""^install-""); set(step_always ON); else(); set(step_always OFF); endif(). ExternalProject_Add_Step(${NEXT_CLANG_STAGE} ${target}; COMMAND ${CMAKE_COMMAND} --build <BINARY_DIR> --target ${target}; COMMENT ""Performing ${target} for '${NEXT_CLANG_STAGE}'""; DEPENDEES configure; ALWAYS ${step_always}; EXCLUDE_FROM_MAIN ON; USES_TERMINAL 1; ). if(target MATCHES ""^stage[0-9]*""); add_custom_target(${target} DEPENDS ${NEXT_CLANG_STAGE}-${target}); endif(). ExternalProject_Add_StepTargets(${NEXT_CLANG_STAGE} ${target}); endforeach(); endif(). if (CLANG_BOLT_INSTRUMENT AND NOT LLVM_BUILD_INSTRUMENTED); set(CLANG_PATH ${LLVM_RUNTIME_OUTPUT_INTDIR}/clang); set(CLANG_INSTRUMENTED ${CLANG_PATH}-bolt.inst); set(BOLT_FDATA ${CMAKE_CURRENT_BINARY_DIR}/utils/perf-training/prof.fdata). # Instrument clang with BOLT; add_custom_target(clang-instrumented; DEPENDS ${CLANG_INSTRUMENTED}; ); add_custom_command(OUTPUT ${CLANG_INSTRUMENTED}; DEPENDS clang llvm-bolt; COMMAND llvm-bolt ${CLANG_PATH} -o ${CLANG_INSTRUMENTED}; -instrument --in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt:30050,install,install,30050,interpreter/llvm-project/clang/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt,1,['install'],['install']
Deployability,"FT,\; Pere Mato, CERN/EP-SFT,\; Lorenzo Moneta, CERN/EP-SFT,\; Ole Morud, CERN/EP-SFT,\; Alja Mrak Tadel, UCSD/CMS,\; Axel Naumann, CERN/EP-SFT,\; Dante Niewenhuis, UvA and CERN/EP-SFT,\; Vincenzo Eduardo Padulano, CERN/EP-SFT,\; Ioanna Maria Panagou, CERN/EP-SFT,\; Danilo Piparo, CERN/EP-SFT,\; Fons Rademakers, CERN/IT,\; Jonas Rembser, CERN/EP-SFT,\; Jakob Schneekloth, CERN/EP-SFT,\; Sanjiban Sengupta, CERN/EP-SFT,\; Neel Shah, GSoC,\; Garima Singh, CERN/EP-SFT and Princeton,\; Yash Solanki, GSoC,\; Uri Stern, CERN/EP-SFT,\; Silia Taider, CPE Lyon and CERN EP-SFT,\; Enric Tejedor Saavedra, CERN/IT,\; Matevz Tadel, UCSD/CMS,\; [QuillPusher](https://github.com/QuillPusher), [Compiler Research Group](https://compiler-research.org/team/),\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/ATLAS,\; Daniel Werner, CERN/EP-SFT,\; Zef Wolffs, NIKHEF/ATLAS. ## Deprecation and Removal; - The minimum C++ standard supported by ROOT is now C++17.; - Support for Python 2 is now deprecated and it will be removed in next release 6.32.; - `ROOT::RDF::RResultHandle::GetResultPtr` has been deprecated. Please use `RResultPtr` directly instead and only cast to `RResultHandle` in order to call `ROOT::RDF::RunGraphs`.; - The RDataFrame factory functions `MakeCsvDataFrame`, `MakeArrowDataFrame`, `MakeNTupleDataFrame` and `MakeSqliteDataFrame` that were deprecated in v6.28 have been removed. Use `FromCSV`, `FromArrow`, `FromRNTuple` or `FromSqlite` instead.; - The TStorage reallocation routine without a size (`TStorage::ReAlloc(void *ovp, size_t size`) and heap related routines (`TStorage::AddToHeap`, `TStorage::IsOnHeap`, `TStorage::GetHeapBegin`, `TStorage::GetHeapEnd`) that were deprecated in v6.02/00 have been removed.; - The deprecated `Format(const char* option, int sigDigits)` option for `RooAbsPdf::paramOn()` was removed. Please use the `Format(const char* option, ...)` overload that takes command arguments.; - The deprecated `RooAbsPdf::paramOn()` overload that directly ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md:2214,release,release,2214,README/ReleaseNotes/v630/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md,1,['release'],['release']
Deployability,"File f(""cernstaff.root""); root[] T->StartViewer(); ```. If you want to start a tree viewer without a tree, you need to load the; tree player library first:. ``` {.cpp}; root[] gSystem->Load(""libTreeViewer.so""); root[] new TTreeViewer(); ```. The figure above shows how the tree viewer looks like for the example file; `cernstaff.root`. The left panel contains the list of trees and their; branches; in this case there is only one tree. You can add more trees; with the File-Open command to open the file containing the new tree,; then use the context menu on the right panel, select `SetTreeName` and; enter the name of the tree to add. On the right are the leaves or; variables in the tree. You can double click on any leaf to a histogram; it. The toolbar in the upper part can be used for user commands, changing; the drawing option and the histogram name. The lower part contains three; picture buttons that draw a histogram, stop the current command, and; refresh the tree. The three check buttons toggle the following:. `Hist`- the histogram drawing mode;. `Scan`- enables redirecting of `TTree::Scan `command in an ASCII file;. `Rec` - enables recording of the last issued command. - ![](pictures/020000F1.jpg) To draw more than one dimension you can drag; and drop any leaf to the `X,Y,Z` boxes"". Then push the Draw button,; witch is marked with the purple icon on the bottom left. - ![](pictures/030000F2.png) All commands can be interrupted at any time; by pressing this button. - ![](pictures/030000F3.png) The method **`TTree::Refresh`** is called by; pressing the refresh button in `TTreeViewer`. It redraws the current; exposed expression. Calling `TTree::Refresh` is useful when a tree is; produced by a writer process and concurrently analyzed by one or more; readers. - ![](pictures/030000F4.png) To add a cut/weight to the histogram, enter an; expression in the ""cut box"". The cut box is the one with the scissor; icon. Below them there are two text widgets for specifying the input a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:7669,toggle,toggle,7669,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['toggle'],['toggle']
Deployability,"FindLibClang.cmake`` sets the following; variables:. ::. LibClang_FOUND - True if libclang is found.; LibClang_LIBRARY - Clang library to link against.; LibClang_VERSION - Version number as a string (e.g. ""3.9"").; LibClang_PYTHON_EXECUTABLE - Compatible python version. ``FindCppyy.cmake`` sets the following variables:. ::. Cppyy_FOUND - set to true if Cppyy is found; Cppyy_DIR - the directory where Cppyy is installed; Cppyy_EXECUTABLE - the path to the Cppyy executable; Cppyy_INCLUDE_DIRS - Where to find the Cppyy header files.; Cppyy_VERSION - the version number of the Cppyy backend. and also defines the following functions::. cppyy_add_bindings - Generate a set of bindings from a set of header files.; cppyy_find_pips - Return a list of available pip programs. cppyy_add_bindings; ^^^^^^^^^^^^^^^^^^. Generate a set of bindings from a set of header files. Somewhat like CMake's; add_library(), the output is a compiler target. In addition ancillary files; are also generated to allow a complete set of bindings to be compiled,; packaged and installed::. cppyy_add_bindings(; pkg; pkg_version; author; author_email; [URL url]; [LICENSE license]; [LANGUAGE_STANDARD std]; [LINKDEFS linkdef...]; [IMPORTS pcm...]; [GENERATE_OPTIONS option...]; [COMPILE_OPTIONS option...]; [INCLUDE_DIRS dir...]; [LINK_LIBRARIES library...]; [H_DIRS H_DIRSectory]; H_FILES h_file...). The bindings are based on https://cppyy.readthedocs.io/en/latest/, and can be; used as per the documentation provided via the cppyy.gbl namespace. First add; the directory of the <pkg>.rootmap file to the LD_LIBRARY_PATH environment; variable, then ""import cppyy; from cppyy.gbl import <some-C++-entity>"". Alternatively, use ""import <pkg>"". This convenience wrapper supports; ""discovery"" of the available C++ entities using, for example Python 3's command; line completion support. The bindings are complete with a setup.py, supporting Wheel-based; packaging, and a test.py supporting pytest/nosetest sanity test of the bindi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:3835,install,installed,3835,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,1,['install'],['installed']
Deployability,"For example see tutorials/eve/cms_calo.C. Possible performance issues with ATI drivers (fglrx). In late 2007 ATI switched to a new driver architecture. With these; drivers a significant degradation of GL performance in selection mode,; up to a factor of 50, was observed. Both linux and Windows drivers; were affected. The issue has been resolved in the latest driver; versions. Eve; Major changes. Support for multiple, parallel OpenGL views that can show different; projections of the same event. Provide object selection and feedback highlight across all GL-views and; list-trees. New classes for visualization of calorimeter data,; TEveCaloXYZ, see tutorials/eve/cms_calo.C. Available; representations: 3D-cylindrical view, projected views r-phi and rho-z,; and lego-view (with dedicated event handler allowing detailed; inspection of the data). Support for compound objects in view of selection, highlight and; color managament (see class TEveCompound). Optimize updates of GL-scenes by introducing change-stamping bits; into TEveElement. See methods AddStamp() and; StampXyzz(). Added support for central management of visualization parameters; of objects. Instead of specifying visual attributes individually by; set-methods a single string tag can be used to retrieve all of them; with a single command, e.g.,; track->ApplyVizTag(""MuonTrack""). The parameter-database can; be saved as a CINT script, edited manually and loaded. This provides more; flexibility as different users can share the same code to; instantiate visualziation objects but still override visualization; parameters independently. See TEveElement::CopyVizParams(); and TEveManager::*VizDB() methods for more information. Minor changes, fixes and improvements. Improved handling of projected elements. For fish-eye projections, allow fixing of compression scale; beyond given distance from the center. Add support for step-function scaling of 2D-projections. This; allows arbitrary magnification of concentric regions in r-ph",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v520/index.html:1964,update,updates,1964,graf3d/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v520/index.html,1,['update'],['updates']
Deployability,"From: Chris Lattner <sabre@nondot.org>; To: ""Vikram S. Adve"" <vadve@cs.uiuc.edu>; Subject: Re: LLVM Feedback. I've included your feedback in the /home/vadve/lattner/llvm/docs directory; so that it will live in CVS eventually with the rest of LLVM. I've; significantly updated the documentation to reflect the changes you; suggested, as specified below:. > We should consider eliminating the type annotation in cases where it is; > essentially obvious from the instruction type:; > br bool <cond>, label <iftrue>, label <iffalse>; > I think your point was that making all types explicit improves clarity; > and readability. I agree to some extent, but it also comes at the; > cost of verbosity. And when the types are obvious from people's; > experience (e.g., in the br instruction), it doesn't seem to help as; > much. Very true. We should discuss this more, but my reasoning is more of a; consistency argument. There are VERY few instructions that can have all; of the types eliminated, and doing so when available unnecessarily makes; the language more difficult to handle. Especially when you see 'int; %this' and 'bool %that' all over the place, I think it would be; disorienting to see:. br %predicate, %iftrue, %iffalse. for branches. Even just typing that once gives me the creeps. ;) Like I; said, we should probably discuss this further in person... > On reflection, I really like your idea of having the two different; > switch types (even though they encode implementation techniques rather; > than semantics). It should simplify building the CFG and my guess is it; > could enable some significant optimizations, though we should think; > about which. Great. I added a note to the switch section commenting on how the VM; should just use the instruction type as a hint, and that the; implementation may choose altermate representations (such as predicated; branches). > In the lookup-indirect form of the switch, is there a reason not to; > make the val-type uint?. No. This was something",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt:268,update,updated,268,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt,1,['update'],['updated']
Deployability,"GOAL:. Provide http interface to arbitrary ROOT application. USAGE:. At any place of the code create http server:. root [0] serv = new THttpServer. By default, civetweb web server with port number 8080 will be started.; It gets access to files, canvases and trees, registered in gROOT.; One additionally could register other objects to the server:. root [1] serv->Register(""abc/fold1"", hpx);; root [2] serv->Register(""abc/fold2"", hpxpy);; root [3] serv->Register(""extra"", c1);. Once server running, just open in any browser page: http://yourhost:8080. Example macro: $ROOTSYS/tutorials/http/httpserver.C. FAST CGI:. Instead of running http server, one could use fast cgi interface; to normal web server like Apache or lighttpd or any other.; When creating server, one could specify:. root [0] serv = new THttpServer(""fastcgi:9000"");. This opens port 9000, which should be specified in web server configuration.; For instance, lighttpd.conf file could contain path like this:. fastcgi.server = (; ""/remote_scripts/"" =>; (( ""host"" => ""192.168.1.10"",; ""port"" => 9000,; ""check-local"" => ""disable"",; ""docroot"" => ""/""; )); ). In this case one should be able to access root application via address. http://your_lighttpd_host/remote_scripts/root.cgi/. AUTHOR:. Sergey Linev, S.Linev@gsi.de. CHANGES:. January 2015; - Provide exe.json request to execute arbitrary object method and return; result in JSON format. Server should run in non-readonly mode. Fall 2014; - Implement gzip for result of any submitted requests, automatically done ; when .gz extension is provided; - Provide access to arbitrary data member of objects, registered to the server; - Prevent data caching in the browser by setting no-cache header. April 2014; - In TCivetweb class support digest authentication method. User; can specify auth_file and auth_domain parameters to protect; access to the server; - Fix error in FastCgi, now correctly works with Apache; - Avoid direct usage of TASImage. March 2014; - Replace mongoose by civetwe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/http/README.txt:896,configurat,configuration,896,net/http/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/README.txt,1,['configurat'],['configuration']
Deployability,"GS`` above. Running CMake and Building; --------------------------. Finally, if you're using your platform compiler, run:. .. code-block:: bash. $ cmake -G Ninja <source-dir> -DCMAKE_BUILD_TYPE=<type> <options above>. If you're using Clang as the cross-compiler, run:. .. code-block:: bash. $ CC='clang' CXX='clang++' cmake -G Ninja <source-dir> -DCMAKE_BUILD_TYPE=<type> <options above>. If you have ``clang``/``clang++`` on the path, it should just work, and special; Ninja files will be created in the build directory. I strongly suggest; you to run ``cmake`` on a separate build directory, *not* inside the; source tree. To build, simply type:. .. code-block:: bash. $ ninja. It should automatically find out how many cores you have, what are; the rules that needs building and will build the whole thing. You can't run ``ninja check-all`` on this tree because the created; binaries are targeted to ARM, not x86_64. Installing and Using; --------------------. After the LLVM/Clang has built successfully, you should install it; via:. .. code-block:: bash. $ ninja install. which will create a sysroot on the install-dir. You can then tar; that directory into a binary with the full triple name (for easy; identification), like:. .. code-block:: bash. $ ln -sf <install-dir> arm-linux-gnueabihf-clang; $ tar zchf arm-linux-gnueabihf-clang.tar.gz arm-linux-gnueabihf-clang. If you copy that tarball to your target board, you'll be able to use; it for running the test-suite, for example. Follow the guidelines at; https://llvm.org/docs/lnt/quickstart.html, unpack the tarball in the; test directory, and use options:. .. code-block:: bash. $ ./sandbox/bin/python sandbox/bin/lnt runtest nt \; --sandbox sandbox \; --test-suite `pwd`/test-suite \; --cc `pwd`/arm-linux-gnueabihf-clang/bin/clang \; --cxx `pwd`/arm-linux-gnueabihf-clang/bin/clang++. Remember to add the ``-jN`` options to ``lnt`` to the number of CPUs; on your board. Also, the path to your clang has to be absolute, so; you'll need ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToCrossCompileLLVM.rst:7118,install,install,7118,interpreter/llvm-project/llvm/docs/HowToCrossCompileLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToCrossCompileLLVM.rst,1,['install'],['install']
Deployability,"G_TABLEGEN_EXE}"" CACHE INTERNAL """"). add_subdirectory(include). # All targets below may depend on all tablegen'd files.; get_property(CLANG_TABLEGEN_TARGETS GLOBAL PROPERTY CLANG_TABLEGEN_TARGETS); add_custom_target(clang-tablegen-targets; DEPENDS; omp_gen; ClangDriverOptions; ${CLANG_TABLEGEN_TARGETS}); set_target_properties(clang-tablegen-targets PROPERTIES FOLDER ""Misc""); list(APPEND LLVM_COMMON_DEPENDS clang-tablegen-targets). # Force target to be built as soon as possible. Clang modules builds depend; # header-wise on it as they ship all headers from the umbrella folders. Building; # an entire module might include header, which depends on intrinsics_gen.; if(LLVM_ENABLE_MODULES); list(APPEND LLVM_COMMON_DEPENDS intrinsics_gen); endif(). add_subdirectory(lib); add_subdirectory(tools); add_subdirectory(runtime). option(CLANG_BUILD_EXAMPLES ""Build CLANG example programs by default."" OFF); add_subdirectory(examples). if(APPLE); # this line is needed as a cleanup to ensure that any CMakeCaches with the old; # default value get updated to the new default.; if(CLANG_ORDER_FILE STREQUAL """"); unset(CLANG_ORDER_FILE CACHE); unset(CLANG_ORDER_FILE); endif(). set(CLANG_ORDER_FILE ${CMAKE_CURRENT_BINARY_DIR}/clang.order CACHE FILEPATH; ""Order file to use when compiling clang in order to improve startup time (Darwin Only - requires ld64).""). if(NOT EXISTS ${CLANG_ORDER_FILE}); string(FIND ""${CLANG_ORDER_FILE}"" ""${CMAKE_CURRENT_BINARY_DIR}"" PATH_START); if(PATH_START EQUAL 0); file(WRITE ${CLANG_ORDER_FILE} ""\n""); else(); message(FATAL_ERROR ""Specified order file '${CLANG_ORDER_FILE}' does not exist.""); endif(); endif(); endif(). if( CLANG_INCLUDE_TESTS ); add_subdirectory(unittests); list(APPEND CLANG_TEST_DEPS ClangUnitTests); list(APPEND CLANG_TEST_PARAMS; clang_unit_site_config=${CMAKE_CURRENT_BINARY_DIR}/test/Unit/lit.site.cfg; ); add_subdirectory(test); add_subdirectory(bindings/python/tests). if(CLANG_BUILT_STANDALONE); umbrella_lit_testsuite_end(check-all); endif(); ad",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt:18113,update,updated,18113,interpreter/llvm-project/clang/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt,1,['update'],['updated']
Deployability,"H` for finding the; headers back at runtime. The ROOT stress suite is now updated to follow this behavior; see for instance the injection of; `$ROOTSYS/test` in `test/stressMathCore.cxx`, allowing ROOT to find the header at runtime, whether interpreted; (`R__ADD_INCLUDE_PATH`) or compiled (`TROOT::AddExtraInterpreterArgs({""-I...""})` before interpreter construction). If you called `ROOT_GENERATE_DICTIONARY(Dict ${CMAKE_CURRENT_SOURCE_DIR}/subdir/Header1.h LINKDEF LinkDef.h)` then update that; call to `ROOT_GENERATE_DICTIONARY(Dict Header1.h OPTIONS -I subdir LINKDEF LinkDef.h)` *if* the header is usually included as; `#include ""Header1.h""`, or to `ROOT_GENERATE_DICTIONARY(Dict subdir/Header1.h LINKDEF LinkDef.h)` *if* the header is usually; included as `#include ""subdir/Header1.h""`. I.e. the general rule is: pass to `ROOT_GENERATE_DICTIONARY` (or; `ROOT_STANDARD_LIBRARY_PACKAGE`) the spelling as `#include`ed. As an important side-effect, `ROOT_GENERATE_DICTIONARY` and thus `ROOT_STANDARD_LIBRARY_PACKAGE` now *require* the header to; be found at configuration time. We have seen too many cases where the header location was mis-stated, and as a consequence,; CMake did not generate the proper dependencies. If the header should not be taken into account for dependencies and / or if; the header will not be found (e.g. the standard library's `vector`) please pass the header through the `NODEPHEADERS` option; to `ROOT_GENERATE_DICTIONARY` or `ROOT_STANDARD_LIBRARY_PACKAGE`. We believe that this simplification / regularization of behavior, and the additional checks are worth the possible changes; on the user side. ## PyROOT. If the fix or new feature is a pythonization related to a C++ class, the change is added to the respective section above. ### Current PyROOT. - Fix compatibility with Python3.7 (ROOT-9922, ROOT-9871, ROOT-9809); - Fix lookup for templated methods (ROOT-9789); - Fix lookup for templated free functions (ROOT-9836). ### Experimental PyROOT. - All pythonisati",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:25331,configurat,configuration,25331,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,1,['configurat'],['configuration']
Deployability,"Hardware; --------; Any system that can adequately run Visual Studio 2019 is fine. The LLVM; source tree including the git index consumes approximately 3GB.; Object files, libraries and executables consume approximately 5GB in; Release mode and much more in Debug mode. SSD drive and >16GB RAM are; recommended. Software; --------; You will need `Visual Studio <https://visualstudio.microsoft.com/>`_ 2019 or; later, with the latest Update installed. Visual Studio Community Edition; suffices. You will also need the `CMake <http://www.cmake.org/>`_ build system since it; generates the project files you will use to build with. CMake is bundled with; Visual Studio 2019 so separate installation is not required. If you do install; CMake separately, Visual Studio 2022 will require CMake Version 3.21 or later. If you would like to run the LLVM tests you will need `Python; <http://www.python.org/>`_. Version 3.6 and newer are known to work. You can; install Python with Visual Studio 2019, from the Microsoft store or from; the `Python web site <http://www.python.org/>`_. We recommend the latter since it; allows you to adjust installation options. You will need `Git for Windows <https://git-scm.com/>`_ with bash tools, too.; Git for Windows is also bundled with Visual Studio 2019. Getting Started; ===============; Here's the short story for getting up and running quickly with LLVM.; These instruction were tested with Visual Studio 2019 and Python 3.9.6:. 1. Download and install `Visual Studio <https://visualstudio.microsoft.com/>`_.; 2. In the Visual Studio installer, Workloads tab, select the; **Desktop development with C++** workload. Under Individual components tab,; select **Git for Windows**.; 3. Complete the Visual Studio installation.; 4. Download and install the latest `Python 3 release <http://www.python.org/>`_.; 5. In the first install screen, select both **Install launcher for all users**; and **Add Python to the PATH**. This will allow installing psutil for all; users",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst:2378,install,install,2378,interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,1,['install'],['install']
Deployability,"IBDIR_SUFFIX}; RUNTIME DESTINATION bin). if (${ARG_SHARED} AND NOT CMAKE_CONFIGURATION_TYPES); add_custom_target(install-${name}; DEPENDS ${name}; COMMAND ""${CMAKE_COMMAND}""; -DCMAKE_INSTALL_COMPONENT=${name}; -P ""${CMAKE_BINARY_DIR}/cmake_install.cmake""); endif(); endif(); set_property(GLOBAL APPEND PROPERTY CLING_EXPORTS ${name}); else(); # Add empty ""phony"" target; add_custom_target(${name}); endif(). set_target_properties(${name} PROPERTIES FOLDER ""Cling libraries""); set_cling_windows_version_resource_properties(${name}); endmacro(add_cling_library). macro(add_cling_executable name); add_llvm_executable( ${name} ${ARGN} ); set_target_properties(${name} PROPERTIES FOLDER ""Cling executables""); set_cling_windows_version_resource_properties(${name}); endmacro(add_cling_executable). set(CMAKE_INCLUDE_CURRENT_DIR ON). include_directories(BEFORE; ${CMAKE_CURRENT_BINARY_DIR}/include; ${CMAKE_CURRENT_SOURCE_DIR}/include; ). if (NOT LLVM_INSTALL_TOOLCHAIN_ONLY); install(DIRECTORY include/cling include/cling-c; DESTINATION include; FILES_MATCHING; PATTERN ""*.def""; PATTERN ""*.h""; PATTERN ""config.h"" EXCLUDE; PATTERN "".svn"" EXCLUDE; ). install(DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/include/cling; DESTINATION include; FILES_MATCHING; PATTERN ""CMakeFiles"" EXCLUDE; PATTERN ""*.inc""; PATTERN ""*.h""; PATTERN ""*.modulemap""; ); endif(). add_definitions( -D_GNU_SOURCE -DCLING_VERSION=${CLING_VERSION}). option(CLING_INCLUDE_TESTS; ""Generate build targets for the Cling unit tests.""; ${LLVM_INCLUDE_TESTS}). if (NOT WIN32); set(cling_path_delim "":""); else(); set(cling_path_delim "";""); endif(). if( CLING_INCLUDE_TESTS ); set(cling_include_deflt ${CMAKE_INSTALL_PREFIX}/include; ${CMAKE_CURRENT_SOURCE_DIR}/include; ${CLANG_INCLUDE_DIRS}; ${LLVM_INCLUDE_DIRS}; ). # CLANG_INCLUDE_DIRS and LLVM_INCLUDE_DIRS can be a semicolon separated lists.; string(REPLACE "";"" ""${cling_path_delim}"" cling_include_deflt ""${cling_include_deflt}""); endif(). if(NOT CLING_INCLUDE_PATHS); set(CLING_INCLUDE_PATHS ""${cl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/CMakeLists.txt:15351,install,install,15351,interpreter/cling/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/CMakeLists.txt,1,['install'],['install']
Deployability,"IG_EXTRA_PATH_HINTS=${Clang_Config_ExtraPathHints}); endif(Clang_DIR). if (LLVM_FORCE_USE_OLD_TOOLCHAIN); list(APPEND _clad_extra_cmake_args -DLLVM_FORCE_USE_OLD_TOOLCHAIN=${LLVM_FORCE_USE_OLD_TOOLCHAIN}); endif(LLVM_FORCE_USE_OLD_TOOLCHAIN). list(APPEND _clad_extra_cmake_args -DCLAD_BUILD_STATIC_ONLY=ON). # Wrap download, configure and build steps in a script to log output; set(_clad_extra_settings; LOG_DOWNLOAD ON; LOG_CONFIGURE ON; LOG_BUILD ON; LOG_INSTALL ON; LOG_OUTPUT_ON_FAILURE ON; ). # If the CLAD_SOURCE_DIR variable is defined in the CMake configuration, we're; # skipping the download of the repository and use the passed directory.; if (DEFINED CLAD_SOURCE_DIR); list(APPEND _clad_extra_settings DOWNLOAD_COMMAND """"); list(APPEND _clad_extra_settings SOURCE_DIR ${CLAD_SOURCE_DIR}); endif(). #list(APPEND _clad_patches_list ""patch1.patch"" ""patch2.patch""); #set(_clad_patch_command; # ${CMAKE_COMMAND} -E copy_directory; # ${CMAKE_SOURCE_DIR}/interpreter/cling/tools/plugins/clad/patches <SOURCE_DIR>; # && git checkout <SOURCE_DIR>; # && git apply --ignore-space-change --ignore-whitespace ${_clad_patches_list}; # ). ExternalProject_Add(; clad; GIT_REPOSITORY https://github.com/vgvassilev/clad.git; GIT_TAG v1.7; UPDATE_COMMAND """"; PATCH_COMMAND ${_clad_patch_command}; CMAKE_ARGS -G ${CMAKE_GENERATOR}; -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE}; -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}; -DCMAKE_C_FLAGS=${CMAKE_C_FLAGS}; -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER}; -DCMAKE_CXX_FLAGS=${CLAD_CXX_FLAGS}; -DCMAKE_INSTALL_PREFIX=${clad_install_dir}/plugins; -DLLVM_DIR=${LLVM_BINARY_DIR}; -DCLANG_INCLUDE_DIRS=${CLANG_INCLUDE_DIRS}; ${_clad_extra_cmake_args}; # FIXME; # Building with 1 core is a temporary workaround for #16654 and has to be ; # there until the behaviour of the clad build on ubuntu 24.10 is understood.; # The performance penalty in the build is negligible.; BUILD_COMMAND ${CMAKE_COMMAND} --build . ${EXTRA_BUILD_ARGS} -j 1; INSTALL_COMMAND ${CMAKE_COMMAND} --build .",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/plugins/clad/CMakeLists.txt:2691,patch,patch,2691,interpreter/cling/tools/plugins/clad/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/plugins/clad/CMakeLists.txt,2,['patch'],"['patch', 'patches']"
Deployability,"ILD_TYPES}); string (REPLACE "";"" ""|"" ALLOWED_BUILD_TYPES_STRING ""${ALLOWED_BUILD_TYPES}""); string (TOUPPER ""${ALLOWED_BUILD_TYPES_STRING}"" uppercase_ALLOWED_BUILD_TYPES). if (CMAKE_BUILD_TYPE AND; NOT uppercase_CMAKE_BUILD_TYPE MATCHES ""^(${uppercase_ALLOWED_BUILD_TYPES})$""); message(FATAL_ERROR ""Unknown value for CMAKE_BUILD_TYPE: ${CMAKE_BUILD_TYPE}""); endif(). # LLVM_INSTALL_PACKAGE_DIR needs to be declared prior to adding the tools; # subdirectory in order to have the value available for llvm-config.; include(GNUInstallPackageDir); set(LLVM_INSTALL_PACKAGE_DIR ""${CMAKE_INSTALL_PACKAGEDIR}/llvm"" CACHE STRING; ""Path for CMake subdirectory for LLVM (defaults to '${CMAKE_INSTALL_PACKAGEDIR}/llvm')""). set(LLVM_TOOLS_INSTALL_DIR ""${CMAKE_INSTALL_BINDIR}"" CACHE STRING; ""Path for binary subdirectory (defaults to '${CMAKE_INSTALL_BINDIR}')""); mark_as_advanced(LLVM_TOOLS_INSTALL_DIR). set(LLVM_UTILS_INSTALL_DIR ""${LLVM_TOOLS_INSTALL_DIR}"" CACHE STRING; ""Path to install LLVM utilities (enabled by LLVM_INSTALL_UTILS=ON) (defaults to LLVM_TOOLS_INSTALL_DIR)""); mark_as_advanced(LLVM_UTILS_INSTALL_DIR). set(LLVM_EXAMPLES_INSTALL_DIR ""examples"" CACHE STRING; ""Path for examples subdirectory (enabled by LLVM_BUILD_EXAMPLES=ON) (defaults to 'examples')""); mark_as_advanced(LLVM_EXAMPLES_INSTALL_DIR). # They are used as destination of target generators.; set(LLVM_RUNTIME_OUTPUT_INTDIR ${CMAKE_CURRENT_BINARY_DIR}/${CMAKE_CFG_INTDIR}/bin); set(LLVM_LIBRARY_OUTPUT_INTDIR ${CMAKE_CURRENT_BINARY_DIR}/${CMAKE_CFG_INTDIR}/lib${LLVM_LIBDIR_SUFFIX}); if(WIN32 OR CYGWIN); # DLL platform -- put DLLs into bin.; set(LLVM_SHLIB_OUTPUT_INTDIR ${LLVM_RUNTIME_OUTPUT_INTDIR}); else(); set(LLVM_SHLIB_OUTPUT_INTDIR ${LLVM_LIBRARY_OUTPUT_INTDIR}); endif(). # Each of them corresponds to llvm-config's.; set(LLVM_TOOLS_BINARY_DIR ${LLVM_RUNTIME_OUTPUT_INTDIR}) # --bindir; set(LLVM_LIBRARY_DIR ${LLVM_LIBRARY_OUTPUT_INTDIR}) # --libdir; set(LLVM_MAIN_SRC_DIR ${CMAKE_CURRENT_SOURCE_DIR} ) # --src-root; set(LL",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:18517,install,install,18517,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['install'],['install']
Deployability,"INATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT llvm-headers; FILES_MATCHING; PATTERN ""*.def""; PATTERN ""*.h""; PATTERN ""*.gen""; PATTERN ""*.inc""; # Exclude include/llvm/CMakeFiles/intrinsics_gen.dir, matched by ""*.def""; PATTERN ""CMakeFiles"" EXCLUDE; PATTERN ""config.h"" EXCLUDE; ). if (LLVM_INSTALL_MODULEMAPS); install(DIRECTORY include; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT llvm-headers; FILES_MATCHING; PATTERN ""module.modulemap""; ); install(FILES include/module.install.modulemap; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT llvm-headers; RENAME ""module.extern.modulemap""; ); endif(LLVM_INSTALL_MODULEMAPS). # Installing the headers needs to depend on generating any public; # tablegen'd headers.; add_custom_target(llvm-headers DEPENDS intrinsics_gen omp_gen); set_target_properties(llvm-headers PROPERTIES FOLDER ""Misc""). if (NOT LLVM_ENABLE_IDE); add_llvm_install_targets(install-llvm-headers; DEPENDS llvm-headers; COMPONENT llvm-headers); endif(). # Custom target to install all libraries.; add_custom_target(llvm-libraries); set_target_properties(llvm-libraries PROPERTIES FOLDER ""Misc""). if (NOT LLVM_ENABLE_IDE); add_llvm_install_targets(install-llvm-libraries; DEPENDS llvm-libraries; COMPONENT llvm-libraries); endif(). get_property(LLVM_LIBS GLOBAL PROPERTY LLVM_LIBS); if(LLVM_LIBS); list(REMOVE_DUPLICATES LLVM_LIBS); foreach(lib ${LLVM_LIBS}); add_dependencies(llvm-libraries ${lib}); if (NOT LLVM_ENABLE_IDE); add_dependencies(install-llvm-libraries install-${lib}); add_dependencies(install-llvm-libraries-stripped install-${lib}-stripped); endif(); endforeach(); endif(); endif(). # This must be at the end of the LLVM root CMakeLists file because it must run; # after all targets are created.; llvm_distribution_add_targets(); process_llvm_pass_plugins(GEN_CONFIG); include(CoverageReport). # This allows us to deploy the Universal CRT DLLs by passing -DCMAKE_INSTALL_UCRT_LIBRARIES=ON to CMake; if (MSVC AND CMAKE_HOST_SYSTEM_NAME STREQUAL ""Windows"" AND ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:52884,install,install,52884,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['install'],['install']
Deployability,"INATION ${CMAKE_INSTALL_MACRODIR} ${DIR_PERMISSIONS}); if(http); install(DIRECTORY js/ DESTINATION ${CMAKE_INSTALL_JSROOTDIR} ${DIR_PERMISSIONS}); endif(); if(webgui); install(DIRECTORY ui5/ DESTINATION ${CMAKE_INSTALL_OPENUI5DIR} ${DIR_PERMISSIONS}); endif(); set(MAN_PATT_EXCL); if(NOT fortran OR NOT CMAKE_Fortran_COMPILER); list(APPEND MAN_PATT_EXCL PATTERN h2root.1 EXCLUDE); list(APPEND MAN_PATT_EXCL PATTERN g2root.1 EXCLUDE); endif(); install(DIRECTORY man/ DESTINATION ${CMAKE_INSTALL_MANDIR} ${DIR_PERMISSIONS} ${MAN_PATT_EXCL}); install(DIRECTORY tutorials/ DESTINATION ${CMAKE_INSTALL_TUTDIR} ${DIR_PERMISSIONS} COMPONENT tests); install(FILES; cmake/modules/RootMacros.cmake; cmake/modules/RootTestDriver.cmake; DESTINATION ${CMAKE_INSTALL_CMAKEDIR}); install(FILES; ""cmake/modules/FindVdt.cmake""; DESTINATION ""${CMAKE_INSTALL_CMAKEDIR}/modules""); endif(). #---Add configuration files for kernel and jupyter----------------------------------------------; # Make sure the Jupyter ROOT C++ kernel runs with the same Python version as ROOT; set(root_jupyter_dir notebook); set(root_jupyter_config jupyter_notebook_config.py); configure_file(etc/${root_jupyter_dir}/${root_jupyter_config}.in etc/${root_jupyter_dir}/${root_jupyter_config}); install(FILES ${CMAKE_BINARY_DIR}/etc/${root_jupyter_dir}/${root_jupyter_config} DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}/${root_jupyter_dir}). set(root_kernel_dir ${root_jupyter_dir}/kernels/root); set(root_kernel_file kernel.json); configure_file(etc/${root_kernel_dir}/${root_kernel_file}.in etc/${root_kernel_dir}/${root_kernel_file}); install(FILES ${CMAKE_BINARY_DIR}/etc/${root_kernel_dir}/${root_kernel_file} DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}/${root_kernel_dir}). #---install clad header files-------------------------------------------------------------------; if(clad); install(DIRECTORY ${CMAKE_BINARY_DIR}/etc/cling/plugins/; DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}/cling/plugins); endif(). #---Set flag for PyROOT tests that are exp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt:26598,configurat,configuration,26598,CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt,1,['configurat'],['configuration']
Deployability,"INSTALL_GTEST; ""Install the llvm gtest library. This should be on if you want to do; stand-alone builds of the other projects and run their unit tests."" OFF). option(LLVM_BUILD_BENCHMARKS ""Add LLVM benchmark targets to the list of default; targets. If OFF, benchmarks still could be built using Benchmarks target."" OFF); option(LLVM_INCLUDE_BENCHMARKS ""Generate benchmark targets. If OFF, benchmarks can't be built."" ON). option (LLVM_BUILD_DOCS ""Build the llvm documentation."" OFF); option (LLVM_INCLUDE_DOCS ""Generate build targets for llvm documentation."" ON); option (LLVM_ENABLE_DOXYGEN ""Use doxygen to generate llvm API documentation."" OFF); option (LLVM_ENABLE_SPHINX ""Use Sphinx to generate llvm documentation."" OFF); option (LLVM_ENABLE_OCAMLDOC ""Build OCaml bindings documentation."" ON); option (LLVM_ENABLE_BINDINGS ""Build bindings."" ON). set(LLVM_INSTALL_DOXYGEN_HTML_DIR ""${CMAKE_INSTALL_DOCDIR}/llvm/doxygen-html""; CACHE STRING ""Doxygen-generated HTML documentation install directory""); set(LLVM_INSTALL_OCAMLDOC_HTML_DIR ""${CMAKE_INSTALL_DOCDIR}/llvm/ocaml-html""; CACHE STRING ""OCamldoc-generated HTML documentation install directory""). option (LLVM_BUILD_EXTERNAL_COMPILER_RT; ""Build compiler-rt as an external project."" OFF). option (LLVM_VERSION_PRINTER_SHOW_HOST_TARGET_INFO; ""Show target and host info when tools are invoked with --version."" ON). # You can configure which libraries from LLVM you want to include in the; # shared library by setting LLVM_DYLIB_COMPONENTS to a semi-colon delimited; # list of LLVM components. All component names handled by llvm-config are valid.; if(NOT DEFINED LLVM_DYLIB_COMPONENTS); set(LLVM_DYLIB_COMPONENTS ""all"" CACHE STRING; ""Semicolon-separated list of components to include in libLLVM, or \""all\"".""); endif(). if(MSVC); option(LLVM_BUILD_LLVM_C_DYLIB ""Build LLVM-C.dll (Windows only)"" ON); # Set this variable to OFF here so it can't be set with a command-line; # argument.; set (LLVM_LINK_LLVM_DYLIB OFF); if (BUILD_SHARED_LIBS); message",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:32788,install,install,32788,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,2,['install'],['install']
Deployability,"IR. Legalizer. No illegal operations must remain or be introduced after this pass. Register Bank Selector. All virtual registers must have a register bank assigned after this pass. Instruction Select. No gMIR must remain or be introduced after this pass. In other words, we must; have completed the conversion from gMIR to MIR. In addition to these passes, there are also some optional passes that perform; an optimization. The current optional passes are:. Combiner. Replaces patterns of instructions with a better alternative. Typically, this; means improving run time performance by replacing instructions with faster; alternatives but Combiners can also focus on code size or other metrics. Additional passes such as these can be inserted to support higher optimization; levels or target specific needs. A likely pipeline is:. .. image:: pipeline-overview-with-combiners.png. Of course, combiners can be inserted in other places too. Also passes can be; replaced entirely so long as their task is complete as shown in this (more; customized) example pipeline. .. image:: pipeline-overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from CodeGen. Testing; -------. The ability to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:3077,pipeline,pipeline,3077,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,1,['pipeline'],['pipeline']
Deployability,"IRgen optimization opportunities. //===---------------------------------------------------------------------===//. The common pattern of; --; short x; // or char, etc; (x == 10); --; generates an zext/sext of x which can easily be avoided. //===---------------------------------------------------------------------===//. Bitfields accesses can be shifted to simplify masking and sign; extension. For example, if the bitfield width is 8 and it is; appropriately aligned then is is a lot shorter to just load the char; directly. //===---------------------------------------------------------------------===//. It may be worth avoiding creation of alloca's for formal arguments; for the common situation where the argument is never written to or has; its address taken. The idea would be to begin generating code by using; the argument directly and if its address is taken or it is stored to; then generate the alloca and patch up the existing code. In theory, the same optimization could be a win for block local; variables as long as the declaration dominates all statements in the; block. NOTE: The main case we care about this for is for -O0 -g compile time; performance, and in that scenario we will need to emit the alloca; anyway currently to emit proper debug info. So this is blocked by; being able to emit debug information which refers to an LLVM; temporary, not an alloca. //===---------------------------------------------------------------------===//. We should try and avoid generating basic blocks which only contain; jumps. At -O0, this penalizes us all the way from IRgen (malloc &; instruction overhead), all the way down through code generation and; assembly time. On 176.gcc:expr.ll, it looks like over 12% of basic blocks are just; direct branches!. //===---------------------------------------------------------------------===//; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/README.txt:919,patch,patch,919,interpreter/llvm-project/clang/lib/CodeGen/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/README.txt,1,['patch'],['patch']
Deployability,"IR}/llvm/Config/TargetExegesis.def.in; ${LLVM_INCLUDE_DIR}/llvm/Config/TargetExegesis.def; ). # They are not referenced. See set_output_directory().; set( CMAKE_RUNTIME_OUTPUT_DIRECTORY ${LLVM_TOOLS_BINARY_DIR} ); set( CMAKE_LIBRARY_OUTPUT_DIRECTORY ${LLVM_LIBRARY_DIR} ); set( CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${LLVM_LIBRARY_DIR} ). # For up-to-date instructions for installing the TFLite dependency, refer to; # the bot setup script: https://github.com/google/ml-compiler-opt/blob/main/buildbot/buildbot_init.sh; set(LLVM_HAVE_TFLITE """" CACHE BOOL ""Use tflite""); if (LLVM_HAVE_TFLITE); find_package(tensorflow-lite REQUIRED); endif(). # For up-to-date instructions for installing the Tensorflow dependency, refer to; # the bot setup script: https://github.com/google/ml-compiler-opt/blob/main/buildbot/buildbot_init.sh; # Specifically, assuming python3 is installed:; # python3 -m pip install --upgrade pip && python3 -m pip install --user tf_nightly==2.3.0.dev20200528; # Then set TENSORFLOW_AOT_PATH to the package install - usually it's ~/.local/lib/python3.7/site-packages/tensorflow; #; set(TENSORFLOW_AOT_PATH """" CACHE PATH ""Path to TensorFlow pip install dir""). if (NOT TENSORFLOW_AOT_PATH STREQUAL """"); set(LLVM_HAVE_TF_AOT ""ON"" CACHE BOOL ""Tensorflow AOT available""); set(TENSORFLOW_AOT_COMPILER; ""${TENSORFLOW_AOT_PATH}/../../../../bin/saved_model_cli""; CACHE PATH ""Path to the Tensorflow AOT compiler""); include_directories(${TENSORFLOW_AOT_PATH}/include); add_subdirectory(${TENSORFLOW_AOT_PATH}/xla_aot_runtime_src; ${CMAKE_ARCHIVE_OUTPUT_DIRECTORY}/tf_runtime); install(TARGETS tf_xla_runtime EXPORT LLVMExports; ARCHIVE DESTINATION lib${LLVM_LIBDIR_SUFFIX} COMPONENT tf_xla_runtime); set_property(GLOBAL APPEND PROPERTY LLVM_EXPORTS tf_xla_runtime); # Once we add more modules, we should handle this more automatically.; if (DEFINED LLVM_OVERRIDE_MODEL_HEADER_INLINERSIZEMODEL); set(LLVM_INLINER_MODEL_PATH ""none""); elseif(NOT DEFINED LLVM_INLINER_MODEL_PATH; OR ""${LLVM_INLINER_MODEL_P",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:43299,install,install,43299,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['install'],['install']
Deployability,"Implementation of BLAKE3, originating from https://github.com/BLAKE3-team/BLAKE3/tree/1.3.1/c. # Example. An example program that hashes bytes from standard input and prints the; result:. Using the C++ API:. ```c++; #include ""llvm/Support/BLAKE3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm::BLAKE3 hasher;. // Read input bytes from stdin.; char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; hasher.update(llvm::StringRef(buf, n));; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. Default output length is 32 bytes.; auto output = hasher.final();. // Print the hash as hexadecimal.; for (uint8_t byte : output) {; printf(""%02x"", byte);; }; printf(""\n"");; return 0;; }; ```. Using the C API:. ```c; #include ""llvm-c/blake3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:552,update,update,552,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,1,['update'],['update']
Deployability,"Integral()` function, simply; return the output using the `buildCall()` function. ``` {.cpp}; std::string; buildCallToAnalyticIntegral(Int_t code, const char *rangeName, RooFit::Detail::RooFit::Detail::CodeSquashContext &ctx) const override {; return ctx.buildCall(""EvaluateFunc::integralFoo"", a, b);; }; ```. \note The implementation of the `RooAbsReal::buildCallToAnalyticIntegral()`; function is quite similar to the `translate()` function, except that in; `translate()`, you have to add to the result (using `addResult()`), while for; `buildCallToAnalyticIntegral()`, you only have to return the string (using; `buildCall()`). **Consolidated Code changes in RooFoo example**. Final RooFoo code:. ``` {.cpp}; class RooFoo : public RooAbsReal {; int a;; int b;; // int doFoo() { return a* b + a + b; }; // int integralFoo() { return /* whatever */;}; public:; // Other functions...; double evaluate() override {; // Do some bookkeeping; return EvaluateFunc::doFoo(a, b);; };; double analyticalIntegral(Int_t code, const char* rangeName) override {; // Select the right paths for integration using codes or whatever.; return EvaluateFunc::integralFoo(a, b);; }. //// ************************** functions for AD Support ***********************; void translate(RooFit::Detail::RooFit::Detail::CodeSquashContext &ctx) const override {; std::string res = ctx.buildCall(""EvaluateFunc::doFoo"", a, b);; ctx.addResult(this, res);; }. std::string; buildCallToAnalyticIntegral(Int_t code, const char *rangeName, RooFit::Detail::RooFit::Detail::CodeSquashContext &ctx) const override {; return ctx.buildCall(""EvaluateFunc::integralFoo"", a, b);; }; //// ************************** functions for AD Support ***********************; };. ```. Mathematical code moved to `MathFuncs.h` file. ``` {.cpp}; int doFoo(int a, int b) { return a* b + a + b; }; ```. Integrals moved to the 'MathFuncs.h' file. ``` {.cpp}; int integralFoo(int a, int b) { return /* whatever */;}; ```. > Remember, as long as your code is supp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:24792,integrat,integration,24792,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['integrat'],['integration']
Deployability,"Introduction; ============. This document contains the release notes for the interactive C++ interpreter; Cling, release 1.2. Cling is built on top of [Clang](http://clang.llvm.org) and; [LLVM](http://llvm.org>) compiler infrastructure. Here we; describe the status of Cling in some detail, including major; improvements from the previous release and new feature work. Note that if you are reading this file from a git checkout or the main Cling; web page, this document applies to the *next* release, not the current one. What's New in Cling 1.2?; ========================. Some of the major new features and improvements to Cling are listed; here. Generic improvements to Cling as a whole or to its underlying; infrastructure are described first. External Dependencies; ---------------------; * Upgrade to LLVM r0000000. Major New Features; ------------------; * A major new feature. Misc; ----; * A misc feature. Experimental Features; ---------------------; * An experimental feature. Jupyter; -------; * A Jupyter feature. Fixed Bugs; ----------; [ROOT-XXXX](https://sft.its.cern.ch/jira/browse/ROOT-XXXX). <!---Get release bugs; git log v1.1..master | grep -i ""fix"" | grep '#' | sed -E 's,.*\#([0-9]*).*,\[\1\]\(https://github.com/root-project/cling/issues/\1\),g' | sort; --->; <!---Standard MarkDown doesn't support neither variables nor <base>; [ROOT-XXX](https://sft.its.cern.ch/jira/browse/ROOT-XXX); --->. <!---Additional Information; ----------------------; A wide variety of additional information is available on the; [Cling web page](http://root.cern/cling). The web page contains versions of; the API documentation which are up-to-date with the git version of the source; code. You can access versions of these documents specific to this release by; going into the “clang/docs/” directory in the Cling source tree. If you have any questions or comments about Cling, please feel free to contact; us via the mailing list.--->. Special Kudos; =============; This release wouldn't have ha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md:55,release,release,55,interpreter/cling/docs/ReleaseNotes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md,4,['release'],['release']
Deployability,"It may; report undefined symbol errors, read archive members, replace weak symbols, etc.; The linker is able to do this seamlessly even though it does not know the exact; content of input LLVM bitcode files. If dead code stripping is enabled then the; linker collects the list of live symbols. Phase 3 : Optimize Bitcode Files; --------------------------------. After symbol resolution, the linker tells the LTO shared object which symbols; are needed by native object files. In the example above, the linker reports; that only ``foo1()`` is used by native object files using; ``lto_codegen_add_must_preserve_symbol()``. Next the linker invokes the LLVM; optimizer and code generators using ``lto_codegen_compile()`` which returns a; native object file creating by merging the LLVM bitcode files and applying; various optimization passes. Phase 4 : Symbol Resolution after optimization; ----------------------------------------------. In this phase, the linker reads optimized a native object file and updates the; internal global symbol table to reflect any changes. The linker also collects; information about any changes in use of external symbols by LLVM bitcode; files. In the example above, the linker notes that ``foo4()`` is not used any; more. If dead code stripping is enabled then the linker refreshes the live; symbol information appropriately and performs dead code stripping. After this phase, the linker continues linking as if it never saw LLVM bitcode; files. .. _libLTO:. ``libLTO``; ==========. ``libLTO`` is a shared object that is part of the LLVM tools, and is intended; for use by a linker. ``libLTO`` provides an abstract C interface to use the LLVM; interprocedural optimizer without exposing details of LLVM's internals. The; intention is to keep the interface as stable as possible even when the LLVM; optimizer continues to evolve. It should even be possible for a completely; different compilation technology to provide a different libLTO that works with; their object fil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:7519,update,updates,7519,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['update'],['updates']
Deployability,"L, .forwarding=&i, .flags=0, .size=sizeof(struct _block_byref_i), .captured_i=2 )};; struct __block_literal_5 _block_literal = {; &_NSConcreteStackBlock,; (1<<25)|(1<<29), <uninitialized>,; __block_invoke_5,; &__block_descriptor_5,; &i,; };. Importing ``__attribute__((NSObject))`` ``__block`` variables; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. A ``__block`` variable that is also marked ``__attribute__((NSObject))`` should; have ``byref_keep`` and ``byref_dispose`` helper functions that use; ``_Block_object_assign`` and ``_Block_object_dispose``. ``__block`` escapes; ^^^^^^^^^^^^^^^^^^^. Because ``Blocks`` referencing ``__block`` variables may have ``Block_copy()``; performed upon them the underlying storage for the variables may move to the; heap. In Objective-C Garbage Collection Only compilation environments the heap; used is the garbage collected one and no further action is required. Otherwise; the compiler must issue a call to potentially release any heap storage for; ``__block`` variables at all escapes or terminations of their scope. The call; should be:. .. code-block:: c. _Block_object_dispose(&_block_byref_foo, BLOCK_FIELD_IS_BYREF);. Nesting; ^^^^^^^. ``Blocks`` may contain ``Block`` literal expressions. Any variables used within; inner blocks are imported into all enclosing ``Block`` scopes even if the; variables are not used. This includes ``const`` imports as well as ``__block``; variables. Objective C Extensions to ``Blocks``; ====================================. Importing Objects; -----------------. Objects should be treated as ``__attribute__((NSObject))`` variables; all; ``copy_helper``, ``dispose_helper``, ``byref_keep``, and ``byref_dispose``; helper functions should use ``_Block_object_assign`` and; ``_Block_object_dispose``. There should be no code generated that uses; ``*-retain`` or ``*-release`` methods. ``Blocks`` as Objects; ---------------------. The compiler will treat ``Blocks`` as objects when synthesizing proper",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst:18104,release,release,18104,interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,1,['release'],['release']
Deployability,"LBI_Signature`` (in configuration: ``Signature``); Align lambda body relative to the lambda signature. This is the default. .. code-block:: c++. someMethod(; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; });. * ``LBI_OuterScope`` (in configuration: ``OuterScope``); For statements within block scope, align lambda body relative to the; indentation level of the outer scope the lambda signature resides in. .. code-block:: c++. someMethod(; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; });. someMethod(someOtherMethod(; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; }));. .. _Language:. **Language** (``LanguageKind``) :versionbadge:`clang-format 3.5` :ref:`¶ <Language>`; Language, this format style is targeted at. Possible values:. * ``LK_None`` (in configuration: ``None``); Do not use. * ``LK_Cpp`` (in configuration: ``Cpp``); Should be used for C, C++. * ``LK_CSharp`` (in configuration: ``CSharp``); Should be used for C#. * ``LK_Java`` (in configuration: ``Java``); Should be used for Java. * ``LK_JavaScript`` (in configuration: ``JavaScript``); Should be used for JavaScript. * ``LK_Json`` (in configuration: ``Json``); Should be used for JSON. * ``LK_ObjC`` (in configuration: ``ObjC``); Should be used for Objective-C, Objective-C++. * ``LK_Proto`` (in configuration: ``Proto``); Should be used for Protocol Buffers; (https://developers.google.com/protocol-buffers/). * ``LK_TableGen`` (in configuration: ``TableGen``); Should be used for TableGen code. * ``LK_TextProto`` (in configuration: ``TextProto``); Should be used for Protocol Buffer messages in text format; (https://developers.google.com/protocol-buffers/). * ``LK_Verilog`` (in configuration: ``Verilog``); Should be used for Verilog and SystemVerilog.; https://standards.ieee.org/ieee/1800/6700/; https://sci-hub.st/10.1109/IEEESTD.2018.8299595. .. _LineEnding:. **LineEnding** (``LineEndingStyle``) :versionbadge:`clang-format 16` :ref:`¶ <LineEnding>`; Line ending style (``\n`` or ``\r\",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:83468,configurat,configuration,83468,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"LF input and binary output files only.; * ``llvm-objcopy`` now supports ``-O elf64-s390`` for SystemZ. * Supported parsing XCOFF auxiliary symbols in ``obj2yaml``. * ``llvm-ranlib`` now supports ``-X`` on AIX to specify the type of object file; ranlib should examine. * ``llvm-cxxfilt`` now supports ``--no-params``/``-p`` to skip function; parameters. * ``llvm-nm`` now supports ``--export-symbol`` to ignore the import symbol file.; * ``llvm-nm`` now supports the ``--line-numbers`` (``-l``) option to use; debugging information to print symbols' filenames and line numbers. * ``llvm-rc`` and ``llvm-windres`` now accept file path references in ``.rc`` files; concatenated from multiple string literals. * The ``llvm-windres`` option ``--preprocessor`` now resolves its argument; in the ``PATH`` environment variable as expected, and options passed with; ``--preprocessor-arg`` are placed before the input file as they should; be. * The ``llvm-windres`` option ``--preprocessor`` has been updated with the; breaking behaviour change from GNU windres from binutils 2.36, where; the whole argument is considered as one path, not considered as a; sequence of tool name and parameters. Changes to LLDB; ---------------------------------. * ``SBWatchpoint::GetHardwareIndex`` is deprecated and now returns -1; to indicate the index is unavailable.; * Methods in SBHostOS related to threads have had their implementations; removed. These methods will return a value indicating failure.; * ``SBType::FindDirectNestedType`` function is added. It's useful; for formatters to quickly find directly nested type when it's known; where to search for it, avoiding more expensive global search via; ``SBTarget::FindFirstType``.; * ``lldb-vscode`` was renamed to ``lldb-dap`` and and its installation; instructions have been updated to reflect this. The underlying functionality; remains unchanged.; * The ``mte_ctrl`` register can now be read from AArch64 Linux core files.; * LLDB on AArch64 Linux now supports d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst:15254,update,updated,15254,interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,1,['update'],['updated']
Deployability,"LF`` and ``DeriveCRLF`` of; ``LineEnding``. .. _DerivePointerAlignment:. **DerivePointerAlignment** (``Boolean``) :versionbadge:`clang-format 3.7` :ref:`¶ <DerivePointerAlignment>`; If ``true``, analyze the formatted file for the most common; alignment of ``&`` and ``*``.; Pointer and reference alignment styles are going to be updated according; to the preferences found in the file.; ``PointerAlignment`` is then used only as fallback. .. _DisableFormat:. **DisableFormat** (``Boolean``) :versionbadge:`clang-format 3.7` :ref:`¶ <DisableFormat>`; Disables formatting completely. .. _EmptyLineAfterAccessModifier:. **EmptyLineAfterAccessModifier** (``EmptyLineAfterAccessModifierStyle``) :versionbadge:`clang-format 13` :ref:`¶ <EmptyLineAfterAccessModifier>`; Defines when to put an empty line after access modifiers.; ``EmptyLineBeforeAccessModifier`` configuration handles the number of; empty lines between two access modifiers. Possible values:. * ``ELAAMS_Never`` (in configuration: ``Never``); Remove all empty lines after access modifiers. .. code-block:: c++. struct foo {; private:; int i;; protected:; int j;; /* comment */; public:; foo() {}; private:; protected:; };. * ``ELAAMS_Leave`` (in configuration: ``Leave``); Keep existing empty lines after access modifiers.; MaxEmptyLinesToKeep is applied instead. * ``ELAAMS_Always`` (in configuration: ``Always``); Always add empty line after access modifiers if there are none.; MaxEmptyLinesToKeep is applied also. .. code-block:: c++. struct foo {; private:. int i;; protected:. int j;; /* comment */; public:. foo() {}; private:. protected:. };. .. _EmptyLineBeforeAccessModifier:. **EmptyLineBeforeAccessModifier** (``EmptyLineBeforeAccessModifierStyle``) :versionbadge:`clang-format 12` :ref:`¶ <EmptyLineBeforeAccessModifier>`; Defines in which cases to put empty line before access modifiers. Possible values:. * ``ELBAMS_Never`` (in configuration: ``Never``); Remove all empty lines before access modifiers. .. code-block:: c++. st",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:60948,configurat,configuration,60948,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"LLVM Command Guide; ------------------. The following documents are command descriptions for all of the LLVM tools.; These pages describe how to use the LLVM commands and what their options are.; Note that these pages do not describe all of the options available for all; tools. To get a complete listing, pass the ``--help`` (general options) or; ``--help-hidden`` (general and debugging options) arguments to the tool you are; interested in. Basic Commands; ~~~~~~~~~~~~~~. .. toctree::; :maxdepth: 1. dsymutil; llc; lli; llvm-as; llvm-config; llvm-cov; llvm-cxxmap; llvm-debuginfo-analyzer; llvm-diff; llvm-dis; llvm-dwarfdump; llvm-dwarfutil; llvm-lib; llvm-libtool-darwin; llvm-link; llvm-lipo; llvm-mc; llvm-mca; llvm-opt-report; llvm-otool; llvm-profdata; llvm-readobj; llvm-reduce; llvm-stress; llvm-symbolizer; opt. GNU binutils replacements; ~~~~~~~~~~~~~~~~~~~~~~~~~. .. toctree::; :maxdepth: 1. llvm-addr2line; llvm-ar; llvm-cxxfilt; llvm-install-name-tool; llvm-nm; llvm-objcopy; llvm-objdump; llvm-ranlib; llvm-readelf; llvm-size; llvm-strings; llvm-strip. Debugging Tools; ~~~~~~~~~~~~~~~. .. toctree::; :maxdepth: 1. bugpoint; llvm-extract; llvm-bcanalyzer. Developer Tools; ~~~~~~~~~~~~~~~. .. toctree::; :maxdepth: 1. FileCheck; tblgen; clang-tblgen; lldb-tblgen; llvm-tblgen; mlir-tblgen; lit; llvm-exegesis; llvm-ifs; llvm-locstats; llvm-pdbutil; llvm-profgen; llvm-tli-checker. Remarks Tools; ~~~~~~~~~~~~~~. .. toctree::; :maxdepth: 1. llvm-remarkutil; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/index.rst:951,install,install-name-tool,951,interpreter/llvm-project/llvm/docs/CommandGuide/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/index.rst,1,['install'],['install-name-tool']
Deployability,"LLVM Documentation; ==================. LLVM's documentation is written in reStructuredText, a lightweight; plaintext markup language (file extension `.rst`). While the; reStructuredText documentation should be quite readable in source form, it; is mostly meant to be processed by the Sphinx documentation generation; system to create HTML pages which are hosted on <https://llvm.org/docs/> and; updated after every commit. Manpage output is also supported, see below. If you instead would like to generate and view the HTML locally, install; Sphinx <http://sphinx-doc.org/> and then do:. cd <build-dir>; cmake -DLLVM_ENABLE_SPHINX=true -DSPHINX_OUTPUT_HTML=true <src-dir>; make -j3 docs-llvm-html; $BROWSER <build-dir>/docs/html/index.html. The mapping between reStructuredText files and generated documentation is; `docs/Foo.rst` <-> `<build-dir>/docs//html/Foo.html` <-> `https://llvm.org/docs/Foo.html`. If you are interested in writing new documentation, you will want to read; `SphinxQuickstartTemplate.rst` which will get you writing documentation; very fast and includes examples of the most important reStructuredText; markup syntax. Manpage Output; ===============. Building the manpages is similar to building the HTML documentation. The; primary difference is to use the `man` makefile target, instead of the; default (which is `html`). Sphinx then produces the man pages in the; directory `<build-dir>/docs/man/`. cd <build-dir>; cmake -DLLVM_ENABLE_SPHINX=true -DSPHINX_OUTPUT_MAN=true <src-dir>; make -j3 docs-llvm-man; man -l <build-dir>/docs/man/FileCheck.1. The correspondence between .rst files and man pages is; `docs/CommandGuide/Foo.rst` <-> `<build-dir>/docs//man/Foo.1`.; These .rst files are also included during HTML generation so they are also; viewable online (as noted above) at e.g.; `https://llvm.org/docs/CommandGuide/Foo.html`. Checking links; ==============. The reachability of external links in the documentation can be checked by; running:. cd llvm/docs/; sphinx-b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/README.txt:396,update,updated,396,interpreter/llvm-project/llvm/docs/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/README.txt,2,"['install', 'update']","['install', 'updated']"
Deployability,"LLVM NVPTX target.; The library can be found under ``nvvm/libdevice/`` in the CUDA Toolkit and; there is a separate version for each compute architecture. For a list of all math functions implemented in libdevice, see; `libdevice Users Guide <http://docs.nvidia.com/cuda/libdevice-users-guide/index.html>`_. To accommodate various math-related compiler flags that can affect code; generation of libdevice code, the library code depends on a special LLVM IR; pass (``NVVMReflect``) to handle conditional compilation within LLVM IR. This; pass looks for calls to the ``@__nvvm_reflect`` function and replaces them; with constants based on the defined reflection parameters. Such conditional; code often follows a pattern:. .. code-block:: c++. float my_function(float a) {; if (__nvvm_reflect(""FASTMATH"")); return my_function_fast(a);; else; return my_function_precise(a);; }. The default value for all unspecified reflection parameters is zero. The ``NVVMReflect`` pass should be executed early in the optimization; pipeline, immediately after the link stage. The ``internalize`` pass is also; recommended to remove unused math functions from the resulting PTX. For an; input IR module ``module.bc``, the following compilation flow is recommended:. 1. Save list of external functions in ``module.bc``; 2. Link ``module.bc`` with ``libdevice.compute_XX.YY.bc``; 3. Internalize all functions not in list from (1); 4. Eliminate all unused internal functions; 5. Run ``NVVMReflect`` pass; 6. Run standard optimization pipeline. .. note::. ``linkonce`` and ``linkonce_odr`` linkage types are not suitable for the; libdevice functions. It is possible to link two IR modules that have been; linked against libdevice using different reflection variables. Since the ``NVVMReflect`` pass replaces conditionals with constants, it will; often leave behind dead code of the form:. .. code-block:: llvm. entry:; ..; br i1 true, label %foo, label %bar; foo:; ..; bar:; ; Dead code; .. Therefore, it is recommended tha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst:8808,pipeline,pipeline,8808,interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,1,['pipeline'],['pipeline']
Deployability,"LLVM examples. **LLVM_INCLUDE_TESTS**:BOOL; Generate build targets for the LLVM unit tests. Defaults to ON. You can use; this option to disable the generation of build targets for the LLVM unit; tests. **LLVM_INCLUDE_TOOLS**:BOOL; Generate build targets for the LLVM tools. Defaults to ON. You can use this; option to disable the generation of build targets for the LLVM tools. **LLVM_INSTALL_BINUTILS_SYMLINKS**:BOOL; Install symlinks from the binutils tool names to the corresponding LLVM tools.; For example, ar will be symlinked to llvm-ar. **LLVM_INSTALL_CCTOOLS_SYMLINKS**:BOOL; Install symliks from the cctools tool names to the corresponding LLVM tools.; For example, lipo will be symlinked to llvm-lipo. **LLVM_INSTALL_OCAMLDOC_HTML_DIR**:STRING; The path to install OCamldoc-generated HTML documentation to. This path can; either be absolute or relative to the CMAKE_INSTALL_PREFIX. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/ocaml-html``. **LLVM_INSTALL_SPHINX_HTML_DIR**:STRING; The path to install Sphinx-generated HTML documentation to. This path can; either be absolute or relative to the CMAKE_INSTALL_PREFIX. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/html``. **LLVM_INSTALL_UTILS**:BOOL; If enabled, utility binaries like ``FileCheck`` and ``not`` will be installed; to CMAKE_INSTALL_PREFIX. **LLVM_INTEGRATED_CRT_ALLOC**:PATH; On Windows, allows embedding a different C runtime allocator into the LLVM; tools and libraries. Using a lock-free allocator such as the ones listed below; greatly decreases ThinLTO link time by about an order of magnitude. It also; midly improves Clang build times, by about 5-10%. At the moment, rpmalloc,; snmalloc and mimalloc are supported. Use the path to `git clone` to select; the respective allocator, for example:. .. code-block:: console. $ D:\git> git clone https://github.com/mjansson/rpmalloc; $ D:\llvm-project> cmake ... -DLLVM_INTEGRATED_CRT_ALLOC=D:\git\rpmalloc. This flag needs to be used along with the static CRT, ie. if building t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:29210,install,install,29210,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['install'],['install']
Deployability,"LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLVM. This makes it easy to apply the patch. For information on how to; clone from git, please see the :ref:`Getting Started Guide; <checkout>`. #. Similarly, patches should be submitted soon after they are generated. Old; patches may not apply correctly if the underlying code changes between the; time the patch was created and the time it is applied. #. Once you have created your patch, create a; :ref:`GitHub Pull Request <github-reviews>` for; it (or commit it directly if applicable). When submitting patches, please do not add confidentiality or non-disclosure; notices to the patches themselves. These notices conflict with the LLVM; licensing terms and may result in your contribution being excluded. .. _code review:. Code Reviews; ------------. LLVM has a code-review policy. Code review is one way to increase the quality of; software. Please see :doc:`CodeReview` for more information on LLVM's code-review; process. .. _breaking:. Making Potentially Breaking Changes; -----------------------------------. Please help notify users and vendors of potential disruptions when upgrading to; a newer version of a tool. For example, deprecating a feature that is expected; to be removed in the future, removing an already-deprecated feature, upgrading a; diagnostic from a warning to an error, switching important default behavior, or; any other potentially disruptive situation thought to be worth raising; awareness of. For such changes, the following should be done:. .. warning::. Phabricator is deprecated and will be switched to read-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:4514,patch,patches,4514,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,2,['patch'],['patches']
Deployability,"LLVM_LIT=ON;-DCLANG_RESOURCE_DIR=${CLANG_RESOURCE_DIR}""); foreach(proj ${LLVM_ENABLE_RUNTIMES}); set(proj_dir ""${CMAKE_CURRENT_SOURCE_DIR}/../../${proj}""); if(IS_DIRECTORY ${proj_dir} AND EXISTS ${proj_dir}/CMakeLists.txt); list(APPEND runtimes ${proj_dir}); else(); message(FATAL_ERROR ""LLVM_ENABLE_RUNTIMES requests ${proj} but directory not found: ${proj_dir}""); endif(); string(TOUPPER ""${proj}"" canon_name); STRING(REGEX REPLACE ""-"" ""_"" canon_name ${canon_name}); set(LLVM_EXTERNAL_${canon_name}_SOURCE_DIR ""${CMAKE_CURRENT_SOURCE_DIR}/../../${proj}""); endforeach(). function(get_compiler_rt_path path); foreach(entry ${runtimes}); get_filename_component(projName ${entry} NAME); if(""${projName}"" MATCHES ""compiler-rt""); set(${path} ${entry} PARENT_SCOPE); return(); endif(); endforeach(); endfunction(). include(LLVMExternalProjectUtils). if(NOT LLVM_BUILD_RUNTIMES); set(EXTRA_ARGS EXCLUDE_FROM_ALL); endif(). function(check_apple_target triple builtin_or_runtime); set(error ""\; compiler-rt for Darwin builds for all platforms and architectures using a \; single configuration. Specify only a single darwin triple (e.g. x86_64-apple-darwin) \; in your targets list (and not a triple for a specific platform such as macos). \; You can use variables such as COMPILER_RT_ENABLE_IOS and DARWIN_ios_ARCHS to \; control the specific platforms and architectures to build.""). set(seen_property ${builtin_or_runtime}_darwin_triple_seen); string(REPLACE ""-"" "";"" triple_components ${triple}); foreach(component ${triple_components}); string(TOLOWER ""${component}"" component_lower); if(component_lower MATCHES ""^darwin""); get_property(darwin_triple_seen GLOBAL PROPERTY ${seen_property}); if(darwin_triple_seen); message(FATAL_ERROR ""${error}""); endif(); set_property(GLOBAL PROPERTY ${seen_property} YES); if(NOT RUNTIMES_BUILD_ALLOW_DARWIN); message(FATAL_ERROR ""\; ${error} Set RUNTIMES_BUILD_ALLOW_DARWIN to allow a single darwin triple.""); endif(); elseif(component_lower MATCHES ""^ios|^macos|^tvos|^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/runtimes/CMakeLists.txt:1348,configurat,configuration,1348,interpreter/llvm-project/llvm/runtimes/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/runtimes/CMakeLists.txt,1,['configurat'],['configuration']
Deployability,"LUDE_DIRS ${LLVM_INCLUDE_DIRS} CACHE PATH ""Path to llvm/include and any other header dirs needed""); set(LLVM_BINARY_DIR ""${LLVM_BINARY_DIR}"" CACHE PATH ""Path to LLVM build tree""); set(LLVM_MAIN_SRC_DIR ""${CMAKE_CURRENT_SOURCE_DIR}/../llvm"" CACHE PATH ""Path to LLVM source tree""); set(LLVM_TOOLS_BINARY_DIR ""${LLVM_TOOLS_BINARY_DIR}"" CACHE PATH ""Path to llvm/bin""); set(LLVM_LIBRARY_DIR ""${LLVM_LIBRARY_DIR}"" CACHE PATH ""Path to llvm/lib""). find_program(LLVM_TABLEGEN_EXE ""llvm-tblgen"" ${LLVM_TOOLS_BINARY_DIR}; NO_DEFAULT_PATH). # They are used as destination of target generators.; set(LLVM_RUNTIME_OUTPUT_INTDIR ${CMAKE_BINARY_DIR}/${CMAKE_CFG_INTDIR}/bin); set(LLVM_LIBRARY_OUTPUT_INTDIR ${CMAKE_BINARY_DIR}/${CMAKE_CFG_INTDIR}/lib${LLVM_LIBDIR_SUFFIX}); if(WIN32 OR CYGWIN); # DLL platform -- put DLLs into bin.; set(LLVM_SHLIB_OUTPUT_INTDIR ${LLVM_RUNTIME_OUTPUT_INTDIR}); else(); set(LLVM_SHLIB_OUTPUT_INTDIR ${LLVM_LIBRARY_OUTPUT_INTDIR}); endif(). option(LLVM_INSTALL_TOOLCHAIN_ONLY; ""Only include toolchain files in the 'install' target."" OFF). option(LLVM_FORCE_USE_OLD_TOOLCHAIN; ""Set to ON to force using an old, unsupported host toolchain."" OFF); option(CLANG_ENABLE_BOOTSTRAP ""Generate the clang bootstrap target"" OFF); option(LLVM_ENABLE_LIBXML2 ""Use libxml2 if available."" ON). include(AddLLVM); include(TableGen); include(HandleLLVMOptions); include(VersionFromVCS); include(CheckAtomic); include(GetErrcMessages); include(LLVMDistributionSupport). set(PACKAGE_VERSION ""${LLVM_PACKAGE_VERSION}""); set(BUG_REPORT_URL ""${LLVM_PACKAGE_BUGREPORT}"" CACHE STRING; ""Default URL where bug reports are to be submitted.""). if (NOT DEFINED LLVM_INCLUDE_TESTS); set(LLVM_INCLUDE_TESTS ON); endif(). include_directories(${LLVM_INCLUDE_DIRS}); link_directories(""${LLVM_LIBRARY_DIR}""). set( CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin ); set( CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib${LLVM_LIBDIR_SUFFIX} ); set( CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib${LLVM_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt:2072,install,install,2072,interpreter/llvm-project/clang/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt,1,['install'],['install']
Deployability,"LUDE_EXPORTS ""include(\""${LLVM_EXPORTS_FILE}\"")""); set(llvm_config_include_buildtree_only_exports; ""include(\""${LLVM_BUILDTREEONLY_EXPORTS_FILE}\"")""); configure_file(; LLVMConfig.cmake.in; ${llvm_cmake_builddir}/LLVMConfig.cmake; @ONLY); set(llvm_config_include_buildtree_only_exports). # For compatibility with projects that include(LLVMConfig); # via CMAKE_MODULE_PATH, place API modules next to it.; # Copy without source permissions because the source could be read-only,; # but we need to write into the copied folder.; # This should be removed in the future.; file(COPY .; DESTINATION ${llvm_cmake_builddir}; NO_SOURCE_PERMISSIONS; FILES_MATCHING PATTERN *.cmake; PATTERN CMakeFiles EXCLUDE; PATTERN llvm-driver-template.cpp.in; ). #; # Generate LLVMConfig.cmake for the install tree.; #. find_prefix_from_config(LLVM_CONFIG_CODE LLVM_INSTALL_PREFIX ""${LLVM_INSTALL_PACKAGE_DIR}""). extend_path(LLVM_CONFIG_MAIN_INCLUDE_DIR ""\${LLVM_INSTALL_PREFIX}"" ""${CMAKE_INSTALL_INCLUDEDIR}""); # This is the same as the above because the handwritten and generated headers; # are combined in one directory at install time.; set(LLVM_CONFIG_INCLUDE_DIR ""${LLVM_CONFIG_MAIN_INCLUDE_DIR}""); set(LLVM_CONFIG_INCLUDE_DIRS; ""${LLVM_CONFIG_MAIN_INCLUDE_DIR}""; ""${LLVM_CONFIG_INCLUDE_DIR}""; ); list(REMOVE_DUPLICATES LLVM_CONFIG_INCLUDE_DIRS). extend_path(LLVM_CONFIG_LIBRARY_DIR ""\${LLVM_INSTALL_PREFIX}"" ""lib\${LLVM_LIBDIR_SUFFIX}""); set(LLVM_CONFIG_LIBRARY_DIRS; ""${LLVM_CONFIG_LIBRARY_DIR}""; # FIXME: Should there be other entries here?; ); list(REMOVE_DUPLICATES LLVM_CONFIG_LIBRARY_DIRS). set(LLVM_CONFIG_BINARY_DIR ""\${LLVM_INSTALL_PREFIX}""); extend_path(LLVM_CONFIG_CMAKE_DIR ""\${LLVM_INSTALL_PREFIX}"" ""${LLVM_INSTALL_PACKAGE_DIR}""); extend_path(LLVM_CONFIG_TOOLS_BINARY_DIR ""\${LLVM_INSTALL_PREFIX}"" ""${LLVM_TOOLS_INSTALL_DIR}""). # Generate a default location for lit; if (LLVM_INSTALL_UTILS AND LLVM_BUILD_UTILS); if (CMAKE_HOST_WIN32 AND NOT CYGWIN); set(LLVM_CONFIG_DEFAULT_EXTERNAL_LIT ""${LLVM_CONFIG_TOO",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/cmake/modules/CMakeLists.txt:4904,install,install,4904,interpreter/llvm-project/llvm/cmake/modules/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/cmake/modules/CMakeLists.txt,1,['install'],['install']
Deployability,"LVM IR generation, the LLVM assembly language; reference manual is; also useful. Debugging. Inspecting data structures in a debugger:. Many LLVM and Clang data structures provide; a dump() method which will print a description of the; data structure to stderr.; The QualType; structure is used pervasively. This is a simple value class for; wrapping types with qualifiers; you can use; the isConstQualified(), for example, to get one of the; qualifiers, and the getTypePtr() method to get the; wrapped Type* which you can then dump.; For LLDB users there are; data formatters for clang data structures in; ; clang/utils/ClangDataFormat.py. Debugging using Visual Studio. The files; ; llvm/utils/LLVMVisualizers/llvm.natvis and; ; clang/utils/ClangVisualizers/clang.natvis provide debugger visualizers; that make debugging of more complex data types much easier.; Depending on how you configure the project, Visual Studio may automatically; use these visualizers when debugging or you may be required to put the files; into %USERPROFILE%\Documents\Visual Studio <version>\Visualizers; or create a symbolic link so they update automatically. See; ; Microsoft's documentation for more details on use of NATVIS. Testing. Testing on Unix-like Systems. Clang includes a basic regression suite in the tree which can be; run with make test from the top-level clang directory, or; just make in the test sub-directory.; make VERBOSE=1 can be used to show more detail; about what is being run.; If you built LLVM and Clang using CMake, the test suite can be run; with make check-clang from the top-level LLVM directory.; The tests primarily consist of a test runner script running the compiler; under test on individual test files grouped in the directories under the; test directory. The individual test files include comments at the; beginning indicating the Clang compile options to use, to be read; by the test runner. Embedded comments also can do things like telling; the test runner that an error is expe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/hacking.html:2356,update,update,2356,interpreter/llvm-project/clang/www/hacking.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/hacking.html,1,['update'],['update']
Deployability,"LVM emits stack map data into the object code within a designated; :ref:`stackmap-section`. This stack map data contains a record for; each stack map. The record stores the stack map's instruction address; and contains an entry for each mapped value. Each entry encodes a; value's location as a register, stack offset, or constant. A patch point is an instruction address at which space is reserved for; patching a new instruction sequence at run time. Patch points look; much like calls to LLVM. They take arguments that follow a calling; convention and may return a value. They also imply stack map; generation, which allows the runtime to locate the patchpoint and; find the location of ``live values`` at that point. Motivation; ==========. This functionality is currently experimental but is potentially useful; in a variety of settings, the most obvious being a runtime (JIT); compiler. Example applications of the patchpoint intrinsics are; implementing an inline call cache for polymorphic method dispatch or; optimizing the retrieval of properties in dynamically typed languages; such as JavaScript. The intrinsics documented here are currently used by the JavaScript; compiler within the open source WebKit project, see the `FTL JIT; <https://trac.webkit.org/wiki/FTLJIT>`_, but they are designed to be; used whenever stack maps or code patching are needed. Because the; intrinsics have experimental status, compatibility across LLVM; releases is not guaranteed. The stack map functionality described in this document is separate; from the functionality described in; :ref:`stack-map`. `GCFunctionMetadata` provides the location of; pointers into a collected heap captured by the `GCRoot` intrinsic,; which can also be considered a ""stack map"". Unlike the stack maps; defined above, the `GCFunctionMetadata` stack map interface does not; provide a way to associate live register values of arbitrary type with; an instruction address, nor does it specify a format for the resulting; stack ma",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:1703,patch,patchpoint,1703,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['patch'],['patchpoint']
Deployability,"LVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/myrepo/release); do; branch=${ref#refs/remotes/myrepo/}; git -C my-monorepo branch --no-track myrepo/${branch} ${ref}; done. # Preserve main.; git -C my-monorepo branch --no-track myrepo/main refs/remotes/myrepo/main. # Merge main.; git -C my-monorepo checkout local/zip/main # Or local/octopus/main; git -C my-monorepo merge myrepo/main. You may want to merge other corresponding branches, for example; ``myrepo`` release branches if they were in lockstep with LLVM project; releases. ``--tag-prefix`` tells ``import-downstream-repo.py`` to rename; annotated tags with the given prefix. Due to limitations with; ``fast_filter_branch.py``, unannotated tags cannot be renamed; (``fast_filter_branch.py`` considers them branches, not tags). Since; the upstream monorepo had its tags rewritten with an ""llvmorg-""; prefix, name conflicts should not be an issue. ``--tag-prefix`` can; be used to more clearly indicate which tags correspond to various; imported repositories. Given this repository history::. R1 - R2 - R3 <- m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:35589,release,release,35589,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['release'],['release']
Deployability,"LVM_TARGETS_TO_BUILD``,; which controls the LLVM target architectures that are included on the; build.; * CMake generates project files for all build types. To select a specific; build type, use the Configuration manager from the VS IDE or the; ``/property:Configuration`` command line option when using MSBuild.; * By default, the Visual Studio project files generated by CMake use the; 32-bit toolset. If you are developing on a 64-bit version of Windows and; want to use the 64-bit toolset, pass the ``-Thost=x64`` flag when; generating the Visual Studio solution. This requires CMake 3.8.0 or later. 13. Start Visual Studio and select configuration:. In the directory you created the project files will have an ``llvm.sln``; file, just double-click on that to open Visual Studio. The default Visual; Studio configuration is **Debug** which is slow and generates a huge amount; of debug information on disk. For now, we recommend selecting **Release**; configuration for the LLVM project which will build the fastest or; **RelWithDebInfo** which is also several time larger than Release.; Another technique is to build all of LLVM in Release mode and change; compiler flags, disabling optimization and enabling debug information, only; for specific libraries or source files you actually need to debug. 14. Test LLVM in Visual Studio:. You can run LLVM tests by merely building the project ""check-all"". The test; results will be shown in the VS output window. Once the build succeeds, you; have verified a working LLVM development environment!. You should not see any unexpected failures, but will see many unsupported; tests and expected failures:. ::. 114>Testing Time: 1124.66s; 114> Skipped : 39; 114> Unsupported : 21649; 114> Passed : 51615; 114> Expectedly Failed: 93; ========== Build: 114 succeeded, 0 failed, 321 up-to-date, 0 skipped ==========``. Alternatives to manual installation; ===================================; Instead of the steps above, to simplify the installation procedu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst:7077,configurat,configuration,7077,interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,1,['configurat'],['configuration']
Deployability,"LVM`_ section for detailed information on; configuring and compiling LLVM. Go to `Directory Layout`_ to learn about the; layout of the source code tree. Stand-alone Builds; ------------------. Stand-alone builds allow you to build a sub-project against a pre-built; version of the clang or llvm libraries that is already present on your; system. You can use the source code from a standard checkout of the llvm-project; (as described above) to do stand-alone builds, but you may also build; from a :ref:`sparse checkout<workflow-multicheckout-nocommit>` or from the; tarballs available on the `releases <https://github.com/llvm/llvm-project/releases/>`_; page. For stand-alone builds, you must have an llvm install that is configured; properly to be consumable by stand-alone builds of the other projects.; This could be a distro provided LLVM install, or you can build it yourself,; like this:. .. code-block:: console. cmake -G Ninja -S path/to/llvm-project/llvm -B $builddir \; -DLLVM_INSTALL_UTILS=ON \; -DCMAKE_INSTALL_PREFIX=/path/to/llvm/install/prefix \; < other options >. ninja -C $builddir install. Once llvm is installed, to configure a project for a stand-alone build, invoke CMake like this:. .. code-block:: console. cmake -G Ninja -S path/to/llvm-project/$subproj \; -B $buildir_subproj \; -DLLVM_EXTERNAL_LIT=/path/to/lit \; -DLLVM_ROOT=/path/to/llvm/install/prefix. Notice that:. * The stand-alone build needs to happen in a folder that is not the; original folder where LLVMN was built; (`$builddir!=$builddir_subproj`).; * ``LLVM_ROOT`` should point to the prefix of your llvm installation,; so for example, if llvm is installed into ``/usr/bin`` and; ``/usr/lib64``, then you should pass ``-DLLVM_ROOT=/usr/``.; * Both the ``LLVM_ROOT`` and ``LLVM_EXTERNAL_LIT`` options are; required to do stand-alone builds for all sub-projects. Additional; required options for each sub-project can be found in the table; below. The ``check-$subproj`` and ``install`` build targets are support",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:6018,install,install,6018,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['install'],['install']
Deployability,"L_TOOLCHAIN_ONLY); install(DIRECTORY include/clang include/clang-c; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT clang-headers; FILES_MATCHING; PATTERN ""*.def""; PATTERN ""*.h""; PATTERN ""config.h"" EXCLUDE; ). install(DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/include/clang; DESTINATION ""${CMAKE_INSTALL_INCLUDEDIR}""; COMPONENT clang-headers; FILES_MATCHING; PATTERN ""CMakeFiles"" EXCLUDE; PATTERN ""*.inc""; PATTERN ""*.h""; ). # Installing the headers needs to depend on generating any public; # tablegen'd headers.; add_custom_target(clang-headers DEPENDS clang-tablegen-targets); set_target_properties(clang-headers PROPERTIES FOLDER ""Misc""); if(NOT LLVM_ENABLE_IDE); add_llvm_install_targets(install-clang-headers; DEPENDS clang-headers; COMPONENT clang-headers); endif(). add_custom_target(bash-autocomplete DEPENDS utils/bash-autocomplete.sh); install(FILES utils/bash-autocomplete.sh; DESTINATION ""${CMAKE_INSTALL_DATADIR}/clang""; COMPONENT bash-autocomplete); if(NOT LLVM_ENABLE_IDE); add_llvm_install_targets(install-bash-autocomplete; DEPENDS bash-autocomplete; COMPONENT bash-autocomplete); endif(); endif(). option(CLANG_BUILD_TOOLS; ""Build the Clang tools. If OFF, just generate build targets."" ON). if(LLVM_ENABLE_PLUGINS OR LLVM_EXPORT_SYMBOLS_FOR_PLUGINS); set(HAVE_CLANG_PLUGIN_SUPPORT ON); else(); set(HAVE_CLANG_PLUGIN_SUPPORT OFF); endif(); CMAKE_DEPENDENT_OPTION(CLANG_PLUGIN_SUPPORT; ""Build clang with plugin support"" ON; ""HAVE_CLANG_PLUGIN_SUPPORT"" OFF). # If libstdc++ is statically linked, clang-repl needs to statically link libstdc++; # itself, which is not possible in many platforms because of current limitations in; # JIT stack. (more platforms need to be supported by JITLink); if(NOT LLVM_STATIC_LINK_CXX_STDLIB); set(HAVE_CLANG_REPL_SUPPORT ON); endif(). option(CLANG_ENABLE_ARCMT ""Build ARCMT."" ON); option(CLANG_ENABLE_STATIC_ANALYZER; ""Include static analyzer in clang binary."" ON). option(CLANG_ENABLE_PROTO_FUZZER ""Build Clang protobuf fuzzer."" OFF). if(NOT CLANG_E",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt:14781,install,install-bash-autocomplete,14781,interpreter/llvm-project/clang/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt,1,['install'],['install-bash-autocomplete']
Deployability,"L_UTILS=ON \; -DCMAKE_INSTALL_PREFIX=/path/to/llvm/install/prefix \; < other options >. ninja -C $builddir install. Once llvm is installed, to configure a project for a stand-alone build, invoke CMake like this:. .. code-block:: console. cmake -G Ninja -S path/to/llvm-project/$subproj \; -B $buildir_subproj \; -DLLVM_EXTERNAL_LIT=/path/to/lit \; -DLLVM_ROOT=/path/to/llvm/install/prefix. Notice that:. * The stand-alone build needs to happen in a folder that is not the; original folder where LLVMN was built; (`$builddir!=$builddir_subproj`).; * ``LLVM_ROOT`` should point to the prefix of your llvm installation,; so for example, if llvm is installed into ``/usr/bin`` and; ``/usr/lib64``, then you should pass ``-DLLVM_ROOT=/usr/``.; * Both the ``LLVM_ROOT`` and ``LLVM_EXTERNAL_LIT`` options are; required to do stand-alone builds for all sub-projects. Additional; required options for each sub-project can be found in the table; below. The ``check-$subproj`` and ``install`` build targets are supported for the; sub-projects listed in the table below. ============ ======================== ======================; Sub-Project Required Sub-Directories Required CMake Options; ============ ======================== ======================; llvm llvm, cmake, third-party LLVM_INSTALL_UTILS=ON; clang clang, cmake CLANG_INCLUDE_TESTS=ON (Required for check-clang only); lld lld, cmake; ============ ======================== ======================. Example for building stand-alone `clang`:. .. code-block:: console. #!/bin/sh. build_llvm=`pwd`/build-llvm; build_clang=`pwd`/build-clang; installprefix=`pwd`/install; llvm=`pwd`/llvm-project; mkdir -p $build_llvm; mkdir -p $installprefix. cmake -G Ninja -S $llvm/llvm -B $build_llvm \; -DLLVM_INSTALL_UTILS=ON \; -DCMAKE_INSTALL_PREFIX=$installprefix \; -DCMAKE_BUILD_TYPE=Release. ninja -C $build_llvm install. cmake -G Ninja -S $llvm/clang -B $build_clang \; -DLLVM_EXTERNAL_LIT=$build_llvm/utils/lit \; -DLLVM_ROOT=$installprefix. ninja -C $build",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:6939,install,install,6939,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['install'],['install']
Deployability,"Limits< double >::Max()=2.22507e-308); T TMath::Limits< T >::Epsilon() returning the epsilon (see Wikipedia for its definition) for the type T ( T; TMath::Limits< double >::Epsilon()=2.22045e-16). TRandom1 and TRandom3. Add an implementation of UInt_t GetSeed() to return the first element of the seed table. Before always a fixed; value was returned, independently of the random generator state; . ROOT::Fit::Fitter and related classes. Add new version of the Fitter class with various improvements:; ; add the possibility to just evaluate the objective function (FCN) one time (Fitter::EvalFCN) and fill the; result (class ROOT::Fit::FitResult using the obtained value of FCN plus the parameter values and errors from; the Fit configuration class (ROOT::Fit::FitConfig).; This required adding a nw constructor of FitResult from FitConfig.; This originated from the Savannah request. ; Add also new methods Fitter::SetFCN.; Update the configuration (parameter values and errors) after a fit with the FitResult values; So next fit will use improved parameter values and errors. This update can be switched on/off; by using FitConfig::SetUpdateAfterFit(on/off). By default is on.; Add new method FitConfig::SetFromFitResult.; Add possibility to run Hesse (Fitter:::CalculateHessErrors) without having done the minimization. Add support for weighted likelihood fits. Add a new method Fitter::ApplyWeightCorrection(fcn2); which corrects covariance matrix for the weights using the likelihood function built using the weight square; Add the support for weights for the binned Poisson likelihood fits (in the; ROOT::Fit::PoissonLikelihoodFCN class). A new option (WL) has been added also in TH1::Fit; for performing weighted fits of histograms (see ).; . ROOT::Math::Minimizer; Add new methods Minimizer::GetHessianMatrix(double * mat) and Minimizer::GetCovMatrix(double * mat) to return the full; matrices by filling the passed C arrays, which must have a dimension of at least n x n, where n is the; tot",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v530/index.html:1597,configurat,configuration,1597,math/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v530/index.html,1,['configurat'],['configuration']
Deployability,"Low-level code; ==============. .. toctree::; :hidden:. C code and older C++ code sometimes makes use of low-level features such as; pointers to builtin types, some of which do not have any Python equivalent; (e.g. ``unsigned short*``).; Furthermore, such codes tend to be ambiguous: the information from header; file is not sufficient to determine the full purpose.; For example, an ``int*`` type may refer to the address of a single ``int``; (an out-parameter, say) or it may refer to an array of ``int``, the ownership; of which is not clear either.; cppyy provides a few low-level helpers and integration with the Python; `ctypes module`_ to cover these cases. Use of these low-level helpers will obviously lead to very ""C-like"" code and; it is recommended to :doc:`pythonize <pythonizations>` the code, perhaps; using the Cling JIT and embedded C++. Note: the low-level module is not loaded by default (since its use is, or; should be, uncommon).; It needs to be imported explicitly:. .. code-block:: python. >>> import cppyy.ll; >>>. `LowLevelView`; --------------. Python has an elaborate array interface (buffer) specification, but no; standard library array type that completely implements it; instead, the; canonical Python array type is the NumPy one.; cppyy introduces the basic ``LowLevelView`` array class to avoid having a; direct dependency on NumPy and to guarantee zero copy.; The ``LowLevelView`` type gives access to array details such as the size,; type, etc. and allows reading/writing of array elements, both for interactive; use and through the buffer interface to allow NumPy to interface with them.; For more complex operations, it's recommended to copy from the; ``LowLevelView`` inta a NumPy array, or to create a NumPy view (see below,; under :ref:`NumPy Casts <npcasts>`). `C/C++ casts`; -------------. C++ instances are auto-casted to the most derived available type, so do not; require explicit casts even when a function returns a pointer to a base; class or interface",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:597,integrat,integration,597,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,1,['integrat'],['integration']
Deployability,"M compiler; infrastructure. Cling implements the [read-eval-print loop; (REPL)](http://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop); concept, in order to leverage rapid application development. Implemented as a; small extension to LLVM and Clang, the interpreter reuses their strengths such; as the praised concise and expressive compiler diagnostics. See also [cling's web page.](https://rawcdn.githack.com/root-project/cling/d59d27ad61f2f3a78cd46e652cd9fb8adb893565/www/index.html). Please note that some of the resources are rather old and most of the stated; limitations are outdated.; * [talks](www/docs/talks); * http://blog.coldflake.com/posts/2012-08-09-On-the-fly-C++.html; * http://solarianprogrammer.com/2012/08/14/cling-cpp-11-interpreter/; * https://www.youtube.com/watch?v=f9Xfh8pv3Fs; * https://www.youtube.com/watch?v=BrjV1ZgYbbA; * https://www.youtube.com/watch?v=wZZdDhf2wDw; * https://www.youtube.com/watch?v=eoIuqLNvzFs. Installation; ------------; ### Release Notes; See our [release notes](docs/ReleaseNotes.md) to find what's new. ### Binaries; Our nightly binary snapshots are currently unavailable. ### Building from Source. ```bash; git clone https://github.com/root-project/llvm-project.git; cd llvm-project; git checkout cling-latest; cd ..; git clone https://github.com/root-project/cling.git; mkdir cling-build && cd cling-build; cmake -DLLVM_EXTERNAL_PROJECTS=cling -DLLVM_EXTERNAL_CLING_SOURCE_DIR=../cling/ -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_TARGETS_TO_BUILD=""host;NVPTX"" -DCMAKE_BUILD_TYPE=Release ../llvm-project/llvm; cmake --build . --target cling; ```. See also the instructions [on the webpage](https://root.cern/cling/cling_build_instructions/). Usage; -----; Assuming we're in the build folder:; ```bash; ./bin/cling '#include <stdio.h>' 'printf(""Hello World!\n"")'; ```. To get started run:; ```bash; ./bin/cling --help; ```; or; ```bash; ./bin/cling; [cling]$ .help; ```. Jupyter; -------; Cling comes with a [Jupyter](http://jupyter.org) k",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md:1292,release,release,1292,interpreter/cling/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md,1,['release'],['release']
Deployability,"M tools, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to *CMAKE_INSTALL_BINDIR*. **LLVM_UTILS_INSTALL_DIR**:STRING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of you",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39085,configurat,configuration,39085,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['configurat'],['configuration']
Deployability,"M) = 0;. The ``runOnLoop`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. ``LPPassManager`` interface; should be used to update loop nest. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnLoop; <writing-an-llvm-pass-runOnLoop>` for every loop in the program being compiled. .. _writing-an-llvm-pass-RegionPass:. The ``RegionPass`` class; ------------------------. ``RegionPass`` is similar to :ref:`LoopPass <writing-an-llvm-pass-LoopPass>`,; but executes on each single entry single exit region in the function.; ``RegionPass`` processes regions in nested order such that the outer most; region is processed last. ``RegionPass`` subclasses are allowed to update the region tree by using the; ``RGPassManager`` interface. You may override three virtual methods of; ``RegionPass`` to implement your own region pass. All these methods should; return ``true`` if they modified the program, or ``false`` if they did not. The ``doInitialization(Region *, RGPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Region *, RGPassManager &RGM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``RPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnRegion:. The ``runOnRegion`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnRegion(Region *, RGPassManager &R",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:23035,update,update,23035,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['update'],['update']
Deployability,"M+14.0.5+Release%22+no%3Aproject+. Replace 14.0.5 in this query with the version from the Release Milestone being; targeted. Add these bugs to the ""Release Status"" project. #. Navigate to the `Release Status project <https://github.com/orgs/llvm/projects/3>`_; to see the list of bugs that are being considered for the release. #. Review each bug and first check if it has been fixed in main. If it has, update; its status to ""Needs Pull Request"", and create a pull request for the fix; using the /cherry-pick or /branch comments if this has not been done already. #. If a bug has been fixed and has a pull request created for backporting it,; then update its status to ""Needs Review"" and notify a knowledgeable reviewer.; Usually you will want to notify the person who approved the patch in Phabricator,; but you may use your best judgement on who a good reviewer would be. Once; you have identified the reviewer(s), assign the issue to them and mention; them (i.e @username) in a comment and ask them if the patch is safe to backport.; You should also review the bug yourself to ensure that it meets the requirements; for committing to the release branch. #. Once a bug has been reviewed, add the release:reviewed label and update the; issue's status to ""Needs Merge"". Check the pull request associated with the; issue. If all the tests pass, then the pull request can be merged. If not,; then add a comment on the issue asking someone to take a look at the failures. #. Once the pull request has been merged push it to the official release branch; with the script ``llvm/utils/git/sync-release-repo.sh``. Then add a comment to the issue stating that the fix has been merged along with; the git hashes from the release branch. Add the release:merged label to the issue; and close it. Release Patch Rules; -------------------. Below are the rules regarding patching the release branch:. #. Patches applied to the release branch may only be applied by the release; manager, the official release teste",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:11668,patch,patch,11668,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['patch'],['patch']
Deployability,"M;; FPM.addPass(FunctionPass1());; FPM.addPass(FunctionPass2());. MPM.addPass(createModuleToFunctionPassAdaptor(std::move(FPM)));. will run ``FunctionPass1`` and ``FunctionPass2`` on the first function in a; module, then run both passes on the second function in the module, and so on.; This is better for cache locality around LLVM data structures. This similarly; applies for the other IR types, and in some cases can even affect the quality; of optimization. For example, running all loop passes on a loop may cause a; later loop to be able to be optimized more than if each loop pass were run; separately. Inserting Passes into Default Pipelines; =======================================. Rather than manually adding passes to a pass manager, the typical way of; creating a pass manager is to use a ``PassBuilder`` and call something like; ``PassBuilder::buildPerModuleDefaultPipeline()`` which creates a typical; pipeline for a given optimization level. Sometimes either frontends or backends will want to inject passes into the; pipeline. For example, frontends may want to add instrumentation, and target; backends may want to add passes that lower custom intrinsics. For these; cases, ``PassBuilder`` exposes callbacks that allow injecting passes into; certain parts of the pipeline. For example,. .. code-block:: c++. PassBuilder PB;; PB.registerPipelineStartEPCallback([&](ModulePassManager &MPM,; PassBuilder::OptimizationLevel Level) {; MPM.addPass(FooPass());; };. will add ``FooPass`` near the very beginning of the pipeline for pass; managers created by that ``PassBuilder``. See the documentation for; ``PassBuilder`` for the various places that passes can be added. If a ``PassBuilder`` has a corresponding ``TargetMachine`` for a backend, it; will call ``TargetMachine::registerPassBuilderCallbacks()`` to allow the; backend to inject passes into the pipeline. Clang's ``BackendUtil.cpp`` shows examples of a frontend adding (mostly; sanitizer) passes to various parts of the pipelin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst:5368,pipeline,pipeline,5368,interpreter/llvm-project/llvm/docs/NewPassManager.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst,1,['pipeline'],['pipeline']
Deployability,"MAKEDIR}/modules""); endif(). #---Add configuration files for kernel and jupyter----------------------------------------------; # Make sure the Jupyter ROOT C++ kernel runs with the same Python version as ROOT; set(root_jupyter_dir notebook); set(root_jupyter_config jupyter_notebook_config.py); configure_file(etc/${root_jupyter_dir}/${root_jupyter_config}.in etc/${root_jupyter_dir}/${root_jupyter_config}); install(FILES ${CMAKE_BINARY_DIR}/etc/${root_jupyter_dir}/${root_jupyter_config} DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}/${root_jupyter_dir}). set(root_kernel_dir ${root_jupyter_dir}/kernels/root); set(root_kernel_file kernel.json); configure_file(etc/${root_kernel_dir}/${root_kernel_file}.in etc/${root_kernel_dir}/${root_kernel_file}); install(FILES ${CMAKE_BINARY_DIR}/etc/${root_kernel_dir}/${root_kernel_file} DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}/${root_kernel_dir}). #---install clad header files-------------------------------------------------------------------; if(clad); install(DIRECTORY ${CMAKE_BINARY_DIR}/etc/cling/plugins/; DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}/cling/plugins); endif(). #---Set flag for PyROOT tests that are expected to fail; if(pyroot); set(PYTESTS_WILLFAIL WILLFAIL); endif(). #---Configure Testing using CTest----------------------------------------------------------------; configure_file(${CMAKE_SOURCE_DIR}/cmake/modules/CTestCustom.cmake ${CMAKE_BINARY_DIR} COPYONLY); if(testing); include(RootCTest); set(upstreamprefix https://github.com/root-project). if(roottest); find_package(Git REQUIRED). # Check whether the repository exists in the source directory or its parent; get_filename_component(source_dir ${CMAKE_CURRENT_SOURCE_DIR} REALPATH); if(IS_DIRECTORY ${source_dir}/roottest/.git); set(repo_dir ${source_dir}/roottest); elseif(IS_DIRECTORY ${source_dir}/../roottest/.git); set(repo_dir ${source_dir}/../roottest); endif(); if(DEFINED repo_dir); execute_process(COMMAND ${GIT_EXECUTABLE} --git-dir=${repo_dir}/.git; remote get-url origi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt:27451,install,install,27451,CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt,2,['install'],['install']
Deployability,"ME_DIR=${LLVM_ENABLE_PER_TARGET_RUNTIME_DIR}; -DCMAKE_C_COMPILER_WORKS=ON; -DCMAKE_CXX_COMPILER_WORKS=ON; -DCMAKE_ASM_COMPILER_WORKS=ON; -DCOMPILER_RT_DEFAULT_TARGET_ONLY=ON; -DLLVM_RUNTIMES_TARGET=${name}; ${COMMON_CMAKE_ARGS}; ${${name}_extra_args}; EXTRA_TARGETS ${${name}_extra_targets}; ${${name}_test_targets}; USE_TOOLCHAIN; ${EXTRA_ARGS} ${ARG_EXTRA_ARGS}). add_dependencies(runtimes runtimes-${name}); add_dependencies(runtimes-configure runtimes-${name}-configure); add_dependencies(install-runtimes install-runtimes-${name}); add_dependencies(install-runtimes-stripped install-runtimes-${name}-stripped); if(LLVM_INCLUDE_TESTS); add_dependencies(check-runtimes check-runtimes-${name}); add_dependencies(runtimes-test-depends runtimes-test-depends-${name}); endif(); foreach(runtime_name ${runtime_names}); if(NOT TARGET ${runtime_name}); add_custom_target(${runtime_name}); endif(); add_dependencies(${runtime_name} ${runtime_name}-${name}); if(NOT TARGET install-${runtime_name}); add_custom_target(install-${runtime_name}); endif(); add_dependencies(install-${runtime_name} install-${runtime_name}-${name}); if(NOT TARGET install-${runtime_name}-stripped); add_custom_target(install-${runtime_name}-stripped); endif(); add_dependencies(install-${runtime_name}-stripped install-${runtime_name}-${name}-stripped); endforeach(); foreach(component ${LLVM_RUNTIME_DISTRIBUTION_COMPONENTS}); add_dependencies(${component} ${component}-${name}); add_dependencies(install-${component} install-${component}-${name}); add_dependencies(install-${component}-stripped install-${component}-${name}-stripped); endforeach(); endfunction(). if(runtimes); # Create a runtimes target that uses this file as its top-level CMake file.; # The runtimes target is a configuration of all the runtime libraries; # together in a single CMake invocation.; set(extra_deps """"); if(""openmp"" IN_LIST LLVM_ENABLE_RUNTIMES); foreach(dep opt llvm-link llvm-extract clang clang-offload-packager); if(TARGET ${dep} AND OPENMP",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/runtimes/CMakeLists.txt:14041,install,install-runtimes,14041,interpreter/llvm-project/llvm/runtimes/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/runtimes/CMakeLists.txt,16,['install'],"['install', 'install-runtimes', 'install-runtimes-stripped']"
Deployability,MPONENT aarch64-resource-headers). install(; FILES ${cuda_wrapper_files}; DESTINATION ${header_install_dir}/cuda_wrappers; EXCLUDE_FROM_ALL; COMPONENT cuda-resource-headers). install(; FILES ${cuda_wrapper_bits_files}; DESTINATION ${header_install_dir}/cuda_wrappers/bits; EXCLUDE_FROM_ALL; COMPONENT cuda-resource-headers). install(; FILES ${cuda_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT cuda-resource-headers). install(; FILES ${hexagon_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT hexagon-resource-headers). install(; FILES ${hip_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT hip-resource-headers). install(; FILES ${loongarch_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT loongarch-resource-headers). install(; FILES ${mips_msa_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT mips-resource-headers). install(; FILES ${ppc_wrapper_files}; DESTINATION ${header_install_dir}/ppc_wrappers; EXCLUDE_FROM_ALL; COMPONENT ppc-resource-headers). install(; FILES ${ppc_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT ppc-resource-headers). install(; FILES ${ppc_htm_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT ppc-htm-resource-headers). install(; FILES ${riscv_generated_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT riscv-resource-headers). install(; FILES ${riscv_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT riscv-resource-headers). install(; FILES ${systemz_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT systemz-resource-headers). install(; FILES ${ve_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT ve-resource-headers). install(; FILES ${webassembly_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT webassembly-resource-headers). install(; FILES ${x86_files}; DESTINATION ${header_install_dir}; EXCLUD,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt:14441,install,install,14441,interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,1,['install'],['install']
Deployability,"M_LINK_LLVM_DYLIB ${ARG_UNPARSED_ARGUMENTS} ${srcs}). if (MSVC AND cling_ex_file_match); # /EHs because cling_runtime_internal_throwIfInvalidPointer is extern “C”; if (cling_ex_file_match); foreach(file_var ${ARGN}); if (file_var MATCHES ${cling_ex_file_match}); set_property(SOURCE ${file_var} APPEND_STRING PROPERTY COMPILE_FLAGS; "" /D _HAS_EXCEPTIONS=1 /EHs /GR /wd4714 ""); elseif (file_var MATCHES "".cpp$""); set_property(SOURCE ${file_var} APPEND_STRING PROPERTY COMPILE_FLAGS; "" /D _HAS_EXCEPTIONS=0 /EHs-c- /GR- ""); endif(); endforeach(); endif(); endif(). if(TARGET ${name}); target_link_libraries(${name} INTERFACE ${LLVM_COMMON_LIBS}). if (NOT LLVM_INSTALL_TOOLCHAIN_ONLY OR ${name} STREQUAL ""libcling""); install(TARGETS ${name}; COMPONENT ${name}; EXPORT ClingTargets; LIBRARY DESTINATION lib${LLVM_LIBDIR_SUFFIX}; ARCHIVE DESTINATION lib${LLVM_LIBDIR_SUFFIX}; RUNTIME DESTINATION bin). if (${ARG_SHARED} AND NOT CMAKE_CONFIGURATION_TYPES); add_custom_target(install-${name}; DEPENDS ${name}; COMMAND ""${CMAKE_COMMAND}""; -DCMAKE_INSTALL_COMPONENT=${name}; -P ""${CMAKE_BINARY_DIR}/cmake_install.cmake""); endif(); endif(); set_property(GLOBAL APPEND PROPERTY CLING_EXPORTS ${name}); else(); # Add empty ""phony"" target; add_custom_target(${name}); endif(). set_target_properties(${name} PROPERTIES FOLDER ""Cling libraries""); set_cling_windows_version_resource_properties(${name}); endmacro(add_cling_library). macro(add_cling_executable name); add_llvm_executable( ${name} ${ARGN} ); set_target_properties(${name} PROPERTIES FOLDER ""Cling executables""); set_cling_windows_version_resource_properties(${name}); endmacro(add_cling_executable). set(CMAKE_INCLUDE_CURRENT_DIR ON). include_directories(BEFORE; ${CMAKE_CURRENT_BINARY_DIR}/include; ${CMAKE_CURRENT_SOURCE_DIR}/include; ). if (NOT LLVM_INSTALL_TOOLCHAIN_ONLY); install(DIRECTORY include/cling include/cling-c; DESTINATION include; FILES_MATCHING; PATTERN ""*.def""; PATTERN ""*.h""; PATTERN ""config.h"" EXCLUDE; PATTERN "".svn"" EXCLUDE; ). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/CMakeLists.txt:14493,install,install,14493,interpreter/cling/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/CMakeLists.txt,1,['install'],['install']
Deployability,"MnMigrad migrad(theFCN, upar);. // minimize; FunctionMinimum min = migrad();. // output; std::cout<<""minimum: ""<<min<<std::endl;; }. {; // demonstrate full interaction with parameters over subsequent; // minimizations. // create Minuit parameters with names; MnUserParameters upar;; upar.add(""mean"", mean, 0.1);; upar.add(""sigma"", rms, 0.1);; upar.add(""area"", area, 0.1);. // access parameter by name to set limits...; upar.setLimits(""mean"", mean-0.01, mean+0.01);. // ... or access parameter by index; upar.setLimits(1, rms-0.1, rms+0.1);. // create Migrad minimizer; MnMigrad migrad(theFCN, upar);. // fix a parameter...; migrad.fix(""mean"");. // ... and minimize; FunctionMinimum min = migrad();. // output; std::cout<<""minimum: ""<<min<<std::endl;. // release a parameter...; migrad.release(""mean"");. // ... and fix another one; migrad.fix(1);. // and minimize again; FunctionMinimum min1 = migrad();. // output; std::cout<<""minimum1: ""<<min1<<std::endl;. // release the parameter...; migrad.release(1);. // ... and minimize with all three parameters; // (still with limits!); FunctionMinimum min2 = migrad();. // output; std::cout<<""minimum2: ""<<min2<<std::endl;. // remove all limits on parameters...; migrad.removeLimits(""mean"");; migrad.removeLimits(""sigma"");. // ... and minimize again with all three parameters; // (now without limits!); FunctionMinimum min3 = migrad();. // output; std::cout<<""minimum3: ""<<min3<<std::endl;; }. {; // demonstrate MINOS error analysis. // create Minuit parameters with names; MnUserParameters upar;; upar.add(""mean"", mean, 0.1);; upar.add(""sigma"", rms, 0.1);; upar.add(""area"", area, 0.1);. // create Migrad minimizer; MnMigrad migrad(theFCN, upar);. // minimize; FunctionMinimum min = migrad();. // create MINOS error factory; MnMinos minos(theFCN, min);. {; // 1-sigma MINOS errors; std::pair<double,double> e0 = minos(0);; std::pair<double,double> e1 = minos(1);; std::pair<double,double> e2 = minos(2);. // output; std::cout<<""1-sigma minos errors: ""<<std:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:80657,release,release,80657,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['release'],['release']
Deployability,"Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - global 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; sc1=1; 4. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. atomicrmw acq_rel - agent - generic 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:321682,release,released,321682,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['released']
Deployability,N ${header_install_dir}; COMPONENT clang-resource-headers). install(; FILES ${cuda_wrapper_files}; DESTINATION ${header_install_dir}/cuda_wrappers; COMPONENT clang-resource-headers). install(; FILES ${cuda_wrapper_bits_files}; DESTINATION ${header_install_dir}/cuda_wrappers/bits; COMPONENT clang-resource-headers). install(; FILES ${ppc_wrapper_files}; DESTINATION ${header_install_dir}/ppc_wrappers; COMPONENT clang-resource-headers). install(; FILES ${llvm_libc_wrapper_files}; DESTINATION ${header_install_dir}/llvm_libc_wrappers; COMPONENT clang-resource-headers). install(; FILES ${openmp_wrapper_files}; DESTINATION ${header_install_dir}/openmp_wrappers; COMPONENT clang-resource-headers). #############################################################; # Install rules for separate header lists; install(; FILES ${core_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT core-resource-headers). install(; FILES ${arm_common_files} ${arm_common_generated_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT arm-common-resource-headers). install(; FILES ${arm_only_files} ${arm_only_generated_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT arm-resource-headers). install(; FILES ${aarch64_only_files} ${aarch64_only_generated_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT aarch64-resource-headers). install(; FILES ${cuda_wrapper_files}; DESTINATION ${header_install_dir}/cuda_wrappers; EXCLUDE_FROM_ALL; COMPONENT cuda-resource-headers). install(; FILES ${cuda_wrapper_bits_files}; DESTINATION ${header_install_dir}/cuda_wrappers/bits; EXCLUDE_FROM_ALL; COMPONENT cuda-resource-headers). install(; FILES ${cuda_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT cuda-resource-headers). install(; FILES ${hexagon_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM_ALL; COMPONENT hexagon-resource-headers). install(; FILES ${hip_files}; DESTINATION ${header_install_dir}; EXCLUDE_FROM,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt:13073,install,install,13073,interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,1,['install'],['install']
Deployability,"N/SFT,\; Harshal Shende, GSOC,\; Matevz Tadel, UCSD/CMS,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/ATLAS,\; Zef Wolffs, NIKHEF/ATLAS,\; Stefan Wunsch, CERN/SFT. ## Deprecation, Removal, Backward Incompatibilities. - The ""Virtual MonteCarlo"" facility VMC (`montecarlo/vmc`) has been removed from ROOT. The development of this package has moved to a [separate project](https://github.com/vmc-project/). ROOT's copy of VMC was deprecated since v6.18.; - `TTreeProcessorMT::SetMaxTasksPerFilePerWorker` has been removed. `TTreeProcessorMT::SetTasksPerWorkerHint` is a superior alternative.; - `TTree::GetEntry()` and `TTree::GetEvent()` no longer have 0 as the default value for the first parameter `entry`. We are not aware of correct uses of this function without providing an entry number. If you have one, please simply pass `0` from now on.; - `TBufferMerger` is now out of the `Experimental` namespace (`ROOT::Experimental::TBufferMerger` is deprecated, please use `ROOT::TBufferMerger` instead); - RooFit container classes marked as deprecated with this release: `RooHashTable`, `RooNameSet`, `RooSetPair`, and `RooList`. These classes are still available in this release, but will be removed in the next one. Please migrate to STL container classes, such as `std::unordered_map`, `std::set`, and `std::vector`.; - The `RooFit::FitOptions(const char*)` command to steer [RooAbsPdf::fitTo()](https://root.cern.ch/doc/v628/classRooAbsPdf.html) with an option string in now deprecated and will be removed in ROOT v6.28. Please migrate to the RooCmdArg-based fit configuration. The former character flags map to RooFit command arguments as follows:; - `'h'` : RooFit::Hesse(); - `'m'` : RooFit::Minos(); - `'o'` : RooFit::Optimize(1); - `'r'` : RooFit::Save(); - `'t'` : RooFit::Timer(); - `'v'` : RooFit::Verbose(); - `'0'` : RooFit::Strategy(0); Subsequently, the `RooMinimizer::fit(const char*)` function and the [RooMCStudy](https://root.cern.ch/doc/v626/classRooMCStudy.html) con",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:2547,release,release,2547,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['release'],['release']
Deployability,"N=OFF; -DENABLE_CEPH=OFF; -DXRDCL_LIB_ONLY=ON; -DCMAKE_INSTALL_RPATH:STRING=${XROOTD_PREFIX}/lib; -DOPENSSL_ROOT_DIR=${OPENSSL_ROOT_DIR}; INSTALL_COMMAND ${CMAKE_COMMAND} --build . --target install; LOG_DOWNLOAD 1 LOG_CONFIGURE 1 LOG_BUILD 1 LOG_INSTALL 1 LOG_OUTPUT_ON_FAILURE 1; BUILD_BYPRODUCTS ${XROOTD_CLIENT_LIBRARIES} ${XROOTD_UTILS_LIBRARIES}; TIMEOUT 600; ). # CMake checks for existence when a target is linked to XRootD; file(MAKE_DIRECTORY ${XROOTD_PREFIX}/include/xrootd). if(builtin_openssl); add_dependencies(BUILTIN_XROOTD OPENSSL); endif(). list(APPEND XROOTD_CLIENT_LIBRARIES OpenSSL::SSL); list(REMOVE_DUPLICATES XROOTD_CLIENT_LIBRARIES); list(APPEND XROOTD_UTILS_LIBRARIES OpenSSL::SSL); list(REMOVE_DUPLICATES XROOTD_UTILS_LIBRARIES). set(XROOTD_INCLUDE_DIRS ${XROOTD_PREFIX}/include/xrootd CACHE INTERNAL """" FORCE); set(XROOTD_CLIENT_LIBRARIES ${XROOTD_CLIENT_LIBRARIES} CACHE INTERNAL """" FORCE); set(XROOTD_UTILS_LIBRARIES ${XROOTD_UTILS_LIBRARIES} CACHE INTERNAL """" FORCE). list(APPEND CMAKE_BUILD_RPATH ${XROOTD_PREFIX}/lib); add_dependencies(XRootD BUILTIN_XROOTD). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS BUILTIN_XROOTD). install(DIRECTORY ${XROOTD_PREFIX}/lib/ DESTINATION ${CMAKE_INSTALL_LIBDIR} COMPONENT libraries FILES_MATCHING PATTERN ""libXrd*""); install(DIRECTORY ${XROOTD_PREFIX}/include/xrootd/ DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}/xrootd COMPONENT headers); if(APPLE); # XRootD libraries on mac need the LC_RPATH variable set. The build process already takes care of setting; # * BUILD_RPATH = build/XROOTD-prefix/../src; # * INSTALL_RPATH = build/lib; # Since the install directory for the builtin_xrootd target corresponds to the build directory of the main project.; # Use a post install script to change the LC_RPATH variable of the libraries in the ROOT install folder.; install(SCRIPT ${CMAKE_CURRENT_LIST_DIR}/XROOTDApplePostInstall.cmake; CODE ""xrootd_libs_change_rpath(${XROOTD_PREFIX}/lib ${CMAKE_INSTALL_FULL_LIBDIR})""; ); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/builtins/xrootd/CMakeLists.txt:2742,install,install,2742,builtins/xrootd/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/builtins/xrootd/CMakeLists.txt,6,['install'],['install']
Deployability,"NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}). # Now build our tools; add_executable(simple-tool tool.cpp). # Find the libraries that correspond to the LLVM components; # that we wish to use; llvm_map_components_to_libnames(llvm_libs support core irreader). # Link against LLVM libraries; target_link_libraries(simple-tool ${llvm_libs}). The ``find_package(...)`` directive when used in CONFIG mode (as in the above; example) will look for the ``LLVMConfig.cmake`` file in various locations (see; cmake manual for details). It creates a ``LLVM_DIR`` cache entry to save the; directory where ``LLVMConfig.cmake`` is found or allows the user to specify the; directory (e.g. by passing ``-DLLVM_DIR=/usr/lib/cmake/llvm`` to; the ``cmake`` command or by setting it directly in ``ccmake`` or ``cmake-gui``). This file is available in two different locations. * ``<LLVM_INSTALL_PACKAGE_DIR>/LLVMConfig.cmake`` where; ``<LLVM_INSTALL_PACKAGE_DIR>`` is the location where LLVM CMake modules are; installed as part of an installed version of LLVM. This is typically; ``cmake/llvm/`` within the lib directory. On Linux, this is typically; ``/usr/lib/cmake/llvm/LLVMConfig.cmake``. * ``<LLVM_BUILD_ROOT>/lib/cmake/llvm/LLVMConfig.cmake`` where; ``<LLVM_BUILD_ROOT>`` is the root of the LLVM build tree. **Note: this is only; available when building LLVM with CMake.**. If LLVM is installed in your operating system's normal installation prefix (e.g.; on Linux this is usually ``/usr/``) ``find_package(LLVM ...)`` will; automatically find LLVM if it is installed correctly. If LLVM is not installed; or you wish to build directly against the LLVM build tree you can use; ``LLVM_DIR`` as previously mentioned. The ``LLVMConfig.cmake`` file sets various useful variables. Notable variables; include. ``LLVM_CMAKE_DIR``; The path to the LLVM CMake directory (i.e. the directory containing; LLVMConfig.cmake). ``LLVM_DEFINITIONS``; A list of preprocessor defines that should be used",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:42741,install,installed,42741,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,2,['install'],['installed']
Deployability,"NG_EXPORTS GLOBAL PROPERTY CLING_EXPORTS); export(TARGETS ${CLING_EXPORTS} FILE ${cling_cmake_builddir}/ClingTargets.cmake). # Generate ClingConfig.cmake for the build tree.; set(CLING_CONFIG_CMAKE_DIR ""${cling_cmake_builddir}""); set(CLING_CONFIG_CLANG_CMAKE_DIR ""${clang_cmake_builddir}""); set(CLING_CONFIG_EXPORTS_FILE ""${cling_cmake_builddir}/ClingTargets.cmake""); set(CLING_CONFIG_INCLUDE_DIRS; ""${CLING_SOURCE_DIR}/include""; ""${CLING_BINARY_DIR}/include""; ); configure_file(; ${CMAKE_CURRENT_SOURCE_DIR}/ClingConfig.cmake.in; ${cling_cmake_builddir}/ClingConfig.cmake; @ONLY); set(CLING_CONFIG_CMAKE_DIR); set(CLING_CONFIG_LLVM_CMAKE_DIR); set(CLING_CONFIG_EXPORTS_FILE). # Generate ClingConfig.cmake for the install tree.; set(CLING_CONFIG_CODE ""; # Compute the installation prefix from this LLVMConfig.cmake file location.; get_filename_component(CLING_INSTALL_PREFIX \""\${CMAKE_CURRENT_LIST_FILE}\"" PATH)""); # Construct the proper number of get_filename_component(... PATH); # calls to compute the installation prefix.; string(REGEX REPLACE ""/"" "";"" _count ""${CLING_INSTALL_PACKAGE_DIR}""); foreach(p ${_count}); set(CLING_CONFIG_CODE ""${CLING_CONFIG_CODE}; get_filename_component(CLING_INSTALL_PREFIX \""\${CLING_INSTALL_PREFIX}\"" PATH)""); endforeach(p); set(CLING_CONFIG_CMAKE_DIR ""\${CLING_INSTALL_PREFIX}/${CLING_INSTALL_PACKAGE_DIR}""); set(CLING_CONFIG_LLVM_CMAKE_DIR ""\${CLING_INSTALL_PREFIX}/${LLVM_INSTALL_PACKAGE_DIR}""); set(CLING_CONFIG_EXPORTS_FILE ""\${CLING_CMAKE_DIR}/ClingTargets.cmake""); set(CLING_CONFIG_INCLUDE_DIRS; ""\${CLING_INSTALL_PREFIX}/include""; ); configure_file(; ${CMAKE_CURRENT_SOURCE_DIR}/ClingConfig.cmake.in; ${CMAKE_CURRENT_BINARY_DIR}/CMakeFiles/ClingConfig.cmake; @ONLY); set(CLING_CONFIG_CODE); set(CLING_CONFIG_CMAKE_DIR); set(CLING_CONFIG_EXPORTS_FILE). if (NOT LLVM_INSTALL_TOOLCHAIN_ONLY); install(EXPORT ClingTargets DESTINATION ${CLING_INSTALL_PACKAGE_DIR}; COMPONENT cling-cmake-exports). install(FILES; ${CMAKE_CURRENT_BINARY_DIR}/CMakeFiles/ClingConfig",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/cmake/modules/CMakeLists.txt:1589,install,installation,1589,interpreter/cling/cmake/modules/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/cmake/modules/CMakeLists.txt,1,['install'],['installation']
Deployability,"NKER**:STRING; Override the system's default linker. For instance use ``lld`` with; ``-DLLVM_USE_LINKER=lld``. Rarely-used CMake variables; ---------------------------. Here are some of the CMake variables that are rarely used, along with a brief; explanation and LLVM-related notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_INCLUDEDIR**:PATH; The path to install header files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""include"". **CMAKE_INSTALL_DOCDIR**:PATH; The path to install documentation, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/doc"". **CMAKE_INSTALL_MANDIR**:PATH; The path to install manpage files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/man"". .. _LLVM-related variables:. LLVM-related variables; -----------------------. These variables provide fine control over the build of LLVM and; enabled sub-projects. Nearly all of these variable names begin with; ``LLVM_``. **BUILD_SHARED_LIBS**:BOOL; Flag indicating if each LLVM component (e.g. Support) is built as a shared; library (ON) or as a static library (OFF). Its default value is OFF. On; Windows, shared libraries may be used when building with MinGW, including; mingw-w64, but not when building with the Microsoft toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared library, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be built with ABI breaking checks or; not. Allowed values are `WITH_ASSERTS` (default), `FORCE_ON` and; `FORCE_OFF`. `WITH_ASSERTS` turns",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:11186,install,install,11186,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['install'],['install']
Deployability,"Needs Merge"". Check the pull request associated with the; issue. If all the tests pass, then the pull request can be merged. If not,; then add a comment on the issue asking someone to take a look at the failures. #. Once the pull request has been merged push it to the official release branch; with the script ``llvm/utils/git/sync-release-repo.sh``. Then add a comment to the issue stating that the fix has been merged along with; the git hashes from the release branch. Add the release:merged label to the issue; and close it. Release Patch Rules; -------------------. Below are the rules regarding patching the release branch:. #. Patches applied to the release branch may only be applied by the release; manager, the official release testers or the code owners with approval from; the release manager. #. Release managers are encouraged, but not required, to get approval from code; owners before approving patches. If there is no code owner or the code owner; is unreachable then release managers can ask approval from patch reviewers or; other developers active in that area. #. *Before RC1* Patches should be limited to bug fixes, important optimization; improvements, or completion of features that were started before the branch; was created. As with all phases, release managers and code owners can reject; patches that are deemed too invasive. #. *Before RC2* Patches should be limited to bug fixes or backend specific; improvements that are determined to be very safe. #. *Before RC3/Final Major Release* Patches should be limited to critical; bugs or regressions. #. *Bug fix releases* Patches should be limited to bug fixes or very safe; and critical performance improvements. Patches must maintain both API and; ABI compatibility with the previous major release. Release Final Tasks; -------------------. The final stages of the release process involves tagging the ""final"" release; branch, updating documentation that refers to the release, and updating the; demo page. Update Documen",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:12900,release,release,12900,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,2,"['patch', 'release']","['patch', 'release']"
Deployability,"Negative values were not painted with option ""TEXT"" for TH2Poly. ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ### Jupyter Notebook Integration; - When starting Jupyter server with `root --notebook arg1 arg2 ...`, extra arguments can be provided.; All these arguments delivered as is to jupyter executable and can be used for configuration.; Like server binding to specific host `root --notebook --ip=hostname`; - Remove `c.NotebookApp.ip = '*'` from default jupyter config. One has to provide ip address for server; binding using `root --notebook --ip=<hostaddr>` arguments; - Now Jupyter Notebooks will use JSROOT provided with ROOT installation. This allows to use notebooks; without internet connection (offline). ## JavaScript ROOT; - Provide monitoring capabilities for TGeoManager object. Now geomtry with some tracks can be displayed and; updated in web browser, using THttpServer monitoring capability like histogram objects. ## Tutorials; - Add the ""Legacy"" category collecting the old tutorials which do not represent any more best practices. ## Class Reference Guide; - Images in tutorials can now be displayed à JavaScript thanks to the (js) option; added next to the directive `\macro_image`; - As the tutorial `palettes.C` is often hit when searching the keyword `palette`; in the reference guide, a direct link from this example to the full list of; predefined palettes given in `TColor` has been added.; - Revisited the TSpectrum2 documentation. All the static images have been replaced; by macros generating images at reference guide build time. These macros have; been added in the tutorial section of the reference guide.; - The Reference Guide can now be accessed directly from the ROOT prompt thanks to; a great extension (implemented by Desislava Kalaydjieva) of the `.help` command.; For example to access the Reference Guide for `TTree` it ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md:6634,update,updated,6634,README/ReleaseNotes/v620/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md,1,['update'],['updated']
Deployability,"New TLazyDS tutorial added tdf015_LazyDataSource.C.; - Show how to inspect a `TCutFlowReport` object. ## Class Reference Guide. - Replace low resolution images with bigger ones more suited for modern screens. ## Build System and Configuration. - ROOT can now be built against an externally built llvm and clang (llvm can be used unpatched, clang still require ROOT specific patches). The options are builtin_llvm and builtin_clang both defaulting to ON.; - Update RConfigure.h with R__HAS__VDT if the package is found/builtin; - CMake exported targets now have the `INTERFACE_INCLUDE_DIRECTORIES` property set ([ROOT-8062](https://sft.its.cern.ch/jira/browse/ROOT-8062)).; - The `-fPIC` compile flag is no longer propagated to dependent projects via `CMAKE_CXX_FLAGS` ([ROOT-9212](https://sft.its.cern.ch/jira/browse/ROOT-9212)).; - Several builtins have updated versions:; - OpenSSL was updated from 1.0.2d to 1.0.2.o (latest lts release, [ROOT-9359](https://sft.its.cern.ch/jira/browse/ROOT-9359)); - Davix was updated from 0.6.4 to 0.6.7 (support for OpenSSL 1.1, [ROOT-9353](https://sft.its.cern.ch/jira/browse/ROOT-9353)); - Vdt has been updated from 0.3.9 to 0.4.1 (includes new atan function); - XRootd has been updated from 4.6.1 to 4.8.2 (for GCC 8.x support); - Builtin TBB can now be used on Windows; - xxHash and LZ4 have been separated so that a system version of LZ4 can be used even if it does not include xxHash headers ([ROOT-9099](https://sft.its.cern.ch/jira/browse/ROOT-9099)); - In addition, several updates have been made to fix minor build system issues, such as not checking for external packages if their builtin is turned off, or checking for packages even when the respective option is disabled ([ROOT-8806](https://sft.its.cern.ch/jira/browse/ROOT-8806), [ROOT-9190](https://sft.its.cern.ch/jira/browse/ROOT-9190), [ROOT-9315](https://sft.its.cern.ch/jira/browse/ROOT-9315), [ROOT-9385](https://sft.its.cern.ch/jira/browse/ROOT-9385)).; - The `python3` option to CMake has ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:18425,update,updated,18425,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,1,['update'],['updated']
Deployability,"Node(x,y,z); ```. Note that the current particle position can be set using; **`SetCurrentPosition(x,y,z)`** method of the manager class, in which; case **`FindNode()`** can be called without arguments. The method; returns a pointer to the *deepest node* that geometrically contains *P*; (in our case let us suppose it is *B\_3*). Since a node is just a; positioned volume, we can then get a pointer to the volume, medium or; material objects related to it. *Deepest* means that *B\_3* still; contains point *P* (as well as *A\_1* and *TOP\_1*), but none of the; daughters of volume **B** does. After finding out the node containing; the particle, one can check if the geometry state is different compared; to the last located point:. ``` {.cpp}; Bool_t *TGeoManager::IsSameLocation(); ```. The algorithm for finding where a point is located in geometry is; presented in the figure 17-36. It always starts by checking if the last computed modeller state is the; answer. This optimizes the search when continuously tracking a particle.; The main actions performed are:. - moving up and down in the logical node tree while updating the; current node and its global matrix; - converting the global position into the local frame of the current; node/volume; - checking whether the local position lies within the geometrical; shape of the current volume - if this is the case continue the; search downwards for the daughters of the current node, otherwise; search upwards its containers until the top level is reached.; - the number of candidate nodes to be checked at a given level is; minimized by an additional optimization structure: voxels. This is; effective even in case there is only one daughter of the current; volume.; - in case the current node is declared as possibly overlapping, the; method FindInCluster() is invoked. This method checks all different; possibilities within the cluster of overlapping candidates. One of; the candidates is prioritized if one of the following conditions id; fu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:157141,continuous,continuously,157141,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['continuous'],['continuously']
Deployability,"OF cluster. CernVM uses; contextualization to specialize each virtual machine to be either a head; node or a worker node. The Virtual Analysis Facility comes with many preconfigured things:. - a HTCondor cluster capable of running PROOF on Demand. - certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *A",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:1446,release,releases,1446,proof/doc/confman/DeployVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md,1,['release'],['releases']
Deployability,"OL_DIR**:STRING; Full path to a directory containing executables for the build host; (containing binaries such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RAM_PER_COMPILE_JOB**:STRING; Calculates the amount of Ninja compile jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_COMPILE_JOBS. Compile jobs ; will be between one and amount of logical cores. **LLVM_RAM_PER_LINK_JOB**:STRING; Calculates the amount of Ninja link jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_LINK_JOBS. Link jobs will ; be between one and amount of logical cores. Link jobs will not run ; exclusively therefore you should add an offset of one or two compile jobs ; to be sure its not terminated in your memory restricted environment. On ELF; platforms also consider ``LLVM_USE_SPLIT_DWARF`` in Debug build. **LLVM_PROFDATA_FILE**:PATH; Path to a pro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:32379,configurat,configurations,32379,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['configurat'],['configurations']
Deployability,"OOT compilation they can be found in; `$ROOTSYS/js/` and `$ROOTSYS/ui5/` subfolders respectively. ## Tutorials; - Add `RSqliteDS` examples.; - Make RCsvDS and RLazyDS tutorials standalone, i.e. downloading input csv directly using `TFile::Cp` rather than relying on CMake. ## Class Reference Guide. ## Build, Configuration and Testing Infrastructure. ### CMake build system requirements and updates. The minimum required version of CMake has been updated to 3.9 or newer to be; able to take advantage of new features such as native support for the CUDA; language, among other things. Please refer to CMake's release notes for further; information. The method to select the C++ standard has changed. Now the recommended way; to select the C++ standard is via the option `-DCMAKE_CXX_STANDARD=XX`, which; is the idiomatic way to do it in CMake. The old options still work, but have; been deprecated and will be removed in a future release. Build option descriptions have been updated to indicate which builtins require; an active network connection during the build. You can inspect the list of; options and their descriptions by running `cmake -LH $PWD` in the build; directory. The build system has been updated to remove most file globbing to improve; the reliability of incremental builds when source files are added or removed. A new check has been added to make ROOT fail during the configuration step; if incompatible versions of the Python interpreter and its libraries are; selected. The `all=ON` option now tries to enable more options. Some options had their; default value toggled to disabled, which affected `all=ON`. Now all options; are listed explicitly so that they are enabled regardless of their default; value. ### Builtins. The following builtins had their versions updated for this release:. * VecCore 0.5.2; * Vc 1.4.1; * XRootD 4.8.5; * OpenSSL 1.0.2q; * PCRE 8.42. ### Header location and `ROOT_GENERATE_DICTIONARY` / `ROOT_STANDARD_LIBRARY_PACKAGE`. A change in the argument ha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:22591,update,updated,22591,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,1,['update'],['updated']
Deployability,"OOTAllocator`, `TSchemaRuleProcessor`, `TStdBitsetHelper`, `TInitBehavior`, `TDefaultInitBehavior`, `DefineBehavior`, `THnBaseBrowsable`, `THnBaseBinIter`, `GenericShowMembers`, `TOperatorNewHelper` and `BranchProxy` implementations classes. Several definition where moved from the global or ROOT namespace to the ROOT::Details namespace as they are intended to be used in 'expert' level code and have a lower level of backward compatibility requirement. This includes `TCollectionProxyInfo`, `TSchemaRuleSet`. ## Interpreter. ROOT can now dump the context of STL collections, for instance `map<string,int>`. A few ROOT types print their content, too. Fixed the handling of the current directory in `#include` of system headers, avoid problem with local files named `new` or `vector`. Fixed the issue with the ROOT special variable where the objects were read from the file at each and every access by caching those object. See [ROOT-7830] for example. This release contains several bug fixes and improvements, notably in unloading and performance. > NOTE: The GCC 5 ABI is *not* supported yet, due to a lack of support in clang. ## I/O Libraries. ### hadd. We extended the `hadd` options to allow more control on the compression settings use for the; output file. In particular the new option -fk allows for a copy of the input; files with no decompressions/recompression of the TTree baskets even if they; do not match the requested compression setting. New options:. - `-ff` allows to force the compression setting to match the one from the first input; - `-fk[0-209]` allows to keep all the basket compressed as is and to compress the meta data with the given compression setting or the compression setting of the first input file.; - `-a` option append to existing file; - The verbosity level is now optional after -v. ### Command line utilities. We added command line utilities to streamline very common operations performed on root files, like listing their content or creating directories.; T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:6541,release,release,6541,README/ReleaseNotes/v606/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md,1,['release'],['release']
Deployability,"OOTSYS=$HOME/root; ```. 2. Add ROOTSYS/bin to your PATH:. ```; $ export PATH=$PATH:$ROOTSYS/bin; ```. 3. Setting the Library Path. On HP-UX, before executing the interactive module, you must set the; library path:. ```; $ export SHLIB_PATH=$SHLIB_PATH:$ROOTSYS/lib; ```. On AIX, before executing the interactive module, you must set the; library path:. ```; $ [ -z ""$LIBPATH"" ] && export LIBPATH=/lib:/usr/lib; $ export LIBPATH=$LIBPATH:$ROOTSYS/lib; ```. On Linux, Solaris, Alpha OSF and SGI, before executing the interactive; module, you must set the library path:. ```; $ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$ROOTSYS/lib; ```. On Solaris, in case your LD\_LIBRARY\_PATH is empty, you should set; it:. ```; $ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$ROOTSYS/lib:/usr/dt/lib; ```. If you use the `afs` version you should set (*vers* = version number,; *arch* = architecture):. ```; $ export ROOTSYS=/afs/cern.ch/sw/lcg/external/root/vers/arch/root; ```. If ROOT was installed in `$HOME/myroot` directory on a local machine,; one can do:. ```; cd $HOME/myroot; . bin/thisroot.sh // or source bin/thisroot.sh; ```. The new `$ROOTSYS/bin/thisroot.[c]sh` scripts will set correctly the; `ROOTSYS`, `LD_LIBRARY_PATH` or other paths depending on the platform; and the `MANPATH`. To run the program just type: `root`. ## Start and Quit a ROOT Session. ```; $ root; -------------------------------------------------------------------------; | Welcome to ROOT 6.10/01 http://root.cern.ch |; | (c) 1995-2017, The ROOT Team |; | Built for macosx64 |; | From heads/v6-10-00-patches@v6-10-00-25-g9f78c3a, Jul 03 2017, 11:39:44 |; | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |; -------------------------------------------------------------------------. root [0]; ```. To start ROOT you can type `root` at the system prompt. This starts up; Cling, the ROOT command line C/C++ interpreter, and it gives you the; ROOT prompt (`root[0]`). It is possible to launch ROOT with some command line opti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md:1828,install,installed,1828,documentation/users-guide/GettingStarted.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md,1,['install'],['installed']
Deployability,"OP_skip`` is an unconditional branch. Its single operand is a 2-byte; signed integer constant. The 2-byte constant is the number of bytes of the; DWARF expression to skip forward or backward from the current operation,; beginning after the 2-byte constant. If the updated position is at one past the end of the last operation, then; the operation expression evaluation is complete. Otherwise, the DWARF expression is ill-formed if the updated operation; position is not in the range of the first to last operation inclusive, or; not at the start of an operation. 4. ``DW_OP_bra``. ``DW_OP_bra`` is a conditional branch. Its single operand is a 2-byte signed; integer constant. This operation pops the top of stack. If the value popped; is not the constant 0, the 2-byte constant operand is the number of bytes of; the DWARF operation expression to skip forward or backward from the current; operation, beginning after the 2-byte constant. If the updated position is at one past the end of the last operation, then; the operation expression evaluation is complete. Otherwise, the DWARF expression is ill-formed if the updated operation; position is not in the range of the first to last operation inclusive, or; not at the start of an operation. 5. ``DW_OP_call2, DW_OP_call4, DW_OP_call_ref``. ``DW_OP_call2``, ``DW_OP_call4``, and ``DW_OP_call_ref`` perform DWARF; procedure calls during evaluation of a DWARF operation expression. ``DW_OP_call2`` and ``DW_OP_call4``, have one operand that is, respectively,; a 2-byte or 4-byte unsigned offset DR that represents the byte offset of a; debugging information entry D relative to the beginning of the current; compilation unit. ``DW_OP_call_ref`` has one operand that is a 4-byte unsigned value in the; 32-bit DWARF format, or an 8-byte unsigned value in the 64-bit DWARF format,; that represents the byte offset DR of a debugging information entry D; relative to the beginning of the ``.debug_info`` section that contains the; current compilation unit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:71914,update,updated,71914,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['update'],['updated']
Deployability,"OR ""Building SPIRV-Tools tests is unsupported without the SPIR-V target""); endif (). # SPIRV_DIS and SPIRV_VAL variables can be used to provide paths to existing; # spirv-dis and spirv-val binaries, respectively. Otherwise, build them from; # SPIRV-Tools source.; if (NOT SPIRV_DIS OR NOT SPIRV_VAL); include(ExternalProject). set(BINARY_DIR ${CMAKE_CURRENT_BINARY_DIR}/SPIRVTools-bin). ExternalProject_Add(SPIRVTools; GIT_REPOSITORY https://github.com/KhronosGroup/SPIRV-Tools.git; GIT_TAG main; BINARY_DIR ${BINARY_DIR}; BUILD_COMMAND ${CMAKE_COMMAND} --build ${BINARY_DIR} --target spirv-dis spirv-val; BUILD_BYPRODUCTS ${BINARY_DIR}/tools/spirv-dis ${BINARY_DIR}/tools/spirv-val; DOWNLOAD_COMMAND git clone https://github.com/KhronosGroup/SPIRV-Tools.git SPIRVTools &&; cd SPIRVTools &&; ${Python3_EXECUTABLE} utils/git-sync-deps; UPDATE_COMMAND git pull origin main &&; ${Python3_EXECUTABLE} utils/git-sync-deps; # Don't auto-update on every build.; UPDATE_DISCONNECTED 1; # Allow manual updating with an explicit SPIRVTools-update target.; STEP_TARGETS update; # Install handled below.; INSTALL_COMMAND """"; ); endif (). if (CMAKE_HOST_UNIX); set(LLVM_LINK_OR_COPY create_symlink); else (); set(LLVM_LINK_OR_COPY copy); endif (). # Link the provided or just built spirv-dis and spirv-val binaries.; if (SPIRV_DIS); add_custom_target(spirv-dis; COMMAND ${CMAKE_COMMAND} -E ${LLVM_LINK_OR_COPY} ""${SPIRV_DIS}"" ""${LLVM_RUNTIME_OUTPUT_INTDIR}/spirv-dis""); else (); add_custom_target(spirv-dis; COMMAND ${CMAKE_COMMAND} -E ${LLVM_LINK_OR_COPY} ""${BINARY_DIR}/tools/spirv-dis"" ""${LLVM_RUNTIME_OUTPUT_INTDIR}/spirv-dis""; DEPENDS SPIRVTools; ); endif (). if (SPIRV_VAL); add_custom_target(spirv-val; COMMAND ${CMAKE_COMMAND} -E ${LLVM_LINK_OR_COPY} ""${SPIRV_VAL}"" ""${LLVM_RUNTIME_OUTPUT_INTDIR}/spirv-val""); else (); add_custom_target(spirv-val; COMMAND ${CMAKE_COMMAND} -E ${LLVM_LINK_OR_COPY} ""${BINARY_DIR}/tools/spirv-val"" ""${LLVM_RUNTIME_OUTPUT_INTDIR}/spirv-val""; DEPENDS SPIRVTools; ); endif (); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/spirv-tools/CMakeLists.txt:1316,update,update,1316,interpreter/llvm-project/llvm/tools/spirv-tools/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/spirv-tools/CMakeLists.txt,1,['update'],['update']
Deployability,"OT files can be accessed remotely in many ways, on the base of the protocol; URL. Among the most popular are XRootD (protocols 'root://' and 'xrd://') and; a Web server (protocl 'http://' or 'https://'). The rootd daemon is deprecated and has been removed in version 6.16/00. Please refer to the XRootD documentation for starting and ensuring that such a; daemon is running. Reading and writing ROOT files over the net can be done by creating a; **`TFile`** object using the static method **`TFile::Open()`** object.; This will instantiate the appropriate derivation of **`TFile`** to handle the; request. Inheriting from the **`TFile`** class, the returned instance will have; exactly the same interface and behavior of **`TFile`**. The only difference; is that it reads and writes from a remote service.; In the example below the file is read via a web server through the TDavixFile plug-in. ### A Simple Session. ``` {.cpp}; root[] TFile *f1 = TFile::Open(""local/file.root"",""update""); root[] TFile *f2 = TFile::Open(""root://my.server.org/data/file.root"",""new""); root[] TFile *f3 = TFile::Open(""http://root.cern.ch/files/hsimple.root""); root[] f3.ls(); TDavixFile** http://root.cern.ch/files/hsimple.root; TDavixFile* http://root.cern.ch/files/hsimple.root; KEY: TH1F hpx;1 This is the px distribution; KEY: TH2F hpxpy;1 py vs px; KEY: TProfile hprof;1 Profile of pz versus px; KEY: TNtuple ntuple;1 Demo ntuple; root[] hpx.Draw(); ```. ## XML Interface. A new module `xml` as implemented by Sergey Linev (GSI). It is an; optional package that can be used to save a canvas into `file.xml` file; format instead of `file.root`. XML files do not have any advantages; compared to the normal ROOT files, except that the information in these; files can be edited via a normal editor. The main motivation for this; new format is to facilitate the communication with other non ROOT; applications. Currently writing and reading XML files is limited to ROOT; applications. It is our intention to develop a sim",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:96512,update,update,96512,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['update'],['update']
Deployability,"Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:46872,release,release,46872,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['release'],['release']
Deployability,"P uses the value provided by the; runtime. It is used, together with Scratch Wavefront Offset as an offset, to; access the private memory space using a segment address. See; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`. The scratch V# is a four-aligned SGPR and always selected for the kernel as; follows:. - If it is known during instruction selection that there is stack usage,; SGPR0-3 is reserved for use as the scratch V#. Stack usage is assumed if; optimizations are disabled (``-O0``), if stack objects already exist (for; locals, etc.), or if there are any function calls. - Otherwise, four high numbered SGPRs beginning at a four-aligned SGPR index; are reserved for the tentative scratch V#. These will be used if it is; determined that spilling is needed. - If no use is made of the tentative scratch V#, then it is unreserved,; and the register count is determined ignoring it.; - If use is made of the tentative scratch V#, then its register numbers; are shifted to the first four-aligned SGPR index after the highest one; allocated by the register allocator, and all uses are updated. The; register count includes them in the shifted location.; - In either case, if the processor has the SGPR allocation bug, the; tentative allocation is not shifted or unreserved in order to ensure; the register count is higher to workaround the bug. .. note::. This approach of using a tentative scratch V# and shifting the register; numbers if used avoids having to perform register allocation a second; time if the tentative V# is eliminated. This is more efficient and; avoids the problem that the second register allocation may perform; spilling which will fail as there is no longer a scratch V#. When the kernel prolog code is being emitted it is known whether the scratch V#; described above is actually used. If it is, the prolog code must set it up by; copying the Private Segment Buffer to the scratch V# registers and then adding; the Private Segment Wavefront Offset to the queue ba",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:199541,update,updated,199541,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['update'],['updated']
Deployability,"P::FPRegsRegisterClass);; addRegisterClass(MVT::f64, SP::DFPRegsRegisterClass);. You should examine the node types in the ``ISD`` namespace; (``include/llvm/CodeGen/SelectionDAGNodes.h``) and determine which operations; the target natively supports. For operations that do **not** have native; support, add a callback to the constructor for the ``XXXTargetLowering`` class,; so the instruction selection process knows what to do. The ``TargetLowering``; class callback methods (declared in ``llvm/Target/TargetLowering.h``) are:. * ``setOperationAction`` --- General operation.; * ``setLoadExtAction`` --- Load with extension.; * ``setTruncStoreAction`` --- Truncating store.; * ``setIndexedLoadAction`` --- Indexed load.; * ``setIndexedStoreAction`` --- Indexed store.; * ``setConvertAction`` --- Type conversion.; * ``setCondCodeAction`` --- Support for a given condition code. Note: on older releases, ``setLoadXAction`` is used instead of; ``setLoadExtAction``. Also, on older releases, ``setCondCodeAction`` may not; be supported. Examine your release to see what methods are specifically; supported. These callbacks are used to determine that an operation does or does not work; with a specified type (or types). And in all cases, the third parameter is a; ``LegalAction`` type enum value: ``Promote``, ``Expand``, ``Custom``, or; ``Legal``. ``SparcISelLowering.cpp`` contains examples of all four; ``LegalAction`` values. Promote; ^^^^^^^. For an operation without native support for a given type, the specified type; may be promoted to a larger type that is supported. For example, SPARC does; not support a sign-extending load for Boolean values (``i1`` type), so in; ``SparcISelLowering.cpp`` the third parameter below, ``Promote``, changes; ``i1`` type values to a large type before loading. .. code-block:: c++. setLoadExtAction(ISD::SEXTLOAD, MVT::i1, Promote);. Expand; ^^^^^^. For a type without native support, a value may need to be broken down further,; rather than promoted. For an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:58136,release,releases,58136,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['release'],['releases']
Deployability,"PEND Depends ${CMAKE_BINARY_DIR}/bin/${BinFile}); install(PROGRAMS bin/${BinFile}; DESTINATION ""${CMAKE_INSTALL_BINDIR}""; COMPONENT scan-build); endforeach(). foreach(LibexecFile ${LibexecFiles}); add_custom_command(OUTPUT ${CMAKE_BINARY_DIR}/libexec/${LibexecFile}; COMMAND ${CMAKE_COMMAND} -E make_directory; ${CMAKE_BINARY_DIR}/libexec; COMMAND ${CMAKE_COMMAND} -E copy; ${CMAKE_CURRENT_SOURCE_DIR}/libexec/${LibexecFile}; ${CMAKE_BINARY_DIR}/libexec/; DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/libexec/${LibexecFile}); list(APPEND Depends ${CMAKE_BINARY_DIR}/libexec/${LibexecFile}); install(PROGRAMS libexec/${LibexecFile}; DESTINATION ""${CMAKE_INSTALL_LIBEXECDIR}""; COMPONENT scan-build); endforeach(). foreach(ManPage ${ManPages}); add_custom_command(OUTPUT ""${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_MANDIR}/man1/${ManPage}""; COMMAND ${CMAKE_COMMAND} -E make_directory; ""${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_MANDIR}/man1""; COMMAND ${CMAKE_COMMAND} -E copy; ""${CMAKE_CURRENT_SOURCE_DIR}/man/${ManPage}""; ""${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_MANDIR}/man1/""; DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/man/${ManPage}); list(APPEND Depends ""${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_MANDIR}/man1/${ManPage}""); install(FILES man/${ManPage}; DESTINATION ""${CMAKE_INSTALL_MANDIR}/man1""; COMPONENT scan-build); endforeach(). foreach(ShareFile ${ShareFiles}); add_custom_command(OUTPUT ${CMAKE_BINARY_DIR}/share/scan-build/${ShareFile}; COMMAND ${CMAKE_COMMAND} -E make_directory; ${CMAKE_BINARY_DIR}/share/scan-build; COMMAND ${CMAKE_COMMAND} -E copy; ${CMAKE_CURRENT_SOURCE_DIR}/share/scan-build/${ShareFile}; ${CMAKE_BINARY_DIR}/share/scan-build/; DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/share/scan-build/${ShareFile}); list(APPEND Depends ${CMAKE_BINARY_DIR}/share/scan-build/${ShareFile}); install(FILES share/scan-build/${ShareFile}; DESTINATION ""${CMAKE_INSTALL_DATADIR}/scan-build""; COMPONENT scan-build); endforeach(). add_custom_target(scan-build ALL DEPENDS ${Depends}); set_target_properties(scan-build PROPERTIES FOLDE",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build/CMakeLists.txt:2031,install,install,2031,interpreter/llvm-project/clang/tools/scan-build/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build/CMakeLists.txt,1,['install'],['install']
Deployability,"PI. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `sizeof(llvm_blake3_hasher)` itself is relatively large, currently 1912 bytes; on x86-64. This size can be reduced by restricting the maximum input; length, as described in Section 5.4 of [the BLAKE3; spec](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf),; but this implementation doesn't currently support that strategy. ## Common API Functions. ```c++; BLAKE3::BLAKE3();. void BLAKE3::init();; ```; ```c; void llvm_blake3_hasher_init(; llvm_blake3_hasher *self);; ```. Initialize a `llvm_blake3_hasher` in the default hashing mode. ---. ```c++; void BLAKE3::update(ArrayRef<uint8_t> Data);. void BLAKE3::update(StringRef Str);; ```; ```c; void llvm_blake3_hasher_update(; llvm_blake3_hasher *self,; const void *input,; size_t input_len);; ```. Add input to the hasher. This can be called any number of times. ---. ```c++; template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; using BLAKE3Result = std::array<uint8_t, NumBytes>;. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; void BLAKE3::final(BLAKE3Result<NumBytes> &Result);. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; BLAKE3Result<NumBytes> BLAKE3::final();; ```; ```c; void llvm_blake3_hasher_finalize(; const llvm_blake3_hasher *self,; uint8_t *out,; size_t out_len);; ```. Finalize the hasher and return an output of any length, given in bytes.; This doesn't modify the hasher itself, and it's possible to finalize; again after adding more input. The constant `LLVM_BLAKE3_OUT_LEN` provides; the default output length, 32 bytes, which is recommended for most; callers. Outputs shorter than the default length of 32 bytes (256 bits) provide; less security. An N-bit BLAKE3 output is intended to provide N ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:2779,update,update,2779,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,1,['update'],['update']
Deployability,"PREFIX. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/html``. **LLVM_INSTALL_UTILS**:BOOL; If enabled, utility binaries like ``FileCheck`` and ``not`` will be installed; to CMAKE_INSTALL_PREFIX. **LLVM_INTEGRATED_CRT_ALLOC**:PATH; On Windows, allows embedding a different C runtime allocator into the LLVM; tools and libraries. Using a lock-free allocator such as the ones listed below; greatly decreases ThinLTO link time by about an order of magnitude. It also; midly improves Clang build times, by about 5-10%. At the moment, rpmalloc,; snmalloc and mimalloc are supported. Use the path to `git clone` to select; the respective allocator, for example:. .. code-block:: console. $ D:\git> git clone https://github.com/mjansson/rpmalloc; $ D:\llvm-project> cmake ... -DLLVM_INTEGRATED_CRT_ALLOC=D:\git\rpmalloc. This flag needs to be used along with the static CRT, ie. if building the; Release target, add -DCMAKE_MSVC_RUNTIME_LIBRARY=MultiThreaded. **LLVM_INSTALL_DOXYGEN_HTML_DIR**:STRING; The path to install Doxygen-generated HTML documentation to. This path can; either be absolute or relative to the *CMAKE_INSTALL_PREFIX*. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/doxygen-html``. **LLVM_LINK_LLVM_DYLIB**:BOOL; If enabled, tools will be linked with the libLLVM shared library. Defaults; to OFF. Setting LLVM_LINK_LLVM_DYLIB to ON also sets LLVM_BUILD_LLVM_DYLIB; to ON.; This option is not available on Windows. **LLVM_LIT_ARGS**:STRING; Arguments given to lit. ``make check`` and ``make clang-test`` are affected.; By default, ``'-sv --no-progress-bar'`` on Visual C++ and Xcode, ``'-sv'`` on; others. **LLVM_LIT_TOOLS_DIR**:PATH; The path to GnuWin32 tools for tests. Valid on Windows host. Defaults to; the empty string, in which case lit will look for tools needed for tests; (e.g. ``grep``, ``sort``, etc.) in your %PATH%. If GnuWin32 is not in your; %PATH%, then you can set this variable to the GnuWin32 directory so that; lit can find tools needed for tests in that directory. **LLVM",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:30329,install,install,30329,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['install'],['install']
