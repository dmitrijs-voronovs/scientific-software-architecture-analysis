quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Security," _intervals=intervals). - reference_data = VariantDataset._add_len_end(reference_data); + # if LEN is missing, add it, _add_len is a no-op if LEN is already present; + reference_data = VariantDataset._add_len(reference_data); if _drop_end:; - reference_data = reference_data.drop('END'); + if 'END' in reference_data.entry:; + reference_data = reference_data.drop('END'); + else: # if END is missing, add it, _add_end is a no-op if END is already present; + reference_data = VariantDataset._add_end(reference_data); +; vds = VariantDataset(reference_data, variant_data); if VariantDataset.ref_block_max_length_field not in vds.reference_data.globals:; fs = hl.current_backend().fs; ```. There was nothing in the IR that stood out when I examined it, but I will admit that I'm not the best at digging into it. ### Version. https://github.com/chrisvittal/hail/tree/vds/repro-example. ### Relevant log output. ```shell; E hail.utils.java.FatalError: RuntimeException: invalid memory access: 140a68008/00000001: not in 140a58008/00010000; E; E Java stack trace:; E java.lang.RuntimeException: invalid memory access: 140a68008/00000001: not in 140a58008/00010000; E 	at is.hail.annotations.Memory.checkAddress(Memory.java:226); E 	at is.hail.annotations.Memory.loadByte(Memory.java:130); E 	at is.hail.annotations.Region$.loadByte(Region.scala:28); E 	at is.hail.annotations.Region$.loadBit(Region.scala:86); E 	at __C23148collect_distributed_array_matrix_native_writer.__m23333split_ToArray(Unknown Source); E 	at __C23148collect_distributed_array_matrix_native_writer.apply_region478_486(Unknown Source); E 	at __C23148collect_distributed_array_matrix_native_writer.apply_region16_503(Unknown Source); E 	at __C23148collect_distributed_array_matrix_native_writer.apply_region14_529(Unknown Source); E 	at __C23148collect_distributed_array_matrix_native_writer.apply(Unknown Source); E 	at __C23148collect_distributed_array_matrix_native_writer.apply(Unknown Source); E 	at is.hail.backend.BackendUtils.$a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14705:2306,access,access,2306,https://hail.is,https://github.com/hail-is/hail/issues/14705,1,['access'],['access']
Security," a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - web_common/requirements.txt. <details>; <summary>⚠️ <b>Warning</b></summary>. ```; aiohttp-jinja2 1.5.1 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14037:1049,Validat,Validation,1049,https://hail.is,https://github.com/hail-is/hail/pull/14037,1,['Validat'],['Validation']
Security," account jigold-59hi5@hail-vdc.iam.gserviceaccount.com read and write access to hail-batch-jigold-oxmmp.; Which region do you want your jobs to run in? [us-central1/us-east1/us-east4/us-west1/us-west2/us-west3/us-west4]: us-central1; Which backend do you want to use for Hail Query? [spark/batch/local]: batch; --------------------; FINAL CONFIGURATION:; --------------------; global/domain=hail.is; batch/remote_tmpdir=gs://hail-batch-jigold-oxmmp/foo; batch/regions=us-central1; batch/backend=service; query/backend=batch; ```. User does not give permissions to existing remote tmpdir:; ```; (py311) jigold@wm349-8c4 hail % hailctl batch init; Do you want to create a new bucket in project for temporary files generated by Hail? [y/n]: n; Enter a path to an existing remote temporary directory (ex: gs://my-bucket/batch/tmp): gs://hail-batch-jigold-oxmmp; Do you want to give service account jigold-59hi5@hail-vdc.iam.gserviceaccount.com read/write access to bucket hail-batch-jigold-oxmmp? [y/n]: n ; WARNING: Please verify service account jigold-59hi5@hail-vdc.iam.gserviceaccount.com has the role ""roles/storage.objectAdmin"" or both ""roles/storage.objectViewer"" and ""roles/storage.objectCreator"" roles for bucket hail-batch-jigold-oxmmp.; Which region do you want your jobs to run in? [us-central1/us-east1/us-east4/us-west1/us-west2/us-west3/us-west4]: us-central1; Which backend do you want to use for Hail Query? [spark/batch/local]: batch; --------------------; FINAL CONFIGURATION:; --------------------; global/domain=hail.is; batch/remote_tmpdir=gs://hail-batch-jigold-oxmmp; batch/regions=us-central1; batch/backend=service; query/backend=batch; ```. Not existing user-specified remote tmpdir:; ```; (py311) jigold@wm349-8c4 hail % hailctl batch init; Do you want to create a new bucket in project for temporary files generated by Hail? [y/n]: n; Enter a path to an existing remote temporary directory (ex: gs://my-bucket/batch/tmp): gs://my-bucket/foo/bar; ERROR: You do not have suffici",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13279#issuecomment-1679133568:3043,access,access,3043,https://hail.is,https://github.com/hail-is/hail/pull/13279#issuecomment-1679133568,1,['access'],['access']
Security," an error since `start` has no option `--beta`. This PR rewrites argument parsing to use click instead of argparse: https://click.palletsprojects.com/en/7.x/. Things you need to know about click:; - A group is a group of commands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line parameters, parses them, and calls the original function. The option options are pretty self-explanatory. - To access an argument to a group (like `dataproc --beta`) in a (sub)command, use the decorator `click.pass_context` to pass the click context which allows you to access parent group parameters. `dataproc start` is an example:. ```; @dataproc.command(; help=""Start a Dataproc cluster configured for Hail.""); @click.argument('cluster_name'); ...; @click.pass_context; def start(ctx, cluster_name, ...):; beta = ctx.parent.params['beta']; ```. The help output for a group looks like this:. ```; $ hailctl dataproc --help; Usage: hailctl dataproc [OPTIONS] COMMAND [ARGS]... Manage and monitor Hail deployments. Options:; --beta Force use of `beta` in gcloud commands; --help Show this message and exit. Commands:; connect Connect to a running Dataproc cluster; describe Gather information about a Hail (Table or MatrixTable) file...; diagnose Diagnose problems in a Dataproc cluster.; list List Dataproc clusters.; modify; start Start a Dataproc cluster configured for Hail.; stop Shut down a Dataproc cluster.; submit Submit a Python script to a runnin",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9842:2214,access,access,2214,https://hail.is,https://github.com/hail-is/hail/pull/9842,1,['access'],['access']
Security," and 3.7 (<a href=""https://redirect.github.com/pyasn1/pyasn1-modules/issues/14"">#14</a>)</li>; <li><a href=""https://github.com/pyasn1/pyasn1-modules/commit/9ec54091547330aaf994e82ba759cb1fe071e070""><code>9ec5409</code></a> Drop support for EOL Python 2.7 (<a href=""https://redirect.github.com/pyasn1/pyasn1-modules/issues/12"">#12</a>)</li>; <li><a href=""https://github.com/pyasn1/pyasn1-modules/commit/252ac00bf1e119a044cc579ffade30164e2cdfff""><code>252ac00</code></a> Add support for Python 3.12 (<a href=""https://redirect.github.com/pyasn1/pyasn1-modules/issues/11"">#11</a>)</li>; <li>See full diff in <a href=""https://github.com/pyasn1/pyasn1-modules/compare/v0.3.0...v0.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyasn1-modules&package-manager=pip&previous-version=0.3.0&new-version=0.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14472:2382,secur,security-vulnerabilities,2382,https://hail.is,https://github.com/hail-is/hail/pull/14472,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," and Java 11, and the minimal supported Java version will be Java 17; > Support for Scala 2.12, and the minimal supported Scala version will be 2.13. Also, requiring specifically Java 8 or 11 has led to some friction for students and researchers who are first evaluating hail. In the past few weeks, I've talked to a lot of students and researchers who wanted to evaluate hail, followed the documentation to install Azul Java 8 but already had an existing Java install and did not update their PATH or JAVA_HOME. Most of their existing Java versions were 17, as 17 is the current default on most Linux distros and a common one to have been installed via Brew in the past few years on Mac. Alternatively, if you don't want to allow Java 17, potentially Hail could bundle a JRE with it in the PyPI distributable? Using jdeps on the Hail shadow jar, I saw that it only needs these modules in a JRE:; ```; java.base,java.compiler,java.desktop,java.management,java.naming,java.rmi,java.scripting,java.security.jgss,java.sql,jdk.httpserver,jdk.unsupported; ```. That means that a JRE created with jlink like this:; ```; jlink --add-modules java.base,java.compiler,java.desktop,java.management,java.naming,java.rmi,java.scripting,java.security.jgss,java.sql,jdk.httpserver,jdk.unsupported --output minimaljre --strip-debug --no-man-pages --no-header-files --compress=2; ```; comes in at under 30MB gzipped, which would increase the PyPI package by about 20% in size, while allowing users to install and run Hail in _any_ supported python environment without having to consider Java versions at all. Alternatively, have you ever considered distributing Hail through conda-forge or bioconda, where you could specify a JRE that should be installed with it and automatically linked?. Is there a better channel than Github Issues for feature requests? I realize this is not a bug report, and if you want to just close it and say ""nope"" that's fine, but I've seen a good number of first-time hail users get a bad i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14433:2305,secur,security,2305,https://hail.is,https://github.com/hail-is/hail/issues/14433,1,['secur'],['security']
Security," and lazy=True</li>; <li><a href=""https://github.com/fonttools/fonttools/commit/1d5feb81e597db8faa53695315befbccf0075b2e""><code>1d5feb8</code></a> ttFont_test: add reproducer for SpooledTemporaryFile has no seekable</li>; <li><a href=""https://github.com/fonttools/fonttools/commit/f1c609aa57fa11ab98f2152275f2c709e06c0680""><code>f1c609a</code></a> .readthedocs.yml: don't use 'legacy' build specification</li>; <li><a href=""https://github.com/fonttools/fonttools/commit/f9b941d226242c6b481e752036654aa346409036""><code>f9b941d</code></a> use python3.10 for ReadTheDocs</li>; <li>Additional commits viewable in <a href=""https://github.com/fonttools/fonttools/compare/4.38.0...4.39.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=fonttools&package-manager=pip&previous-version=4.38.0&new-version=4.39.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12910:17326,secur,security-vulnerabilities,17326,https://hail.is,https://github.com/hail-is/hail/pull/12910,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," architectures were part of 5.10) - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1404"">#1404</a>: Added Solaris Kstat2 library - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1416"">#1416</a>: Add <code>CFDictionaryGetCount</code> to <code>c.s.j.p.mac.CoreFoundation</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1418"">#1418</a>: Add <code>CertOpenStore</code> to <code>c.s.j.p.win32.Crypt32</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1411"">#1411</a>: Do not throw <code>Win32Exception</code> on success for empty section in <code>Kernel32Util#getPrivateProfileSection</code> - <a href=""https://github.com/mkarg""><code>@​mkarg</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1414"">#1414</a>: Fix definition of <code>c.s.j.p.unix.X11.XK_Shift_R</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1323"">#1323</a>. Fix crashes in direct callbacks on mac OS aarch64 - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1422"">#1422</a>: Load jawt library relative to <code>sun.boot.library.path</code> system on unix OSes - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1427"">#1427</a>: R",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:4017,access,access,4017,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security, at scala.collection.mutable.HashMap.apply(HashMap.scala:65); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply$mcVJ$sp(TaskSchedulerImpl.scala:243); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:235); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:235); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:234); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.TaskSchedulerImpl.cancelTasks(TaskSchedulerImpl.scala:234); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply$mcVI$sp(DAGScheduler.scala:1543); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at sca,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:200392,Hash,HashTable,200392,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['Hash'],['HashTable']
Security," because this PR addresses questions of state and will take care of this. ```python; self.exit_code = pod.status.container_statuses[0].state.terminated.exit_code; ```. We should probably do something like . ```python; self.exit_code = max(status.state.terminated.exit_code for status in pod.status.container_statuses); ```; although I also see that in update_job_with_pod we effectively restrict to a single container. I'm not sure why this limit exists, but if needed, should probably occur during creation. In the upcoming PR, which moves state to MySQL 5.7+, and a different server model (async), I think it would be neat to represent meta-state (across all containers, and potentially the job subgraph whose first node is the inspected job) as:. ```go; const (; 	Cancelled = -3; 	Initialized = -2; 	Created = -1; ); ```. with values >=0 being the maximum of the linux error codes, 0-255, of the subgraph. Simple queries. Alternative is to use NULL when not completed, but when used in a client would require a null check, or potentially have surprising side effects (i.e where the default value is 0). We could also use a separate, text-based status field, but I will store a queryable JSON field containing the full status as well. In a similar vein, we have some state race conditions. For instance:. ```python; self.pod_template = kube.client.V1Pod(; metadata=kube.client.V1ObjectMeta(generate_name='job-{}-'.format(self.id),; labels={; 'app': 'batch-job',; 'hail.is/batch-instance': instance_id,; 'uuid': uuid.uuid4().hex; }),; spec=pod_spec). self._pod_name = None; self.exit_code = None. self._state = 'Created'; log.info('created job {}'.format(self.id)). self._create_pod(); ```. Here, every time pod creation fails, _state will be misaligned, and will have potential side effects (say in get_log). One solution could be to validate and rewind state in _create_pod. In any case, I will do my best to address state questions in the upcoming PR, and will close this when / if we approve it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5118:1919,validat,validate,1919,https://hail.is,https://github.com/hail-is/hail/issues/5118,1,['validat'],['validate']
Security," checking of node.docstring (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/704"">#704</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/405a0906c8debafaae419472d3f51b84b7ba5c49""><code>405a090</code></a> simplify PYPY check (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/703"">#703</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/30ec8589e183f76f40764a8dd78591719f521943""><code>30ec858</code></a> remove unused WIN (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/702"">#702</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pyflakes/compare/2.4.0...2.5.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyflakes&package-manager=pip&previous-version=2.4.0&new-version=2.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12149:3825,secur,security-vulnerabilities,3825,https://hail.is,https://github.com/hail-is/hail/pull/12149,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," configuration file that configures TLS for; outgoing (proxy_pass) requests.; - `site-key.pem`: a private key.; - `site-cert.pem`: a certificate.; - `site-incoming.pem`: a list of certificates trusted for incoming requests.; - `site-outgoing.pem`: a list of certificates expected from outgoing requests. If site makes an HTTP request to a server and that server does not return a; certificate in `site-outgoing.pem`, it will immediately halt the connection. I; intend (though do not currently) site to also reject incoming requests that are; not accompanied by a certificate in `site-incoming.pem`. I describe the [trouble; with that later](#incoming-trust). There are two other kinds: `json` and `curl`. The former is for Hail Python; services. The later is for the admin-pod and image-fetcher. Deploy will run `create_certs` on every master deploy. Newly deployed services; will be unable to talk to not-yet-deployed services. I include the; one-deploy-ago certificates in the trust chains, but once incoming trust is; fixed, I am unsure how to smoothly upgrade services. I probably need to notify; old services to refresh their certificates after the secrets are updated. ### Incoming Trust. Mutual TLS (mTLS) refers to TLS connections wherein both sides are; authenticated. This is rare on the web. In our system, it means verifying that a; request made to you carries a certificate in the `NAME-incoming.pem` file. I; cannot enable that in this PR because the three unmanaged services,; router-resolver, internal-gateway, and gateway, do not currently have; certificates. As a result, all the services in the PR namespace reject the; requests from the unmangaed services. In particular, batch pods cannot; communicate with batch-driver. After this PR is deployed and the unmanaged services have certificates, I can; enable mutual TLS. I've marked the tow lines that need to change with `# FIXME:; mTLS`. ### Batch Confused Deputy. The [confused deputy; problem](https://en.wikipedia.org/wiki/Conf",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:8176,certificate,certificates,8176,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['certificate'],['certificates']
Security," extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0f43ce67de72bd511d849c07bd7728c0d6f2e6dd""><code>0f43ce6</code></a> Document path and relativePath properties</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a8504f9d60d0264808894e4bb80d4a73b8086a3e""><code>a8504f9</code></a> Bump up version number to 5.3.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/708067cd11c4a013da7a8c15d91f7f946967cf94""><code>708067c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0fdebf3c7ad43ed4739",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:2688,authenticat,authentication,2688,https://hail.is,https://github.com/hail-is/hail/pull/12345,2,"['Authenticat', 'authenticat']","['Authenticate', 'authentication']"
Security," extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.5</h2>; <p>Maintenance:</p>; <ul>; <li>Publish signed artifacts to Gradle plugin portal</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.4</h2>; <p>Bug fixes:</p>; <ul>; <li>Fix deadlock in <code>DownloadExtension</code> if <code>max-workers</code> equals 1 (thanks to <a href=""https://github.com/beatbrot""><code>@​beatbrot</code></a> for spotting this, see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/205"">#205</a>)</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1b5d69",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:1969,authenticat,authentication,1969,https://hail.is,https://github.com/hail-is/hail/pull/12332,2,"['Authenticat', 'authenticat']","['Authenticate', 'authentication']"
Security," extra dependency</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/4a1d10e19fdca00db47fd50725715dc5e4aa68e6""><code>4a1d10e</code></a> consistent ordering</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/bf6c960f60f8a390b47ac55d2ece3ffc419e5dcd""><code>bf6c960</code></a> emoji bars</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/7994aa8285743b351cf1a3b36275335d8d0730b7""><code>7994aa8</code></a> warn once on error</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/a1d4401f186dc5a79b4ad452f38cae75e1f2e6da""><code>a1d4401</code></a> remove unneeded variable</li>; <li>Additional commits viewable in <a href=""https://github.com/tqdm/tqdm/compare/v4.42.1...v4.64.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tqdm&package-manager=pip&previous-version=4.42.1&new-version=4.64.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12260:5964,secur,security-vulnerabilities,5964,https://hail.is,https://github.com/hail-is/hail/pull/12260,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Expected Behavior Violation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3314966](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3314966) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Use After Free <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315324](https://snyk.io/vuln/SNYK-PY",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14134:1108,Certificate,Certificate,1108,https://hail.is,https://github.com/hail-is/hail/pull/14134,1,['Certificate'],['Certificate']
Security," gcr.io/hail-vdc/query:tfkm2kev7zcf'). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 372, in run; await self.ensure_image_is_pulled(); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 363, in ensure_image_is_pulled; docker.images.pull, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 104, in _handle_list; async with cm as response:; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(500, ""unauthorized: You don't have the needed permissions to perform this operation, and you may have invalid credentials. To authenticate your request, follow the steps in: https://cloud.google.com/container-registry/docs/advanced-authentication""); ```. [1] The Docker specifications are confusing. After reading; [v1](https://github.com/moby/moby/blob/master/image/spec/v1.md) and; [v1.2](https://github.com/moby/moby/blob/master/image/spec/v1.2.md), it seems that the ""repository""; is everything before the last colon and the ""image name suffix"" is everything after the last; colon. For example, in `server:8080/abc/def:123`, the repository is `server:8080/abc/def` and the; ""image name suffix"" is `123`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9902:4211,authenticat,authenticate,4211,https://hail.is,https://github.com/hail-is/hail/pull/9902,2,['authenticat'],"['authenticate', 'authentication']"
Security," href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/654"">jpadilla/pyjwt#654</a></li>; <li>Ignore coverage files generated during test runs by <a href=""https://github.com/makusu2""><code>@​makusu2</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/617"">jpadilla/pyjwt#617</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/656"">jpadilla/pyjwt#656</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/658"">jpadilla/pyjwt#658</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/667"">jpadilla/pyjwt#667</a></li>; <li>Fix aud validation to support {'aud': null} case. by <a href=""https://github.com/dajiaji""><code>@​dajiaji</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/670"">jpadilla/pyjwt#670</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/678"">jpadilla/pyjwt#678</a></li>; <li>Prefer headers['alg'] to algorithm parameter in encode(). by <a href=""https://github.com/dajiaji""><code>@​dajiaji</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/673"">jpadilla/pyjwt#673</a></li>; <li>DOC: Clarify RSA encoding and decoding depend on the cryptography package by <a href=""https://github.com/TPXP""><code>@​TPXP</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/664"">jpadilla/pyjwt#664</a></li>; <li>Make typ optional by <a href=""https://github.com/dajiaji""><code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11457:2929,validat,validation,2929,https://hail.is,https://github.com/hail-is/hail/pull/11457,1,['validat'],['validation']
Security," href=""https://github-redirect.dependabot.com/plotly/plotly.js/pull/6193"">plotly.js#6193</a>, <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3749"">#3749</a></li>; </ul>; <h2>[5.8.2] - 2022-06-10</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed a syntax error that caused rendering issues in Databricks notebooks and likely elsewhere. <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3763"">#3763</a> with thanks to <a href=""https://github.com/fwetdb""><code>@​fwetdb</code></a></li>; </ul>; <h2>[5.8.1] - 2022-06-08</h2>; <p>(no changes, due to a mixup with the build process!)</p>; <h2>[5.8.0] - 2022-05-09</h2>; <h3>Fixed</h3>; <ul>; <li>Improve support for type checking and IDE auto-completion by bypassing lazy-loading when type checking. <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3425"">#3425</a> with thanks to <a href=""https://github.com/JP-Ellis""><code>@​JP-Ellis</code></a></li>; <li>line dash-style validators are now correctly used everywhere so that values like <code>10px 2px</code> are accepted <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3722"">#3722</a></li>; <li>Resolved various deprecation warning messages and compatibility issues with upstream dependencies and Python 3.11, plus removed dependency on <code>six</code>, with thanks to <a href=""https://github.com/maresb""><code>@​maresb</code></a>, <a href=""https://github.com/hugovk""><code>@​hugovk</code></a>, <a href=""https://github.com/tirkarthi""><code>@​tirkarthi</code></a>, <a href=""https://github.com/martinRenou""><code>@​martinRenou</code></a>, and <a href=""https://github.com/BjoernLudwigPTB""><code>@​BjoernLudwigPTB</code></a></li>; <li>Better support for MathJax 3 <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3706"">#3706</a></li>; </ul>; <h3>Added</h3>; <ul>; <li>Type annotations for Plotly Express functions and chainable <code>go.Figure</code> methods, for better IDE auto-completion <a href=""https://github",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12113:3896,validat,validators,3896,https://hail.is,https://github.com/hail-is/hail/pull/12113,1,['validat'],['validators']
Security," href=""https://github.com/boto/boto3/commit/1de404aff4ecb1c5560b4e023f0614d8149622ed""><code>1de404a</code></a> fix typo: 'are specified the' should be 'are specified in the' (<a href=""https://github-redirect.dependabot.com/boto/boto3/issues/3499"">#3499</a>)</li>; <li><a href=""https://github.com/boto/boto3/commit/47f20744b3c57223da5e14e185120586f8212af8""><code>47f2074</code></a> Merge branch 'release-1.26.13'</li>; <li><a href=""https://github.com/boto/boto3/commit/3d4081ccb7c350538ba3d6a5073c59575a812eb0""><code>3d4081c</code></a> Merge branch 'release-1.26.13' into develop</li>; <li>Additional commits viewable in <a href=""https://github.com/boto/boto3/compare/1.26.7...1.26.15"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=boto3&package-manager=pip&previous-version=1.26.7&new-version=1.26.15)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12498:9558,secur,security-vulnerabilities,9558,https://hail.is,https://github.com/hail-is/hail/pull/12498,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," href=""https://github.com/dateutil/dateutil/commit/ee85831cc25d34ff597cfb3f2d90ce5904dbc561""><code>ee85831</code></a> Build releases with Python 3.9</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/6b337ea412d399fb48771c544b1a6880763b46c6""><code>6b337ea</code></a> Automate cutting new releases</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/9c2ad8f981ece1bdb3d52527f1cb39523b11d862""><code>9c2ad8f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1056"">#1056</a> from ffe4/issue_1029</li>; <li>Additional commits viewable in <a href=""https://github.com/dateutil/dateutil/compare/2.8.1...2.8.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=python-dateutil&package-manager=pip&previous-version=2.8.1&new-version=2.8.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:11407,secur,security-vulnerabilities,11407,https://hail.is,https://github.com/hail-is/hail/pull/11518,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," href=""https://github.com/prometheus/client_python/commit/da15e4a4d671b8aea0e60fc859d5df8102be3897""><code>da15e4a</code></a> Change to imports to fix go-to-declaration in editors (<a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/747"">#747</a>)</li>; <li><a href=""https://github.com/prometheus/client_python/commit/3ef865e1cccae66f63ae764762a700c5775a5190""><code>3ef865e</code></a> Allow to add labels inside a context manager (<a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/730"">#730</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/prometheus/client_python/compare/v0.11.0...v0.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=prometheus-client&package-manager=pip&previous-version=0.11.0&new-version=0.13.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11515:5611,secur,security-vulnerabilities,5611,https://hail.is,https://github.com/hail-is/hail/pull/11515,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1134"">PyMySQL/PyMySQL#1134</a></li>; <li><a href=""https://github.com/svaskov""><code>@​svaskov</code></a> made their first contribution in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1145"">PyMySQL/PyMySQL#1145</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/PyMySQL/PyMySQL/compare/v1.1.0...v1.1.1"">https://github.com/PyMySQL/PyMySQL/compare/v1.1.0...v1.1.1</a></p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/PyMySQL/PyMySQL/blob/main/CHANGELOG.md"">pymysql's changelog</a>.</em></p>; <blockquote>; <h2>v1.1.1</h2>; <p>Release date: 2024-05-21</p>; <blockquote>; <p>[!WARNING]; This release fixes a vulnerability (CVE-2024-36039).; All users are recommended to update to this version.</p>; <p>If you can not update soon, check the input value from; untrusted source has an expected type. Only dict input; from untrusted source can be an attack vector.</p>; </blockquote>; <ul>; <li>Prohibit dict parameter for <code>Cursor.execute()</code>. It didn't produce valid SQL; and might cause SQL injection. (CVE-2024-36039)</li>; <li>Added ssl_key_password param. <a href=""https://redirect.github.com/PyMySQL/PyMySQL/issues/1145"">#1145</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/2cab9ecc641e962565c6254a5091f90c47f59b35""><code>2cab9ec</code></a> v1.1.1</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/521e40050cb386a499f68f483fefd144c493053c""><code>521e400</code></a> forbid dict parameter</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/7f032a699d55340f05101deb4d7d4f63db4adc11""><code>7f032a6</code></a> remove coveralls from requirements</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/69f6c7439bee14784e0ea70ae107af6446cc0c67""><code>69f6c74</code></a> ruff format</li>; <li><a href=",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14556:4886,attack,attack,4886,https://hail.is,https://github.com/hail-is/hail/pull/14556,1,['attack'],['attack']
Security," in RFC 2246. This new version was backwards-incompatible and was; thus given a new name: Transport Layer Security. In common discussion, SSL; and TLS are used interchangeable. Indeed, the python TLS library is called; `ssl`. [2] Forward secrecy is a property of an encryption system. Forward secrecy means; a message cannot be decrypted in the future by an adversary who learned one; of the private keys. For example, imagine you are sending sensitive messages; to another individual. If that individual is later coerced into revealing; their secret key, forward secrecy would prevent the coercer from reading; your messages. Forward secrecy is achieved by negotiating a shared private; key between the two parties that is only used for a ""session"" and then; discarded. If the session key is securely discarded and neither key can; recreate it without cooperation from the other key, then *one* leaked key is; insufficient to reveal the messages. ---. Things for you to verify:; - does every service load *its own unqiue* ssl-config secret?; - does every service use an SSL context for serving?; - does everyone who makes http requests to internal services use an SSL client; session?; - do all TLS-secured nginx instances include their http.conf in the `http`; section and the `proxy.conf` file in any proxying sections?; - Do the SSLContext's from `ssl.py` and the nginx configurations generated by; `create_certs.py` actually ensure security?. Post-merge actions:; - deploy gateway; - deploy internal-gateway; - deploy router-resolver. Anticipated outages:. - Before a service is redeployed it will be inaccessible from the outside; because the router will try to speak to it on HTTPS. Services that speak to; one another (ci<->batch, everyone<->auth) will lose connections while the; deploy is happening. Deploy should move smoothly because CI will completely; transmit the deploy batch to batch before batch goes dark.; - dev namespaces will be broken until the owner redeploys the router, etc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:12915,secur,secured,12915,https://hail.is,https://github.com/hail-is/hail/pull/8561,2,['secur'],"['secured', 'security']"
Security," is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get namespaces in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""/v1, Resource=serviceaccounts"", GroupVersionKind: ""/v1, Kind=ServiceAccount""; Name: ""batch-svc"", Namespace: ""batch-pods""; Object: &{map[""kind"":""ServiceAccount"" ""metadata"":map[""name"":""batch-svc"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""apiVersion"":""v1""]}; from server for: ""deployment.yaml"": serviceaccounts ""batch-svc"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get serviceaccounts in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=roles"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=Role""; Name: ""batch-pods-admin"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""Role"" ""metadata"":map[""name"":""batch-pods-admin"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""rules"":[map[""apiGroups"":[""""] ""resources"":[""pods""] ""verbs"":[""get"" ""list"" ""watch"" ""create"" ""update"" ""patch"" ""delete""]] map[""apiGroups"":[""""] ""resources"":[""pods/log""] ""verbs"":[""get""]]]]}; from server for: ""deployment.yaml"": roles.rbac.authorization.k8s.io ""batch-pods-admin"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get roles.rbac.authorization.k8s.io in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=rolebindings"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=RoleBinding""; Name: ""batch-pods-admin",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4609:1463,authoriz,authorization,1463,https://hail.is,https://github.com/hail-is/hail/issues/4609,1,['authoriz'],['authorization']
Security," is implemented on TCP/IP. HTTPS is also implemented on TCP/IP and differs; very mildly. After the socket is opened, a TLS [1] connection is established; over the socket. Thereafter, every HTTP message is encrypted and transported by; the TLS machinery. The HTTP protocol is unchanged. The default port fort HTTP is; 80 and the default port for HTTPS 443, however any port may be used. There are currently four versions of TLS, the latest is TLS 1.3. All versions of; SSL are considered insecure. The OpenSSL library implements TLS. There are other implementations, such as; LibreSSL, but they implement roughly the same interface as OpenSSL. The TLS protocol defines both a scheme for the *encryption of messages* and for; the *authentication of parties*. The protocol defines authentication as; optional. In practice, at least one party presents authentication. For example,; public web servers authenticate themselves to clients but clients do not; reciprocate. ### Authentication; #### X.509 Certificates. TLS uses X.509 Certificates for authentication. X.509 is a rather complicated; standard. X.509 Certificates can be serialized in a variety of ways. We use the; Privacy-enhanced Electronic Mail (PEM) file format for serialization. PEM is; really simple. A file may contain multiple base64-encoded blobs each with a; header and footer of the form:. ```; -----BEGIN LABEL-----; ...; -----END LABEL-----; ```. where `LABEL` describes the data. We only use two labels: `CERTIFICATE` and; `PRIVATE KEY`. An X.509 Certificate is an unforgeable proof of identity. It usually is paired; with a private key that was used to digitally sign the certificate. In the; security literature, an authenticatable entity is usually called a; *principal*. Each principal should have a unique private key. In our system the; principals are both our services (e.g. `batch`, `batch-driver`) and any; non-serving clients (e.g. `test-batch`, `admin-pod`). A key and certificate are; generated ad nihilum by `openssl r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:2334,Certificate,Certificates,2334,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['Certificate'],['Certificates']
Security," line 2, in import_vcf; File ""/tmp/7417fcfbbeee44d0b3f4c0b3750121a7/hail-0.1-es-6.2.4-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, without-vep-520334-sw-rmwj.c.seqr-project.internal): java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:245); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:1937,Checksum,ChecksumFileSystem,1937,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['Checksum'],['ChecksumFileSystem']
Security," merge <code>matchLabels</code> content and replace <code>matchExpressions</code> content. In 1.21, patch requests touching the <code>selector</code> field started replacing the entire selector. This is consistent with server-side apply and the v1 PodDisruptionBudget behavior, but should not have been changed for v1beta1. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108139"">kubernetes/kubernetes#108139</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>) [SIG Auth and Testing]</li>; <li>Fix OpenAPI serialization of the x-kubernetes-validations field (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108030"">kubernetes/kubernetes#108030</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>) [SIG API Machinery]</li>; <li>A new field <code>omitManagedFields</code> has been added to both <code>audit.Policy</code> and <code>audit.PolicyRule</code>; so cluster operators can opt in to omit managed fields of the request and response bodies from; being written to the API audit log. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/94986"">kubernetes/kubernetes#94986</a>, <a href=""https://github.com/tkashem""><code>@​tkashem</code></a>) [SIG API Machinery, Auth, Cloud Provider and Testing]</li>; <li>A small regression in Service updates was fixed. The circumstances are so unlikely that probably nobody would ever hit it. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104601"">kubernetes/kubernetes#104601</a>, <a href=""https://github.com/thockin""><code>@​thockin</code></a>)</li>; <li>Added a feature gate <code>StatefulSetAutoDeletePVC</code>, which allows PVCs automatically created for StatefulSet pods to be automatically deleted. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/99728"">kubernetes/kubernetes#99728</a>, <a href=""https://github.com/mattcary""><code>@​mattcary</code></a>)</li>; <li>Client-go impersonat",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:1896,audit,audit,1896,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['audit'],['audit']
Security," migration works is there are 5 phases:; 1. Compute the expected number of attempts to process for format version < 3. ; 2. Divide the search space into chunks of size 100 attempts (empirically determined this was the best chunk size) and randomize the order of the chunks.; 3. Serially process 5000 chunks with only 10 out of the 100 records as a ""burn in period"" to avoid the birthday problem when trying to insert records in parallel.; 4. In parallel, process all the chunks with 10 way parallelism (empirically determined to max CPU for a 4 core db instance); 5. Do an audit of the results to make sure the attempt resources now has the correct number of rows and the billing is within $0.001 per job with the old way and new way of computing the billing. The tolerance of $0.001 was empirically determined. At a threshold of $0.0001, 33/30,000,000 attempts failed. I think this is good enough as there's always going to be rounding errors. I did not do an explicit audit in the code to make sure the other aggregated_*_resources tables did not change. I spot checked this was correct in my test database. To do the complete audit during the actual migration would take more time. I made sure all the inserts were idempotent. Please double check this. The inserts use a temporary table with an isolation level of read committed. The reason for this is because `INSERT INTO ... SELECT` locks the next gap lock if the isolation level is not read committed. Maybe what I did is overkill and it's no longer a problem with the new burn in period. https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html I'd be interested to hear @danking feedback on what the best query here is to allow parallelism. There are ~30 million attempts that need to be processed for hail-vdc (~60% of the attempts). This will add ~20Gi to the existing database. I use 4 cores to get this migration to be ~3 hours, so we will want to **upgrade the database to 8 cores** while this migration is running. The inserting t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11990:2069,audit,audit,2069,https://hail.is,https://github.com/hail-is/hail/pull/11990,1,['audit'],['audit']
Security," module importer was used, importing modules could fail if the; custom module importer didn't use the latest Python import hook finder/loader; APIs and instead used the deprecated API. This was actually occurring with the; <code>zipimporter</code> in Python itself, which was not updated to use the newer Python; APIs until Python 3.10.</li>; </ul>; <h2>Version 1.14.0</h2>; <p><strong>Bugs Fixed</strong></p>; <ul>; <li>; <p>Python 3.11 dropped <code>inspect.formatargspec()</code> which was used in creating; signature changing decorators. Now bundling a version of this function; which uses <code>Parameter</code> and <code>Signature</code> from <code>inspect</code> module when; available. The replacement function is exposed as <code>wrapt.formatargspec()</code>; if need it for your own code.</p>; </li>; <li>; <p>When using a decorator on a class, <code>isinstance()</code> checks wouldn't previously; work as expected and you had to manually use <code>Type.__wrapped__</code> to access; the real type when doing instance checks. The <code>__instancecheck__</code> hook is; now implemented such that you don't have to use <code>Type.__wrapped__</code> instead; of <code>Type</code> as last argument to <code>isinstance()</code>.</p>; </li>; <li>; <p>Eliminated deprecation warnings related to Python module import system, which; would have turned into broken code in Python 3.12. This was used by the post; import hook mechanism.</p>; </li>; </ul>; <p><strong>New Features</strong></p>; <ul>; <li>Binary wheels provided on PyPi for <code>aarch64</code> Linux systems and macOS; native silicon where supported by Python when using <code>pypa/cibuildwheel</code>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/f2f1a680113d500f525de78da91ae19235efef16""><code>f2f1a68</code></a> Merge branch 'release/1.14.1'</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/97b72d49a8cda771c60065",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12102:1421,access,access,1421,https://hail.is,https://github.com/hail-is/hail/pull/12102,1,['access'],['access']
Security," not require calling &quot;exec&quot;).; Added a way to mimic functools.wraps-generated decorators.; Ported the Continuous Integration from Travis to GitHub.</p>; <h2>4.4.2 (2020-02-29)</h2>; <p>Sylvan Mosberger (<a href=""https://github.com/Infinisil"">https://github.com/Infinisil</a>) contributed a patch to; some doctests that were breaking on NixOS.; John Vandenberg (<a href=""https://github.com/jayvdb"">https://github.com/jayvdb</a>) made a case for removing the usage</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/micheles/decorator/commits/5.1.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=decorator&package-manager=pip&previous-version=4.4.0&new-version=5.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11799:2974,secur,security-vulnerabilities,2974,https://hail.is,https://github.com/hail-is/hail/pull/11799,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," occurred:. Traceback (most recent call last):; File ""/usr/lib/python3/dist-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/usr/lib/python3/dist-packages/pip/commands/install.py"", line 342, in run; requirement_set.prepare_files(finder); File ""/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 821, in unpack_url; hashes=hashes; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 659, in unpack_http_url; hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 882, in _download_http_url; _download_url(resp, link, content_file, hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 603, in _download_url; hashes.check_against_chunks(downloaded_chunks); File ""/usr/lib/python3/dist-packages/pip/utils/hashes.py"", line 46, in check_against_chunks; for chunk in chunks:; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 571, in written_chunks; for chunk in chunks:; File ""/usr/lib/python3/dist-packages/pip/utils/ui.py"", line 139, in iter; for x in it:; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 560, in resp_read; decode_content=False):; File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 436, in stream; data = self.read(amt=amt, decode_content=decode_content); File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 401, in read; raise IncompleteRead(self._fp_bytes_read, self.length_remaining); File ""/usr/lib/python3.6/contextlib.py"", line 99, in __exit__; self.gen.throw(type, value, traceback); File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 307, in _error_catcher; raise ReadTimeoutError(self._pool, Non",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8390:1980,hash,hashes,1980,https://hail.is,https://github.com/hail-is/hail/issues/8390,1,['hash'],['hashes']
Security," of sharing the CloudSQL database server. The areas of change are as follows:. ### Generation of the namespace's database-server-config; The current approach in main does a little trick. Since the current `createDatabase` step uses the `database-server-config` from default to generate admin/user sql configs, the CI pipeline creates a dummy database `test-database-instance` to create a `sql-test-instance-admin-config` that inherits the credentials from the production `database-server-config`, and then copies that within the test namespace to `database-server-config`. In this change, since we are creating the server ourselves, we can just replace these with a step that creates a `database-server-config` from scratch, and then uses that for the DB pod. Overall making these changes really gave me the heebie jeebies that the test and dev namespaces have all these credentials to the CloudSQL server. I'm glad this gets rid of that. ### Accessing the database server; We use the DB pod's service DNS name as the `host` so inside Kubernetes this Just Works. The one caveat is the CI pipeline in which we run migrations in batch jobs. Those jobs need a way to reach the DB pod. I achieve this with a NodePort and then use the job's K8s credentials to resolve the node and port that the DB is on. The code I've added to do this resolution feels a bit janky, wouldn't mind some feedback on that. In terms of security, if a user job was able to somehow resolve the address of a test db, they would still not have the credentials to access it, and this is currently also the case with the production database. Nevertheless, this does raise an action item that we should only allow traffic to the k8s and DB subnets for `network=private` jobs, but I think we should make that a separate PR. ### Database creation; In order to test this properly in a dev deploy, I needed to make some changes to `create_database.py`. In main, dev deploys can't create databases. I think they should be able to, and tho",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13030:1010,Access,Accessing,1010,https://hail.is,https://github.com/hail-is/hail/pull/13030,1,['Access'],['Accessing']
Security," on light</li>; <li><a href=""https://github.com/Textualize/rich/commit/a972ca05522577de2f98eb7c957deead9c87b38f""><code>a972ca0</code></a> changelog</li>; <li><a href=""https://github.com/Textualize/rich/commit/bef0e50b63cf7294ae6c27bf8a79cbe3592599a0""><code>bef0e50</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3130"">#3130</a> from Textualize/fix-table-inline-styles</li>; <li><a href=""https://github.com/Textualize/rich/commit/e30b822ecc264c5c4f984a023124d31d8052de49""><code>e30b822</code></a> Fix markdown table rendering issue.</li>; <li>Additional commits viewable in <a href=""https://github.com/Textualize/rich/compare/v12.6.0...v13.5.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.5.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13651:7144,secur,security-vulnerabilities,7144,https://hail.is,https://github.com/hail-is/hail/pull/13651,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," osgi.version is defined, wrap create-export-pac...</li>; <li><a href=""https://github.com/java-native-access/jna/commit/65cf52803ec2249c61573bdc7bd4314b77c019a0""><code>65cf528</code></a> add utility shell script to create 'Export-Package' metadata</li>; <li><a href=""https://github.com/java-native-access/jna/commit/b3984aaf1bf87c8da2e84797f62180adc405b48a""><code>b3984aa</code></a> Add 'uses' information to OSGI metadata in MANIFEST.MF</li>; <li><a href=""https://github.com/java-native-access/jna/commit/780facdf55b488d504c17183066df6a34531d747""><code>780facd</code></a> Add missing change log entry for libffi update</li>; <li><a href=""https://github.com/java-native-access/jna/commit/5dd4bd707f8f1f49b5d1af158402859a86161367""><code>5dd4bd7</code></a> Merge pull request <a href=""https://redirect.github.com/java-native-access/jna/issues/1491"">#1491</a> from matthiasblaesing/update_libffi</li>; <li><a href=""https://github.com/java-native-access/jna/commit/db1b5531b10fed9fb68d6d4d79913660759b22d3""><code>db1b553</code></a> Merge pull request <a href=""https://redirect.github.com/java-native-access/jna/issues/1490"">#1490</a> from korlibs/feature/direct.mapping.custom.symbol.pr...</li>; <li>Additional commits viewable in <a href=""https://github.com/java-native-access/jna/compare/5.12.1...5.13.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=net.java.dev.jna:jna&package-manager=gradle&previous-version=5.12.1&new-version=5.13.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:5734,access,access,5734,https://hail.is,https://github.com/hail-is/hail/pull/12886,1,['access'],['access']
Security," own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datasets` have been generated to reflect the available datasets in the config file, and `hail/python/hail/docs/datasets.rst` has been updated with the new files as well. Future updates:; - In next PR can add the functionality to automatically determine the users region.; - Also considering modifying the `load_datasets()` function a bit to only require one `version` parameter, to be consistent with the way the version strings are formatted in `annotation_db.json`, and to avoid having to check if the version and reference genome are available separately. Something like this:. ```; mt_1kg = hl.experimental.load_dataset(name='1000_Genomes_autosomes',; version='phase_3-GRCh37', ; region='us'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9496:2311,access,accessible,2311,https://hail.is,https://github.com/hail-is/hail/pull/9496,1,['access'],['accessible']
Security," pervasive (but minor) improvements to Hail's I/O infrastructure. We should start with the egregious examples. Consider `AzureStorageFS.createNoCompression`'s [`OutputStream`](https://github.com/hail-is/hail/blob/main/hail/src/main/scala/is/hail/io/fs/AzureStorageFS.scala#L332-L342):; ```scala; val os: PositionedOutputStream = new FSPositionedOutputStream(4 * 1024 * 1024) {; private[this] val client: BlockBlobClient = blockBlobClient; private[this] val blobOutputStream = client.getBlobOutputStream(true). override def flush(): Unit = {; bb.flip(). if (bb.limit() > 0) {; blobOutputStream.write(bb.array(), 0, bb.limit()); }. bb.clear(); }; // ...; }; ```. Notice how we already have a `ByteBuffer` but we convert it to an array and send that to the OutputStream. Instead, we could just use the [`ByteChannel` methods of `BlockBlobClient`](https://learn.microsoft.com/en-us/java/api/com.azure.storage.blob.specialized.blockblobclient?view=azure-java-stable#com-azure-storage-blob-specialized-blockblobclient-openseekablebytechannelwrite(com-azure-storage-blob-options-blockblobseekablebytechannelwriteoptions)). The [read case also supports a channel](https://learn.microsoft.com/en-us/java/api/com.azure.storage.blob.specialized.blobclientbase?view=azure-java-stable#com-azure-storage-blob-specialized-blobclientbase-openseekablebytechannelread(com-azure-storage-blob-options-blobseekablebytechannelreadoptions-com-azure-core-util-context)). The next, more complicated problem, is the InputBuffer and OutputBuffer interfaces. These assume their sources/sinks are `java.io.InputStream` and `java.io.OutputStream`. Moreover, they too rely on and expose `Array[Byte]` interfaces (e.g. `readBytesArray` and the implementation of `StreamInputBuffer.readBytes`). Let's start with InputBuffer and the decoders and use decoding of VDS variant matrix tables as our benchmark. ```python3; import hail as hl; hl.init(master='local[1]'); vds = hl.vds.read_vds(...); vds.variant_data._force_count_rows(); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13840:1832,expose,expose,1832,https://hail.is,https://github.com/hail-is/hail/issues/13840,1,['expose'],['expose']
Security," push to a `:cache` tag, everyone uses that tag.; 2. List all the tags in the repository and include them all as --cache-from's (this doesn't actually work: https://github.com/moby/moby/issues/34715#issuecomment-425933774); 3. Push a tag for each git SHA and then include as --cache-from's the last ten git SHAs on this branch, the most recent common commit with main (i.e. `git merge-base origin/main this-branch`), maybe the current main, and maybe the PR number?; 4. Write our own OCI image builder so we can write our own OCI image cache that actually works the way it ought to (everything in the registry is considered fair game for the cache). It seems like 3 is actually a decent solution that should enable lots of caching.; 1. The last ten SHAs on the branch should speed up repeated builds when you're fixing little bugs.; 2. The most recent common commit with main should avoid rebuilds unless the packages changed.; 3. I suspect the current main is actually not helpful (either 2 will work or 3 wouldn't help).; 4. Pushing to something like `cache-11907` would allow force pushes to still access the last build's images. What do you think of the #3 proposal? . ---. [1]: I had two files:; ```; # cat sleep/Dockerfile; FROM ubuntu:18.04; RUN sleep 10; # cat touch/Dockerfile; FROM ubuntu:18.04; RUN touch foo; ```; To build I use this command (slightly different syntax from the buildctl syntax, but, AFAIK, uses the same backend):; ```; docker buildx \ ; build \; DIRECTORY_NAME_HERE \; --output 'type=image,""name=gcr.io/hail-vdc/dktest,gcr.io/hail-vdc/dktest:cache"",push=true' \; --cache-to type=inline \; --cache-from type=registry,ref=gcr.io/hail-vdc/dktest; ```; Before every build I clear the _local_ cache with:; ```; docker system prune -a; ```; I can clear the remote cache with:; ```; gcloud container images list-tags gcr.io/hail-vdc/dktest --format=""get(digest)"" \; | awk '{print ""gcr.io/hail-vdc/dktest@"" $1}' \; | xargs gcloud container images delete --force-delete-tags; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11907#issuecomment-1152646800:2657,access,access,2657,https://hail.is,https://github.com/hail-is/hail/pull/11907#issuecomment-1152646800,1,['access'],['access']
Security," pybind11 fixups</li>; <li><a href=""https://github.com/scipy/scipy/commit/843500aabde17aaf1eec65c589d50bd12ee35039""><code>843500a</code></a> Merge pull request <a href=""https://redirect.github.com/scipy/scipy/issues/17689"">#17689</a> from mdhaber/gh17686</li>; <li><a href=""https://github.com/scipy/scipy/commit/089924b61012a106ffa4f58939b0180124051a0b""><code>089924b</code></a> REL: integrate.qmc_quad: remove from release notes</li>; <li><a href=""https://github.com/scipy/scipy/commit/3e47110f10e3267d228e9da84174f3cee325e7c3""><code>3e47110</code></a> REL: 1.10.0rc3 unreleased</li>; <li>Additional commits viewable in <a href=""https://github.com/scipy/scipy/compare/v1.9.3...v1.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=scipy&package-manager=pip&previous-version=1.9.3&new-version=1.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13227:5137,secur,security-vulnerabilities,5137,https://hail.is,https://github.com/hail-is/hail/pull/13227,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," pyzmq 25.1.1.; matplotlib 3.5.3 requires numpy, which is not installed.; matplotlib 3.5.3 requires pillow, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **/1000** <br/> **Why?** | NULL Pointer Dereference <br/>[SNYK-PYTHON-NUMPY-2321964](https://snyk.io/vuln/SNYK-PYTHON-NUMPY-2321964) | `numpy:` <br> `1.21.3 -> 1.22.2` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **/1000** <br/> **Why?** | Buffer Overflow <br/>[SNYK-PYTHON-NUMPY",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13871:1639,Access,Access,1639,https://hail.is,https://github.com/hail-is/hail/pull/13871,1,['Access'],['Access']
Security," recent failure: Lost task 12.3 in stage 103.0 (TID 644994, scc-q21.scc.bu.edu, executor 2): java.io.FileNotFoundException: /scratch/.writeBlocksRDD-l5om7fTy3akZKCYbLDY4AD.crc (Too many open files); at java.io.FileOutputStream.open0(Native Method); at java.io.FileOutputStream.open(FileOutputStream.java:270); at java.io.FileOutputStream.<init>(FileOutputStream.java:213); at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:222); at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209); at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307); at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296); at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328); at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:402); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:778); at is.hail.io.fs.HadoopFS.createNoCompression(HadoopFS.scala:60); at is.hail.io.fs.FS$class.create(FS.scala:151); at is.hail.io.fs.HadoopFS.create(HadoopFS.scala:56); at is.hail.linalg.WriteBlocksRDD$$anonfun$62.apply(BlockMatrix.scala:1838); at is.hail.linalg.WriteBlocksRDD$$anonfun$62.apply(BlockMatrix.scala:1829); at scala.Array$.tabulate(Array.scala:331); at is.hail.linalg.WriteBlocksRDD.compute(BlockMatrix.scala:1829); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403:10631,Checksum,ChecksumFileSystem,10631,https://hail.is,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403,1,['Checksum'],['ChecksumFileSystem']
Security," regression in <code>metadata.managedFields</code> handling in update/patch requests submitted by older API clients (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91748"">kubernetes/kubernetes#91748</a>, <a href=""https://github.com/apelisse""><code>@​apelisse</code></a>)</li>; <li>Scheduler: optionally check for available storage capacity before scheduling pods which have unbound volumes (alpha feature with the new <code>CSIStorageCapacity</code> feature gate, only works for CSI drivers and depends on support for the feature in a CSI driver deployment) (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92387"">kubernetes/kubernetes#92387</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>) [SIG API Machinery, Apps, Auth, Scheduling, Storage and Testing]</li>; <li>Seccomp support has graduated to GA. A new <code>seccompProfile</code> field is added to pod and container securityContext objects. Support for <code>seccomp.security.alpha.kubernetes.io/pod</code> and <code>container.seccomp.security.alpha.kubernetes.io/...</code> annotations is deprecated, and will be removed in v1.22. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91381"">kubernetes/kubernetes#91381</a>, <a href=""https://github.com/pjbgf""><code>@​pjbgf</code></a>) [SIG Apps, Auth, Node, Release, Scheduling and Testing]</li>; <li>ServiceAppProtocol feature gate is now beta and enabled by default, adding new AppProtocol field to Services and Endpoints. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/90023"">kubernetes/kubernetes#90023</a>, <a href=""https://github.com/robscott""><code>@​robscott</code></a>) [SIG Apps and Network]</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/bcfd4ed2ec3b2f503adc4f2e681f9404216d302c""><code>bcfd4ed</code></a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:13431,secur,security,13431,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['secur'],['security']
Security," removed.; Users on older version of OpenSSL will need to upgrade.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Dropped support for LibreSSL &lt; 3.5. The new; minimum LibreSSL version is 3.5.0. Going forward our policy is to support; versions of LibreSSL that are available in versions of OpenBSD that are; still receiving security support.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Removed the <code>encode_point</code> and; <code>from_encoded_point</code> methods on; :class:<code>~cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicNumbers</code>,; which had been deprecated for several years.; :meth:<code>~cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicKey.public_bytes</code>; and; :meth:<code>~cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicKey.from_encoded_point</code>; should be used instead.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for using MD5 or SHA1 in; :class:<code>~cryptography.x509.CertificateBuilder</code>, other X.509 builders, and; PKCS7 has been removed.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Dropped support for macOS 10.10 and 10.11, macOS; users must upgrade to 10.12 or newer.</li>; <li><strong>ANNOUNCEMENT:</strong> The next version of <code>cryptography</code> (40.0) will change; the way we link OpenSSL. This will only impact users who build; <code>cryptography</code> from source (i.e., not from a <code>wheel</code>), and specify their; own version of OpenSSL. For those users, the <code>CFLAGS</code>, <code>LDFLAGS</code>,; <code>INCLUDE</code>, <code>LIB</code>, and <code>CRYPTOGRAPHY_SUPPRESS_LINK_FLAGS</code> environment; variables will no longer be respected. Instead, users will need to; configure their builds <code>as documented here</code>_.</li>; <li>Added support for; :ref:<code>disabling the legacy provider in OpenSSL 3.0.x&lt;legacy-provider&gt;</code>.</li>; <li>Added support for disabling RSA key validation checks when loading RSA; keys via; :func:<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12668:1678,Certificate,CertificateBuilder,1678,https://hail.is,https://github.com/hail-is/hail/pull/12668,4,['Certificate'],['CertificateBuilder']
Security," requirement docutils<0.19, but you have docutils 0.20.1.; notebook 6.5.6 has requirement pyzmq<25,>=17, but you have pyzmq 25.1.1. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low sever",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14026:1522,Access,Access,1522,https://hail.is,https://github.com/hail-is/hail/pull/14026,1,['Access'],['Access']
Security," severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Use After Free <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315324](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315324) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **584/1000** <br/> **Why?** Has a fix available, CVSS 7.4 | Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315328](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315328) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Timing Attack <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315331](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315331) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315452](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315452) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315972](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315972) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:3458,Attack,Attack,3458,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['Attack'],['Attack']
Security," severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Use After Free <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315324](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315324) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **584/1000** <br/> **Why?** Has a fix available, CVSS 7.4 | Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315328](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315328) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Timing Attack <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315331](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315331) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315452](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315452) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315972](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315972) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:3450,Attack,Attack,3450,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['Attack'],['Attack']
Security," severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Timing Attack <br/>[SNYK-PYTHON-RSA-1038401](https://snyk.io/vuln/SNYK-PYTHON-RSA-1038401) | `rsa:` <br> `4.5 -> 4.7` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit . Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhZGQ5ZWQxOC00MjJhLTRkZWUtYWI4Yy01MTkyYmQ4ZmYxMzIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFkZDllZDE4LTQyMmEtNGRlZS1hYjhjLTUxOTJiZDhmZjEzMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""add9ed18-422a-4dee-ab8c-5192bd8ff132"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13975:3088,access,access,3088,https://hail.is,https://github.com/hail-is/hail/pull/13975,2,"['access', 'authoriz']","['access', 'authorized']"
Security," speaking to servers with certs they didn't trust. Now everyone trusts everyone. As long as the root key is not leaked this is OK. Only `create_certs` mounts this secret. The key is used to sign every certificate and the cert is included in each principal's incoming and outgoing trust lists. The root certificate and key are never re-created, so our deploys have no downtime and we avoid addressing the rotation problem. I removed all the trust specifications. A later PR will resolve rotation and mTLS. That PR will restore the trust specifications. I didn't change the structure of the secrets (they still have an incoming and outgoing trust list which only contains the root cert) because I need this structure for mTLS anyway. The original PR text follows. ---. ## HTTPS and TLS. HTTP is implemented on TCP/IP. HTTPS is also implemented on TCP/IP and differs; very mildly. After the socket is opened, a TLS [1] connection is established; over the socket. Thereafter, every HTTP message is encrypted and transported by; the TLS machinery. The HTTP protocol is unchanged. The default port fort HTTP is; 80 and the default port for HTTPS 443, however any port may be used. There are currently four versions of TLS, the latest is TLS 1.3. All versions of; SSL are considered insecure. The OpenSSL library implements TLS. There are other implementations, such as; LibreSSL, but they implement roughly the same interface as OpenSSL. The TLS protocol defines both a scheme for the *encryption of messages* and for; the *authentication of parties*. The protocol defines authentication as; optional. In practice, at least one party presents authentication. For example,; public web servers authenticate themselves to clients but clients do not; reciprocate. ### Authentication; #### X.509 Certificates. TLS uses X.509 Certificates for authentication. X.509 is a rather complicated; standard. X.509 Certificates can be serialized in a variety of ways. We use the; Privacy-enhanced Electronic Mail (PEM) fil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:1543,encrypt,encrypted,1543,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['encrypt'],['encrypted']
Security," str, sampleType: str, individualGuid: str, familyGuid: str, affected_id: int32}>>, struct{z_score: float32}, struct{region_type_ids: array<int32>}, locus<GRCh37>, str, array<struct{amino_acids: str, canonical: int32, codons: str, gene_id: str, hgvsc: str, hgvsp: str, transcript_id: str, biotype_id: int32, consequence_term_ids: array<int32>, is_lof_nagnag: bool, lof_filter_ids: array<int32>, transcript_rank: int32}>, str, int64, struct{PHRED: float32}, struct{alleleId: int32, conflictingPathogenicities: array<struct{pathogenicity_id: int32, count: int32}>, goldStars: int32, pathogenicity_id: int32, assertion_ids: array<int32>}, struct{REVEL_score: float32, VEST4_score: float32, MutPred_score: float32, SIFT_pred_id: int32, Polyphen2_HVAR_pred_id: int32, MutationTaster_pred_id: int32, fathmm_MKL_coding_pred_id: int32}, struct{Eigen_phred: float32}, struct{AF_POPMAX: float32, AF: float32, AC_Adj: int32, AC_Het: int32, AC_Hom: int32, AC_Hemi: int32, AN_Adj: int32}, struct{AF: float32, AN: int32, AC: int32, Hom: int32, AF_POPMAX_OR_GLOBAL: float32, FAF_AF: float32, Hemi: int32}, struct{AF: float32, AN: int32, AC: int32, Hom: int32, AF_POPMAX_OR_GLOBAL: float32, FAF_AF: float32, Hemi: int32}, struct{MPC: float32}, struct{score: float32}, struct{delta_score: float32, splice_consequence_id: int32}, struct{AC: int32, AF: float32, AN: int32, Hom: int32, Het: int32}, struct{accession: str, class_id: int32}, struct{AC: int32, AN: int32, AF: float32, hom: int32}, array<struct{amino_acids: str, canonical: int32, codons: str, gene_id: str, hgvsc: str, hgvsp: str, transcript_id: str, biotype_id: int32, consequence_term_ids: array<int32>, is_lof_nagnag: bool, lof_filter_ids: array<int32>, transcript_rank: int32}>, bool, array<struct{amino_acids: str, canonical: int32, codons: str, gene_id: str, hgvsc: str, hgvsp: str, transcript_id: str, biotype_id: int32, consequence_term_ids: array<int32>, is_lof_nagnag: bool, lof_filter_ids: array<int32>, transcript_rank: int32}>, bool, str""; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13882#issuecomment-1830257465:2504,access,accession,2504,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1830257465,1,['access'],['accession']
Security," tables **by date**. In this PR, I don't try and add the usage to the existing `aggregated_*_resources` tables. I did this to cut down on time and space since we're eventually going to deprecate those tables anyways. Because I don't touch those tables, we don't need to worry about modifying the client code and how the current billing information is calculated. How this migration works is there are 5 phases:; 1. Compute the expected number of attempts to process for format version < 3. ; 2. Divide the search space into chunks of size 100 attempts (empirically determined this was the best chunk size) and randomize the order of the chunks.; 3. Serially process 5000 chunks with only 10 out of the 100 records as a ""burn in period"" to avoid the birthday problem when trying to insert records in parallel.; 4. In parallel, process all the chunks with 10 way parallelism (empirically determined to max CPU for a 4 core db instance); 5. Do an audit of the results to make sure the attempt resources now has the correct number of rows and the billing is within $0.001 per job with the old way and new way of computing the billing. The tolerance of $0.001 was empirically determined. At a threshold of $0.0001, 33/30,000,000 attempts failed. I think this is good enough as there's always going to be rounding errors. I did not do an explicit audit in the code to make sure the other aggregated_*_resources tables did not change. I spot checked this was correct in my test database. To do the complete audit during the actual migration would take more time. I made sure all the inserts were idempotent. Please double check this. The inserts use a temporary table with an isolation level of read committed. The reason for this is because `INSERT INTO ... SELECT` locks the next gap lock if the isolation level is not read committed. Maybe what I did is overkill and it's no longer a problem with the new burn in period. https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html I'd be interested to h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11990:1672,audit,audit,1672,https://hail.is,https://github.com/hail-is/hail/pull/11990,1,['audit'],['audit']
Security," the end of the day, kubernetes does not support this. TCP; probes are the best we can do. There [was a; PR](kubernetes/kubernetes#61231) to allow httpGet probes; to send the kubelet certificate, but it was closed because, apparently, the; [httpGet probes can be targeted at arbitrary IP; addresses](kubernetes/kubernetes#61231 (review)) (what; the hell?), ergo Confused Deputy. ### Future Work. - Require TLS 1.3 everywhere.; - Comply with Mozilla's ""Modern"" recommendations.; - [Incoming Trust](#incoming-trust).; - Refresh certificates after deploying new ones. ### Footnotes. [1] TLS: Transport Layer Security. Preceded by Secure Sockets Layer (SSL) which; is not obsolete and insecure. After SSL version 3, a new version of SSL was; proposed in RFC 2246. This new version was backwards-incompatible and was; thus given a new name: Transport Layer Security. In common discussion, SSL; and TLS are used interchangeable. Indeed, the python TLS library is called; `ssl`. [2] Forward secrecy is a property of an encryption system. Forward secrecy means; a message cannot be decrypted in the future by an adversary who learned one; of the private keys. For example, imagine you are sending sensitive messages; to another individual. If that individual is later coerced into revealing; their secret key, forward secrecy would prevent the coercer from reading; your messages. Forward secrecy is achieved by negotiating a shared private; key between the two parties that is only used for a ""session"" and then; discarded. If the session key is securely discarded and neither key can; recreate it without cooperation from the other key, then *one* leaked key is; insufficient to reveal the messages. ---. Things for you to verify:; - does every service load *its own unqiue* ssl-config secret?; - does every service use an SSL context for serving?; - does everyone who makes http requests to internal services use an SSL client; session?; - do all TLS-secured nginx instances include their http.conf in the ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:11981,encrypt,encryption,11981,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['encrypt'],['encryption']
Security," to latest models</li>; <li><a href=""https://github.com/boto/botocore/commit/7b4b3bbb13a5d59097e6d5f178de58e280fdb553""><code>7b4b3bb</code></a> Resolve endpoint with default partition when no region is set (<a href=""https://github-redirect.dependabot.com/boto/botocore/issues/2818"">#2818</a>)</li>; <li><a href=""https://github.com/boto/botocore/commit/cc3f1c22f55ba50ca792eb73e7a6f721abdcc5ee""><code>cc3f1c2</code></a> Fix: S3 Object Lambda requests miss x-amz-content-sha256 headers (<a href=""https://github-redirect.dependabot.com/boto/botocore/issues/2819"">#2819</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/boto/botocore/compare/1.29.13...1.29.16"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=botocore&package-manager=pip&previous-version=1.29.13&new-version=1.29.16)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12503:3839,secur,security-vulnerabilities,3839,https://hail.is,https://github.com/hail-is/hail/pull/12503,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," use two labels: `CERTIFICATE` and; `PRIVATE KEY`. An X.509 Certificate is an unforgeable proof of identity. It usually is paired; with a private key that was used to digitally sign the certificate. In the; security literature, an authenticatable entity is usually called a; *principal*. Each principal should have a unique private key. In our system the; principals are both our services (e.g. `batch`, `batch-driver`) and any; non-serving clients (e.g. `test-batch`, `admin-pod`). A key and certificate are; generated ad nihilum by `openssl req -new`:. ```; openssl req -new \; -x509; -keyout key_file; -out cert_file; -newkey rsa:4096; -nodes; -subj /CN=example.com; -addext subjectAltName = DNS:www.example.com,DNS:foo.com; ```. The first three arguments are self-explanatory. I explain the rest:. - `-newkey rsa:4096`. TLS supports many different kinds of private keys. This; generates a 4096-bit private key.; - `-nodes`. This should be read as ""no DES"". It means that the private key is not; itself encrypted using DES and a password.; - `-subj /CN=example.com`. This certificate is valid for a server whose DNS name; is `example.com`. If ""hostname checking"" is enabled (web browsers always; enable it), then the client will reject the certificate if the hostname used; to open the socket does not match the certificate.; - `-addext subjectAltName = ...`. This specifies additional acceptable hostnames; for the aformentioned hostname check. #### Trust. An X.509 Certificate only proves that the principal has a private key. On the; world wide web, ownership of a particular domain, e.g. `example.com`, is; guaranteed by a Certificate Authority (CA). A Certificate Authority (like; letsencypt or VeriSign) digitally signs the certificate of a user that has; proven they own the domain name mentioned in the certificate (see above; discussion of `CN` and `subjectAltName`). Web browsers have a file of the ""root""; certificates of the public Certificate Authorities. They establish a ""chain of; t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:3801,encrypt,encrypted,3801,https://hail.is,https://github.com/hail-is/hail/pull/8561,2,"['encrypt', 'password']","['encrypted', 'password']"
Security," using DES and a password.; - `-subj /CN=example.com`. This certificate is valid for a server whose DNS name; is `example.com`. If ""hostname checking"" is enabled (web browsers always; enable it), then the client will reject the certificate if the hostname used; to open the socket does not match the certificate.; - `-addext subjectAltName = ...`. This specifies additional acceptable hostnames; for the aformentioned hostname check. #### Trust. An X.509 Certificate only proves that the principal has a private key. On the; world wide web, ownership of a particular domain, e.g. `example.com`, is; guaranteed by a Certificate Authority (CA). A Certificate Authority (like; letsencypt or VeriSign) digitally signs the certificate of a user that has; proven they own the domain name mentioned in the certificate (see above; discussion of `CN` and `subjectAltName`). Web browsers have a file of the ""root""; certificates of the public Certificate Authorities. They establish a ""chain of; trust"" from a root certificate to the server's certificate. Our system is simpler. We have no root certificate. Each principal has a; certificate which is given to all the principals to which it might; communicate. ### Encryption. TLS has many encryption schemes. I will focus on encryption using a *symmetric*; key because asymmetric schemes do not enable *forward secrecy* [2]. Under; forward secret schemes, the two parties share a private key unknown to all; adversaries. TLS 1.3 makes forward secrecy mandatory. I intend to eventually; require all our services to refuse to speak anything other than TLS 1.3. The shared private key is used to encrypt and decrypt messages sent over a; socket. This poses a problem: how do two parties who have never met each other; agree on a private key without revealing the key to the public? This is a; classic cryptography problem called [key; exchange](https://en.wikipedia.org/wiki/Key_exchange). The classic solution to; this problem is [Diffie-Hellman key; exchange](h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:4814,certificate,certificate,4814,https://hail.is,https://github.com/hail-is/hail/pull/8561,2,['certificate'],['certificate']
Security," via &quot;argsCanBeInterpretedByShell&quot;</li>; <li><a href=""https://github.com/microsoft/debugpy/commit/6b276e339cd850c5f8c93ff4bdbd305dd963d7bb""><code>6b276e3</code></a> Step in/step over support for IPython. Fixes <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/869"">#869</a></li>; <li><a href=""https://github.com/microsoft/debugpy/commit/a294092d9c6d8459126ecb8f537b6012fb7e7d28""><code>a294092</code></a> Properly stop at line 1 in frame eval mode. Fixes <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/995"">#995</a></li>; <li>Additional commits viewable in <a href=""https://github.com/microsoft/debugpy/compare/v1.6.0...v1.6.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=debugpy&package-manager=pip&previous-version=1.6.0&new-version=1.6.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12103:5651,secur,security-vulnerabilities,5651,https://hail.is,https://github.com/hail-is/hail/pull/12103,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=3.20.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12223:4717,secur,security,4717,https://hail.is,https://github.com/hail-is/hail/pull/12223,6,"['Secur', 'secur']","['Security', 'security']"
Security," view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=requests&package-manager=pip&previous-version=2.28.2&new-version=2.31.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13091:9146,secur,security,9146,https://hail.is,https://github.com/hail-is/hail/pull/13091,12,"['Secur', 'secur']","['Security', 'security']"
Security," when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=roles"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=Role""; Name: ""batch-pods-admin"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""Role"" ""metadata"":map[""name"":""batch-pods-admin"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""rules"":[map[""apiGroups"":[""""] ""resources"":[""pods""] ""verbs"":[""get"" ""list"" ""watch"" ""create"" ""update"" ""patch"" ""delete""]] map[""apiGroups"":[""""] ""resources"":[""pods/log""] ""verbs"":[""get""]]]]}; from server for: ""deployment.yaml"": roles.rbac.authorization.k8s.io ""batch-pods-admin"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get roles.rbac.authorization.k8s.io in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=rolebindings"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=RoleBinding""; Name: ""batch-pods-admin-binding"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""RoleBinding"" ""metadata"":map[""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""] ""name"":""batch-pods-admin-binding"" ""namespace"":""batch-pods""] ""roleRef"":map[""apiGroup"":"""" ""kind"":""Role"" ""name"":""batch-pods-admin""] ""subjects"":[map[""kind"":""ServiceAccount"" ""name"":""batch-svc"" ""namespace"":""default""]]]}; from server for: ""deployment.yaml"": rolebindings.rbac.authorization.k8s.io ""batch-pods-admin-binding"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get rolebindings.rbac.authorization.k8s.io in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""apps/v1beta2, Resource=deployments"", GroupVersionK",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4609:2330,authoriz,authorization,2330,https://hail.is,https://github.com/hail-is/hail/issues/4609,1,['authoriz'],['authorization']
Security," which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Heap-based Buffer Overflow <br/>[SNYK-PYTHON-PILLOW-5918878](https://snyk.io/vuln/SNYK-PYTHON-PILLOW-5918878) | `pillow:` <br> `9.5.0 -> 10.0.1` <br> | No | Mature . Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzNTM4YWIwOC03Yzk4LTRjMDUtOTQ0Ny0yMjYwYjliNjhmY2IiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjM1MzhhYjA4LTdjOTgtNGMwNS05NDQ3LTIyNjBiOWI2OGZjYiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""3538ab08-7c98-4c05-9447-2260b9b68fcb"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13708:1702,access,access,1702,https://hail.is,https://github.com/hail-is/hail/pull/13708,2,"['access', 'authoriz']","['access', 'authorized']"
Security," | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Timing Attack <br/>[SNYK-PYTHON-RSA-1038401](https://snyk.io/vuln/SNYK-PYTHON-RSA-1038401) | `rsa:` <br> `4.5 -> 4.7` <br> | No | No Known Exploit . Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxMjk3MjE5NC04YzAyLTRhMjQtYTA0Ni0yZjIxMjk4YjQ2NmEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjEyOTcyMTk0LThjMDItNGEyNC1hMDQ2LTJmMjEyOThiNDY2YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""12972194-8c02-4a24-a046-2f21298b466a"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14134:8195,access,access,8195,https://hail.is,https://github.com/hail-is/hail/pull/14134,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"![Finally.](https://media.giphy.com/media/yIsbuPCEOgNHO/giphy.gif). - update endpoints to handle the ""zen"" that GitHub sends when a web hook is created. - update `make run-local` and friends for the new IP of the `dk-test` micro instance. - remove the unused `refresh_statuses` (this was intended to recover build state from github's commit statuses, but the commit status description is limited to like 120 characters, so I gave up on this a while ago, but never removed the code). - `.strip()` the GitHub token in case there are newlines. - print the SHA being deployed in the log statement. - add `hail-ci-build.sh` to CI, which just invokes `make test-in-cluster`(which in turn runs `test-in-cluster.sh`. - `test-in-cluster.sh` copies the secrets for testing to the expected locations and exposes the pod in which it is running with an internal service, recent changes to `site` [redirect sub URLs of ci.test.is to services named using this scheme](https://github.com/hail-is/hail/blob/master/site/hail.nginx.conf#L38-L41). GitHub uses these URLs to send updates to the CI under test about the watched repositories. - `test-locally.sh` now installs `../batch` into the currently running `pip` before testing (NB: if you edit batch and run the tests without committing the changes you've made to batch, this will pass tests but fail when pushed to a PR!). - `test-locally.sh` activates the `hail-ci` conda environment itself because it was not being propagated from the `Makefile`. I don't know why, but this is a simple fix. - `test-locally.sh` starts the ci after the repository is created. CI will print error messages if a watched repository doesn't exist. - `test/test-ci.py` now uses access tokens for all interaction with GitHub, previously it relied on the latent privileges that I and Cotton had in our environments. - `test/test-ci.py` uses a temporary, but not automatically deleted, directory when the environment variable `IN_CLUSTER` is set to `true` (to which it is set by `test-in-c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4474:793,expose,exposes,793,https://hail.is,https://github.com/hail-is/hail/pull/4474,1,['expose'],['exposes']
Security,""" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""4d1e728e-269c-49a2-a2d0-bf1c04966e29"",""prPublicId"":""4d1e728e-269c-49a2-a2d0-bf1c04966e29"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,509,384,494,539],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14026:6058,validat,validation,6058,https://hail.is,https://github.com/hail-is/hail/pull/14026,3,"['Access', 'access', 'validat']","['Access', 'access-control', 'validation']"
Security,"""""]]}; from server for: ""deployment.yaml"": namespaces ""batch-pods"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get namespaces in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""/v1, Resource=serviceaccounts"", GroupVersionKind: ""/v1, Kind=ServiceAccount""; Name: ""batch-svc"", Namespace: ""batch-pods""; Object: &{map[""kind"":""ServiceAccount"" ""metadata"":map[""name"":""batch-svc"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""apiVersion"":""v1""]}; from server for: ""deployment.yaml"": serviceaccounts ""batch-svc"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get serviceaccounts in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=roles"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=Role""; Name: ""batch-pods-admin"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""Role"" ""metadata"":map[""name"":""batch-pods-admin"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""rules"":[map[""apiGroups"":[""""] ""resources"":[""pods""] ""verbs"":[""get"" ""list"" ""watch"" ""create"" ""update"" ""patch"" ""delete""]] map[""apiGroups"":[""""] ""resources"":[""pods/log""] ""verbs"":[""get""]]]]}; from server for: ""deployment.yaml"": roles.rbac.authorization.k8s.io ""batch-pods-admin"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get roles.rbac.authorization.k8s.io in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=rolebindings"", GroupVersionKind: ""rbac.a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4609:1397,authoriz,authorization,1397,https://hail.is,https://github.com/hail-is/hail/issues/4609,1,['authoriz'],['authorization']
Security,""",""from"":""0.8.4"",""to"":""2.0.3""},{""name"":""nbconvert"",""from"":""5.6.1"",""to"":""6.3.0b0""},{""name"":""notebook"",""from"":""5.7.16"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,531,null,null,null,null,null,null,null,null,null,null,509,null,null,null,null,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13835:10594,validat,validation,10594,https://hail.is,https://github.com/hail-is/hail/pull/13835,1,['validat'],['validation']
Security,""",""from"":""0.8.4"",""to"":""2.0.3""},{""name"":""nbconvert"",""from"":""5.6.1"",""to"":""6.3.0b0""},{""name"":""notebook"",""from"":""5.7.16"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,531,null,null,null,null,null,null,null,null,null,null,509,null,null,null,null,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13866:10620,validat,validation,10620,https://hail.is,https://github.com/hail-is/hail/pull/13866,1,['validat'],['validation']
Security,"""./gradlew"", ""test"", ""shadowJar""]; outputs:; - ""build/libs/hail-all-spark.jar""; - type: exec; name: pytests; image: hail-pr-builder; dependsOn:; - build-jar; command: [""./run-python-tests-using-input-jar.sh""]; ```. A series of steps that get us there:. - [x] (https://github.com/hail-is/hail/pull/5231) jobs may only depend on other jobs in the same batch ; - [x] (https://github.com/hail-is/hail/pull/5232) a batch can be `closed` indicating no more jobs will be added; - [ ] (https://github.com/hail-is/hail/pull/5233) a batch is automatically closed after 30 minutes; - [ ] add ""outputs"" to batch jobs. When a batch job is complete, the batch system copies its outputs to some durable storage (e.g. GCS), this is not user-visible; - [ ] add input/output dependencies to batch jobs. A batch job always receives the output of its parents. The data is copied (somehow) from the durable storage to the pod's filesystem at the path `/input/PARENT_JOB_NAME` and set to permissions 777. The copying is done in a secure way. In particular, the job container can be completely unprivileged (e.g. no credentials in the job's image, no credentials in the mounted volumes, no way to escalate to these credentials); - [ ] parse and run a series of `exec` commands that execute in parallel but no namespace dependencies and no image dependencies. This immediately puts us in a better place wrt logging. All artifacts, such as HTML reports are served through the batch outputs mechanism described above. Job file dependencies are handled exactly as described in input/output dependencies above.; - [ ] allow ""finalizer"" jobs. A finalizer job executes when its parents are all complete or cancelled. It is not cancelled when its parents are cancelled.; - [ ] add namespace dependencies. CI allocates anonymous namespaces as requested by the build process. All `exec`s are, by default, run in an anonymous namespace. CI adds a finalizer job that deletes namespaces when all relevant `exec`s are finished; - [ ] add ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5193:1311,secur,secure,1311,https://hail.is,https://github.com/hail-is/hail/issues/5193,1,['secur'],['secure']
Security,""":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""},{""name"":""wheel"",""from"":""0.30.0"",""to"":""0.38.0""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JINJA2-6150717"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PROMPTTOOLKIT-6141120"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512"",""SNYK-PYTHON-WHEEL-3180413""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,531,null,null,null,null,null,null,null,null,null,null,null,null,509,null,null,null,null,384,494,539,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Cross-site Scripting (XSS)](https://learn.snyk.io/lesson/xss/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14257:12044,validat,validation,12044,https://hail.is,https://github.com/hail-is/hail/pull/14257,4,"['Cross-site Scripting', 'XSS', 'validat', 'xss']","['Cross-site Scripting', 'XSS', 'validation', 'xss']"
Security,""":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""40.5.0"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""},{""name"":""wheel"",""from"":""0.32.2"",""to"":""0.38.0""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JINJA2-6150717"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PROMPTTOOLKIT-6141120"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512"",""SNYK-PYTHON-WHEEL-3180413""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,531,null,null,null,null,null,null,null,null,null,null,null,null,509,null,null,null,null,384,494,539,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Cross-site Scripting (XSS)](https://learn.snyk.io/lesson/xss/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14364:12397,validat,validation,12397,https://hail.is,https://github.com/hail-is/hail/pull/14364,4,"['Cross-site Scripting', 'XSS', 'validat', 'xss']","['Cross-site Scripting', 'XSS', 'validation', 'xss']"
Security,"""global"",; ""reason"": ""forbidden""; }; ]; }; }. 		at com.google.api.client.http.HttpResponseException$Builder.build(HttpResponseException.java:293) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		... 48 more; Caused by: com.google.api.client.http.HttpResponseException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 	at com.google.api.client.http.HttpResponseException$Builder.build(HttpResponseException.java:293) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:27387,access,access,27387,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['access'],['access']
Security,"""hgnc"":""CABIN1"",""consequence"":[""missense_variant""],""hgvsc"":""ENST00000263119.5:c.2558G>A"",""hgvsp"":""ENSP00000263119.5:p.(Arg853Gln)"",""isCanonical"":null,""polyPhenScore"":0.625,""polyPhenPrediction"":""possibly damaging"",""proteinId"":""ENSP00000263119.5"",""proteinPos"":""853"",""siftScore"":0.01,""siftPrediction"":""deleterious""},{""transcript"":""ENST00000405822.2"",""bioType"":""protein_coding"",""aminoAcids"":""R/Q"",""cDnaPos"":""2502"",""codons"":""cGg/cAg"",""cdsPos"":""2408"",""exons"":""17/36"",""introns"":null,""geneId"":""ENSG00000099991"",""hgnc"":""CABIN1"",""consequence"":[""missense_variant""],""hgvsc"":""ENST00000405822.2:c.2408G>A"",""hgvsp"":""ENSP00000384694.2:p.(Arg803Gln)"",""isCanonical"":null,""polyPhenScore"":0.94,""polyPhenPrediction"":""probably damaging"",""proteinId"":""ENSP00000384694.2"",""proteinPos"":""803"",""siftScore"":0.02,""siftPrediction"":""deleterious""},{""transcript"":""ENST00000398319.2"",""bioType"":""protein_coding"",""aminoAcids"":""R/Q"",""cDnaPos"":""2943"",""codons"":""cGg/cAg"",""cdsPos"":""2558"",""exons"":""18/37"",""introns"":null,""geneId"":""ENSG00000099991"",""hgnc"":""CABIN1"",""consequence"":[""missense_variant""],""hgvsc"":""ENST00000398319.2:c.2558G>A"",""hgvsp"":""ENSP00000381364.2:p.(Arg853Gln)"",""isCanonical"":true,""polyPhenScore"":0.625,""polyPhenPrediction"":""possibly damaging"",""proteinId"":""ENSP00000381364.2"",""proteinPos"":""853"",""siftScore"":0.01,""siftPrediction"":""deleterious""},{""transcript"":""ENST00000484593.1"",""bioType"":""retained_intron"",""aminoAcids"":null,""cDnaPos"":null,""codons"":null,""cdsPos"":null,""exons"":null,""introns"":null,""geneId"":""ENSG00000099991"",""hgnc"":""CABIN1"",""consequence"":[""downstream_gene_variant""],""hgvsc"":null,""hgvsp"":null,""isCanonical"":null,""polyPhenScore"":null,""polyPhenPrediction"":null,""proteinId"":null,""proteinPos"":null,""siftScore"":null,""siftPrediction"":null}]},""genes"":null}]}}; ```. I've added the experimental warning until there is some form of automated testing in place (perhaps validating that consistency is maintained against a fixed output file that's been otherwise reviewed by Nirvana). Note that this method is modeled on VEP.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2377#issuecomment-340889701:6447,validat,validating,6447,https://hail.is,https://github.com/hail-is/hail/pull/2377#issuecomment-340889701,1,['validat'],['validating']
Security,"""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyN2MzNWY4NC0yNDIyLTRmNzUtYWMxYy1mODQxOGJmNzRlMzciLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjI3YzM1Zjg0LTI0MjItNGY3NS1hYzFjLWY4NDE4YmY3NGUzNyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""27c35f84-2422-4f75-ac1c-f8418bf74e37"",""prPublicId"":""27c35f84-2422-4f75-ac1c-f8418bf74e37"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.7"",""to"":""42.0.2""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6149518"",""SNYK-PYTHON-CRYPTOGRAPHY-6157248"",""SNYK-PYTHON-CRYPTOGRAPHY-6210214""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[509,581,451],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use of a Broken or Risky Cryptographic Algorithm](https://learn.snyk.io/lesson/insecure-hash/?loc&#x3D;fix-pr); 🦉 [Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [NULL Pointer Dereference](https://learn.snyk.io/lesson/null-dereference/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14234:4498,hash,hash,4498,https://hail.is,https://github.com/hail-is/hail/pull/14234,1,['hash'],['hash']
Security,"""https://github-redirect.dependabot.com/lepture/mistune/issues/307"">#307</a> from jieter/patch-1</li>; <li><a href=""https://github.com/lepture/mistune/commit/0eba47196a81453bafe1f2492748a87475063dff""><code>0eba471</code></a> Fix typo in guide.rst</li>; <li><a href=""https://github.com/lepture/mistune/commit/61e9337884e20f9f8fdc0b7788d319afdd259729""><code>61e9337</code></a> Fix table plugin</li>; <li><a href=""https://github.com/lepture/mistune/commit/76dec68c4514c2612ef9263b49c6ec7f4d77bd14""><code>76dec68</code></a> Add documentation for renderer heading when TOC enabled</li>; <li>Additional commits viewable in <a href=""https://github.com/lepture/mistune/compare/v0.8.4...v2.0.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mistune&package-manager=pip&previous-version=0.8.4&new-version=2.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12066:4191,secur,security-vulnerabilities,4191,https://hail.is,https://github.com/hail-is/hail/pull/12066,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2301"">#2301</a> from jeff-m-sullivan/rscript-path</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/d65016042b67d09139876e1903e839a168dfa7c3""><code>d650160</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2252"">#2252</a> from daschuer/worktree_fix</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/fd0177ae3ae5f94b36aafb54ab496f76fcead7b9""><code>fd0177a</code></a> implement default_install_hook_types</li>; <li>Additional commits viewable in <a href=""https://github.com/pre-commit/pre-commit/compare/v2.17.0...v2.18.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pre-commit&package-manager=pip&previous-version=2.17.0&new-version=2.18.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11731:13110,secur,security-vulnerabilities,13110,https://hail.is,https://github.com/hail-is/hail/pull/11731,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"""https://github.com/PyCQA/pylint/commit/c73353064f934ae49472eb6138e1f8071b6b733e""><code>c733530</code></a> <code>unnecessary-ellipsis</code> false positive: allow ellipsis as default argument (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6"">#6</a>...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/19e6531068cf95d602054ff8638adcb79971d552""><code>19e6531</code></a> Fix crash on unbalanced tuple unpacking</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/2066cab9bbe43341b84014ac9610e275db586431""><code>2066cab</code></a> Bump pylint to 2.13.2, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/6a25d7048edadc18a05e999021049ade86ef2bd9""><code>6a25d70</code></a> Better error message when we cant write the crash files (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5987"">#5987</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c42fe73a1613bbfb52a5ba9129efa45a3fd76401""><code>c42fe73</code></a> Fix false negative for <code>protected-access</code> on functions (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5990"">#5990</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/dec241b1787e6c99a092bb9ef6a993abf51fea91""><code>dec241b</code></a> Add regression test for <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5982"">#5982</a> upgrade astroid to 2.11.2 (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5988"">#5988</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b25859c4a56ccce61087f7a1270f40deaed68169""><code>b25859c</code></a> Fix false positive for <code>superfluous-parens</code> for <code>return (a or b) in iterable</code>...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/0e1ca11ac65cbe5a65437518fca1e25f1ad0e48e""><code>0e1ca11</code></a> Bump pylint to 2.13.1, update changelog</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.12.2...v2.13.3"">compar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11702:3731,access,access,3731,https://hail.is,https://github.com/hail-is/hail/pull/11702,1,['access'],['access']
Security,"""https://github.com/lepture/authlib/releases"">authlib's releases</a>.</em></p>; <blockquote>; <h2>Version 0.15.5</h2>; <ul>; <li>Make Authlib compatible with latest httpx</li>; <li>Make Authlib compatible with latest werkzeug</li>; <li>Allow customize RFC7523 <code>alg</code> value</li>; </ul>; <h2>Version 0.15.4</h2>; <p>Security fix when JWT claims is None.</p>; <p>For example, JWT payload has <code>iss=None</code>:</p>; <pre><code>{; &quot;iss&quot;: None,; ...; }; </code></pre>; <p>But we need to decode it with claims:</p>; <pre><code>claims_options = {; 'iss': {'essential': True, 'values': ['required']}; }; jwt.decode(token, key, claims_options=claims_options); </code></pre>; <p>It didn't raise an error before this fix.</p>; <h2>Version 0.15.3</h2>; <p>Fixed <code>.authorize_access_token</code> for OAuth 1.0 services, via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/308"">lepture/authlib#308</a></p>; <h2>Version 0.15.2</h2>; <p>Fixed httpx authentication bug via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/283"">#283</a></p>; <h2>Version 0.15.1</h2>; <p>Backward compitable fix for using JWKs in JWT, via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/280"">#280</a>.</p>; <h2>Version 0.15</h2>; <p>This is the last release before v1.0. In this release, we added more RFCs; implementations and did some refactors for JOSE:</p>; <ul>; <li>RFC8037: CFRG Elliptic Curve Diffie-Hellman (ECDH) and Signatures in JSON Object Signing and Encryption (JOSE)</li>; <li>RFC7638: JSON Web Key (JWK) Thumbprint</li>; </ul>; <p>We also fixed bugs for integrations:</p>; <ul>; <li>Fixed support for HTTPX&gt;=0.14.3</li>; <li>Added OAuth clients of HTTPX back via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/270"">#270</a></li>; <li>Fixed parallel token refreshes for HTTPX async OAuth 2 client</li>; <li>Raise OAuthError when callback contains errors via <a href=""https://github-redirect.dependa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11483:1131,authenticat,authentication,1131,https://hail.is,https://github.com/hail-is/hail/pull/11483,1,['authenticat'],['authentication']
Security,# Batch Inter-Job File Dependencies. The important addition of this PR is a `copy_service_account_name` field on batch jobs that permits the client to authorize with some GCP credentials stored in a k8s secret. The copy pods and the main pod only share the `/io` folder (k8s forbids mounting a volume as `/`). This interface is pretty onerous. Pipelines will be updated to use this interface. Pipelines is becoming the easy-to-use interface to batch.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5574:151,authoriz,authorize,151,https://hail.is,https://github.com/hail-is/hail/pull/5574,1,['authoriz'],['authorize']
Security,"# Notes On Container Security. Every pod has a [`PodSecurityContext`](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.13/#podsecuritycontext-v1-core) which lets us restrict linux permissions, the linux user id, group id, SELinux policies, and permitted sysctl resources. I suspect for CI purposes non-root user is fine. k8s [already limits](https://kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/) pods to the ""safe"" sysctl resources. Each container in a pod as a [`SecurityContext`](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.13/#securitycontext-v1-core). By default containers have `privileged` set to false, meaning they don't have root-like abilities on the host system. @cseed I don't see anyway for a pod to modify the mounted volumes, *particularly* if has no privileges to access the k8s api. If the volumes it is already given have no credentials that give access to k8s, I don't see how it could possibly ask k8s to mount a volume for it. ---. Containers within a single pod share a network. I have not found anyway to restrict the network access of individual containers. In particular, the [V1Container.md doc file](https://github.com/kubernetes-client/python/blob/master/kubernetes/docs/V1Container.md) states "" Any port which is listening on the default '0.0.0.0' address inside a container will be accessible from the network."" In the case of an initContainer, I don't think this is an issue since the container must terminate before the regular containers start. In the case of a sidecar container waiting for its peer to die so it can copy out results, we must be very careful to not expose any comprisable service on any port. ---. ""ExitContainers"" / ""anti-initContainers"". I think we can pull this off with a second container that polls the k8s API to check if its peer container has died or not. I need to investigate further how much we can limit this API access. Ideally you would only be able to get information about the pod y",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5193#issuecomment-456988573:21,Secur,Security,21,https://hail.is,https://github.com/hail-is/hail/issues/5193#issuecomment-456988573,5,"['Secur', 'access', 'secur']","['Security', 'SecurityContext', 'access', 'securitycontext-']"
Security,"# SRE; - The Google SRE Books https://landing.google.com/sre/books/; - Distributed Systems Observability https://www.oreilly.com/library/view/distributed-systems-observability/9781492033431/; - ""Learning to Build Distributed Systems"" http://brooker.co.za/blog/2019/04/03/learning.html; - Increment's On-Call issue https://increment.com/on-call/; # SWE; - ""Designing Data-Intensive Systems"" by Kleppman https://www.amazon.com/gp/product/1449373321/; # SEC; - ""The Confused Deputy"" http://zoo.cs.yale.edu/classes/cs422/2010/bib/hardy88confused.pdf; - ""Blueprint fo a science of cybersecurity"" http://www.cs.cornell.edu/fbs/publications/SoS.blueprint.pdf; - ""Macaroons: Cookies with Contextual Caveats for Decentralized Authorization in the Cloud"" https://ai.google/research/pubs/pub41892; - ""Native Client: A Sandbox for Portable, Untrusted x86 Native Code"" https://ai.google/research/pubs/pub34913; - What is CSRF https://www.owasp.org/index.php/Cross-Site_Request_Forgery_(CSRF); - What is XSS https://www.owasp.org/index.php/Cross-site_Scripting_(XSS); ## Containers; - gVisor Architecture Guide https://gvisor.dev/docs/architecture_guide/; - ""cgroups"" https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt; - ""cgroups v2"" https://github.com/torvalds/linux/blob/master/Documentation/admin-guide/cgroup-v2.rst; - ""Docker Security"" https://docs.docker.com/engine/security/security/; - ""On the security of containers"" https://medium.com/@ewindisch/on-the-security-of-containers-2c60ffe25a9e; - ""User namespaces might not be enough"" https://medium.com/@ewindisch/linux-user-namespaces-might-not-be-secure-enough-a-k-a-subverting-posix-capabilities-f1c4ae19cad; - ""OS-level virtualization"" https://en.wikipedia.org/wiki/OS-level_virtualisation; - ""Sandbox (computer security)"" https://en.wikipedia.org/wiki/Sandbox_(computer_security); - ""Making Containers More Isolated: An Overview of Sandboxed Container Technologies"" https://unit42.paloaltonetworks.com/making-containers-more-isolated-an-over",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6720:717,Authoriz,Authorization,717,https://hail.is,https://github.com/hail-is/hail/issues/6720,2,"['Authoriz', 'XSS']","['Authorization', 'XSS']"
Security,"## Bug fixes to enable Azure deployment. Most of these bugs were discovered in deploying the MySQL server from scratch, specifically deploying version 8.0. ; Some were encountered when we hit certificate issues in trying to run the `./bootstrap.sh deploy_unmanaged` step multiple times within 24hrs. Documentation was clarified in order to resolve this issue. - build.yaml; - Step one fails on rerun since the /repo directory exists, -p to fix; - ci/create_database.py; - In MySQL 8 a new error was introduced [4006](https://dev.mysql.com/doc/mysql-errors/8.0/en/server-error-reference.html#error_er_cannot_user_referenced_as_definer); - This error gets triggered on the CREATE USER IF NOT EXISTS commands for both user and admin if the user was previously created and set a a definer on any events/triggers.; - Really this statement should be a no-op given that the user exists, but for some reason the error triggers anyway.; - To get around this I added a manual check if the user/admin exists and if they do simply skip the create user command. This fixes the bug and allows the MySQL db deploy to finish properly. - dev-docs/letsencrypt.md; - Debugging was confusing since the revoke command addressed ids we were unable to find.; - After extensive searching I added to the documentation how to find your existing cert IDs if you need to revoke them. - infra/azure/README.md; - Added clarity to the Azure deployment documentation. - infra/azure/bootstrap.sh; - Added the passing of additional flag arguments to terraform; - In our case the passing of the `-upgrade` flag to the terraform init step was required in order to continue. - infra/azure/main.tf, infra/azure/modules/batch/main.tf, infra/azure/modules/batch/variables.tf infra/azure/variables.tf; - Add additional argument for the az_storage_account.; - The name must be globally unique in Azure, so the original argument failed on our deployment since it shared the name with the Hail team's Azure deployment",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12065:192,certificate,certificate,192,https://hail.is,https://github.com/hail-is/hail/pull/12065,1,['certificate'],['certificate']
Security,## Change Description. AWS no longer maintains the Hail on AWS quickstart. This PR removes the reference to this now-broken documentation. ## Security Assessment. - This change has no security impact. ### Impact Description. This PR removes broken documentation. There is no end user impact.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14738:142,Secur,Security,142,https://hail.is,https://github.com/hail-is/hail/pull/14738,2,"['Secur', 'secur']","['Security', 'security']"
Security,"## Change Description. Config and records relating to the appsec deployment instance. Necessary for future maintenance and management of the appsec instance. ## Security Assessment. - This change has no security impact. ### Impact Description. No impact because this relates only to the parallel appsec instance, not the main production instance. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14726:161,Secur,Security,161,https://hail.is,https://github.com/hail-is/hail/pull/14726,3,"['Secur', 'secur']","['Security', 'security']"
Security,"## Change Description. Corrects our gsa-key copying instructions (from #14664) to copy the key contents, not the entire secret metadata. The batch service seems resilient to these badly formed secrets, but the rotate_keys.py script was not. ## Security Assessment. Delete all except the correct answer:; - This change has a low security impact. ### Impact Description. - Not a production change; - Does not add any new information to the secrets, only formats them a useable way. ; - Only in dev namespaces. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14735:244,Secur,Security,244,https://hail.is,https://github.com/hail-is/hail/pull/14735,3,"['Secur', 'secur']","['Security', 'security']"
Security,"## Change Description. Fixes #14597. ## Security Assessment. Delete all except the correct answer:; - This change has a high security impact; - [ ] Required: The impact has been assessed and approved by appsec; - This change has a medium security impact; - This change has a low security impact; - This change has no security impact. ### Impact Description. For none/low impact: a quick one/two sentence justification of the rating.; - Example: ""Docs only"", ""Low-level refactoring of non-security code"", etc.; For medium/high impact: provide a description of the impact and the mitigations in place.; - Example: ""New UI text field added in analogy to existing elements, with input strings escaped and validated against code injection"". (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14745:40,Secur,Security,40,https://hail.is,https://github.com/hail-is/hail/pull/14745,9,"['Secur', 'inject', 'secur', 'validat']","['Security', 'injection', 'security', 'validated']"
Security,## Change Description. Fixes #14597. cancel_after_n_failures = 1; cancels whole job group if one partition fails. ## Security Assessment. - This change has no security impact. ### Impact Description. Unit tests and no interaction on anything secure. (Reviewers: please confirm the security impact before approving),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14747:117,Secur,Security,117,https://hail.is,https://github.com/hail-is/hail/pull/14747,4,"['Secur', 'secur']","['Security', 'secure', 'security']"
Security,"## Change Description. Fixes #<issue_number> (delete if N/A). Brief description and justification of what this PR is doing. ## Security Assessment. Delete all except the correct answer:; - This change has a high security impact; - [ ] Required: The impact has been assessed and approved by appsec; - This change has a medium security impact; - This change has a low security impact; - This change has no security impact. ### Impact Description. For none/low impact: a quick one/two sentence justification of the rating.; - Example: ""Docs only"", ""Low-level refactoring of non-security code"", etc.; For medium/high impact: provide a description of the impact and the mitigations in place.; - Example: ""New UI text field added in analogy to existing elements, with input strings escaped and validated against code injection"". (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14732:127,Secur,Security,127,https://hail.is,https://github.com/hail-is/hail/pull/14732,18,"['Secur', 'inject', 'secur', 'validat']","['Security', 'injection', 'security', 'validated']"
Security,"## Change Description. On windows, gcloud is 'gcloud.cmd' and as such, it needs to be run via the command shell. Other platforms are not affected. This change is in response to Nico Valencia having difficulties running hailctl on Windows. ## Security Assessment. Delete all except the correct answer:; - This change has a medium security impact. ### Impact Description. Technically speaking, this opens up users of `hailctl dataproc` to command injection, but only on platforms where `sys.platform == 'win32'`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14736:242,Secur,Security,242,https://hail.is,https://github.com/hail-is/hail/pull/14736,3,"['Secur', 'inject', 'secur']","['Security', 'injection', 'security']"
Security,"## Change Description. Replacing pyright with pyright[nodejs] in /dev/requirements.txt, allowing for installation of necessary node.js binaries to run pyright when one installs dev requirements. As per https://pypi.org/project/pyright/, pyright needs node to run, but pip installing pyright doesn't also install node. Pyright acknowledges this, and they have a separate pip installation command that will also give you the necessary node binaries to run pyright. We now specify that proper pyright+node install in our requirements.txt. ## Security Assessment. Delete all except the correct answer:; - This change has a low security impact; - [ ] Required: The impact has been assessed and approved by appsec. ### Impact Description. Updating old pyright installation in /dev/requirements.txt, no impact on security-sensitive systems. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14741:539,Secur,Security,539,https://hail.is,https://github.com/hail-is/hail/pull/14741,4,"['Secur', 'secur']","['Security', 'security', 'security-sensitive']"
Security,## Change Description. This PR updates the tutorial instructions for running Hail on Dataproc to clarify that the Google Cloud SDK must be installed and configured before Hail can be run. I made this change to prevent future users from also needing to Google these setup instructions. ## Security Assessment. - This change has no security impact. ### Impact Description. This change only updates documentation and has no immediate end user impact. The updated documentation does not leak any proprietary / confidential / sensitive information about Hail or any related systems.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14737:288,Secur,Security,288,https://hail.is,https://github.com/hail-is/hail/pull/14737,3,"['Secur', 'confidential', 'secur']","['Security', 'confidential', 'security']"
Security,"## Change Description. Updates new developer template to include the need for a Google project role. ## Security Assessment. - This change has no security impact. ### Impact Description. None, documentation change only. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14733:104,Secur,Security,104,https://hail.is,https://github.com/hail-is/hail/pull/14733,3,"['Secur', 'secur']","['Security', 'security']"
Security,"## Change Description. When going through the [documentation for installing Hail on OSX](https://hail.is/docs/0.2/install/macosx.html), I noticed that the syntax for installing Java via Homebrew was out of date. This PR updates the documentation to use the latest syntax for Homebrew. It also updates the command to install version 11 of Temurin instead of version 8. ## Security Assessment. - This change has no security impact. ### Impact Description. This change updates documentation only and has no immediate end user impact. This change updates the recommended version of Temurin to a newer version (11 vs. 8). It is reasonable to assume that the newer version is at least as secure as previous versions. So, there also should be no negative security impact on future users of this documentation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14729:371,Secur,Security,371,https://hail.is,https://github.com/hail-is/hail/pull/14729,4,"['Secur', 'secur']","['Security', 'secure', 'security']"
Security,"## Change Description; - Added ability to check job status in individual jobs in a JobGroup; - Cancel JobGroup if any jobs in the partition fail; - Added test functionality for detecting cancelled, failed jobs; - Query batch for which jobs have failed within a JobGroup, rather than go through every job in the group. ## Security Assessment. Delete all except the correct answer:; - This change has no security impact. ### Impact Description; Mainly just code for testing, nothing security related. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14751:321,Secur,Security,321,https://hail.is,https://github.com/hail-is/hail/pull/14751,4,"['Secur', 'secur']","['Security', 'security']"
Security,## Change Description; Add section on authenticating to GKS+GAR and AKS+ACR and then setting the kubectl context to the appropriate cluster. Note that the one should clean the letsencrypt image files created by make. ## Security Assessment. - This change has no security impact. ### Impact Description. Only documentation changes.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14734:38,authenticat,authenticating,38,https://hail.is,https://github.com/hail-is/hail/pull/14734,3,"['Secur', 'authenticat', 'secur']","['Security', 'authenticating', 'security']"
Security,"## HTTPS and TLS. HTTP is implemented on TCP/IP. HTTPS is also implemented on TCP/IP and differs; very mildly. After the socket is opened, a TLS [1] connection is established; over the socket. Thereafter, every HTTP message is encrypted and transported by; the TLS machinery. The HTTP protocol is unchanged. The default port fort HTTP is; 80 and the default port for HTTPS 443, however any port may be used. There are currently four versions of TLS, the latest is TLS 1.3. All versions of; SSL are considered insecure. The OpenSSL library implements TLS. There are other implementations, such as; LibreSSL, but they implement roughly the same interface as OpenSSL. The TLS protocol defines both a scheme for the *encryption of messages* and for; the *authentication of parties*. The protocol defines authentication as; optional. In practice, at least one party presents authentication. For example,; public web servers authenticate themselves to clients but clients do not; reciprocate. ### Authentication; #### X.509 Certificates. TLS uses X.509 Certificates for authentication. X.509 is a rather complicated; standard. X.509 Certificates can be serialized in a variety of ways. We use the; Privacy-enhanced Electronic Mail (PEM) file format for serialization. PEM is; really simple. A file may contain multiple base64-encoded blobs each with a; header and footer of the form:. ```; -----BEGIN LABEL-----; ...; -----END LABEL-----; ```. where `LABEL` describes the data. We only use two labels: `CERTIFICATE` and; `PRIVATE KEY`. An X.509 Certificate is an unforgeable proof of identity. It usually is paired; with a private key that was used to digitally sign the certificate. In the; security literature, an authenticatable entity is usually called a; *principal*. Each principal should have a unique private key. In our system the; principals are both our services (e.g. `batch`, `batch-driver`) and any; non-serving clients (e.g. `test-batch`, `admin-pod`). A key and certificate are; generated a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:2307,Authenticat,Authentication,2307,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['Authenticat'],['Authentication']
Security,## Security Assessment. Delete all except the correct answer:; - This change has no security impact. ### Impact Description; Docs only,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14730:3,Secur,Security,3,https://hail.is,https://github.com/hail-is/hail/pull/14730,2,"['Secur', 'secur']","['Security', 'security']"
Security,"### Change Description. A convenience template for creating ""add new developer"" issues and documenting the steps required. ### Security Assessment; This change has no security impact. #### Description of the security impact and necessary mitigations:. No impact, only a new github issue creation form. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14719:127,Secur,Security,127,https://hail.is,https://github.com/hail-is/hail/pull/14719,4,"['Secur', 'secur']","['Security', 'security']"
Security,### Change Description. Adds grohli to list of AUTHORIZED_USERS. ### Security Assessment; - [x] This change has a low security impact. (Reviewers: please confirm the security impact before approving),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14716:69,Secur,Security,69,https://hail.is,https://github.com/hail-is/hail/pull/14716,3,"['Secur', 'secur']","['Security', 'security']"
Security,"### Change Description. Adds more logging around CI decisions, to make future debugging of ""why is my PR stuck"" easier to trace through. ### Security Assessment. - [ ] This change has a high security impact; - [ ] Required: and the impact has been assessed and approved by appsec; - [ ] This change has a medium security impact; - [X] This change has a low security impact; - [ ] This change has no security impact. Description of the security impact and necessary mitigations:. Logs-only change in non-user-data-facing component.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14674:141,Secur,Security,141,https://hail.is,https://github.com/hail-is/hail/pull/14674,6,"['Secur', 'secur']","['Security', 'security']"
Security,### Change Description. Corrections and updates to the gcp deploy instructions following a fresh deployment in a brand new project. ### Security Assessment. This change has no security impact. No impact because this does not impact the production system. (Reviewers: please confirm the security impact before approving),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14722:136,Secur,Security,136,https://hail.is,https://github.com/hail-is/hail/pull/14722,3,"['Secur', 'secur']","['Security', 'security']"
Security,"### Change Description. In [09437c5](https://github.com/hail-is/hail/commit/09437c531b47c9af2faa196817c6edeaba17fced), I moved `pytest.ini` up a directory but didn't update the artefacts built in ci.; As a consequence, test stages like `test_unchecked_allocator` have not run since. ### Security Assessment. This change has no security impact",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14721:287,Secur,Security,287,https://hail.is,https://github.com/hail-is/hail/pull/14721,2,"['Secur', 'secur']","['Security', 'security']"
Security,"### Change Description. Jobs within our CI pipeline often invoke `mill` indirectly through `Makefile` prerequisites.; By staging mill's build area to and from `/derived/{release/debug}/hail/out`, mill will not rebuild artefacts from previous steps.; Exposing `MILLOPTS` in `hail/Makefile` allows us to build in CI without a compilation server. ; Using a compilation server may have been why we experienced intermittent failures between building the jar and copying to its final destination.; Note that the `--no-server` option must be the first argument to `millw`. ### Security Assessment; - [x] This change has no security impact. Description of the security impact and necessary mitigations:. Only derived files from the mill + python build process are staged and unstaged.; No secrets or otherwise sensitive information are contained therein. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14709:570,Secur,Security,570,https://hail.is,https://github.com/hail-is/hail/pull/14709,4,"['Secur', 'secur']","['Security', 'security']"
Security,### Change Description. Make the PR template a little easier to work with. ### Security Assessment. - This change has no security impact. Description of the security impact and necessary mitigations:. No impact because this is not code being deployed to production. (Reviewers: please confirm the security impact before approving),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14723:79,Secur,Security,79,https://hail.is,https://github.com/hail-is/hail/pull/14723,4,"['Secur', 'secur']","['Security', 'security']"
Security,### Change Description. Seems like only yesterday that we had #14668. Also removes @illusional as I believe he's no longer in a contributing role (... but please shout out if you disagree! And cc @jmarshall). ### Security Assessment. - [ ] This change has a high security impact; - [ ] Required: and the impact has been assessed and approved by appsec; - [ ] This change has a medium security impact; - [X] This change has a low security impact; - [ ] This change has no security impact. Description of the security impact and necessary mitigations:. Removes entries from the allow-list of contributors and recommended reviewers.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14704:213,Secur,Security,213,https://hail.is,https://github.com/hail-is/hail/pull/14704,6,"['Secur', 'secur']","['Security', 'security']"
Security,### Change Description. The `letsencrypt` inputs to `batch_worker_image` are duplicated (though; the second time were localised to an unreachable location). . ### Security Assessment. - [x] This change has no security impact. Description of the security impact and necessary mitigations:. These files were unreachable from the ci job. (Reviewers: please confirm the security impact before approving),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14712:163,Secur,Security,163,https://hail.is,https://github.com/hail-is/hail/pull/14712,4,"['Secur', 'secur']","['Security', 'security']"
Security,"### Change Description. The changes in #14708 caused our vep images to be rebuilt, breaking them. The solution here is the one that we should have done from the beginning, install dependencies through the system package manager. In the interest of my sanity and effort, I only added the libraries that were being problematic from CPAN to the list of system installed ones. ### Security Assessment; - [x] This change has no security impact",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14713:377,Secur,Security,377,https://hail.is,https://github.com/hail-is/hail/pull/14713,2,"['Secur', 'secur']","['Security', 'security']"
Security,"### Change Description. This change exists as part of larger refactoring work. Herein, I've exchanged; hard-coded contextual strings passed to `ExecutionTimer.time` with implict; contexts, drawing inspiration from scalatest. These contexts are now supplied after entering functions like `Compile` and; `Emit` instead of before (see `ExecuteContext.time`). By sprinking calls to ; `time` throughout the codebase after entering functions, we obtain a nice trace; of the timings with `sourcecode.Enclosing`, minus the previous verbosity. See [1] for more information about what pre-built macros are available. We can; always build our own later. See comments in [pull request id] for example output.; Note that `ExectionTimer.time` still accepts a string to support uses like; `Optimise` and `LoweringPass` where those contexts are provided already.; It is also exception-safe now. This change exposed many similarities between the implementations of query; execution across all three backends. I've stopped short of full unification; which is a greater work, I've instead simplified and moved duplicated result; encoding into the various backend api implementations. More interesting changes are to `ExecuteContext`, which now supports; - `time`, as discussed above; - `local`, a generalisation for temporarily overriding properties of an ; `ExecuteContext` (inspired by [2]). While I've long wanted this for testing,; we were doing some questionable things when reporting timings back to python,; for which locally overriding the `timer` of a `ctx` has been very useful.; We also follow this pattern for local regions. [1] https://github.com/com-lihaoyi/sourcecode; [2] https://hackage.haskell.org/package/mtl-2.3.1/docs/Control-Monad-Reader.html#v:local. ### Security Assessment. This change has no security impact as it's confined to refactoring of existing non-security-related code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14683:891,expose,exposed,891,https://hail.is,https://github.com/hail-is/hail/pull/14683,4,"['Secur', 'expose', 'secur']","['Security', 'exposed', 'security', 'security-related']"
Security,"### Change Description. This is the vep85/grch37 analogue to #14713. ### Security Assessment. - [x] This change has a low security impact. Description of the security impact and necessary mitigations:; Rebuilds a docker image could introduce new vulnerabilities, but in all likelihood, fixes more/more critical vulnerabilities than it would introduce.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14714:73,Secur,Security,73,https://hail.is,https://github.com/hail-is/hail/pull/14714,3,"['Secur', 'secur']","['Security', 'security']"
Security,"### Change Description. `test_dataproc-*` is failing with:; ```; ERROR: (gcloud.dataproc.clusters.create) unrecognized arguments: --public-ip-address (did you mean '--no-address'?) ; ```; Went into the pushed `ci-utils` image, and verified that gcloud didn't have the `--public-ip-address` flag. Version 495 is current and has the flag. ### Security Assessment. - [x] This change has a low security impact",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14707:341,Secur,Security,341,https://hail.is,https://github.com/hail-is/hail/pull/14707,2,"['Secur', 'secur']","['Security', 'security']"
Security,### Description. Creation of a new hail developer account - . Github username - @grohli; Hail username - grohlice. Action items:; - Coordinate with appsec; - Create a new developer account [here](https://auth.hail.is/users); - Add a new authorized CI user [here](https://github.com/hail-is/hail/blob/main/ci/ci/constants.py). ### Security Impact. High. ### Security Impact Description. High because we are granting new administrative privileges. ### Appsec Signoff. - [x] Reviewed and approved,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14718:237,authoriz,authorized,237,https://hail.is,https://github.com/hail-is/hail/issues/14718,3,"['Secur', 'authoriz']","['Security', 'authorized']"
Security,### Description. Creation of a new hail developer account - . Github username - @kasittig kasittig; Hail username - ksittig. Action items:; - Existing developer: Coordinate with appsec; - Existing developer: Create a new developer account - see [here](https://github.com/hail-is/hail/blob/main/dev-docs/services/creating-a-developer-account.md#creating-a-developer-account); - New developer: Create a PR to add yourself as a new CI user (see [here](https://github.com/hail-is/hail/blob/main/ci/ci/constants.py)); - Existing developers: review and approve PR. ### Security Impact. High. ### Security Impact Description. High because a new user will be granted administrative privileges and developer access. ### Appsec Signoff. - [ ] Reviewed and approved,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14728:563,Secur,Security,563,https://hail.is,https://github.com/hail-is/hail/issues/14728,3,"['Secur', 'access']","['Security', 'access']"
Security,"### Description. In this pull request, I add a function to perform a Cochran-Mantel-Haenszel statistical test for association. This pull request closes #13481. ### Testing. I add unit tests. Since I have not used R before (the [associated GitHub issue](https://github.com/hail-is/hail/issues/13481) suggests using R to create test cases), I created the unit tests from examples that I found on the internet. I linked these sources in the code for the unit tests. I built the documentation locally and inspected it to confirm that it matches my expectations. I am having trouble testing the docstring examples locally. When I run `make -C hail doctest-query`, the tests error due to a checksum exception. ### Discussion. ~I have not added an example to the documentation that uses a matrix table yet. (This is an acceptance criteria in #13481.) I wanted to get some advice about the best way to do this. I think ideally, the example would have a binary phenotype, an allele to test for association, and some stratifying variable. I tried to search through the existing code to find suitable example matrix tables in the docstrings, but I didn't find anything promising. I would appreciate help here.~. Update: thanks to @patrick-schultz's recommendation, I have added an example using a matrix table.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14255:684,checksum,checksum,684,https://hail.is,https://github.com/hail-is/hail/pull/14255,1,['checksum'],['checksum']
Security,"### Description. Today our APIs are ""documented"" only through the list of endpoint handlers in implementation code ([example](https://github.com/hail-is/hail/blob/main/batch/batch/front_end/front_end.py#L239)). We can and should:; - Create OpenAPI documentation for our APIs (maybe per-service, maybe once in the gateway?); - Host swagger page/pages for exploring and testing out APIs . ### Security Impact. High. ### Security Impact Description. ""None"" for the creation of documentation, since we do not believe that documenting our APIs is inherently risky. ""High"" for hosting a new functional component on our web endpoints. Mitigating factor: swagger pages are loaded as static html with no need (or ability) to interact with other functional components, except through the same public APIs as are already accessible. ### Appsec Signoff. - [ ] Reviewed and approved",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14725:391,Secur,Security,391,https://hail.is,https://github.com/hail-is/hail/issues/14725,3,"['Secur', 'access']","['Security', 'accessible']"
Security,### Security Assessment. - [x] This change has no security impact,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14701:4,Secur,Security,4,https://hail.is,https://github.com/hail-is/hail/pull/14701,2,"['Secur', 'secur']","['Security', 'security']"
Security,"### Security Assessment. - [x] This change has no security impact. Description of the security impact and necessary mitigations:; This change doesn't change anything that we actually run, we just split the `make_pr_for` step of the release script into its own file.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14715:4,Secur,Security,4,https://hail.is,https://github.com/hail-is/hail/pull/14715,3,"['Secur', 'secur']","['Security', 'security']"
Security,### Security Assessment. This change has no security impact as it just moves code around. (Reviewers: please confirm the security impact before approving),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731:4,Secur,Security,4,https://hail.is,https://github.com/hail-is/hail/pull/14731,3,"['Secur', 'secur']","['Security', 'security']"
Security,"### What happened?. # Problem. A user submitted a Hail Batch batch which read from a bucket whose storage class was ""Archive"". This produced a large unexpected spend because Archive class objects cost 0.05 USD per GB whereas Standard class objects are free. # Solution. Hail Batch and Hail Query should collect the set of buckets which were used as reads, imports, input files, or temporary intermediates and assert that the bucket default storage class is the standard class / hot tier. In Google this is called the [Standard storage class](https://cloud.google.com/storage/docs/storage-classes#standard). In Azure, this is called the [Hot tier](https://learn.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview?tabs=azure-portal). A user should be able to explicitly override this setting with an allowlist. The allowlist should be initialized using Hail's [standard configuration system](https://github.com/hail-is/hail/blob/48d7b5cfbf9a2231d72dd0a1a682da28422fde4b/hail/python/hailtop/config/user_config.py#L42). In Hail Query, this allowlist should be a setting on `hl.init`. In Hail Batch, it should be a setting on `ServiceBackend`. ### Version. 0.2.115. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13003:701,access,access-tiers-overview,701,https://hail.is,https://github.com/hail-is/hail/issues/13003,1,['access'],['access-tiers-overview']
Security,"### What happened?. #13131 Adds the ability for users to authenticate with the hail service using access tokens from their hail identity provider (GCP IAM or Azure AAD) instead of using tokens minted by the hail auth service. It does *not*, however, remove the old form of authentication. There are two actions that must be taken to fully remove the old authentication method:. 1. In #13131, the hail python client attempts to use the new `identity.json` cloud credentials for authentication, but falls back to the old `tokens.json` credentials if present.; 2. The `auth` server still supports the old `/api/v1alpha/login` endpoint. This is unused in the new authentication flow and should ultimately be removed. Removing these old code paths can be done in a two-step process, first with deprecation/warnings (the user need only run `hailctl auth login` to start using the new code paths) and then with removal of the old code paths. This issue is considered complete when the new code paths are removed. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13531:57,authenticat,authenticate,57,https://hail.is,https://github.com/hail-is/hail/issues/13531,6,"['access', 'authenticat']","['access', 'authenticate', 'authentication']"
Security,"### What happened?. > Laura Gauthier: I'm struggling with some DRAGEN data that probably doesn't quite meet the VCF spec. I got the import working, but once I go to split multi-allelics, one of the annotations seems to be the wrong length because I get an array index out of bounds exception. Is there anyway to get more info on the variant that's causing the problem? VCFtool validator found a bunch of issues with FORMAT annotations and I've turned them all into count=1 strings, but there must be something else.; > ...; > Tim Poterba (he/him): yeah, the answer is that this isn't a parse failure, it's a failure of the split_multi_hts method to support haploid sex chromosome calls; > Tim Poterba (he/him): the right plan is to support sex chromosomes The Right Way™ and update all of Hail to infer, track, and use appropriate ploidy but that's not at all what the system looks like right now. ### Version. 0.2.117. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13149:377,validat,validator,377,https://hail.is,https://github.com/hail-is/hail/issues/13149,1,['validat'],['validator']
Security,"### What happened?. After sorting our costs into ""cost of goods"", ""operating expenses"", and ""capital expenses"", I realized there are four ""operating expenses"" that are not tracked and reported with the other expenses. I regressed these costs against the core-hours to estimate the cost per core-hour. resource | intercept (USD) | cost (USD/core-hour); -- | -- | --; GCP Support Variable fee | 3.46403 +- 0.49155 | 0.00123 +- 0.00007; System logs costs SKU#1 | 13.09991 +- 3.13991 | 0.00093 +- 0.00039; System logs costs SKU#2 | 7.87838 +- 0.81695 | 0.00027 +- 0.00012; Job specifications | 5.41150 +- 0.36608 | 0.00025 +- 0.00005; Firewall policy | 0.51216 +- 0.03185 | 0.00012 +- 0.00000. To fully recover the operating expenses at our current revenue, we need an additional 0.005 USD per core-hour (which is 0.002 more than the sum of intercepts). This issue is complete after we add a new product:. resource | cost (USD/core-hour); -- | --; support-logs-specs-and-firewall-fees/1 | 0.005. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13526:631,Firewall,Firewall,631,https://hail.is,https://github.com/hail-is/hail/issues/13526,2,"['Firewall', 'firewall']","['Firewall', 'firewall-fees']"
Security,"### What happened?. Although it is not possible to avoid all cross-region access (and thus costs), there are some obvious preventable misuses. For example, the following pipeline should error:. ```; b = hb.Batch(regions=['us-east1']); x = b.read_input('gs://bucket-in-central1/'); b.new_job(f'cat {x}'); b.run(); ```; But the following pipeline should not error:; ```; b = hb.Batch(regions=['us-east1']); x = b.read_input('gs://bucket-in-central1/'); j = b.new_job(f'cat {x}'); j.regions(['us-central1']); ```; The following should error because the job *could* be in us-east1:; ```; b = hb.Batch(regions=['us-east1', 'us-central1']); x = b.read_input('gs://bucket-in-central1/'); b.new_job(f'cat {x}'); b.run(); ```; The following should error:; ```; b = hb.Batch(regions=['us-east1']) # remote_tmpdir is set in config file as a us-centra1 bucket; j = b.new_job(f'echo hi > {j.f}'); j2 = b.new_job(f'cat {j.f}'); b.run(); ```. ### Version. 0.2.119. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13232:74,access,access,74,https://hail.is,https://github.com/hail-is/hail/issues/13232,1,['access'],['access']
Security,"### What happened?. Batch should expose a job's cloud location to the job. In particular, now that multi-regional buckets charge egress, users needing large numbers of cores will need to manually duplicate their data in multiple regions and then choose the correct data source based on the region in which the job is scheduled. The implementor should consider other options but here is an initial proposal:. 1. Input and output files become dictionaries mapping from location to input/output. (If location is not found in list, job fails).; 2. Main container's file system and environment are populated with information about the location. Implementor should consider whether region, zone, or both should be exposed in GCP. Likewise for Azure regions and AZs. ### References; - https://hail.zulipchat.com/#narrow/stream/127527-team/topic/batch.20cluster/near/417261935 . ### Version. 0.2.127. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14189:33,expose,expose,33,https://hail.is,https://github.com/hail-is/hail/issues/14189,2,['expose'],"['expose', 'exposed']"
Security,"### What happened?. Currently, the `ServiceBackend`'s implementation of collect distributed array submits a job group full of worker jobs (1 per partition) and waits for the job group to complete before reading the results of the worker jobs. For small analyses this is fine, but when a query has tens of thousands of partitions it can take time to schedule and complete all of the worker jobs and reading back those results on the driver can become a bottleneck. Below is one possible solution to this problem:. #### Expose log for job completions in a job group. The Query Driver should attempt to read worker job results while the stage is running, but to do this it needs the Batch API to provide an append-only log of completed jobs in a job group that the Query Driver can consume instead of issuing O(jobs) job status requests during each stage. It may be that this is already possible with the current database schema, but can at worst be achieved by creating an indexed column on jobs that contain the spot they completed in in the job group. . Completion of this feature would require:; - Carefully evaluating the Batch data model to determine if there are any database changes necessary to construct an append-only log of job completions in a job group from the state of the database; - If changes are needed, design and implement a batch front end API endpoint to query the log; - (Separately) Add support for streaming the log in the Scala BatchClient and use it to read partition results before the job group completes. ### Version. 0.2.132. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14607:518,Expose,Expose,518,https://hail.is,https://github.com/hail-is/hail/issues/14607,1,['Expose'],['Expose']
Security,### What happened?. From Mike Wilson on hail zulip [here](https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/hail.200.2E2.2E132.20streamconstraintsexception/near/453934859). > I'm running the new vds combiner on ~340 DRAGEN gVCFs and have hit this error; >; > ```; > Error summary: StreamConstraintsException: String length (20054016) exceeds the maximum length (20000000); > ```. ### Version. 0.2.132. ### Relevant log output. ```shell; Full java stack trace:. Java stack trace:; com.fasterxml.jackson.core.exc.StreamConstraintsException: String length (20054016) exceeds the maximum length (20000000); at com.fasterxml.jackson.core.StreamReadConstraints.validateStringLength(StreamReadConstraints.java:324); at com.fasterxml.jackson.core.util.ReadConstrainedTextBuffer.validateStringLength(ReadConstrainedTextBuffer.java:27); at com.fasterxml.jackson.core.util.TextBuffer.finishCurrentSegment(TextBuffer.java:939); at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._finishString2(UTF8StreamJsonParser.java:2584); at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._finishAndReturnString(UTF8StreamJsonParser.java:2560); at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.getText(UTF8StreamJsonParser.java:335); at is.hail.relocated.org.json4s.jackson.JValueDeserializer._deserialize$1(JValueDeserializer.scala:26); at is.hail.relocated.org.json4s.jackson.JValueDeserializer._deserialize$1(JValueDeserializer.scala:48); at is.hail.relocated.org.json4s.jackson.JValueDeserializer.deserialize(JValueDeserializer.scala:57); at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323); at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:2105); at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1481); at is.hail.relocated.org.json4s.jackson.JsonMethods.parse(JsonMethods.scala:35); at is.hail.relocated.org.json4s.jackson.JsonMethods.parse$(J,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14650:685,validat,validateStringLength,685,https://hail.is,https://github.com/hail-is/hail/issues/14650,2,['validat'],['validateStringLength']
Security,"### What happened?. Google will start to enforce egress fees on Broad multi-region buckets in March 2024. The remaining multi-regional buckets that the hail team pays for are:. ```; ""gs://artifacts.broad-ctsa.appspot.com/""; ""gs://broad/""; ""gs://broad-ctsa-usage-export/""; ""gs://cdv-hail-us/""; ""gs://danking/""; ""gs://dataproc-7f9e9d5e-03bd-4e95-bea1-fe0321239b35-us/""; ""gs://dataproc-temp-us-842871226259-x3fbdioe/""; ""gs://hail/""; ""gs://hail-1kg/""; ""gs://hail-benchmarks-2/""; ""gs://hail-ci/""; ""gs://hail-ci-0-1-dataproc-staging-bucket/""; ""gs://hail-ci-test/""; ""gs://hail-common/""; ""gs://hail-common-coldline/""; ""gs://hail-cseed/""; ""gs://hail-dataproc-deps/""; ""gs://hail-dataproc-images-scratch/""; ""gs://hail-datasets-eu/""; ""gs://hail-datasets-tmp/""; ""gs://hail-datasets-us/""; ""gs://hail-docker-build-0-1/""; ""gs://hail-ekelmins/""; ""gs://hail-eu-vep/""; ""gs://hail-internal/""; ""gs://hail-rnaseq/""; ""gs://hail-test/""; ""gs://hail-tutorial/""; ""gs://hail-us-vep/""; ""gs://hail-wgspd/""; ""gs://jbloom/""; ""gs://jigold/""; ""gs://johnc-seqr-temp-bucket/""; ```. Obtained by running: . ```bash; gcloud storage ls --project broad-ctsa -b -j | jq '.[] | select(.metadata.locationType==""multi-region"") | .url'; ```. These buckets should either be deleted (some are no longer used) or moved to an appropriate region. The appspot bucket is GCR and has been deprecated for months now. It should be unused and can be deleted (but worth checking if it has been accessed recently first). US-based user-facing buckets should probably be moved to `us-central1`. This issue requires no PR and can be closed when no buckets in the `broad-ctsa` and `hail-vdc` projects are multi-regional. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13507:1436,access,accessed,1436,https://hail.is,https://github.com/hail-is/hail/issues/13507,1,['access'],['accessed']
Security,"### What happened?. Hail's google/azure credential classes do not require the caller to specify scopes when requesting access tokens, and thus default to a [very wide set of scopes](https://github.com/hail-is/hail/blob/91f5a0bfc30927014b60b11a353a4d95db009427/hail/python/hailtop/aiocloud/aiogoogle/credentials.py#L140), making those access tokens excessively powerful. An access token does not need to have the `https://www.googleapis.com/auth/appengine.admin` scope to read a blob from GCS. This poses an unnecessary risk if such a token were leaked. These classes should instead require that scopes be specified when requesting an access token, and call sights should specify the minimum set of scopes necessary to perform their function. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13530:119,access,access,119,https://hail.is,https://github.com/hail-is/hail/issues/13530,4,['access'],['access']
Security,### What happened?. I cannot access the hail website.; ![Screenshot 2024-07-16 at 8 03 18 AM](https://github.com/user-attachments/assets/d576c595-d9fd-46fe-b982-3ee58e212ee1). ### Version. 0.2.57. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14616:29,access,access,29,https://hail.is,https://github.com/hail-is/hail/issues/14616,1,['access'],['access']
Security,"### What happened?. In #14675 I replaced `END` with `LEN` in VDS. In doing so, I made sure that both fields were present so as to not break people's existing pipelines. I added a hidden `_drop_end` flag to `read_vds` in order to be able to (mostly in the combiner) not have the `END` field present. This lead to a strange code pattern:. https://github.com/chrisvittal/hail/blob/f39364c177e0b009589826b2c6b3cd36c3ec359d/hail/python/hail/vds/variant_dataset.py#L44-L46. When running the final VDS+VDS merge in [`test_combiner_run`](https://github.com/chrisvittal/hail/blob/f39364c177e0b009589826b2c6b3cd36c3ec359d/hail/python/test/hail/vds/test_combiner.py#L178-L222) on the local backend, this failed with a memory error (in debug mode):. ```; RuntimeException: invalid memory access: 140a68008/00000001: not in 140a58008/00010000; ```. Applying this patch fixed `test_combiner_run`:; ```patch; diff --git a/hail/python/hail/vds/variant_dataset.py b/hail/python/hail/vds/variant_dataset.py; index 0f851e7364..01be83a982 100644; --- a/hail/python/hail/vds/variant_dataset.py; +++ b/hail/python/hail/vds/variant_dataset.py; @@ -41,9 +41,14 @@ def read_vds(; reference_data = hl.read_matrix_table(VariantDataset._reference_path(path), _intervals=intervals); variant_data = hl.read_matrix_table(VariantDataset._variants_path(path), _intervals=intervals). - reference_data = VariantDataset._add_len_end(reference_data); + # if LEN is missing, add it, _add_len is a no-op if LEN is already present; + reference_data = VariantDataset._add_len(reference_data); if _drop_end:; - reference_data = reference_data.drop('END'); + if 'END' in reference_data.entry:; + reference_data = reference_data.drop('END'); + else: # if END is missing, add it, _add_end is a no-op if END is already present; + reference_data = VariantDataset._add_end(reference_data); +; vds = VariantDataset(reference_data, variant_data); if VariantDataset.ref_block_max_length_field not in vds.reference_data.globals:; fs = hl.current_backend",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14705:776,access,access,776,https://hail.is,https://github.com/hail-is/hail/issues/14705,1,['access'],['access']
Security,"### What happened?. Public access buckets typically grant; ```yaml; - members:; - allUsers; role: roles/storage.objectViewer; ```; which permits; ```; resourcemanager.projects.get; resourcemanager.projects.list; storage.managedFolders.get; storage.managedFolders.list; storage.objects.get; storage.objects.list; ```; Notably excluding; ```; storage.buckets.get; ```; Which is necessary for getting metadata like storage class about a bucket. Reported here: https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/No.20storage.2Ebuckets.2Eget.20access.20to.20gs.3A.2F.2Fhail-common. ### Version. 0.2.127. ### Relevant log output. Example code:; ```; rg37.add_sequence(; ""gs://hail-common/references/human_g1k_v37.fasta.gz"",; ""gs://hail-common/references/human_g1k_v37.fasta.fai""; ); ```. ```; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.127-bb535cd096c5; LOGGING: writing to /Users/mkanai/Dropbox/Workspace/github.com/mkanai/immune_v2f/python/hail-20240214-1046-0.2.127-bb535cd096c5.log; Traceback (most recent call last):; File ""/Users/mkanai/Dropbox/Workspace/github.com/mkanai/immune_v2f/python/annotate_base_editing_variants.py"", line 21, in <module>; rg37.add_sequence(; File ""<decorator-gen-34>"", line 2, in add_sequence; File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hail/genetics/reference_genome.py"", line 390, in add_sequence; Env.backend().add_sequence(self.name, fasta_file, index_file); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hail/backend/service_backend.py"", line 548, in add_sequence; self.validate_file(blob); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hail/backend/service_backen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14291:27,access,access,27,https://hail.is,https://github.com/hail-is/hail/issues/14291,1,['access'],['access']
Security,### What happened?. Reported here: https://discuss.hail.is/t/how-to-capture-summarize-outputs/3348/2. Maybe make it easier to return the `Summary` object from `ht.x.summarize()` so you can access its `summ_fields`?. ### Version. 0.2.114. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12943:189,access,access,189,https://hail.is,https://github.com/hail-is/hail/issues/12943,1,['access'],['access']
Security,"### What happened?. See #13489 for context. We want to use terraform to keep track of artifact registry cleanup policies once it is available in Terraform. Relevant links:; https://github.com/hashicorp/terraform-provider-google-beta/commit/bc4aa512356891f78415d5f309bfe47b0697ac11; https://github.com/hashicorp/terraform-provider-google/issues/13824. It's not in 4.79.0 (see [what was added since then](https://github.com/hashicorp/terraform-provider-google-beta/compare/v4.79.0...main)). Releases appear to happen ~once a week, so we should be able to import into terraform in September. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13504:192,hash,hashicorp,192,https://hail.is,https://github.com/hail-is/hail/issues/13504,3,['hash'],['hashicorp']
Security,"### What happened?. See [Batch Metadata Server RFC](https://github.com/hail-is/hail-rfcs/blob/main/rfc/0012-keyless-job-auth.rst) for background. The objective of this issue is to fully remove GSA key files from Batch job filesystems, preventing possible exfiltration of long-lived credentials. Each remaining task should get its own issue if there isn't already one. Breakdown of tasks:. - [X] Implement a Batch metadata server and expose it in GCP `DockerJob`s (#14019); - [ ] Add metadata server support for `JVMJob`s aka Query-on-Batch in GCP (#14487); - [ ] Add metadata server support in Azure; - [ ] Deprecate and remove support for key files in `DockerJob`s; - [ ] Deprecate and remove support for key files in `JVMJob`s. This requires dropping support for old versions of hail that depend on the key file (up to and including at least 0.2.130). These steps get us past the security milestone of not exposing GSA key files to jobs and risking exfiltration. We might be able to go even further and get rid of key files entirely, which would reduce our operational burden of securing and rotating them.; - [ ] In GCP, use Service Account Impersonation to have the Batch Worker identity impersonate user GSAs, allowing it to create metadata server access tokens without the key files themselves; - [ ] In Azure, investigate if something like the above is even possible. At time of writing, it does not appear that there is an alternative other than storing credentials or adding users to the VM's metadata server. It is unclear whether this can be done dynamically and with what frequency and feels like not their intended use case. ### Version. 0.2.130. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14486:433,expose,expose,433,https://hail.is,https://github.com/hail-is/hail/issues/14486,4,"['access', 'expose', 'secur']","['access', 'expose', 'securing', 'security']"
Security,"### What happened?. Semantic hash assumes the params.files is a list of concrete file paths but it is a list of file paths with glob expressions. Consider the following example. Part of this ticket must also determine why this was not caught by `test_glob`.; ```; (base) dking@wm28c-761 hail % gsutil cp ./src/test/resources/ldprune2.vcf gs://danking/chr1.vcf; Copying file://./src/test/resources/ldprune2.vcf [Content-Type=text/x-vcard]...; / [1 files][ 11.5 KiB/ 11.5 KiB] ; Operation completed over 1 objects/11.5 KiB. ; (base) dking@wm28c-761 hail % gsutil cp ./src/test/resources/ldprune2.vcf gs://danking/chr2.vcf; Copying file://./src/test/resources/ldprune2.vcf [Content-Type=text/x-vcard]...; / [1 files][ 11.5 KiB/ 11.5 KiB] ; Operation completed over 1 objects/11.5 KiB. ; (base) dking@wm28c-761 hail % ipython ; Python 3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.16.1 -- An enhanced Interactive Python. Type '?' for help. In [1]: import hail as hl; ...: hl.import_vcf('gs://danking/chr*.vcf').count(); Initializing Hail with default parameters...; /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:29: UserWarning: You have specified the GCS requester pays configuration in both your spark-defaults.conf (/Users/dking/miniconda3/lib/python3.10/site-packages/pyspark/conf/spark-defaults.conf) and either an explicit argument or through `hailctl config`. For GCS requester pays configuration, Hail first checks explicit arguments, then `hailctl config`, then spark-defaults.conf.; warnings.warn(; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/Users/dking/miniconda3/lib/python3.10/site-packages/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13915:29,hash,hash,29,https://hail.is,https://github.com/hail-is/hail/issues/13915,1,['hash'],['hash']
Security,"### What happened?. Since we guarantee a job will run at least once, there are two issues that can happen:. 1. A user can write a pipeline in which two jobs race to write the same file, e.g.; ```; j = b.new_job(); j.command('echo hello > {j.out}'); j.write_output(j.out, ""gs://bucket/final-output""); ```; 2. Or, a clever user can avoid this race with some randomness:; ```; j = b.new_job(); j.command('echo hello gsutil cp - gs://bucket/final-output-$RANDOM'); ```. The former is a really common pattern and a bit of a footgun! The latter is rare (I don't know anyone who does it) and hard to work with: how would you know the output file of the *successful* attempt?. Hail should provide some mechanism for a user to get the list of successful attempts and their outputs. One simple option is to include some kind of seeded randomness which the user can access and to return either the seed or all the draws of the successful attempt for each job in `/jobs` or for the one job in `/job/{job_id}`. For example, consider:. ```; j = b.new_job(); j.command('echo hello gsutil cp - gs://bucket/final-output-$(/hail-random-str)'); ```. Where `/hail-random-str` is a binary we mount into the container that randomly generates numbers seeded by `(batch id, job id, attempt id)`. Hail should use the same randomness to ensure that `write_output` is reliable. We might also want a way to automatically remove the output files of the non-successful (e.g. preempted) attempts. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13502:855,access,access,855,https://hail.is,https://github.com/hail-is/hail/issues/13502,1,['access'],['access']
Security,"### What happened?. The Batch UI should only show the most recent 50 batches that the user has submitted, but I suspect there is a flaw in the search query that is doing a full scan on one of the main tables. Searching for `user = ci` in the Batch UI nearly times out. First thing I would do here is get the SQL query that is run for `user = ci` (can hopefully do this in `ipython`) and run an `EXPLAIN` against the database. That should hopefully expose a `WHERE` condition that could be re-written to use an existing index or at worst add an index for. ### Version. 0.2.131. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14599:448,expose,expose,448,https://hail.is,https://github.com/hail-is/hail/issues/14599,1,['expose'],['expose']
Security,"### What happened?. The infrastructure necessary to run a Hail Batch deployment (network, buckets, DB, Kubernetes cluster) are managed through Terraform in `infra/gcp` and `infra/azure`. In order to migrate terraform resources, the terraform module need to be given input variables specific to our deployment provided through a `global.tfvars` file. Since this file contains secrets, in GCP we encrypt the file with [SOPS](https://github.com/getsops/sops) and check it into the repo so that any developer with the credentials to our deployment can run the terraform. This is not the case in Azure, so if a developer wants to run the Azure terraform they have to obtain the `global.tfvars` from myself. We should use the same strategy for communicating this file as we do in GCP. ### Version. 0.2.129. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14457:394,encrypt,encrypt,394,https://hail.is,https://github.com/hail-is/hail/issues/14457,1,['encrypt'],['encrypt']
Security,"### What happened?. Try running a job with `_machine_type: 'n1-highmem-64'`. This is necessary to get enough memory for some larger jobs (> ~200GB). Startup on the batch worker fails because the job is calculating how many theoretical network namespaces it could support (4 per CPU, 64 CPUS, plus some for JVMs), but not considering that the IPv4 schema puts a hard limit of 255 on namespaces if only one subnet value is changing each time. ### Version. Live 7/30/24. ### Relevant log output. _No response_. ### Security considerations:. Low risk of impacting security. High CPU machine types are not materially different from others with respect to security considerations, and the bug is a simple logic error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14644:512,Secur,Security,512,https://hail.is,https://github.com/hail-is/hail/issues/14644,3,"['Secur', 'secur']","['Security', 'security']"
Security,"### What happened?. Try writing to a bucket to which your service account has read-only access:; ```; hl.utils.range_table(5,n_partitions=5).write('gs://neale-bge/foo.ht'); ```. https://batch.hail.is/batches/8042383. The client gets an error like this:; ```; Java stack trace:; is.hail.relocated.com.google.cloud.storage.StorageException: 404 Not Found; GET https://storage.googleapis.com/download/storage/v1/b/1-day/o/parallelizeAndComputeWithIndex%2FO3mcL5QoyfBBMz0eSi7uIjGQkV3FuD5vCON_8i4r0ss=%2Fresult.0?alt=media; No such object: 1-day/parallelizeAndComputeWithIndex/O3mcL5QoyfBBMz0eSi7uIjGQkV3FuD5vCON_8i4r0ss=/result.0; 	at is.hail.relocated.com.google.cloud.storage.StorageException.translate(StorageException.java:165); 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:298); 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.load(HttpStorageRpc.java:729); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.lambda$readAllBytes$20(StorageImpl.java:610); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103); 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at is.hail.relocated.com.google.cloud.storage.Retrying.run(Retrying.java:65); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.run(StorageImpl.java:1515); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.readAllBytes(StorageImpl.java:610); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.readAllBytes(StorageImpl.java:599); 	at is.hail.io.fs.GoogleStorageFS.$anonfun$readNoCompression$1(GoogleStorageFS.scala:280); 	at is.hail.services.package$.retryTransientErrors(package.scala:182); 	at is.hail.io.fs.GoogleStorageFS.readNoCompression(GoogleStorageFS.scala:278); 	at is.hail.io.fs.RouterFS.readNoCompression(RouterFS.scala:25); 	at is.hail.backend.service.ServiceBac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:88,access,access,88,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['access'],['access']
Security,"### What happened?. Using Google Dataproc Apache Spark cluster. We're getting access to the source paths now. ```python3. import hail as hl; hl.init(default_reference='GRCh38'); marazita_mt_path = # ...; hapmap_snps_path = # ...; marazita_mt = hl.read_matrix_table(marazita_mt_path, _n_partitions=500); hapmap_snps = (hl.import_table(hapmap_snps_path, ; impute = True, ; no_header=True)); hapmap_snps = hapmap_snps.annotate(interval = hl.locus_interval(hapmap_snps.f0,; hapmap_snps.f1,; hapmap_snps.f2)); hapmap_snps = hapmap_snps.annotate(locus = hapmap_snps.f0 + ':' + hl.str(hapmap_snps.f1)); hapmap_snps = hapmap_snps.annotate(locus = hl.locus(hapmap_snps.f0, hapmap_snps.f1)); hapmap_snps = hapmap_snps.key_by(hapmap_snps.locus); hapmap_snps.count(); marazita_mt.count(); marazita_hapmap = marazita_mt.filter_rows(hl.is_defined(hapmap_snps[marazita_mt.locus])); # Here is where the number of variants changed prior to writing out the hapmap keyed mt; # other numbers I got: 1498507, 1498499, 1498506; # I am still getting more SNPs than prior to intersection; # I would expect it to be less than the 1437453 in hapmap; marazita_hapmap.count(); ```. ### Version. 0.2.122-be9d88a80695. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13689:78,access,access,78,https://hail.is,https://github.com/hail-is/hail/issues/13689,1,['access'],['access']
Security,"### What happened?. When using logistic regression, the null model tells me about the relationship between my covariates and the phenotype(s). In particular, if my covariates perfectly predict my phenotype, the model will fail to converge on every row. Investigating this situation demands access to the null model.; ```; import hail as hl; mt = hl.utils.range_matrix_table(3,3); mt = mt.annotate_entries(prod = mt.row_idx * mt.col_idx); hl.logistic_regression_rows('wald', y=[hl.bool(mt.col_idx)], x=mt.prod, covariates=[1.0]).describe(); ```. When using the Query-on-Spark backend, I receive no access to the null model parameters:; ```; ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'row_idx': int32 ; 'logistic_regression': array<struct {; beta: float64, ; standard_error: float64, ; z_stat: float64, ; p_value: float64, ; fit: struct {; n_iterations: int32, ; converged: bool, ; exploded: bool; }; }> ; ----------------------------------------; Key: ['row_idx']; ----------------------------------------; ```. In contrast, the Query-on-Batch backend exposes this information:; ```; Global fields:; 'null_fits': array<struct {; b: ndarray<float64, 1>, ; score: ndarray<float64, 1>, ; fisher: ndarray<float64, 2>, ; mu: ndarray<float64, 1>, ; n_iterations: int32, ; log_lkhd: float64, ; converged: bool, ; exploded: bool; }> ; ```. The Query-on-Spark backend should expose the same information for the benefit of the user. ### Version. 0.2.124. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13789:290,access,access,290,https://hail.is,https://github.com/hail-is/hail/issues/13789,4,"['access', 'expose']","['access', 'expose', 'exposes']"
Security,### What happened?. [Open ID Connect](https://auth0.com/docs/authenticate/protocols/openid-connect-protocol) is a standard that allows you to basically exchange a proof of identity from identity provider X for an authorized token at identity provider Y. We should support using GCP credentials + OIDC to copy files to and from AWS and Azure. We should then remove the AWS and Azure keys from our GCP deployment that are used to run inter-cloud copy tests. ### Version. 0.2.122. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13613:61,authenticat,authenticate,61,https://hail.is,https://github.com/hail-is/hail/issues/13613,2,"['authenticat', 'authoriz']","['authenticate', 'authorized']"
Security,"### What happened?. [SAIGE](https://github.com/weizhouUMICH/SAIGE) and its competitor [REGENIE](https://rgcgithub.github.io/regenie/) are the standard bearers for modern GWAS. Hail should expose SAIGE within the Hail Query language. The interface should roughly match `hl.linear_regression_rows`. A Batch pipeline would serve the needs of Broadies (and, indeed, such a pipeline already exists) but has two downsides:; 1. There is substantial I/O involved in exporting the data from Hail-native formats to SAIGE-compatible formats.; 2. Non-Broadies cannot use this pipeline. Query language support for SAIGE would transform the accessibility of SAIGE by making it usable at scale by anyone with access to Hail, which is basically anyone with a large dataset (e.g. [DNANexus](https://med.stanford.edu/gbsc/projects/vapahcs.html), [AoU RWB](https://support.researchallofus.org/hc/en-us/articles/6090679838100-How-to-Work-with-All-of-Us-Genomic-Data-Hail-Plink-), [MVP](https://med.stanford.edu/gbsc/projects/vapahcs.html), [FinnGen](https://www.medrxiv.org/content/10.1101/2022.03.03.22271360v1.full)). There are two options:; 1. Determine and implement the linear algebraic primitives necessary for SAIGE.; 2. Compile and link directly against SAIGE. Expose these functions, via JNI, to the Hail Query language. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13442:188,expose,expose,188,https://hail.is,https://github.com/hail-is/hail/issues/13442,4,"['Expose', 'access', 'expose']","['Expose', 'access', 'accessibility', 'expose']"
Security,"### What happened?. [reporter's note: IIRC, exit code 137 indicates that the ""container"" in which the worker JVM was executing exceeded memory limits. It seems likely that whole stage codegen has either (1) changed memory management in a way that uses more memory or (2) is newly lowering code that exposes a latent issue in memory management that uses too much (or leaks) memory.]. Reported by Ben Weisburd and Julia Goodrich. [Ben is] running the first step of readviz for gnomAD v4 and we are hitting a 137 error on a partition that includes a site that has 27374 alleles. His code is [here](https://github.com/broadinstitute/gnomad-readviz/blob/step1_optimizations/step1__select_samples.py). I was testing his code out on just that failing partition (just added mt = vds.variant_data._filter_partitions([41229])) and I was able to recreate the error using Hail 0.2.119 (this is what Ben was using when he hit the error on the full dataset). However, the first time I tried to recreate the error I was accidentally using a different version of Hail and it ran with no memory error. It seems that 0.2.117 runs without error, but 0.2.118 and 0.2.119 both hit the 137 error. I am currently rerunning these tests so I can get logs:. Test with Hail 0.2.118:. Cluster:; ```; hailctl dataproc start readviz-118 \; --requester-pays-allow-all \; --packages=""git+https://github.com/broadinstitute/gnomad_methods.git@main"",""git+https://github.com/broadinstitute/gnomad_qc.git@main"" \; --autoscaling-policy=max-20 \; --master-machine-type n1-highmem-16 \; --no-off-heap-memory \; --worker-machine-type n1-highmem-8 \; --max-idle 560m \; --labels gnomad_release=gnomad_v4,gnomad_v4_testing=readviz_test_118; ```; Command:; ```; hailctl dataproc submit readviz-118 /Users/jgoodric/PycharmProjects/gnomad-readviz/step1__select_samples.py --sample-metadata-tsv gs://gnomad-readviz/v4.0/gnomad.exomes.v4.0.metadata.tsv.gz --output-ht-path gs://gnomad-tmp/julia/readviz/gnomad.exomes.v4.0.readviz_crams.part_41229.ha",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13248:299,expose,exposes,299,https://hail.is,https://github.com/hail-is/hail/issues/13248,1,['expose'],['exposes']
Security,"### What happened?. `hail-0.2.129-py3-none-any.whl` bundled a version of `hailtop/hailctl/deploy.yaml` that was intended for internal testing only. This file provides configuration variables for `hailctl`. The file in [0.2.129](https://github.com/hail-is/hail/releases/tag/0.2.129) pointed to cloud resources in `gs://hail-30-day/` that cause commands like `hailctl dataproc start` to fail due to one of the following:; - the user does not have access to `gs://hail-30-day`, or; - the resources have been deleted according to the bucket's 30-day lifecycle policy. ### Version. 0.2.129. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14452:445,access,access,445,https://hail.is,https://github.com/hail-is/hail/issues/14452,1,['access'],['access']
Security,"### What happened?. `hailctl dataproc start` fails with an error message like the one below because [in Dataproc 2.2](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/network#:~:text=Internal%20addresses%20only%20(no%2Daddress)%20is%20set%20by%20default%20when%20creating%20a%20Dataproc%202.2%20image%20version%20cluster.%20You%20can%20use%20the%20gcloud%20dataproc%20clusters%20create%20%2D%2Dpublic%2Dip%2Daddress%20flag%20to%20enable%20public%20IP%20addresses.), clusters are created without public internet access by default. A workaround is to pass the `--public-ip-address` flag to the command. Error message:. ```python; pip packages are ['setuptools', 'mkl<2020', 'lxml<5', 'https://github.com/hail-is/jgscm/archive/v0.1.13+hail.zip', 'ipykernel==6.22.0', 'ipywidgets==8.0.6', 'jupyter-console==6.6.3', 'nbconvert==7.3.1', 'notebook==6.5.6', 'qtconsole==5.4.2', 'aiodns==2.0.0', 'aiohttp==3.9.5', 'aiosignal==1.3.1', 'async-timeout==4.0.3', 'attrs==23.2.0', 'avro==1.11.3', 'azure-common==1.1.28', 'azure-core==1.30.2', 'azure-identity==1.17.1', 'azure-mgmt-core==1.4.0', 'azure-mgmt-storage==20.1.0', 'azure-storage-blob==12.20.0', 'bokeh==3.3.4', 'boto3==1.34.138', 'botocore==1.34.138', 'cachetools==5.3.3', 'certifi==2024.6.2', 'cffi==1.16.0', 'charset-normalizer==3.3.2', 'click==8.1.7', 'commonmark==0.9.1', 'contourpy==1.2.1', 'cryptography==42.0.8', 'decorator==4.4.2', 'deprecated==1.2.14', 'dill==0.3.8', 'frozenlist==1.4.1', 'google-auth==2.31.0', 'google-auth-oauthlib==0.8.0', 'humanize==1.1.0', 'idna==3.7', 'isodate==0.6.1', 'janus==1.0.0', 'jinja2==3.1.4', 'jmespath==1.0.1', 'jproperties==2.1.1', 'markupsafe==2.1.5', 'msal==1.29.0', 'msal-extensions==1.2.0', 'msrest==0.7.1', 'multidict==6.0.5', 'nest-asyncio==1.6.0', 'numpy==1.26.4', 'oauthlib==3.2.2', 'orjson==3.10.6', 'packaging==24.1', 'pandas==2.2.2', 'parsimonious==0.10.0', 'pillow==10.4.0', 'plotly==5.22.0', 'portalocker==2.10.0', 'protobuf==3.20.2', 'py4j==0.10.9.7', 'pyasn1==0.6.0', 'pyasn1-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14652:531,access,access,531,https://hail.is,https://github.com/hail-is/hail/issues/14652,1,['access'],['access']
Security,"### What happened?. `hl.maximal_independent_set` should return the same independent set regardless of the ordering of the input table. gnomAD team reports that the returned set can differ depending on whether or not the input table had been written or came directly from PC-Relate. I have yet to create a simple reproducible example. Permuting the entries in this array does not change the output. I always get 'a' and 'b'. I suspect this is because what really matters is the order in which we traverse the entries of the multi map which depends on the hash of the nodes. I think a durable fix might be to eliminate the MultiMap, insert all the nodes into the binary heap, then increment priority for each edge detected. This will perform more reflows of the heap, but eliminates the non-determinism of MultiMap iteration order. ```; import hail as hl; ht = hl.Table.parallelize([; hl.Struct(i=hl.Struct(s=x[0]), j=hl.Struct(s=x[1])); for x in [('c', 'a'), ('a', 'b'), ('b', 'c'), ]; ]); hl.maximal_independent_set(ht.i, ht.j, False).collect(); ```. ### Version. 0.2.122. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13635:554,hash,hash,554,https://hail.is,https://github.com/hail-is/hail/issues/13635,1,['hash'],['hash']
Security,### What happened?. https://discuss.hail.is/t/matrixtable-filter-rows-produces-error-for-data-on-secure-lustre/3344/2. Seems like we drop the file:// scheme at some point when generating code that uses PartitionNativeIntervalReader. ### Version. ????. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13998:97,secur,secure-lustre,97,https://hail.is,https://github.com/hail-is/hail/issues/13998,1,['secur'],['secure-lustre']
Security,"### What happened?. ~~I have a PR that proposes something roughly along these lines: https://github.com/hail-is/hail/pull/13057/files It has some problems:~~; ~~1. It should use a cron job.~~; ~~2. The last time I ran this code, I'm pretty sure I deleted things I shouldn't have. We should audit the `find-expired-images.py` code again.~~. We should probably just use https://cloud.google.com/artifact-registry/docs/repositories/cleanup-policy. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13441:290,audit,audit,290,https://hail.is,https://github.com/hail-is/hail/issues/13441,1,['audit'],['audit']
Security,"#133</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/133"">brettcannon/gidgethub#133</a>).</li>; <li>Make the minimum version of PyJWT be v2.0.0.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/brettcannon/gidgethub/blob/main/docs/changelog.rst"">gidgethub's changelog</a>.</em></p>; <blockquote>; <h2>5.2.1</h2>; <ul>; <li>; <p>Fix cgi and importlib_resources deprecations.; (<code>PR [#185](https://github.com/brettcannon/gidgethub/issues/185) &lt;https://github.com/brettcannon/gidgethub/pull/185&gt;_</code>)</p>; </li>; <li>; <p>Add support for Python 3.11 and drop EOL Python 3.6; (<code>PR [#184](https://github.com/brettcannon/gidgethub/issues/184) &lt;https://github.com/brettcannon/gidgethub/pull/184&gt;_</code>)</p>; </li>; </ul>; <h2>5.2.0</h2>; <ul>; <li>Make the minimum version of PyJWT be v2.4.0.</li>; </ul>; <h2>5.1.0</h2>; <ul>; <li>; <p>Use <code>X-Hub-Signature-256</code> header for webhook validation when available.; (<code>PR [#160](https://github.com/brettcannon/gidgethub/issues/160) &lt;https://github.com/brettcannon/gidgethub/pull/160&gt;</code>_).</p>; </li>; <li>; <p>The documentation is now built using Sphinx v&gt;= 4.0.0.; (<code>Issue [#143](https://github.com/brettcannon/gidgethub/issues/143) &lt;https://github.com/brettcannon/gidgethub/issues/143&gt;</code>_)</p>; </li>; <li>; <p>:meth:<code>gidgethub.abc.GitHubAPI.getiter</code> now accepts <code>iterable_key</code> parameter; in order to support the Checks API.; (<code>Issue [#164](https://github.com/brettcannon/gidgethub/issues/164) &lt;https://github.com/brettcannon/gidgethub/issues/164&gt;</code>_)</p>; </li>; <li>; <p>Accept HTTP 202 ACCEPTED as successful.; (<code>PR [#174](https://github.com/brettcannon/gidgethub/issues/174) &lt;https://github.com/brettcannon/gidgethub/pull/174&gt;</code>_)</p>; </li>; </ul>; <h2>5.0.1</h2>; <ul>; <li>Drop the <code>machine-man-preview</code> ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:4937,validat,validation,4937,https://hail.is,https://github.com/hail-is/hail/pull/12328,1,['validat'],['validation']
Security,"#7246</a>; [radarhere]</p>; </li>; <li>; <p>Added ImageFont.MAX_STRING_LENGTH <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7244"">#7244</a>; [radarhere, hugovk]</p>; </li>; <li>; <p>Fix Windows build with pyproject.toml <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7230"">#7230</a>; [hugovk, nulano, radarhere]</p>; </li>; <li>; <p>Do not close provided file handles with libtiff <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7199"">#7199</a>; [radarhere]</p>; </li>; <li>; <p>Convert to HSV if mode is HSV in getcolor() <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7226"">#7226</a>; [radarhere]</p>; </li>; <li>; <p>Added alpha_only argument to getbbox() <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7123"">#7123</a>; [radarhere. hugovk]</p>; </li>; <li>; <p>Prioritise speed in <em>repr_png</em> <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7242"">#7242</a>; [radarhere]</p>; </li>; <li>; <p>Do not use CFFI access by default on PyPy <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7236"">#7236</a>; [radarhere]</p>; </li>; <li>; <p>Limit size even if one dimension is zero in decompression bomb check <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7235"">#7235</a>; [radarhere]</p>; </li>; <li>; <p>Use --config-settings instead of deprecated --global-option <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7171"">#7171</a>; [radarhere]</p>; </li>; <li>; <p>Better C integer definitions <a href=""https://redirect.github.com/python-pillow/Pillow/issues/6645"">#6645</a>; [Yay295, hugovk]</p>; </li>; <li>; <p>Fixed finding dependencies on Cygwin <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7175"">#7175</a>; [radarhere]</p>; </li>; <li>; <p>Changed grabclipboard() to use PNG instead of JPG compression on macOS <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7219"">#7219</a>; [abey79, radarhere]</p>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13321:10838,access,access,10838,https://hail.is,https://github.com/hail-is/hail/pull/13321,1,['access'],['access']
Security,"#PdhEnumObjectItems (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/99fcfa822db86b1f2ba5823dbf17efeb3d246ad5""><code>99fcfa8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1444"">#1444</a> from matthiasblaesing/update_libffi</li>; <li><a href=""https://github.com/java-native-access/jna/commit/9e473350a5ad5e04aab8b01e4018f973976e19f8""><code>9e47335</code></a> Update CHANGES.md</li>; <li>Additional commits viewable in <a href=""https://github.com/java-native-access/jna/compare/5.6.0...5.12.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=net.java.dev.jna:jna&package-manager=gradle&previous-version=5.6.0&new-version=5.12.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:8120,secur,security-vulnerabilities,8120,https://hail.is,https://github.com/hail-is/hail/pull/12438,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,$$evalNoTypeCheck$1.apply(Parser.scala:64); 	at is.hail.expr.Parser$$anonfun$parseTypedExpr$1.apply(Parser.scala:102); 	at scala.Function0$class.apply$mcJ$sp(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcJ$sp(AbstractFunction0.scala:12); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:81); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:79); 	at is.hail.utils.BinaryHeap.isLeftFavoredTie(BinaryHeap.scala:16); 	at is.hail.utils.BinaryHeap.is$hail$utils$BinaryHeap$$bubbleUp(BinaryHeap.scala:161); 	at is.hail.utils.BinaryHeap.insert(BinaryHeap.scala:40); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:101); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:100); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:100); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:86); 	at is.hail.utils.Graph.maximalIndependentSet(Graph.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnectio,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3704:2530,Hash,HashTable,2530,https://hail.is,https://github.com/hail-is/hail/pull/3704,1,['Hash'],['HashTable']
Security,"$1.apply$mcVI$sp(DAGScheduler.scala:1543); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1457); at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply$mcVI$sp(DAGScheduler.scala:723); at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:723); at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:723); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.doCancelAllJobs(DAGScheduler.scala:723); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onError(DAGScheduler.scala:1741); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:52); 2019-01-22 13:12:06 AbstractConnector: INFO: Stopped Spark@1433e9ec{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-01-22 13:12:06 SparkUI: INFO: Stopped Spark web UI at http://10.48.225.55:4040; 2019-01-22 13:12:06 DAGScheduler: INFO: Job 0 failed: fold at RVD.scala:603, took 14.445174 s; 2019-01-22 13:12:06 DAGScheduler: INFO: ResultStage 0 (fold at RVD.scala:603) failed in 14.237 s due to Stage cancelled because SparkContext was shut down; 2019-01-22 13:12:06 root: ERROR: SparkException: Job 0 cancelled because SparkContext was shut down; From org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down; at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:205688,Hash,HashSet,205688,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['Hash'],['HashSet']
Security,$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.mutable.ListBuffer.$plus$eq,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:2604,Hash,HashMap,2604,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Hash'],['HashMap']
Security,$anonfun$apply$2$$anonfun$apply$3.apply(Graph.scala:60); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2$$anonfun$apply$3.apply(Graph.scala:54); 	at is.hail.utils.package$.using(package.scala:587); 	at is.hail.annotations.Region$.scoped(Region.scala:20); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2.apply(Graph.scala:54); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2.apply(Graph.scala:53); 	at is.hail.utils.BinaryHeap.isLeftFavoredTie(BinaryHeap.scala:16); 	at is.hail.utils.BinaryHeap.is$hail$utils$BinaryHeap$$bubbleUp(BinaryHeap.scala:161); 	at is.hail.utils.BinaryHeap.insert(BinaryHeap.scala:40); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:91); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:90); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:90); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:76); 	at is.hail.utils.Graph.maximalIndependentSet(Graph.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4857:4315,Hash,HashTable,4315,https://hail.is,https://github.com/hail-is/hail/issues/4857,1,['Hash'],['HashTable']
Security,$anonfun$runWithDelayedValues$1.apply(CM.scala:84); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:82); 	at is.hail.expr.Parser$$anonfun$is$hail$expr$Parser$$evalNoTypeCheck$1.apply(Parser.scala:64); 	at is.hail.expr.Parser$$anonfun$parseTypedExpr$1.apply(Parser.scala:102); 	at scala.Function0$class.apply$mcJ$sp(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcJ$sp(AbstractFunction0.scala:12); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:81); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:79); 	at is.hail.utils.BinaryHeap.isLeftFavoredTie(BinaryHeap.scala:16); 	at is.hail.utils.BinaryHeap.is$hail$utils$BinaryHeap$$bubbleUp(BinaryHeap.scala:161); 	at is.hail.utils.BinaryHeap.insert(BinaryHeap.scala:40); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:101); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:100); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:100); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:86); 	at is.hail.utils.Graph.maximalIndependentSet(Graph.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at p,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3704:2339,Hash,HashMap,2339,https://hail.is,https://github.com/hail-is/hail/pull/3704,1,['Hash'],['HashMap']
Security,"$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: org.apache.spark.sql.catalyst.expressions.GenericRow is not a valid external type for schema of boolean; named_struct(contig, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 0, contig), StringType), true), start, validateexternaltype(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 1, start), IntegerType), ref, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexte",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1260:7555,validat,validateexternaltype,7555,https://hail.is,https://github.com/hail-is/hail/issues/1260,2,['validat'],['validateexternaltype']
Security,"$run$2.apply$mcV$sp(TaskResultGetter.scala:139); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply(TaskResultGetter.scala:124); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply(TaskResultGetter.scala:124); at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:124); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```; `pyhail-submit`:; ```bash; #!/bin/bash. if [ $# -ne 2 ]; then; echo 'usage: gcp-pyhail-submit <cluster> <py-file>'; exit 1; fi. cluster=$1; script=$2. echo cluster = $cluster; echo script = $script. HASH=`gsutil cat gs://hail-common/latest-hash.txt`. JAR_FILE=hail-hail-is-master-all-spark2.0.2-$HASH.jar; JAR=gs://hail-common/$JAR_FILE. PYHAIL_ZIP=gs://hail-common/pyhail-hail-is-master-$HASH.zip. gcloud dataproc jobs submit pyspark \; $script \; --cluster $cluster \; --files=$JAR \; --py-files=$PYHAIL_ZIP \; --properties=""spark.driver.extraClassPath=./$JAR_FILE,spark.executor.extraClassPath=./$JAR_FILE"" \; --; ```; cluster JSON:; ```; {; ""projectId"": ""broad-ctsa"",; ""clusterName"": ""cluster-2"",; ""config"": {; ""configBucket"": ""dataproc-7f9e9d5e-03bd-4e95-bea1-fe0321239b35-us"",; ""gceClusterConfig"": {; ""zoneUri"": ""https://www.googleapis.com/compute/v1/projects/broad-ctsa/zones/us-central1-f"",; ""networkUri"": ""https://www.googleapis.com/compute/v1/projects/broad-ctsa/global/networks/default"",; ""serviceAccountScopes"": [; ""https://www.googleapis.com/auth/bigquery"",; ""https://www.googleapis.com/auth/bigtable.admin.table"",; ""https://www.googleapis.com/auth/bigtable.data"",; ""https://www.googleapis.com/auth/cloud.useraccounts.readonly"",; ""https://www.googleapis.com/auth/devstorage.full_control"",; ""https://www.googleapis.com/auth/devstorage.read_write"",; ""http",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027:2842,HASH,HASH,2842,https://hail.is,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027,1,['HASH'],['HASH']
Security,"', inputs, ir=ir, progress=progress); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 449, in _rpc; result_bytes = await retry_transient_errors(self._read_output, ir, iodir + '/out'); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 774, in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 787, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 475, in _read_output; raise reconstructed_error.maybe_user_error(ir); hail.utils.java.FatalError: SocketException: Connection reset. Java stack trace:; javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:2892,secur,security,2892,https://hail.is,https://github.com/hail-is/hail/issues/12982,1,['secur'],['security']
Security,"', inputs, ir=ir, progress=progress); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 451, in _rpc; result_bytes = await retry_transient_errors(self._read_output, ir, iodir + '/out'); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 779, in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 792, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 477, in _read_output; raise reconstructed_error.maybe_user_error(ir); hail.utils.java.FatalError: SocketException: Connection reset. Java stack trace:; javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:3780,secur,security,3780,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,'hailtop/hailctl/dataproc/diagnose.py'; adding 'hailtop/hailctl/dataproc/gcloud.py'; adding 'hailtop/hailctl/dataproc/modify.py'; adding 'hailtop/hailctl/dataproc/start.py'; adding 'hailtop/hailctl/dataproc/submit.py'; adding 'hailtop/hailctl/dataproc/utils.py'; adding 'hailtop/hailctl/dev/__init__.py'; adding 'hailtop/hailctl/dev/ci_client.py'; adding 'hailtop/hailctl/dev/cli.py'; adding 'hailtop/hailctl/dev/config.py'; adding 'hailtop/hailctl/hdinsight/__init__.py'; adding 'hailtop/hailctl/hdinsight/cli.py'; adding 'hailtop/hailctl/hdinsight/start.py'; adding 'hailtop/hailctl/hdinsight/submit.py'; adding 'hailtop/utils/__init__.py'; adding 'hailtop/utils/filesize.py'; adding 'hailtop/utils/process.py'; adding 'hailtop/utils/rate_limiter.py'; adding 'hailtop/utils/rates.py'; adding 'hailtop/utils/rich_progress_bar.py'; adding 'hailtop/utils/serialization.py'; adding 'hailtop/utils/time.py'; adding 'hailtop/utils/utils.py'; adding 'hailtop/utils/validate/__init__.py'; adding 'hailtop/utils/validate/validate.py'; adding 'hail-0.2.124.dist-info/METADATA'; adding 'hail-0.2.124.dist-info/WHEEL'; adding 'hail-0.2.124.dist-info/entry_points.txt'; adding 'hail-0.2.124.dist-info/top_level.txt'; adding 'hail-0.2.124.dist-info/RECORD'; emoving build/bdist.linux-x86_64/wheel; python3 -m pip install 'pip-tools==6.13.0' && bash ../check_pip_requirements.sh python; Defaulting to user installation because normal site-packages is not writeable; Collecting pip-tools==6.13.0; Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:28824,validat,validate,28824,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,2,['validat'],['validate']
Security,'may or may not' is redundant phrasing. The word 'may' is sufficient to indicate the optional nature of glob expressions in the `path` argument to `import_vcf`. ## Security Assessment; - This change has no security impact. ### Impact Description; Docs only,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14746:164,Secur,Security,164,https://hail.is,https://github.com/hail-is/hail/pull/14746,2,"['Secur', 'secur']","['Security', 'security']"
Security,"(2021-01-31)</h1>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h1>2.10.0 (2021-12-30)</h1>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; <h1>2.9.0 (2019-11-04)</h1>; <ul>; <li>Fix memcached expiring time (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/398"">#398</a>)</li>; </ul>; <h1>2.8.0 (2019-09-17)</h1>; <ul>; <li>Make this compatible with Python 3.7+. Import from collections.abc, instead; of from collections. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/373"">#373</a>)</li>; </ul>; <h1>2.7.0 (2018-10-13)</h1>; <ul>; <li>; <p>Reset a session if the session age &gt; max_age (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/331"">#331</a>)</p>; </li>; <li>; <p>Reset a session on TTL expiration for EncryptedCookieStorage (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/326"">#326</a>)</p>; </li>; </ul>; <h1>2.6.0 (2018-09-12)</h1>; <ul>; <li>Create a new session if <code>NaClCookieStorage</code> cannot decode a; corrupted cookie (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/317"">#317</a>)</li>; </ul>; <h1>2.5.0 (2018-05-12)</h1>; <ul>; <li>Add an API for requesting new session explicitly (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/281"">#281</a>)</li>; </ul>; <h1>2.4.0 (2018-05-04)</h1>; <ul>; <li>Fix a bug for session fixation (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/272"">#272</a>)</li>; </ul>; <h1>2.3.0 (2018-02-13)</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/af05608",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11577:1790,Encrypt,EncryptedCookieStorage,1790,https://hail.is,https://github.com/hail-is/hail/pull/11577,1,['Encrypt'],['EncryptedCookieStorage']
Security,"(<a href=""https://redirect.github.com/pallets/jinja/issues/1918"">#1918</a>)</li>; <li><a href=""https://github.com/pallets/jinja/commit/19a55db3b411343309f2faaffaedbb089e841895""><code>19a55db</code></a> Make nested-trans-block exceptions nicer</li>; <li><a href=""https://github.com/pallets/jinja/commit/716795349a41d4983a9a4771f7d883c96ea17be7""><code>7167953</code></a> Merge pull request from GHSA-h5c8-rqwp-cp95</li>; <li><a href=""https://github.com/pallets/jinja/commit/7dd3680e6eea0d77fde024763657aa4d884ddb23""><code>7dd3680</code></a> xmlattr filter disallows keys with spaces</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/jinja/compare/3.1.2...3.1.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jinja2&package-manager=pip&previous-version=3.1.2&new-version=3.1.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14144:3549,secur,security-vulnerabilities,3549,https://hail.is,https://github.com/hail-is/hail/pull/14144,6,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"(<a href=""https://redirect.github.com/urllib3/urllib3/issues/3009"">urllib3/urllib3#3009</a>)</li>; </ul>; <h2>2.0.1</h2>; <ul>; <li>Fixed a socket leak when fingerprint or hostname verifications fail. (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2991"">#2991</a>)</li>; <li>Fixed an error when <code>HTTPResponse.read(0)</code> was the first <code>read</code> call or when the internal response body buffer was otherwise empty. (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2998"">#2998</a>)</li>; </ul>; <h2>2.0.0</h2>; <p>Read the <a href=""https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html"">v2.0 migration guide</a> for help upgrading to the latest version of urllib3.</p>; <h1>Removed</h1>; <ul>; <li>Removed support for Python 2.7, 3.5, and 3.6 (<a href=""https://redirect.github.com/urllib3/urllib3/issues/883"">#883</a>, <a href=""https://redirect.github.com/urllib3/urllib3/issues/2336"">#2336</a>).</li>; <li>Removed fallback on certificate <code>commonName</code> in <code>match_hostname()</code> function. This behavior was deprecated in May 2000 in RFC 2818. Instead only <code>subjectAltName</code> is used to verify the hostname by default. To enable verifying the hostname against <code>commonName</code> use <code>SSLContext.hostname_checks_common_name = True</code> (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2113"">#2113</a>).</li>; <li>Removed support for Python with an <code>ssl</code> module compiled with LibreSSL, CiscoSSL, wolfSSL, and all other OpenSSL alternatives. Python is moving to require OpenSSL with PEP 644 (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2168"">#2168</a>).</li>; <li>Removed support for OpenSSL versions earlier than 1.1.1 or that don't have SNI support. When an incompatible OpenSSL version is detected an <code>ImportError</code> is raised (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2168"">#2168</a>).</li>; <li>Removed the list of default ciphers for OpenSSL 1.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13768:3672,certificate,certificate,3672,https://hail.is,https://github.com/hail-is/hail/pull/13768,3,['certificate'],['certificate']
Security,(MapLike.scala:228); at scala.collection.AbstractMap.default(Map.scala:59); at scala.collection.mutable.HashMap.apply(HashMap.scala:65); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply$mcVJ$sp(TaskSchedulerImpl.scala:243); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:235); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:235); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:234); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.TaskSchedulerImpl.cancelTasks(TaskSchedulerImpl.scala:234); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply$mcVI$sp(DAGScheduler.scala:1543); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGSched,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:200312,Hash,HashMap,200312,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['Hash'],['HashMap']
Security,(RegionValueBuilder.scala:298); 	at is.hail.annotations.RegionValueBuilder.addAnnotation(RegionValueBuilder.scala:541); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2$$anonfun$apply$3.apply(Graph.scala:60); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2$$anonfun$apply$3.apply(Graph.scala:54); 	at is.hail.utils.package$.using(package.scala:587); 	at is.hail.annotations.Region$.scoped(Region.scala:20); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2.apply(Graph.scala:54); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2.apply(Graph.scala:53); 	at is.hail.utils.BinaryHeap.isLeftFavoredTie(BinaryHeap.scala:16); 	at is.hail.utils.BinaryHeap.is$hail$utils$BinaryHeap$$bubbleUp(BinaryHeap.scala:161); 	at is.hail.utils.BinaryHeap.insert(BinaryHeap.scala:40); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:91); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:90); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:90); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:76); 	at is.hail.utils.Graph.maximalIndependentSet(Graph.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.Abstract,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4857:4157,Hash,HashMap,4157,https://hail.is,https://github.com/hail-is/hail/issues/4857,1,['Hash'],['HashMap']
Security,"(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 0, contig), StringType), true), start, validateexternaltype(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 1, start), IntegerType), ref, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 2, ref), StringType), true), altAlleles, mapobjects(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object), if (isnull(validateexternaltype(lambdavariable(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object)), StructField(ref,StringType,false), StructField(alt,StringType,false)))) null else named_struct(ref, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexternaltype(lambdavariable(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object)), StructFiel",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1260:8539,validat,validateexternaltype,8539,https://hail.is,https://github.com/hail-is/hail/issues/1260,2,['validat'],['validateexternaltype']
Security,"(https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4MmVlNzU5Ny0wZmFhLTQ1NmUtOTA3Ny0zOTM4ODRjNzJmNGMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjgyZWU3NTk3LTBmYWEtNDU2ZS05MDc3LTM5Mzg4NGM3MmY0YyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""82ee7597-0faa-456e-9077-393884c72f4c"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13370:2546,access,access,2546,https://hail.is,https://github.com/hail-is/hail/pull/13370,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"(https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5Nzc0NDQwMi1iNzEyLTQ5NjMtYWQ0Zi01YjFhZWZmOTcwZDciLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6Ijk3NzQ0NDAyLWI3MTItNDk2My1hZDRmLTViMWFlZmY5NzBkNyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""97744402-b712-4963-ad4f-5b1aeff970d7"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13365:2345,access,access,2345,https://hail.is,https://github.com/hail-is/hail/pull/13365,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"(https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxOGJjNGZiYS05ZTMwLTRmNWItYTE4Yy0wOGNmNDVmZDExMTciLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjE4YmM0ZmJhLTllMzAtNGY1Yi1hMThjLTA4Y2Y0NWZkMTExNyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""18bc4fba-9e30-4f5b-a18c-08cf45fd1117"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13366:2554,access,access,2554,https://hail.is,https://github.com/hail-is/hail/pull/13366,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"(i) -> O(i, i)` makes a square matrix whose diagonal is T. * `T(i) -> O(i, j)` and `T(i) -> O(j, i)` broadcast T over a matrix in the two possible directions. Now let T be a 2-tensor. * `T(i, j) -> O(i)` is the vector of row-sums of T. * `T(i, i) -> O(i)` is the diagonal of T. * `T(i, i) -> O()` is the trace of T. * `T(i, j) -> O(j, i)` is transposition. How do we represent matrix multiplication? Let T1 and T2 be 2-tensors. Then letting `T = Out(T1, T2, ""and"").map((x, y) => x * y)`, the matrix product is given by. * `T(i, j, j, k) -> O(i, k)`. In general, an index operation on T requires specifying an output tensor O (including its shape, though you can deduce that in non-broadcasting cases), a set of index variables (eg. ""i, j, k""), and an assignment of a variable to each dimension of T and O. . More abstractly, let DT and DO be the sets of dimensions of T and O. An index operation consists of a set I and two functions DT -> I <- DO, a ""cospan"". These operations compose by cospan composition, which involves a pushout (a disjoint union and a quotient). Let i: DT -> I and o: DO -> I be the two maps assigning index variables. It helps to consider some special cases (compare to the examples above):. * If i is surjective, and o is identity, this is extracting a diagonal from T. * If i is injective, and o is identity, this is a broadcast. * If i is identity, and o is surjective, this embeds T as a diagonal of a higher-dimensional output tensor. * If i is identity, and o is injective, this is a pure aggregation, summing out some dimensions of T. To make composition easy to compute, we could represent an index operation using a union-find structure for I. In other words, an index operation consists of a union-find structure I, and two arrays of points of I, encoding the two functions above. Then the composition of (T, I1, M) and (M, I2, O) is (T, I', O), where I' is computed by taking the union I1+I2, then for each dimension of M, unioning the assigned points of I1 and I2.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5190#issuecomment-457598772:3583,inject,injective,3583,https://hail.is,https://github.com/hail-is/hail/pull/5190#issuecomment-457598772,2,['inject'],['injective']
Security,"(that's not to say we shouldn't do dependency audits every few months, bumping the pinned version to latest)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7299#issuecomment-542205189:46,audit,audits,46,https://hail.is,https://github.com/hail-is/hail/issues/7299#issuecomment-542205189,1,['audit'],['audits']
Security,"). A Certificate Authority (like; letsencypt or VeriSign) digitally signs the certificate of a user that has; proven they own the domain name mentioned in the certificate (see above; discussion of `CN` and `subjectAltName`). Web browsers have a file of the ""root""; certificates of the public Certificate Authorities. They establish a ""chain of; trust"" from a root certificate to the server's certificate. Our system is simpler. We have no root certificate. Each principal has a; certificate which is given to all the principals to which it might; communicate. ### Encryption. TLS has many encryption schemes. I will focus on encryption using a *symmetric*; key because asymmetric schemes do not enable *forward secrecy* [2]. Under; forward secret schemes, the two parties share a private key unknown to all; adversaries. TLS 1.3 makes forward secrecy mandatory. I intend to eventually; require all our services to refuse to speak anything other than TLS 1.3. The shared private key is used to encrypt and decrypt messages sent over a; socket. This poses a problem: how do two parties who have never met each other; agree on a private key without revealing the key to the public? This is a; classic cryptography problem called [key; exchange](https://en.wikipedia.org/wiki/Key_exchange). The classic solution to; this problem is [Diffie-Hellman key; exchange](https://en.wikipedia.org/wiki/Diffie–Hellman_key_exchange). The; Wikipedia article has ""General overview"" which is quite clear. In addition to a key, the parties must agree on a cipher. There are many old,; insecure ciphers available. In the future I intend all our servers to refuse to; use insecure ciphers. Mozilla; [has a list of secure cipher suites](https://wiki.mozilla.org/Security/Server_Side_TLS#Recommended_configurations). ## New Hail Concepts. Every principal in our system has a secret: `ssl-config-NAME`. These secrets are; automatically created for a particular namespace by `tls/create_certs.py`. Who; trusts who (i.e. who i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:5443,encrypt,encrypt,5443,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['encrypt'],['encrypt']
Security,); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; 	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); 	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); 	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); 	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:245); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:11815,Checksum,ChecksumFileSystem,11815,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['Checksum'],['ChecksumFileSystem']
Security,")</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/437ac47fe332106a07a2d5335bb89619f1bc23f7""><code>437ac47</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7995"">#7995</a>/43a5bc50 backport][3.9] Fix examples of <code>fallback_charset_resolver</code>...</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/034e5e34ee11c6138c773d85123490e691e1b708""><code>034e5e3</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8042"">#8042</a>/4b91b530 backport][3.9] Tightening the runtime type check for ssl (...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.9.1...v3.9.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.9.1&new-version=3.9.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14212:7013,secur,security-vulnerabilities,7013,https://hail.is,https://github.com/hail-is/hail/pull/14212,12,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"* Fix error in TableKeyByAndAggregate caused by field name clobbering; * Fix error in TableLeftJoinRightDistinct with non-strict left tables; * Fix erroneous key preservation in TableStage.mapPartition; * Add Consume to TypeCheck; * Fix error where globals were not exposed in TableAggregate; * Fix error where globals were not exposed in TableAggregate. New local backend success rate:. ```; 271 failed, 496 passed, 75 skipped, 15 warnings in 368.17 seconds; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9202:266,expose,exposed,266,https://hail.is,https://github.com/hail-is/hail/pull/9202,2,['expose'],['exposed']
Security,"* Implement arithemetic in the finite field of order 2^32, as; polynomials over F_2 modulo the irreducible polynomial; x^32 + x^7 + x^3 + x^2 + 1. * Define class `PolyHash`, implementing polynomials over above field,; using Horner's rule for polynomial evaluation. * Use random polynomials to fill tables in tabulation hashes, for; guaranteed 32-independent randomness.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2452:319,hash,hashes,319,https://hail.is,https://github.com/hail-is/hail/pull/2452,1,['hash'],['hashes']
Security,"** Dropped support for LibreSSL &lt; 3.6.; * Updated the minimum supported Rust version (MSRV) to 1.56.0, from 1.48.0.; * Updated Windows, macOS, and Linux wheels to be compiled with OpenSSL 3.1.1.; * Added support for the :class:`~cryptography.x509.OCSPAcceptableResponses`; OCSP extension.; * Added support for the :class:`~cryptography.x509.MSCertificateTemplate`; proprietary Microsoft certificate extension.; * Implemented support for equality checks on all asymmetric public key types.; * Added support for ``aes256-gcm@openssh.com`` encrypted keys in; :func:`~cryptography.hazmat.primitives.serialization.load_ssh_private_key`.; * Added support for obtaining X.509 certificate signature algorithm parameters; (including PSS) via; :meth:`~cryptography.x509.Certificate.signature_algorithm_parameters`.; * Support signing :class:`~cryptography.hazmat.primitives.asymmetric.padding.PSS`; X.509 certificates via the new keyword-only argument ``rsa_padding`` on; :meth:`~cryptography.x509.CertificateBuilder.sign`.; * Added support for; :class:`~cryptography.hazmat.primitives.ciphers.aead.ChaCha20Poly1305`; on BoringSSL.; <p>.. _v40-0-2:; </code></pre></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/c4d494fd3ee907316bd846e90cbf4a8df75a25ac""><code>c4d494f</code></a> 41.0.0 version bump (<a href=""https://redirect.github.com/pyca/cryptography/issues/8991"">#8991</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/8708245ccdeaff21d65eea68a4f8d2a7c5949a22""><code>8708245</code></a> new openssl day (<a href=""https://redirect.github.com/pyca/cryptography/issues/8990"">#8990</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/31436a486661cd863d4c77e40facf93fbb2d9f54""><code>31436a4</code></a> admit to the existence of nuance in HKDF (<a href=""https://redirect.github.com/pyca/cryptography/issues/8987"">#8987</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/91e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13141:1543,Certificate,CertificateBuilder,1543,https://hail.is,https://github.com/hail-is/hail/pull/13141,3,['Certificate'],['CertificateBuilder']
Security,"+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​jupyterlab-probot</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Akrassowski+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​krassowski</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Alumberbot-app+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​lumberbot-app</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Ameeseeksmachine+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​meeseeksmachine</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Awelcome+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​welcome</code></a></p>; <!-- raw HTML omitted -->; <h2>4.0.11</h2>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/compare/v4.0.10...0708330843fd087134a239d2ad6005b1d543e246"">Full Changelog</a>)</p>; <h3>Security fixes</h3>; <ul>; <li>Potential authentication and CSRF tokens leak in JupyterLab (<a href=""https://github.com/jupyterlab/jupyterlab/security/advisories/GHSA-44cc-43rp-5947"">GHSA-44cc-43rp-5947</a>)</li>; <li>SXSS in Markdown Preview (<a href=""https://github.com/jupyterlab/jupyterlab/security/advisories/GHSA-4m77-cmpx-vjc4"">GHSA-4m77-cmpx-vjc4</a>)</li>; </ul>; <h3>Bugs fixed</h3>; <ul>; <li>Fixes focus indicator on input checkbox for Firefox <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15612"">#15612</a> (<a href=""https://github.com/alden-ilao""><code>@​alden-ilao</code></a>)</li>; </ul>; <h3>Documentation improvements</h3>; <ul>; <li>Fix link to yarn docs in extension migration guide <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15640"">#15640</a> (<a href=""https://github.com/krassowski""><code>@​krassowski</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/graphs/contributors?from=2023-12-29&amp;to",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14218:10205,Secur,Security,10205,https://hail.is,https://github.com/hail-is/hail/pull/14218,2,"['Secur', 'authenticat']","['Security', 'authentication']"
Security,", but we do not verify; (proxied) servers. I load the client certificates anyway so that I can smoke; test them before I require servers verify them. For VERIFY_CA, we load server; certs, load client certs, verify clients, and verify (proxied) servers. For Hail principals, we only generate a json configuration; file containing the ssl mode and some named paths. The new `hailtop/ssl.py`; module defines the mapping from configuration to Python's; [`SSLContext`](https://docs.python.org/3.6/library/ssl.html#ssl.SSLContext). There is also one ""curl"" principal: the admin-pod. REQUIRED and DISABLED are; mostly the same because required passes the `insecure` flag. As curl is; client-only, there is no notion of ""incoming connection"". ---. FAQ. Does this recreate certs on each deploy?. Yes. How do services speak to each other while a deploy is happening? Newly deployed; services will only trust newly deployed clients?. `create_certs.py` includes the previous deploy's certificates in the trust; chain, so we can always accept clients from one deploy backwards. Old services; will not trust the new clients, but the `build.yaml` ensures things are deployed; in dependency order. Deploy would never work if a client could depend on; a not-yet-deployed server. ---. Things for you to verify:; - does every service load *its own unqiue* ssl-config secret?; - does every service use an SSL context for serving?; - does everyone who makes http requests to internal services use an SSL client; session?; - do all TLS-secured nginx instances include their http.conf in the `http`; section and the `proxy.conf` file in any proxying sections?; - Do the SSLContext's from `ssl.py` and the nginx configurations generated by; `create_certs.py` obey the aforementioned matrix?. Post-merge actions:; - deploy gateway; - deploy internal-gateway; - deploy router-resolver. Anticipated outages:. - Before a service is redeployed it will be inaccessible from the outside; because the router will try to speak to it o",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8513:5560,certificate,certificates,5560,https://hail.is,https://github.com/hail-is/hail/pull/8513,1,['certificate'],['certificates']
Security,", instead of returning a value. Under the hood, `JoinPoint`s are implemented; with a label and a `GOTO` instruction. ```scala; def example1(j: JoinPoint[Code[Int]]): Code[Ctrl] = Code(; j(3),; ""this line is never reached"".println,; j(4)); ```. ### `ParameterPack`. The trait `ParameterPack[A]` says that the type `A` is comprised of a list of `Code[T]`s, such that the structure of that list is statically known. While this is generally useful for representing deforested tuples, it is specifically useful here because it allows `JoinPoint`s to take multiple arguments as a tuple of the individual arguments. This ""tuple"" will be represented at runtime by pushing or popping multiple values from the JVM argument stack. ```scala; // case class JoinPoint[A: ParameterPack] ( .... ); def example2(j: JoinPoint[(Code[Int], Code[Boolean], Code[Int])]): Code[Ctrl] =; j((8, true, 9)); /* LDC 8; * LDC 1; * LDC 9; * GOTO j */; ```. ### `JoinPointBuilder`. The only way to create new join-points is via a `JoinPointBuilder` object, using the `joinPoint[A]` method (where `A` is the desired argument type). Then the body of the join-point can be provided by calling `define`. ```scala; val mb: MethodBuilder; // method builder required to create locals to store join point arguments; def example3(jb: JoinPointBuilder, exit: JoinPoint[Code[Int]]): JoinPoint[Code[Int]] = {; val j = jb.joinPoint[Code[Int]](mb); j.define { n => exit(n + 1) }; j; }; ```. ### `CallCC`. The only way to obtain a `JoinPointBuilder` is through a `CallCC`. `CallCC` also provides access to; the ""current continuation"" -- a join-point which takes an argument that will become the final result; of the entire `CallCC` expression. In fact, the only way to return a value from a `CallCC` is by; eventually calling this join-point. ```scala; val example4: Code[Boolean] =; JoinPoint.CallCC { (jb: JoinPointBuilder, ret: JoinPoint[Code[Boolean]]) =>; const(false).mux(; ret(false),; ret(true)); }; // running 'example4' gives 'true'; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7055:3644,access,access,3644,https://hail.is,https://github.com/hail-is/hail/pull/7055,1,['access'],['access']
Security,",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""42.0.2""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6050294"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-CRYPTOGRAPHY-6126975"",""SNYK-PYTHON-CRYPTOGRAPHY-6210214"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14296:11546,Access,Access,11546,https://hail.is,https://github.com/hail-is/hail/pull/14296,1,['Access'],['Access']
Security,",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""},{""name"":""wheel"",""from"":""0.30.0"",""to"":""0.38.0""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JINJA2-6150717"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PROMPTTOOLKIT-6141120"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512"",""SNYK-PYTHON-WHEEL-3180413""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,624,531,556,604,589,726,434,589,449,399,696,589,479,519,509,711,701,586,586,384,494,539,589],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Cross-site Scripting (XSS)](https://learn.snyk.io/lesson/xss/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:14123,validat,validation,14123,https://hail.is,https://github.com/hail-is/hail/pull/14205,4,"['Cross-site Scripting', 'XSS', 'validat', 'xss']","['Cross-site Scripting', 'XSS', 'validation', 'xss']"
Security,",StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 2, ref), StringType), true), altAlleles, mapobjects(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object), if (isnull(validateexternaltype(lambdavariable(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object)), StructField(ref,StringType,false), StructField(alt,StringType,false)))) null else named_struct(ref, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexternaltype(lambdavariable(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object)), StructField(ref,StringType,false), StructField(alt,StringType,false)), 0, ref), StringType), true), alt, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexternaltype(lambdavariable(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object)), StructField(ref,StringType,false), StructField(alt,StringType,false)), 1, alt), StringType), true)), validateexternaltype(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 3, altAlleles), ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false)))) AS variant#8; ```. Attached is a toy test.in.vds that reproduces the problem [test.in.vds.tar.gz](https://github.com/hail-is/hail/files/709524/test.in.vds.tar.gz). Tested on a clean ed544897f04722142b14b8e620614587c8f398a0 built with gradlew installDist.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1260:9756,validat,validateexternaltype,9756,https://hail.is,https://github.com/hail-is/hail/issues/1260,4,['validat'],['validateexternaltype']
Security,",h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 41.0.4` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 41.0.4` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `3.3.2 -> 41.0.4` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `3.3.2 -> 41.0.4` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `3.3.2 -> 41.0.4` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `3.3.2 -> 41.0.4` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13736:5116,Certificate,Certificate,5116,https://hail.is,https://github.com/hail-is/hail/pull/13736,4,"['Certificate', 'Validat']","['Certificate', 'Validation']"
Security,",h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 41.0.5` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 41.0.5` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `3.3.2 -> 41.0.5` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `3.3.2 -> 41.0.5` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `3.3.2 -> 41.0.5` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `3.3.2 -> 41.0.5` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13938:5172,Certificate,Certificate,5172,https://hail.is,https://github.com/hail-is/hail/pull/13938,2,"['Certificate', 'Validat']","['Certificate', 'Validation']"
Security,",h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14134:4848,Certificate,Certificate,4848,https://hail.is,https://github.com/hail-is/hail/pull/14134,4,"['Certificate', 'Validat']","['Certificate', 'Validation']"
Security,",h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14296:5104,Certificate,Certificate,5104,https://hail.is,https://github.com/hail-is/hail/pull/14296,2,"['Certificate', 'Validat']","['Certificate', 'Validation']"
Security,"- Added IR node to go from a BlockMatrix to a value; - Added BlockMatrixToValueFunction to get an element at a certain index and used it to access elements in BlockMatrix.__getitem__; - This raises an interesting question of whether accessing an element of a tensor should return a Python value or a Hail expr. Right now, it just builds a BlockMatrixToValue IR and immediately executes it to return a Python number (matches existing behavior), but we could just as easily return the IR node.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5402:140,access,access,140,https://hail.is,https://github.com/hail-is/hail/pull/5402,2,['access'],"['access', 'accessing']"
Security,- Added Scala infrastructure to aggregate to new row fields (current is only entry fields). To Do:; - Expose in Python interface (currently just passing an empty struct); - Write tests in Python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4131:102,Expose,Expose,102,https://hail.is,https://github.com/hail-is/hail/pull/4131,1,['Expose'],['Expose']
Security,- Added a new annotate module due to demand from users to be able to annotate variants without ref/alt.; - Added `Locus` constructor and accessor methods in the expr language,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/516:137,access,accessor,137,https://hail.is,https://github.com/hail-is/hail/pull/516,1,['access'],['accessor']
Security,"- Added a shared image gallery to terraform; - Added a managed identity `batch-worker` to terraform; - Gave `batch-worker` ""acrpull"" privileges for the resource group; - Added new config variables in config.mk that are specific to Azure; - Added commands to batch/Makefile to create a boot disk image; - Added an Azure-specific startup script that installs Docker and the CLI and then authenticates and pulls the base image. The disk image we create is specialized. This means it has credentials in there after publishing it. I think this is okay and I specifically used the batch-worker managed identity to login for this. I can try and double check this assumption if you think I'm not correct after reading these docs: https://docs.microsoft.com/en-us/cli/azure/vm?view=azure-cli-latest#az_vm_create. > Accept system or user assigned identities separated by spaces. Use '[system]' to refer system assigned identity, or a resource id to refer user assigned identity. Check out help for more examples. I had to give the batch-worker managed identity in the resource group we want permissions to be an identity for a VM in the build-batch-worker-image resource group.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10834:385,authenticat,authenticates,385,https://hail.is,https://github.com/hail-is/hail/pull/10834,1,['authenticat'],['authenticates']
Security,"- Added support for blobfuse, which is Azure's equivalent of gcsfuse.; - Renamed operations/variables to cloudfuse to be generic; - The validator is slightly more complicated because there is a double renaming of gcsfuse to cloud fuse to gcsfuse for old clients. This is to maintain backwards compatibility with old instances. Once v21 instances die, then we can remove the extra backwards compatibility step.; - renamed instance_env.py files to worker_api.py files. @daniel-goldstein @danking Can you decide amongst yourselves who should review this? Maybe Dan takes a first glance and then Daniel reads it in more detail?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11211:136,validat,validator,136,https://hail.is,https://github.com/hail-is/hail/pull/11211,1,['validat'],['validator']
Security,- Added the AzureGraphClient which creates applications and service principals; - Modified Auth to create service principals and delete them; - Added two fields to the auth database that optionally store the application ID and the credentials secret name; - Had to modify AzureCredentials a bit to account for a different scope (one of the Azure Credentials types cannot take multiple scopes for some reason); - There's an auth database migration here!; - I tried to figure out what API calls result in the same result in the portal. It's possible the exact calls are not quite right (ex: addPassword on the application versus the service principal). TODO:; - Figure out how to use the global config in auth/Makefile to template global.cloud; - Double check the service principal creation is correct (I know the appID and password end up working to create resources at least). cc: @danking,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10986:822,password,password,822,https://hail.is,https://github.com/hail-is/hail/pull/10986,1,['password'],['password']
Security,"- Adds typeArgs: Array[Type] to registered functions. Exposed on Apply, ApplyIR, ApplySpecial, but currently not on ApplySeeded. - Removes munging of reference genome function names: there is no longer a global registry of ""{function}_{rg}"" functions. - Minor: (bug) unify was previously being used without asserts (in apply methods on IRFunctions)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8538:54,Expose,Exposed,54,https://hail.is,https://github.com/hail-is/hail/pull/8538,1,['Expose'],['Exposed']
Security,"- Also moved the location of where buckets are mounted to not be in /batch so as to avoid accidentally deleting entire buckets.; - The file mode didn't do what I expected (allowed you to write to a bucket), but now that I think about it, we probably do want to expose this and my first intuition was right. We probably want files to be specified as read only when they're created on the local file system. I can make this a separate PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8979:261,expose,expose,261,https://hail.is,https://github.com/hail-is/hail/pull/8979,1,['expose'],['expose']
Security,"- Basic JSON format for NGINX access logs; - `message`, `remote_address`, `request_duration`, `response_status` and `x_real_ip` should match the Python Access logger so we should be able to query these fields all at once; - Unfortunately the NGINX `error_log` does not allow the same custom formatter, but we can create multiple, [custom access logs](https://www.nginx.com/blog/diagnostic-logging-nginx-javascript-module/#proxy_next_upstream) based on arbitrary failure criteria if there's a particular class of error logs we want to get in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9928:30,access,access,30,https://hail.is,https://github.com/hail-is/hail/pull/9928,3,"['Access', 'access']","['Access', 'access']"
Security,"- Expose init_local.; - Fix formatting of some error messages (stray }).; - Fix index paths, they don't have a ""parts"" component, have "".idx"" suffix. This showed up as an issue interopreating between Spark and local modes. FYI @tpoterba rather than just testing them independently, it might be worthwhile to have write/read interop tests between the various backends. Spark to local is partially tested by the pre-existing (matrix)tables tests, but not the other way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9596:2,Expose,Expose,2,https://hail.is,https://github.com/hail-is/hail/pull/9596,1,['Expose'],['Expose']
Security,- Expose the ability to permute dimensions on NDArrays in Python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6059:2,Expose,Expose,2,https://hail.is,https://github.com/hail-is/hail/pull/6059,1,['Expose'],['Expose']
Security,"- Nested arrays appear to be supported in the current code, and I don't think this is intended.; - Why do exportFormat and exportInfo differ?; - Number is accessed from the field attrs without being checked. There could be something silly in there.; - Bad error messages (don't say which field was the problem)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1820:155,access,accessed,155,https://hail.is,https://github.com/hail-is/hail/issues/1820,1,['access'],['accessed']
Security,- Only batch for now -- will add for pipeline and ci later; - This should fail until the kubernetes secret is added; - Requires a password `CLOUD_SQL_PASSWORD` to run the tests locally; (not sure what the best way to distribute this is); - Requires downloading the `cloud_sql_proxy` binary to run the tests locally,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5615:130,password,password,130,https://hail.is,https://github.com/hail-is/hail/pull/5615,1,['password'],['password']
Security,"- Use the scorecard tag or design-docs tag to have Asana tasks show up in scorecard; - Easy to add different tags to track; - Currently using my personal access token. Not sure if that's ideal, but seemed fine for now.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9488:154,access,access,154,https://hail.is,https://github.com/hail-is/hail/pull/9488,1,['access'],['access']
Security,"- [x] Remove the reader permission created during testing. - [ ] Convert user service accounts permission from owner to read/write. - [ ] Give user email address read/write permissions to the bucket that we create on their behalf. - [ ] Ensure equivalent of chmod -R 600; right now appears that (at least) legacy owners don't have automatic, recursive read access to objects in their bucket.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5920:357,access,access,357,https://hail.is,https://github.com/hail-is/hail/issues/5920,1,['access'],['access']
Security,"- add PIndexableValue. This represents canonical array, set and dict values.; - use in ArrayRef; - newP{Local, FIeld} now has a `PV <: PValue` type parameter to eliminate some casting. Where I'm going:. There will be a abstract PValue with the interface for each virtual type (container/indexable, base struct, etc.) Each concrete PType will have a corresponding PValue implementation (in this case, PCanonicalArray is implemented by PCanonicalIndexableValue.) I think this will allow us to get rid of PArrayBackedContainer. Only primitive PValues will have a code method (since other types might be compound). The code generator should then dispatch through downcasts of PValues get access to the relevant methods.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8213:684,access,access,684,https://hail.is,https://github.com/hail-is/hail/pull/8213,1,['access'],['access']
Security,"- add ci database with 1 table: authorized_shas; - only start build if authorized author or source_sha is authorized; - form on main page to add authorized sha,; - unauthorized PRs are created, but not tested, and shown as unauthorized in UI",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6308:71,authoriz,authorized,71,https://hail.is,https://github.com/hail-is/hail/pull/6308,3,['authoriz'],['authorized']
Security,- added `entropy` to IR and wrote missing 0.2 documentation; - fixed entropy to handle the empty string correctly; - exposed the `sign` documentation; - made `NaN` consistently Python's `nan` in docs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3793:117,expose,exposed,117,https://hail.is,https://github.com/hail-is/hail/pull/3793,1,['expose'],['exposed']
Security,- fixed structure of docs + links (hail/* -> docs/stable/*); - Added Hail version + supported spark versions + git hash as gradle variables; - Used these versions in Sphinx.; - Changed path of distribution links in getting started to point at current hash.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2034:115,hash,hash,115,https://hail.is,https://github.com/hail-is/hail/pull/2034,2,['hash'],['hash']
Security,"- hail/python/dev/pinned-requirements.txt. <details>; <summary>⚠️ <b>Warning</b></summary>. ```; jupyter 1.0.0 requires qtconsole, which is not installed.; jupyter 1.0.0 requires notebook, which is not installed.; beautifulsoup4 4.12.2 requires soupsieve, which is not installed.; argon2-cffi-bindings 21.2.0 requires cffi, which is not installed.; aiohttp-devtools 1.1 requires watchfiles, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14042:1316,Validat,Validation,1316,https://hail.is,https://github.com/hail-is/hail/pull/14042,1,['Validat'],['Validation']
Security,"- made decoder stuff modular/composable; - CodecSpec, stored in RVDSpec (and hence in metadata) describes the en/decoding process; - exposed to Python (private parameter in MT and Table.write)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2859:133,expose,exposed,133,https://hail.is,https://github.com/hail-is/hail/pull/2859,1,['expose'],['exposed']
Security,"- new filter_alleles method: takes MT and lambda,; produces the fields needed to update row/entry fields; (old_to_new, new_to_old, old_locus, old_alleles); - subset_entries_hts and downcode_entries_hts are now; filter_alleles_hts, which calls filter_alleles.; - Exposed min_rep expr function in Python; - Added min_rep to AST FunctionRegistry (Scala); - Removed hl.min_rep method to minrep a MT (easy with the; function now); - Deleted FilterAlleles; - Deleted FilterAlleles (Scala); - Deleted minRep (Scala); - Moved MinRepSuite to Python",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3505:262,Expose,Exposed,262,https://hail.is,https://github.com/hail-is/hail/pull/3505,1,['Expose'],['Exposed']
Security,"- starting batch; (nginx timed out, but we got 30k submitted); Should multiplex client sending requests to the server. - close batch should start running all pods, don't create pods before batch has been closed. - wait should not list jobs (separate end point?). - add log statement if we delete a pod. - figure out discrepancy between kubernetes and batch on how many pods have been completed / created. - why were logs accessed twice? Both batch or is one of those fluentd?. - race condition still between accessing the log and deleting the pod?. - See whether our containers are being garbage collected: ; https://kubernetes.io/docs/concepts/cluster-administration/kubelet-garbage-collection/; https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6566#issuecomment-508267674:421,access,accessed,421,https://hail.is,https://github.com/hail-is/hail/issues/6566#issuecomment-508267674,2,['access'],"['accessed', 'accessing']"
Security,"--------------------------------------------------------------------------------------------------------------------+; | batch_id | job_group_id | resources |; +----------+--------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+; | 1 | 0 | {""service-fee/1"": 39973000, ""ip-fee/preemptible/1024/1"": 2558272, ""ip-fee/nonpreemptible/1024/1"": 3449280, ""disk/pd-ssd/us-central1/1707831761013"": 51165440, ""gcp-support-logs-specs-and-firewall-fees/1"": 39973000, ""memory/n1-preemptible/us-central1/1707831761013"": 153496320, ""compute/n1-preemptible/us-central1/1707831761013"": 39973000, ""memory/n1-nonpreemptible/us-central1/1707831761013"": 206956800, ""compute/n1-nonpreemptible/us-central1/1707831761013"": 53895000, ""disk/local-ssd/preemptible/us-central1/1707831761013"": 959352000, ""disk/local-ssd/nonpreemptible/us-central1/1707831761013"": 1293480000} |; +----------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14282#issuecomment-1941610575:5469,firewall,firewall-fees,5469,https://hail.is,https://github.com/hail-is/hail/pull/14282#issuecomment-1941610575,1,['firewall'],['firewall-fees']
Security,"-------------------------------------------------------------------------------------------------------------------------+; | batch_id | ancestor_id | resources |; +----------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+; | 1 | 0 | {""service-fee/1"": 14452500, ""ip-fee/preemptible/1024/1"": 924960, ""ip-fee/nonpreemptible/1024/1"": 4239936, ""disk/pd-ssd/us-central1/1707831761013"": 18499200, ""gcp-support-logs-specs-and-firewall-fees/1"": 14452500, ""memory/n1-preemptible/us-central1/1707831761013"": 55497600, ""compute/n1-preemptible/us-central1/1707831761013"": 14452500, ""memory/n1-nonpreemptible/us-central1/1707831761013"": 254396160, ""compute/n1-nonpreemptible/us-central1/1707831761013"": 66249000, ""disk/local-ssd/preemptible/us-central1/1707831761013"": 346860000, ""disk/local-ssd/nonpreemptible/us-central1/1707831761013"": 1589976000} |; +----------+-------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14282#issuecomment-1941610575:2568,firewall,firewall-fees,2568,https://hail.is,https://github.com/hail-is/hail/pull/14282#issuecomment-1941610575,1,['firewall'],['firewall-fees']
Security,"-------------------------------------------------------------------------------------------------------------------------------------------------------------------------+; | batch_id | resources |; +----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+; | 1 | {""service-fee/1"": 427000, ""ip-fee/preemptible/1024/1"": 27328, ""ip-fee/nonpreemptible/1024/1"": 4239936, ""disk/pd-ssd/us-central1/1707831761013"": 546560, ""gcp-support-logs-specs-and-firewall-fees/1"": 427000, ""memory/n1-preemptible/us-central1/1707831761013"": 1639680, ""compute/n1-preemptible/us-central1/1707831761013"": 427000, ""memory/n1-nonpreemptible/us-central1/1707831761013"": 254396160, ""compute/n1-nonpreemptible/us-central1/1707831761013"": 66249000, ""disk/local-ssd/preemptible/us-central1/1707831761013"": 10248000, ""disk/local-ssd/nonpreemptible/us-central1/1707831761013"": 1589976000} |; +----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14282#issuecomment-1941610575:8297,firewall,firewall-fees,8297,https://hail.is,https://github.com/hail-is/hail/pull/14282#issuecomment-1941610575,1,['firewall'],['firewall-fees']
Security,"---------------------------; Column key: ['s']; Row key: ['locus', 'alleles']; ----------------------------------------; [Stage 4:===================================================> (480 + 20) / 500]2020-04-05 14:09:48 Hail: INFO: Coerced almost-sorted dataset; [Stage 5:======================================================>(498 + 2) / 500]2020-04-05 14:09:50 Hail: INFO: Coerced almost-sorted dataset; [Stage 7:> (0 + 108) / 500]ERROR: [pid 11941] Worker Worker(salt=943636132, workers=1, host=seqr-loading-cluster-m, username=root, pid=11941) failed SeqrVCFToMTTask(source_paths=gs://seqr-bw/merged_phased_3P5CH.split.vcf.gz, dest_path=gs://seqr-bw/merged_phased_3P5CH.mt, genome_version=38, vep_runner=VEP, reference_ht_path=gs://seqr-reference-data/GRCh38/all_reference_data/combined_reference_data_grch38.ht, clinvar_ht_path=gs://seqr-reference-data/GRCh38/clinvar/clinvar.GRCh38.2020-03-29.ht, hgmd_ht_path=None, sample_type=WGS, validate=False, dataset_type=VARIANTS, remap_path=, subset_path=, vep_config_json_path=); Traceback (most recent call last):; File ""/opt/conda/default/lib/python3.6/site-packages/luigi/worker.py"", line 199, in run; new_deps = self._run_get_new_deps(); File ""/opt/conda/default/lib/python3.6/site-packages/luigi/worker.py"", line 141, in _run_get_new_deps; task_gen = self.task.run(); File ""/tmp/c7e0443c47b54e91b295e2bff7b554b9/seqr_loading.py"", line 54, in run; self.read_vcf_write_mt(); File ""/tmp/c7e0443c47b54e91b295e2bff7b554b9/seqr_loading.py"", line 84, in read_vcf_write_mt; mt.write(self.output().path, stage_locally=True, overwrite=True); File ""<decorator-gen-1092>"", line 2, in write; File ""/opt/conda/default/lib/python3.6/site-packages/hail/typecheck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/conda/default/lib/python3.6/site-packages/hail/matrixtable.py"", line 2529, in write; Env.backend().execute(MatrixWrite(self._mir, writer)); File ""/opt/conda/default/lib/python3.6/site-packages/hail/backend/backend",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:47366,validat,validate,47366,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['validat'],['validate']
Security,"-------------------------. Running on Ubuntu 18.04. I had installed openjdk-11-jre-headless instead of openjdk-8-jre-headless. ### Hail version:; 0.2 ; ### What you did:. ### What went wrong (all error messages here, including the full java stack trace):; 2018-12-04 22:13:57 root: ERROR: IllegalArgumentException: null; From java.lang.IllegalArgumentException: null; at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:46); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:443); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:426); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:103); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:426); at org.apache.xbean.asm5.ClassReader.a(Unknown Source); at org.apache.xbean.asm5.ClassReader.b(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:257); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(Closure",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4896:1191,Hash,HashMap,1191,https://hail.is,https://github.com/hail-is/hail/issues/4896,1,['Hash'],['HashMap']
Security,"----------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1NDMwZTFmMi0wNDZjLTQwNDctYmI3Mi1hZmJkZmM1MDViNGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjU0MzBlMWYyLTA0NmMtNDA0Ny1iYjcyLWFmYmRmYzUwNWI0YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""5430e1f2-046c-4047-bb72-afbdfc505b4a"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13304:1589,access,access,1589,https://hail.is,https://github.com/hail-is/hail/pull/13304,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"----------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3Mzc3ZjFlZS1kMjJjLTQ0MDAtYmE1Yy04NGNkYWZmZWJmYzgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjczNzdmMWVlLWQyMmMtNDQwMC1iYTVjLTg0Y2RhZmZlYmZjOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7377f1ee-d22c-4400-ba5c-84cdaffebfc8"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13305:1572,access,access,1572,https://hail.is,https://github.com/hail-is/hail/pull/13305,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"----------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjMDQ5NzlhMC1iYWM3LTRiMjEtYmE0ZS02OWU5YjAzMTE5ZjAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImMwNDk3OWEwLWJhYzctNGIyMS1iYTRlLTY5ZTliMDMxMTlmMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/7fad328c-8d01-4768-8813-73d6c644e2d4?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/7fad328c-8d01-4768-8813-73d6c644e2d4?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""c04979a0-bac7-4b21-ba4e-69e9b03119f0"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13309:1574,access,access,1574,https://hail.is,https://github.com/hail-is/hail/pull/13309,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"----------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkY2E2ZDI1ZC1hZGM3LTRiNTctYWU3Zi0yNjExOTYzNTY5MmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImRjYTZkMjVkLWFkYzctNGI1Ny1hZTdmLTI2MTE5NjM1NjkyZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""dca6d25d-adc7-4b57-ae7f-26119635692e"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13294:1581,access,access,1581,https://hail.is,https://github.com/hail-is/hail/pull/13294,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"----------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMjNiYjk0OC04YjdmLTQ5MzUtYTRkMi05ZWJmNjg4NjZlMmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImUyM2JiOTQ4LThiN2YtNDkzNS1hNGQyLTllYmY2ODg2NmUyZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e23bb948-8b7f-4935-a4d2-9ebf68866e2e"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13316:1585,access,access,1585,https://hail.is,https://github.com/hail-is/hail/pull/13316,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"----------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmYWJiOGYzZi1mMDFjLTQxMjktODJjNC1kZjQzMjRmZTU4YTIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZhYmI4ZjNmLWYwMWMtNDEyOS04MmM0LWRmNDMyNGZlNThhMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""fabb8f3f-f01c-4129-82c4-df4324fe58a2"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13296:1574,access,access,1574,https://hail.is,https://github.com/hail-is/hail/pull/13296,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **451/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.3 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0Y2E5NmE2ZC02MjMxLTQ1YTctYmQyOS1kYTA0ZmZhNTliYzQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjRjYTk2YTZkLTYyMzEtNDVhNy1iZDI5LWRhMDRmZmE1OWJjNCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""4ca96a6d-6231-45a7-bd29-da04ffa59bc4"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14238:1823,access,access,1823,https://hail.is,https://github.com/hail-is/hail/pull/14238,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5NmE4NGVhMS1hYzgxLTQxYmEtOGYzNC02MGU1ZTdhYzNjZTMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6Ijk2YTg0ZWExLWFjODEtNDFiYS04ZjM0LTYwZTVlN2FjM2NlMyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""96a84ea1-ac81-41ba-8f34-60e5e7ac3ce3"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12896:1690,access,access,1690,https://hail.is,https://github.com/hail-is/hail/pull/12896,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"---------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyOTUzNDFmZi1lMjQ4LTRiOTItYTY1Yy1kYjJiZWQ3ZDQxMGQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjI5NTM0MWZmLWUyNDgtNGI5Mi1hNjVjLWRiMmJlZDdkNDEwZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""295341ff-e248-4b92-a65c-db2bed7d410d"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13066:1672,access,access,1672,https://hail.is,https://github.com/hail-is/hail/pull/13066,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"---------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlNTZiOGU3Ni1mMTk3LTQ0MmMtOGVlMC04MjFhMDk5YzM3YTAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU1NmI4ZTc2LWYxOTctNDQyYy04ZWUwLTgyMWEwOTljMzdhMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e56b8e76-f197-442c-8ee0-821a099c37a0"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13072:1446,access,access,1446,https://hail.is,https://github.com/hail-is/hail/pull/13072,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `40.0.2 -> 41.0.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhYmU2OWI5ZC1kMzViLTQ1Y2ItYWY2NS04ZDEwN2YxZWMzZmMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFiZTY5YjlkLWQzNWItNDVjYi1hZjY1LThkMTA3ZjFlYzNmYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""abe69b9d-d35b-45cb-af65-8d107f1ec3fc"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13139:1563,access,access,1563,https://hail.is,https://github.com/hail-is/hail/pull/13139,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `40.0.2 -> 41.0.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjOTM3MTIxYy1lZTM3LTQ2ZmMtYTcxMC04MWY4YzdhZmUyN2IiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImM5MzcxMjFjLWVlMzctNDZmYy1hNzEwLTgxZjhjN2FmZTI3YiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""c937121c-ee37-46fc-a710-81f8c7afe27b"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13136:1554,access,access,1554,https://hail.is,https://github.com/hail-is/hail/pull/13136,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `40.0.2 -> 41.0.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmZWM3ZmQ2Ny0xZmE0LTRlNzEtODQ4Ni1hMDk5YThmYWM3NzgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZlYzdmZDY3LTFmYTQtNGU3MS04NDg2LWEwOTlhOGZhYzc3OCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""fec7fd67-1fa4-4e71-8486-a099a8fac778"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13138:1479,access,access,1479,https://hail.is,https://github.com/hail-is/hail/pull/13138,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **611/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5914629](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5914629) | `cryptography:` <br> `41.0.3 -> 41.0.4` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiN2QwMTZlZS0zODA0LTQwMjItOWE0Yi01MzExNjZhNjBjMWQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI3ZDAxNmVlLTM4MDQtNDAyMi05YTRiLTUzMTE2NmE2MGMxZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""b7d016ee-3804-4022-9a4b-531166a60c1d"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13698:1554,access,access,1554,https://hail.is,https://github.com/hail-is/hail/pull/13698,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **611/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5914629](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5914629) | `cryptography:` <br> `41.0.3 -> 41.0.4` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkNGViNWEyYS04NmZjLTRhZDQtYmM5MC1mZDViZWU4Mjg3YWUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImQ0ZWI1YTJhLTg2ZmMtNGFkNC1iYzkwLWZkNWJlZTgyODdhZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""d4eb5a2a-86fc-4ad4-bc90-fd5bee8287ae"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13701:1763,access,access,1763,https://hail.is,https://github.com/hail-is/hail/pull/13701,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **611/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5914629](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5914629) | `cryptography:` <br> `41.0.3 -> 41.0.4` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmOTk4OWJlMC0yOWQ3LTQyYTctYTAzMC04NzljMTRmOGE2N2YiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImY5OTg5YmUwLTI5ZDctNDJhNy1hMDMwLTg3OWMxNGY4YTY3ZiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""f9989be0-29d7-42a7-a030-879c14f8a67f"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13700:1755,access,access,1755,https://hail.is,https://github.com/hail-is/hail/pull/13700,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6261585](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6261585) | `cryptography:` <br> `42.0.2 -> 42.0.4` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1MzAxOWZkZC04YjQwLTQ5NmUtYjRmYS0wMzA5MTAxOTBkZWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjUzMDE5ZmRkLThiNDAtNDk2ZS1iNGZhLTAzMDkxMDE5MGRlYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""53019fdd-8b40-496e-b4fa-030910190dec"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14344:1829,access,access,1829,https://hail.is,https://github.com/hail-is/hail/pull/14344,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6261585](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6261585) | `cryptography:` <br> `42.0.2 -> 42.0.4` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiYWUwMDM5My05NGUzLTRhNjYtYTE5Ni0xMjUwZDg0ZGZiZDgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImJhZTAwMzkzLTk0ZTMtNGE2Ni1hMTk2LTEyNTBkODRkZmJkOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""bae00393-94e3-4a66-a196-1250d84dfbd8"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14343:1555,access,access,1555,https://hail.is,https://github.com/hail-is/hail/pull/14343,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0MmRjMDIwMC02MDI1LTQ1M2QtYWUxNC00NDRlZjM5MmU4NTciLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjQyZGMwMjAwLTYwMjUtNDUzZC1hZTE0LTQ0NGVmMzkyZTg1NyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""42dc0200-6025-453d-ae14-444ef392e857"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13854:1834,access,access,1834,https://hail.is,https://github.com/hail-is/hail/pull/13854,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3OWQ3MTdiYy05MThjLTRlMjctOGQ2OC0xNTNhNWIxZGFmM2YiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6Ijc5ZDcxN2JjLTkxOGMtNGUyNy04ZDY4LTE1M2E1YjFkYWYzZiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""79d717bc-918c-4e27-8d68-153a5b1daf3f"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13850:1832,access,access,1832,https://hail.is,https://github.com/hail-is/hail/pull/13850,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxNGQyZDIxMi00ZjI4LTQ0OGEtYWRkNS02NThkNDEwNzQxZDYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjE0ZDJkMjEyLTRmMjgtNDQ4YS1hZGQ1LTY1OGQ0MTA3NDFkNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""14d2d212-4f28-448a-add5-658d410741d6"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13847:1750,access,access,1750,https://hail.is,https://github.com/hail-is/hail/pull/13847,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyNWE2ZGYzMi1kYmEzLTQzOTctYmIyNC0zNjdlMzhmZWQ3ZmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjI1YTZkZjMyLWRiYTMtNDM5Ny1iYjI0LTM2N2UzOGZlZDdmZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""25a6df32-dba3-4397-bb24-367e38fed7fe"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13848:1556,access,access,1556,https://hail.is,https://github.com/hail-is/hail/pull/13848,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmNDI4YzVjNi05NmZmLTQ1ZTMtYjY4ZC0zYzU5NjY3MjA3MGUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImY0MjhjNWM2LTk2ZmYtNDVlMy1iNjhkLTNjNTk2NjcyMDcwZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""f428c5c6-96ff-45e3-b68d-3c596672070e"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13851:1826,access,access,1826,https://hail.is,https://github.com/hail-is/hail/pull/13851,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-5926907](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-5926907) | `urllib3:` <br> `1.26.16 -> 1.26.17` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3ZGVlZGFlMy1mZmE3LTQxYmUtOGY4MS1lNmYwZTA5YTczOTMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdkZWVkYWUzLWZmYTctNDFiZS04ZjgxLWU2ZjBlMDlhNzM5MyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7deedae3-ffa7-41be-8f81-e6f0e09a7393"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13770:1556,access,access,1556,https://hail.is,https://github.com/hail-is/hail/pull/13770,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-5926907](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-5926907) | `urllib3:` <br> `1.26.16 -> 1.26.17` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4MmZhNTRjZC0yOGI4LTQ3OTUtYWFjNy02MDE0NjY3NjMwNTUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjgyZmE1NGNkLTI4YjgtNDc5NS1hYWM3LTYwMTQ2Njc2MzA1NSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""82fa54cd-28b8-4795-aac7-601466763055"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13771:1750,access,access,1750,https://hail.is,https://github.com/hail-is/hail/pull/13771,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-5926907](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-5926907) | `urllib3:` <br> `1.26.16 -> 1.26.17` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxOGU4YzI4Yi1kYWQ0LTQ5ZDUtOTExNi04NjFkYTdkODk5OTYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjE4ZThjMjhiLWRhZDQtNDlkNS05MTE2LTg2MWRhN2Q4OTk5NiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""18e8c28b-dad4-49d5-9116-861da7d89996"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13773:1834,access,access,1834,https://hail.is,https://github.com/hail-is/hail/pull/13773,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-5926907](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-5926907) | `urllib3:` <br> `1.26.16 -> 1.26.17` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiNzM0YmY4Ni1mNzQyLTQyMjMtOWVlYS1lNGU3ZjNmMTVlYWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI3MzRiZjg2LWY3NDItNDIyMy05ZWVhLWU0ZTdmM2YxNWVhYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""b734bf86-f742-4223-9eea-e4e7f3f15eac"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13772:1764,access,access,1764,https://hail.is,https://github.com/hail-is/hail/pull/13772,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-5926907](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-5926907) | `urllib3:` <br> `1.26.16 -> 1.26.17` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiODhmOTA3Ny02ZjlmLTRiZjEtYjFiYy0yZjNkNTE1MDEwYWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI4OGY5MDc3LTZmOWYtNGJmMS1iMWJjLTJmM2Q1MTUwMTBhYSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""b88f9077-6f9f-4bf1-b1bc-2f3d515010aa"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13783:1826,access,access,1826,https://hail.is,https://github.com/hail-is/hail/pull/13783,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"----------|:-------------------------|:-------------------------|:-------------------------; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **763/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 7.4 | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `41.0.1 -> 41.0.2` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIwMjJhZDMzNS1kYzBkLTQxZWYtYmRjYi03ZTFkODQwNWJhYTYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjAyMmFkMzM1LWRjMGQtNDFlZi1iZGNiLTdlMWQ4NDA1YmFhNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""022ad335-dc0d-41ef-bdcb-7e1d8405baa6"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13247:1593,access,access,1593,https://hail.is,https://github.com/hail-is/hail/pull/13247,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"---------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **661/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 7.5 | Relative Path Traversal <br/>[SNYK-PYTHON-ORJSON-6276643](https://snyk.io/vuln/SNYK-PYTHON-ORJSON-6276643) | `orjson:` <br> `3.9.7 -> 3.9.15` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3YTljMjVmNy0wMTBmLTQxNmItYjc0OS1jNzFkY2I4YjY5YjgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdhOWMyNWY3LTAxMGYtNDE2Yi1iNzQ5LWM3MWRjYjhiNjliOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7a9c25f7-010f-416b-b749-c71dcb8b69b8"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14361:1541,access,access,1541,https://hail.is,https://github.com/hail-is/hail/pull/14361,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **566/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzYWE2MzZiYi00NmJmLTQ3MjgtOGVjMC0yMDg0OWE4NzgyZGMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjNhYTYzNmJiLTQ2YmYtNDcyOC04ZWMwLTIwODQ5YTg3ODJkYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""3aa636bb-46bf-4728-8ec0-20849a8782dc"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13444:1675,access,access,1675,https://hail.is,https://github.com/hail-is/hail/pull/13444,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **461/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.5 | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3MThjYjgyZC1jNGU3LTRlNWEtODgzZi02NjQ0NjlmYzA4MGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjcxOGNiODJkLWM0ZTctNGU1YS04ODNmLTY2NDQ2OWZjMDgwYSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""718cb82d-c4e7-4e5a-883f-664469fc080a"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14070:1986,access,access,1986,https://hail.is,https://github.com/hail-is/hail/pull/14070,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **658/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.3 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-5798483](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-5798483) | `aiohttp:` <br> `3.8.4 -> 3.8.5` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2ZWQ3MzlmOS1mZjc4LTQzYzgtYWQwOC05MThjNmRhMWNlOTYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjZlZDczOWY5LWZmNzgtNDNjOC1hZDA4LTkxOGM2ZGExY2U5NiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""6ed739f9-ff78-43c8-ad08-918c6da1ce96"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13284:1564,access,access,1564,https://hail.is,https://github.com/hail-is/hail/pull/13284,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **658/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.3 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-5798483](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-5798483) | `aiohttp:` <br> `3.8.4 -> 3.8.5` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4YTljZTU5Zi0yOTY3LTQ2MTQtOGE5YS1iY2M5YjU1ZWZkZGQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjhhOWNlNTlmLTI5NjctNDYxNC04YTlhLWJjYzliNTVlZmRkZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""8a9ce59f-2967-4614-8a9a-bcc9b55efddd"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13282:1579,access,access,1579,https://hail.is,https://github.com/hail-is/hail/pull/13282,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **658/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.3 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-5798483](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-5798483) | `aiohttp:` <br> `3.8.4 -> 3.8.5` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjZmU2NDEwYi1jYjQ3LTQ2YzgtOTYwYy1kOWRlY2UxMjI5ZTIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImNmZTY0MTBiLWNiNDctNDZjOC05NjBjLWQ5ZGVjZTEyMjllMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""cfe6410b-cb47-46c8-960c-d9dece1229e2"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13286:1570,access,access,1570,https://hail.is,https://github.com/hail-is/hail/pull/13286,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **658/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.3 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-5798483](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-5798483) | `aiohttp:` <br> `3.8.4 -> 3.8.5` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMjk5ZmU1Ni0wNGI1LTQ3MzEtYmUzYS03M2ZmYzgxZTZjYjgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImUyOTlmZTU2LTA0YjUtNDczMS1iZTNhLTczZmZjODFlNmNiOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e299fe56-04b5-4731-be3a-73ffc81e6cb8"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13283:1571,access,access,1571,https://hail.is,https://github.com/hail-is/hail/pull/13283,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **658/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.3 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-5798483](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-5798483) | `aiohttp:` <br> `3.8.4 -> 3.8.5` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmZmEwNjUyZi1hMzc2LTQ0NmQtYWJjNC04NmJhMzUwNmY3MzMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZmYTA2NTJmLWEzNzYtNDQ2ZC1hYmM0LTg2YmEzNTA2ZjczMyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ffa0652f-a376-446d-abc4-86ba3506f733"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13285:1565,access,access,1565,https://hail.is,https://github.com/hail-is/hail/pull/13285,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"---:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-JINJA2-6150717](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `3.1.2 -> 3.1.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0M2ViODJhZS04ZDkwLTRjZWUtYjIzMS01ZDMyYmZiZWM4OWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjQzZWI4MmFlLThkOTAtNGNlZS1iMjMxLTVkMzJiZmJlYzg5YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""43eb82ae-8d90-4cee-b231-5d32bfbec89a"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14136:1803,access,access,1803,https://hail.is,https://github.com/hail-is/hail/pull/14136,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"---:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-JINJA2-6150717](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `3.1.2 -> 3.1.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlOTc1OTMyYy1kNmNhLTQ0NTUtYmU4ZC04NzY1ZGY0MTZjMWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU5NzU5MzJjLWQ2Y2EtNDQ1NS1iZThkLTg3NjVkZjQxNmMxYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e975932c-d6ca-4455-be8d-8765df416c1c"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14141:2121,access,access,2121,https://hail.is,https://github.com/hail-is/hail/pull/14141,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"---:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-JINJA2-6150717](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `3.1.2 -> 3.1.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlYTQ5ODFkZC02M2FmLTQ4YzYtYTIwMC05NjkyZjg2ZTlhNjIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImVhNDk4MWRkLTYzYWYtNDhjNi1hMjAwLTk2OTJmODZlOWE2MiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ea4981dd-63af-48c6-a200-9692f86e9a62"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14140:1677,access,access,1677,https://hail.is,https://github.com/hail-is/hail/pull/14140,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-42010a8000af; spec:; containers:; - command:; - bash; - -c; - |-; set -e; gcloud -q auth activate-service-account --key-file=/test-gsa-key/privateKeyData; gsutil -m cp -r /test/resources/* gs://hail-test-1c9nm/sj0nb47zqys1/pipeline/input/; env:; - name: POD_IP; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: status.podIP; - name: POD_NAME; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: metadata.name; image: gcr.io/hail-vdc/ci-intermediate:oyyg6y2um4kx; imagePullPolicy: IfNotPresent; name: main; resources:; requests:; cpu: 100m; memory: 500M; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /test-gsa-key; name: test-gsa-key; - mountPath: /gsa-key; name: gsa-key; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: default-token-8h99c; readOnly: true; dnsPolicy: ClusterFirst; enableServiceLinks: true; nodeName: gke-vdc-preemptible-pool-9c7148b2-1f89; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: default; serviceAccountName: default; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: test-gsa-key; secret:; defaultMode: 420; optional: false; secretName: test-gsa-key; - name: gsa-key; secret:; defaultMode: 420; secretName: ci-gsa-key; - name: default-token-8h99c; secret:; defaultMode: 420; secretName: default-token-8h99c; status:; conditions:; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; status: ""True""; type: Initialized; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: ""2019",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6625:4208,secur,securityContext,4208,https://hail.is,https://github.com/hail-is/hail/issues/6625,1,['secur'],['securityContext']
Security,"-6.2.4-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, without-vep-520334-sw-rmwj.c.seqr-project.internal): java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:245); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:2015,Checksum,ChecksumFileSystem,2015,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['Checksum'],['ChecksumFileSystem']
Security,"-:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1ZDhmZDhmZC1mZGUxLTRiYmMtYWMzMi0xOTE1NmY0ZDFjZjIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjVkOGZkOGZkLWZkZTEtNGJiYy1hYzMyLTE5MTU2ZjRkMWNmMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/7fad328c-8d01-4768-8813-73d6c644e2d4?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/7fad328c-8d01-4768-8813-73d6c644e2d4?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""5d8fd8fd-fde1-4bbc-ac32-19156f4d1cf2"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13112:1541,access,access,1541,https://hail.is,https://github.com/hail-is/hail/pull/13112,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2YzU3NmY1Yi1lNGM5LTQ4ZjctYmYxNy04YjEzOTIxODlmZDQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjZjNTc2ZjViLWU0YzktNDhmNy1iZjE3LThiMTM5MjE4OWZkNCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""6c576f5b-e4c9-48f7-bf17-8b1392189fd4"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13097:1464,access,access,1464,https://hail.is,https://github.com/hail-is/hail/pull/13097,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIwMzdiOGRmZS1hZDA4LTRmZjUtYTFkOC1hNGM4Nzg2N2NkYjAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjAzN2I4ZGZlLWFkMDgtNGZmNS1hMWQ4LWE0Yzg3ODY3Y2RiMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""037b8dfe-ad08-4ff5-a1d8-a4c87867cdb0"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13159:1556,access,access,1556,https://hail.is,https://github.com/hail-is/hail/pull/13159,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzM2VkMzM4Ny0zZTVmLTRkZDgtYjIxYy1iYzIyNzk4ODViZjMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjMzZWQzMzg3LTNlNWYtNGRkOC1iMjFjLWJjMjI3OTg4NWJmMyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""33ed3387-3e5f-4dd8-b21c-bc2279885bf3"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13107:1449,access,access,1449,https://hail.is,https://github.com/hail-is/hail/pull/13107,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzYWEwNDk2OC02NDIxLTRmODktYTBjYy03MjE4MzExNDNiZGQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjNhYTA0OTY4LTY0MjEtNGY4OS1hMGNjLTcyMTgzMTE0M2JkZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""3aa04968-6421-4f89-a0cc-721831143bdd"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13100:1552,access,access,1552,https://hail.is,https://github.com/hail-is/hail/pull/13100,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiNzM2NzI0Yi1hY2RiLTRiOTUtYWQwMy1hYWI3MjkyZGNlYzQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI3MzY3MjRiLWFjZGItNGI5NS1hZDAzLWFhYjcyOTJkY2VjNCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""b736724b-acdb-4b95-ad03-aab7292dcec4"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13116:1456,access,access,1456,https://hail.is,https://github.com/hail-is/hail/pull/13116,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlNDQxZTBmNS1jZDQ4LTQzZDUtYTdkMy1kMTM4YzQ2ZTc2NTgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU0NDFlMGY1LWNkNDgtNDNkNS1hN2QzLWQxMzhjNDZlNzY1OCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e441e0f5-cd48-43d5-a7d3-d138c46e7658"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13158:1548,access,access,1548,https://hail.is,https://github.com/hail-is/hail/pull/13158,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlZjQxMWYxOC1hM2JiLTQ1YzgtODFjOS1hNmNhNjI4MWI1ZjMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImVmNDExZjE4LWEzYmItNDVjOC04MWM5LWE2Y2E2MjgxYjVmMyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ef411f18-a3bb-45c8-81c9-a6ca6281b5f3"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13108:1539,access,access,1539,https://hail.is,https://github.com/hail-is/hail/pull/13108,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-entryway.jar:?]; 		at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 		at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 		at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 		at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 		at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; 	Caused by: com.google.api.client.http.HttpResponseException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 		at com.google.api.client.http.HttpResponseException$Builder.build(HttpResponseException.java:293) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		... 48 more; Caused by: com.google.api.cl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:26036,access,access,26036,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['access'],['access']
Security,"-java/commit/47e36b651e9abc80f8d711cbff69c821539851c2""><code>47e36b6</code></a> Updating CODEOWNERS for Communication Identity &amp; Common Packages (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32222"">#32222</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/c051757b394000308e0a79bcb93da05875892401""><code>c051757</code></a> Increment package versions for cosmos releases (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32209"">#32209</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-java/compare/v1.2.1...azure-identity_1.7.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.azure:azure-identity&package-manager=gradle&previous-version=1.2.1&new-version=1.7.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12508:4627,secur,security-vulnerabilities,4627,https://hail.is,https://github.com/hail-is/hail/pull/12508,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"-metadata/issues/46"">#46</a> from pytest-dev/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/025be8999a22ae395b0e2b8ae4e7c9fa2334f874""><code>025be89</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/429840f4de26276560961929f21aab79ed305875""><code>429840f</code></a> Avoid running nightly on forks</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/c1968f39609978ec9c6a4bcf91c37c6164483f04""><code>c1968f3</code></a> Fix nightly</li>; <li>See full diff in <a href=""https://github.com/pytest-dev/pytest-metadata/compare/v2.0.1...v2.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-metadata&package-manager=pip&previous-version=2.0.1&new-version=2.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12188:2546,secur,security-vulnerabilities,2546,https://hail.is,https://github.com/hail-is/hail/pull/12188,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"-packages/hail/context.py"", line 345, in init; return init_spark(; File ""<decorator-gen-1760>"", line 2, in init_spark; File ""/opt/homebrew/lib/python3.10/site-packages/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/homebrew/lib/python3.10/site-packages/hail/context.py"", line 424, in init_spark; backend = SparkBackend(; File ""/opt/homebrew/lib/python3.10/site-packages/hail/backend/spark_backend.py"", line 188, in __init__; self._jbackend = hail_package.backend.spark.SparkBackend.apply(; File ""/opt/homebrew/lib/python3.10/site-packages/py4j/java_gateway.py"", line 1304, in __call__; return_value = get_return_value(; File ""/opt/homebrew/lib/python3.10/site-packages/py4j/protocol.py"", line 326, in get_return_value; raise Py4JJavaError(; py4j.protocol.Py4JJavaError: An error occurred while calling z:is.hail.backend.spark.SparkBackend.apply.; : java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x4d740d85) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x4d740d85; 	at org.apache.spark.storage.StorageUtils$.<init>(StorageUtils.scala:213); 	at org.apache.spark.storage.StorageUtils$.<clinit>(StorageUtils.scala); 	at org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:109); 	at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:371); 	at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:311); 	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:359); 	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:189); 	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:277); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:458); 	at is.hail.backend.spark.SparkBackend$.configureAndCreateSparkContext(SparkBackend.scala:148); 	at is.hail.backend.spark.SparkBackend$.apply(SparkBackend.scala:230); 	at is.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12630:1983,access,access,1983,https://hail.is,https://github.com/hail-is/hail/issues/12630,1,['access'],['access']
Security,"-session[aioredis]</code> then it will be necessary to manually install <code>redis</code>).</li>; </ul>; <h2>v2.11.0</h2>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h2>v2.10.0</h2>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp-session/blob/master/CHANGES.txt"">aiohttp-session's changelog</a>.</em></p>; <blockquote>; <h1>2.12.0 (2022-10-28)</h1>; <ul>; <li>Migrated from <code>aioredis</code> to <code>redis</code> (if using redis without installing; <code>aiohttp-session[aioredis]</code> then it will be necessary to manually install <code>redis</code>).</li>; </ul>; <h1>2.11.0 (2021-01-31)</h1>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h1>2.10.0 (2021-12-30)</h1>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; <h1>2.9.0 (2019-11-04)</h1>; <ul>; <li>Fix memcached expiring time (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/398"">#398</a>)</li>; </ul>; <h1>2.8.0 (2019-09-17)</h1>; <ul>; <li>Make this compatible with Python 3.7+. Import from collections.abc, instead; of from collections. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/373"">#373</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/4cedef7c62419de606aca7464a2e3247fdb0dd3c""><code>4cedef7</code></a> Release 2.12 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12499:1405,Encrypt,EncryptedCookieStorage,1405,https://hail.is,https://github.com/hail-is/hail/pull/12499,1,['Encrypt'],['EncryptedCookieStorage']
Security,"-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, without-vep-520334-sw-rmwj.c.seqr-project.internal): java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; 	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); 	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); 	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); 	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:245); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:5856,Checksum,ChecksumFileSystem,5856,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['Checksum'],['ChecksumFileSystem']
Security,"-|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **661/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 7.5 | Improper Neutralization of Special Elements in Data Query Logic <br/>[SNYK-PYTHON-MSAL-5904284](https://snyk.io/vuln/SNYK-PYTHON-MSAL-5904284) | `msal:` <br> `1.24.0 -> 1.24.1` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2NWVkZTk2ZC0xYjZkLTQ1ZjktOTU3OC00NzdjMWNmNDhiZmQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjY1ZWRlOTZkLTFiNmQtNDVmOS05NTc4LTQ3N2MxY2Y0OGJmZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""65ede96d-1b6d-45f9-9578-477c1cf48bfd"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13754:1844,access,access,1844,https://hail.is,https://github.com/hail-is/hail/pull/13754,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **661/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 7.5 | Improper Neutralization of Special Elements in Data Query Logic <br/>[SNYK-PYTHON-MSAL-5904284](https://snyk.io/vuln/SNYK-PYTHON-MSAL-5904284) | `msal:` <br> `1.24.0 -> 1.24.1` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhYjlhNGM2ZS0xOTg1LTRmYTctYjg0OC0zOTNmOWE3MGJkMWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFiOWE0YzZlLTE5ODUtNGZhNy1iODQ4LTM5M2Y5YTcwYmQxYSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ab9a4c6e-1985-4fa7-b848-393f9a70bd1a"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13753:1836,access,access,1836,https://hail.is,https://github.com/hail-is/hail/pull/13753,2,"['access', 'authoriz']","['access', 'authorized']"
Security,". ### Notes of Annoyance. `aiohttp` silently ignores most invalid TLS requests, this makes debugging a TLS; issue difficult. `aiohttp`'s `raise_for_status` does not include the HTTP body in the; message. NGINX sometimes returns 400 in response to TLS issues with a proxy. It; includes crucial details in the HTTP body. I usually debug these issues by; sshing to the client pod and using curl to manually reproduce the error. Readiness and liveness probes cannot use HTTP. Although k8s supports HTTPS, it; does not support so-called ""mTLS"" or ""mutual TLS."" This is fancy verbiage for; servers that require clients to send trusted certificates. I will eventually require; this. There is a lot of information in GitHub issues and the Istio web pages; about this, but at the end of the day, kubernetes does not support this. TCP; probes are the best we can do. There [was a; PR](kubernetes/kubernetes#61231) to allow httpGet probes; to send the kubelet certificate, but it was closed because, apparently, the; [httpGet probes can be targeted at arbitrary IP; addresses](kubernetes/kubernetes#61231 (review)) (what; the hell?), ergo Confused Deputy. ### Future Work. - Require TLS 1.3 everywhere.; - Comply with Mozilla's ""Modern"" recommendations.; - [Incoming Trust](#incoming-trust).; - Refresh certificates after deploying new ones. ### Footnotes. [1] TLS: Transport Layer Security. Preceded by Secure Sockets Layer (SSL) which; is not obsolete and insecure. After SSL version 3, a new version of SSL was; proposed in RFC 2246. This new version was backwards-incompatible and was; thus given a new name: Transport Layer Security. In common discussion, SSL; and TLS are used interchangeable. Indeed, the python TLS library is called; `ssl`. [2] Forward secrecy is a property of an encryption system. Forward secrecy means; a message cannot be decrypted in the future by an adversary who learned one; of the private keys. For example, imagine you are sending sensitive messages; to another individual. If",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:11152,certificate,certificate,11152,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['certificate'],['certificate']
Security,". ### What went wrong (all error messages here, including the full java stack trace):; 2018-12-04 22:13:57 root: ERROR: IllegalArgumentException: null; From java.lang.IllegalArgumentException: null; at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:46); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:443); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:426); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:103); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:426); at org.apache.xbean.asm5.ClassReader.a(Unknown Source); at org.apache.xbean.asm5.ClassReader.b(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:257); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:256); at scala.collection.immutable.List.foreach(List.scala:381); at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(Clo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4896:1369,Hash,HashTable,1369,https://hail.is,https://github.com/hail-is/hail/issues/4896,1,['Hash'],['HashTable']
Security,". (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/206"">#206</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/308f153f91b7942476f2d4ddda3dc8c99933d598""><code>308f153</code></a> ci: add workflow to publish sdist/wheel to PyPI (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/202"">#202</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/961624063383cbcdc78a61b1d18448429a61a489""><code>9616240</code></a> [chore] update changelog</li>; <li>Additional commits viewable in <a href=""https://github.com/tomplus/kubernetes_asyncio/compare/v19.15.1...23.6.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=kubernetes-asyncio&package-manager=pip&previous-version=19.15.1&new-version=23.6.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:15811,secur,security-vulnerabilities,15811,https://hail.is,https://github.com/hail-is/hail/pull/11957,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,". Running on Ubuntu 18.04. I had installed openjdk-11-jre-headless instead of openjdk-8-jre-headless. ### Hail version:; 0.2 ; ### What you did:. ### What went wrong (all error messages here, including the full java stack trace):; 2018-12-04 22:13:57 root: ERROR: IllegalArgumentException: null; From java.lang.IllegalArgumentException: null; at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:46); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:443); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:426); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:103); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:426); at org.apache.xbean.asm5.ClassReader.a(Unknown Source); at org.apache.xbean.asm5.ClassReader.b(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:257); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:256); at s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4896:1232,Hash,HashMap,1232,https://hail.is,https://github.com/hail-is/hail/issues/4896,1,['Hash'],['HashMap']
Security,"..</li>; <li><a href=""https://github.com/apache/spark/commit/be891ad99083564a7bf7f421e00b2cc4759a679f""><code>be891ad</code></a> [SPARK-39551][SQL][3.2] Add AQE invalid plan check</li>; <li><a href=""https://github.com/apache/spark/commit/1c0bd4c15a28d7c6a2dca846a5b8d0eb1d152aae""><code>1c0bd4c</code></a> [SPARK-39656][SQL][3.2] Fix wrong namespace in DescribeNamespaceExec</li>; <li><a href=""https://github.com/apache/spark/commit/3d084fe3217bea9af4c544f10ead8a2e5b97dad4""><code>3d084fe</code></a> [SPARK-39677][SQL][DOCS][3.2] Fix args formatting of the regexp and like func...</li>; <li>Additional commits viewable in <a href=""https://github.com/apache/spark/compare/v3.1.3...v3.2.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyspark&package-manager=pip&previous-version=3.1.3&new-version=3.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12452:2464,secur,security-vulnerabilities,2464,https://hail.is,https://github.com/hail-is/hail/pull/12452,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,".0 failed 4 times, most recent failure: Lost task 12.3 in stage 103.0 (TID 644994, scc-q21.scc.bu.edu, executor 2): java.io.FileNotFoundException: /scratch/.writeBlocksRDD-l5om7fTy3akZKCYbLDY4AD.crc (Too many open files); at java.io.FileOutputStream.open0(Native Method); at java.io.FileOutputStream.open(FileOutputStream.java:270); at java.io.FileOutputStream.<init>(FileOutputStream.java:213); at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:222); at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209); at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307); at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296); at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328); at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:402); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:778); at is.hail.io.fs.HadoopFS.createNoCompression(HadoopFS.scala:60); at is.hail.io.fs.FS$class.create(FS.scala:151); at is.hail.io.fs.HadoopFS.create(HadoopFS.scala:56); at is.hail.linalg.WriteBlocksRDD$$anonfun$62.apply(BlockMatrix.scala:1838); at is.hail.linalg.WriteBlocksRDD$$anonfun$62.apply(BlockMatrix.scala:1829); at scala.Array$.tabulate(Array.scala:331); at is.hail.linalg.WriteBlocksRDD.compute(BlockMatrix.scala:1829); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403:10605,Checksum,ChecksumFileSystem,10605,https://hail.is,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403,1,['Checksum'],['ChecksumFileSystem']
Security,".1 (2022-08-04)</h2>; <h3>Bugs Fixed</h3>; <ul>; <li>Fixed two rare issues with ranged blob download when using client-side encryption V1 or V2.</li>; </ul>; <h2>azure-storage-blob_12.13.0</h2>; <h2>12.13.0 (2022-07-07)</h2>; <h3>Bugs Fixed</h3>; <ul>; <li>Stable release of features from 12.13.0b1.</li>; <li>Added support for deleting versions in <code>delete_blobs</code> by supplying <code>version_id</code>.</li>; </ul>; <h2>azure-storage-blob_12.13.0b1</h2>; <h2>12.13.0b1 (2022-06-15)</h2>; <h3>Features Added</h3>; <ul>; <li>Added support for service version 2021-08-06.</li>; <li>Added a new version of client-side encryption for blobs (version 2.0) which utilizes AES-GCM-256 encryption.; If you are currently using client-side encryption, it is <strong>highly recommended</strong> to switch to a form of server-side; encryption (Customer-Provided Key, Encryption Scope, etc.) or version 2.0 of client-side encryption. The encryption; version can be specified on any client constructor via the <code>encryption_version</code> keyword (<code>encryption_version='2.0'</code>).</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/13989b5b1253e26f3f3ee24013a3013fea1bdf73""><code>13989b5</code></a> [Storage] Fix ranged download for client-side encryption (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25522"">#25522</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e90af4374bfd7c139737ad2888fcd269b3023520""><code>e90af43</code></a> DataLake funny dependency (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25129"">#25129</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/cbec3383039ffeb46760268d1a8f81cf1b4d2219""><code>cbec338</code></a> [AutoRelease] t2-storagecache-2022-07-06-35884(Do not merge) (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-pyt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12109:1268,encrypt,encryption,1268,https://hail.is,https://github.com/hail-is/hail/pull/12109,1,['encrypt'],['encryption']
Security,".1.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/java-native-access/jna/blob/master/CHANGES.md"">jna's changelog</a>.</em></p>; <blockquote>; <h1>Release 5.12.1</h1>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1447"">#1447</a>: Null-check cleanable in <code>c.s.j.Memory#close</code> - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; </ul>; <h1>Release 5.12.0</h1>; <h2>Features</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1433"">#1433</a>: Add <code>CFEqual</code>, <code>CFDictionaryRef.ByReference</code>, <code>CFStringRef.ByReference</code> to <code>c.s.j.p.mac.CoreFoundation</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/978"">#978</a>: Remove use of finalizers in JNA and improve concurrency for <code>Memory</code>, <code>CallbackReference</code> and <code>NativeLibrary</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1440"">#1440</a>: Support for LoongArch64 - <a href=""https://github.com/Panxuefeng-loongson""><code>@​Panxuefeng-loongson</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1444"">#1444</a>: Update embedded libffi to 1f14b3fa92d4442a60233e9596ddec428a985e3c and rebuild native libraries - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1438"">#1438</a>: Handle arrays in structures with differing size - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/jav",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:980,access,access,980,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,".16"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""},{""name"":""wheel"",""from"":""0.30.0"",""to"":""0.38.0""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512"",""SNYK-PYTHON-WHEEL-3180413""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,624,531,604,589,726,434,589,449,696,589,479,519,509,711,701,586,586,384,494,539,589],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14108:12931,validat,validation,12931,https://hail.is,https://github.com/hail-is/hail/pull/14108,1,['validat'],['validation']
Security,".16.2 to 2.16.4 (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8092"">#8092</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5ff4b3c405ee741a46d6743209cd32259f939313""><code>5ff4b3c</code></a> Update version</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/94462eea445d43bf574ca6321349f67219ce9cb0""><code>94462ee</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/3957"">#3957</a>/79fe2045 backport][3.9] Improve test suite handling of paths, temp ...</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/24a6d64966d99182e95f5d3a29541ef2fec397ad""><code>24a6d64</code></a> Release v3.9.2 (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8082"">#8082</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/9118a5831e8a65b8c839eb7e4ac983e040ff41df""><code>9118a58</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8079"">#8079</a>/1c335944 backport][3.9] Validate static paths (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8080"">#8080</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/435ad46e6c26cbf6ed9a38764e9ba8e7441a0e3b""><code>435ad46</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/3955"">#3955</a>/8960063e backport][3.9] Replace all tmpdir fixtures with tmp_path (...</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/d33bc21414e283c9e6fe7f6caf69e2ed60d66c82""><code>d33bc21</code></a> Improve validation in HTTP parser (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8074"">#8074</a>) (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8078"">#8078</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/0d945d1be08f2ba8475513216a66411f053c3217""><code>0d945d1</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7916"">#7916</a>/822fbc74 backport][3.9] Add more information to contributing page (...</li>; <li>Additional commits viewable i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14219:4845,Validat,Validate,4845,https://hail.is,https://github.com/hail-is/hail/pull/14219,2,['Validat'],['Validate']
Security,".9.19...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/7d6742115bcea6b848a289fdf5c4e4bbafc4cf18""><code>7d67421</code></a> build(deps): update dependency com.google.cloud:google-cloud-shared-config to...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/3bf403e94c035e6cf936e062a1ced2b5221b3912""><code>3bf403e</code></a> deps: update dependency org.apache.httpcomponents:httpcore to v4.4.16 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1786"">#1786</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/java-storage/compare/v1.106.0...v2.16.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.cloud:google-cloud-storage&package-manager=gradle&previous-version=1.106.0&new-version=2.16.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12545:13073,secur,security-vulnerabilities,13073,https://hail.is,https://github.com/hail-is/hail/pull/12545,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,".; <p>.. _v41-0-0:</p>; <p>41.0.0 - 2023-05-30; </code></pre></p>; <ul>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for OpenSSL less than 1.1.1d has been; removed. Users on older version of OpenSSL will need to upgrade.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for Python 3.6 has been removed.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Dropped support for LibreSSL &lt; 3.6.</li>; <li>Updated the minimum supported Rust version (MSRV) to 1.56.0, from 1.48.0.</li>; <li>Updated Windows, macOS, and Linux wheels to be compiled with OpenSSL 3.1.1.</li>; <li>Added support for the :class:<code>~cryptography.x509.OCSPAcceptableResponses</code>; OCSP extension.</li>; <li>Added support for the :class:<code>~cryptography.x509.MSCertificateTemplate</code>; proprietary Microsoft certificate extension.</li>; <li>Implemented support for equality checks on all asymmetric public key types.</li>; <li>Added support for <code>aes256-gcm@openssh.com</code> encrypted keys in; :func:<code>~cryptography.hazmat.primitives.serialization.load_ssh_private_key</code>.</li>; <li>Added support for obtaining X.509 certificate signature algorithm parameters; (including PSS) via; :meth:<code>~cryptography.x509.Certificate.signature_algorithm_parameters</code>.</li>; <li>Support signing :class:<code>~cryptography.hazmat.primitives.asymmetric.padding.PSS</code>; X.509 certificates via the new keyword-only argument <code>rsa_padding</code> on; :meth:<code>~cryptography.x509.CertificateBuilder.sign</code>.</li>; <li>Added support for; :class:<code>~cryptography.hazmat.primitives.ciphers.aead.ChaCha20Poly1305</code>; on BoringSSL.</li>; </ul>; <p>.. _v40-0-2:</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/d02de9f26e9a2353e89427c1cea8b9ed2bae969e""><code>d02de9f</code></a> changelog and version bump (<a href=""https://redirect.github.com/pyca/cryptography/issues/9008"">#9008</a>)</li>; <li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13146:1494,encrypt,encrypted,1494,https://hail.is,https://github.com/hail-is/hail/pull/13146,1,['encrypt'],['encrypted']
Security,".; argon2-cffi-bindings 21.2.0 requires cffi, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium seve",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14211:1731,Access,Access,1731,https://hail.is,https://github.com/hail-is/hail/pull/14211,2,['Access'],['Access']
Security,".</li>; <li>Added a mention of the size of the connection pool when discarding a connection due to the pool being full.</li>; <li>Added explicit support for Python 3.11.</li>; <li>Deprecated the <code>Retry.MAX_BACKOFF</code> class property in favor of <code>Retry.DEFAULT_MAX_BACKOFF</code>; to better match the rest of the default parameter names. <code>Retry.MAX_BACKOFF</code> is removed in v2.0.</li>; <li>Changed location of the vendored <code>ssl.match_hostname</code> function from <code>urllib3.packages.ssl_match_hostname</code>; to <code>urllib3.util.ssl_match_hostname</code> to ensure Python 3.10+ compatibility after being repackaged; by downstream distributors.</li>; <li>Fixed absolute imports, all imports are now relative.</li>; </ul>; <h1>1.26.7 (2021-09-22)</h1>; <ul>; <li>Fixed a bug with HTTPS hostname verification involving IP addresses and lack; of SNI. (Issue <a href=""https://github-redirect.dependabot.com/urllib3/urllib3/issues/2400"">#2400</a>)</li>; <li>Fixed a bug where IPv6 braces weren't stripped during certificate hostname; matching. (Issue <a href=""https://github-redirect.dependabot.com/urllib3/urllib3/issues/2240"">#2240</a>)</li>; </ul>; <h1>1.26.6 (2021-06-25)</h1>; <ul>; <li>Deprecated the <code>urllib3.contrib.ntlmpool</code> module. urllib3 is not able to support; it properly due to <code>reasons listed in this issue &lt;https://github.com/urllib3/urllib3/issues/2282&gt;</code>_.; If you are a user of this module please leave a comment.</li>; <li>Changed <code>HTTPConnection.request_chunked()</code> to not erroneously emit multiple; <code>Transfer-Encoding</code> headers in the case that one is already specified.</li>; <li>Fixed typo in deprecation message to recommend <code>Retry.DEFAULT_ALLOWED_METHODS</code>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/urllib3/urllib3/commit/b1f60e44d43b13e5272d5b6003f125af9c25c8ad""><code>b1f60e4</code></a> Release 1.26.8</li>; <li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11532:4657,certificate,certificate,4657,https://hail.is,https://github.com/hail-is/hail/pull/11532,1,['certificate'],['certificate']
Security,".Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:170); at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:45); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:108); at scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:108); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:108); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at org.apache.spark.SparkStatusTracker.getActiveStageIds(SparkStatusTracker.scala:61); at org.apache.spark.ui.ConsoleProgressBar.org$apache$spark$ui$ConsoleProgressBar$$refresh(ConsoleProgressBar.scala:67); at org.apache.spark.ui.ConsoleProgressBar$$anon$1.run(ConsoleProgressBar.scala:55); at java.util.TimerThread.mainLoop(Timer.java:555); at java.util.TimerThread.run(Timer.java:505); ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); /restricted/projectnb/ukbiobank/ad/analysis/ad.v1/bgen2mt.py in <module>; 6 sample=""/project/ukbiobank/imp/uk",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:4024,Hash,HashMap,4024,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Hash'],['HashMap']
Security,.Parser$$anonfun$parseTypedExpr$1.apply(Parser.scala:102); 	at scala.Function0$class.apply$mcJ$sp(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcJ$sp(AbstractFunction0.scala:12); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:81); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:79); 	at is.hail.utils.BinaryHeap.isLeftFavoredTie(BinaryHeap.scala:16); 	at is.hail.utils.BinaryHeap.is$hail$utils$BinaryHeap$$bubbleUp(BinaryHeap.scala:161); 	at is.hail.utils.BinaryHeap.insert(BinaryHeap.scala:40); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:101); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:100); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:100); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:86); 	at is.hail.utils.Graph.maximalIndependentSet(Graph.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745); ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3704:2602,Hash,HashMap,2602,https://hail.is,https://github.com/hail-is/hail/pull/3704,3,['Hash'],['HashMap']
Security,".call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; Caused by: is.hail.relocated.com.google.cloud.storage.StorageException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 	at is.hail.relocated.com.google.cloud.storage.StorageException.translate(StorageException.java:165) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:298) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1029) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ResumableMedia.lambda$startUploadForBlobInfo$0(ResumableMedia.java:40) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.gax.retrying.Dir",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:10938,access,access,10938,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['access'],['access']
Security,".com/Crain-32""><code>@​crain-32</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1459"">#1459</a>: Add <code>VirtualLock</code> and <code>VirtualUnlock</code> in <code>c.s.j.p.win32.Kernel32</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1471"">#1471</a>: Add <code>c.s.j.p.win32.Advapi32Util#isCurrentProcessElevated</code> and associated Types - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1474"">#1474</a>: Add <code>c.s.j.p.win32.WbemCli#IWbemClassObject.IWbemQualifierSet</code>, <code>IWbemServices.GetObject</code>, <code>IWbemContext.SetValue</code> and associated methods - <a href=""https://github.com/rchateauneu""><code>@​rchateauneu</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1482"">#1482</a>: Add multilingual support of <code>Kernel32Util.formatMessage</code> - <a href=""https://github.com/overpathz""><code>@​overpathz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1490"">#1490</a>: Adds support for a custom <code>SymbolProvider</code> in <code>NativeLibrary</code> &amp; <code>Library</code> - <a href=""https://github.com/soywiz""><code>@​soywiz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1491"">#1491</a>: Update libffi to v3.4.4 - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1487"">#1487</a>: Add 'uses' information to OSGI metadata in MANIFEST.MF to improve stability of package resolution - <a href=""https://github.com/sratz""><code>@​sratz</code></a>.</li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1452"">#1452</a>: Fix memor",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:1501,access,access,1501,https://hail.is,https://github.com/hail-is/hail/pull/12886,1,['access'],['access']
Security,".com/ai/nanoid/issues/335"">#335</a>)</li>; <li><a href=""https://github.com/ai/nanoid/commit/90a446fef3ecaac78e5af2ea01025c4f40182e2b""><code>90a446f</code></a> Update benchmark results</li>; <li><a href=""https://github.com/ai/nanoid/commit/8ba2319b579895cc1f9060b9946a44852f97c509""><code>8ba2319</code></a> bench: add <code>@​napi-rs/uuid</code> v4 (<a href=""https://github-redirect.dependabot.com/ai/nanoid/issues/333"">#333</a>)</li>; <li><a href=""https://github.com/ai/nanoid/commit/f4257780ece488734a65c176e80c2fd8ab6aab8e""><code>f425778</code></a> Release 3.1.32 version</li>; <li>Additional commits viewable in <a href=""https://github.com/ai/nanoid/compare/3.1.23...3.2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=nanoid&package-manager=npm_and_yarn&previous-version=3.1.23&new-version=3.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11284:3592,secur,security-vulnerabilities,3592,https://hail.is,https://github.com/hail-is/hail/pull/11284,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,".com/chardet/chardet/issues/244"">#244</a>)</li>; <li><a href=""https://github.com/chardet/chardet/commit/49b8341f507bed68f7d3ff7138bb97047a0e04f0""><code>49b8341</code></a> Configure setuptools using the declarative syntax in setup.cfg (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/239"">#239</a>)</li>; <li><a href=""https://github.com/chardet/chardet/commit/5c73bfcdf819251d1a1d0de672e34480ebafbe1f""><code>5c73bfc</code></a> Run all pre-commit hooks on pull requests (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/236"">#236</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/chardet/chardet/compare/4.0.0...5.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=chardet&package-manager=pip&previous-version=4.0.0&new-version=5.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12107:5791,secur,security-vulnerabilities,5791,https://hail.is,https://github.com/hail-is/hail/pull/12107,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,".com/protocolbuffers/protobuf) from 3.20.1 to 4.21.6.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/protocolbuffers/protobuf/releases"">protobuf's releases</a>.</em></p>; <blockquote>; <h2>Protocol Buffers v3.20.2</h2>; <h1>C++</h1>; <ul>; <li>Reduce memory consumption of MessageSet parsing</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf"">Security Advisory for C++ and Python users</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=4.21.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12227:999,secur,security-vulnerabilities,999,https://hail.is,https://github.com/hail-is/hail/pull/12227,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,".dependabot.com/pandas-dev/pandas/issues/50"">#50</a>...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/54b40379e3fe6825f676cf02767ee81adb6ffeb5""><code>54b4037</code></a> Backport PR on Branch 1.5.x (REV: revert deprecation of Series.<strong>getitem</strong> sl...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/71db310a328a0dfa194ef0fe2b95238817b4f419""><code>71db310</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/50396"">#50396</a> on branch 1.5.x (BUG/COMPAT: fix assert_* functions for ne...</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.5...v1.5.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.5&new-version=1.5.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Depe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12610:5649,secur,security-vulnerabilities,5649,https://hail.is,https://github.com/hail-is/hail/pull/12610,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:170); at scala.collection.mutable.ListBuffer.$p,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:2667,Hash,HashMap,2667,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Hash'],['HashMap']
Security,.invoke(Method.java:566) ~[?:?]; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119) [jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]; 	at java.lang.Thread.run(Thread.java:829) [?:?]; Caused by: com.fasterxml.jackson.core.exc.StreamConstraintsException: String length (20013488) exceeds the maximum length (20000000); 	at com.fasterxml.jackson.core.StreamReadConstraints.validateStringLength(StreamReadConstraints.java:324) ~[jackson-core-2.15.2.jar:2.15.2]; 	at com.fasterxml.jackson.core.util.ReadConstrainedTextBuffer.validateStringLength(ReadConstrainedTextBuffer.java:27) ~[jackson-core-2.15.2.jar:2.15.2]; 	at com.fasterxml.jackson.core.util.TextBuffer.finishCurrentSegment(TextBuffer.java:939) ~[jackson-core-2.15.2.jar:2.15.2]; 	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._finishString2(UTF8StreamJsonParser.java:2584) ~[jackson-core-2.15.2.jar:2.15.2]; 	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._finishAndReturnString(UTF8StreamJsonParser.java:2560) ~[jackson-core-2.15.2.jar:2.15.2]; 	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.getText(UTF8StreamJsonParser.java:335) ~[jackson-core-2.15.2.jar:2.15.2]; 	at is.hail.relocated.org.json4s.jackson.JValueDeserializer._deserialize$1(JValueDeserializer.scala:26) ~[gs:__hail-query-daaf463550_jars_4c60fddb171a52c21f41a81995c53a28e375c26b.jar.jar:?]; 	at is.hail.relocated.org.json4s.jackson.JValueDeserializer._deserialize$1(JValueDeserializer.scala:48) ~[gs:__hail-query-daaf463550_jars_4c60fddb171a52c21f41a81995c53a28e375c26b.jar.jar:?]; 	at is.hai,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14749:3539,validat,validateStringLength,3539,https://hail.is,https://github.com/hail-is/hail/issues/14749,1,['validat'],['validateStringLength']
Security,.java:196); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:470); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:251); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.Exec,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:7278,access,access,7278,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699,2,['access'],['access']
Security,.java:498); at is.hail.JVMEntryway$1.run(JVMEntryway.java:105); ... 7 more; Caused by: is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/rwalters-hail-tmp/o?name=merged_round2_sumstats.fix_lowconf.mt/entries/rows/parts/part-15801-2fde3786-67cb-42ed-8aac-f900cfcc4c00&uploadType=resumable&upload_id=ADPycduMEzX6d_uX4CiP6_XItJKmP8UnUnYBfyPoselMbyLUkxs1wDLPnxWl5gXr5LnBaVntYR_i7jchyxgVsRb_5PknvcCIcfDJ; chunkOffset: 16777216; chunkLength: 0; localOffset: 0; remoteOffset: 16777216; lastChunk: false. at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:267); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103); at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76); at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.flushBuffer(BlobWriteChannel.java:189); at is.hail.relocated.com.google.cloud.BaseWriteChannel.flush(BaseWriteChannel.java:112); at is.hail.relocated.com.google.cloud.BaseWriteChannel.write(BaseWriteChannel.java:139); at is.hail.io.fs.GoogleStorageFS$$anon$2.flush(GoogleStorageFS.scala:270); at is.hail.io.fs.FSPositionedOutputStream.write(FS.scala:218); at java.io.DataOutputStream.write(DataOutputStream.java:107); at is.hail.utils.richUtils.ByteTrackingOutputStream.write(ByteTr,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950:3124,access,access,3124,https://hail.is,https://github.com/hail-is/hail/issues/12950,1,['access'],['access']
Security,".k8s.io/v1, Resource=roles"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=Role""; Name: ""batch-pods-admin"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""Role"" ""metadata"":map[""name"":""batch-pods-admin"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""rules"":[map[""apiGroups"":[""""] ""resources"":[""pods""] ""verbs"":[""get"" ""list"" ""watch"" ""create"" ""update"" ""patch"" ""delete""]] map[""apiGroups"":[""""] ""resources"":[""pods/log""] ""verbs"":[""get""]]]]}; from server for: ""deployment.yaml"": roles.rbac.authorization.k8s.io ""batch-pods-admin"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get roles.rbac.authorization.k8s.io in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=rolebindings"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=RoleBinding""; Name: ""batch-pods-admin-binding"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""RoleBinding"" ""metadata"":map[""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""] ""name"":""batch-pods-admin-binding"" ""namespace"":""batch-pods""] ""roleRef"":map[""apiGroup"":"""" ""kind"":""Role"" ""name"":""batch-pods-admin""] ""subjects"":[map[""kind"":""ServiceAccount"" ""name"":""batch-svc"" ""namespace"":""default""]]]}; from server for: ""deployment.yaml"": rolebindings.rbac.authorization.k8s.io ""batch-pods-admin-binding"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get rolebindings.rbac.authorization.k8s.io in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""apps/v1beta2, Resource=deployments"", GroupVersionKind: ""apps/v1beta2, Kind=Deployment""; Name: ""batch-deployment"", Namespace",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4609:2403,authoriz,authorization,2403,https://hail.is,https://github.com/hail-is/hail/issues/4609,1,['authoriz'],['authorization']
Security,.lang.reflect.Method.invoke(Method.java:498); E 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:105); E 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); E 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); E 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); E 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); E 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); E 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); E 	at java.lang.Thread.run(Thread.java:748); E ; E java.util.concurrent.TimeoutException: Did not observe any item or terminal signal within 5000ms in 'flatMap' (and no fallback has been configured); E 	at reactor.core.publisher.FluxTimeout$TimeoutMainSubscriber.handleTimeout(FluxTimeout.java:294); E 	at reactor.core.publisher.FluxTimeout$TimeoutMainSubscriber.doTimeout(FluxTimeout.java:279); E 	at reactor.core.publisher.FluxTimeout$TimeoutTimeoutSubscriber.onNext(FluxTimeout.java:418); E 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79); E 	at reactor.core.publisher.MonoDelay$MonoDelayRunnable.propagateDelay(MonoDelay.java:270); E 	at reactor.core.publisher.MonoDelay$MonoDelayRunnable.run(MonoDelay.java:285); E 	at reactor.core.scheduler.SchedulerTask.call(SchedulerTask.java:68); E 	at reactor.core.scheduler.SchedulerTask.call(SchedulerTask.java:28); E 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); E 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180); E 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293); E 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); E 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); E 	at java.lang.Thread.run(Thread.java:748). ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11883#issuecomment-1144890222:5498,access,access,5498,https://hail.is,https://github.com/hail-is/hail/pull/11883#issuecomment-1144890222,1,['access'],['access']
Security,".onError(DAGScheduler.scala:1741); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:52); 2019-01-22 13:12:06 AbstractConnector: INFO: Stopped Spark@1433e9ec{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-01-22 13:12:06 SparkUI: INFO: Stopped Spark web UI at http://10.48.225.55:4040; 2019-01-22 13:12:06 DAGScheduler: INFO: Job 0 failed: fold at RVD.scala:603, took 14.445174 s; 2019-01-22 13:12:06 DAGScheduler: INFO: ResultStage 0 (fold at RVD.scala:603) failed in 14.237 s due to Stage cancelled because SparkContext was shut down; 2019-01-22 13:12:06 root: ERROR: SparkException: Job 0 cancelled because SparkContext was shut down; From org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down; at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:820); at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:818); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:818); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1750); at org.apache.spark.util.EventLoop.stop(EventLoop.scala:83); at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1669); at org.apache.spark.SparkContext$$anonfun$stop$8.apply$mcV$sp(SparkContext.scala:1928); at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317); at org.apache.spark.SparkContext.stop(SparkContext.scala:1927); at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:1872); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1089); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.ap",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:206849,Hash,HashSet,206849,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['Hash'],['HashSet']
Security,".org/en/master/changes.html</a></p>; <h2>v5.0.0</h2>; <p>No release notes provided.</p>; <h2>v5.0.0b1</h2>; <p>Changelog: <a href=""https://www.sphinx-doc.org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.5.0</h2>; <p>Changelog: <a href=""https://www.sphinx-doc.org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.4.0</h2>; <p>Changelog: <a href=""https://www.sphinx-doc.org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.3.1</h2>; <p>No release notes provided.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/sphinx-doc/sphinx/blob/5.x/CHANGES"">sphinx's changelog</a>.</em></p>; <blockquote>; <h1>Release 5.0.2 (released Jun 17, 2022)</h1>; <h2>Features added</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10523"">#10523</a>: HTML Theme: Expose the Docutils's version info tuple as a template; variable, <code>docutils_version_info</code>. Patch by Adam Turner.</li>; </ul>; <h2>Bugs fixed</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10538"">#10538</a>: autodoc: Inherited class attribute having docstring is documented even; if :confval:<code>autodoc_inherit_docstring</code> is disabled</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10509"">#10509</a>: autosummary: autosummary fails with a shared library</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10497"">#10497</a>: py domain: Failed to resolve strings in Literal. Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10523"">#10523</a>: HTML Theme: Fix double brackets on citation references in Docutils 0.18+.; Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10534"">#10534</a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11925:1486,Expose,Expose,1486,https://hail.is,https://github.com/hail-is/hail/pull/11925,1,['Expose'],['Expose']
Security,".p.win32.Crypt32</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1411"">#1411</a>: Do not throw <code>Win32Exception</code> on success for empty section in <code>Kernel32Util#getPrivateProfileSection</code> - <a href=""https://github.com/mkarg""><code>@​mkarg</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1414"">#1414</a>: Fix definition of <code>c.s.j.p.unix.X11.XK_Shift_R</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1323"">#1323</a>. Fix crashes in direct callbacks on mac OS aarch64 - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1422"">#1422</a>: Load jawt library relative to <code>sun.boot.library.path</code> system on unix OSes - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1427"">#1427</a>: Rebuild all binaries with fix from <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1422"">#1422</a> and <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1323"">#1323</a> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; </ul>; <h1>Release 5.10.0</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/java-native-access/jna/commit/3705b849892aa3c37e5608e640eff19047811a5c""><code>3705b84</code></a> Release 5.12.1</li>; <li><a href=""https://github.com/java-native-access/jna/commit/2f919e56bad203494fe9589206d6d23f27ef4f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:4794,access,access,4794,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,".png ""medium severity"") | Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;) <br/>[SNYK-PYTHON-AIOHTTP-6209406](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209406) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-6209407](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209407) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYT",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14259:2666,Access,Access,2666,https://hail.is,https://github.com/hail-is/hail/pull/14259,1,['Access'],['Access']
Security,.provider.CipherCore.doFinal(CipherCore.java:941) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.AESCipher.engineDoFinal(AESCipher.java:491) ~[sunjce_provider.jar:1.8.0_392]; 	at javax.crypto.CipherSpi.bufferCrypt(CipherSpi.java:779) ~[?:1.8.0_392]; 	at javax.crypto.CipherSpi.engineDoFinal(CipherSpi.java:730) ~[?:1.8.0_392]; 	at javax.crypto.Cipher.doFinal(Cipher.java:2463) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLCipher$T12GcmReadCipherGenerator$GcmReadCipher.decrypt(SSLCipher.java:1606) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:262) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$Scattering,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:8996,secur,security,8996,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352,1,['secur'],['security']
Security,".py"", line 21, in <module>; rg37.add_sequence(; File ""<decorator-gen-34>"", line 2, in add_sequence; File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hail/genetics/reference_genome.py"", line 390, in add_sequence; Env.backend().add_sequence(self.name, fasta_file, index_file); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hail/backend/service_backend.py"", line 548, in add_sequence; self.validate_file(blob); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hail/backend/service_backend.py"", line 337, in validate_file; validate_file(uri, self._async_fs, validate_scheme=True); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiotools/validators.py"", line 19, in validate_file; return hail_event_loop().run_until_complete(; File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/nest_asyncio.py"", line 99, in run_until_complete; return f.result(); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/asyncio/futures.py"", line 201, in result; raise self._exception; File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/asyncio/tasks.py"", line 256, in __step; result = coro.send(None); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiotools/validators.py"", line 38, in _async_validate_file; if not await fs.is_hot_storage(location):; File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiocloud/aiogoogle/client/storage_client.py"", line 630, in is_hot_storage; return (await self._storage_client.bucket_info(location))[""storag",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14291:2205,validat,validators,2205,https://hail.is,https://github.com/hail-is/hail/issues/14291,1,['validat'],['validators']
Security,.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); 	Suppressed: is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-2LzGioRNy6RqIS2pfXIoSO&uploadType=resumable&upload_id=ADPycdvZ5HhnGfOKt5TE1qXWiHpqIpZnXVTYWuWUCXNPRF9HqyCB-4LvRsxNX6SUWRgk13pYrzYaa9-wXlvNZt1oct0ptaEz0bS3; chunkOffset: 16777216; chunkLength: 16777216; localOffset: 268435456; remoteOffset: 285212672; lastChunk: false. 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:267); 		at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 		at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103); 		at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 		at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.flushBuffer(BlobWriteChannel.java:189); 		at is.hail.relocated.com.google.cloud.BaseWriteChannel.flush(BaseWriteChannel.java:112); 		at is.hail.relocated.com.google.cloud.BaseWriteChannel.write(BaseWriteChannel.java:139); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$flush$1(GoogleStorageFS.scala:317); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:299); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.flush(GoogleStorageFS.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911:5873,access,access,5873,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911,1,['access'],['access']
Security,.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply$mcVJ$sp(TaskSchedulerImpl.scala:243); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:235); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:235); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:234); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.TaskSchedulerImpl.cancelTasks(TaskSchedulerImpl.scala:234); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply$mcVI$sp(DAGScheduler.scala:1543); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spar,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:200471,Hash,HashMap,200471,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['Hash'],['HashMap']
Security,"/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); (1000, 500); ```. it seems working in command line using pyspark !. I need to test on jupyter notebook now... FYI the pyspark configs. ```sh ; - Classification: spark-defaults; ConfigurationProperties:; spark.jars: /opt/hail/backend/hail-all-spark.jar; spark.driver.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar; spark.executor.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar; spark.serializer: org.apache.spark.serializer.KryoSerializer; spark.kryo.registrator: is.hail.kryo.HailKryoRegistrator; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:3809,secur,security,3809,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949,4,['secur'],['security']
Security,"//]: # (snyk:metadata:{""prId"":""648a0aea-922c-46c9-b851-66c7e282d2e5"",""prPublicId"":""648a0aea-922c-46c9-b851-66c7e282d2e5"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""41.0.6""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14196:10501,Access,Access,10501,https://hail.is,https://github.com/hail-is/hail/pull/14196,1,['Access'],['Access']
Security,"//github-redirect.dependabot.com/axios/axios/pull/2702"">#2702</a>)</li>; <li>Updating of transformResponse (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3377"">#3377</a>)</li>; <li>Adding ability to omit User-Agent header (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3703"">#3703</a>)</li>; <li>Adding multiple JSON improvements (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3688"">#3688</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3763"">#3763</a>)</li>; <li>Fixing quadratic runtime and extra memory usage when setting a maxContentLength (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3738"">#3738</a>)</li>; <li>Adding parseInt to config.timeout (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3781"">#3781</a>)</li>; <li>Adding custom return type support to interceptor (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3783"">#3783</a>)</li>; <li>Adding security fix for ReDoS vulnerability (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3980"">#3980</a>)</li>; </ul>; <p>Internal and Tests:</p>; <ul>; <li>Updating build dev dependancies (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3401"">#3401</a>)</li>; <li>Fixing builds running on Travis CI (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3538"">#3538</a>)</li>; <li>Updating follow rediect version (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3694"">#3694</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3771"">#3771</a>)</li>; <li>Updating karma sauce launcher to fix failing sauce tests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3712"">#3712</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3717"">#3717</a>)</li>; <li>Updating content-type header for application/json to not contain charset field, according do RFC 8259 (<a href=""https://github-redirect.dependabo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:1583,secur,security,1583,https://hail.is,https://github.com/hail-is/hail/pull/11080,4,['secur'],['security']
Security,"//github-redirect.dependabot.com/bartdag/py4j/issues/487"">#487</a>)</li>; <li><a href=""https://github.com/py4j/py4j/commit/1c622faa81e983f5ceface5290859d6a49974849""><code>1c622fa</code></a> Migrate nosetest to pytest (<a href=""https://github-redirect.dependabot.com/bartdag/py4j/issues/481"">#481</a>)</li>; <li><a href=""https://github.com/py4j/py4j/commit/64ba89c5a680218d682161a4a6d952a969d1299b""><code>64ba89c</code></a> Add explanations for releasing Py4J for eclipse. Convert .txt to .md (<a href=""https://github-redirect.dependabot.com/bartdag/py4j/issues/479"">#479</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/bartdag/py4j/compare/0.10.9...0.10.9.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=py4j&package-manager=pip&previous-version=0.10.9&new-version=0.10.9.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12298:2749,secur,security-vulnerabilities,2749,https://hail.is,https://github.com/hail-is/hail/pull/12298,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"//github-redirect.dependabot.com/brettcannon/gidgethub/issues/180"">#180</a>)</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/cf2cb85551a8aa36536dc828e830e13032e594d4""><code>cf2cb85</code></a> Bump min PyJWT v2.4.0 (<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/179"">#179</a>)</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/9096d1b79447a3ef81b331457ea39c43f43e2f2d""><code>9096d1b</code></a> Release v5.1.0 (<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/175"">#175</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/brettcannon/gidgethub/compare/v4.2.0...v5.2.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=gidgethub&package-manager=pip&previous-version=4.2.0&new-version=5.2.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:9635,secur,security-vulnerabilities,9635,https://hail.is,https://github.com/hail-is/hail/pull/12328,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"//github.com/eranl""><code>@​eranl</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1472"">#1472</a>: Fix incorrect bitmask in <code>c.s.j.Pointer#createConstant(int)</code> - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1481"">#1481</a>: Fix NPE in NativeLibrary when unpacking from classpath is disabled - <a href=""https://github.com/trespasserw""><code>@​trespasserw</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1489"">#1489</a>: Fixes typo in <code>OpenGL32Util#wglGetProcAddress</code>, instead of parameter <code>procName</code> the hardcoded value <code>wglEnumGpusNV</code> was used - <a href=""https://github.com/soywiz""><code>@​soywiz</code></a>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/java-native-access/jna/commit/4962fd7758493b7395e86578705d8a32f6238872""><code>4962fd7</code></a> Release 5.13.0</li>; <li><a href=""https://github.com/java-native-access/jna/commit/a56504611b00cc7d90c165f924c3915cb7a6f759""><code>a565046</code></a> Adjust release directions</li>; <li><a href=""https://github.com/java-native-access/jna/commit/f7017c4f957d7fc13c7455efcae200e29407a729""><code>f7017c4</code></a> Remove artifacts classified as &quot;-jpms&quot;, there are the jna-jpms and jna-platfo...</li>; <li><a href=""https://github.com/java-native-access/jna/commit/a5f47cd359d5fe62a0e5d6c2bd9d649874be955d""><code>a5f47cd</code></a> Merge pull request <a href=""https://redirect.github.com/java-native-access/jna/issues/1494"">#1494</a> from matthiasblaesing/pr-1492</li>; <li><a href=""https://github.com/java-native-access/jna/commit/1af6eb14e0059c7acd5d5ee71fd62e519536fac5""><code>1af6eb1</code></a> Improve documentation, ensure osgi.version is defined, wrap create-export-pac...</li>; <li><a href=""https://github.com/java-native-access/jna/commit/65",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:3873,access,access,3873,https://hail.is,https://github.com/hail-is/hail/pull/12886,1,['access'],['access']
Security,"//github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1422"">#1422</a>: Load jawt library relative to <code>sun.boot.library.path</code> system on unix OSes - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1427"">#1427</a>: Rebuild all binaries with fix from <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1422"">#1422</a> and <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1323"">#1323</a> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; </ul>; <h1>Release 5.10.0</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/java-native-access/jna/commit/3705b849892aa3c37e5608e640eff19047811a5c""><code>3705b84</code></a> Release 5.12.1</li>; <li><a href=""https://github.com/java-native-access/jna/commit/2f919e56bad203494fe9589206d6d23f27ef4f26""><code>2f919e5</code></a> Null-check cleanable in Memory#close (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1447"">#1447</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/1eec7dd76830af97ed64ecb2d8d39a56db104dcd""><code>1eec7dd</code></a> Prepare next development iteration</li>; <li><a href=""https://github.com/java-native-access/jna/commit/0d7499f105e4495bdea15fc21f5b1046e81ca822""><code>0d7499f</code></a> Release 5.12.0</li>; <li><a href=""https://github.com/java-native-access/jna/commit/fa86166d4f75ef4478de7ad9d7d6c0b6b6933ee0""><code>fa86166</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1445"">#1445</a> from matthiasblaesing/aix</li>; <li><a href=""https://github.com/java-native-access/jna/commit/4cca4405f7",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:5617,access,access,5617,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,"//redirect.github.com/jaraco/zipp/issues/106"">#106</a>.</li>; <li><a href=""https://github.com/jaraco/zipp/commit/4cceb497c278ad0ecb11a9472e58f4130f5ff16b""><code>4cceb49</code></a> Add special accounting for pypy when computing the stack level for text encod...</li>; <li><a href=""https://github.com/jaraco/zipp/commit/2ec3ed8567d0842675c38fd8ef0a28db668e602d""><code>2ec3ed8</code></a> Add another test at another magnitude.</li>; <li><a href=""https://github.com/jaraco/zipp/commit/d9bf5aab8b39c6a124d9499ae0315d3bf2ac2f46""><code>d9bf5aa</code></a> Fix name generator for width=1</li>; <li>Additional commits viewable in <a href=""https://github.com/jaraco/zipp/compare/v3.17.0...v3.18.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=zipp&package-manager=pip&previous-version=3.17.0&new-version=3.18.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14473:3083,secur,security-vulnerabilities,3083,https://hail.is,https://github.com/hail-is/hail/pull/14473,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/2752"">#2752</a>)</li>; </ul>; <h3>Style</h3>; <ul>; <li>Deprecate <code>--experimental-string-processing</code> and move the functionality under; <code>--preview</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2789"">#2789</a>)</li>; <li>For stubs, one blank line between class attributes and methods is now kept if there's; at least one pre-existing blank line (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2736"">#2736</a>)</li>; <li>Black now normalizes string prefix order (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2297"">#2297</a>)</li>; <li>Remove spaces around power operators if both operands are simple (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2726"">#2726</a>)</li>; <li>Work around bug that causes unstable formatting in some cases in the presence of the; magic trailing comma (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2807"">#2807</a>)</li>; <li>Use parentheses for attribute access on decimal float and int literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Don't add whitespace for attribute access on hexadecimal, binary, octal, and complex; literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Treat blank lines in stubs the same inside top-level <code>if</code> statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2820"">#2820</a>)</li>; <li>Fix unstable formatting with semicolons and arithmetic expressions (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2817"">#2817</a>)</li>; <li>Fix unstable formatting around magic trailing comma (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2572"">#2572</a>)</li>; </ul>; <h3>Parser</h3>; <ul>; <li>Fix mapping cases that contain as-expressions, like <code>case {&quot;key&quot;: 1 | 2 as password}</code>; (<a href=""https://github-redirect.dependabot.com/psf/black/is",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:8753,access,access,8753,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['access'],['access']
Security,"/65cf52803ec2249c61573bdc7bd4314b77c019a0""><code>65cf528</code></a> add utility shell script to create 'Export-Package' metadata</li>; <li><a href=""https://github.com/java-native-access/jna/commit/b3984aaf1bf87c8da2e84797f62180adc405b48a""><code>b3984aa</code></a> Add 'uses' information to OSGI metadata in MANIFEST.MF</li>; <li><a href=""https://github.com/java-native-access/jna/commit/780facdf55b488d504c17183066df6a34531d747""><code>780facd</code></a> Add missing change log entry for libffi update</li>; <li><a href=""https://github.com/java-native-access/jna/commit/5dd4bd707f8f1f49b5d1af158402859a86161367""><code>5dd4bd7</code></a> Merge pull request <a href=""https://redirect.github.com/java-native-access/jna/issues/1491"">#1491</a> from matthiasblaesing/update_libffi</li>; <li><a href=""https://github.com/java-native-access/jna/commit/db1b5531b10fed9fb68d6d4d79913660759b22d3""><code>db1b553</code></a> Merge pull request <a href=""https://redirect.github.com/java-native-access/jna/issues/1490"">#1490</a> from korlibs/feature/direct.mapping.custom.symbol.pr...</li>; <li>Additional commits viewable in <a href=""https://github.com/java-native-access/jna/compare/5.12.1...5.13.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=net.java.dev.jna:jna&package-manager=gradle&previous-version=5.12.1&new-version=5.13.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:5887,access,access,5887,https://hail.is,https://github.com/hail-is/hail/pull/12886,1,['access'],['access']
Security,"/665"">#665</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/29ddff39290f4e2fbc7b9feb94eb622763e156e2""><code>29ddff3</code></a> Bump pytest-aiohttp from 0.3.0 to 1.0.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/668"">#668</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/3bc517092aff39330f2f96315e6f542e23415831""><code>3bc5170</code></a> Bump multidict from 5.2.0 to 6.0.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/670"">#670</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_session/compare/v2.7.0...v2.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp-session&package-manager=pip&previous-version=2.7.0&new-version=2.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11544:4664,secur,security-vulnerabilities,4664,https://hail.is,https://github.com/hail-is/hail/pull/11544,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/77"">#77</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/258a8832d9518340386e584206d7b5116185b182""><code>258a883</code></a> DOC: adjust test badge to point to Github Actions (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/76"">#76</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/ef894b2bf6ae4b1eaa0c5adec7ab5c1540da97cd""><code>ef894b2</code></a> Support Python 3.10 (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/74"">#74</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/hagenw/sphinxcontrib-katex/compare/0.5.1...v0.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinxcontrib-katex&package-manager=pip&previous-version=0.5.1&new-version=0.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12241:6622,secur,security-vulnerabilities,6622,https://hail.is,https://github.com/hail-is/hail/pull/12241,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/797b57a4ac8da86c13e52bf60586cd2432864400""><code>797b57a</code></a> Fixed pyproject.toml and setup.py.</li>; <li><a href=""https://github.com/mrabarnett/mrab-regex/commit/16bcce0d56e84367f61c24b369e23e73a3e9ad9e""><code>16bcce0</code></a> Add changelog.txt.</li>; <li><a href=""https://github.com/mrabarnett/mrab-regex/commit/d235c2c17f2335dd7699f3c29a6ae6db6dbe6dab""><code>d235c2c</code></a> pyproject.toml was missing.</li>; <li><a href=""https://github.com/mrabarnett/mrab-regex/commit/78460dc755b09966ee6e87d04c8dcfca7212256b""><code>78460dc</code></a> Added pyproject.toml.</li>; <li>See full diff in <a href=""https://github.com/mrabarnett/mrab-regex/compare/2023.3.23...2023.5.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=regex&package-manager=pip&previous-version=2023.3.23&new-version=2023.5.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12989:3181,secur,security-vulnerabilities,3181,https://hail.is,https://github.com/hail-is/hail/pull/12989,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/9319"">#9319</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/bfa4d95f0f356f2d535efd5c775e0fb3efe90ef2""><code>bfa4d95</code></a> changelog for 41.0.3 (<a href=""https://redirect.github.com/pyca/cryptography/issues/9320"">#9320</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/0da7165aa73c0a4865b0a4d9e019db3c16eea55a""><code>0da7165</code></a> backport fix the memory leak in fixedpool (<a href=""https://redirect.github.com/pyca/cryptography/issues/9272"">#9272</a>) (<a href=""https://redirect.github.com/pyca/cryptography/issues/9309"">#9309</a>)</li>; <li>See full diff in <a href=""https://github.com/pyca/cryptography/compare/41.0.2...41.0.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=41.0.2&new-version=41.0.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13357:2175,secur,security-vulnerabilities,2175,https://hail.is,https://github.com/hail-is/hail/pull/13357,6,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/AzureAD/microsoft-authentication-extensions-for-python/commit/bd5b4074dbb7d03c9d91ce6a75378851be92552a""><code>bd5b407</code></a> Update README to reflect the new APIs</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6f77b1e70be086aae752dcf7e08d7f06bcabdcd7""><code>6f77b1e</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/109"">#109</a> from AzureAD/release-1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/50bf9674f9c65229a1573be39ef4ef507eee17fa""><code>50bf967</code></a> MSAL EX for Python 1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6b904af1a3d4fc0e28e3f090fa3dd8492f79e6bf""><code>6b904af</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/110"">#110</a> from AzureAD/persistence-factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/d0696aeb6f65168b1e0d405cd871b80bb101cd76""><code>d0696ae</code></a> Add build_encrypted_persistence() factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/289a94f694645c642ae67b2d5972d3f9fdadb928""><code>289a94f</code></a> Remove old classes that are deprecated for 2 years</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/fa1f45b556341b2c34e9bf63c06a5068571cd337""><code>fa1f45b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/108"">#108</a> from AzureAD/actionable-encryption-exceptions</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/effe77842d25a8b093d18d9e33347f13e2ee094f""><code>effe778</code></a> Provide act",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:2984,authenticat,authentication-extensions-for-python,2984,https://hail.is,https://github.com/hail-is/hail/pull/11992,1,['authenticat'],['authentication-extensions-for-python']
Security,"/AzureAD/microsoft-authentication-extensions-for-python/issues/110"">#110</a>)</li>; <li>Enhancement: Make all platform-dependent parameters optional (<a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/103"">#103</a>)</li>; <li>Enhancement: Provide <code>PersistenceEncryptError</code> and <code>PersistenceDecryptError</code>, currently raised when encryption on Windows fails. (<a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/108"">#108</a>)</li>; <li>Enhancement: The data file will be created with <code>600</code> permission when running in Unix-like systems. (<a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/107"">#107</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/a88fa673af3602fe7c8c922314599b0c245e7add""><code>a88fa67</code></a> Merge branch 'release-1.0.0'</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/bd5b4074dbb7d03c9d91ce6a75378851be92552a""><code>bd5b407</code></a> Update README to reflect the new APIs</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6f77b1e70be086aae752dcf7e08d7f06bcabdcd7""><code>6f77b1e</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/109"">#109</a> from AzureAD/release-1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/50bf9674f9c65229a1573be39ef4ef507eee17fa""><code>50bf967</code></a> MSAL EX for Python 1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6b904af1a3d4fc0e28e3f090fa3dd8492f79e6bf""><code>6b904af</code></a> Merge pull reque",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:1858,authenticat,authentication-extensions-for-python,1858,https://hail.is,https://github.com/hail-is/hail/pull/11992,1,['authenticat'],['authentication-extensions-for-python']
Security,"/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiocloud/common/base_client.py"", line 21, in request; async with await self._session.request(method, url, **kwargs) as resp:; File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiocloud/common/session.py"", line 103, in request; return await retry_transient_errors(self._request_with_valid_authn, method, url, **kwargs); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/utils/utils.py"", line 769, in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/utils/utils.py"", line 785, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiocloud/common/session.py"", line 115, in _request_with_valid_authn; return await self._http_session.request(method, url, **kwargs); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/httpx.py"", line 138, in request_and_raise_for_status; raise ClientResponseError(; hailtop.httpx.ClientResponseError: 403, message='Forbidden', url=URL('https://storage.googleapis.com/storage/v1/b/hail-common?userProject=finngen-xavier') body='{\n ""error"": {\n ""code"": 403,\n ""message"": ""mkanai@broadinstitute.org does not have storage.buckets.get access to the Google Cloud Storage bucket. Permission \'storage.buckets.get\' denied on resource (or it may not exist)."",\n ""errors"": [\n {\n ""message"": ""mkanai@broadinstitute.org does not have storage.buckets.get access to the Google Cloud Storage bucket. Permission \'storage.buckets.get\' denied on resource (or it may not exist)."",\n ""domain"": ""global"",\n ""reason"": ""forbidden""\n }\n ]\n }\n}\n'; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14291:5245,access,access,5245,https://hail.is,https://github.com/hail-is/hail/issues/14291,2,['access'],['access']
Security,"/a> Name as 'options' in lambda_eval and unsafe_eval, but '_dict' in deprecated eval</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/facf3af93dabcbdd8cdbda8c3b50eefafa3bb04c""><code>facf3af</code></a> Added release notes</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/2a93aba5cfcf6e241ab4f9392c13e3b74032c061""><code>2a93aba</code></a> Use strncpy to avoid buffer overflow</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/a670597bc30e9d489656fc9d807170b8f3d7ca57""><code>a670597</code></a> Update CHANGES.rst [ci skip]</li>; <li>Additional commits viewable in <a href=""https://github.com/python-pillow/Pillow/compare/10.2.0...10.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pillow&package-manager=pip&previous-version=10.2.0&new-version=10.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14439:15466,secur,security-vulnerabilities,15466,https://hail.is,https://github.com/hail-is/hail/pull/14439,6,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/a> Slight perf enhancement in Empty</li>; <li><a href=""https://github.com/pyparsing/pyparsing/commit/801863aa4582a8ce5e6a7408d4966afcd247ea90""><code>801863a</code></a> Make htmlStripper.py and html_table_parser examples use PEP-8 names, add comm...</li>; <li><a href=""https://github.com/pyparsing/pyparsing/commit/7d4da80b2bca8a2767134f4a181ea9aac4bbb230""><code>7d4da80</code></a> Prep for release</li>; <li><a href=""https://github.com/pyparsing/pyparsing/commit/be0310a83436bb4893d0068bb5da3059199e4c0b""><code>be0310a</code></a> Add bf parser/executor example</li>; <li>Additional commits viewable in <a href=""https://github.com/pyparsing/pyparsing/compare/pyparsing_3.0.9...3.1.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyparsing&package-manager=pip&previous-version=3.0.9&new-version=3.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13334:9111,secur,security-vulnerabilities,9111,https://hail.is,https://github.com/hail-is/hail/pull/13334,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/a> Test all constructors</li>; <li><a href=""https://github.com/apache/commons-codec/commit/3535c17eccb2251fc518aa545a800b4922c8dc35""><code>3535c17</code></a> Test encode of null and empty array with an offset</li>; <li><a href=""https://github.com/apache/commons-codec/commit/e42dfe1ff2f273926fd759abea82b1c7b3021985""><code>e42dfe1</code></a> Fix test names</li>; <li><a href=""https://github.com/apache/commons-codec/commit/536587931cb77538709c57455165379a74e2f04f""><code>5365879</code></a> Test the codec policy property</li>; <li>Additional commits viewable in <a href=""https://github.com/apache/commons-codec/compare/commons-codec-1.11...rel/commons-codec-1.15"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=commons-codec:commons-codec&package-manager=gradle&previous-version=1.11&new-version=1.15)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12385:4940,secur,security-vulnerabilities,4940,https://hail.is,https://github.com/hail-is/hail/pull/12385,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/9683c1a82add3182be967050d164349da426a20f""><code>9683c1a</code></a> Backport test case from #python/cpython/96358 (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/71"">#71</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/db79268673ac10412b4aad19efea03948869b7db""><code>db79268</code></a> Silence a <code>flake8-bugbear</code> warning (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/72"">#72</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/python/typing_extensions/compare/4.3.0...4.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=typing-extensions&package-manager=pip&previous-version=4.3.0&new-version=4.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12288:4403,secur,security-vulnerabilities,4403,https://hail.is,https://github.com/hail-is/hail/pull/12288,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/aio-libs/aiorwlock/issues/250"">#250</a>)</li>; <li><a href=""https://github.com/aio-libs/aiorwlock/commit/63f68eb11d293a5e15133ef933304eddf61753e7""><code>63f68eb</code></a> Bump pytest-asyncio from 0.16.0 to 0.17.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiorwlock/issues/249"">#249</a>)</li>; <li><a href=""https://github.com/aio-libs/aiorwlock/commit/34092ffd1f8927d68dc3e3e9f2a0bfddbdc3a382""><code>34092ff</code></a> Bump flake8-bugbear from 21.11.29 to 22.1.11 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiorwlock/issues/248"">#248</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiorwlock/compare/v1.0.0...v1.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiorwlock&package-manager=pip&previous-version=1.0.0&new-version=1.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11514:3804,secur,security-vulnerabilities,3804,https://hail.is,https://github.com/hail-is/hail/pull/11514,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,/anaconda3/5.2.0/install/bin:/usr/java/default/jre/bin:/usr/java/default/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/dell/srvadmin/bin:/usr3/bustaff/farrell/bin:/usr3/bustaff/farrell/bin; spark.yarn.appMasterEnv.PYTHONPATH=/share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip:/share/pkg/spark/2.2.1/install/python:/restricted/projectnb/genpro/github/hail/hail/build/distributions/hail-python.zip:/share/pkg/spark/2.2.1/install/python:/share/pkg/spark/2.2.1/install/python/lib/py4j-*-src.zip; spark.yarn.dist.jars=file:/restricted/projectnb/genpro/github/hail/hail/build/libs/hail-all-spark.jar; spark.yarn.isPython=true; 2019-01-22 13:11:21 SecurityManager: INFO: Changing view acls to: farrell; 2019-01-22 13:11:21 SecurityManager: INFO: Changing modify acls to: farrell; 2019-01-22 13:11:21 SecurityManager: INFO: Changing view acls groups to:; 2019-01-22 13:11:21 SecurityManager: INFO: Changing modify acls groups to:; 2019-01-22 13:11:21 SecurityManager: INFO: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-22 13:11:21 Utils: INFO: Successfully started service 'sparkDriver' on port 38253.; 2019-01-22 13:11:21 SparkEnv: INFO: Registering MapOutputTracker; 2019-01-22 13:11:21 SparkEnv: INFO: Registering BlockManagerMaster; 2019-01-22 13:11:21 BlockManagerMasterEndpoint: INFO: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-22 13:11:21 BlockManagerMasterEndpoint: INFO: BlockManagerMasterEndpoint up; 2019-01-22 13:11:21 DiskBlockManager: INFO: Created local directory at /tmp/blockmgr-8d910f25-2ae8-439c-8577-377758342d28; 2019-01-22 13:11:21 MemoryStore: INFO: MemoryStore started with capacity 2.5 GB; 2019-01-22 13:11:22 SparkEnv: INFO: Registering OutputCommitCoordinator; 2019-01-22 13:11:22 log:,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:9218,Secur,SecurityManager,9218,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"/authlib/issues/275"">#275</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/lepture/authlib/blob/master/docs/changelog.rst"">authlib's changelog</a>.</em></p>; <blockquote>; <h2>Version 0.15.5</h2>; <p><strong>Released on Oct 18, 2021.</strong></p>; <ul>; <li>Make Authlib compatible with latest httpx</li>; <li>Make Authlib compatible with latest werkzeug</li>; <li>Allow customize RFC7523 <code>alg</code> value</li>; </ul>; <h2>Version 0.15.4</h2>; <p><strong>Released on Jul 17, 2021.</strong></p>; <ul>; <li>Security fix when JWT claims is None.</li>; </ul>; <h2>Version 0.15.3</h2>; <p><strong>Released on Jan 15, 2021.</strong></p>; <ul>; <li>Fixed <code>.authorize_access_token</code> for OAuth 1.0 services, via :gh:<code>issue#308</code>.</li>; </ul>; <h2>Version 0.15.2</h2>; <p><strong>Released on Oct 18, 2020.</strong></p>; <ul>; <li>Fixed HTTPX authentication bug, via :gh:<code>issue#283</code>.</li>; </ul>; <h2>Version 0.15.1</h2>; <p><strong>Released on Oct 14, 2020.</strong></p>; <ul>; <li>Backward compitable fix for using JWKs in JWT, via :gh:<code>issue#280</code>.</li>; </ul>; <h2>Version 0.15</h2>; <p><strong>Released on Oct 10, 2020.</strong></p>; <p>This is the last release before v1.0. In this release, we added more RFCs; implementations and did some refactors for JOSE:</p>; <ul>; <li>RFC8037: CFRG Elliptic Curve Diffie-Hellman (ECDH) and Signatures in JSON Object Signing and Encryption (JOSE)</li>; <li>RFC7638: JSON Web Key (JWK) Thumbprint</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/lepture/authlib/commit/d8e428c9350c792fc3d25dbaaffa3bfefaabd8e3""><code>d8e428c</code></a> Version bump 0.15.5</li>; <li><a href=""https://github.com/lepture/authlib/commit/f24962835fd0725349cb1b368ee69ba0cc8670f9""><code>f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11483:3156,authenticat,authentication,3156,https://hail.is,https://github.com/hail-is/hail/pull/11483,1,['authenticat'],['authentication']
Security,"/b64ec22effafffc6a1371e544c560e6bfc24b56e""><code>b64ec22</code></a> Add explicit name in setup.py</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/4f8ef056177513ea599597d4089fed4275ae5d12""><code>4f8ef05</code></a> chore(deps): update actions/checkout action to v3 (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/121"">#121</a>)</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/6389c5acb15153df43b0681cb1333bbd892c3a16""><code>6389c5a</code></a> chore: allow automerge for official GitHub Actions</li>; <li>Additional commits viewable in <a href=""https://github.com/thibaudcolas/curlylint/compare/v0.12.0...v0.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=curlylint&package-manager=pip&previous-version=0.12.0&new-version=0.13.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11713:9350,secur,security-vulnerabilities,9350,https://hail.is,https://github.com/hail-is/hail/pull/11713,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/code> to monitor webhooks that fail to open. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107171"">kubernetes/kubernetes#107171</a>, <a href=""https://github.com/ltagliamonte-dd""><code>@​ltagliamonte-dd</code></a>)</li>; <li>Adds a new Status subresource in Network Policy objects (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107963"">kubernetes/kubernetes#107963</a>, <a href=""https://github.com/rikatz""><code>@​rikatz</code></a>)</li>; <li>Adds support for <code>InterfaceNamePrefix</code> and <code>BridgeInterface</code> as arguments to <code>--detect-local-mode</code> option and also introduces a new optional <code>--pod-interface-name-prefix</code> and <code>--pod-bridge-interface</code> flags to kube-proxy. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/95400"">kubernetes/kubernetes#95400</a>, <a href=""https://github.com/tssurya""><code>@​tssurya</code></a>)</li>; <li>CEL CRD validation expressions may now reference existing object state using the identifier <code>oldSelf</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108073"">kubernetes/kubernetes#108073</a>, <a href=""https://github.com/benluddy""><code>@​benluddy</code></a>)</li>; <li>CRD deep copies should no longer contain shallow copies of <code>JSONSchemaProps.XValidations</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107956"">kubernetes/kubernetes#107956</a>, <a href=""https://github.com/benluddy""><code>@​benluddy</code></a>)</li>; <li>CRD writes will generate validation errors if a CEL validation rule references the identifier <code>oldSelf</code> on a part of the schema that does not support it. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108013"">kubernetes/kubernetes#108013</a>, <a href=""https://github.com/benluddy""><code>@​benluddy</code></a>)</li>; <li>CSIStorageCapacity.storage.k8s.io: The v1beta1 version of this AP",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:3042,validat,validation,3042,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['validat'],['validation']
Security,"/github-redirect.dependabot.com/grpc/grpc/issues/30326"">#30326</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/4c51abf12053e3c43a62059c693322ea992b35ce""><code>4c51abf</code></a> Bump version to 1.48.0-pre1 (on v1.48.x branch) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30194"">#30194</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/46bd0be2c99aa8228ec5d93d8a27f20ab0c61956""><code>46bd0be</code></a> Bump core version to 26.0.0 for upcoming release (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30163"">#30163</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/grpc/grpc/compare/v1.47.0...v1.48.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=grpcio&package-manager=pip&previous-version=1.47.0&new-version=1.48.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12201:6355,secur,security-vulnerabilities,6355,https://hail.is,https://github.com/hail-is/hail/pull/12201,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/github-redirect.dependabot.com/jaraco/zipp/issues/62"">#62</a>)</li>; <li><a href=""https://github.com/jaraco/zipp/commit/a4f5b769793af19f7b858816889c1bf026f55f5c""><code>a4f5b76</code></a> Update base URL for PEPs (<a href=""https://github-redirect.dependabot.com/jaraco/zipp/issues/61"">#61</a>)</li>; <li><a href=""https://github.com/jaraco/zipp/commit/10bf1b1fb9e09e9836bea9e2edec620cd9eea7f9""><code>10bf1b1</code></a> Add Python 3.11 into the matrix using workaround from <a href=""https://github-redirect.dependabot.com/actions/setup-python/issues/21"">actions/setup-python#21</a>...</li>; <li>Additional commits viewable in <a href=""https://github.com/jaraco/zipp/compare/v3.8.0...v3.8.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=zipp&package-manager=pip&previous-version=3.8.0&new-version=3.8.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12108:2891,secur,security-vulnerabilities,2891,https://hail.is,https://github.com/hail-is/hail/pull/12108,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/github.com/michel-kraemer/gradle-download-task/commit/b3fa29f9ffb4d4544e13ef84601e371fb2778ddf""><code>b3fa29f</code></a> Revert &quot;Update Apache HttpClient to 5.2.1&quot;</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/01f05e046be0dca18f506723c79e88f208336e71""><code>01f05e0</code></a> Add integration tests for Gradle 6.9.3 and 7.6</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a998a544908a8b39f713f4526f717fcb328c06eb""><code>a998a54</code></a> Upgrade Gradle to 7.6</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.0...5.3.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.0&new-version=5.3.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:3520,secur,security-vulnerabilities,3520,https://hail.is,https://github.com/hail-is/hail/pull/12707,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/github.com/psf/black/commit/afed2c01903465f9a486ac481a66aa3413cc1b01""><code>afed2c0</code></a> Load .gitignore and exclude regex at time of use</li>; <li><a href=""https://github.com/psf/black/commit/e269f44b25737360e0dc65379f889dfa931dc68a""><code>e269f44</code></a> Lazily import parallelized format modules</li>; <li><a href=""https://github.com/psf/black/commit/c47b91f513052cd39b818ea7c19716423c85c04e""><code>c47b91f</code></a> Fix misdetection of project root with <code>--stdin-filename</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3216"">#3216</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/psf/black/compare/22.3.0...22.8.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=black&package-manager=pip&previous-version=22.3.0&new-version=22.8.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:11511,secur,security-vulnerabilities,11511,https://hail.is,https://github.com/hail-is/hail/pull/12174,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/github.com/python-jsonschema/jsonschema/commit/76b2e597d691e4cf5e9ebb7f3d1cff4f5da0115a""><code>76b2e59</code></a> Merge commit '095a009acc1938caf9596085d5581e7196021f66'</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/aeecae37b17b430c328d3c3e15bec90d30c8848b""><code>aeecae3</code></a> Squashed 'json/' changes from d40b3e62f..cf78d97d0</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/2f3a79c61176f60c9244d07fa8afb728218270ff""><code>2f3a79c</code></a> Merge commit 'aeecae37b17b430c328d3c3e15bec90d30c8848b'</li>; <li>Additional commits viewable in <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.6.0...v4.6.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jsonschema&package-manager=pip&previous-version=4.6.0&new-version=4.6.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11981:4199,secur,security-vulnerabilities,4199,https://hail.is,https://github.com/hail-is/hail/pull/11981,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/github.com/tornadoweb/tornado/commit/7dfe8b597f2d179334d7b528f61e9449ac131273""><code>7dfe8b5</code></a> httpserver_test: Add ExpectLog to fix CI</li>; <li><a href=""https://github.com/tornadoweb/tornado/commit/217295b1dd30f556ea374d62007f6821688f00f0""><code>217295b</code></a> http1connection: Make content-length parsing more strict</li>; <li><a href=""https://github.com/tornadoweb/tornado/commit/e3aa6c5e2943242d8ab25448c2798365b3cb9945""><code>e3aa6c5</code></a> Merge pull request <a href=""https://redirect.github.com/tornadoweb/tornado/issues/3267"">#3267</a> from bdarnell/branch6.3</li>; <li>See full diff in <a href=""https://github.com/tornadoweb/tornado/compare/v6.3.2...v6.3.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tornado&package-manager=pip&previous-version=6.3.2&new-version=6.3.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13432:2760,secur,security-vulnerabilities,2760,https://hail.is,https://github.com/hail-is/hail/pull/13432,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/issues/1481"">#1481</a>: Fix NPE in NativeLibrary when unpacking from classpath is disabled - <a href=""https://github.com/trespasserw""><code>@​trespasserw</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1489"">#1489</a>: Fixes typo in <code>OpenGL32Util#wglGetProcAddress</code>, instead of parameter <code>procName</code> the hardcoded value <code>wglEnumGpusNV</code> was used - <a href=""https://github.com/soywiz""><code>@​soywiz</code></a>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/java-native-access/jna/commit/4962fd7758493b7395e86578705d8a32f6238872""><code>4962fd7</code></a> Release 5.13.0</li>; <li><a href=""https://github.com/java-native-access/jna/commit/a56504611b00cc7d90c165f924c3915cb7a6f759""><code>a565046</code></a> Adjust release directions</li>; <li><a href=""https://github.com/java-native-access/jna/commit/f7017c4f957d7fc13c7455efcae200e29407a729""><code>f7017c4</code></a> Remove artifacts classified as &quot;-jpms&quot;, there are the jna-jpms and jna-platfo...</li>; <li><a href=""https://github.com/java-native-access/jna/commit/a5f47cd359d5fe62a0e5d6c2bd9d649874be955d""><code>a5f47cd</code></a> Merge pull request <a href=""https://redirect.github.com/java-native-access/jna/issues/1494"">#1494</a> from matthiasblaesing/pr-1492</li>; <li><a href=""https://github.com/java-native-access/jna/commit/1af6eb14e0059c7acd5d5ee71fd62e519536fac5""><code>1af6eb1</code></a> Improve documentation, ensure osgi.version is defined, wrap create-export-pac...</li>; <li><a href=""https://github.com/java-native-access/jna/commit/65cf52803ec2249c61573bdc7bd4314b77c019a0""><code>65cf528</code></a> add utility shell script to create 'Export-Package' metadata</li>; <li><a href=""https://github.com/java-native-access/jna/commit/b3984aaf1bf87c8da2e84797f62180adc405b48a""><code>b3984aa</code></a> Add 'uses' information to OSGI metadata in MANIFEST.MF</li>; <li><a href=""https://github.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:4184,access,access,4184,https://hail.is,https://github.com/hail-is/hail/pull/12886,1,['access'],['access']
Security,"/li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/fa1f45b556341b2c34e9bf63c06a5068571cd337""><code>fa1f45b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/108"">#108</a> from AzureAD/actionable-encryption-exceptions</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/effe77842d25a8b093d18d9e33347f13e2ee094f""><code>effe778</code></a> Provide actionable messages for 2 dpapi errors</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/b674b6a07ca27b2c1b6f371040f035a546cfd468""><code>b674b6a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/107"">#107</a> from AzureAD/file600</li>; <li>Additional commits viewable in <a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/compare/0.3.1...1.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=msal-extensions&package-manager=pip&previous-version=0.3.1&new-version=1.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:4490,authenticat,authentication-extensions-for-python,4490,https://hail.is,https://github.com/hail-is/hail/pull/11992,1,['authenticat'],['authentication-extensions-for-python']
Security,"/li>; <li><a href=""https://github.com/pallets/jinja/commit/466a200ea40642b674db77588d13889abbad55f5""><code>466a200</code></a> update requirements</li>; <li><a href=""https://github.com/pallets/jinja/commit/990602f719b4086540287e95f601baefd830d790""><code>990602f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/jinja/issues/1647"">#1647</a> from Tom-Brouwer/202204/add-missing-overlay-options</li>; <li><a href=""https://github.com/pallets/jinja/commit/5d3d2414710c1439105d84efc58e4aba8e453cb3""><code>5d3d241</code></a> fix flake8-bugbear finding</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/jinja/compare/3.0.3...3.1.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jinja2&package-manager=pip&previous-version=3.0.3&new-version=3.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12173:6806,secur,security-vulnerabilities,6806,https://hail.is,https://github.com/hail-is/hail/pull/12173,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/lib/py4j-0.10.4-src.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0174/py4j-0.10.4-src.zip; 2019-01-22 13:11:31 Client: INFO: Uploading resource file:/tmp/spark-1afae5c8-6de0-4d0d-8db4-c834966e0865/__spark_conf__963896229742184890.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0174/__spark_conf__.zip; 2019-01-22 13:11:31 SecurityManager: INFO: Changing view acls to: farrell; 2019-01-22 13:11:31 SecurityManager: INFO: Changing modify acls to: farrell; 2019-01-22 13:11:31 SecurityManager: INFO: Changing view acls groups to:; 2019-01-22 13:11:31 SecurityManager: INFO: Changing modify acls groups to:; 2019-01-22 13:11:31 SecurityManager: INFO: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-22 13:11:31 Client: INFO: Submitting application application_1542127286896_0174 to ResourceManager; 2019-01-22 13:11:32 YarnClientImpl: INFO: Submitted application application_1542127286896_0174; 2019-01-22 13:11:32 SchedulerExtensionServices: INFO: Starting Yarn extension services with app application_1542127286896_0174 and attemptId None; 2019-01-22 13:11:33 Client: INFO: Application report for application_1542127286896_0174 (state: ACCEPTED); 2019-01-22 13:11:33 Client: INFO:; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1548180691687; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0174/; user: farrell; 2019-01-22 13:11:34 Client: INFO: Application report for application_1542127286896_0174 (state: ACCEPTED); 2019-01-22 13:11:35 Client: INFO: Application report for application_1542127286896_0174 (state: ACCEPTED); 2019-01-22 13:11:36 Client: INFO: Application report for applica",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:16371,Secur,SecurityManager,16371,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"/numpy/numpy/issues/22593"">#22593</a> from charris/backport-22447</li>; <li><a href=""https://github.com/numpy/numpy/commit/3ca02ce5b1a4ec2412cad839d42452a4200a5270""><code>3ca02ce</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22594"">#22594</a> from charris/backport-22450</li>; <li><a href=""https://github.com/numpy/numpy/commit/8cededdf4eeebd4f1985bd74c11fbf44f367937f""><code>8cededd</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22592"">#22592</a> from charris/backport-22393</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.23.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.23.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12515:6498,secur,security-vulnerabilities,6498,https://hail.is,https://github.com/hail-is/hail/pull/12515,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/p>; <blockquote>; <h1>1.26.16</h1>; <ul>; <li>api-change:<code>grafana</code>: [<code>botocore</code>] This release includes support for configuring a Grafana workspace to connect to a datasource within a VPC as well as new APIs for configuring Grafana settings.</li>; <li>api-change:<code>rbin</code>: [<code>botocore</code>] This release adds support for Rule Lock for Recycle Bin, which allows you to lock retention rules so that they can no longer be modified or deleted.</li>; </ul>; <h1>1.26.15</h1>; <ul>; <li>bugfix:Endpoints: [<code>botocore</code>] Resolve endpoint with default partition when no region is set</li>; <li>bugfix:s3: [<code>botocore</code>] fixes missing x-amz-content-sha256 header for s3 object lambda</li>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] Adding support for Amazon AppFlow to transfer the data to Amazon Redshift databases through Amazon Redshift Data API service. This feature will support the Redshift destination connector on both public and private accessible Amazon Redshift Clusters and Amazon Redshift Serverless.</li>; <li>api-change:<code>kinesisanalyticsv2</code>: [<code>botocore</code>] Support for Apache Flink 1.15 in Kinesis Data Analytics.</li>; </ul>; <h1>1.26.14</h1>; <ul>; <li>api-change:<code>route53</code>: [<code>botocore</code>] Amazon Route 53 now supports the Asia Pacific (Hyderabad) Region (ap-south-2) for latency records, geoproximity records, and private DNS for Amazon VPCs in that region.</li>; </ul>; <h1>1.26.13</h1>; <ul>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] AppFlow provides a new API called UpdateConnectorRegistration to update a custom connector that customers have previously registered. With this API, customers no longer need to unregister and then register a connector to make an update.</li>; <li>api-change:<code>auditmanager</code>: [<code>botocore</code>] This release introduces a new feature for Audit Manager: Evidence finder. You can now use evidence finder to qui",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12502:1237,access,accessible,1237,https://hail.is,https://github.com/hail-is/hail/pull/12502,1,['access'],['accessible']
Security,"/p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - gear/pinned-requirements.txt. <details>; <summary>⚠️ <b>Warning</b></summary>. ```; prometheus-async 19.2.0 requires prometheus-client, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14034:1063,Validat,Validation,1063,https://hail.is,https://github.com/hail-is/hail/pull/14034,1,['Validat'],['Validation']
Security,"/protobuf/issues/9486"">#9486</a>)</li>; <li>Allocate with xrealloc()/xfree() so message allocation is visible to the; Ruby GC. In certain tests this leads to much lower memory usage due to more; frequent GC runs (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9586"">#9586</a>).</li>; <li>Fix conversion of singleton classes in Ruby (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9342"">#9342</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.19.6&new-version=4.21.12)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12563:4213,secur,security-vulnerabilities,4213,https://hail.is,https://github.com/hail-is/hail/pull/12563,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/redirect.github.com/pyca/cryptography/issues/8975"">#8975</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/851d8ccb340bfc93c827b9e80af939a216b34925""><code>851d8cc</code></a> Bump openssl from 0.10.52 to 0.10.53 in /src/rust (<a href=""https://redirect.github.com/pyca/cryptography/issues/8986"">#8986</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/0918c7236c94c29272e0790ba0227cfa9401943b""><code>0918c72</code></a> Bump coverage from 7.2.6 to 7.2.7 (<a href=""https://redirect.github.com/pyca/cryptography/issues/8985"">#8985</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pyca/cryptography/compare/40.0.2...41.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=40.0.2&new-version=41.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13146:5042,secur,security-vulnerabilities,5042,https://hail.is,https://github.com/hail-is/hail/pull/13146,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/samtools/htsjdk/issues/1592"">#1592</a>); 6507249a4 Make the CRAM MD5 failure message more user friendly. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1607"">#1607</a>); b5af659e6 Fix restoration of read base feature code. <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1379"">#1379</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1590"">#1590</a>); e63c34a92 Ignore TC, TN on CRAM read (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1578"">#1578</a>)</p>; <p>BAM/SAM; 1449dec45 Support loading of CSI from URLs/streams. <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1507"">#1507</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1595"">#1595</a>); a38c78d6c Add an option to SAMFileWriter to disable checking of ordering of rec… (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1599"">#1599</a>); 51aa6ed2b Validate that SAM header tag keys are exactly 2 characters long (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1561"">#1561</a>); fbd9e96d5 Deprecate OTHER as a PL value (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1552"">#1552</a>); d5f7e106b Adding PL Tag 'DNBSEQ' as the Platform/Technology for BGI/MGI (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1547"">#1547</a>)</p>; <p>Misc Improvements; f461401e3 Silence AsciiLineReader warning when creating a FASTA sequence index (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1559"">#1559</a>); 8f82871c1 Update explain samflags script to python3 (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1585"">#1585</a>); 4ba4c0678 Update to new version of the snappy library which will work with M1 macs (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1580"">#1580</a>); e92706452 add predicate to GFF3Codec to give a chance to filter ou",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:3329,Validat,Validate,3329,https://hail.is,https://github.com/hail-is/hail/pull/12229,2,['Validat'],['Validate']
Security,"/summary>; <ul>; <li><a href=""https://github.com/ipython/comm/commit/d119118d950f2c64f184c37e7e42b4c968701668""><code>d119118</code></a> Publish 0.2.2</li>; <li><a href=""https://github.com/ipython/comm/commit/76149e7ee0f331772c964ae86cdb8bafebe6dfa2""><code>76149e7</code></a> Update Release Scripts (<a href=""https://redirect.github.com/ipython/comm/issues/27"">#27</a>)</li>; <li><a href=""https://github.com/ipython/comm/commit/915898ddeddd0d1c8a1b87c5dcfbe6392fd225b7""><code>915898d</code></a> chore: update pre-commit hooks (<a href=""https://redirect.github.com/ipython/comm/issues/26"">#26</a>)</li>; <li>See full diff in <a href=""https://github.com/ipython/comm/compare/v0.2.1...v0.2.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=comm&package-manager=pip&previous-version=0.2.1&new-version=0.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14492:3771,secur,security-vulnerabilities,3771,https://hail.is,https://github.com/hail-is/hail/pull/14492,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/v3.0.0/gcs/INSTALL.md). Somehow I managed to make the normal Spark backend work correctly but the Local backend (which still, afaik, uses Spark & Hadoop for filesystems) is still trying to pick up CI's credentials instead of the test account's credentials. ```; E hail.utils.java.FatalError: GoogleJsonResponseException: 403 Forbidden; E GET https://storage.googleapis.com/storage/v1/b/hail-test-requester-pays-fds32/o/zero-to-nine?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata&userProject=hail-vdc; E {; E ""code"": 403,; E ""errors"": [; E {; E ""domain"": ""global"",; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfoInternal(GoogleCloudStorageFileSystemImpl.java:861); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfo(GoogleCloudStorageFileSystemImpl.java:833); E 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.getFileStatus(GoogleHadoopFileSystem.java:724); E 	at org.apache.hadoop.fs.Globber.getFileStat",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:1389,access,access,1389,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236,1,['access'],['access']
Security,"0000004: not in 7f15e9ffb1f8/00010000'; tpl = JavaObject id=o553; deepest = 'RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000'; full = 'java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000\n\tat is.h...ava:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\n'; error_id = -1. def deco(*args, **kwargs):; import pyspark; try:; return f(*args, **kwargs); except py4j.protocol.Py4JJavaError as e:; s = e.java_exception.toString(); ; # py4j catches NoSuchElementExceptions to stop array iteration; if s.startswith('java.util.NoSuchElementException'):; raise; ; tpl = Env.jutils().handleForPython(e.java_exception); deepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); > raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; E hail.utils.java.FatalError: RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E ; E Java stack trace:; E java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E 	at is.hail.annotations.Memory.checkAddress(Memory.java:226); E 	at is.hail.annotations.Memory.loadInt(Memory.java:140); E 	at is.hail.annotations.Region$.loadInt(Region.scala:20); E 	at __C92844etypeDecode.__m92863ord_compareNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92862ord_compareNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92861ord_ltNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92860ord_lt(Unknown Source); E 	at __C92844etypeDecode.__m92857arraySorter_merge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844e",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:3514,access,access,3514,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198,1,['access'],['access']
Security,"00</a></li>; <li>Add exception chaining by <a href=""https://github.com/ehdgua01""><code>@​ehdgua01</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/702"">jpadilla/pyjwt#702</a></li>; <li>Revert &quot;Remove arbitrary kwargs.&quot; by <a href=""https://github.com/auvipy""><code>@​auvipy</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/701"">jpadilla/pyjwt#701</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jpadilla/pyjwt/blob/master/CHANGELOG.rst"">pyjwt's changelog</a>.</em></p>; <blockquote>; <h2><code>v2.4.0 &lt;https://github.com/jpadilla/pyjwt/compare/2.3.0...2.4.0&gt;</code>__</h2>; <p>Security</p>; <pre><code>; - [CVE-2022-29217] Prevent key confusion through non-blocklisted public key formats. https://github.com/jpadilla/pyjwt/security/advisories/GHSA-ffqj-6fqr-9h24; <p>Changed</p>; <pre><code>; - Explicit check the key for ECAlgorithm by @estin in https://github.com/jpadilla/pyjwt/pull/713; - Raise DeprecationWarning for jwt.decode(verify=...) by @akx in https://github.com/jpadilla/pyjwt/pull/742. Fixed; ~~~~~. - Don't use implicit optionals by @rekyungmin in https://github.com/jpadilla/pyjwt/pull/705; - documentation fix: show correct scope for decode_complete() by @sseering in https://github.com/jpadilla/pyjwt/pull/661; - fix: Update copyright information by @kkirsche in https://github.com/jpadilla/pyjwt/pull/729; - Don't mutate options dictionary in .decode_complete() by @akx in https://github.com/jpadilla/pyjwt/pull/743. Added; ~~~~~. - Add support for Python 3.10 by @hugovk in https://github.com/jpadilla/pyjwt/pull/699; - api_jwk: Add PyJWKSet.__getitem__ by @woodruffw in https://github.com/jpadilla/pyjwt/pull/725; - Update usage.rst by @guneybilen in https://github.com/jpadilla/pyjwt/pull/727; - Docs: mention performance reasons for reusing RSAPrivateKey when ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11866:9335,secur,security,9335,https://hail.is,https://github.com/hail-is/hail/pull/11866,1,['secur'],['security']
Security,"01:04:37.601 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=0, peakBytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.603 : ERROR: SocketException: Connection reset; From javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUn",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:24058,secur,security,24058,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,"024</a>)</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/a1ae994cabff37eb86c6ca4564b4f193a73a7b0d""><code>a1ae994</code></a> fix <a href=""https://github-redirect.dependabot.com/giampaolo/psutil/issues/2023"">#2023</a> [Linux] cpu_freq() return order is wrong on systems with &gt; 9 CPUs.</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/875d2195fc8efa642c7bca714d468551d1805c6c""><code>875d219</code></a> Handle missing dependencies on MidnightBSD (<a href=""https://github-redirect.dependabot.com/giampaolo/psutil/issues/2019"">#2019</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/giampaolo/psutil/compare/release-5.8.0...release-5.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=psutil&package-manager=pip&previous-version=5.8.0&new-version=5.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11459:6469,secur,security-vulnerabilities,6469,https://hail.is,https://github.com/hail-is/hail/pull/11459,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"04:37.601 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.603 : ERROR: SocketException: Connection reset; From javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:104); 	at is.hail.relocated.com.google.cloud.storage.UnbufferedReadableByteChannelSession$UnbufferedReadableByteChannel.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:24211,secur,security,24211,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,"05ee42</code></a> test(deps): update testbench version to v0.32.0 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1768"">#1768</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/8ea8131d17eba29859518da7199bbd03019d0644""><code>8ea8131</code></a> chore: update google-auth to 2.14.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1703"">#1703</a>) (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1767"">#1767</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/java-storage/compare/v1.106.0...v2.15.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.cloud:google-cloud-storage&package-manager=gradle&previous-version=1.106.0&new-version=2.15.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12529:14359,secur,security-vulnerabilities,14359,https://hail.is,https://github.com/hail-is/hail/pull/12529,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"0696</a> from jfbu/latex_fix_for_old_latex</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/d1b4a75f4f09281af70a04fb405c126744c54651""><code>d1b4a75</code></a> LaTeX: fix another incompatibility with old pict2e LaTeX</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/faccc2182275354ebe7d85ac61dd753887b98315""><code>faccc21</code></a> Fix <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10695"">#10695</a>: old LaTeX does not allow <a href=""https://github.com/ifpackageloaded""><code>@​ifpackageloaded</code></a> usage in body</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v5.1.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=5.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12165:8005,secur,security-vulnerabilities,8005,https://hail.is,https://github.com/hail-is/hail/pull/12165,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"074d6e9""><code>a41e349</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2234"">#2234</a> from pallets/release-8.1.1</li>; <li><a href=""https://github.com/pallets/click/commit/3c301ebacbfe8ec7dc3d9d46ebf517082a8ee4b1""><code>3c301eb</code></a> release version 8.1.1</li>; <li><a href=""https://github.com/pallets/click/commit/d5741a2ca2ebc21d525c903f628b1bebad75b735""><code>d5741a2</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2233"">#2233</a> from henryiii/henryiii/fix/commandtype</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/click/compare/8.0.4...8.1.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=click&package-manager=pip&previous-version=8.0.4&new-version=8.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11801:6989,secur,security-vulnerabilities,6989,https://hail.is,https://github.com/hail-is/hail/pull/11801,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"08-0.2.34-914bd8a10ca2.log; {'_Task__hash': -3818947167740532127,; 'clinvar_ht_path': 'gs://seqr-reference-data/GRCh38/clinvar/clinvar.GRCh38.2020-03-29.ht',; 'dataset_type': 'VARIANTS',; 'decrease_running_resources': <bound method TaskStatusReporter.decrease_running_resources of <luigi.worker.TaskStatusReporter object at 0x7f0583f0f588>>,; 'dest_path': 'gs://seqr-bw/merged_phased_3P5CH.mt',; 'genome_version': '38',; 'hgmd_ht_path': None,; 'param_kwargs': {'clinvar_ht_path': 'gs://seqr-reference-data/GRCh38/clinvar/clinvar.GRCh38.2020-03-29.ht',; 'dataset_type': 'VARIANTS',; 'dest_path': 'gs://seqr-bw/merged_phased_3P5CH.mt',; 'genome_version': '38',; 'hgmd_ht_path': None,; 'reference_ht_path': 'gs://seqr-reference-data/GRCh38/all_reference_data/combined_reference_data_grch38.ht',; 'remap_path': None,; 'sample_type': 'WGS',; 'source_paths': 'gs://seqr-bw/merged_phased_3P5CH.split.vcf.gz',; 'subset_path': None,; 'validate': False,; 'vep_config_json_path': None,; 'vep_runner': 'VEP'},; 'reference_ht_path': 'gs://seqr-reference-data/GRCh38/all_reference_data/combined_reference_data_grch38.ht',; 'remap_path': None,; 'sample_type': 'WGS',; 'scheduler_messages': None,; 'set_progress_percentage': <bound method TaskStatusReporter.update_progress_percentage of <luigi.worker.TaskStatusReporter object at 0x7f0583f0f588>>,; 'set_status_message': <bound method TaskStatusReporter.update_status_message of <luigi.worker.TaskStatusReporter object at 0x7f0583f0f588>>,; 'set_tracking_url': <bound method TaskStatusReporter.update_tracking_url of <luigi.worker.TaskStatusReporter object at 0x7f0583f0f588>>,; 'source_paths': ['gs://seqr-bw/merged_phased_3P5CH.split.vcf.gz'],; 'subset_path': None,; 'task_id': 'SeqrVCFToMTTask_gs___seqr_refere_VARIANTS_gs___seqr_bw_mer_b185718e87',; 'validate': False,; 'vep_config_json_path': None,; 'vep_runner': 'VEP'}; [Stage 1:======================================================>(492 + 8) / 500]2020-04-05 14:09:30 Hail: INFO: Coerced almost-sorted data",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:37919,validat,validate,37919,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['validat'],['validate']
Security,"0</a>)</li>; <li><a href=""https://github.com/googleapis/python-cloud-core/commit/70b348bdfd4c11c77793b907468c206ee457bd32""><code>70b348b</code></a> chore(deps): update all dependencies (<a href=""https://github-redirect.dependabot.com/googleapis/python-cloud-core/issues/188"">#188</a>)</li>; <li><a href=""https://github.com/googleapis/python-cloud-core/commit/6014db08ca2078a1c8ebb37ee46c53dae381e7d5""><code>6014db0</code></a> chore(main): release 2.3.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-cloud-core/issues/185"">#185</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-cloud-core/compare/v1.7.2...v2.3.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-cloud-core&package-manager=pip&previous-version=1.7.2&new-version=2.3.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12175:10275,secur,security-vulnerabilities,10275,https://hail.is,https://github.com/hail-is/hail/pull/12175,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"0e55bd51d3693d381ccc06f2fd4b5443d86""><code>c196f0e</code></a> 3.6.6</li>; <li><a href=""https://github.com/ijl/orjson/commit/81890b097f7a479d1c1e697d21467952e0be24a9""><code>81890b0</code></a> Fix 53-bit error on value between isize and usize</li>; <li><a href=""https://github.com/ijl/orjson/commit/8fc1e8989d6a72581aa71533384cb1ef9a260ebc""><code>8fc1e89</code></a> Fast conditional for zoneinfo.ZoneInfo</li>; <li><a href=""https://github.com/ijl/orjson/commit/853ffbdf8dc5f34792765c22aa835e1b67d90a76""><code>853ffbd</code></a> fix(errors): adjust column offset if not at char boundary</li>; <li>Additional commits viewable in <a href=""https://github.com/ijl/orjson/compare/3.6.4...3.6.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=orjson&package-manager=pip&previous-version=3.6.4&new-version=3.6.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11572:4552,secur,security-vulnerabilities,4552,https://hail.is,https://github.com/hail-is/hail/pull/11572,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,1(LocalBackend.scala:272); E 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:271); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); E 	at is.hail.utils.package$.using(package.scala:673); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); E 	at is.hail.utils.package$.using(package.scala:673); E 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); E 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); E 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:120); E 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); E 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); E 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:105); E 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:271); E 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); E 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); E 	at jdk.httpserver/sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:82); E 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:80); E 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:848); E 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); E 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:817); E 	at jdk.httpserver/sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:201); E 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:560); E 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.run(ServerImpl.java:526); E 	at java.base/java.lang.Thread.run(Thread.java:829); E; E; E; E Hail version: 0.2.132-f39364c177e0; E Error summary: RuntimeException: invalid memory access: 140a68008/00000001: not in 140a58008/00010000; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14705:8619,access,access,8619,https://hail.is,https://github.com/hail-is/hail/issues/14705,1,['access'],['access']
Security,"1. Do not leak the private key for lets encrypt into the renewal container's stdout and consequently into the logs.; 2. Do not revert the secret to an empty state before renewing the certificate. Doing so causes a failed renewal (e.g. 500s from lets encrypt) to destroy the extant keys. ---. Anyone using the Hail infrastructure should both regenerate their lets encrypt certificates with the changes in that PR. To do so they can execute the following from the root of the Hail repository:. make -C letsencrypt run. To take advantage of this vulnerability, someone would need access to the k8s container logs and the ability to redirect the relevant domain name to an IP they control. We have no evidence anyone has done this with Hail’s certs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11743:40,encrypt,encrypt,40,https://hail.is,https://github.com/hail-is/hail/pull/11743,6,"['access', 'certificate', 'encrypt']","['access', 'certificate', 'certificates', 'encrypt']"
Security,"1. If the user has not specified a configuration for disable_progress_bar, then only disable it if we are noninteractive. 2. Change @fails_service_backend to @skip... for a `to_spark` test. 3. Pass the path collision test by using `Validate`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12535:232,Validat,Validate,232,https://hail.is,https://github.com/hail-is/hail/pull/12535,1,['Validat'],['Validate']
Security,"1. Implement hailtop.aiotools.delete.; 2. Unify most definitions of rmtree and actually use parallelism.; 3. Remove unnecesary and confusing async annotation on OnlineBoundedGather2.call.; 4. Substantially increase the complexity of the rmtree test. I had to fix a circularity caused by RouterAsyncFS referencing the other clouds. The fix was easy, I don't re-expose it in hailtop.aiotools.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11072:360,expose,expose,360,https://hail.is,https://github.com/hail-is/hail/pull/11072,1,['expose'],['expose']
Security,"1. localize_entries is a no-op at runtime, it just exposes the table representation to python; 2. Good point. We agreed on ordering by column key, right?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13405#issuecomment-1673655493:51,expose,exposes,51,https://hail.is,https://github.com/hail-is/hail/pull/13405#issuecomment-1673655493,1,['expose'],['exposes']
Security,1.apply(CM.scala:82); 	at is.hail.expr.Parser$$anonfun$is$hail$expr$Parser$$evalNoTypeCheck$1.apply(Parser.scala:64); 	at is.hail.expr.Parser$$anonfun$parseTypedExpr$1.apply(Parser.scala:102); 	at scala.Function0$class.apply$mcJ$sp(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcJ$sp(AbstractFunction0.scala:12); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:81); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:79); 	at is.hail.utils.BinaryHeap.isLeftFavoredTie(BinaryHeap.scala:16); 	at is.hail.utils.BinaryHeap.is$hail$utils$BinaryHeap$$bubbleUp(BinaryHeap.scala:161); 	at is.hail.utils.BinaryHeap.insert(BinaryHeap.scala:40); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:101); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:100); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:100); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:86); 	at is.hail.utils.Graph.maximalIndependentSet(Graph.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.ex,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3704:2453,Hash,HashMap,2453,https://hail.is,https://github.com/hail-is/hail/pull/3704,1,['Hash'],['HashMap']
Security,105); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:464); 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:237); 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.go,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:14779,secur,security,14779,https://hail.is,https://github.com/hail-is/hail/issues/12982,3,['secur'],['security']
Security,"10db</code></a> Fix linter configs</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/6af8bf421a799208b27d57c6bf69de0d998fedec""><code>6af8bf4</code></a> Bump pre-commit from 2.15 to 2.16.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/269"">#269</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c71bbb5b5d7330f6dabfde7a1adec30a4611c0be""><code>c71bbb5</code></a> Bump docutils from 0.18 to 0.18.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/266"">#266</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/async-timeout/compare/v3.0.1...v4.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=async-timeout&package-manager=pip&previous-version=3.0.1&new-version=4.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:6589,secur,security-vulnerabilities,6589,https://hail.is,https://github.com/hail-is/hail/pull/11465,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"11509c75cfffd10e1ede1e2266249c0a""><code>b557851</code></a> Make section labels verbose to avoid numeric labels</li>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/73d1707e791712efb837167065c4173ce9b380f8""><code>73d1707</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1088"">#1088</a> from readthedocs/Blendify/fix-717</li>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/3a031121ed86bc2b857f734eede0b48d8164545b""><code>3a03112</code></a> Fix build</li>; <li>Additional commits viewable in <a href=""https://github.com/readthedocs/sphinx_rtd_theme/compare/0.4.2...1.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx-rtd-theme&package-manager=pip&previous-version=0.4.2&new-version=1.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11464:7201,secur,security-vulnerabilities,7201,https://hail.is,https://github.com/hail-is/hail/pull/11464,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"12.1</li>; <li><a href=""https://github.com/java-native-access/jna/commit/2f919e56bad203494fe9589206d6d23f27ef4f26""><code>2f919e5</code></a> Null-check cleanable in Memory#close (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1447"">#1447</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/1eec7dd76830af97ed64ecb2d8d39a56db104dcd""><code>1eec7dd</code></a> Prepare next development iteration</li>; <li><a href=""https://github.com/java-native-access/jna/commit/0d7499f105e4495bdea15fc21f5b1046e81ca822""><code>0d7499f</code></a> Release 5.12.0</li>; <li><a href=""https://github.com/java-native-access/jna/commit/fa86166d4f75ef4478de7ad9d7d6c0b6b6933ee0""><code>fa86166</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1445"">#1445</a> from matthiasblaesing/aix</li>; <li><a href=""https://github.com/java-native-access/jna/commit/4cca4405f7f6bc32d2a08495efb81c081b065279""><code>4cca440</code></a> Fix name mapping difference between AIX JDK 8 and Semeru JDK 18</li>; <li><a href=""https://github.com/java-native-access/jna/commit/f58b0f8f6b5c013adfe44a2cfb018ccb6ef6a688""><code>f58b0f8</code></a> Improve test stability on AIX (exclude tests that are expected to fail)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/c1565fb89469cbcba67b1cc305e16d520779b270""><code>c1565fb</code></a> Handle race condition in PdhUtil#PdhEnumObjectItems (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/99fcfa822db86b1f2ba5823dbf17efeb3d246ad5""><code>99fcfa8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1444"">#1444</a> from matthiasblaesing/update_libffi</li>; <li><a href=""https://github.com/java-native-access/jna/commit/9e473350a5ad5e04aab8b01e4018f973976e19f8""><code>9e47335</code></a> Update CHANGES.md</li>; <l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:6629,access,access,6629,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,"167b6""><code>bbc1d75</code></a> Test example code as part of tests</li>; <li><a href=""https://github.com/python-parsy/parsy/commit/18df37a479f1bc4170999866433ca19f92f19f63""><code>18df37a</code></a> Dropped Python 3.4 from tox</li>; <li><a href=""https://github.com/python-parsy/parsy/commit/1d7189b5bf78bd0d8d6e4bb2170dfeabba659c5c""><code>1d7189b</code></a> Merge branch 'master' of github.com:python-parsy/parsy</li>; <li><a href=""https://github.com/python-parsy/parsy/commit/8ec01153ccf6c58e2811c0e4c760b98125aeebca""><code>8ec0115</code></a> Link to SQL example from README</li>; <li>Additional commits viewable in <a href=""https://github.com/python-parsy/parsy/compare/v1.1.0...v1.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=parsy&package-manager=pip&previous-version=1.1.0&new-version=1.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12007:3461,secur,security-vulnerabilities,3461,https://hail.is,https://github.com/hail-is/hail/pull/12007,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,18-12-04 22:13:57 root: ERROR: IllegalArgumentException: null; From java.lang.IllegalArgumentException: null; at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:46); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:443); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:426); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:103); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:426); at org.apache.xbean.asm5.ClassReader.a(Unknown Source); at org.apache.xbean.asm5.ClassReader.b(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:257); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:256); at scala.collection.immutable.List.foreach(List.scala:381); at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:256); at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scal,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4896:1469,Hash,HashMap,1469,https://hail.is,https://github.com/hail-is/hail/issues/4896,1,['Hash'],['HashMap']
Security,"1bc1497"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""42.0.2""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6050294"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-CRYPTOGRAPHY-6126975"",""SNYK-PYTHON-CRYPTOGRAPHY-6210214"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,509,454,616,584,479,509,509,509,509,589,509,691,399,479,399,539,479,479,616,616,561,519],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:13220,Access,Access,13220,https://hail.is,https://github.com/hail-is/hail/pull/14327,1,['Access'],['Access']
Security,"1plus: error: unrecognized command line option ""-std=c++11""; make: *** [ibs.o] Error 1; :nativeLib FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':nativeLib'.; > Process 'command 'make'' finished with non-zero exit value 2. * Try:; Run with --info or --debug option to get more log output. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':nativeLib'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:69); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35); at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:66); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:52); at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52); at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:53); at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:203); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:185); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:66); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:50); at org.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3705:1891,Validat,ValidatingTaskExecuter,1891,https://hail.is,https://github.com/hail-is/hail/issues/3705,1,['Validat'],['ValidatingTaskExecuter']
Security,"2""><code>f6a3c11</code></a> Adding missing Py_DECREF call on iter</li>; <li><a href=""https://github.com/numpy/numpy/commit/8274a16bd4434405597f32aacaf8a53002718fc5""><code>8274a16</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22391"">#22391</a> from charris/backport-22372</li>; <li><a href=""https://github.com/numpy/numpy/commit/fa16a0ca51ef0654f541fcf6fa8d30f0f6263a94""><code>fa16a0c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22390"">#22390</a> from charris/backport-22360</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.23.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.23.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12441:6101,secur,security-vulnerabilities,6101,https://hail.is,https://github.com/hail-is/hail/pull/12441,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"21); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply$mcV$sp(TaskResultGetter.scala:139); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply(TaskResultGetter.scala:124); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply(TaskResultGetter.scala:124); at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:124); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```; `pyhail-submit`:; ```bash; #!/bin/bash. if [ $# -ne 2 ]; then; echo 'usage: gcp-pyhail-submit <cluster> <py-file>'; exit 1; fi. cluster=$1; script=$2. echo cluster = $cluster; echo script = $script. HASH=`gsutil cat gs://hail-common/latest-hash.txt`. JAR_FILE=hail-hail-is-master-all-spark2.0.2-$HASH.jar; JAR=gs://hail-common/$JAR_FILE. PYHAIL_ZIP=gs://hail-common/pyhail-hail-is-master-$HASH.zip. gcloud dataproc jobs submit pyspark \; $script \; --cluster $cluster \; --files=$JAR \; --py-files=$PYHAIL_ZIP \; --properties=""spark.driver.extraClassPath=./$JAR_FILE,spark.executor.extraClassPath=./$JAR_FILE"" \; --; ```; cluster JSON:; ```; {; ""projectId"": ""broad-ctsa"",; ""clusterName"": ""cluster-2"",; ""config"": {; ""configBucket"": ""dataproc-7f9e9d5e-03bd-4e95-bea1-fe0321239b35-us"",; ""gceClusterConfig"": {; ""zoneUri"": ""https://www.googleapis.com/compute/v1/projects/broad-ctsa/zones/us-central1-f"",; ""networkUri"": ""https://www.googleapis.com/compute/v1/projects/broad-ctsa/global/networks/default"",; ""serviceAccountScopes"": [; ""https://www.googleapis.com/auth/bigquery"",; ""https://www.googleapis.com/auth/bigtable.admin.table"",; ""https://www.googleapis.com/auth/bigtable.data"",; ""https://www.googleapis.com/auth/cloud.useraccounts.readonly"",; ""https://www.googleapis.com/auth/devstorage.full_contr",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027:2749,HASH,HASH,2749,https://hail.is,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027,1,['HASH'],['HASH']
Security,"217a1ce694e169ea2b33219d""><code>5166ee9</code></a> [Storage] Fix <code>upload_blob()</code> from an OS pipe on Linux (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23211"">#23211</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/84cbec033ed8e4df87f44a82dcebb96aa19deac0""><code>84cbec0</code></a> [Storage] Adjust some file-datalake test recordings (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23147"">#23147</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.8.1...azure-storage-blob_12.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-storage-blob&package-manager=pip&previous-version=12.8.1&new-version=12.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11610:6072,secur,security-vulnerabilities,6072,https://hail.is,https://github.com/hail-is/hail/pull/11610,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"21a7/hail-0.1-es-6.2.4-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, without-vep-520334-sw-rmwj.c.seqr-project.internal): java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; 	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); 	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); 	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); 	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:245); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:5832,Checksum,ChecksumFileSystem,5832,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['Checksum'],['ChecksumFileSystem']
Security,23); at sun.misc.URLClassPath$JarLoader.getResource(URLClassPath.java:1042); at sun.misc.URLClassPath.getResource(URLClassPath.java:239); at java.net.URLClassLoader$1.run(URLClassLoader.java:365); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at ja,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:2377,Hash,HashMap,2377,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Hash'],['HashMap']
Security,"26574/00000004: not in 7f15e9ffb1f8/00010000'; full = 'java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000\n\tat is.h...ava:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\n'; error_id = -1. def deco(*args, **kwargs):; import pyspark; try:; return f(*args, **kwargs); except py4j.protocol.Py4JJavaError as e:; s = e.java_exception.toString(); ; # py4j catches NoSuchElementExceptions to stop array iteration; if s.startswith('java.util.NoSuchElementException'):; raise; ; tpl = Env.jutils().handleForPython(e.java_exception); deepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); > raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; E hail.utils.java.FatalError: RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E ; E Java stack trace:; E java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E 	at is.hail.annotations.Memory.checkAddress(Memory.java:226); E 	at is.hail.annotations.Memory.loadInt(Memory.java:140); E 	at is.hail.annotations.Region$.loadInt(Region.scala:20); E 	at __C92844etypeDecode.__m92863ord_compareNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92862ord_compareNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92861ord_ltNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92860ord_lt(Unknown Source); E 	at __C92844etypeDecode.__m92857arraySorter_merge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:3649,access,access,3649,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198,1,['access'],['access']
Security,"3-05-04 01:04:37.560 : INFO: RegionPool: FREE: 129.0K allocated (129.0K blocks / 0 chunks), regions.size = 3, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.561 : ERROR: error while applying lowering 'LowerAndExecuteShuffles'; 2023-05-04 01:04:37.600 : INFO: RegionPool: initialized for thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=0, peakBytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.603 : ERROR: SocketException: Connection reset; From javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingIn",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:23709,secur,security,23709,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,30); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:235); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:234); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.TaskSchedulerImpl.cancelTasks(TaskSchedulerImpl.scala:234); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply$mcVI$sp(DAGScheduler.scala:1543); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAG,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:201438,Hash,HashSet,201438,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['Hash'],['HashSet']
Security,"30); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:235); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:234); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.TaskSchedulerImpl.cancelTasks(TaskSchedulerImpl.scala:234); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply$mcVI$sp(DAGScheduler.scala:1543); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1457); at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply$mcVI$sp(DAGScheduler.scala:723); at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:723); at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:723); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.doCancelAllJobs(DAGScheduler.scala:723); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onError(DAGScheduler.scala:1741); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:52); 2019-01-22 13:12:06 AbstractConnector: INFO: Stopped Spark@1433e9ec{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-01-22 13:12:06 SparkUI: ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:205085,Hash,HashSet,205085,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['Hash'],['HashSet']
Security,"3103d0ba35d0f0""><code>deea056</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45910"">#45910</a>: TST/CI: Set hypothesis deadline to None to avoid flaky fa...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/58aebf1940b56b77279174f5413b76a5aaba465c""><code>58aebf1</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45909"">#45909</a>: BUG: DateOffset(n) not defaulting to days (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45918"">#45918</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.0...v1.4.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.0&new-version=1.4.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11539:6263,secur,security-vulnerabilities,6263,https://hail.is,https://github.com/hail-is/hail/pull/11539,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"33d5f380513308f3e1a2d""><code>8dfa47d</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/23148"">#23148</a> from charris/backport-23079</li>; <li><a href=""https://github.com/numpy/numpy/commit/62af62aa546e27f6f3348c950a76aca9a230e37c""><code>62af62a</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/23147"">#23147</a> from charris/backport-23077</li>; <li><a href=""https://github.com/numpy/numpy/commit/2de8e5228a2df34160709b570df16070ba23818b""><code>2de8e52</code></a> Add missing &lt;type_traits&gt; header.</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.24.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.24.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12898:6307,secur,security-vulnerabilities,6307,https://hail.is,https://github.com/hail-is/hail/pull/12898,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"365e196daa39d038035325d5ed""><code>a47764b</code></a> docs: fix typo and unnecessary word in docstring (<a href=""https://github-redirect.dependabot.com/googleapis/google-api-python-client/issues/1692"">#1692</a>)</li>; <li><a href=""https://github.com/googleapis/google-api-python-client/commit/755cff661f95430dee01e676f63267ae0b97119c""><code>755cff6</code></a> chore(deps): update dependency google-api-python-client to v2.37.0 (<a href=""https://github-redirect.dependabot.com/googleapis/google-api-python-client/issues/1690"">#1690</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/google-api-python-client/compare/v1.7.10...v2.39.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-api-python-client&package-manager=pip&previous-version=1.7.10&new-version=2.39.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11541:35449,secur,security-vulnerabilities,35449,https://hail.is,https://github.com/hail-is/hail/pull/11541,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"3</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/bc9317ef90a629f27f1ab706bfce99da873044b4""><code>bc9317e</code></a> Change home URL to tree instead of README (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/1157"">#1157</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/c10296f15f92277ed1d3ed0c83103ae3818d3669""><code>c10296f</code></a> Add a README.rst file back temporarily. (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/1156"">#1156</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/python/typing_extensions/compare/4.2.0...4.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=typing-extensions&package-manager=pip&previous-version=4.2.0&new-version=4.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12200:4214,secur,security-vulnerabilities,4214,https://hail.is,https://github.com/hail-is/hail/pull/12200,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"3</h1>; <ul>; <li>api-change:<code>synthetics</code>: [<code>botocore</code>] Allow custom handler function.</li>; <li>api-change:<code>transfer</code>: [<code>botocore</code>] Add waiters for server online and offline.</li>; <li>api-change:<code>devops-guru</code>: [<code>botocore</code>] Amazon DevOps Guru now integrates with Amazon CodeGuru Profiler. You can view CodeGuru Profiler recommendations for your AWS Lambda function in DevOps Guru. This feature is enabled by default for new customers as of 3/4/2022. Existing customers can enable this feature with UpdateEventSourcesConfig.</li>; <li>api-change:<code>macie</code>: [<code>botocore</code>] Amazon Macie Classic (macie) has been discontinued and is no longer available. A new Amazon Macie (macie2) is now available with significant design improvements and additional features.</li>; <li>api-change:<code>ec2</code>: [<code>botocore</code>] Documentation updates for Amazon EC2.</li>; <li>api-change:<code>sts</code>: [<code>botocore</code>] Documentation updates for AWS Security Token Service.</li>; <li>api-change:<code>connect</code>: [<code>botocore</code>] This release updates the *InstanceStorageConfig APIs so they support a new ResourceType: REAL_TIME_CONTACT_ANALYSIS_SEGMENTS. Use this resource type to enable streaming for real-time contact analysis and to associate the Kinesis stream where real-time contact analysis segments will be published.</li>; </ul>; <h1>1.21.12</h1>; <ul>; <li>api-change:<code>greengrassv2</code>: [<code>botocore</code>] Doc only update that clarifies Create Deployment section.</li>; <li>api-change:<code>fsx</code>: [<code>botocore</code>] This release adds support for data repository associations to use root (&quot;/&quot;) as the file system path</li>; <li>api-change:<code>kendra</code>: [<code>botocore</code>] Amazon Kendra now suggests spell corrections for a query. For more information, see <a href=""https://docs.aws.amazon.com/kendra/latest/dg/query-spell-check.html"">https://docs.a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11504:1292,Secur,Security,1292,https://hail.is,https://github.com/hail-is/hail/pull/11504,1,['Secur'],['Security']
Security,"3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""50e1cce8-d68e-4133-a591-e2d1a6257337"",""prPublicId"":""50e1cce8-d68e-4133-a591-e2d1a6257337"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""41.0.4""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13887:9811,Access,Access,9811,https://hail.is,https://github.com/hail-is/hail/pull/13887,1,['Access'],['Access']
Security,"3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""d900f7ca-fce7-41d4-a16d-bad109338beb"",""prPublicId"":""d900f7ca-fce7-41d4-a16d-bad109338beb"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""41.0.4""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13736:9811,Access,Access,9811,https://hail.is,https://github.com/hail-is/hail/pull/13736,1,['Access'],['Access']
Security,"3aa65c4291b8a1a134cd024fbe071323f400c83""><code>83aa65c</code></a> Add mamba support to <code>language: conda</code></li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/657e76ba77ef4ae5b6e2ebe5f06cacdbf22a19a2""><code>657e76b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2205"">#2205</a> from jalessio/jamie/upgrade-rbenv</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/428dc6e46eb68065bfc115419927949cdd056811""><code>428dc6e</code></a> Update rbenv / ruby-build versions</li>; <li>Additional commits viewable in <a href=""https://github.com/pre-commit/pre-commit/compare/v2.9.2...v2.17.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pre-commit&package-manager=pip&previous-version=2.9.2&new-version=2.17.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11460:14660,secur,security-vulnerabilities,14660,https://hail.is,https://github.com/hail-is/hail/pull/11460,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"3bef2d6e531e83cefd65be4cbbf41fcf2531""><code>66dd3be</code></a> [Storage] Fix more flaky lease tests (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25011"">#25011</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/030141734a239fa6fb1aa7a8c43d322c82753510""><code>0301417</code></a> [Storage] Add argument to perf tests to use client-side encryption (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/24978"">#24978</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.11.0...azure-storage-blob_12.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-storage-blob&package-manager=pip&previous-version=12.11.0&new-version=12.13.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12109:4897,secur,security-vulnerabilities,4897,https://hail.is,https://github.com/hail-is/hail/pull/12109,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"4, scc-q21.scc.bu.edu, executor 2): java.io.FileNotFoundException: /scratch/.writeBlocksRDD-l5om7fTy3akZKCYbLDY4AD.crc (Too many open files); at java.io.FileOutputStream.open0(Native Method); at java.io.FileOutputStream.open(FileOutputStream.java:270); at java.io.FileOutputStream.<init>(FileOutputStream.java:213); at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:222); at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209); at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307); at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296); at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328); at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:402); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:778); at is.hail.io.fs.HadoopFS.createNoCompression(HadoopFS.scala:60); at is.hail.io.fs.FS$class.create(FS.scala:151); at is.hail.io.fs.HadoopFS.create(HadoopFS.scala:56); at is.hail.linalg.WriteBlocksRDD$$anonfun$62.apply(BlockMatrix.scala:1838); at is.hail.linalg.WriteBlocksRDD$$anonfun$62.apply(BlockMatrix.scala:1829); at scala.Array$.tabulate(Array.scala:331); at is.hail.linalg.WriteBlocksRDD.compute(BlockMatrix.scala:1829); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.ex",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403:10685,Checksum,ChecksumFileSystem,10685,https://hail.is,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403,1,['Checksum'],['ChecksumFileSystem']
Security,"40803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxMjY5MWQyMS0wMzk1LTQxYjMtODBkMi1mMjEyODMwZjY2ZWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjEyNjkxZDIxLTAzOTUtNDFiMy04MGQyLWYyMTI4MzBmNjZlYSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""12691d21-0395-41b3-80d2-f212830f66ea"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13873:3955,access,access,3955,https://hail.is,https://github.com/hail-is/hail/pull/13873,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"41fa331a5b4d129d94""><code>2004149</code></a> Update test</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/78c478a579b9d3f57091544d1717ee7f1c507ff1""><code>78c478a</code></a> Merge remote-tracking branch 'upstream/5.0.x' into lang-none-en</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/479e48266c025c99025787a8004a82b2afda8e6c""><code>479e482</code></a> Update warning, revert my original warning patch</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/fb6db30c1024ce5838dcf330f275cdf2adbd94b6""><code>fb6db30</code></a> Update comment</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v5.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=5.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11871:6525,secur,security-vulnerabilities,6525,https://hail.is,https://github.com/hail-is/hail/pull/11871,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"4423b434495f5""><code>8b8e4b5</code></a> Temporary fix for SLSA generator</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/cc9b0dc10eaf83b1242d710222525edd73555b6d""><code>cc9b0dc</code></a> [1.26] Fix logo URL in README</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/eb47444a9dfaa045cc4753e4d77c57fbdccaa619""><code>eb47444</code></a> [1.26] Fix CI by switching to macOS 11</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/34d7348bb96eca390c2115aeeee31d1147830844""><code>34d7348</code></a> Remove &quot;&lt;4&quot; upper bound from python_requires</li>; <li>See full diff in <a href=""https://github.com/urllib3/urllib3/compare/1.26.12...1.26.13"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.12&new-version=1.26.13)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12506:3539,secur,security-vulnerabilities,3539,https://hail.is,https://github.com/hail-is/hail/pull/12506,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"4a""><code>3f2143d</code></a> Always allow use of <code>type[T]</code> in stubs (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/11863"">#11863</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/12290decccf3d60e3b56c23be09bc853a3ed6051""><code>12290de</code></a> Bump version to 0.931+dev</li>; <li><a href=""https://github.com/python/mypy/commit/8ce64aca6e84860ffbd2605f7cb52e97c8c10771""><code>8ce64ac</code></a> [0.931 backport] Fix <strong>reduce</strong> regression (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/11866"">#11866</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/python/mypy/compare/v0.780...v0.931"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mypy&package-manager=pip&previous-version=0.780&new-version=0.931)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11498:2860,secur,security-vulnerabilities,2860,https://hail.is,https://github.com/hail-is/hail/pull/11498,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"5). org.apache.spark.SparkException: Job aborted due to stage failure: Task 12 in stage 103.0 failed 4 times, most recent failure: Lost task 12.3 in stage 103.0 (TID 644994, scc-q21.scc.bu.edu, executor 2): java.io.FileNotFoundException: /scratch/.writeBlocksRDD-l5om7fTy3akZKCYbLDY4AD.crc (Too many open files); at java.io.FileOutputStream.open0(Native Method); at java.io.FileOutputStream.open(FileOutputStream.java:270); at java.io.FileOutputStream.<init>(FileOutputStream.java:213); at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:222); at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209); at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307); at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296); at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328); at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:402); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:778); at is.hail.io.fs.HadoopFS.createNoCompression(HadoopFS.scala:60); at is.hail.io.fs.FS$class.create(FS.scala:151); at is.hail.io.fs.HadoopFS.create(HadoopFS.scala:56); at is.hail.linalg.WriteBlocksRDD$$anonfun$62.apply(BlockMatrix.scala:1838); at is.hail.linalg.WriteBlocksRDD$$anonfun$62.apply(BlockMatrix.scala:1829); at scala.Array$.tabulate(Array.scala:331); at is.hail.linalg.WriteBlocksRDD.compute(BlockMatrix.scala:1829); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.it",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403:10502,Checksum,ChecksumFileSystem,10502,https://hail.is,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403,2,['Checksum'],"['ChecksumFSOutputSummer', 'ChecksumFileSystem']"
Security,"506, in _async_execute; _, resp, timings = await self._rpc('execute(...)', inputs, ir=ir, progress=progress); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 449, in _rpc; result_bytes = await retry_transient_errors(self._read_output, ir, iodir + '/out'); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 774, in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 787, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 475, in _read_output; raise reconstructed_error.maybe_user_error(ir); hail.utils.java.FatalError: SocketException: Connection reset. Java stack trace:; javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingIn",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:2820,secur,security,2820,https://hail.is,https://github.com/hail-is/hail/issues/12982,1,['secur'],['security']
Security,"509, in _async_execute; _, resp, timings = await self._rpc('execute(...)', inputs, ir=ir, progress=progress); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 451, in _rpc; result_bytes = await retry_transient_errors(self._read_output, ir, iodir + '/out'); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 779, in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 792, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 477, in _read_output; raise reconstructed_error.maybe_user_error(ir); hail.utils.java.FatalError: SocketException: Connection reset. Java stack trace:; javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingIn",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:3708,secur,security,3708,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,"51</code></a> Merge branch 'release/v3.8.2' into 3.8</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/3ef9cab654f1d2101d4e243cd5907966f9953f4c""><code>3ef9cab</code></a> Bump the hardcoded version to v3.8.2.post0.dev0</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/99c8d0d7706153970bc1cbace8bdf4ab137783c7""><code>99c8d0d</code></a> Brush up the changelog wording for v3.8.2</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/a56b31cae75506e0640808567372359a159b1f96""><code>a56b31c</code></a> Add a note about Python 3.6 in the changelog</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.8.1...v3.8.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.8.1&new-version=3.8.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12296:7732,secur,security-vulnerabilities,7732,https://hail.is,https://github.com/hail-is/hail/pull/12296,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"5b97ccab04ab""><code>1957538</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/issues/157"">#157</a>)</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/e6c1a64d24eb9f1524cc0464bf6acd87a82b08fd""><code>e6c1a64</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/issues/156"">#156</a>)</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/fbf0e45745556f508b0861f370ba8af13a09d07e""><code>fbf0e45</code></a> Add funding</li>; <li>Additional commits viewable in <a href=""https://github.com/tox-dev/py-filelock/compare/3.7.1...3.8.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=filelock&package-manager=pip&previous-version=3.7.1&new-version=3.8.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12157:6859,secur,security-vulnerabilities,6859,https://hail.is,https://github.com/hail-is/hail/pull/12157,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"5bf9f9115e6a3a455d8cc947790b64f8c7101a7""><code>45bf9f9</code></a> Merge remote-tracking branch 'upstream/main' into patch-1</li>; <li><a href=""https://github.com/docker/docker-py/commit/c03aeb659e2ac996aa69927e928b73d2979b9fce""><code>c03aeb6</code></a> Merge remote-tracking branch 'upstream/main' into connect-with-mac</li>; <li><a href=""https://github.com/docker/docker-py/commit/58aa62bb154a2ccea433cf475aefbd695fb5abc8""><code>58aa62b</code></a> swarm: add sysctl support for services (<a href=""https://github-redirect.dependabot.com/docker/docker-py/issues/3029"">#3029</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/docker/docker-py/compare/5.0.3...6.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=docker&package-manager=pip&previous-version=5.0.3&new-version=6.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12475:7410,secur,security-vulnerabilities,7410,https://hail.is,https://github.com/hail-is/hail/pull/12475,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"6"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""},{""name"":""wheel"",""from"":""0.30.0"",""to"":""0.38.0""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512"",""SNYK-PYTHON-WHEEL-3180413""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,531,null,null,null,null,null,null,null,null,null,null,509,null,null,null,null,384,494,539,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14024:11273,validat,validation,11273,https://hail.is,https://github.com/hail-is/hail/pull/14024,1,['validat'],['validation']
Security,"6)</h2>; <p><strong>Improvements</strong></p>; <ul>; <li>Requests now defers chunked requests to the urllib3 implementation to improve; standardization. (<a href=""https://redirect.github.com/psf/requests/issues/6226"">#6226</a>)</li>; <li>Requests relaxes header component requirements to support bytes/str subclasses. (<a href=""https://redirect.github.com/psf/requests/issues/6356"">#6356</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/requests/blob/main/HISTORY.md"">requests's changelog</a>.</em></p>; <blockquote>; <h2>2.31.0 (2023-05-22)</h2>; <p><strong>Security</strong></p>; <ul>; <li>; <p>Versions of Requests between v2.3.0 and v2.30.0 are vulnerable to potential; forwarding of <code>Proxy-Authorization</code> headers to destination servers when; following HTTPS redirects.</p>; <p>When proxies are defined with user info (<a href=""https://user:pass@proxy:8080"">https://user:pass@proxy:8080</a>), Requests; will construct a <code>Proxy-Authorization</code> header that is attached to the request to; authenticate with the proxy.</p>; <p>In cases where Requests receives a redirect response, it previously reattached; the <code>Proxy-Authorization</code> header incorrectly, resulting in the value being; sent through the tunneled connection to the destination server. Users who rely on; defining their proxy credentials in the URL are <em>strongly</em> encouraged to upgrade; to Requests 2.31.0+ to prevent unintentional leakage and rotate their proxy; credentials once the change has been fully deployed.</p>; <p>Users who do not use a proxy or do not supply their proxy credentials through; the user information portion of their proxy URL are not subject to this; vulnerability.</p>; <p>Full details can be read in our <a href=""https://github.com/psf/requests/security/advisories/GHSA-j8r2-6x86-q33q"">Github Security Advisory</a>; and <a href=""https://nvd.nist.gov/vuln/detail/CVE-2023-32681"">CVE-20",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13091:3257,Authoriz,Authorization,3257,https://hail.is,https://github.com/hail-is/hail/pull/13091,12,"['Authoriz', 'authenticat']","['Authorization', 'authenticate']"
Security,"6456</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/requests/blob/main/HISTORY.md"">requests's changelog</a>.</em></p>; <blockquote>; <h2>2.32.0 (2024-05-20)</h2>; <p><strong>Security</strong></p>; <ul>; <li>Fixed an issue where setting <code>verify=False</code> on the first request from a; Session will cause subsequent requests to the <em>same origin</em> to also ignore; cert verification, regardless of the value of <code>verify</code>.; (<a href=""https://github.com/psf/requests/security/advisories/GHSA-9wx4-h78v-vm56"">https://github.com/psf/requests/security/advisories/GHSA-9wx4-h78v-vm56</a>)</li>; </ul>; <p><strong>Improvements</strong></p>; <ul>; <li><code>verify=True</code> now reuses a global SSLContext which should improve; request time variance between first and subsequent requests. It should; also minimize certificate load time on Windows systems when using a Python; version built with OpenSSL 3.x. (<a href=""https://redirect.github.com/psf/requests/issues/6667"">#6667</a>)</li>; <li>Requests now supports optional use of character detection; (<code>chardet</code> or <code>charset_normalizer</code>) when repackaged or vendored.; This enables <code>pip</code> and other projects to minimize their vendoring; surface area. The <code>Response.text()</code> and <code>apparent_encoding</code> APIs; will default to <code>utf-8</code> if neither library is present. (<a href=""https://redirect.github.com/psf/requests/issues/6702"">#6702</a>)</li>; </ul>; <p><strong>Bugfixes</strong></p>; <ul>; <li>Fixed bug in length detection where emoji length was incorrectly; calculated in the request content-length. (<a href=""https://redirect.github.com/psf/requests/issues/6589"">#6589</a>)</li>; <li>Fixed deserialization bug in JSONDecodeError. (<a href=""https://redirect.github.com/psf/requests/issues/6629"">#6629</a>)</li>; <li>Fixed bug where an ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14555:4903,certificate,certificate,4903,https://hail.is,https://github.com/hail-is/hail/pull/14555,1,['certificate'],['certificate']
Security,"66d4f75ef4478de7ad9d7d6c0b6b6933ee0""><code>fa86166</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1445"">#1445</a> from matthiasblaesing/aix</li>; <li><a href=""https://github.com/java-native-access/jna/commit/4cca4405f7f6bc32d2a08495efb81c081b065279""><code>4cca440</code></a> Fix name mapping difference between AIX JDK 8 and Semeru JDK 18</li>; <li><a href=""https://github.com/java-native-access/jna/commit/f58b0f8f6b5c013adfe44a2cfb018ccb6ef6a688""><code>f58b0f8</code></a> Improve test stability on AIX (exclude tests that are expected to fail)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/c1565fb89469cbcba67b1cc305e16d520779b270""><code>c1565fb</code></a> Handle race condition in PdhUtil#PdhEnumObjectItems (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/99fcfa822db86b1f2ba5823dbf17efeb3d246ad5""><code>99fcfa8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1444"">#1444</a> from matthiasblaesing/update_libffi</li>; <li><a href=""https://github.com/java-native-access/jna/commit/9e473350a5ad5e04aab8b01e4018f973976e19f8""><code>9e47335</code></a> Update CHANGES.md</li>; <li>Additional commits viewable in <a href=""https://github.com/java-native-access/jna/compare/5.6.0...5.12.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=net.java.dev.jna:jna&package-manager=gradle&previous-version=5.6.0&new-version=5.12.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:7318,access,access,7318,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,"718c4a5d3ddd671fbd4881bf176e7d6e2""><code>0818628</code></a> Check input type before escaping</li>; <li><a href=""https://github.com/jupyter/nbconvert/commit/b206470f9ecd71b006a37dd1298dd3d9e3dd46dd""><code>b206470</code></a> GHSL-2021-1017, GHSL-2021-1020, GHSL-2021-1021</li>; <li><a href=""https://github.com/jupyter/nbconvert/commit/a03cbb8a8d04d47aefec51e7b1b816045682aed5""><code>a03cbb8</code></a> GHSL-2021-1026, GHSL-2021-1025</li>; <li><a href=""https://github.com/jupyter/nbconvert/commit/48fe71eb3335caf4e03166e56e0d16efcfbeaf44""><code>48fe71e</code></a> GHSL-2021-1024</li>; <li>Additional commits viewable in <a href=""https://github.com/jupyter/nbconvert/compare/6.5...6.5.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=nbconvert&package-manager=pip&previous-version=6.5.0&new-version=6.5.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12125:2065,secur,security-vulnerabilities,2065,https://hail.is,https://github.com/hail-is/hail/pull/12125,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"74845225#HowTo...-SetUpTeamCitybehindaProxyServer):. ``` apache; <IfModule mod_ssl.c>; <VirtualHost *:443>; # The ServerName directive sets the request scheme, hostname and port that; # the server uses to identify itself. This is used when creating; # redirection URLs. In the context of virtual hosts, the ServerName; # specifies what hostname must appear in the request's Host: header to; # match this virtual host. For the default virtual host (this file) this; # value is not decisive as it is used as a last resort host regardless.; # However, you must set it for any further virtual host explicitly.; ServerName hail.is; ServerAlias www.hail.is. ServerAdmin webmaster@localhost; DocumentRoot /var/www/html. RedirectMatch 404 /\.git. # Available loglevels: trace8, ..., trace1, debug, info, notice, warn,; # error, crit, alert, emerg.; # It is also possible to configure the loglevel for particular; # modules, e.g.; #LogLevel info ssl:warn. ErrorLog ${APACHE_LOG_DIR}/error.log; CustomLog ${APACHE_LOG_DIR}/access.log combined. # For most configuration files from conf-available/, which are; # enabled or disabled at a global level, it is possible to; # include a line for only one particular virtual host. For example the; # following line enables the CGI configuration for this host only; # after it has been globally disabled with ""a2disconf"".; #Include conf-available/serve-cgi-bin.conf; SSLCertificateFile /etc/letsencrypt/live/hail.is/fullchain.pem; SSLCertificateKeyFile /etc/letsencrypt/live/hail.is/privkey.pem; Include /etc/letsencrypt/options-ssl-apache.conf; </VirtualHost>. <VirtualHost *:443>; ServerName ci.hail.is; ServerAdmin webmaster@localhost. LoadModule proxy_module /usr/lib/apache2/modules/mod_proxy.so; LoadModule proxy_http_module /usr/lib/apache2/modules/mod_proxy_http.so; LoadModule headers_module /usr/lib/apache2/modules/mod_headers.so; LoadModule proxy_wstunnel_module /usr/lib/apache2/modules/mod_proxy_wstunnel.so. ProxyRequests Off; ProxyPreserveHost On; Proxy",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/674#issuecomment-243899170:1518,access,access,1518,https://hail.is,https://github.com/hail-is/hail/issues/674#issuecomment-243899170,1,['access'],['access']
Security,"7742b6cee738aa295d8b835c3a195""><code>e04ea73</code></a> cargo update, build misc</li>; <li><a href=""https://github.com/ijl/orjson/commit/ba8c701292e4720b4e10210b266be5666d098fb6""><code>ba8c701</code></a> 3.9.14</li>; <li><a href=""https://github.com/ijl/orjson/commit/a2f7b7bfa4987c102892793ab7c7483fcb8050a0""><code>a2f7b7b</code></a> impl_format_simd!() lift create from loop, rotate left</li>; <li><a href=""https://github.com/ijl/orjson/commit/528220fb0d18bbf0212de7f0ce5c7aec209bc6e7""><code>528220f</code></a> format_escaped_str() fast and slow paths depending on page boundary</li>; <li>Additional commits viewable in <a href=""https://github.com/ijl/orjson/compare/3.9.10...3.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=orjson&package-manager=pip&previous-version=3.9.10&new-version=3.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14427:5157,secur,security-vulnerabilities,5157,https://hail.is,https://github.com/hail-is/hail/pull/14427,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"77819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-5750273](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-5750273) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-SPHINX-570772](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-570772) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-SPHINX-570773](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-570773) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5811865](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5811865) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5812109](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5812109) | `sphinx:` <br> `1.8.6",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13835:5619,Cross-site Scripting,Cross-site Scripting,5619,https://hail.is,https://github.com/hail-is/hail/pull/13835,10,"['Cross-site Scripting', 'XSS']","['Cross-site Scripting', 'XSS']"
Security,"77819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-5750273](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-5750273) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `40.5.0 -> 65.5.1` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-SPHINX-570772](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-570772) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-SPHINX-570773](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-570773) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5811865](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5811865) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5812109](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5812109) | `sphinx:` <br> `1.8.6",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14364:6532,Cross-site Scripting,Cross-site Scripting,6532,https://hail.is,https://github.com/hail-is/hail/pull/14364,2,"['Cross-site Scripting', 'XSS']","['Cross-site Scripting', 'XSS']"
Security,7bada10c324c0b)). That landed in [2.25.0](https://github.com/googleapis/java-storage/releases/tag/v2.25.0) which was released in July. ```; is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-2LzGioRNy6RqIS2pfXIoSO&uploadType=resumable&upload_id=ADPycdvZ5HhnGfOKt5TE1qXWiHpqIpZnXVTYWuWUCXNPRF9HqyCB-4LvRsxNX6SUWRgk13pYrzYaa9-wXlvNZt1oct0ptaEz0bS3; chunkOffset: 16777216; chunkLength: 8388608; localOffset: 268435456; remoteOffset: 285212672; lastChunk: false. 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:267); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103); 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.flushBuffer(BlobWriteChannel.java:189); 	at is.hail.relocated.com.google.cloud.BaseWriteChannel.flush(BaseWriteChannel.java:112); 	at is.hail.relocated.com.google.cloud.BaseWriteChannel.write(BaseWriteChannel.java:139); 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$flush$1(GoogleStorageFS.scala:317); 	at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:299); 	at is.hail.io.fs.GoogleStorageFS$$anon$2.flush(GoogleStorageFS.scala:317);,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911:2086,access,access,2086,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911,1,['access'],['access']
Security,"7cf0b55a1""><code>3de7f40</code></a> Remove dependency on deprecated keyring.util.properties. Fixes <a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/47"">#47</a>.</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/010fe59c64ffacbc0f97405d3bf21072d811baf1""><code>010fe59</code></a> Merge <a href=""https://github.com/jaraco/skeleton"">https://github.com/jaraco/skeleton</a></li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/47c2cb324e20f784289496ef3a7b19a1cd23d196""><code>47c2cb3</code></a> Also update release to v4</li>; <li>Additional commits viewable in <a href=""https://github.com/jaraco/keyrings.alt/compare/v3.5.2...v4.2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=keyrings-alt&package-manager=pip&previous-version=3.5.2&new-version=4.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12448:3647,secur,security-vulnerabilities,3647,https://hail.is,https://github.com/hail-is/hail/pull/12448,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"8""><code>c3c0b3f</code></a> Fix potential ReDoS (<a href=""https://github-redirect.dependabot.com/chalk/ansi-regex/issues/37"">#37</a>)</li>; <li><a href=""https://github.com/chalk/ansi-regex/commit/178363b3a297b712a0054e702d8ddde3879913e5""><code>178363b</code></a> Move to GitHub Actions (<a href=""https://github-redirect.dependabot.com/chalk/ansi-regex/issues/35"">#35</a>)</li>; <li><a href=""https://github.com/chalk/ansi-regex/commit/0755e661553387cfebcb62378181e9f55b2567ff""><code>0755e66</code></a> Add <a href=""https://github.com/Qix""><code>@​Qix</code></a>- to funding.yml</li>; <li>See full diff in <a href=""https://github.com/chalk/ansi-regex/compare/v5.0.0...v5.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ansi-regex&package-manager=npm_and_yarn&previous-version=5.0.0&new-version=5.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11287:2694,secur,security-vulnerabilities,2694,https://hail.is,https://github.com/hail-is/hail/pull/11287,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"80f7bc40d39""><code>d9ac3f3</code></a> FIX:linalg:Guard against possible permute_l out of bound behavior</li>; <li><a href=""https://github.com/scipy/scipy/commit/7ec501097b3a22569025bf0d62cb2d89474c812b""><code>7ec5010</code></a> BUG: fix handling for <code>factorial(..., exact=False)</code> for 0-dim array inputs (#...</li>; <li><a href=""https://github.com/scipy/scipy/commit/90415c6890365585576e96e42c5aeba253da0091""><code>90415c6</code></a> BUG: Fix work array construction for various weight shapes. (<a href=""https://redirect.github.com/scipy/scipy/issues/18741"">#18741</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/scipy/scipy/compare/v1.9.3...v1.11.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=scipy&package-manager=pip&previous-version=1.9.3&new-version=1.11.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Depe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13228:4782,secur,security-vulnerabilities,4782,https://hail.is,https://github.com/hail-is/hail/pull/13228,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"82 indicate that a bad interaction between the data and a hash function can cause this integer map to exceed its size limitations at a load factor of 5%. Even a 20x increase in footprint puts us at 400 million. Each element of that array has 6 entries, so we're at 1.2 billion. That definitely feels like the danger zone. Maybe there's more variants than Danfeng expects, maybe there's more overhead than we've accounted for. The GATK folks have been chasing down the fix. Kryo [released 4.0.0](https://github.com/EsotericSoftware/kryo/issues/431) which should fix this issue. Spark [upgraded to Kryo 4.0.0](https://github.com/apache/spark/pull/22179) on September 8th of 2018. (resolving [Spark-20389](https://issues.apache.org/jira/browse/SPARK-20389)). This change made it to 2.4.0, but it was not back ported to other versions of Spark. GATK [references a temporary fix via JVM options](; https://github.com/broadinstitute/gatk/issues/1524#issuecomment-189368808), which apparently forces the JVM to use an alternative hash function with better behavior in this specific case:; ```; spark.executor.extraJavaOptions -XX:hashCode=0; spark.driver.extraJavaOptions -XX:hashCode=0; ```; A [generally interesting blog post on Java's hashCode](https://srvaroa.github.io/jvm/java/openjdk/biased-locking/2017/01/30/hashCode.html), which I haven't fully read, claims that the JVM previously defaulted to a PRNG draw for an object's hash code. In JDK 8 it uses some function of the current thread state. It appears this old strategy is preserved as JVM hashCode parameter value 0 and is less likely to trigger the bad behavior in Kryo. This `-XX:hashCode` option is undocumented [1](https://docs.oracle.com/javase/8/docs/technotes/tools/windows/java.html), [2](https://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html) 🤷‍♀️. Another suggested Kryo option is to disable reference tracking. This would cause duplicate objects in the object graph to be serialized twice:; ```java; Kryo kryo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5564:1565,hash,hash,1565,https://hail.is,https://github.com/hail-is/hail/issues/5564,1,['hash'],['hash']
Security,"898</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13905"">#13905</a> from Carreau/bad-fd</li>; <li><a href=""https://github.com/ipython/ipython/commit/4a065015a1b987ac6f30fff9180efbd93cffbed6""><code>4a06501</code></a> Remove opening/at-exit closing of devnull.</li>; <li><a href=""https://github.com/ipython/ipython/commit/9d0419bed36bae7228b2ad48296e58b918b1a9b8""><code>9d0419b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13900"">#13900</a> from Carreau/doc-autosugg</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12664:2510,secur,security-vulnerabilities,2510,https://hail.is,https://github.com/hail-is/hail/pull/12664,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"89a94f694645c642ae67b2d5972d3f9fdadb928""><code>289a94f</code></a> Remove old classes that are deprecated for 2 years</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/fa1f45b556341b2c34e9bf63c06a5068571cd337""><code>fa1f45b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/108"">#108</a> from AzureAD/actionable-encryption-exceptions</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/effe77842d25a8b093d18d9e33347f13e2ee094f""><code>effe778</code></a> Provide actionable messages for 2 dpapi errors</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/b674b6a07ca27b2c1b6f371040f035a546cfd468""><code>b674b6a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/107"">#107</a> from AzureAD/file600</li>; <li>Additional commits viewable in <a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/compare/0.3.1...1.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=msal-extensions&package-manager=pip&previous-version=0.3.1&new-version=1.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recre",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:4324,authenticat,authentication-extensions-for-python,4324,https://hail.is,https://github.com/hail-is/hail/pull/11992,1,['authenticat'],['authentication-extensions-for-python']
Security,9); at java.net.URLClassLoader$1.run(URLClassLoader.java:365); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.Out,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:2504,Hash,HashTable,2504,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Hash'],['HashTable']
Security,"912</code></a> MAINT: mock slowest test.</li>; <li><a href=""https://github.com/ipython/ipython/commit/a011765b44febfb11bae122d2ed7db763621ac8f""><code>a011765</code></a> Isolate the attack tests with setUp and tearDown methods</li>; <li><a href=""https://github.com/ipython/ipython/commit/c7a9470e540392c575aac46c3ee5cf4fe5123eb1""><code>c7a9470</code></a> Add some regression tests for this change</li>; <li><a href=""https://github.com/ipython/ipython/commit/fd34cf5f1f6e243243c738c6e0cf62eb682c4d68""><code>fd34cf5</code></a> Swallow potential exceptions from showtraceback()</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12683:2436,secur,security-vulnerabilities,2436,https://hail.is,https://github.com/hail-is/hail/pull/12683,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"93b95d</code></a> Merge CHANGES entry for 4.4.1 to 4.5.0</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/a001bf47d66ae804a9a6e5d754de9b5eda4d0eb9""><code>a001bf4</code></a> Update CHANGES for PR <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10107"">#10107</a></li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/b20e04968e73234da9fff7d19b12dfbeebebe944""><code>b20e049</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10107"">#10107</a> from Jean-Abou-Samra/intl-warnings</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v4.5.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=4.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11714:7779,secur,security-vulnerabilities,7779,https://hail.is,https://github.com/hail-is/hail/pull/11714,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"9518) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6157248](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6157248) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxZDhjNDI0MS1hOTllLTQwZDktOTM5Yy0zZWMzM2NkNTI0ZjkiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjFkOGM0MjQxLWE5OWUtNDBkOS05MzljLTNlYzMzY2Q1MjRmOSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""1d8c4241-a99e-40d9-939c-3ec33cd524f9"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14230:2287,access,access,2287,https://hail.is,https://github.com/hail-is/hail/pull/14230,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"9717165b352c7f2f207c8e4ef624a01""><code>8bd8288</code></a> Build(deps): Bump pytest from 8.0.2 to 8.1.1 in /dependencies/default</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/ef3b3477070d6a270e1bb2c1d438c64dba42724c""><code>ef3b347</code></a> Build(deps): Bump packaging from 23.2 to 24.0 in /dependencies/default</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/b22d84e1f0d53920352be4c66d1b6c7f7a9ce005""><code>b22d84e</code></a> [docs] Fixes the example showing how to run all tests in a session-scoped loop.</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest-asyncio/compare/v0.21.1...v0.23.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-asyncio&package-manager=pip&previous-version=0.21.1&new-version=0.23.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14507:9438,secur,security-vulnerabilities,9438,https://hail.is,https://github.com/hail-is/hail/pull/14507,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"99fd48d029f326cc54e036c994084c190""><code>18e1933</code></a> Migrate KeyVault Secrets to Autorest and stream-style serialization (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36461"">#36461</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/910c88d6e85ba55d62062bf502055dfefa109530""><code>910c88d</code></a> mgmt compute, support convenience API listVmByVmss (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36631"">#36631</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-java/compare/azure-core-http-netty_1.13.3...azure-core-http-netty_1.13.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.azure:azure-core-http-netty&package-manager=gradle&previous-version=1.13.3&new-version=1.13.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13597:3812,secur,security-vulnerabilities,3812,https://hail.is,https://github.com/hail-is/hail/pull/13597,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"9c4acb8d289e51005b8""><code>441d458</code></a> fix FUNDING file</li>; <li><a href=""https://github.com/qos-ch/slf4j/commit/f5e741ba1af6565269499d34c725c32ef8ca467f""><code>f5e741b</code></a> add FUNDING file</li>; <li><a href=""https://github.com/qos-ch/slf4j/commit/2e71327c8ee745927d731e8d9f4e51d331dad138""><code>2e71327</code></a> remove unused log4j dependency in the version definition section of pom.xml</li>; <li><a href=""https://github.com/qos-ch/slf4j/commit/3ff2a30e05e5825d96ddb54da243df48f1a9d897""><code>3ff2a30</code></a> start work on 2.0.6-SNAPSHOT</li>; <li>Additional commits viewable in <a href=""https://github.com/qos-ch/slf4j/compare/v_1.7.25...v_2.0.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.slf4j:slf4j-api&package-manager=gradle&previous-version=1.7.25&new-version=2.0.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12714:2084,secur,security-vulnerabilities,2084,https://hail.is,https://github.com/hail-is/hail/pull/12714,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"9d6805c47a175""><code>e89c8c8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/241"">#241</a> from samueljsb/remove-deprecated-private-function-ali...</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/ffe4bcfaa6cfbd95ba47315f8f71a206485af6ae""><code>ffe4bcf</code></a> Remove deprecated VERSION, use <strong>version</strong> instead</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/eb3e2534267714361da866109bd33ff20e63416c""><code>eb3e253</code></a> Merge branch 'master' into no-overflow-naturaldelta</li>; <li>Additional commits viewable in <a href=""https://github.com/jmoiron/humanize/compare/1.0.0...4.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=humanize&package-manager=pip&previous-version=1.0.0&new-version=4.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11517:6962,secur,security-vulnerabilities,6962,https://hail.is,https://github.com/hail-is/hail/pull/11517,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"9e6eee0e9edf010034b63b""><code>d725a9b</code></a> Add Python 3.10 to GitHub Actions</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/339ad34c677c98fd9ad008de1d8bbeb9dbf34381""><code>339ad34</code></a> Use pytest==6.2.4 on Python 3.10+</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/f271c9c3149e20d7feffb6429b135bbb6c09ddf4""><code>f271c9c</code></a> Apply latest Black formatting</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/1884878aac87ef0494b282e940c32c24ee917d52""><code>1884878</code></a> [1.26] Properly proxy EOF on the SSLTransport test suite</li>; <li>See full diff in <a href=""https://github.com/urllib3/urllib3/compare/1.26.4...1.26.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.4&new-version=1.26.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10544:3069,secur,security-vulnerabilities,3069,https://hail.is,https://github.com/hail-is/hail/pull/10544,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"9f69135f292903d046207773794""><code>b0942e1</code></a> Add initial 'Methods, helpers and QtPy namespace specifics' section to the RE...</li>; <li><a href=""https://github.com/spyder-ide/qtpy/commit/b3efba8b2f5ef670842c73dd171aaa98e298db37""><code>b3efba8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/354"">#354</a> from zjp/objectisalive</li>; <li><a href=""https://github.com/spyder-ide/qtpy/commit/60af2d85eb25590e2ae7c1382011fe7fac818279""><code>60af2d8</code></a> compat.py: Add wrapper around sip/shiboken isdeleted/isvalid</li>; <li>Additional commits viewable in <a href=""https://github.com/spyder-ide/qtpy/compare/v2.1.0...v2.2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=qtpy&package-manager=pip&previous-version=2.1.0&new-version=2.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12194:8745,secur,security-vulnerabilities,8745,https://hail.is,https://github.com/hail-is/hail/pull/12194,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,": None,; 'vep_runner': 'VEP'},; 'reference_ht_path': 'gs://seqr-reference-data/GRCh38/all_reference_data/combined_reference_data_grch38.ht',; 'remap_path': None,; 'sample_type': 'WGS',; 'scheduler_messages': None,; 'set_progress_percentage': <bound method TaskStatusReporter.update_progress_percentage of <luigi.worker.TaskStatusReporter object at 0x7f0583f0f588>>,; 'set_status_message': <bound method TaskStatusReporter.update_status_message of <luigi.worker.TaskStatusReporter object at 0x7f0583f0f588>>,; 'set_tracking_url': <bound method TaskStatusReporter.update_tracking_url of <luigi.worker.TaskStatusReporter object at 0x7f0583f0f588>>,; 'source_paths': ['gs://seqr-bw/merged_phased_3P5CH.split.vcf.gz'],; 'subset_path': None,; 'task_id': 'SeqrVCFToMTTask_gs___seqr_refere_VARIANTS_gs___seqr_bw_mer_b185718e87',; 'validate': False,; 'vep_config_json_path': None,; 'vep_runner': 'VEP'}; [Stage 1:======================================================>(492 + 8) / 500]2020-04-05 14:09:30 Hail: INFO: Coerced almost-sorted dataset; [Stage 2:====================================================> (485 + 15) / 500]2020-04-05 14:09:34 Hail: INFO: Coerced almost-sorted dataset; [Stage 3:==================================================> (467 + 33) / 500]MT using schema class <class 'lib.model.seqr_mt_schema.SeqrVariantsAndGenotypesSchema'> already has vep annotation.; MT using schema class <class 'lib.model.seqr_mt_schema.SeqrVariantsAndGenotypesSchema'> already has filters annotation.; MT using schema class <class 'lib.model.seqr_mt_schema.SeqrVariantsAndGenotypesSchema'> already has rsid annotation.; MT using schema class <class 'lib.model.seqr_mt_schema.SeqrVariantsAndGenotypesSchema'> already has vep annotation.; ----------------------------------------; Global fields:; 'gencodeVersion': str; 'sourceFilePath': str; 'genomeVersion': str; 'sampleType': str; 'hail_version': str; ----------------------------------------; Column fields:; 's': str; -----------------------------------",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:38783,validat,validate,38783,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['validat'],['validate']
Security,": RegionPool: initialized for thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=0, peakBytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.603 : ERROR: SocketException: Connection reset; From javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.go",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:23990,secur,security,23990,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,"://github-redirect.dependabot.com/axios/axios/pull/3707"">#3707</a>)</li>; <li>Updating documentation around dispatching requests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3772"">#3772</a>)</li>; <li>Adding documentation for the type guard isAxiosError (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3767"">#3767</a>)</li>; <li>Adding explanation of cancel token (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3803"">#3803</a>)</li>; <li>Updating CI status badge (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3953"">#3953</a>)</li>; <li>Fixing errors with JSON documentation (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3936"">#3936</a>)</li>; <li>Fixing README typo under Request Config (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3825"">#3825</a>)</li>; <li>Adding axios-multi-api to the ecosystem file (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3817"">#3817</a>)</li>; <li>Adding SECURITY.md to properly disclose security vulnerabilities (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3981"">#3981</a>)</li>; </ul>; <p>Huge thanks to everyone who contributed to this release via code (authors listed below) or via reviews and triaging on GitHub:</p>; <ul>; <li><a href=""https://github.com/SashaKoro"">Sasha Korotkov</a></li>; <li><a href=""https://github.com/timemachine3030"">Daniel Lopretto</a></li>; <li><a href=""https://github.com/MikeBishop"">Mike Bishop</a></li>; <li><a href=""https://github.com/DigitalBrainJS"">Dmitriy Mozgovoy</a></li>; <li><a href=""https://github.com/bimbiltu"">Mark</a></li>; <li><a href=""https://github.com/piiih"">Philipe Gouveia Paixão</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/axios/axios/blob/master/CHANGELOG.md"">axios's changelog</a>.</em></p>; <blockquote>; <h3>0.21.2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:4807,SECUR,SECURITY,4807,https://hail.is,https://github.com/hail-is/hail/pull/11080,2,['SECUR'],['SECURITY']
Security,"://github-redirect.dependabot.com/axios/axios/pull/3707"">#3707</a>)</li>; <li>Updating documentation around dispatching requests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3772"">#3772</a>)</li>; <li>Adding documentation for the type guard isAxiosError (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3767"">#3767</a>)</li>; <li>Adding explanation of cancel token (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3803"">#3803</a>)</li>; <li>Updating CI status badge (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3953"">#3953</a>)</li>; <li>Fixing errors with JSON documentation (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3936"">#3936</a>)</li>; <li>Fixing README typo under Request Config (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3825"">#3825</a>)</li>; <li>Adding axios-multi-api to the ecosystem file (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3817"">#3817</a>)</li>; <li>Adding SECURITY.md to properly disclose security vulnerabilities (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3981"">#3981</a>)</li>; </ul>; <p>Huge thanks to everyone who contributed to this release via code (authors listed below) or via reviews and triaging on GitHub:</p>; <ul>; <li><a href=""https://github.com/axios/axios/blob/master/mailto:jasonsaayman@gmail.com"">Jay</a></li>; <li><a href=""https://github.com/SashaKoro"">Sasha Korotkov</a></li>; <li><a href=""https://github.com/timemachine3030"">Daniel Lopretto</a></li>; <li><a href=""https://github.com/MikeBishop"">Mike Bishop</a></li>; <li><a href=""https://github.com/DigitalBrainJS"">Dmitriy Mozgovoy</a></li>; <li><a href=""https://github.com/bimbiltu"">Mark</a></li>; <li><a href=""https://github.com/piiih"">Philipe Gouveia Paixão</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/axios/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:10332,SECUR,SECURITY,10332,https://hail.is,https://github.com/hail-is/hail/pull/11080,2,['SECUR'],['SECURITY']
Security,"://github-redirect.dependabot.com/pytest-dev/pytest/issues/9668"">#9668</a> from hugovk/test-me-latest-3.10</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/0fae45bb6e4ecf177afdfa3bf03738813ec7b913""><code>0fae45b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9660"">#9660</a> from pytest-dev/backport-9646-to-7.0.x</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/37d434f5fcb5f80188b3d5b8f22d418dc191b955""><code>37d434f</code></a> [7.0.x] Delay warning about collector/item diamond inheritance</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest/compare/6.2.5...7.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest&package-manager=pip&previous-version=6.2.5&new-version=7.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11516:6799,secur,security-vulnerabilities,6799,https://hail.is,https://github.com/hail-is/hail/pull/11516,6,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"://github.com/tomplus/kubernetes_asyncio/commit/11c3eb4d50ae822545572aa7b8c15f7153f65a1c""><code>11c3eb4</code></a> [feat] regenerate library using API K8s v23.6.0 (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/211"">#211</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/35f109ce6e093285f232b4f45d68f44a964c6d11""><code>35f109c</code></a> chore(deps): bump actions/setup-python from 3 to 4 (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/208"">#208</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/tomplus/kubernetes_asyncio/compare/v19.15.1...24.2.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=kubernetes-asyncio&package-manager=pip&previous-version=19.15.1&new-version=24.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:16816,secur,security-vulnerabilities,16816,https://hail.is,https://github.com/hail-is/hail/pull/12196,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-NBCONVERT-2979829](https://snyk.io/vuln/SNYK-PYTHON-NBCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Open Redirect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Access Restriction Bypass <br/>[SNYK-PYTHON-NOTEBOOK-2928995](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2928995) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-1086606](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1086606) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-PYGMENTS-1088505](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1088505) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-5750273](https://snyk.io/vuln/SNYK-PYTHON-PYGM",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13835:3774,Access,Access,3774,https://hail.is,https://github.com/hail-is/hail/pull/13835,4,['Access'],['Access']
Security,"://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-NBCONVERT-2979829](https://snyk.io/vuln/SNYK-PYTHON-NBCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Open Redirect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Access Restriction Bypass <br/>[SNYK-PYTHON-NOTEBOOK-2928995](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2928995) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Race Condition <br/>[SNYK-PYTHON-PROMPTTOOLKIT-6141120](https://snyk.io/vuln/SNYK-PYTHON-PROMPTTOOLKIT-6141120) | `prompt-toolkit:` <br> `1.0.18 -> 3.0.13` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-1086606](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1086606) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-PYGMENTS-1088505](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1088505) | `py",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14257:4035,Access,Access,4035,https://hail.is,https://github.com/hail-is/hail/pull/14257,2,['Access'],['Access']
Security,; 2019-01-22 13:12:06 YarnSchedulerBackend$YarnDriverEndpoint: INFO: Asked to remove non-existent executor 12; 2019-01-22 13:12:06 YarnScheduler: INFO: Cancelling stage 0; 2019-01-22 13:12:06 DAGSchedulerEventProcessLoop: ERROR: DAGSchedulerEventProcessLoop failed; shutting down SparkContext; java.util.NoSuchElementException: key not found: 70; at scala.collection.MapLike$class.default(MapLike.scala:228); at scala.collection.AbstractMap.default(Map.scala:59); at scala.collection.mutable.HashMap.apply(HashMap.scala:65); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply$mcVJ$sp(TaskSchedulerImpl.scala:243); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:235); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:235); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:234); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.TaskSchedulerImpl.cancelTasks(TaskSchedulerImpl.scala:234); at org.apache.sp,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:199937,Hash,HashSet,199937,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['Hash'],['HashSet']
Security,"; <li><a href=""https://github.com/lepture/mistune/commit/babb0cfa57a983ead615286a2b7c8f6885c46721""><code>babb0cf</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/lepture/mistune/issues/295"">#295</a> from dairiki/bug.escape_url</li>; <li><a href=""https://github.com/lepture/mistune/commit/fc2cd53d7698e432ab5b250ffac53458263a49e2""><code>fc2cd53</code></a> Make mistune.util.escape_url less aggressive</li>; <li><a href=""https://github.com/lepture/mistune/commit/3e8d35215120ac82176f300dd5e20c0bea5464ea""><code>3e8d352</code></a> Version bump 2.0.1</li>; <li>Additional commits viewable in <a href=""https://github.com/lepture/mistune/compare/v0.8.4...v2.0.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mistune&package-manager=pip&previous-version=0.8.4&new-version=2.0.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12064:4147,secur,security-vulnerabilities,4147,https://hail.is,https://github.com/hail-is/hail/pull/12064,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"; <li><a href=""https://github.com/samtools/htsjdk/commit/500cffda9c511d88a736bcbb91d3f10259b967fb""><code>500cffd</code></a> Test fix</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/662c8274fad42e001e63e2b9c9c2066714b42a0d""><code>662c827</code></a> Test fix</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/e58f8a2250fc47afecfa38611b0f51b02ac6b933""><code>e58f8a2</code></a> Minor code cleanup</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/b1085dab46bc220b1f6d3eb92fcbe73818ade3eb""><code>b1085da</code></a> Test fixes</li>; <li>Additional commits viewable in <a href=""https://github.com/samtools/htsjdk/compare/3.0.4...4.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.samtools:htsjdk&package-manager=gradle&previous-version=3.0.4&new-version=4.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13576:8450,secur,security-vulnerabilities,8450,https://hail.is,https://github.com/hail-is/hail/pull/13576,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"; <li>Address remaining <code>ResourceWarning</code> related to the socket used by <code>run_simple</code>.; Remove <code>prepare_socket</code>, which now happens when creating the server. :issue:<code>2421</code></li>; <li>Update pre-existing headers for <code>multipart/form-data</code> requests with the test; client. :issue:<code>2549</code></li>; <li>Fix handling of header extended parameters such that they are no longer quoted.; :issue:<code>2529</code></li>; <li><code>LimitedStream.read</code> works correctly when wrapping a stream that may not return; the requested size in one <code>read</code> call. :issue:<code>2558</code></li>; <li>A cookie header that starts with <code>=</code> is treated as an empty key and discarded,; rather than stripping the leading <code>==</code>.</li>; <li>Specify a maximum number of multipart parts, default 1000, after which a; <code>RequestEntityTooLarge</code> exception is raised on parsing. This mitigates a DoS; attack where a larger number of form/file parts would result in disproportionate; resource use.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/werkzeug/commit/22a254fca2ad0130adbbcbd11d3de51bcb04a08b""><code>22a254f</code></a> release version 2.2.3</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/517cac5a804e8c4dc4ed038bb20dacd038e7a9f1""><code>517cac5</code></a> Merge pull request from GHSA-xg9f-g7g7-2323</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/babc8d9e8c9fa995ef26050698bc9b5a92803664""><code>babc8d9</code></a> rewrite docs about request data limits</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/09449ee77934a0c883f5959785864ecae6aaa2c9""><code>09449ee</code></a> clean up docs</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/fe899d0cdf767a7289a8bf746b7f72c2907a1b4b""><code>fe899d0</code></a> limit the maximum number of multipart form parts</li>; <li><a href=""https://github.com/pallets/we",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12703:2822,attack,attack,2822,https://hail.is,https://github.com/hail-is/hail/pull/12703,1,['attack'],['attack']
Security,"; <li>Deprecated the <code>urllib3[secure]</code> extra and the <code>urllib3.contrib.pyopenssl</code> module.; Both will be removed in v2.x. See this <code>GitHub issue &lt;https://github.com/urllib3/urllib3/issues/2680&gt;</code>_; for justification and info on how to migrate.</li>; </ul>; <h1>1.26.11 (2022-07-25)</h1>; <ul>; <li>Fixed an issue where reading more than 2 GiB in a call to <code>HTTPResponse.read</code> would; raise an <code>OverflowError</code> on Python 3.9 and earlier.</li>; </ul>; <h1>1.26.10 (2022-07-07)</h1>; <ul>; <li>Removed support for Python 3.5</li>; <li>Fixed an issue where a <code>ProxyError</code> recommending configuring the proxy as HTTP; instead of HTTPS could appear even when an HTTPS proxy wasn't configured.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/urllib3/urllib3/commit/a5b29ac1025f9bb30f2c9b756f3b171389c2c039""><code>a5b29ac</code></a> Add outputs.hashes to build action</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/a0b22f820639e6212994ba147f76b60d88185792""><code>a0b22f8</code></a> Release 1.26.12</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/13f11172648e880bb4a385fc4425420cd2534516""><code>13f1117</code></a> [1.26] Add SLSA generic generator to publish workflow</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/f95b9640604e7dd70d50d81f68fd14a36c082841""><code>f95b964</code></a> Add deprecation warnings for pyOpenSSL and the [secure] extra</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/aa3def7d242525e6e854991247c4b68583d15135""><code>aa3def7</code></a> Release 1.26.11</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/6f93b8f450b18b4c9f4c6333d759a911a63d15ae""><code>6f93b8f</code></a> Fix <code>OverflowError</code> when TLS is used on some Python versions</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/0a5f34d2c2ee6457e8365543243eccd3d1dc9430""><code>0a5f34d</code></a> Set GHA token perm",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12140:3105,hash,hashes,3105,https://hail.is,https://github.com/hail-is/hail/pull/12140,1,['hash'],['hashes']
Security,"; File ""<decorator-gen-502>"", line 2, in import_vcf; File ""/tmp/7417fcfbbeee44d0b3f4c0b3750121a7/hail-0.1-es-6.2.4-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, without-vep-520334-sw-rmwj.c.seqr-project.internal): java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; 	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); 	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); 	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); 	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:245); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:5728,Checksum,ChecksumFileSystem,5728,https://hail.is,https://github.com/hail-is/hail/issues/3760,2,['Checksum'],"['ChecksumFSInputChecker', 'ChecksumFileSystem']"
Security,"; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **554/1000** <br/> **Why?** Has a fix available, CVSS 6.8 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **454/1000** <br/> **Why?** Has a fix available, CVSS 4.8 | Expected Behavior Violation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3314966](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3314966) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:1539,Certificate,Certificate,1539,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['Certificate'],['Certificate']
Security,"; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **554/1000** <br/> **Why?** Has a fix available, CVSS 6.8 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **454/1000** <br/> **Why?** Has a fix available, CVSS 4.8 | Expected Behavior Violation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3314966](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3314966) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:1531,Certificate,Certificate,1531,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['Certificate'],['Certificate']
Security,; at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.HadoopConfigurationProperty.getPropsWithPrefix(HadoopConfigurationProperty.java:106); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemConfiguration.getGcsOptionsBuilder(GoogleHadoopFileSystemConfiguration.java:421); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemConfiguration.getGcsFsOptionsBuilder(GoogleHadoopFileSystemConfiguration.java:383); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1516); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1486); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:541); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:494); at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2669); at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94); at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703); at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685); at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373); at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295); at is.hail.io.fs.HadoopFS.is$hail$io$fs$HadoopFS$$_fileSystem(HadoopFS.scala:157); at is.hail.io.fs.HadoopFS.glob(HadoopFS.scala:244); at is.hail.io.fs.HadoopFS$$anonfun$globAll$1.apply(HadoopFS.scala:226); at is.hail.io.fs.HadoopFS$$anonfun$globAll$1.apply(HadoopFS.scala:225); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collect,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8343:3811,access,access,3811,https://hail.is,https://github.com/hail-is/hail/issues/8343,1,['access'],['access']
Security,"; at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:170); at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:45); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:108); at scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:108); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:108); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at org.apache.spark.SparkStatusTracker.getActiveStageIds(SparkStatusTracker.scala:61); at org.apache.spark.ui.ConsoleProgressBar.org$apache$spark$ui$ConsoleProgressBar$$refresh(ConsoleProgressBar.scala:67); at org.apache.spark.ui.ConsoleProgressBar$$anon$1.run(ConsoleProgressBar.scala:55); at java.util.TimerThread.mainLoop(Timer.java:555); at java.util.TimerThread.run(Timer.java:505); ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); /restricted/projectnb/ukbiobank/ad/analysis/ad.v1/bgen2mt.py in <module>; 6 sample=""/project/ukbiobank/imp/uk.v3/bgen/ukb19416_imp_chr""+chr+""_v3_s487327.sample""; 7 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:4072,Hash,HashTable,4072,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Hash'],['HashTable']
Security,"; }; ```; * Scripts are thing that can be run by typing, in shell `npm run`. Ex: `npm run dev`. ### Async, Await, Promises and callback (WIP); Javascript is async-first. This is most obvious in Node.js, which is the most popular library for server-side JS.; * [How event loop works](https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick/); <img width=""765"" alt=""screen shot 2019-01-18 at 11 20 51 am"" src=""https://user-images.githubusercontent.com/5543229/51399094-1f999c00-1b13-11e9-8dfb-da8aa20807b0.png"">. * The event loop call stack: https://www.youtube.com/watch?v=8aGhZQkoFbQ. At a high level, a function that defines a callback will return immediately. The callback is pushed on to the event-loop stack, and on each tick, is checked to determine whether it has returned or not. Blocking operations within the callbacks will block the event loop. This is how CPU viruses, like blockchain manage to slow down web pages that are hijacked to include some mining script: hashing something 30 million times, takes a long time, and JS cannot do anything besides waiting for those operations to finish in a synchronous fashion. Luckily, asynchronous functions are the norm in the JS ecosystem, such that both in the browser, and nodejs, IO functions are (mostly?) asynchronous.; * For NodeJS: Transparently to the user, blocking operations (IO) are executed from kernel threads that Node maintains in the background, effectively making these operations non-blocking (until the thread pool is exhausted). Browsers and NodeJS use different event loops:. NodeJS: libuv event loop; * Node maintains a hidden worker thread pool (kernel threads) through which it issues sys calls, to avoid blocking the event loop. Web: depends on the underlying Javascript Engine; * Chromium: V8: libevent: https://stackoverflow.com/questions/25750884/are-there-significant-differences-between-the-chrome-browser-event-loop-versus-t; * Firefox: Spidermonkey: ?; * https://developer.mozilla.org/en-US/docs/Web/Jav",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:3878,hash,hashing,3878,https://hail.is,https://github.com/hail-is/hail/pull/5162,1,['hash'],['hashing']
Security,"</a> release 8.12.0</li>; <li><a href=""https://github.com/ipython/ipython/commit/2bb46729ded8e58153f10629c3b6fa0d42acb751""><code>2bb4672</code></a> Update whats new for 3.12 (<a href=""https://redirect.github.com/ipython/ipython/issues/14000"">#14000</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/4f0b2357354aa35042244f902f9bcea9da65dfd9""><code>4f0b235</code></a> upate whats new for 3.12</li>; <li><a href=""https://github.com/ipython/ipython/commit/d52bf622ce9922106f8bcc1867c0a27a884201a0""><code>d52bf62</code></a> Allow to dispatch getting documentation on objects. (<a href=""https://redirect.github.com/ipython/ipython/issues/13975"">#13975</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/3a9419dce7d6ccf7de39be606eec2fc212ef4445""><code>3a9419d</code></a> Update completer documentation (<a href=""https://redirect.github.com/ipython/ipython/issues/13999"">#13999</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/a7d8defdecca3cfa54eada171181e0880c8b6b5f""><code>a7d8def</code></a> Expose <code>auto_suggest.resume_hinting</code>, fix resume on backspace (<a href=""https://redirect.github.com/ipython/ipython/issues/13994"">#13994</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/4e7b9408a0b35cabbdc973f131257f4e97a3ddcf""><code>4e7b940</code></a> Fix autosuggestions in multi-line mode, vi command mode delay (<a href=""https://redirect.github.com/ipython/ipython/issues/13991"">#13991</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/ad452c1d8bb25e742caa152fb301e0e6626b6faa""><code>ad452c1</code></a> Improve API documentation around configuration of embedded IPython (<a href=""https://redirect.github.com/ipython/ipython/issues/13989"">#13989</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/92027083ab69186db3f104fe38651086bcf4e760""><code>9202708</code></a> Handle OSError cases where traceback frames occur from built files (<a href=""https://redirect.github.com/ipython/ipython/issues/13964"">#1396",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12832:1272,Expose,Expose,1272,https://hail.is,https://github.com/hail-is/hail/pull/12832,2,['Expose'],['Expose']
Security,"</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=certifi&package-manager=pip&previous-version=2022.9.24&new-version=2022.12.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12549:2275,secur,security,2275,https://hail.is,https://github.com/hail-is/hail/pull/12549,6,"['Secur', 'secur']","['Security', 'security']"
Security,"</code> &amp; <code>Library</code> - <a href=""https://github.com/soywiz""><code>@​soywiz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1491"">#1491</a>: Update libffi to v3.4.4 - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1487"">#1487</a>: Add 'uses' information to OSGI metadata in MANIFEST.MF to improve stability of package resolution - <a href=""https://github.com/sratz""><code>@​sratz</code></a>.</li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1452"">#1452</a>: Fix memory allocation/handling for error message generation in native library code (<code>dispatch.c</code>) - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1460"">#1460</a>: Fix win32 variant date conversion in DST offest window and with millisecond values - <a href=""https://github.com/eranl""><code>@​eranl</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1472"">#1472</a>: Fix incorrect bitmask in <code>c.s.j.Pointer#createConstant(int)</code> - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1481"">#1481</a>: Fix NPE in NativeLibrary when unpacking from classpath is disabled - <a href=""https://github.com/trespasserw""><code>@​trespasserw</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1489"">#1489</a>: Fixes typo in <code>OpenGL32Util#wglGetProcAddress</code>, instead of parameter <code>procName</code> the hardcoded value <code>wglEnumGpusNV</code> was used - <a href=""https://github.com/soywiz""><code>@​soywiz</code></a>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:2777,access,access,2777,https://hail.is,https://github.com/hail-is/hail/pull/12886,1,['access'],['access']
Security,"</code></a> [Storage] Fix bug with <code>ignore_read_only</code> in <code>start_copy_from_url()</code> (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23141"">#23141</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/5166ee94acdb80f2217a1ce694e169ea2b33219d""><code>5166ee9</code></a> [Storage] Fix <code>upload_blob()</code> from an OS pipe on Linux (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23211"">#23211</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.8.1...azure-storage-blob_12.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-storage-blob&package-manager=pip&previous-version=12.8.1&new-version=12.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11703:6550,secur,security-vulnerabilities,6550,https://hail.is,https://github.com/hail-is/hail/pull/11703,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/45e66e89373ef016eff9b7deb30dbdfa818770d2""><code>45e66e8</code></a> deps: update actions/checkout action to v4 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2190"">#2190</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/5c048c499eef224dade8f4409dfae732cb5a7017""><code>5c048c4</code></a> deps: update actions/checkout action to v4 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2189"">#2189</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/java-storage/compare/v2.17.1...v2.27.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.cloud:google-cloud-storage&package-manager=gradle&previous-version=2.17.1&new-version=2.27.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13624:15492,secur,security-vulnerabilities,15492,https://hail.is,https://github.com/hail-is/hail/pull/13624,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"<a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/pull/983"">python-jsonschema/jsonschema#983</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.10.3...v4.11.0"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.3...v4.11.0</a></p>; <h2>v4.10.3</h2>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.10.2...v4.10.3"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.2...v4.10.3</a></p>; <h2>v4.10.2</h2>; <ul>; <li>Fix a second place where subclasses may have added attrs attributes (<a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/issues/982"">#982</a>).</li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.10.1...v4.10.2"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.1...v4.10.2</a></p>; <h2>v4.10.1</h2>; <ul>; <li>Fix Validator.evolve (and APIs like <code>iter_errors</code> which call it) for cases; where the validator class has been subclassed. Doing so wasn't intended to be; public API, but given it didn't warn or raise an error it's of course; understandable. The next release however will make it warn (and a future one; will make it error). If you need help migrating usage of inheriting from a; validator class feel free to open a discussion and I'll try to give some; guidance (<a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/issues/982"">#982</a>).</li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.10.0...v4.10.1"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.0...v4.10.1</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/python-jsonschema/jsonschema/blob/main/C",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12163:3088,Validat,Validator,3088,https://hail.is,https://github.com/hail-is/hail/pull/12163,1,['Validat'],['Validator']
Security,"<a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6f77b1e70be086aae752dcf7e08d7f06bcabdcd7""><code>6f77b1e</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/109"">#109</a> from AzureAD/release-1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/50bf9674f9c65229a1573be39ef4ef507eee17fa""><code>50bf967</code></a> MSAL EX for Python 1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6b904af1a3d4fc0e28e3f090fa3dd8492f79e6bf""><code>6b904af</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/110"">#110</a> from AzureAD/persistence-factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/d0696aeb6f65168b1e0d405cd871b80bb101cd76""><code>d0696ae</code></a> Add build_encrypted_persistence() factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/289a94f694645c642ae67b2d5972d3f9fdadb928""><code>289a94f</code></a> Remove old classes that are deprecated for 2 years</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/fa1f45b556341b2c34e9bf63c06a5068571cd337""><code>fa1f45b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/108"">#108</a> from AzureAD/actionable-encryption-exceptions</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/effe77842d25a8b093d18d9e33347f13e2ee094f""><code>effe778</code></a> Provide actionable messages for 2 dpapi errors</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/b674b6a07ca27b2c1b6f371040f035a546cfd468"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:3131,authenticat,authentication-extensions-for-python,3131,https://hail.is,https://github.com/hail-is/hail/pull/11992,1,['authenticat'],['authentication-extensions-for-python']
Security,"<a href=""https://github.com/java-native-access/jna/commit/f58b0f8f6b5c013adfe44a2cfb018ccb6ef6a688""><code>f58b0f8</code></a> Improve test stability on AIX (exclude tests that are expected to fail)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/c1565fb89469cbcba67b1cc305e16d520779b270""><code>c1565fb</code></a> Handle race condition in PdhUtil#PdhEnumObjectItems (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/99fcfa822db86b1f2ba5823dbf17efeb3d246ad5""><code>99fcfa8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1444"">#1444</a> from matthiasblaesing/update_libffi</li>; <li><a href=""https://github.com/java-native-access/jna/commit/9e473350a5ad5e04aab8b01e4018f973976e19f8""><code>9e47335</code></a> Update CHANGES.md</li>; <li>Additional commits viewable in <a href=""https://github.com/java-native-access/jna/compare/5.6.0...5.12.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=net.java.dev.jna:jna&package-manager=gradle&previous-version=5.6.0&new-version=5.12.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:7786,access,access,7786,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,"<code>fc3b525</code></a> Fix typos in docs</li>; <li><a href=""https://github.com/ipython/ipython/commit/75ecfe932fc9ca3505efbebc016b046ffc7d0d68""><code>75ecfe9</code></a> capture_output does not respect trailing semicolon (<a href=""https://redirect.github.com/ipython/ipython/issues/13940"">#13940</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/3edbe3bd10c434af6458bdbe02269880b10b9adf""><code>3edbe3b</code></a> Resurrect fast (non-highlighted) traceback code for long files. (<a href=""https://redirect.github.com/ipython/ipython/issues/13947"">#13947</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12807:2394,secur,security-vulnerabilities,2394,https://hail.is,https://github.com/hail-is/hail/pull/12807,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"<li><a href=""https://github.com/googleapis/python-api-core/commit/d84d66c2a4107f5f9a20c53e870a27fb1250ea3d""><code>d84d66c</code></a> fix(deps): require protobuf&gt;= 3.15.0, &lt;4.0.0dev (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/385"">#385</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-core/commit/eed844f211ad8c6ab2c4cb0d6f089e1f11999f71""><code>eed844f</code></a> chore(main): release 2.8.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/381"">#381</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-api-core/compare/v1.31.6...v2.8.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-api-core[grpc]&package-manager=pip&previous-version=1.31.6&new-version=2.8.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11970:11220,secur,security-vulnerabilities,11220,https://hail.is,https://github.com/hail-is/hail/pull/11970,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"<li><a href=""https://github.com/googleapis/python-logging/commit/e1506fa9030776353878048ce562c53bf6ccf7bf""><code>e1506fa</code></a> fix!: api consistency between HTTP and Gapic layers (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/375"">#375</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/6fa17735fe3edb45483ec5e3abd1f53c24ffa881""><code>6fa1773</code></a> feat!: support string-encoded json (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/339"">#339</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-logging/compare/v1.12.1...v3.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-cloud-logging&package-manager=pip&previous-version=1.12.1&new-version=3.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11574:14320,secur,security-vulnerabilities,14320,https://hail.is,https://github.com/hail-is/hail/pull/11574,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"<li><a href=""https://github.com/psf/requests/commit/87d63de8739263bbe17034fba2285c79780da7e8""><code>87d63de</code></a> v2.29.0</li>; <li><a href=""https://github.com/psf/requests/commit/51716c4ef390136b0d4b800ec7665dd5503e64fc""><code>51716c4</code></a> enable the warnings plugin (<a href=""https://redirect.github.com/psf/requests/issues/6416"">#6416</a>)</li>; <li><a href=""https://github.com/psf/requests/commit/a7da1ab3498b10ec3a3582244c94b2845f8a8e71""><code>a7da1ab</code></a> try on ubuntu 22.04 (<a href=""https://redirect.github.com/psf/requests/issues/6418"">#6418</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/psf/requests/compare/v2.28.2...v2.31.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=requests&package-manager=pip&previous-version=2.28.2&new-version=2.31.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13091:7546,secur,security-vulnerabilities,7546,https://hail.is,https://github.com/hail-is/hail/pull/13091,12,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"<li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/f9219b21ef8807150dbbcbaf45d6118387ff9a32""><code>f9219b2</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/222"">#222</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/a9b90238f74f1c5f69d7dcafb83c9775504f9b3b""><code>a9b9023</code></a> Fix typos (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/224"">#224</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/compare/1.11.1...1.18.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx-autodoc-typehints&package-manager=pip&previous-version=1.11.1&new-version=1.18.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11909:7564,secur,security-vulnerabilities,7564,https://hail.is,https://github.com/hail-is/hail/pull/11909,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"<li>When starting the development server, a warning not to use it in a; production deployment is always shown. :issue:<code>2480</code></li>; <li><code>LocalProxy.__wrapped__</code> is always set to the wrapped object when; the proxy is unbound, fixing an issue in doctest that would cause it; to fail. :issue:<code>2485</code></li>; <li>Address one <code>ResourceWarning</code> related to the socket used by; <code>run_simple</code>. :issue:<code>2421</code></li>; </ul>; <h2>Version 2.2.1</h2>; <p>Released 2022-07-27</p>; <ul>; <li>Fix router so that <code>/path/</code> will match a rule <code>/path</code> if strict; slashes mode is disabled for the rule. :issue:<code>2467</code></li>; <li>Fix router so that partial part matches are not allowed; i.e. <code>/2df</code> does not match <code>/&lt;int&gt;</code>. :pr:<code>2470</code></li>; <li>Fix router static part weighting, so that simpler routes are matched; before more complex ones. :issue:<code>2471</code></li>; <li>Restore <code>ValidationError</code> to be importable from; <code>werkzeug.routing</code>. :issue:<code>2465</code></li>; </ul>; <h2>Version 2.2.0</h2>; <p>Released 2022-07-23</p>; <ul>; <li>Deprecated <code>get_script_name</code>, <code>get_query_string</code>,; <code>peek_path_info</code>, <code>pop_path_info</code>, and; <code>extract_path_info</code>. :pr:<code>2461</code></li>; <li>Remove previously deprecated code. :pr:<code>2461</code></li>; <li>Add MarkupSafe as a dependency and use it to escape values when; rendering HTML. :issue:<code>2419</code></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/werkzeug/commit/15fcb87d36f4ed45b127692d2d739266b918503c""><code>15fcb87</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/werkzeug/issues/2499"">#2499</a> from pallets/release-2.2.2</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/87",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12119:3833,Validat,ValidationError,3833,https://hail.is,https://github.com/hail-is/hail/pull/12119,1,['Validat'],['ValidationError']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - auth/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjMDQ5NzlhMC1iYWM3LTRiMjEtYmE0ZS02OWU5YjAzMTE5ZjAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImMwNDk3OWEwLWJhYzctNGIyMS1iYTRlLTY5ZTliMDMxMTlmMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13309:893,Certificate,Certificate,893,https://hail.is,https://github.com/hail-is/hail/pull/13309,1,['Certificate'],['Certificate']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - ci/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3Mzc3ZjFlZS1kMjJjLTQ0MDAtYmE1Yy04NGNkYWZmZWJmYzgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjczNzdmMWVlLWQyMmMtNDQwMC1iYTVjLTg0Y2RhZmZlYmZjOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest proj",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13305:891,Certificate,Certificate,891,https://hail.is,https://github.com/hail-is/hail/pull/13305,1,['Certificate'],['Certificate']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - gear/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmYWJiOGYzZi1mMDFjLTQxMjktODJjNC1kZjQzMjRmZTU4YTIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZhYmI4ZjNmLWYwMWMtNDEyOS04MmM0LWRmNDMyNGZlNThhMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13296:893,Certificate,Certificate,893,https://hail.is,https://github.com/hail-is/hail/pull/13296,1,['Certificate'],['Certificate']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMjNiYjk0OC04YjdmLTQ5MzUtYTRkMi05ZWJmNjg4NjZlMmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImUyM2JiOTQ4LThiN2YtNDkzNS1hNGQyLTllYmY2ODg2NmUyZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [Vie",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13316:904,Certificate,Certificate,904,https://hail.is,https://github.com/hail-is/hail/pull/13316,1,['Certificate'],['Certificate']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/pinned-requirements.txt. <details>; <summary>⚠️ <b>Warning</b></summary>. ```; jupyter 1.0.0 requires notebook, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit . Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ens",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13517:887,Access,Access,887,https://hail.is,https://github.com/hail-is/hail/pull/13517,1,['Access'],['Access']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1NDMwZTFmMi0wNDZjLTQwNDctYmI3Mi1hZmJkZmM1MDViNGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjU0MzBlMWYyLTA0NmMtNDA0Ny1iYjcyLWFmYmRmYzUwNWI0YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13304:908,Certificate,Certificate,908,https://hail.is,https://github.com/hail-is/hail/pull/13304,1,['Certificate'],['Certificate']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14045:924,Validat,Validation,924,https://hail.is,https://github.com/hail-is/hail/pull/14045,1,['Validat'],['Validation']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **763/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 7.4 | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `41.0.1 -> 41.0.2` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIwMjJhZDMzNS1kYzBkLTQxZWYtYmRjYi03ZTFkODQwNWJhYTYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjAyMmFkMzM1LWRjMGQtNDFlZi1iZGNiLTdlMWQ4NDA1YmFhNiJ9fQ=="" width=""0"" height=""0""/>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13247:913,Certificate,Certificate,913,https://hail.is,https://github.com/hail-is/hail/pull/13247,2,"['Certificate', 'Validat']","['Certificate', 'Validation']"
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkY2E2ZDI1ZC1hZGM3LTRiNTctYWU3Zi0yNjExOTYzNTY5MmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImRjYTZkMjVkLWFkYzctNGI1Ny1hZTdmLTI2MTE5NjM1NjkyZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View la",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13294:900,Certificate,Certificate,900,https://hail.is,https://github.com/hail-is/hail/pull/13294,1,['Certificate'],['Certificate']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - web_common/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14036:922,Validat,Validation,922,https://hail.is,https://github.com/hail-is/hail/pull/14036,1,['Validat'],['Validation']
Security,"<strong>getitem</strong></li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/6ee5d57fc8d691fbab4972b853a60348d0f922ef""><code>6ee5d57</code></a> improve SortedList.<strong>getitem</strong>() performance for small slices</li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/ac80254fb6a08045ced7d9704412878ff8000fa7""><code>ac80254</code></a> suppress warning in test of deprecated function (<a href=""https://github-redirect.dependabot.com/grantjenks/python-sortedcontainers/issues/118"">#118</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/grantjenks/python-sortedcontainers/compare/v2.1.0...v2.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sortedcontainers&package-manager=pip&previous-version=2.1.0&new-version=2.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11476:4012,secur,security-vulnerabilities,4012,https://hail.is,https://github.com/hail-is/hail/pull/11476,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"<ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1438"">#1438</a>: Handle arrays in structures with differing size - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>: Handle race condition in <code>c.s.j.p.win32.PdhUtil#PdhEnumObjectItems</code> - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; </ul>; <h2>Important Changes</h2>; <ul>; <li><code>Memory#dispose</code>, <code>CallbackReference#dispose</code> and <code>NativeLibrary#dispose</code>; were called by the <code>Object#finalize</code> override. These calls were replaced by; the use of a cleaner. It is not guaranteed anymore, that <code>dispose</code> is called; on subclasses on finalization.</li>; </ul>; <h1>Release 5.11.0</h1>; <h2>Features</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1398"">#1398</a>: Increase <code>c.s.j.p.win32.Sspi#MAX_TOKEN_SIZE</code> on Windows 8/Server 2012 and later - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1403"">#1403</a>: Rebuild AIX binaries with libffi 3.4.2 (other architectures were part of 5.10) - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1404"">#1404</a>: Added Solaris Kstat2 library - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1416"">#1416</a>: Add <code>CFDictionaryGetCount</code> to <code>c.s.j.p.mac.CoreFoundation</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1418"">#1418</a>:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:2759,access,access,2759,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,"=""https://github-redirect.dependabot.com/docker/docker-py/pull/3056"">docker/docker-py#3056</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/docker/docker-py/compare/6.0.0...6.0.1"">https://github.com/docker/docker-py/compare/6.0.0...6.0.1</a></p>; <h2>6.0.0</h2>; <h3>ℹ️ Upgrade Notes</h3>; <ul>; <li>Minimum supported Python version is 3.7+</li>; <li>When installing with pip, the <code>docker[tls]</code> extra is deprecated and a no-op,; use <code>docker</code> for same functionality (TLS support is always available now)</li>; <li>Native Python SSH client (used by default / <code>use_ssh_client=False</code>) will now; reject unknown host keys with <code>paramiko.ssh_exception.SSHException</code></li>; <li>Short IDs are now 12 characters instead of 10 characters (same as Docker CLI)</li>; <li>Version metadata is now exposed as <code>__version__</code></li>; </ul>; <h3>✨ Features</h3>; <ul>; <li>Python 3.10 support</li>; <li>Automatically negotiate most secure TLS version</li>; <li>Add <code>platform</code> (e.g. <code>linux/amd64</code>, <code>darwin/arm64</code>) to container create &amp; run</li>; <li>Add support for <code>GlobalJob</code> and <code>ReplicatedJobs</code> for Swarm</li>; <li>Add <code>remove()</code> method on <code>Image</code></li>; <li>Add <code>force</code> param to <code>disable()</code> on <code>Plugin</code></li>; </ul>; <h3>🐛 Bugfixes</h3>; <ul>; <li>Fix install issues on Windows related to <code>pywin32</code></li>; <li>Do not accept unknown SSH host keys in native Python SSH mode</li>; <li>Use 12 character short IDs for consistency with Docker CLI</li>; <li>Ignore trailing whitespace in <code>.dockerignore</code> files</li>; <li>Fix IPv6 host parsing when explicit port specified</li>; <li>Fix <code>ProxyCommand</code> option for SSH connections</li>; <li>Do not spawn extra subshell when launching external SSH client</li>; <li>Improve exception semantics to preserve context</li>; <li>Documentation improvements ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12475:3174,secur,secure,3174,https://hail.is,https://github.com/hail-is/hail/pull/12475,1,['secur'],['secure']
Security,"=""https://github.com/Azure/azure-sdk-for-python/commit/9791fb5bc4cb6001768e6e1fb986b8d8f8326c43""><code>9791fb5</code></a> [core] add error body to HttpResponseError str (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22302"">#22302</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/772054c9cf24e860cf08563ac33caab50e904dd5""><code>772054c</code></a> drop py27 support (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22531"">#22531</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-identity_1.6.0...azure-identity_1.8.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-identity&package-manager=pip&previous-version=1.6.0&new-version=1.8.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11493:5138,secur,security-vulnerabilities,5138,https://hail.is,https://github.com/hail-is/hail/pull/11493,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"=""https://github.com/googleapis/google-auth-library-python/commit/5a09454703bd004d23355a6f660ec8579597d981""><code>5a09454</code></a> chore(main): release 2.4.1 (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/955"">#955</a>)</li>; <li><a href=""https://github.com/googleapis/google-auth-library-python/commit/c8b5cae3da5eb9d40067d38dac51a4a8c1e0763e""><code>c8b5cae</code></a> fix: urllib3 import (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/953"">#953</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/google-auth-library-python/compare/v1.27.0...v2.6.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-auth&package-manager=pip&previous-version=1.27.0&new-version=2.6.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11546:12695,secur,security-vulnerabilities,12695,https://hail.is,https://github.com/hail-is/hail/pull/11546,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"> > > Can you clarify the reasoning for replicating this in a sub-folder? It's much harder to review this change when there's a huge diff and I'm supposed to ignore certain things but those things actually subtly differ from the originals (see the Dockerfile).; > > > If there's some issue on Feb 1 and we're not confident for Feb 2, we'll just use git to revert to an old version.; > > ; > > ; > > Sure, clean separation between the two projects. It's 512 lines now, 434 from notebook.py; > ; > There aren't two projects though. We're updating notebook to use the new authentication system. A diff helps leverage my understanding of the previous notebook to understanding the proposed new notebook. They are different enough at this point that tying one to the other doesn't make much sense to me. But the bigger reason is that if needed, it will be easier to restore notebook from a pristine file, then look back through git commit history to the first breaking change. The goal should always be to introduce as few breaking changes as possible before a public demonstration. Once that is done, I don't mind doing something else. I've had the unfortunate pleasure of doing this with large-ish user-facing deployments (thousands of users), and it's not a fun experience. Git works well, but under the pressure of public-facing issues, entropy is not a friend.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215#issuecomment-460065939:569,authenticat,authentication,569,https://hail.is,https://github.com/hail-is/hail/pull/5215#issuecomment-460065939,1,['authenticat'],['authentication']
Security,"> > Can you clarify the reasoning for replicating this in a sub-folder? It's much harder to review this change when there's a huge diff and I'm supposed to ignore certain things but those things actually subtly differ from the originals (see the Dockerfile).; > > If there's some issue on Feb 1 and we're not confident for Feb 2, we'll just use git to revert to an old version.; > ; > Sure, clean separation between the two projects. It's 512 lines now, 434 from notebook.py. There aren't two projects though. We're updating notebook to use the new authentication system. A diff helps leverage my understanding of the previous notebook to understanding the proposed new notebook.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215#issuecomment-459893109:549,authenticat,authentication,549,https://hail.is,https://github.com/hail-is/hail/pull/5215#issuecomment-459893109,1,['authenticat'],['authentication']
Security,"> Add more basic CLI tests</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/08bdb0ce9e044e008eb487f32162865740c25232""><code>08bdb0c</code></a> Switch to official GitHub Actions coveralls integration</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/3a92cc4b4e6f5951bea72234f57b32bef133ab75""><code>3a92cc4</code></a> Tentatively declare support for Python 3.10</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/145983f7a3764743a653ef61595dd3ea33f24620""><code>145983f</code></a> Declare support for Python 3.9</li>; <li>Additional commits viewable in <a href=""https://github.com/thibaudcolas/curlylint/compare/v0.12.0...v0.13.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=curlylint&package-manager=pip&previous-version=0.12.0&new-version=0.13.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11494:7450,secur,security-vulnerabilities,7450,https://hail.is,https://github.com/hail-is/hail/pull/11494,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"> Almost by definition I'd suspect that adding a system administrator is a high security impact (that's not a judgement on you, just a statement about the security boundary getting wider).; > ; > This is obviously fine in this case because we want you to be a system administrator, but we should let appsec know regardless. They'll also probably want to send you some standard trainings (and maybe background check forms?). I'll ping them. Ah right that's an extremely fair point. Should I put ""high"" back in this PR description, or just sit tight until I hear from appsec?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14717#issuecomment-2400720230:80,secur,security,80,https://hail.is,https://github.com/hail-is/hail/pull/14717#issuecomment-2400720230,2,['secur'],['security']
Security,"> Am I strange in that I want to name something what it is (ci, batch, etc.); > rather than give everything codenames? The purpose of codenames is to hide and; > obscure, you know. Good point. > I think this should be called tutorial. And when it becomes a notebook; > service, notebook. And when it becomes the Hail service, it should just be the; > main website. I almost called it notebook-service but all our other names were single; words. I'll call it notebook so we can avoid a rename. > The landing page should be password protected. We should think about whether; > we want to collect additional information there (e.g. email), although for now; > I don't think we need to, as everyone who signed up for the next tutorial; > filled out a questionnaire. For the tutorial, I'll just put a password. I think for Stanley Center stuff we; should use GCP auth. > I'm getting proxy timeouts. We need an ready endpoint and something on the; > client side to poll and redirect. Actually, awesome if it doesn't poll but; > uses, say, websockets, and the server watches the pod for a notification for; > k8s (or does this and also polls, which seems to be our standard pattern). The proxy timeouts might be because I shut the whole thing down? But yeah, I; also saw timeouts if a pod can't be scheduled right away. > Should we have an auto-scaling non-preemptible pool and schedule these there?. We already have such a pool, and these pods do not tolerate the preemptible; taint, so they are forced to get scheduled on non-preemptibles. > If we do that, to optimize startup time, we should have imagePullPolicy: Never; > and then pull the image on startup and push it on update. I think `imagePullPolicy: Never` is a bad idea. If there's a bug where the image; is not present, then we get stuck. I think we should rely on k8s to pull the 5GB; jupyter image in a reasonable time period. If we cannot rely on that, we just; start up N nodes before the tutorial, ssh to each and pull the image. If; somehow",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4576#issuecomment-431185878:522,password,password,522,https://hail.is,https://github.com/hail-is/hail/pull/4576#issuecomment-431185878,2,['password'],['password']
Security,"> As far as I can tell, there's never a reason to use dgesvd. It appears dgesvd uses less memory and is more accurate, particularly on very small singular values, but is potentially several times slower. I agree dgesdd is the right default, but it's possible (though I'm guessing unlikely) we'll eventually have reason to expose dgesvd as an option. Here's a thread of Julia devs discussing which to use: https://groups.google.com/u/1/g/julia-dev/c/mmgO65i6-fA?pli=1",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9303#issuecomment-677708620:322,expose,expose,322,https://hail.is,https://github.com/hail-is/hail/pull/9303#issuecomment-677708620,1,['expose'],['expose']
Security,> Closing because; > ; > 1. The change is purely cosmetic; > 2. Breaking previously-run migration checksums feels like a bad idea. Do python files contribute to migration checksums?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14669#issuecomment-2318144085:98,checksum,checksums,98,https://hail.is,https://github.com/hail-is/hail/pull/14669#issuecomment-2318144085,2,['checksum'],['checksums']
Security,"> DOC: Update what's new for 8.10</li>; <li><a href=""https://github.com/ipython/ipython/commit/385d69325319a5972ee9b5983638e3617f21cb1f""><code>385d693</code></a> Merge pull request from GHSA-29gw-9793-fvw7</li>; <li><a href=""https://github.com/ipython/ipython/commit/e548ee23ac460a99901f1cd43b94ae84a35ec393""><code>e548ee2</code></a> Swallow potential exceptions from showtraceback() (<a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13934"">#13934</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/0694b08b436203817059ec7e7136cf8561a6f013""><code>0694b08</code></a> MAINT: mock slowest test. (<a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13885"">#13885</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/865591252a67c6907fe03228b4053305715286e6""><code>8655912</code></a> MAINT: mock slowest test.</li>; <li><a href=""https://github.com/ipython/ipython/commit/a011765b44febfb11bae122d2ed7db763621ac8f""><code>a011765</code></a> Isolate the attack tests with setUp and tearDown methods</li>; <li><a href=""https://github.com/ipython/ipython/commit/c7a9470e540392c575aac46c3ee5cf4fe5123eb1""><code>c7a9470</code></a> Add some regression tests for this change</li>; <li><a href=""https://github.com/ipython/ipython/commit/fd34cf5f1f6e243243c738c6e0cf62eb682c4d68""><code>fd34cf5</code></a> Swallow potential exceptions from showtraceback()</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12683:1649,attack,attack,1649,https://hail.is,https://github.com/hail-is/hail/pull/12683,1,['attack'],['attack']
Security,"> For the tutorial, I'll just put a password. I think for Stanley Center stuff we should use GCP auth. Yes. I'm imagining we'll have a tutorial service for intermittent tutorials and a jupyter/Hail service, both, although maybe eventually the latter can be used for both?. > But yeah, I also saw timeouts if a pod can't be scheduled right away. I definitely saw this case (e.g. I refreshed and then got the notebook). > I think imagePullPolicy: Never is a bad idea. Agreed, too aggressive. > I think we should rely on k8s to pull the 5GB jupyter image in a reasonable time period. No. I'm going to be demanding about making our tools responsive with good feedback (not responsive in the sense of responsive web design, but responsive in the sense of fast). It has to be fast, and when can't be, it has to give clear feedback about what it's doing and how long it will take. We routinely see pulling a 5GB image take 1-2m. That's spin up a VM level nonsense. Kubernetes 1.6 had an SLO to schedule 99% of pre-pulled containers within 5s on a 5K node cluster (from the plots it looks like they were closer to 2s):. > Pod startup time: 99% of pods and their containers (with pre-pulled images) start within 5s. from http://webcache.googleusercontent.com/search?q=cache:Soglxt0kAI0J:blog.kubernetes.io/2017/03/scalability-updates-in-kubernetes-1.6.html+&cd=1&hl=en&ct=clnk&gl=us. When we have to pull an image, I want spinner and the estimated spin time. If we have to spin up a node, same. (I know this is a first cut. I'm just saying where I'd like to see us head.). > I just run make clean-jobs, but we could add a delete endpoint and a little web page. OK, here's my picture:; - first time, prompt for password,; - if no notebook is running launch one and go straight there,; - if notebook is running, get a page with a link to the notebook and a link to kill it. That might be considered strange web design (skip the console depending on the state), in which case I'd vote for the console always. (Wha",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4576#issuecomment-431248659:36,password,password,36,https://hail.is,https://github.com/hail-is/hail/pull/4576#issuecomment-431248659,1,['password'],['password']
Security,"> Forks would indeed need to overwrite ours, but since the file wouldn't change much it seems like that's not much of a hassle to maintain, right Leo? And ya this seems like a fine change but we would need to follow up right afterward with our own credentials. Yes, alternatively we could also use the GitHub organization name or something similar when constructing the file path to encrypted credentials, to avoid collisions completely. (Forks like the CPG one would only add files to their deployments.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11724#issuecomment-1171065130:383,encrypt,encrypted,383,https://hail.is,https://github.com/hail-is/hail/pull/11724#issuecomment-1171065130,1,['encrypt'],['encrypted']
Security,"> Github doesn't have a way to say ""stacked on this PR"", so removal of the stacked tag is a manual gating. I'm surprised it doesn't have a way to do this, since when a PR is mentioned by a link or hash, that dependency is updated with its dependent. . Looks like this may be coming: https://twitter.com/natfriedman/status/1170804894241972224",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7417#issuecomment-548479314:197,hash,hash,197,https://hail.is,https://github.com/hail-is/hail/issues/7417#issuecomment-548479314,1,['hash'],['hash']
Security,"> Having the Auth service ping the Batch API with it to verify the token is valid. I believe the way our CRSF is implemented, we don't actually ever ""validate"" the tokens, we only check that the token in the formdata matches the token in the cookie. > Or perhaps we could just make this UI a single page application instead of a bunch of pages on different subdomains that resemble one. . This would be wonderful! Sort of similar-but-better to my thought of hosting the ""top menu bar"" as a separate iframe that always comes from auth. For the same reason (in particular, the apparently lack of regular usage of the logout button), that kind of change is probably larger than the scope of getting this bug fixed... but would cool to look into some day!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14639#issuecomment-2269645369:150,validat,validate,150,https://hail.is,https://github.com/hail-is/hail/pull/14639#issuecomment-2269645369,1,['validat'],['validate']
Security,"> High level question: is the state stored in MySQL the same as the k8s notebook pod state? If so, should we just query k8s rather than duplicating the notebook state in MySQL?. Not entirely the same I think, but I also prefer tools that are well-designed for the purpose, and have limited k8 / etcd experience / survivor bias. One interesting fact (spoke with Dan), is that we don't have direct access to etcd, so are limited to k8 client operations. * We had talked about, in batch context, of having our own master state, against which k8 is reconciled, to protect against k8 operational errors. Obviously that means our record of state is a point of failure, but db failure modes and uptime solutions are well defined across cloud/db provider vendors (we can minimize lock-in as well). The idea seemed to be that we don't particularly care how k8 works, or how much state it persists; the contract is with our users, and we should satisfy . * K8 does not store all state indefinitely. It's more like a rotating log: https://stackoverflow.com/questions/40636021/how-to-list-kubernetes-recently-deleted-pods . For users, and for investors, we want to have a permanent record of all user interactions. * Some kinds of data may be awkward to store and query within pod labels. For instance, how much user state do we want to store in labels? How do we store operation graphs / history?; ; * aggregation operations across users or resources; * a given, or all users' history: so the user can manage, see, so we can track (some, gross) metrics for billing; * various sorting operations (by date/time, etc); * full log of state for a given set of related resources (I think k8 stores last 5 events, this is probably configurable) ; ability to retry in a user-controlled way, even if pod is deleted from etcd. * Operations across N k8 resources seems like it may take up to N queries (i.e k8s.list_namespaced_service, k8s.list_namespaced_pod). There may be more efficient ways of handling this (there eith",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215#issuecomment-459054290:396,access,access,396,https://hail.is,https://github.com/hail-is/hail/pull/5215#issuecomment-459054290,1,['access'],['access']
Security,"> I agree users should have `storage.buckets.get` only to their own folder, and not `storage.buckets.get`. However, it looks like it is trying to create a bucket with the new folder name, and failing against that (non-existent) bucket:; > ; > > exceptions.from_http_response(response) google.api_core.exceptions.Forbidden: 403 GET https://www.googleapis.com/storage/v1/b/untitled-folder?projection=noAcl: [user-nrru16jaxrwmnzkv5f35xfibg@hail-vdc.iam.gserviceaccount.com](mailto:user-nrru16jaxrwmnzkv5f35xfibg@hail-vdc.iam.gserviceaccount.com) does not have storage.buckets.get access to untitled-folder.; > ; > That's untitled-folder. Maybe the error is not permissions at all, but it is using the wrong base directory to create the folder?. Right, I mentioned this above. It appears to be trying to create, or trying to read, untitled_folder as a bucket. If you trick it into using /your_bucket_name as the cwd, folder creation works.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5788#issuecomment-480381353:577,access,access,577,https://hail.is,https://github.com/hail-is/hail/pull/5788#issuecomment-480381353,1,['access'],['access']
Security,"> I think now that ci-agent lives in batch-pods, but has access to default, the ci-agent currently in batch-pods with cluster wide access is fine, and this should just be able to merged in as is. I agree. Looks like there is an issue, hello isn't showing up. I'll let you investigate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7466#issuecomment-551133834:57,access,access,57,https://hail.is,https://github.com/hail-is/hail/pull/7466#issuecomment-551133834,2,['access'],['access']
Security,"> I think port 443 is so we don't need root privileges in Envoy?. This is related to the way headless services expose the pod itself, but as I'm writing this I feel like I want more clarity on exactly why, so I will do a bit of digging and come back with a better response.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12094#issuecomment-1283003577:111,expose,expose,111,https://hail.is,https://github.com/hail-is/hail/pull/12094#issuecomment-1283003577,1,['expose'],['expose']
Security,"> I think pretty strongly that if nPreservedFields==0, you've done something very wrong. I don't disagree, but if you're concerned about this, I think an assert here is both in the wrong place and the wrong solution. I think for the design the IR, we should focus on (1) simple operations (this is already more complicated than I'd like), (2) that are composable, and (3) minimize special cases. By composability, I mean each IR should have a (local) contract, and each program composed from that local contract should be valid. Breaking this introduces a lot of potential bugs that can't be reasoned about locally, which is not good. The IR nodes do what they do. If you don't like what they do, we should probably find different ones. > so how could you possibly join this with another table? You'd have to create a single partition, and we'd never want to do that. Yeah, create a single partition. Or reshuffle if the partitioner has too little information. How much is too little? What if nPreservedFields==1 and we're down to 1 partition? Should that be an error? 2 partitions? How many partitions is too few? Any time nPreservedFields is less than the requested keys, you could get down to 1 partition. This is a continuous issue and rejecting the extreme case doesn't actually solve the problem. I guess isSorted isn't user exposed, but this seems dangerously close to reporting a user error with an assertion. When the service comes up, hopefully not too long, we're going to want to document the IR and make it public. So if we want to reject this case, we should do it early on: when the IR is parsed and/or constructed. (In general I think to give a nice experience we're going to have to do more up-front validation.) This is what I mean when I say ""find another IR"". In summary:; - If we're going to have this assertion, it needs to be in TableKeyBy constructor, and; - This is a complex and serious issue that isn't actually solved by your assertion.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8649#issuecomment-622415940:1331,expose,exposed,1331,https://hail.is,https://github.com/hail-is/hail/pull/8649#issuecomment-622415940,2,"['expose', 'validat']","['exposed', 'validation']"
Security,"> I'd propose to do an implicit dependency audit every time you push a new commit. > You can still pin versions on published packages, but use unpinned dependencies for CI testing. I think our only option here would be to test twice -- once with the major versions we explicitly depend on, and once with unbounded versions. I don't really like this model, since it basically couples breaking changes in other tools to Hail commits, which isn't how it actually works. I'd much prefer a weekly cron job that tries to update dependencies, I think, but that thing isn't trivial to build.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7299#issuecomment-542222446:43,audit,audit,43,https://hail.is,https://github.com/hail-is/hail/issues/7299#issuecomment-542222446,1,['audit'],['audit']
Security,"> I'm confused. What do you mean by this? Are you planning on using Dan's version of notebook (the rainbow gradient notebook.hail.is), or mine? If Dan's, he and I spoke about it, and he specifically stated that his version of Notebook is no longer needed, which is why I deleted the existing notebook. My apologies, @danking was wrong. I'm currently planning to use Dan's version because yours isn't ready. If yours is ready, I will use it. What does ready mean? From our recent email:. - it needs to get in master,; - and and integrated with our CI/CD (we can't be fixing issues and doing manual deployments leading up to or during a tutorial),; - it need to be beaten on by the team to look for issues (including scale issues), and; - it needs to be scale tested (@danking has a script for the old one that fires up N notebooks and reports any failures and summarizes the latency to notebook available),; - @tpoterba and I need to be comfortable enough with it we have confidence we can fix issues that arise during the tutorial. I probably also need time to review the workshop auth flow since I think that changed. If we're requiring login, we'll need to support more social login providers and/or email/password.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215#issuecomment-464229358:1208,password,password,1208,https://hail.is,https://github.com/hail-is/hail/pull/5215#issuecomment-464229358,1,['password'],['password']
Security,"> In particular, the matrixtable available in doc examples as `ds` lives at `hail/hail/python/hail/docs/data/example.mt`. Thanks, this is exactly what I was looking for. I am having trouble testing my new example locally though. When I run `make -C hail doctest-query`, the tests fail with a checksum error. I tried running `make -C hail clean` and retrying, but I still get the same error. ```; E hail.utils.java.FatalError: ChecksumException: Checksum error: file:/Users/willtyler/Desktop/hail/hail/python/hail/docs/data/example.8bits.bgen.idx2/metadata.json.gz at 0 exp: 982431825 got: -2031629660; E; E Java stack trace:; E org.apache.hadoop.fs.ChecksumException: Checksum error: file:/Users/willtyler/Desktop/hail/hail/python/hail/docs/data/example.8bits.bgen.idx2/metadata.json.gz at 0 exp: 982431825 got: -2031629660; E 	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:347); E 	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:303); E 	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:252); E 	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:197); E 	at java.base/java.io.DataInputStream.read(DataInputStream.java:149); E 	at is.hail.io.fs.HadoopFS$$anon$2.read(HadoopFS.scala:58); E 	at java.base/java.io.DataInputStream.read(DataInputStream.java:149); E 	at org.apache.commons.compress.utils.CountingInputStream.read(CountingInputStream.java:56); E 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252); E 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271); E 	at org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream.init(GzipCompressorInputStream.java:185); E 	at org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream.<init>(GzipCompressorInputStream.java:168); E 	at is.hail.io.fs.GZipCompressionCodec$.makeInputStream(FS.scala:125); E 	at is.hail.io.fs.FS.open(FS.scala:563); E 	at is.hail.io.fs.FS.open$(FS.scala:560); E 	",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14255#issuecomment-1933346001:292,checksum,checksum,292,https://hail.is,https://github.com/hail-is/hail/pull/14255#issuecomment-1933346001,5,"['Checksum', 'checksum']","['Checksum', 'ChecksumException', 'checksum']"
Security,"> Maybe lazy fields should not subclass Value, and to access a lazy field requires an explicit load(cb: CodeBuilder): Value[T]. I think this is probably the right model.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10907#issuecomment-961973892:54,access,access,54,https://hail.is,https://github.com/hail-is/hail/pull/10907#issuecomment-961973892,1,['access'],['access']
Security,"> Merge pull request <a href=""https://redirect.github.com/michel-kraemer/gradle-download-task/issues/295"">#295</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/c1e212c0fb41b3ea9185a9ea463fb1ea7142f748""><code>c1e212c</code></a> Add integration tests for Gradle 8.0 and 8.0.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/304f68e25f53633a92a4d2d6ce003a4986929503""><code>304f68e</code></a> Fix type inference issue</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.1...5.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.1&new-version=5.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:3046,secur,security-vulnerabilities,3046,https://hail.is,https://github.com/hail-is/hail/pull/12893,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"> Oh, I misunderstood, I thought you were suggesting changing our FROM to stretch/9.6.; > ; > I think that should be fine, but can we do it as a separate PR since it seems orthogonal to this change which we're trying to get in for the demo tomorrow? (And in general orthogonal changes should be separate PRs so discussion on one part doesn't hold up the other parts.). Yes, although the gzip settings issued in this pr will be different between the two version. 1.10.3 doesn't have gzip on by default. I understand the value of conservative updates before public demonstrations, so will do what you ask. Btw, the full config if relying on nginx:10.15.8 goes from:. ```; FROM debian:9.5. RUN apt-get update -y && \; apt-get install -y nginx && \; rm -rf /var/lib/apt/lists/*. RUN rm -f /etc/nginx/sites-enabled/default; ADD @nginx_conf@ /etc/nginx/conf.d/hail.conf; ADD gzip.conf /etc/nginx/conf.d/gzip.conf. RUN ln -sf /dev/stdout /var/log/nginx/access.log; RUN ln -sf /dev/stderr /var/log/nginx/error.log. CMD [""nginx"", ""-g"", ""daemon off;""]; ```. to . ```; FROM nginx:1.15.8. RUN rm -f /etc/nginx/sites-enabled/default; ADD @nginx_conf@ /etc/nginx/conf.d/hail.conf; ADD gzip.conf /etc/nginx/conf.d/gzip.conf; ```. kind of neat.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5244#issuecomment-460378467:946,access,access,946,https://hail.is,https://github.com/hail-is/hail/pull/5244#issuecomment-460378467,1,['access'],['access']
Security,"> Read through and looks good. Just checking: this is just intended to be an internal registered function, not something for users to call, right?. Users may sometimes use this -- it was exposed through `hl.experimental` previously as part of the vcf combiner utilities, I just moved it to `hl.vds` (though it still exists at the old location for compatibility)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10703#issuecomment-887575834:187,expose,exposed,187,https://hail.is,https://github.com/hail-is/hail/pull/10703#issuecomment-887575834,1,['expose'],['exposed']
Security,"> Relatedly, the auth system and the front end are not in this pull request (and AFACIT aren't in master yet?), which makes it harder to reason about the overall system. The auth system make sense as an independent PR (is that what #5162 is?). The changes that expose / use this new API (i.e. the UI component) should be a part of this PR so we can reason about the entire proposed change. I'm not sure how to really avoid this, some of it is the nature of our pull request goal (small, single-principle), and the other is the tradeoff of decoupling. This is also why I spend more time writing comments about the intended consumption of the notebook updates. Use those comments to reason about the overall system, and if that doesn't help, ask me to write more helpful comments.; ; The auth system is part of the Greenfield web pull request. That will be split up into something like 10-20 pull requests once the system is fully working, as mentioned in that repo. The auth-gateway will be in 2 of those (one for package-lock, one for the business logic). I've added the gateway changes to this particular pull request; that effectively shows the interface for authorization. I have mixed feelings about mixing that with the rest of this PR, happy to remove and issue separate PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215#issuecomment-460065641:261,expose,expose,261,https://hail.is,https://github.com/hail-is/hail/pull/5215#issuecomment-460065641,2,"['authoriz', 'expose']","['authorization', 'expose']"
Security,"> Second, StructExpression.init creates expressions for each field in the constructor. That seems excessive, we should construct the field expressions on demand when they are accessed. We lose dot-completion, then. I think the current design is correct (constructing 3k things shouldn't be a problem, anyhow)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4153#issuecomment-413194946:175,access,accessed,175,https://hail.is,https://github.com/hail-is/hail/issues/4153#issuecomment-413194946,1,['access'],['accessed']
Security,"> Should I get rid of that option?. Yes. For security, I don't think we should ever make our production database public, even in a limited way. For testing, we have a few options: use a test one as you say (in a non-production project?), use Cloud SQL proxy, spin up one locally, or make in-cluster testing easier. You can grant specific privileges to a user to a database in MySQL. I'm guessing you granted all on *.* which will allow them to create tables (among everything else). Basically, we should have an admin user that can create databases, and then individual users for each role that have read or read/write access to specific databases. Yeah, let's talk about it more today.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5618#issuecomment-473946373:45,secur,security,45,https://hail.is,https://github.com/hail-is/hail/pull/5618#issuecomment-473946373,2,"['access', 'secur']","['access', 'security']"
Security,"> Slight question about the shuffle ID/client/server model, mostly just to make sure I understand: each HailContext has one ShuffleClient,. There should be a ShuffleClient per-shuffle. I think in our current model, this means one active ShuffleClient at any given time (because there's only one active shuffle at any given time). However, I intend Hail service pipelines to be able to use multiple concurrent shuffles, if useful. In particular, a ShuffleClient has as type and an encoding, so its only useful for one type of dataset. Though you could theoretically re-use the object on a different dataset of the same type by calling `start` again. > which communicates with a ShuffleServer (which only connects to one ShuffleClient). I intended the ShuffleServer to serve an arbitrary number of non-adversarial clients (perhaps two different users in nascent hail service). I think it's pretty secure, but I don't think `UUID.randomUUID().toString()` is cryptographically random, so an adversary could probably guess it and thus get access to shuffle data. Moreover, the ShuffleServer must support concurrent connections from all the workers of a Hail pipeline. `ShuffleServer.serve` starts a fresh server thread for every connection. During the read or write phases of the shuffler, the idea is 1:1 mappings from workers to connections to server `Handler` threads. > Every time the hail context wants some data to be shuffled, the server creates a new shuffle ID to associate with the shuffle (starting the shuffle) and then the client sends over the data and can then access it, in ranges, using get. As soon as it starts a new shuffle, it can no longer access the data from the previous shuffle (at least through current interfaces---the shuffle server never deletes shuffled data, so we could theoretically define a put and get that take the uuid and then keep accessing older shuffles as long as we know the uuid). Does that sound about right?. The hail leader node could keep multiple `ShuffleC",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8361#issuecomment-609940052:895,secur,secure,895,https://hail.is,https://github.com/hail-is/hail/pull/8361#issuecomment-609940052,2,"['access', 'secur']","['access', 'secure']"
Security,"> So I'm going to insist on the classical loop interface I described above, since it is strictly more powerful than the interfaces you've proposed. I agree that the tail-recursion interface seems like the right primitive to expose in python, on top of which we could implement convenience methods for building while/for loops if we decide it's worth it. > Giving each loop a name seems natural. Apart from the wrapping issue (the greatest existential threat our generation faces) I don't see any problem calling an outer loop from an inner loop. Also agree. This will require either adding another context of loops/continuations in the environment (valid places to jump to, and their argument types), or keeping them in the normal value context by adding a new continuation type. > Is Patrick's proposal for extra types written up anywhere?. My proposal has two main differences. In; ```; hl.loop(; lambda i, x:; hl.cond(i < 10, hl.recur(i + 1, x + i), x),; 0, 0); ```; the point that jumps back to the top of the loop is explicit, but the point that jumps out of the loop is not. I suggested making this something like; ```; hl.loop(; lambda i, x:; hl.cond(i < 10, hl.recur(i + 1, x + i), hl.break(x)),; 0, 0); ```; or, if we're giving names to loops, it might be simpler to pass the break and recur functions to the lambda:; ```; hl.loop(; lambda sum, ret, i, x:; hl.cond(i < 10, sum(i + 1, x + i), ret(x)),; 0, 0); ```. The second difference is in the typing. In this PR, the `hl.recur` expression is given the type of the entire loop. I would add a single new type `Bottom`, and give all expressions which jump (both the recur and the break expressions) the type `Bottom`. `Bottom` is the empty type, so there can be no closed expressions of type `Bottom`. In the type checker, `Bottom` is only allowed to appear in tail positions, and for `If`, we keep the rule that both branches must have the same type, so either both branches are `Bottom` or neither are. This keeps the semantics simple: an i",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7614#issuecomment-559072407:224,expose,expose,224,https://hail.is,https://github.com/hail-is/hail/pull/7614#issuecomment-559072407,2,"['expose', 'threat']","['expose', 'threat']"
Security,"> Thanks for the explanation! I'm happy to make the change, I was just trying to understand the difference between Host and X-Forwarded-Host a little better before first.; > ; > So if I understand correctly, for the different headers:; > ; > * X-Forwarded-Proto gets passed to the router through the base https server in gateway, which sets X-Forwarded-Proto to `$scheme`, which is always going to be https since that's always going to be the protocol you're using for that server? And so when we use `$updated_scheme` for the blog server in the router's config, it's going to look at `$http_x_forwarded_proto` which will always have been set to `https` from the gateway? I. Yep. In fact everything request to a Hail service (besides a lets-encrypt path) gets redirected to https. > Or am I misunderstanding how this works?. Nope, you have it correct. $http_x_forwarded_proto should never be absent, and would be fine to use instead of $updated_scheme (but I'd prefer one of those two, rather than https, because otherwise we're not relying on our upstream infrastructure). > * I'm having trouble understanding the difference between `Host` and `X-Forwarded-Host`, still. As I understand it, `Host` is the name of the server that the current request is trying to reach, and `X-Forwarded-Host` is the name of the server that the original request was trying to reach? Which is why `Host` is set to `$service.internal` and `X-Forwarded-Host` is `$http_host` in the internal.hail.is server? . Yeah that's right. Host refers to the current server (or in the proxied case, what gateway set Host to). X-Forwarded-Host is set by gateway to be the $http_host at the time it proxies the request to router, which is going to be blog.hail.is. > I don't quite follow your comment about our use of `Host` being wrong, in this case; I _think_ I understand what you're saying? but I'm not sure why all of our stuff is setting `Host` to `$updated_host` if that's the case, and I don't understand what's happening enoug",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7381#issuecomment-548082569:741,encrypt,encrypt,741,https://hail.is,https://github.com/hail-is/hail/pull/7381#issuecomment-548082569,1,['encrypt'],['encrypt']
Security,"> Thanks, added with one tweak. Sadly I don't know how to convince your code analyser that using `randint` to make test cases in test code is not a security issue…. Me neither :shrug: . > Feel free to push to PR branches directly, or just to add things while merging. . I don't have write access to the `populationgenomics` fork, hence the PR :)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14700#issuecomment-2402897043:148,secur,security,148,https://hail.is,https://github.com/hail-is/hail/pull/14700#issuecomment-2402897043,2,"['access', 'secur']","['access', 'security']"
Security,"> The approach in this PR doubles down on the functional Code[T] structure. I don't see anything in the design that prevents us from moving away from `Code[T]`, but it does have to support it for now. > I think if I could choose an interface for injecting line numbers from IR in emit it would look something like:. This is also the interface I would like to see for CodeBuilder. And you're right, making that change would allow methods taking a `CodeBuilder` to not need a line number argument. I agree that's better. I may have gotten a bit of tunnel vision in the middle of the giant mechanical refactoring :) I will make this change. > I think part of my concern is that I’m not entirely sold by the need to have a whole stack of IR printouts and associated line numbers — right now, the option to get debug information by LIR line number or IR (fully lowered, compile-ready) seems plenty sufficient. I think most of this PR is necessary for debug information with the fully lowered IR line numbers. It doesn't do anything to propagate line numbers through IR lowerings, which is what would be needed to support line numbers at earlier compiler stages. > Part of my pushback is that I'm hesitant to use Scala implicits pervasively without a careful cost/benefit consideration. My main reason for that approach was to manage the number of changes required in this PR. We could follow up on this with making line number arguments explicit in manageable chunks. But personally this seems like the ideal use case for implicit arguments. And as `Code` goes away, the number of places with implicit line number arguments should go down significantly.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9770#issuecomment-742042975:246,inject,injecting,246,https://hail.is,https://github.com/hail-is/hail/pull/9770#issuecomment-742042975,1,['inject'],['injecting']
Security,"> The first usage of this feature is to move the FS off of the class itself and onto a container class. Is the container class generated globally? That's going to be a problem. The service backend has multiple FSes for multiple, different users. Keeping those FSes separate is **critical** for security. The reference genomes are the same story. Each service query will come with its own, distinct context of reference genomes, and they can't get mixed up. In particular, a reference genome sequence may be sensitive data and can't be exposed to other users. The reference genome global state will only be stored in the Python client. Removing the global reference state from the Scala side is a pending Query service project.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9044#issuecomment-652673222:294,secur,security,294,https://hail.is,https://github.com/hail-is/hail/pull/9044#issuecomment-652673222,2,"['expose', 'secur']","['exposed', 'security']"
Security,"> The missing permission is `storage.buckets.get` though? It seems reasonable for a user to [be able to read metadata](https://cloud.google.com/storage/docs/access-control/iam-permissions) about their own bucket. I'd wager that jgscm was designed for use with the `roles/storage.legacyBucketWriter` role granted on their bucket. What role are we currently granting?. The problem I believe is that they would need project-wide read/list permissions. The blob (folder) is not being created in their bucket, but as a new bucket in the project. edit: You can clearly see the difference if you click on the checkpoint folder, back up to the folder /bucket_name and try to create a folder. No additional permissions needed (it's being made in their bucket)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5788#issuecomment-480375549:157,access,access-control,157,https://hail.is,https://github.com/hail-is/hail/pull/5788#issuecomment-480375549,1,['access'],['access-control']
Security,"> The reason we didn't expose the other parameters was what if we had 16 core jobs waiting to be scheduled and then we changed the worker pool size to 4 cores. Yep. Let's call that admin operator error and let's not do that. The other reason was we had hardcoded the billing computation in the code, but that's fixed now. But it is hardcoded in the documentation, so we still shouldn't really be changing any of these settings (I see this mainly for the second instance at this point). Separately, we should decouple the billing from the details of the implementation so we get a bit more flexibility on the backend in the main instance, as we've discussed. I'm OK with this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9285#issuecomment-674998109:23,expose,expose,23,https://hail.is,https://github.com/hail-is/hail/pull/9285#issuecomment-674998109,1,['expose'],['expose']
Security,"> There are other implementations, such as LibreSSL, but they implement roughly the same interface as OpenSSL. LibreSSL introduced a new interface, libtls, that's designed to be easy to use, secure by default, and match the underlying socket semantics as much as possible. If we ever do any C level networking, we should use it. > ad nihilum. You mean ex nihilo, from nothing?. > I intend to eventually require all our services to refuse to speak anything other than TLS 1.3. Can we get a task for this in Asana? And for mTLS?. > Our system is simpler. We have no root certificate.; > Deploy will run create_certs on every master deploy.; > [O]nce incoming trust is fixed, I am unsure how to smoothly upgrade services. I think we should a have a root certificate for all services in the cluster and verify all certificates are signed by the root certificate. I don't know how to handle creating new certs on every deploy, either. I think we should just create them if they don't already exist. It looks like you're pinning keys for incoming and outgoing, which is awesome. It looks like you're duplicating the keys for each incoming/outgoing list it appears in. Alternatively, you could break the cert secret into two parts: the private key/config needed by the service, and the certs needed by the clients/servers. > In the long run, I want to fix batch to use an entirely different network for callbacks. I agree. Can we get a task for this? Using authorization to control who can talk to whom is great. We should enforce that with network policies. Defense in depth. Another task. > Readiness and liveness probes cannot use HTTP.; > Although k8s supports HTTPS, it does not support so-called ""mTLS"" or ""mutual TLS."". Ugh. But probes can be run via a command, so we should be able to use curl and our client certs for this: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/. ```; livenessProbe:; exec:; command:; - cat; - /tmp/healthy; initialDela",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561#issuecomment-615209805:191,secur,secure,191,https://hail.is,https://github.com/hail-is/hail/pull/8561#issuecomment-615209805,5,"['certificate', 'secur']","['certificate', 'certificates', 'secure']"
Security,"> There should be no notebook2 links. I just grepped through the entire codebase, I didn't find anything. We're not asking for notebook2 certs anymore. Notebook2 is dead, long live notebook. Nobody is using it besides us, so I don't see any need for maintaining backward compatibility. In particular, if/when we make this more widely available, there shouldn't be anything2. I just mean we should have a gateway/router redirect, or have 404's issued. Right now some kind of routing happens, resulting in a certificate error.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7145#issuecomment-536197945:506,certificate,certificate,506,https://hail.is,https://github.com/hail-is/hail/pull/7145#issuecomment-536197945,1,['certificate'],['certificate']
Security,"> This doesn't track the length if known like the old code. That will make some things e.g. ToArray much more expensive. I think you should finish all the stream processing nodes to unblock lowering and then return to this. Right, I was waiting to get the hard parts right first. This should be easy to add back. > Finally, this seems a silent on the the question of region management. What's your picture here? The region management write had consumers passing regions to producers, but I don't see how that fits in here. I put the region management on hold when I realized there was no way to make a stream free any regions it owns when its consumer stops pulling from it. So the new stream design is just to expose those setup and finalization hooks, where creating and freeing regions can go. When I start moving the region management logic I had over to the new design, I'll have to see if regions have to be baked into streams, or if they can be orthogonal. My plan was to first try making `EmitStream` return `Stream[Region => EmitTriplet]`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8129#issuecomment-589676137:711,expose,expose,711,https://hail.is,https://github.com/hail-is/hail/pull/8129#issuecomment-589676137,1,['expose'],['expose']
Security,"> What happens? I just tested it and it works fine for me. Although we probably shouldn't have spaces in workshop names, maybe I'll do that if/when I add validation. It would claim deletion without deleting. Must have been resolved or caused by a separate issue.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7162#issuecomment-536318084:154,validat,validation,154,https://hail.is,https://github.com/hail-is/hail/pull/7162#issuecomment-536318084,1,['validat'],['validation']
Security,"> agree: api is in GH, ergo public, so only point of contention is:. It's public to people who read GitHub and hail docs. It isn't really public to someone who is probing around for endpoints to exploit. > Yes, because I know I will make mistakes (and users will make config mistakes) and I want an easily debuggable system. Sure. > The risk is that an attacker may learn /jobs exists. If that knowledge substantially improves an attacker's ability to infiltrate batch, then we've made a severe error in securing batch. I agree in general, except I think of the problem seemingly inversely. If providing 401/403 responses to the end user substantially improves their experience, then we should do it. If not we shouldn't, because the degree to which an attacker is ""substantially"" enabled, is in my mind anything other than 0. Battles can be lost by small degrees. The choices should be user driven. . I think you told me that your system benefits, so let's do it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5844#issuecomment-483797170:353,attack,attacker,353,https://hail.is,https://github.com/hail-is/hail/pull/5844#issuecomment-483797170,4,"['attack', 'secur']","['attacker', 'securing']"
Security,"> but not the thunk of thunking. You mean the dependent aggregators? The issue is the copy code needs access to the type that was matched in the TVariable. The TVariable binding is cleaned on every function match, which is long before the code is executed on a worker. Therefore, we need to run some code to capture the TVariable binding just after the match happens. That's what the extra level of thunking is about.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2360#issuecomment-340047873:102,access,access,102,https://hail.is,https://github.com/hail-is/hail/pull/2360#issuecomment-340047873,1,['access'],['access']
Security,"> if MathJax changes the vertical layout of the page, we might have scrolled too far or not far enough to have the anchor located just below the header. I haven't seen the issue in practice, but it would be better to listen to mathjaxj onload. Anchor tags / clicks of course wouldn't be affected. > if we navigate to a new URL using any means other than clicking on an anchor tag, our history will have the URL with the special hash. I don't think there's anything special about the hash; without this solution clicking on an anchor tag should produce exactly the same behavior (a #id appended).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7334#issuecomment-544692099:428,hash,hash,428,https://hail.is,https://github.com/hail-is/hail/pull/7334#issuecomment-544692099,2,['hash'],['hash']
Security,"> if there's a problem with the expression, I don't want to get a crash from a requirementError from the Variant constructor without any context. You need to do validation in the expr code. User could isn't allowed to fail with a requirement error. I'd solve the error message problem by carrying it along with the annotation. Line can be generalized to carry line information about any type. > My CNV work involves parallelizing file parsing, and this interface wouldn't be compatible with that use case. I don't understand, can you elaborate on this?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/462#issuecomment-233005833:161,validat,validation,161,https://hail.is,https://github.com/hail-is/hail/pull/462#issuecomment-233005833,1,['validat'],['validation']
Security,"> it seems to provide visibility into what happened during the last run of lets encrypt?. Yes. As far as I know, certbot needs the previous config to do a renew (which I'm not doing yet). > I think the ""sidecar"" approach is simpler than this one (no extra nginx instance, no secrets, no service, no k8s secret creation privileges). We beef up the nginx pod to have a second container sharing a letsencrypt volume (which we've already defined in this PR). You can't mount volumes to multiple pods. You can't even mount volumes to the SAME pod if you want to do rolling updates (because the new instance can't launch because the old one is mounting the volume). I think this means volumes for certs and web root are out. volumes only work for replicated StatefulSets where you can take down one instance at a time for updates.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4624#issuecomment-432724868:80,encrypt,encrypt,80,https://hail.is,https://github.com/hail-is/hail/pull/4624#issuecomment-432724868,1,['encrypt'],['encrypt']
Security,"> nb, from [Authorization Overview](https://kubernetes.io/docs/reference/access-authn-authz/authorization/):; > ; > > Caution: System administrators, use care when granting access to pod creation. A user granted permission to create pods (or controllers that create pods) in the namespace can: read all secrets in the namespace; read all config maps in the namespace; and impersonate any service account in the namespace and take any action the account could take. This applies regardless of authorization mode.; > ; > Permission to create a pod gives you permission to mount any secrets in said namespace. Pod creation is a dangerous and powerful permission.; > ; > See this [recently closed ticket on k8s](https://github.com/kubernetes/kubernetes/issues/4957).; > ; > [An issue from June 2018](https://github.com/kubernetes/community/pull/1604) notes this is an issue for multi-tenant clusters. The k8s maintainers don't have bandwidth to iterate on a solution right now. Thanks, yeah, I shared this with Cotton yesterday. We need to be careful seems to be the conclusion.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5753#issuecomment-479640942:12,Authoriz,Authorization,12,https://hail.is,https://github.com/hail-is/hail/pull/5753#issuecomment-479640942,5,"['Authoriz', 'access', 'authoriz']","['Authorization', 'access', 'access-authn-authz', 'authorization']"
Security,"> security. for kubernetes/flask/those things? I don't see much security risk for the other stuff right now (not including malicious packages as security risks, those seem to be in their own category). Agree to punt on this for now though 😉",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4701#issuecomment-435205370:2,secur,security,2,https://hail.is,https://github.com/hail-is/hail/pull/4701#issuecomment-435205370,3,['secur'],['security']
Security,"> validation. Checking the arguments to the `Variant` constructor and generating nice error messages. For CNV work, you want to parallelize over files and not lines within files? You need to process the each file serially?. I'm not against having an additional interface like ParseContext that you can use both for the RDD interface and for the CNV stuff. Another option might be to make `TableReader[C[_]](...): (TStruct, C[Annotation])` but you'll have to do some work to define a `C` that knows how to load itself from a file, for example. It would be useful to be able to write code that can be used with either RDDs or local collections. > For the 'annotation line' are you suggesting a general error-catching wrapper?. Yep! I'll look over your proposed interface. Letting my mind wander a little here. One of the challenges with Spark error handling is propagating errors from the workers back to the master. RDDs are naturally used functionally, so functional error handling might be a better approach. The `Try` monad is the normal way to do functional error handling in Scala. Since we have concurrency, we have multiple errors and we want to preserve them all. In addition, it would be nice if the new generalized `Try` monad tracked warnings (like VCFReport). The main thing it isn't clear how to handle is writing RDDs. You basically want a write to write out the values and return an RDD, but just with the errors and warnings, which you could transfer to the driver at the end with collect.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/462#issuecomment-233041581:2,validat,validation,2,https://hail.is,https://github.com/hail-is/hail/pull/462#issuecomment-233041581,1,['validat'],['validation']
Security,"> wait, you force-pushed current master as this branch. Yep, I put the wrong hash in a rebase --onto and when it was the same as master, Github closed it and marked it as merged. Surprising! Fixed!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5004#issuecomment-448650369:77,hash,hash,77,https://hail.is,https://github.com/hail-is/hail/pull/5004#issuecomment-448650369,1,['hash'],['hash']
Security,">#1123</a>)</li>; <li>Add support for Docutils 0.17 (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1185"">#1185</a> and <a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1199"">#1199</a>)</li>; <li>Fixed logo scaling on IE11 (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1183"">#1183</a>)</li>; <li>Added support for logos as URLs (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1171"">#1171</a>)</li>; <li>Align top and side navigation background colors on mobile (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1132"">#1132</a>)</li>; <li>Added support for deep toc levels (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1089"">#1089</a>)</li>; <li>Updated translations for Chinese, Dutch, Estonian, French, German, Italian,; Lithuanian, Persian, Polish, Portuguese, Russian, Spanish, Swedish, and; Turkish locales</li>; </ul>; <p>A number of accessibility features were added in this release:</p>; <ul>; <li>Allow keyboard to toggle menu expansion (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1167"">#1167</a>)</li>; <li>Allow keyboard to activate permalink (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1162"">#1162</a>)</li>; <li>Show keyboard focus on buttons (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1161"">#1161</a>)</li>; <li>Maintain aria-expanded along with .current in menu (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1151"">#1151</a>)</li>; <li>Respect tab order for prev/next buttons (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1051"">#1051</a>)</li>; </ul>; <h2>Fixes</h2>; <ul>; <li>Updated Google analytics integration (<a href=""https://github-redirect.dependabot.com/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11464:2139,access,accessibility,2139,https://hail.is,https://github.com/hail-is/hail/pull/11464,2,['access'],['accessibility']
Security,">#8028</a>) (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8035"">#8035</a>) (<a href=""https://github.com/vitejs/vite/commit/992aee2"">992aee2</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8028"">#8028</a> <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8035"">#8035</a></li>; <li>fix: invalidate ssrError when HMR update occurs (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8052"">#8052</a>) (<a href=""https://github.com/vitejs/vite/commit/22fa882"">22fa882</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8052"">#8052</a></li>; <li>fix: use <code>strip-literal</code> to strip string lterals (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8054"">#8054</a>) (<a href=""https://github.com/vitejs/vite/commit/b6fc3cd"">b6fc3cd</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8054"">#8054</a></li>; <li>perf(lib): reduce backtrack when injecting esbuild helpers (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8110"">#8110</a>) (<a href=""https://github.com/vitejs/vite/commit/e5556ab"">e5556ab</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8110"">#8110</a></li>; </ul>; <h2><!-- raw HTML omitted -->2.9.8 (2022-05-04)<!-- raw HTML omitted --></h2>; <ul>; <li>fix: inline js and css paths for virtual html (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7993"">#7993</a>) (<a href=""https://github.com/vitejs/vite/commit/d49e3fb"">d49e3fb</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7993"">#7993</a></li>; <li>fix: only handle merge ssr.noExternal (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8003"">#8003</a>) (<a href=""https://github.com/vitejs/vite/commit/642d65b"">642d65b</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8003"">#8003</a></li>; <li>fix",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12142:8153,inject,injecting,8153,https://hail.is,https://github.com/hail-is/hail/pull/12142,2,['inject'],['injecting']
Security,">, <a href=""https://github.com/sarveshr7""><code>@​sarveshr7</code></a>)</li>; <li>Introduction of a new &quot;sync_proxy_rules_no_local_endpoints_total&quot; proxy metric. This metric represents the number of services with no internal endpoints. The &quot;traffic_policy&quot; label will contain both &quot;internal&quot; or &quot;external&quot;. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108930"">kubernetes/kubernetes#108930</a>, <a href=""https://github.com/MaxRenaud""><code>@​MaxRenaud</code></a>)</li>; <li>JobReadyPods graduates to Beta and it's enabled by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107476"">kubernetes/kubernetes#107476</a>, <a href=""https://github.com/alculquicondor""><code>@​alculquicondor</code></a>)</li>; <li>Kube-apiserver: <code>--audit-log-version</code> and <code>--audit-webhook-version</code> now only support the default value of <code>audit.k8s.io/v1</code>. The v1alpha1 and v1beta1 audit log versions, deprecated since 1.13, have been removed. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108092"">kubernetes/kubernetes#108092</a>, <a href=""https://github.com/carlory""><code>@​carlory</code></a>)</li>; <li>Kube-apiserver: the <code>metadata.selfLink</code> field can no longer be populated by kube-apiserver; it was deprecated in 1.16 and has not been populated by default since 1.20+. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107527"">kubernetes/kubernetes#107527</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>)</li>; <li>Kubelet external Credential Provider feature is moved to Beta. Credential Provider Plugin and Credential Provider Config API's updated from v1alpha1 to v1beta1 with no API changes. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108847"">kubernetes/kubernetes#108847</a>, <a href=""https://github.com/adisky""><code>@​adisky</code></a>)</li>; <li>Make ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:8468,audit,audit,8468,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['audit'],['audit']
Security,">. ```; jupyter 1.0.0 requires notebook, which is not installed.; beautifulsoup4 4.12.2 requires soupsieve, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low sever",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13718:1413,Access,Access,1413,https://hail.is,https://github.com/hail-is/hail/pull/13718,1,['Access'],['Access']
Security,">; </ul>; <h1>Release 5.10.0</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/java-native-access/jna/commit/3705b849892aa3c37e5608e640eff19047811a5c""><code>3705b84</code></a> Release 5.12.1</li>; <li><a href=""https://github.com/java-native-access/jna/commit/2f919e56bad203494fe9589206d6d23f27ef4f26""><code>2f919e5</code></a> Null-check cleanable in Memory#close (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1447"">#1447</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/1eec7dd76830af97ed64ecb2d8d39a56db104dcd""><code>1eec7dd</code></a> Prepare next development iteration</li>; <li><a href=""https://github.com/java-native-access/jna/commit/0d7499f105e4495bdea15fc21f5b1046e81ca822""><code>0d7499f</code></a> Release 5.12.0</li>; <li><a href=""https://github.com/java-native-access/jna/commit/fa86166d4f75ef4478de7ad9d7d6c0b6b6933ee0""><code>fa86166</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1445"">#1445</a> from matthiasblaesing/aix</li>; <li><a href=""https://github.com/java-native-access/jna/commit/4cca4405f7f6bc32d2a08495efb81c081b065279""><code>4cca440</code></a> Fix name mapping difference between AIX JDK 8 and Semeru JDK 18</li>; <li><a href=""https://github.com/java-native-access/jna/commit/f58b0f8f6b5c013adfe44a2cfb018ccb6ef6a688""><code>f58b0f8</code></a> Improve test stability on AIX (exclude tests that are expected to fail)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/c1565fb89469cbcba67b1cc305e16d520779b270""><code>c1565fb</code></a> Handle race condition in PdhUtil#PdhEnumObjectItems (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/99fcfa822db86b1f2ba5823dbf17efeb3d246ad5""><code>99fcfa8</code></a> Merge pull re",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:6355,access,access,6355,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,">; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/09d1eca91afbf21ace3672be24c68d9028ee1e33""><code>09d1eca</code></a> Document runAsync method</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/800e3df1647c5ce65bffdd25c3240dfa5244e6c5""><code>800e3df</code></a> Add runAsync method to download extension</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/80f04c6a46fe7df053ac55bcfc6f90ff74c4b873""><code>80f04c6</code></a> Bump up version number to 5.1.3</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/3.2.0...5.2.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=3.2.0&new-version=5.2.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:5188,secur,security-vulnerabilities,5188,https://hail.is,https://github.com/hail-is/hail/pull/12332,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,">; <li><a href=""https://github.com/pygments/pygments/commit/96a0cdf200ab8a36dc5f6f748f3b9d01c05cb91b""><code>96a0cdf</code></a> PythonTracebackLexer: minor tweak in docstring</li>; <li><a href=""https://github.com/pygments/pygments/commit/569eea6ee85ec4d679bb38a890c167b58ee727dd""><code>569eea6</code></a> Enable Sphinx nitpicky mode and fix warnings (<a href=""https://redirect.github.com/pygments/pygments/issues/2403"">#2403</a>)</li>; <li><a href=""https://github.com/pygments/pygments/commit/b018a65cb6ef51596c2cb8d6c97f0d79d9fa2ae7""><code>b018a65</code></a> Prepare for next release.</li>; <li>See full diff in <a href=""https://github.com/pygments/pygments/compare/2.15.0...2.15.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pygments&package-manager=pip&previous-version=2.15.0&new-version=2.15.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12909:3826,secur,security-vulnerabilities,3826,https://hail.is,https://github.com/hail-is/hail/pull/12909,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,">; <li><code>FormatChecker.cls_checks</code> is deprecated. Use <code>FormatChecker.checks</code> on; an instance of <code>FormatChecker</code> instead.</li>; <li><code>unevaluatedItems</code> has been fixed for draft 2019. It's nonetheless; discouraged to use draft 2019 for any schemas, new or old.</li>; <li>Fix a number of minor annotation issues in <code>protocols.Validator</code></li>; </ul>; <h1>v4.13.0</h1>; <ul>; <li>Add support for creating validator classes whose metaschema uses a different; dialect than its schemas. In other words, they may use draft2020-12 to define; which schemas are valid, but the schemas themselves use draft7 (or a custom; dialect, etc.) to define which <em>instances</em> are valid. Doing this is likely; not something most users, even metaschema authors, may need, but occasionally; will be useful for advanced use cases.</li>; </ul>; <h1>v4.12.1</h1>; <ul>; <li>Fix some stray comments in the README.</li>; </ul>; <h1>v4.12.0</h1>; <ul>; <li>Warn at runtime when subclassing validator classes. Doing so was not; intended to be public API, though it seems some downstream libraries; do so. A future version will make this an error, as it is brittle and; better served by composing validator objects instead. Feel free to reach; out if there are any cases where changing existing code seems difficult; and I can try to provide guidance.</li>; </ul>; <h1>v4.11.0</h1>; <ul>; <li>Make the rendered README in PyPI simpler and fancier. Thanks Hynek (<a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/issues/983"">#983</a>)!</li>; </ul>; <h1>v4.10.3</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/420fc6bd9a3ecc4cd637ece97cb4b482b4d0d37e""><code>420fc6b</code></a> Minor verbiage tweak for protocols.</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/8ce8250897e1b2e9",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12163:5615,validat,validator,5615,https://hail.is,https://github.com/hail-is/hail/pull/12163,1,['validat'],['validator']
Security,">; <summary>⚠️ <b>Warning</b></summary>. ```; msal-extensions 1.0.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiohttp 3.8.5 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 41.0.4` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Expected Behavior Violation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3314966](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3314966) | `cryptography:` <br> `3.3.2 -> 41.0.4` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Use After Free <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315324](https://snyk.io/vuln/SNYK-PY",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13736:1376,Certificate,Certificate,1376,https://hail.is,https://github.com/hail-is/hail/pull/13736,2,['Certificate'],['Certificate']
Security,">; <ul>; <li><a href=""https://github.com/urllib3/urllib3/commit/9c2c2307dd1d6af504e09aac0326d86ee3597a0b""><code>9c2c230</code></a> Release 1.26.18 (<a href=""https://redirect.github.com/urllib3/urllib3/issues/3159"">#3159</a>)</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/b594c5ceaca38e1ac215f916538fb128e3526a36""><code>b594c5c</code></a> Merge pull request from GHSA-g4mx-q9vg-27p4</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/944f0eb134485f41bc531be52de12ba5a37bca73""><code>944f0eb</code></a> [1.26] Use vendored six in urllib3.contrib.securetransport</li>; <li>See full diff in <a href=""https://github.com/urllib3/urllib3/compare/1.26.17...1.26.18"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.17&new-version=1.26.18)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13842:1857,secur,security-vulnerabilities,1857,https://hail.is,https://github.com/hail-is/hail/pull/13842,10,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"></a>)</li>; </ul>; <h1>v24.2.0</h1>; <p>Kubernetes API Version: v1.24.2</p>; <h3>API Change</h3>; <ul>; <li>Add 2 new options for kube-proxy running in winkernel mode. <code>--forward-healthcheck-vip</code>, if specified as true, health check traffic whose destination is service VIP will be forwarded to kube-proxy's healthcheck service. <code>--root-hnsendpoint-name</code> specifies the name of the hns endpoint for the root network namespace. This option enables the pass-through load balancers like Google's GCLB to correctly health check the backend services. Without this change, the health check packets is dropped, and Windows node will be considered to be unhealthy by those load balancers. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/99287"">kubernetes/kubernetes#99287</a>, <a href=""https://github.com/anfernee""><code>@​anfernee</code></a>)</li>; <li>Added CEL runtime cost calculation into CustomerResource validation. CustomerResource validation will fail if runtime cost exceeds the budget. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108482"">kubernetes/kubernetes#108482</a>, <a href=""https://github.com/cici37""><code>@​cici37</code></a>)</li>; <li>Added a new metric <code>webhook_fail_open_count</code> to monitor webhooks that fail to open. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107171"">kubernetes/kubernetes#107171</a>, <a href=""https://github.com/ltagliamonte-dd""><code>@​ltagliamonte-dd</code></a>)</li>; <li>Adds a new Status subresource in Network Policy objects (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107963"">kubernetes/kubernetes#107963</a>, <a href=""https://github.com/rikatz""><code>@​rikatz</code></a>)</li>; <li>Adds support for <code>InterfaceNamePrefix</code> and <code>BridgeInterface</code> as arguments to <code>--detect-local-mode</code> option and also introduces a new optional <code>--pod-interface-name-prefix</code> and <",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:1768,validat,validation,1768,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['validat'],['validation']
Security,"><a href=""https://github.com/PyCQA/flake8/commit/ff6569b87db8ae28c41b548071454de620ad14d5""><code>ff6569b</code></a> Release 5.0.3</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/e76b59ae44f46f7958d13b28bd2d7d9bdc0f5962""><code>e76b59a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pycqa/flake8/issues/1648"">#1648</a> from PyCQA/invalid-syntax-partial-parse</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/25e8ff18b30b58f1dabc1d20546ebc20fd775560""><code>25e8ff1</code></a> ignore config files that partially parse as flake8 configs</li>; <li>Additional commits viewable in <a href=""https://github.com/pycqa/flake8/compare/4.0.1...5.0.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=flake8&package-manager=pip&previous-version=4.0.1&new-version=5.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12105:2494,secur,security-vulnerabilities,2494,https://hail.is,https://github.com/hail-is/hail/pull/12105,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/712679f88772fb15184ad7c87dea220a87803f44""><code>712679f</code></a> Upgrade to Gradle 7.5 (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1980"">#1980</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/a4d14077a58ba3272469d48500ce007c725f1c73""><code>a4d1407</code></a> [DOCS] Added 8.3.2 RNs (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1978"">#1978</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/elastic/elasticsearch-hadoop/compare/v8.0.0...v8.4.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.elasticsearch:elasticsearch-spark-30_2.12&package-manager=gradle&previous-version=8.0.0&new-version=8.4.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:7705,secur,security-vulnerabilities,7705,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"><a href=""https://github.com/python-parsy/parsy/commit/638bec2cd810f85058599b9df93b155c04142a00""><code>638bec2</code></a> Fixed indentation of code in tutorial</li>; <li><a href=""https://github.com/python-parsy/parsy/commit/ebf374ebd9c2736da851d9aeb0500b62f3db074e""><code>ebf374e</code></a> Merge pull request <a href=""https://redirect.github.com/python-parsy/parsy/issues/69"">#69</a> from python-parsy/docstrings-and-types</li>; <li><a href=""https://github.com/python-parsy/parsy/commit/9380385e2bc39f23c1378d66d3105c1f1e1d2713""><code>9380385</code></a> Fixed Python 3.11 tests</li>; <li>Additional commits viewable in <a href=""https://github.com/python-parsy/parsy/compare/v1.1.0...v2.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=parsy&package-manager=pip&previous-version=1.1.0&new-version=2.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Depe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12934:4260,secur,security-vulnerabilities,4260,https://hail.is,https://github.com/hail-is/hail/pull/12934,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"><code>e4cba8f</code></a> Support python 3.7 and 3.8 in tests and travis CI</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/f9b86aa08576c677afe16caf41aa2ab685b0f995""><code>f9b86aa</code></a> Update dependencies (<a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/485"">#485</a>)</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/e3c1bb808d0af308e21d2488be75a40dfd054b78""><code>e3c1bb8</code></a> chore(flake8): fixed flake8 errors (<a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/484"">#484</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiomysql/compare/v0.0.20...v0.0.22"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiomysql&package-manager=pip&previous-version=0.0.20&new-version=0.0.22)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11543:6466,secur,security-vulnerabilities,6466,https://hail.is,https://github.com/hail-is/hail/pull/11543,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,">@​ahg-g</code></a>)</li>; <li>Promote IdentifyPodOS feature to beta. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107859"">kubernetes/kubernetes#107859</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@​ravisantoshgudimetla</code></a>)</li>; <li>Remove a v1alpha1 networking API for ClusterCIDRConfig (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/109436"">kubernetes/kubernetes#109436</a>, <a href=""https://github.com/JamesLaverack""><code>@​JamesLaverack</code></a>)</li>; <li>Renamed metrics <code>evictions_number</code> to <code>evictions_total</code> and mark it as stable. The original <code>evictions_number</code> metrics name is marked as &quot;Deprecated&quot; and has been removed in kubernetes 1.23 . (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106366"">kubernetes/kubernetes#106366</a>, <a href=""https://github.com/cyclinder""><code>@​cyclinder</code></a>)</li>; <li>Skip x-kubernetes-validations rules if having fundamental error against the OpenAPIv3 schema. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108859"">kubernetes/kubernetes#108859</a>, <a href=""https://github.com/cici37""><code>@​cici37</code></a>)</li>; <li>Support for gRPC probes is now in beta. GRPCContainerProbe feature gate is enabled by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108522"">kubernetes/kubernetes#108522</a>, <a href=""https://github.com/SergeyKanzhelev""><code>@​SergeyKanzhelev</code></a>)</li>; <li>Suspend job to GA. The feature gate <code>SuspendJob</code> is locked and will be removed in 1.26. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108129"">kubernetes/kubernetes#108129</a>, <a href=""https://github.com/ahg-g""><code>@​ahg-g</code></a>)</li>; <li>The AnyVolumeDataSource feature is now beta, and the feature gate is enabled by default. In order to provide user feedback on PVCs with data s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:12624,validat,validations,12624,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['validat'],['validations']
Security,">Can you help me understand why we can't set a very negative z-index on whatever element is creating the offset or use one of these shorter solutions?. Sure. These solutions don't work because they interfere with the layout of content. What you linked above works fine with 1 element, but not with adjacent elements. All of these solutions try to make up for the fact that the browser will position the element at the top of the browser (has no concept of non-0 offset). The javascript solution fixes this by introducing that non-0-offset. - I tried every permutation of these solutions, including every solution at the link you provided, in the original fix. They all interfere with layout in the presence of nested and adjacent modified elements. There is no z-index solution possible for all combinations, at least without JS (because you need adjacent elements to have descending ordered z-indices). MathJax was handling scrolling at page load. If you remove that line MathJax will scroll the page whenever it detects a hash in the URL. ""Since typesetting usually changes the vertical dimensions of the page, if the URL contains an anchor position, then after the page is typeset, you may no longer be positioned at the correct position on the page. MathJax can reposition to that location after it completes its initial typesetting of the page. This value controls whether MathJax will reposition the browser to the #hash location from the page URL after typesetting for the page"". * https://docs.mathjax.org/en/v2.7-latest/options/hub.html. . The reason we use history instead of say updating location.href is because there is no way to prevent the browser from scrolling to that location when you update that value. It's undefeatable, as mentioned in the comments.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7334#issuecomment-544655748:1024,hash,hash,1024,https://hail.is,https://github.com/hail-is/hail/pull/7334#issuecomment-544655748,2,['hash'],['hash']
Security,">Explicitly specify the subnet in the VM creation. This was optional before but BITS changed some settings in GCP such that you have to specify subnets when creating a VM. Nah that was me (to comply with security requirements, but still me). My bad for not updating the script.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13404#issuecomment-1673480429:204,secur,security,204,https://hail.is,https://github.com/hail-is/hail/pull/13404#issuecomment-1673480429,1,['secur'],['security']
Security,">We only have to support two platforms: recent Linux and OSX. OSX is not a problem, all recent versions are based on libc++ (rather than libstdc++) which has; had a more stable ABI. The problem is precisely that ""recent Linux"" encompasses both; systems based on g++-4.8.x/4.9.x with only old-ABI std::string's (e.g. debian8), and systems; based on g++-5.x and later with new-ABI std::string by default (e.g. debian9). That; incompatibility is the problem. >Not having access to the standard library seems problematic. You absolutely have access to the full C++11 standard library in dynamically-generated code -; you're compiling with the master node's default compiler, and header files, and using; the default libstdc++.o (libc++.dylib), and it's all fine. And you'll be using whichever flavor; of std::string is the default for that system, which will presumably also be interoperable with any; third-party library packages on that system. The issues we're getting round are:. a) If libhail.so is prebuilt on a new-ABI system *and* uses std::string, then it can't run against; the libstdc++ on an old-ABI system. b) If libhail.so is prebuilt on an old-ABI system, then it can run against either old-ABI or new-ABI; libstdc++, but if it then gets linked against third-party libraries compiled against new-ABI; headers, you'll have two different flavors of std::string floating around in the same program,; which causes confusion at any interfaceswhich pass std::string around. Now if you want to go further in shipping more of the system, then the question of whether to; ship your own libstdc++ (or libc++) is independent of the choice of compiler version. *If* you ; ship your own libstdc++, then you potentially introduce the problems of interoperability with; other libraries on the system). And there's a slight question about whether your libstdc++ will; work against the other systems libc.so, though I think the ABI at that level has been stable enough for long enough that it probably doesn",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4422#issuecomment-424787941:468,access,access,468,https://hail.is,https://github.com/hail-is/hail/pull/4422#issuecomment-424787941,2,['access'],['access']
Security,">[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-WHEEL-3180413](https://snyk.io/vuln/SNYK-PYTHON-WHEEL-3180413) | `wheel:` <br> `0.30.0 -> 0.38.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2NTQzMzZlYi02MmRmLTQ0ODAtOTFkOS0xZDg4N2FmNmQwMTUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjY1NDMzNmViLTYyZGYtNDQ4MC05MWQ5LTFkODg3YWY2ZDAxNSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""654336eb-62df-4480-91d9-1d887af6d015"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:10913,access,access,10913,https://hail.is,https://github.com/hail-is/hail/pull/14205,2,"['access', 'authoriz']","['access', 'authorized']"
Security,">[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-WHEEL-3180413](https://snyk.io/vuln/SNYK-PYTHON-WHEEL-3180413) | `wheel:` <br> `0.30.0 -> 0.38.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3YmFjNzAzOC00ZmQzLTQ3YmItOGUwMy0yNjRmYTUxNDRlNGQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdiYWM3MDM4LTRmZDMtNDdiYi04ZTAzLTI2NGZhNTE0NGU0ZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7bac7038-4fd3-47bb-8e03-264fa5144e4d"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14108:9897,access,access,9897,https://hail.is,https://github.com/hail-is/hail/pull/14108,2,"['access', 'authoriz']","['access', 'authorized']"
Security,">_</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Raise a ClientResponseError instead of an AssertionError for a blank; HTTP Reason Phrase.; <code>[#3532](https://github.com/aio-libs/aiohttp/issues/3532) &lt;https://github.com/aio-libs/aiohttp/issues/3532&gt;</code>_</li>; <li>Fix <code>web_middlewares.normalize_path_middleware</code> behavior for patch without slash.; <code>[#3669](https://github.com/aio-libs/aiohttp/issues/3669) &lt;https://github.com/aio-libs/aiohttp/issues/3669&gt;</code>_</li>; <li>Fix overshadowing of overlapped sub-applications prefixes.; <code>[#3701](https://github.com/aio-libs/aiohttp/issues/3701) &lt;https://github.com/aio-libs/aiohttp/issues/3701&gt;</code>_</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/0a26acc1de9e1b0244456b7881ec16ba8bb64fc3""><code>0a26acc</code></a> Bump aiohttp to v3.7.4 for a security release</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/021c416c18392a111225bc7326063dc4a99a5138""><code>021c416</code></a> Merge branch 'ghsa-v6wp-4m6f-gcjg' into master</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/4ed7c25b537f71c6245bb74d6b20e5867db243ab""><code>4ed7c25</code></a> Bump chardet from 3.0.4 to 4.0.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5333"">#5333</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/b61f0fdffc887df24244ba7bdfe8567c580240ff""><code>b61f0fd</code></a> Fix how pure-Python HTTP parser interprets <code>//</code></li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5c1efbc32c46820250bd25440bb7ea96cb05abe9""><code>5c1efbc</code></a> Bump pre-commit from 2.9.2 to 2.9.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5322"">#5322</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/007507580137efcc0a20391a0792f39b337d9c1a""><code>0075075</code></a> Bump ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10115:6598,secur,security,6598,https://hail.is,https://github.com/hail-is/hail/pull/10115,1,['secur'],['security']
Security,"@armartin is getting (what appears to be) a hang running `import_table` on a table with 3K columns. The problem seems two-fold:; - When you access a tstruct field, it populates the jtype of each field. tstruct.__getitem__ should just get the jtype for the field being accessed. Aside, is there a bug in __getitem__? It isn't adding the type if you index by offset:. ```; def __getitem__(self, item):; if not isinstance(item, str):; item = self._fields[item]; self._add_jtypes(); return self._field_types[item]; ```. - Second, StructExpression.__init__ creates expressions for each field in the constructor. That seems excessive, we should construct the field expressions on demand when they are accessed. It still astounds me how slow py4j is.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4153:140,access,access,140,https://hail.is,https://github.com/hail-is/hail/issues/4153,3,['access'],"['access', 'accessed']"
Security,@ce-carey Do you know which hail version hash you were running?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508#issuecomment-388847560:41,hash,hash,41,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-388847560,1,['hash'],['hash']
Security,"@chrisvittal This will fix your define_function issue. I was wrong, the types were the same. @danking Something very strange is going on here. I can verify only one GenomeReference is being constructed, so this and concrete must be the same object, but eq is returning false. I don't see how this can be possible. I some something similar last week which caused me to add ReferenceGenome.hashCode (we were defining one but not the other). However, that shouldn't matter because there was only one reference genome object, but two different pointers captured at different times were returning different values of hashCode. I don't see how that's possible but I don't see an alternate explanation. This fixes the immediate bug. I think ReferenceGenome shouldn't be a case class, and it should only use ref equality (don't override equals, hashCode). That will take a little work because the case class is being used for JSON serialization.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5471:388,hash,hashCode,388,https://hail.is,https://github.com/hail-is/hail/pull/5471,3,['hash'],['hashCode']
Security,"@chrisvittal not sure what this error is. Doesn’t happen on local (on local all tests pass, besides the one that also fails on master, `is.hail.methods.IBDSuite.ibdPlinkSameOnRealVCF`, because I don't have Plink installed). Will try to investigate tomorrow, first step is accessing the log, but if you have suggestions I’m interested!. 2019-05-16 00:23:41 Hail: INFO: test is.hail.expr.ir.ForwardLetsSuite.testAggregators SUCCESS; 2019-05-16 00:23:41 Hail: INFO: starting test is.hail.expr.ir.ForwardLetsSuite.testForwardingOps...; dlopen: /tmp/hail_dJAhNQ/hm_fd419e9b11e18f87ceb4.so: undefined symbol: _ZN4hail2FSC1EP8_jobject",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6083#issuecomment-492892219:272,access,accessing,272,https://hail.is,https://github.com/hail-is/hail/pull/6083#issuecomment-492892219,1,['access'],['accessing']
Security,"@cseed ; I added a secret to default named `ssl-config-hail-root` containing `hail-root-key.pem`, and `hail-root-cert.pem`. Every principal trusts this root. This root trusts every principal. This PR originally prevented clients from speaking to servers with certs they didn't trust. Now everyone trusts everyone. As long as the root key is not leaked this is OK. Only `create_certs` mounts this secret. The key is used to sign every certificate and the cert is included in each principal's incoming and outgoing trust lists. The root certificate and key are never re-created, so our deploys have no downtime and we avoid addressing the rotation problem. I removed all the trust specifications. A later PR will resolve rotation and mTLS. That PR will restore the trust specifications. I didn't change the structure of the secrets (they still have an incoming and outgoing trust list which only contains the root cert) because I need this structure for mTLS anyway. I've updated the PR description with this text so it ends up in the squashed commit.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561#issuecomment-617911061:434,certificate,certificate,434,https://hail.is,https://github.com/hail-is/hail/pull/8561#issuecomment-617911061,2,['certificate'],['certificate']
Security,@cseed ; ```; AccessDeniedException: 403 vdc-sa@hail-vdc.iam.gserviceaccount.com does not have storage.objects.list access to hail-ci-test.; ```. The CI tests use this hail-ci-test bucket as a fake deploy area. We'll need to fix that before we can merge any CI-related PRs.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4603#issuecomment-435938023:14,Access,AccessDeniedException,14,https://hail.is,https://github.com/hail-is/hail/pull/4603#issuecomment-435938023,2,"['Access', 'access']","['AccessDeniedException', 'access']"
Security,"@cseed @tpoterba . this was my solution to wrapping the `registerIR` calls to the function registry as one unit. The `fn` tag at the beginning is more or less just a tag on what the function name was. If this looks ok, maybe we can just expose the ability to create and register these from python (maybe with uids as function names for distinctness) to wrap things like `alt_allele` and other things where the IR gets big and explody.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3538:237,expose,expose,237,https://hail.is,https://github.com/hail-is/hail/pull/3538,1,['expose'],['expose']
Security,"@cseed All set! Still not sure why 0.0.0.0 was needed in this case, but not Dan's config; first assumption is that JupyterLab sets this as default, and not sure. why listening on localhost was insufficient (first guess is that the docker image didn't specify EXPOSE 8888?). Still need to provide finer-grained status updates, based on more than status.phase (inspect container during the MODIFIED watch event). Also. need to re-implement auth_request to deal with (ignore) the ~30 requests subsequent to the redirect.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5243#issuecomment-460097832:259,EXPOSE,EXPOSE,259,https://hail.is,https://github.com/hail-is/hail/pull/5243#issuecomment-460097832,1,['EXPOSE'],['EXPOSE']
Security,@cseed Can you take a look at the last commit and see if this is what you envisioned by securing the api calls with headers instead of cookies?. Stacked on #6288,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6361:88,secur,securing,88,https://hail.is,https://github.com/hail-is/hail/pull/6361,1,['secur'],['securing']
Security,"@cseed One small annoyance is that k8 has restrictions on characterset in labels tighter than ascii. Affects user ids: auth0 concatenates id and social service with a pipe, ex: google-oauth2|something. Also affects notebook naming (smaller concern): I want people to be able to name notebooks, with some human-readable default value, because strings of random numbers and non-alphanumeric characters feel intimidating to non-cs / data-science / similar people, and I don't want them to feel intimidated in anything so trivial, since those intimidated will project that the core product is inaccessible. I can obviously str.replace unwanted characters, and do the transformation on the other end, but this will be fragile and a bit awkward. If we want this kind of thing and want to stay with k8 label-based storage for such things. Not a concern for the demo. Wondering what is better, hash, base64, or move to sql. Regarding hash, auth0 user names are globally unique, so I imagine, but am not certain, that a so-called ""cryptographically secure"" algorithm would be exceedingly unlikely to result in name collisions. For demo, this isn't a problem; I will just str.replace(|, '--_--'), collisions won't happen unintentionally.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215#issuecomment-459208736:886,hash,hash,886,https://hail.is,https://github.com/hail-is/hail/pull/5215#issuecomment-459208736,3,"['hash', 'secur']","['hash', 'secure']"
Security,@cseed The part I am stuck on is the authentication for the router resolver. How does the batch2 instance in a test namespace get access to the real encryption key that the router resolver is expecting? Can you also double check the nginx configuration?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6918:37,authenticat,authentication,37,https://hail.is,https://github.com/hail-is/hail/pull/6918,3,"['access', 'authenticat', 'encrypt']","['access', 'authentication', 'encryption']"
Security,"@cseed This is the IR infrastructure needed for the `groupBy` aggregator. I wrote tests by adding a `KeyedAggregator` so we can use the interpreter. I don't think it is trivial to incorporate `groupBy` into the AST / Parser. Since we're going to rip out the AST soon anyways, I decided to leave the code where it's at and expose it in Python once we can build IRs in Python.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3768:322,expose,expose,322,https://hail.is,https://github.com/hail-is/hail/pull/3768,1,['expose'],['expose']
Security,"@cseed This should now be sufficient for Wed. I will probably add 2 features before then: reconnecting web sockets (though connection should infrequently drop, shouldn't affect workshop), and an admin panel to blow out users / delete notebooks. And maybe SSL. Edit: my commit https://github.com/hail-is/hail/pull/5162/commits/bac155c9713d99c68cd7d0605eb59585656c14ea makes reference to csrf. This may not be necessary: inspecting the login request I notice a nonce, generated by the auth0-js lib, sent with login and silent token rotation / refresh, which is nice. Assuming it's used to prevent replay attacks, in this case it has the same purpose as a CSRF token. Yay auth0. Edit2: Regarding performance. Scorecard page, before server-side caching takes 100ms on refresh, and 50ms on navigation from another page. This effectively means no overhead from my web implementation. Why? It takes ~50ms to return *anything* (including favicon.ico of 0 bytes), i.e 50ms is the time it takes from my computer to kubernetes and back, with no additional work done. We have 2 such requests currently when visiting app.hail.is/scorecard: one to to the web app server, one to scorecard/json. After caching (which is invalidated every 3 minutes), takes 50ms. So, if current scorecard.hail.is needed to hit a json endpoint to get data for its template, we would expect it to be no faster. Alternatively if we placed the json-generating function in the web-app's nodejs server it's response time would drop by ~50ms.; * I also am trying to use the internal DNS (SSR phase routes to http://scorecard/json, so should use kubernetes DNS; still take ~50ms to get the json... before caching).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162#issuecomment-460071524:602,attack,attacks,602,https://hail.is,https://github.com/hail-is/hail/pull/5162#issuecomment-460071524,1,['attack'],['attacks']
Security,"@cseed You're really the only one who understands this well enough to review it. resolves #5168 . In order to create a test, we'd have to expose the pod_name to the clients and the tests would have to talk to k8s to ensure said pod was really deleted. Not a terrible test, but maybe more work than I care to do right now given my other commitments. See the [description of the issue in a comment on #5168](; https://github.com/hail-is/hail/issues/5168#issuecomment-456618542). cc: k8s-and-services team: @jigold @tpoterba @akotlar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5191:138,expose,expose,138,https://hail.is,https://github.com/hail-is/hail/pull/5191,1,['expose'],['expose']
Security,@cseed an issue remains: not sure if this is the cause:. `ls: cannot access 'PARK_HOME/python/lib/py4j-*-src.zip': No such file or directory` as a result of `make test`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5929#issuecomment-485140905:69,access,access,69,https://hail.is,https://github.com/hail-is/hail/pull/5929#issuecomment-485140905,1,['access'],['access']
Security,"@cseed that seems good enough for our purposes. We can run it, unprivileged, on a VM outside of k8s. We have a thin service in k8s that has privilege to talk to that VM. It streams build context and docker file to said VM. That VM invokes `img`. That VM is secure as long as `img` doesn't allow builds to escalate their privileges.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5623#issuecomment-474448122:257,secur,secure,257,https://hail.is,https://github.com/hail-is/hail/pull/5623#issuecomment-474448122,1,['secur'],['secure']
Security,"@cseed: One thing to note. Safari currently has an issue with silent refresh of auth token, due to the way it prevents cross-site tracking. This can be disabled (we could certainly mention this to participants), and other browsers don't appear to have this problem. The solution I recommend for the moment is to pay auth0 ~$15-20/month for a custom domain (we get some additional features as well: https://auth0.com/pricing, including built-in account linking across social providers, which would be nice to not have to write ourselves) ... which will mean that no cross-site cookies are needed. The other approaches involve putting more authentication functionality on our servers, which will be more work for us, and cost much more than $250/year in developer time. Auth0 is also working on a more community-friendly fix (an authentication standard that is exempt from this kind of cross-site cookie block). I've also posted a request for their opinion on the matter in our case specifically.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162#issuecomment-460040357:638,authenticat,authentication,638,https://hail.is,https://github.com/hail-is/hail/pull/5162#issuecomment-460040357,2,['authenticat'],['authentication']
Security,"@daniel-goldstein After this lands in main, can we do a lets encrypt rotation just to smoke test that flow while this is all front of find? Thanks!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12095#issuecomment-1255548750:61,encrypt,encrypt,61,https://hail.is,https://github.com/hail-is/hail/pull/12095#issuecomment-1255548750,1,['encrypt'],['encrypt']
Security,"@daniel-goldstein Can you take a look at the changes in the first query and see if the addition of the audit helps at all? I didn't change the second one as it was a lot of work to do the first and if it's not the right approach, then no need to waste time rewriting that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13213#issuecomment-1613498289:103,audit,audit,103,https://hail.is,https://github.com/hail-is/hail/pull/13213#issuecomment-1613498289,1,['audit'],['audit']
Security,@daniel-goldstein I added an exit 1 after argument validation and removed the test-dataproc and wheel dependencies in the Makefile to demonstrate the functionality in these examples:. ```sh; # HAIL_PIP_VERSION=0.2.123 \; HAIL_VERSION=0.2.123-abcdef123 \ ; GIT_VERSION=abcdef123 \; REMOTE=origin \; WHEEL=/path/to/the.whl \; GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file \; HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc \; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc \; HAIL_GENETICS_HAIL_IMAGE_PY_3_11=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc \; HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc \; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc \; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc \; WHEEL_FOR_AZURE= \; WEBSITE_TAR=/path/to/www.tar.gz \; hail/scripts/release.sh. +++ dirname -- hail/scripts/release.sh; ++ cd -- hail/scripts; ++ pwd; + SCRIPT_DIR=/Users/dking/projects/hail/hail/scripts; + arguments='HAIL_PIP_VERSION HAIL_VERSION GIT_VERSION REMOTE WHEEL GITHUB_OAUTH_HEADER_FILE HAIL_GENETICS_HAIL_IMAGE HAIL_GENETICS_HAIL_IMAGE_PY_3_10 HAIL_GENETICS_HAIL_IMAGE_PY_3_11 HAIL_GENETICS_HAILTOP_IMAGE HAIL_GENETICS_VEP_GRCH37_85_IMAGE HAIL_GENETICS_VEP_GRCH38_95_IMAGE WHEEL_FOR_AZURE WEBSITE_TAR'; + for varname in '$arguments'; + '[' -z 0.2.123 ']'; + echo HAIL_PIP_VERSION=0.2.123; HAIL_PIP_VERSION=0.2.123; + for varname in '$arguments'; + '[' -z 0.2.123-abcdef123 ']'; + echo HAIL_VERSION=0.2.123-abcdef123; HAIL_VERSION=0.2.123-abcdef123; + for varname in '$arguments'; + '[' -z abcdef123 ']'; + echo GIT_VERSION=abcdef123; GIT_VERSION=abcdef123; + for varname in '$arguments'; + '[' -z origin ']'; + echo REMOTE=origin; REMOTE=o,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:51,validat,validation,51,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,1,['validat'],['validation']
Security,@daniel-goldstein I found an error in async_cancel that was exposed by the new version of nest_asyncio. I'm 99% sure the change is correct. Feel free to ask Dan to double check it. The issue was that `fetch_coro` is a Task and not a Future. Cancelling a task just adds the cancellation event to the event loop. You have to actually wait for it to finish before the state of the task will be cancelled. Dan wrote a bunch of tests that asserted `cancel` results in `cancelled == True`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10705#issuecomment-888513583:60,expose,exposed,60,https://hail.is,https://github.com/hail-is/hail/pull/10705#issuecomment-888513583,1,['expose'],['exposed']
Security,"@daniel-goldstein sorry I was a dummy, what I had didn't actually do what I thought it did. It's a bit complex to get access to test information in a fixture, but there's some docs on how to do it. I did that. Now the fixture checks and only tears down a batch when the test failed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13326#issuecomment-1664664775:118,access,access,118,https://hail.is,https://github.com/hail-is/hail/pull/13326#issuecomment-1664664775,1,['access'],['access']
Security,"@danking : added security flags (httponly, secure, samesite). should be ready +/- if Cotton wants me to add a cookie field that stores the Kubernetes secret path, or whether we can have that stored under the user's Kubernetes namespace.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5633#issuecomment-474511788:17,secur,security,17,https://hail.is,https://github.com/hail-is/hail/pull/5633#issuecomment-474511788,2,['secur'],"['secure', 'security']"
Security,@danking @daniel-goldstein Do we want this endpoint to be public? I think we should add the authorized users only decorator.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11559#issuecomment-1065308519:92,authoriz,authorized,92,https://hail.is,https://github.com/hail-is/hail/pull/11559#issuecomment-1065308519,1,['authoriz'],['authorized']
Security,@danking Can you let me know what I'm supposed to do here with these security errors? Thanks!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12794#issuecomment-1505755543:69,secur,security,69,https://hail.is,https://github.com/hail-is/hail/pull/12794#issuecomment-1505755543,1,['secur'],['security']
Security,"@danking Could you please look at the comments and changes made to this repo? I would also like to focus on making the smallest set of changes necessary. Some of the comments appear to be better suited for future PRs, for instance differences in architectural preferences (whether or not a user_id should be validated at this layer, whether the marshaling function could be written to more resemble something you find idiomatic) that don't affect the ability of the web client to consume a valid response. . This PR is getting quite hard to follow, so I'd like to get a summary of what remaining needs to be addressed for you to accept.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215#issuecomment-464232124:308,validat,validated,308,https://hail.is,https://github.com/hail-is/hail/pull/5215#issuecomment-464232124,1,['validat'],['validated']
Security,"@danking Curious for your thoughts on this refactor. I was getting pretty turned around myself with the various credential classes and I think this is closer to what we want in a keyless world. Ideally the batch worker should just be able to request credentials (in the form of an access token) for a given identity with just the identity's ID. LMK if you're in favor of this or not, or if you would like to see it folded into the metadata server PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14125#issuecomment-1879054756:281,access,access,281,https://hail.is,https://github.com/hail-is/hail/pull/14125#issuecomment-1879054756,1,['access'],['access']
Security,"@danking I can now access https://auth.hail.is/user successfully (for the `lgruensc` user), but https://ci.hail.is/batches/3654512 or similar still results in a ""redirected you too many times"" followed by a 401.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11954#issuecomment-1178404584:19,access,access,19,https://hail.is,https://github.com/hail-is/hail/pull/11954#issuecomment-1178404584,1,['access'],['access']
Security,"@danking I noticed the hail-ci-azure automated check failed.; I don't have access to see the root cause, but let me know if I need to change anything.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12951#issuecomment-1531772729:75,access,access,75,https://hail.is,https://github.com/hail-is/hail/pull/12951#issuecomment-1531772729,1,['access'],['access']
Security,@danking I'm getting this error. Do you see any problem with granting that capability to the test service account?. ```; + retry gcloud -q auth activate-service-account '--key-file=/gsa-key/key.json'; + gcloud -q auth activate-service-account '--key-file=/gsa-key/key.json'; Activated service account credentials for: [test-665@hail-vdc.iam.gserviceaccount.com]; + mkdir -p /io/batch/27b395/inputs/wjDTI; + retry gsutil -u hail-vdc -m cp -R gs://hail-services-requester-pays/hello /io/batch/27b395/inputs/wjDTI/hello; + gsutil -u hail-vdc -m cp -R gs://hail-services-requester-pays/hello /io/batch/27b395/inputs/wjDTI/hello; AccessDeniedException: 403 test-665@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; CommandException: 1 file/object could not be transferred.; + sleep 2; + gsutil -u hail-vdc -m cp -R gs://hail-services-requester-pays/hello /io/batch/27b395/inputs/wjDTI/hello; AccessDeniedException: 403 test-665@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; CommandException: 1 file/object could not be transferred.; + sleep 5; + gsutil -u hail-vdc -m cp -R gs://hail-services-requester-pays/hello /io/batch/27b395/inputs/wjDTI/hello; AccessDeniedException: 403 test-665@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; CommandException: 1 file/object could not be transferred.; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9096#issuecomment-662085952:625,Access,AccessDeniedException,625,https://hail.is,https://github.com/hail-is/hail/pull/9096#issuecomment-662085952,6,"['Access', 'access']","['AccessDeniedException', 'access']"
Security,@danking Looks like there are still some failing CDN fetches and a kind of annoying false-positive complaint about URL sanitization.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12269#issuecomment-1270381357:119,sanitiz,sanitization,119,https://hail.is,https://github.com/hail-is/hail/pull/12269#issuecomment-1270381357,1,['sanitiz'],['sanitization']
Security,"@danking Pushed a version that should work on local, now focusing on deployment changes. This is a clean fork; I rolled back all notebook changes to master. notebook-api/notebook/notebook.py is the file to review. Corresponding client pr commit: https://github.com/hail-is/hail/pull/5162/commits/7afc4a5b599a233a4e4b40bb9c7a260b062dd925; - This also includes all CORS bits. With the caveat that this is my first attempt at Kubernetes events, I think this moves things in the right direction. We now have an authenticated, push-notification system for an arbitrary number of notebooks. There are a few issues with it currently, mostly in handling closed web socket connections in gevent, which I will move away from in the iteration after Wednesday, but I handle dead socket errors and they don't *seem* to accumulate over time. I also need to implement a reconnection system on the client. The neat thing about this synchronizes sessions between refresh. So if you have N collaborators all on the same window (or more likely, you have 2 windows open), they will all get consistent state as quickly as Kubernetes knows it. This may not seem useful atm, but it allows us to get really fine-grained view into svc/pod uptime. This also should be much faster, provided we don't overburden the server with watchers (can be solved using server implementation as well), say by using an interval of a second, because we query kubernetes directly, rather than hitting the liveness endpoint by traveling over public internet and then being proxied at the boundary by nginx. We know within ms of the true state. Remaining q is whether this completely replicates the liveness endpoint. I also tried to make the serializing the kubernetes object the domain of the caller; I like this because the called can stop thinking about whether something implements __getitem__, and can specify pretty arbitrary transformations on that data (see lines 172-210, 331, 360, and all other calls to marshall_json), and allows us t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215#issuecomment-459839071:507,authenticat,authenticated,507,https://hail.is,https://github.com/hail-is/hail/pull/5215#issuecomment-459839071,1,['authenticat'],['authenticated']
Security,"@danking So would be curious to get your thoughts. I was initially going to make this change such that instead of these activation tokens the batch worker authenticates with a cloud access token. I had a minor pause though because this means that other workers (even from other namespaces) could potentially impersonate each other, whereas they cannot in our current token system. Is that a concern to you? I suppose we are already pretty compromised if someone gets control of the batch worker's identity, considering the buckets that the batch worker has access to.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13071#issuecomment-1551928272:155,authenticat,authenticates,155,https://hail.is,https://github.com/hail-is/hail/pull/13071#issuecomment-1551928272,3,"['access', 'authenticat']","['access', 'authenticates']"
Security,"@danking This doesn't forbid clashing field names, but accessing the field must use the `struct['items']` syntax. This appears to be what we meant to be doing, but we had a bug. Open to discussion on whether we should just prevent the clashing entirely (but what happens when importing data with a bad field name?).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13498#issuecomment-1693437508:55,access,accessing,55,https://hail.is,https://github.com/hail-is/hail/pull/13498#issuecomment-1693437508,1,['access'],['accessing']
Security,"@danking Unfortunately I didn't get the hash, but I was running whatever version was the default 6 days ago. Started the cluster using `--version devel --spark 2.2.0`, no specific hash specified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508#issuecomment-388871629:40,hash,hash,40,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-388871629,2,['hash'],['hash']
Security,@danking it seems to me that this is exactly the situation for which they exposed `unsafeValueAt`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1566#issuecomment-287549194:74,expose,exposed,74,https://hail.is,https://github.com/hail-is/hail/pull/1566#issuecomment-287549194,1,['expose'],['exposed']
Security,"@danking, @cseed An alternative: [as mentioned in the ticket Dan linked] the acl boundary for pod creation is a namespace. If we scope all user resources to their namespace, and during user resource creation give notebook service account 'create-pod' permissions in the user's namespace, and also remove create pod permissions in the default namespace, we reduce the likelihood that a compromised notebook leader could expose user secrets and other data.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5753#issuecomment-479643234:419,expose,expose,419,https://hail.is,https://github.com/hail-is/hail/pull/5753#issuecomment-479643234,1,['expose'],['expose']
Security,"@gregsmi Looks like the scopes we currently have set are insufficient for reading the storage account keys. Do you know best practice permissions for creating SAS tokens?. ```; The client '96fe73da-25e0-4a69-9cd8-0043e56d0d0a' with object id '96fe73da-25e0-4a69-9cd8-0043e56d0d0a' does not have authorization to perform action 'Microsoft.Storage/storageAccounts/listKeys/action' over scope '/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/haildev/providers/Microsoft.Storage/storageAccounts/hailtest' or the scope is invalid. If access was recently granted, please refresh your credentials.; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13140#issuecomment-1577254412:295,authoriz,authorization,295,https://hail.is,https://github.com/hail-is/hail/pull/13140#issuecomment-1577254412,2,"['access', 'authoriz']","['access', 'authorization']"
Security,"@iris-garden I think you make great points! And I agree, across many PRs we probably do want to be analyzing the security impacts at every stage, not just as a one-off ""when we're done it will be X"" analysis in the ticket... So I guess in my mind the _only_ real reason for using the issue-level review would be for tracking the impact of non-code changes (like configuration updates to production). I will try to make the templates reflect that distinction",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14666#issuecomment-2329290981:113,secur,security,113,https://hail.is,https://github.com/hail-is/hail/pull/14666#issuecomment-2329290981,1,['secur'],['security']
Security,"@jbloom22 sorry, I meant could you include the commit hash in the VDS's name in case we ever have to go back to the commit used to generate it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2173#issuecomment-327467484:54,hash,hash,54,https://hail.is,https://github.com/hail-is/hail/pull/2173#issuecomment-327467484,1,['hash'],['hash']
Security,"@jigold that's a great suggestion. To test that this code is acutally idempotent, I wanted to do this:. Duplicate the test database createDatabase task in `ci/test/resources/build.yaml` (but with a new step name). The jobs have the same parents so they race to run first. They have distinct passwords, so the resulting secret will non-deterministically have the wrong password (e.g. A creates the user, A writes its password first, B ignores already created user, then B writes its password second), but if everything but the secret works, then I'm confident repeated attempts sharing the same secret should work!. Unfortunately, I can't test CI itself in this way because test CIs (whether in dev or in a PR) are not permitted to create databases. I took your suggestion and copied the SQL query out and ran it twice instead. That worked fine. Everything was created once.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8833#issuecomment-631672719:291,password,passwords,291,https://hail.is,https://github.com/hail-is/hail/pull/8833#issuecomment-631672719,4,['password'],"['password', 'passwords']"
Security,"@konradjk This ended up being more work than expected since we had not yet had a function that took a lambda (only had methods that did so). I have it exposed on a branch, but it seems our uniroot functionality is a little bit unexpected. It always returns the right root when there is one, but it fails to identify situations where no root exists. Will require some investigation",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1717#issuecomment-305575523:151,expose,exposed,151,https://hail.is,https://github.com/hail-is/hail/issues/1717#issuecomment-305575523,1,['expose'],['exposed']
Security,"@nawatts points out that the docs are missing the font-awesome icons. This new website; stuff is confusing! Here is how to think about it going forward:. This PR is the *long-term fix*. It will not resolve the current production issue. The easiest fix; for that is to release a new version of Hail, which will generate a new version of the docs. That; new version will be compatible with the currently released `website`. We have two phases: docs-generation-time and serve-time. Importantly, we always need to support the; *previously released documentation* with the current `main` `website`. This PR makes things work like this:. At docs-generation-time (which happens every time we release a new version of the Hail package to; PyPI), Sphinx uses `dynamic-base.html` to build the docs website. Those HTML files will look like; this:. ```; <!DOCTYPE html>; <html lang=""en"">; <head>; <title>Hail | {% block title %}{% endblock %}</title>. {% include ""base-head.html"" %}. <!-- Sphinx will insert some header stuff here -->; </head>; <body>; {% include ""nav-top.html"" %}; <div id=""main"">; {% raw %}; <!-- Sphinx will insert the actual documentation here -->; {% endraw %}; </div>; {% include ""nav-bottom.html"" %}; {% include ""base-foot.html"" %}; </body>; </html>; ```. Note that this is *still a Jinja2 template!*. At serve-time, `website` will run this through Jinja2 templating *a second time*. At this time,; we'll use the latest `base-head.html`. In particular, suppose I need access to a new CSS file in `nav-top.html`. I can modify; `base-head.html`. Since `base-head.html` is added to the web page *at serve-time*, it will include; all the latest changes. In contrast, everything inside the `#main` `div` *only changes when Hail is released* because it is; only updated at docs-generation-time. cc: @daniel-goldstein",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10278:1480,access,access,1480,https://hail.is,https://github.com/hail-is/hail/pull/10278,1,['access'],['access']
Security,"@patrick-schultz, sorry, I missed this in-line comment. For the sake of unifying the discussion, I'll reply in PR comment so we can continue in one thread for both discussions (which I think are intimately related). > Right, but this is on the generic key_by path, and this is no longer an obvious optimization in all cases. I think my real question is: what is the new semantics for key_by? If I want to change my key from [A, B] to [B], then probably it will shuffle and choose balanced partitions, keeping roughly the same amount of parallelism, but if the existing partitioner satisfies a somewhat obscure condition that I don't have much control over, it will instead coalesce partitions.; >; > What if we gate this behavior behind a flag on TableKeyBy, and expose a way to opt in to the optimization in python?. This behavior is only accessible when TableKeyBy isSorted=true. If you've used a hidden field (only accessible through a) my newly exposed `_key_by_assert_sorted` or b) writing IR yourself) to assert that your dataset is already in the order of the new key, I'm certain you would *not* want to shuffle. Moreover, switching from `[A, B]` to `[B]` could very well reduce your effective parallelism even after a shuffle because keys are not permitted to be split across partitions. Consider a dataset keyed by `[Locus, Alleles, Gene]` with 10k partitions. If we re-key to `[Gene]` and we only have 1000 genes annotated, we'll lose partitions. In fact, in the 1:1 partition case (the case we're optimizing here) you *must* lose parallelism because each partition contains exactly one value for the key `B`. Indeed, each partition contains only one record at all!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8864#issuecomment-637177344:763,expose,expose,763,https://hail.is,https://github.com/hail-is/hail/pull/8864#issuecomment-637177344,4,"['access', 'expose']","['accessible', 'expose', 'exposed']"
Security,"@sjparsa I'll take a look! In the future, if you set the ""Assignee"" it shows in my Hail CI queue. You should have access to the Hail CI page now: https://ci.hail.is Your ""queue"" is at https://ci.hail.is/me . It shows you just the PRs you're working on or reviewing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13258#issuecomment-1644475278:114,access,access,114,https://hail.is,https://github.com/hail-is/hail/pull/13258#issuecomment-1644475278,1,['access'],['access']
Security,"@tpoterba @danking We at Databricks are still interested in this. Although Hail's frontend is in Python, it's still useful to publish to maven central. First, it makes the dependency information available. I've seen people write pipelines that are partly in Hail and partly in PySpark and can include Java libraries for things like data sources. There's a lot of tooling for resolving dependency conflicts between different libraries, but they're not very accessible unless all your dependencies are published to maven repos and have dependency poms available. It's also easier to update pipelines to the latest Hail version if the artifacts published to a standard location.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1963#issuecomment-481354319:456,access,accessible,456,https://hail.is,https://github.com/hail-is/hail/issues/1963#issuecomment-481354319,1,['access'],['accessible']
Security,"@tpoterba @jbloom22 a few more things to fix for the workshop. I was using a too powerful kubernetes command to look up worker pods and services for the admin page. I now use a restricted form of it that is permitted by our security policy. We also are missing the non-preemptible node pool (!), so this adds that to our gcp-config. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4862:224,secur,security,224,https://hail.is,https://github.com/hail-is/hail/pull/4862,1,['secur'],['security']
Security,"@tpoterba I don't quite see why anyone should use `hadoop_copy` if their tool supports exporting to a file handle. Unless they're doing some random access, but I think that's much rarer than `df.to_csv(f)` and using `hadoop_copy` for that is silly (AFAIK?).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4644#issuecomment-433528370:148,access,access,148,https://hail.is,https://github.com/hail-is/hail/pull/4644#issuecomment-433528370,1,['access'],['access']
Security,@tpoterba I just realized I forgot to propagate the FUSE config through to worker jobs. Should I be and I got lucky that the singular test is just doing everything driver-side? Or is there a test we can write to ensure that worker jobs access the FASTA data?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12736#issuecomment-1478404495:236,access,access,236,https://hail.is,https://github.com/hail-is/hail/pull/12736#issuecomment-1478404495,1,['access'],['access']
Security,"@tpoterba I realized that hl.index is actually exposed in python, so I added it back in. I don't think it's documented, though.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3662#issuecomment-392173394:47,expose,exposed,47,https://hail.is,https://github.com/hail-is/hail/pull/3662#issuecomment-392173394,1,['expose'],['exposed']
Security,"@tpoterba I think write access is necessary to dismiss reviews. I rebased this branch, hopefully should be good to go now. Will probably be making some changes in the near future, but I think it should be fine in experimental for now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4247#issuecomment-423306621:24,access,access,24,https://hail.is,https://github.com/hail-is/hail/pull/4247#issuecomment-423306621,1,['access'],['access']
Security,"@ttbek, thanks for the comment and concern,. > ""the implementations should rely directly on java.util.Random"" Umm, why? From my outsiders perspective I would have assumed that high quality software worked on by the Broad Institute would use a half decent Random Number Generator (RNG). The phrase ""should rely directly on `java.util.Random`"" was referring to not accepting a source of Randomness as a parameter. It was unnecessarily specific, we're sorry that lead to your confusion. We would be happy to accept a pull request that resolves this issue by building an RNG on more theoretically sound primitives as we have done for [hash functions](https://github.com/hail-is/hail/blob/master/src/main/scala/is/hail/utils/HashMethods.scala) or by using an existing efficient random number generator, such as the ones provided by Apache.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2314#issuecomment-384139281:631,hash,hash,631,https://hail.is,https://github.com/hail-is/hail/issues/2314#issuecomment-384139281,2,"['Hash', 'hash']","['HashMethods', 'hash']"
Security,"A checklist of things to make this robust:. - [x] https://github.com/Nealelab/cloudtools/issues/72; - [x] we need more permissions:; ```; ++ cluster start ci-test-4d8a9b262c3687f33359d92afdae693c819dfb09-e9e8a40bb4f0c2337e5088c26186a4da4948bed2 --version devel --spark 2.2.0 --jar build/libs/hail-all-spark.jar --zip build/distributions/hail-python.zip; ERROR: (gcloud.dataproc.clusters.create) PERMISSION_DENIED: Request had insufficient authentication scopes.; ```; - [x] be certain clusters don't stick around. I am not too concerned about the latter. We should look carefully, but it appears that, by default, processes on pods [get 30s notice via TERM](https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods) before they're killed. All `cluster` needs to do is to send google a termination request. Although the command takes forever to exit after `cluster stop`, this is because it waits for the cluster to shut down before returning. I regularly issue `cluster stop` and then force-kill the `cluster` command instead of waiting for the cluster to shutdown.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4241#issuecomment-417653146:439,authenticat,authentication,439,https://hail.is,https://github.com/hail-is/hail/pull/4241#issuecomment-417653146,1,['authenticat'],['authentication']
Security,"A forthcoming change to the hail ci system will introduce deployment. This change adds `hail-ci-deploy.sh` which replicates the [""Deploy Website""](https://ci.hail.is/admin/editRunType.html?id=buildType:HailSourceCode_HailMainline_DeployWebsite&runnerId=RUNNER_29) and [""Deploy Google Cloud""](https://ci.hail.is/admin/editRunType.html?id=buildType:HailSourceCode_HailMainline_DeployDocsAndGoogleCloudSpark220&runnerId=RUNNER_10) TeamCity jobs. My general thinking for deploy jobs from the CI is that, for the time being, we'll hardcode a mapping from GitHub repository to [Kubernetes Secret](https://kubernetes.io/docs/concepts/configuration/secret/). That's where this `/secret/ci.hail.is-web-updater-rsa-key` will come from. Moreover, the CI will always authorize a gcloud account (again with a baked in mapping from GitHub repository to GCP service account) before calling the deploy script. I did not retest the master branch here. Should we do that even though a PR is only merged to master if it passes the tests? Even after locking down merging, there's still the possibility of CI bugs. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4220:755,authoriz,authorize,755,https://hail.is,https://github.com/hail-is/hail/pull/4220,1,['authoriz'],['authorize']
Security,"A job running for five days *could* cause an issue here, so the operator should still be cognizant of that. The; move to access tokens will eliminate that concern anyway. We should not consider system-managed keys because those are managed by Google and not even visible in the; UI. We are not obligated to rotate them (nor are we able, afaik). There are two special secrets which do not conform to the `key.json` naming scheme for their; secret files. I added them as special cases.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13319:121,access,access,121,https://hail.is,https://github.com/hail-is/hail/pull/13319,1,['access'],['access']
Security,"A little chaos testing revealed a database integrity issue. If jobs.state = Running, instance_id must be non-null. I incorrectly had `ON DELETE SET NULL`. Instead, make sure that the instance has been deactivated (which reschedules all jobs, setting state = Ready) before deleting the instance entry. Also, feedback on cancellation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7443:43,integrity,integrity,43,https://hail.is,https://github.com/hail-is/hail/pull/7443,1,['integrity'],['integrity']
Security,"A long-standing fixme in the LocalBackend was to not rely on HadoopFS, which we use with the SparkBackend for compatibility with dataproc and hdfs urls. By default, the HadoopFS doesn't understand gs urls. Users need to install the gcs-hadoop-connector (preinstalled in dataproc) to communicate with google cloud storage. Spark handles supplying credentials to the connector. Issue #13904 is caused by failing to properly supply the gcs-hadoop-connector with credentials in the LocalBackend. In the absence of config, the connector hangs while trying to fetch a token form a non-existant metadata server. The LocalBackend was designed to be a testing ground for lowered and compiled code that would eventually be run on batch, where we use the RouterFS. I propose a pragmatic fix for #13904 that ditches the HadoopFS for all but local filesystem access in the LocalBackend instead of identifying and fixing the root cause. In doing so, I made a couple of changes to how the RouterFS is configured: In the absence of the `HAIL_CLOUD` environment variable, RouterFS can handle gs and az urls iff credentials are not supplied. If the user supplies creditials, we use `HAIL_CLOUD` to decide which cloud to route to. fixes #13904",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14407:846,access,access,846,https://hail.is,https://github.com/hail-is/hail/pull/14407,1,['access'],['access']
Security,A stack trace for posterity:; ```; Caused by: javax.net.ssl.SSLException: Tag mismatch!; 	at sun.security.ssl.Alert.createSSLException(Alert.java:133) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:331) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:274) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:269) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:119) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:97,secur,security,97,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352,10,"['access', 'secur']","['access', 'security']"
Security,"A summary of major changes:; - The genotype schema has changed from pl to px, where px is an Array[Int] that stores probabilifrom pl to px, where px is an Array[Int] that stores probabilities (phred or linear scaled). g.pl and g.dosage are used for accessing the PLs and/or dosages.; - The VariantMetadata includes information about whether the dataset is dosage data; - Can use indexbgen and importbgen to load BGEN files; - Can use importplink to load PLINK binary files; - Can use importgen to load GEN files and exportgen to export data in GEN format; - Reorganized the VCF import/export scripts to the io folder",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/542:249,access,accessing,249,https://hail.is,https://github.com/hail-is/hail/pull/542,1,['access'],['accessing']
Security,"A summary of major changes:; - The genotype schema has changed from pl to px, where px is an Array[Int] that stores probabilifrom pl to px, where px is an Array[Int] that stores probabilities (phred or linear scaled). g.pl and g.dosage are used for accessing the PLs and/or dosages.; - The VariantMetadata includes information about whether the dataset is dosage data; - Can use indexbgen and importbgen to load BGEN files; - Can use importplink to load PLINK binary files; - Can use importgen to load GEN files and exportgen to export data in GEN format; - Reorganized the VCF import/export scripts to the io folder. Fix indentation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/573:249,access,accessing,249,https://hail.is,https://github.com/hail-is/hail/pull/573,1,['access'],['accessing']
Security,A use case is to add the `cloud-platform` scope to allow accessing GCP secrets from within a dataproc script.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10633:57,access,accessing,57,https://hail.is,https://github.com/hail-is/hail/pull/10633,1,['access'],['accessing']
Security,"A very small PR but here's the background and context behind this change. When talking to either GCP or Azure, hail chooses credentials in the following order from highest priority to lowest priority:. 1. An explicit `credential_file` argument passed to the relevant credentials class; 2. An environment variable containing the path to the credentials (`GOOGLE_APPLICATION_CREDENTIALS` or `AZURE_APPLICATION_CREDENTIALS`) (from this you can see why the code that was here is totally redundant); 3. The latent credentials present on the machine. This might be `gcloud` or `az` credentials, or the metadata server if you're on a cloud VM. I'm trying to rid the codebase of most explicit providing of credentials file paths, for two reasons:; - Quality of life. I'm already signed into the cloud with `gcloud` and `az`. I shouldn't need to download some file and provide `AZURE_APPLICATION_CREDENTIALS` to run this test. It should just use the latent credentials.; - We are trying to phase out credentials files altogether for security reasons. These files are long-lived secrets that you really don't want to leak and are currently exposed to users in Batch jobs, so they can be easily exfiltrated. Using the latent credentials on a cloud VM (the metadata server) has the benefit of only issuing short-lived access tokens which last for hours not months, so it's basically always better to use the latent credentials when possible.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13981:1024,secur,security,1024,https://hail.is,https://github.com/hail-is/hail/pull/13981,3,"['access', 'expose', 'secur']","['access', 'exposed', 'security']"
Security,"A way to do this: https://pypi.org/project/secure/0.1.6/. ```python; secure.SecureCookie.aiohttp(; response,; value=""ABC123"",; samesite=False,; path=""/secure"",; expires=24,; ); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7132#issuecomment-535488533:43,secur,secure,43,https://hail.is,https://github.com/hail-is/hail/issues/7132#issuecomment-535488533,4,"['Secur', 'secur']","['SecureCookie', 'secure']"
Security,"AD/microsoft-authentication-extensions-for-python/issues/107"">#107</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/a88fa673af3602fe7c8c922314599b0c245e7add""><code>a88fa67</code></a> Merge branch 'release-1.0.0'</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/bd5b4074dbb7d03c9d91ce6a75378851be92552a""><code>bd5b407</code></a> Update README to reflect the new APIs</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6f77b1e70be086aae752dcf7e08d7f06bcabdcd7""><code>6f77b1e</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/109"">#109</a> from AzureAD/release-1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/50bf9674f9c65229a1573be39ef4ef507eee17fa""><code>50bf967</code></a> MSAL EX for Python 1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6b904af1a3d4fc0e28e3f090fa3dd8492f79e6bf""><code>6b904af</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/110"">#110</a> from AzureAD/persistence-factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/d0696aeb6f65168b1e0d405cd871b80bb101cd76""><code>d0696ae</code></a> Add build_encrypted_persistence() factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/289a94f694645c642ae67b2d5972d3f9fdadb928""><code>289a94f</code></a> Remove old classes that are deprecated for 2 years</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/fa1f45b556341b2c34e9bf63c06a5068571cd337""><code>f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:2596,authenticat,authentication-extensions-for-python,2596,https://hail.is,https://github.com/hail-is/hail/pull/11992,1,['authenticat'],['authentication-extensions-for-python']
Security,AFAIK it is only a matter of deleting old code paths and secrets. I don't believe there is anything blocked on the old authentication tokens existing.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13531#issuecomment-1767090181:119,authenticat,authentication,119,https://hail.is,https://github.com/hail-is/hail/issues/13531#issuecomment-1767090181,1,['authenticat'],['authentication']
Security,"AFAIK, building images should not require access to our private network. Neither should creating passwords. I put both of those on the private network. Eventually, I'd prefer that CI jobs explicitly opt-in to the private network, but for now I put them all on the private network.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9380#issuecomment-686655669:42,access,access,42,https://hail.is,https://github.com/hail-is/hail/pull/9380#issuecomment-686655669,2,"['access', 'password']","['access', 'passwords']"
Security,"AFAIK, none of our CI image builds should need to contact the k8s cluster. That and the create passwords step are the only steps of CI that are not on the private network. Everything else uses k8s.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9380#issuecomment-684063947:95,password,passwords,95,https://hail.is,https://github.com/hail-is/hail/pull/9380#issuecomment-684063947,1,['password'],['passwords']
Security,"Action items for getting this in:; - Delete Docker's copy of an image when deleting an expanded root filesystem; - Try docker save instead of docker export so docker doesn't create a container. If this doesn't work, delete the container before deleting the image; - Pull every time a job is run for authentication purposes; - Up the reserved image cache size to 30",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10648#issuecomment-879462826:299,authenticat,authentication,299,https://hail.is,https://github.com/hail-is/hail/pull/10648#issuecomment-879462826,1,['authenticat'],['authentication']
Security,"Actually, even simpler: . ```; def downsample_matrix_table(mt: hl.MatrixTable, n_divisions: int, p_threshold: float) -> hl.Table:; mt = mt.choose_cols(list(range(10))). x = mt.locus.global_position(); y = -hl.log10(mt.Pvalue). downsampled = mt.annotate_cols(; binned=hl.agg.downsample(; x,; y,; label=hl.str(mt.Pvalue),; n_divisions=n_divisions; ); ; ); downsampled = downsampled.cols(). return downsampled. mt = hl.balding_nichols_model(3, 100, 1000); pmt = mt.annotate_rows(Pvalue = hl.rand_unif(0, 1)); downed = downsample_matrix_table(pmt, 4, .05); downed.show(); ```. I'm now somewhat convinced that the downsample aggregator is accessing cleared memory",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8240#issuecomment-594754052:634,access,accessing,634,https://hail.is,https://github.com/hail-is/hail/issues/8240#issuecomment-594754052,1,['access'],['accessing']
Security,Add AccessLogger which standardizes access logging across our infrastructure and crucially prints the X-Real-IP header. Also includes a fix for the google auth issue and two missing tables from delete_auth_tables.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8102:4,Access,AccessLogger,4,https://hail.is,https://github.com/hail-is/hail/pull/8102,2,"['Access', 'access']","['AccessLogger', 'access']"
Security,Add HashAggregator[T],MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1947:4,Hash,HashAggregator,4,https://hail.is,https://github.com/hail-is/hail/issues/1947,1,['Hash'],['HashAggregator']
Security,Add Julia Goodrich (@jkgoodrich) to authorized users,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11865:36,authoriz,authorized,36,https://hail.is,https://github.com/hail-is/hail/pull/11865,1,['authoriz'],['authorized']
Security,Add TakeSet aggregator (exposed as a `unique=` flag on `take`),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7205:24,expose,exposed,24,https://hail.is,https://github.com/hail-is/hail/issues/7205,1,['expose'],['exposed']
Security,"Add a `hailctl auth` subcommand that prints an access token for the hail service, mirroring the behavior of `gcloud auth application-default print-access-token`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13934:47,access,access,47,https://hail.is,https://github.com/hail-is/hail/pull/13934,2,['access'],"['access', 'access-token']"
Security,"Add a code cache. 50 is was chosen somewhat randomly. Normalize incoming IR so name differences don't case a recompile. Move ApplyIR `conversion` since it shouldn't be involved in equality. Add hashCode to GR because you should always define hashCode, equals as a pair (and it was behaving very strangely without it). @chrisvittal I think this resolves the last of the issues you ran into on Friday.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5426:194,hash,hashCode,194,https://hail.is,https://github.com/hail-is/hail/pull/5426,2,['hash'],['hashCode']
Security,Add a number of hash function families,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2288:16,hash,hash,16,https://hail.is,https://github.com/hail-is/hail/pull/2288,1,['hash'],['hash']
Security,Add billing projects. Billing projects are validated once in /batches/create.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7596:43,validat,validated,43,https://hail.is,https://github.com/hail-is/hail/pull/7596,1,['validat'],['validated']
Security,"Add new command to aggregate and export statistics over intervals with; access to a 'variants' aggregator. Takes an interval list as input,; takes an export command (see exportvariants), and an output path. Exposed `Interval` in the expr language, which has `start`, `end`,; and `contains` (all locus-based). Reworked property-based testing for annotation impexes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/543:72,access,access,72,https://hail.is,https://github.com/hail-is/hail/pull/543,4,"['Expose', 'access']","['Exposed', 'access']"
Security,Add simple- and twisted-tabulation hashes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2304:35,hash,hashes,35,https://hail.is,https://github.com/hail-is/hail/pull/2304,1,['hash'],['hashes']
Security,Add simplest hash functions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2303:13,hash,hash,13,https://hail.is,https://github.com/hail-is/hail/pull/2303,1,['hash'],['hash']
Security,Added LDMatrix computation on VDS's. Did not expose any python api yet. Will do that in subsequent PR.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1775:45,expose,expose,45,https://hail.is,https://github.com/hail-is/hail/pull/1775,1,['expose'],['expose']
Security,"Added `AzureBaseClient.get_next_link` and `AzureBaseClient.delete_and_wait`. ## Batch; - Added `batch.azure` which mirrors the functionality of `batch.gcp`; - Renamed `worker_local_ssd_data_disk` to `local_ssd_data_disk` in the PoolConfig; - Renamed `worker_pd_ssd_data_disk_size_gb` to `external_data_disk_size_gb` in the PoolConfig; - Added {Azure,GCP}UserCredentials to the worker to abstract away the names of environment variables and the mount paths of credentials in containers. ## Auth; - Added new fields in the auth database for `azure service principal name` and `azure_credentials_secret_name`; - Made `auth` only create `GSAResource` if CLOUD == 'gcp'. ## Gear; - Added `azure-vm` to the location options for `DeployConfig`. # Assumptions:; - Mapped `{'lowmen': 'F', 'standard': 'D', 'highmem': 'E'}` for machine types in Azure. This corresponds to 2Gi/core, 4Gi/core, and 8Gi/core.; - Spot price is set to -1 for now until we figure out a better billing strategy; - We look for existing network security groups to tell if a VM has been fully cleaned up already in the garbage collection loop. # To-Do:. ## Services. - Use global config and make an `AzureConfig` (@daniel-goldstein not sure if you're already doing this) instead of optional environment variables; - Azure user disks are not implemented; There's a maximum number of disks that can be mounted per machine type with a maximum of 32 along with figuring out the API calls. We'll need a semaphore of some sort.; - No activity logs loop. Not necessary for initial development and preemption billing is not working how intended anyways (will add to the list to fix!). We also don't track vm creation success rates per zone like we do with GCP. It might be good to look for VM deletion events to remove instances that are no longer present and then do a deep delete as then we'll have some redundancy and faster response times.; - Figure out how to do a deep-delete as much as possible for VMs when using the create VM REST API. T",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10970:1226,secur,security,1226,https://hail.is,https://github.com/hail-is/hail/pull/10970,1,['secur'],['security']
Security,"Added functions to make annotations py4j-convertible.; Exposed global and sample annotations in python. This is the start of a long list of changes that need to be made before our interface starts to actually look nice in python. Doing `annotate_global_expr_by_sample` followed by `show_globals` to do aggregations is horrible -- here you can just do . ```; >>> europeans = vds.query_samples('samples.filter(s => sa.pop == ""EUR"").collect()'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1255:55,Expose,Exposed,55,https://hail.is,https://github.com/hail-is/hail/pull/1255,1,['Expose'],['Exposed']
Security,Added region value accessors to types.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2093:19,access,accessors,19,https://hail.is,https://github.com/hail-is/hail/pull/2093,1,['access'],['accessors']
Security,Added set_va_attributes to expose setting Field attributes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1373:27,expose,expose,27,https://hail.is,https://github.com/hail-is/hail/pull/1373,1,['expose'],['expose']
Security,Added the verification function. Allows a single auth_request to handle both user and notebook authorization checks. . Obviously the MySQL connection handling will change. Relates to https://github.com/hail-is/hail/pull/5162/commits/3114234f51002ce6c477cca40a28c3ebb6ebe759,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215#issuecomment-458849293:95,authoriz,authorization,95,https://hail.is,https://github.com/hail-is/hail/pull/5215#issuecomment-458849293,1,['authoriz'],['authorization']
Security,"Adding a new compiler pass (lowering MatrixIR to TableIR) exposed a problem in Simplify. The logic for preventing some simplifications from triggering if they would introduce non-determinism was broken, and fixing it required a pretty complete overhaul. Fortunately, I think it's now a lot simpler. Besides the rewrite of the high level Simplify architecture, I also:; * Changed `testRepartitioningSimplifyRules` to something that failed in the old version.; * Changed the `copy` signature on the IR hierarchy to be more precise (to avoid unnecessary coercions).; * Grouped the Simplify rules into IR, MatrixIR, and TableIR. After the reorganization, a couple of rule redundancies became evident.; * A couple of vals in PruneSuite required running the compiler. When I had a bug in Simplify, this was causing the test runner to fail before any tests were run, on class initialization of PruneSuite, which gives very little help in diagnosing the issue. I made them lazy vals to prevent this in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4564:58,expose,exposed,58,https://hail.is,https://github.com/hail-is/hail/pull/4564,1,['expose'],['exposed']
Security,"Adding a printout to the requirement, shows that the partitioner's key is not getting trimmed.; ```; java.lang.IllegalArgumentException: requirement failed: struct{locus: locus<GRCh38>} struct{locus: locus<GRCh38>, alleles: array<str>}; ```. ```diff; diff --git a/hail/src/main/scala/is/hail/rvd/RVD.scala b/hail/src/main/scala/is/hail/rvd/RVD.scala; index 88fdc84b3..dcf9a5773 100644; --- a/hail/src/main/scala/is/hail/rvd/RVD.scala; +++ b/hail/src/main/scala/is/hail/rvd/RVD.scala; @@ -43,7 +43,7 @@ class RVD(; self =>; require(crdd.getNumPartitions == partitioner.numPartitions); ; - require(typ.kType.virtualType isIsomorphicTo partitioner.kType); + require(typ.kType.virtualType isIsomorphicTo partitioner.kType, s""${typ.kType.virtualType} ${partitioner.kType}""); ; // Basic accessors; ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8027#issuecomment-581552954:781,access,accessors,781,https://hail.is,https://github.com/hail-is/hail/issues/8027#issuecomment-581552954,1,['access'],['accessors']
Security,"Adding bearer tokens would essentially add an element of expiration. our own issued tokens prove you are that particular instance, the bearer token proves you are the batch worker identity (at least that the batch worker identity requested an access token in the past X minutes)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13071#issuecomment-1552039791:243,access,access,243,https://hail.is,https://github.com/hail-is/hail/pull/13071#issuecomment-1552039791,1,['access'],['access']
Security,Adding to list of PRs I'm going to dev deploy to validate since this is many major versions apart from what we have now.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11517#issuecomment-1061043455:49,validat,validate,49,https://hail.is,https://github.com/hail-is/hail/pull/11517#issuecomment-1061043455,1,['validat'],['validate']
Security,"Adds BlockMatrix sparsify functions for:; - band matrix; - upper/lower triangle (special case of band); - a collection of rectangles. For diagonal band, I switched GridPartitioner.filterBand to go from lower to upper diagonal index, rather than taking a lower and upper bandwidth. This is more general, e.g. the diagonal itself need not be in the band. Band and triangle zero out elements in partially overlapping blocks by default. Rectangles currently only supports dropping whole blocks. Also adds `export_rectangles` for exporting rectangular regions to TSV in parallel.; I use parameters `path_in` and `path_out`, and switched `BlockMatrix.export` to this convention as well from `input` and `output` to avoid using the reserved word `input`. I have not exposed export methods directly on BlockMatrix for now as it'd be very easy for users to needlessly write and read an already written BlockMatrix. I could add these in a later PR with a warning, or we can wait until we've moved to IR and can optimize read followed by export to export on the file. It'd also be good to add compression options (and float formatting options to `export` and `export_rectanges`). Along the way I fixed NaN checking (due to Double.NaN != Double.NaN) on scalar and vector `/` sparse block ops and added NaN and Infinity checking to scalar and vector `*` sparse ops. Together with `sparsify_row_intervals` in the first sparse matrix PR, this PR exposes all the BlockMatrix functionality needed for big LD applications of Kate/Ran and Jacob/Masa.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3539:759,expose,exposed,759,https://hail.is,https://github.com/hail-is/hail/pull/3539,2,['expose'],"['exposed', 'exposes']"
Security,"Adds dbSNP build 154 Hail Tables to datasets API and annotation DB. . The dataset named `dbSNP` includes all fields, and the one named `dbSNP_rsid` only contains locus, alleles, and rsIDs. The process used to generate the tables is outlined in the notebook. I needed to use the GRCh37/38 assembly reports to map contigs from RefSeq accession numbers to chromosomes, and could then import the VCFs. . To make parsing/formatting strings possible after importing the VCFs as MatrixTables, the following `INFO` fields in the VCF headers were changed from `Number=.` to `Number=1`: FREQ, CLNHGVS, CLNVI, CLNORIGIN, CLNSIG, CLNDISB, CLNDN, CLNREVSTAT, CLNACC. . Biallelic and multiallelic variants were present. The multiallelic variants were first filtered out to be split, and then were unioned back with the biallelic variants to create the final tables.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10473:332,access,accession,332,https://hail.is,https://github.com/hail-is/hail/pull/10473,1,['access'],['accession']
Security,"Adds the [1000 Genomes NYGC 30x on GRCh38](https://www.internationalgenome.org/data-portal/data-collection/30x-grch38) autosomes, chrX, and chrY MatrixTables as `1000_Genomes_HighCov_autosomes`, `1000_Genomes_HighCov_chrX`, and `1000_Genomes_HighCov_chrY`. . The `1000_Genomes_HighCov_autosomes` and `1000_Genomes_HighCov_chrX` datasets have phased calls. . [Due to multiple issues](http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/supporting/GRCh38_positions/README_GRCh38_liftover_20170504.txt), the phase 3 GRCh38 versions of the current `1000_Genomes_autosomes`, `1000_Genomes_chrX`, and `1000_Genomes_chrY` datasets have been retracted. They have been renamed to `1000_Genomes_Retracted_autosomes`, `1000_Genomes_Retracted_chrX`, and `1000_Genomes_Retracted_chrY`, respectively. The phase 3 GRCh37 versions of `1000_Genomes_autosomes`, `1000_Genomes_chrX`, and `1000_Genomes_chrY` are not affected and are still accessible as before.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10413:927,access,accessible,927,https://hail.is,https://github.com/hail-is/hail/pull/10413,1,['access'],['accessible']
Security,"Adds the ability to rerun/retry queries from the nearest `CollectDistributedArray` (`CDA`) IR site. Computes a ""Semantic Hash"" of the top-level IR, which is split and shared among the various constituent `CDA` calls in a query. The `CDA` procedure looks in an execution cache for the results of each partition for that call and uses/updates the cache with successful partition computations. . The nature of the staged- lower and execute model means we don't know how many `CDA` calls that will be generated ahead of time. Thus we treat the ""Semantic Hash"" in a similar way to an RNG state variable and generate a key from the Semantic Hash every time every time we encounter a `CDA`. Since an `ExecutionContext` is re-used for multiple queries in tests while a `SemanticHash` is coupled to one query, the two were kept separate. To minimise the amount of manual state handling, the code was transformed to use a ""State"" monad (abstracted as `MonadLower`). Since the `ExecuteContext` is used nearly everywhere the semantic hash is required, the `ExecuteContext` was absorbed into the `MonadLower` interface. `Lower` is a simple, concrete instance of `MonadLower`, and is used to adapt statements into `MonadLower` expressions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13194:121,Hash,Hash,121,https://hail.is,https://github.com/hail-is/hail/pull/13194,4,"['Hash', 'hash']","['Hash', 'hash']"
Security,"Adds the ability to rerun/retry queries from the nearest `CollectDistributedArray` (`CDA`) `IR` site. Computes a ""Semantic Hash"" of the top-level `IR` which is used to generate a key for the various constituent `CDA` calls in a query. The implementation for CDA, `BackendUtils.collectDArray`, uses that key to look into an the execution cache for the results of each partition for that call and uses/updates the cache with successful partition computations. The nature of the staged- lower and execute model means we don't know how many `CDA` calls that will be generated ahead of time. Thus we treat the ""Semantic Hash"" in a similar way to an RNG state variable and generate a key from the Semantic Hash every time every time we encounter a `CDA`. The execution cache is implemented on-top of a local or remote filesystem (configurable via the `HAIL_CACHE_DIR` environment variable). This defaults to `{tmpdir}/hail/{pip-version}`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12954:123,Hash,Hash,123,https://hail.is,https://github.com/hail-is/hail/pull/12954,3,['Hash'],['Hash']
Security,"Adds the split `VariantDataset` representation, where reference block data and variant data are contained in separate `MatrixTable` objects. Functions are accessible via the `hail.vds` submodule, e.g. `hl.vds.sample_qc(vds)`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10698:155,access,accessible,155,https://hail.is,https://github.com/hail-is/hail/pull/10698,1,['access'],['accessible']
Security,"After discussion with @danking, I redesigned this. The PR was failing due to timeouts since we weren't refreshing statuses in `wait` causing everything to loop forever. I split the API up into ""always hit the endpoint"", and ""if you use this function, hit the endpoint at most one time"". I think it's more explicit. We'll want to audit uses of `status()` to ensure that we're using the cached one if possible in several circumstances especially in `hailctl batch` itself, but that can be a future change.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9510#issuecomment-703726796:329,audit,audit,329,https://hail.is,https://github.com/hail-is/hail/pull/9510#issuecomment-703726796,1,['audit'],['audit']
Security,"Ah, yes, ex nihilio, should've taken a latin class. I added these to uncurated:; - [security] enable mTLS for all services; - [security] disable TLS <1.3; - [security] comply with Mozilla's ""modern"" recommendations; - [batch][security] use a separate network for batch's callbacks. ### liveness probes. Ah, that's a good point. I'll rewrite to use curl and the client's own certificate and I'll make sure clients trust themselves. ### root cert. I don't think it is possible in aiohttp to both verify a certificate has a valid chain from a root cert and, separately, exists in a list of trusted certificates. The effect would be that every client would trust every server because every server certificate is signed by the same root certificate. I think using a root cert is quite secure (a big improvement over our current situation!). However, I endeavored in this PR to additionally prevent, for example, a compromised `notebook` from masquerading as `batch`. I agree that additionally verifying that the certificate came from a single root certificate (that we, perhaps, destroy after everything is signed) would additionally prevent a malicious user from inserting their certificates into the trusted certificates list. AFAICT, python's `ssl` module has no support for this verification strategy. We could probably build an SSLContext shim that contained two SSLContexts one with a root cert and one with the trusted certs and require certification verification to pass both. Seems easy to get wrong, so I'm inclined to not take this path. ### trusted cert lists. Yeah, it felt a little silly to duplicate the cert in each secret. However, this seems like the simplest approach if I require each principal to only trust a subset of incoming/outgoing principals. If I had one secret per principal, then I have to modify build.yaml or deployment.yamls if I modify the trust sets. That seemed error prone. If I had one secret with all the certs, then when a service starts up it has to select the tru",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561#issuecomment-617428243:84,secur,security,84,https://hail.is,https://github.com/hail-is/hail/pull/8561#issuecomment-617428243,10,"['certificate', 'secur']","['certificate', 'certificates', 'secure', 'security']"
Security,"Ah. This has nothing to do with notebook2. We have a wildcard DNS entry for *.hail.is so we don't have to modify DNS every time we add/remove a service. However, Let's Encrypt didn't support wildcard certificates when I wrote that code. So anything.hail.is will get a cert error. To fix this we either need to get a wildcard cert or fix the subdomains we use in DNS.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7145#issuecomment-536222416:168,Encrypt,Encrypt,168,https://hail.is,https://github.com/hail-is/hail/pull/7145#issuecomment-536222416,2,"['Encrypt', 'certificate']","['Encrypt', 'certificates']"
Security,"All this `HAIL_AZURE_OAUTH_SCOPE` and `HAIL_IDENTITY_PROVIDER_JSON` are now injected by batch workers by default so we don't need to specify them explicitly in `build.yaml`. Unrelatedly, I don't think `create_dummy_oauth2_client_secret` does anything as `auth-oauth2-client-secret` already exists inside new namespaces.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13570:76,inject,injected,76,https://hail.is,https://github.com/hail-is/hail/pull/13570,1,['inject'],['injected']
Security,"Allows the notebook container to have access to the user's gsa secret key, a necessary step in mounting the user's bucket. I modified `delete_worker_pod` to exclude the V1DeleteOptions, because the signature appears to have changed, and no options were actually provided. ```sh; File ""notebook/notebook.py"", line 443, in delete_worker_pod; kube.client.V1DeleteOptions()); TypeError: delete_namespaced_pod() takes 3 positional arguments but 4 were given; ```. Will double check that I have necessary permissions: its the case when running on local, but I think I will need to update vdc to provide broad secret read access for notebook for this to work on the cluster. Checking now. cc @cseed, @danking, @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5753:38,access,access,38,https://hail.is,https://github.com/hail-is/hail/pull/5753,2,['access'],['access']
Security,"Almost by definition I'd suspect that adding a system administrator is a high security impact (that's not a judgement on you, just a statement about the security boundary getting wider). This is obviously fine in this case because we want you to be a system administrator, but we should let appsec know regardless. They'll also probably want to send you some standard trainings (and maybe background check forms?). I'll ping them.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14717#issuecomment-2400614863:78,secur,security,78,https://hail.is,https://github.com/hail-is/hail/pull/14717#issuecomment-2400614863,2,['secur'],['security']
Security,"Alright, rebased and made the requested change. Noticed one strange thing though. When I do ; `make install-deps`, the print out starts with:. ```; cat: /secrets//pypi-username: No such file or directory; cat: /secrets//pypi-password: No such file or directory; python3 -m pip install -U -r python/requirements.txt -r python/dev-requirements.txt; ```; Obviously that third line makes sense but I don't see why first 2 happen.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6318#issuecomment-501311985:225,password,password,225,https://hail.is,https://github.com/hail-is/hail/pull/6318#issuecomment-501311985,1,['password'],['password']
Security,"Also - when we're ready, someone will need to authorize the final commit SHA in https://ci.hail.is/ for CI to run",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14727#issuecomment-2419840886:46,authoriz,authorize,46,https://hail.is,https://github.com/hail-is/hail/pull/14727#issuecomment-2419840886,1,['authoriz'],['authorize']
Security,"Also for posterity, the reason we need to modify the audit from before was because we didn't completely dedup the resource id, so we cannot assume resource_id == deduped_resource_id in the new v3 table. This applies to all v3 tables and not just the bp_users one.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13117#issuecomment-1563131585:53,audit,audit,53,https://hail.is,https://github.com/hail-is/hail/pull/13117#issuecomment-1563131585,1,['audit'],['audit']
Security,"Also may need to add back annotate_global_expr. Either way include these examples which used to be un the FAQ:. **How do I access an annotation name with white-space in the Hail Expression Language?**. Put the annotation name in back ticks. ```; annotateglobal expr -c 'global.`my variable` = global.`lof count`'; ```. **How do I count the number of samples matching a phenotype annotation?**. ```; annotateglobal expr -c '; global.nMales = samples.count(sa.pheno.sex == ""Male""),; global.nFemales = samples.count(sa.pheno.sex == ""Female""),; global.nSamples = samples.count(true)'; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1349:123,access,access,123,https://hail.is,https://github.com/hail-is/hail/issues/1349,1,['access'],['access']
Security,"Also, FYI - @cseed I had to change the permissions of the worker container to privileged and SYS_ADMIN. This doesn't apply to the user containers. But still we should double check the security implications of this change.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8960#issuecomment-644205887:184,secur,security,184,https://hail.is,https://github.com/hail-is/hail/pull/8960#issuecomment-644205887,1,['secur'],['security']
Security,"Also, I forgot to test that the query that does the audit doesn't lock any tables from writes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11990#issuecomment-1172526665:52,audit,audit,52,https://hail.is,https://github.com/hail-is/hail/pull/11990#issuecomment-1172526665,1,['audit'],['audit']
Security,"Also, I'm forging ahead for the rest of the day at least. I can't seem to figure out where the issue is for the validation errors that I'm seeing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7803#issuecomment-571283839:112,validat,validation,112,https://hail.is,https://github.com/hail-is/hail/pull/7803#issuecomment-571283839,1,['validat'],['validation']
Security,"Also, to be more specific. The scope of work needed is 4 PRs. This is just 1 PR that exposes the REST API and the parser. There's still the list_batches query to implement as well as both UI search boxes with the help dropdown.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12748#issuecomment-1548471068:85,expose,exposes,85,https://hail.is,https://github.com/hail-is/hail/pull/12748#issuecomment-1548471068,1,['expose'],['exposes']
Security,"Although the test is still running now, I am pretty sure the following solution solved the problem. ```; #https://discuss.hail.is/t/i-get-a-negativearraysizeexception-when-loading-a-plink-file/899. export PYSPARK_SUBMIT_ARGS=""--driver-java-options '-XX:hashCode=0' --conf 'spark.executor.extraJavaOptions=-XX:hashCode=0' pyspark-shell"". ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14168#issuecomment-1897770087:253,hash,hashCode,253,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1897770087,2,['hash'],['hashCode']
Security,"Am I strange in that I want to name something what it is (ci, batch, etc.) rather than give everything codenames? The purpose of codenames is to hide and obscure, you know. I think this should be called tutorial. And when it becomes a notebook service, notebook. And when it becomes the Hail service, it should just be the main website. The landing page should be password protected. We should think about whether we want to collect additional information there (e.g. email), although for now I don't think we need to, as everyone who signed up for the next tutorial filled out a questionnaire. I'm getting proxy timeouts. We need an ready endpoint and something on the client side to poll and redirect. Actually, awesome if it doesn't poll but uses, say, websockets, and the server watches the pod for a notification for k8s (or does this and also polls, which seems to be our standard pattern). Should we have an auto-scaling non-preemptible pool and schedule these there? If we do that, to optimize startup time, we should have imagePullPolicy: Never and then pull the image on startup and push it on update. When do you reap jupyter pods? jupyterhub has a simple management console that lets you shut down notebooks. > figure out how to teach flask url_for to use a root other than /. I don't think you can do this dynamically using headers. Blueprints seem to be the answer in Flask: https://stackoverflow.com/questions/18967441/add-a-prefix-to-all-flask-routes/18969161#18969161. Is there a reason you didn't make it a subdomain? I thought we decided we preferred that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4576#issuecomment-431037869:364,password,password,364,https://hail.is,https://github.com/hail-is/hail/pull/4576#issuecomment-431037869,1,['password'],['password']
Security,"An example of a script that currently fails on `main` but passes in this PR:. ```python; import hailtop.batch as hb. def test_python_function(*values):; # making this function smaller with 102 jobs submits successfully?; print(*values); h = hash(values); print(f'Hash is {h}'); # this return is important, otherwise it submits successfully; return h. if __name__ == '__main__':; b = hb.Batch('Scale size recursion test'); # 101 submits, 102 fails; for i in range(101):; j = b.new_python_job(f'Function call {i+1}'); j.call(test_python_function, i + 1). submitted = b.run(wait=False); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14576#issuecomment-2161133045:241,hash,hash,241,https://hail.is,https://github.com/hail-is/hail/pull/14576#issuecomment-2161133045,2,"['Hash', 'hash']","['Hash', 'hash']"
Security,And why can't you just access `mt.globals`? (I guess that's the goal here?),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4027#issuecomment-408647913:23,access,access,23,https://hail.is,https://github.com/hail-is/hail/issues/4027#issuecomment-408647913,1,['access'],['access']
Security,"Another very simple pipeline reported https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/zip.3A.20length.20mismatch . We can get access to these files via Sam B. ```python3; context_mis_freq_ht = hl.read_table(""gs://epi25/misc-data/gnomAD_v4/grch38_context_vep_annotated.v105.prefiltered.missense_freq_ensp.ht""); ensp2uniprot_ht = hl.import_table(""gs://epi-mis-3d/misc/ensp2uniprot_mart_export.ensp2uniprot.txt""). context_mis_freq_ht = context_mis_freq_ht.key_by(""ensp""); ensp2uniprot_ht = ensp2uniprot_ht.key_by(""ensp""). context_mis_freq_ht = context_mis_freq_ht.annotate(; uniprot = ensp2uniprot_ht[context_mis_freq_ht.ensp].uniprot); ```. notice that the error is removed if you instead use:; ```python3; context_mis_freq_ht = hl.read_table(""gs://epi25/misc-data/gnomAD_v4/grch38_context_vep_annotated.v105.prefiltered.missense_freq_ensp.ht""); ensp2uniprot_ht = hl.import_table(""gs://epi-mis-3d/misc/ensp2uniprot_mart_export.ensp2uniprot.txt""). context_mis_freq_ht = context_mis_freq_ht.key_by(""ensp""); ensp2uniprot_ht = ensp2uniprot_ht.key_by(""ensp""). context_mis_freq_ht = context_mis_freq_ht.join(ensp2uniprot_ht,'left'). ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13486#issuecomment-1883607858:158,access,access,158,https://hail.is,https://github.com/hail-is/hail/issues/13486#issuecomment-1883607858,1,['access'],['access']
Security,"Appears unrelated to hail version. JAR and ZIP:; ```; gs://hail-common/builds/0.2/jars/hail-0.2-3b1cb0772301-Spark-2.2.0.jar; gs://hail-common/builds/0.2/python/hail-0.2-3b1cb0772301.zip; ```. In Google Chrome we see 404s for; ```; GET http://localhost:8123/spark/api/v1/applications; ```; which happened repeatedly if you try to evaluate a cell. On the leader node of the spark cluster, `journalctl -u jupyter` shows:; ```; -- Logs begin at Fri 2019-03-01 19:54:49 UTC, end at Fri 2019-03-01 20:11:51 UTC. --; Mar 01 19:59:03 dk-m systemd[1]: Started Jupyter Notebook.; Mar 01 19:59:04 dk-m python[5149]: [I 19:59:04.630 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret; Mar 01 19:59:04 dk-m python[5149]: [W 19:59:04.796 NotebookApp] All authentication is disabled. Anyone who can connect to this server will be able to run code.; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.802 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /etc/jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.803 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /usr/local/etc/jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.804 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /opt/conda/etc/jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.804 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /root/.jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [W 19:59:04.904 NotebookApp] Error loading server extension jupyter_spark; Mar 01 19:59:04 dk-m python[5149]: Traceback (most recent call last):; Mar 01 19:59:04 dk-m python[5149]: File ""/opt/conda/lib/python3.6/site-packages/notebook/notebookapp.p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5505:803,authenticat,authentication,803,https://hail.is,https://github.com/hail-is/hail/issues/5505,1,['authenticat'],['authentication']
Security,Are you saying that a future version of `SparkBackend.executeJSON()` will support the substitution that currently happens through e.g. `parse_table_ir()` without expecting a `java.util.HashMap` to map symbols to Java IR objects?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5340#issuecomment-463377623:185,Hash,HashMap,185,https://hail.is,https://github.com/hail-is/hail/issues/5340#issuecomment-463377623,1,['Hash'],['HashMap']
Security,As a separate follow up PR: we should inject the cloud location into the job's environment so that users' can make choices based on that information.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12221#issuecomment-1269124272:38,inject,inject,38,https://hail.is,https://github.com/hail-is/hail/pull/12221#issuecomment-1269124272,1,['inject'],['inject']
Security,As mentioned in #5448 admins need to enter a separate admin password (basic auth). This can be solved by implementing account roles and/or scopes.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5475:60,password,password,60,https://hail.is,https://github.com/hail-is/hail/issues/5475,1,['password'],['password']
Security,"As part of the ci2 work, I want to set things up so it is possible (and easy!) to spin up independent copies of the entire stack for development, testing and staging. To that end, I'm breaking apart gateway, into gateway and router. Each publicly accessible namespace will have a router, and gateway will only be responsible for stripping encryption and forwarding requests to these routers. Requests like `...mynamespace.internal.hail.is` will get forwarded to the router for `mynamespace`. All other requests will get forwarded to the default namespace router. I will so modify gateway in another PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5867:247,access,accessible,247,https://hail.is,https://github.com/hail-is/hail/pull/5867,2,"['access', 'encrypt']","['accessible', 'encryption']"
Security,"As part of the security POAMs, we'll follow up on this with instructions of making operator devs viewers + ability to assign themselves roles. This is just what I did for Sophie to give access just to the dev namespace.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13347:15,secur,security,15,https://hail.is,https://github.com/hail-is/hail/pull/13347,2,"['access', 'secur']","['access', 'security']"
Security,"Assigning @tpoterba since he (and cotton) have the most context to review this. A few preliminaries:. 1. I noticed the proxy headers were not quite right when you're testing this without SSL or on some non-standard port. `$host` does not include the port, `$http_host` does. `$scheme` returns `http` or `https` depending on how the user connected to gateway; 2. The admin privilege check was too restrictive, if `delete_worker_pod` is called by `/new` there's no need to check admin privs; 3. I realized that the timeout logic wasn't quite right because a misconfigured gateway (I was testing with a broken gateway config) will return 5xx codes, but that doesn't mean the server is alive. We probably should error here, but I'm hesitant to add new error modes so close to a tutorial. Ok, how does this work? Basically, if the gateway cannot connect to the notebook pod, we intercept the error and redirect the user to the ""create new notebook"" webpage. That webpage deletes whatever remains of the users previous notebook pod & service. Here are the pieces:. 1. `recursive_error_pages on;` the internet suggests that without this we cannot use `error_page` with an ""internal"" rule (the `@` rules are internal rules that users cannot directly access); 2. `proxy_connect_timeout` defaults to 60s which is a shit user experience if your pod dies. Honestly, I might set this to 100ms. This is all inside a datacenter.; 3. `proxy_intercept_errors` permits us to use `error_page` with 5xx errors from failing to connect to the proxy. ---. I tested this with a pile of hacks to deploy this into an anonymous namespace in `vdc`. I'm not ready to PR those changes, they need a clean up before others use them. Sometime next week I hope to get that in. Getting it requires some restructuring of `vdc/` and `gateway/` to be more modular.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4974:1242,access,access,1242,https://hail.is,https://github.com/hail-is/hail/pull/4974,1,['access'],['access']
Security,"Assigning to Daniel 2 because the scorecard beacon is tired. This removes the workshop login option (previously agreed upon with Cotton), which makes the login.html page totally useless; so I've converted the login link to hit the old /login POST endpoint, and converted the POST to a GET. I think this is semantically fine, because no credentials (or other data) is actually sent to that endpoint (as workshop password is kaput), making that endpoint solely issue a redirect. Since login.html is gone, I also no longer redirect to it. Instead, unauthorized users are redirected to /error, and I refactored this redirect into a function since it's now used identically in 2 places. I've also imported the jwt library, so that jwt.exceptions.InvalidTokenError is in scope, and made some minor cleanup. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6078:411,password,password,411,https://hail.is,https://github.com/hail-is/hail/pull/6078,1,['password'],['password']
Security,"At time of writing dependabot doesn't have a great way to bulk update dependencies across unrelated lockfiles in the repo, which often require manual intervention because we assert that we're always using the same package version everywhere. It's also just a lot of noise and hogs CI time. We've decided to move to a periodic bulk-update process + using repo Security alerts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14504:359,Secur,Security,359,https://hail.is,https://github.com/hail-is/hail/pull/14504,1,['Secur'],['Security']
Security,Audit RegistryFunctions to ensure that IR generators don't need to include Let statements,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4764:0,Audit,Audit,0,https://hail.is,https://github.com/hail-is/hail/issues/4764,1,['Audit'],['Audit']
Security,"Azure already has a Jupyter system in place, so I worked within that. As a result, I took a very different approach from `hailctl dataproc`. I'm not sure how many of the configuration settings done in `hailctl dataproc` are necessary in Azure. I also do not plan to add special support for any special parameters from Azure. If a user wants to, for example, configure auto-scaling, they can use pass through arguments. There are three files that need to be hosted somewhere: two startup scripts and an Azure-specific wheel file. For the startup scripts, I just rely on GitHub tagged raw files. For the wheel file, I placed it in hail common and use the public HTTP endpoint. For development, you have to manually upload the files you want to override and invoke `hailctl hdinsight` like this:; ```; hailctl hdinsight; start \; clustername \; password \; password \; storageaccount \; --install-hail-uri https://raw.githubusercontent.com/danking/hail/dk-hdinsight-test/hail/python/hailtop/hailctl/hdinsight/resources/install-hail.sh \; --install-native-deps-uri https://raw.githubusercontent.com/danking/hail/dk-hdinsight-test/hail/python/hailtop/hailctl/hdinsight/resources/install-native-deps.sh \; --wheel-uri https://storage.googleapis.com/hail-common/dking/hail-0.2.79-py3-none-any.whl; ```; We could make this easier, but I'd rather spend that time on the query service. cc: @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11180:842,password,password,842,https://hail.is,https://github.com/hail-is/hail/pull/11180,2,['password'],['password']
Security,"BCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **434/1000** <br/> **Why?** Has a fix available, CVSS 4.4 | Open Redirect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **449/1000** <br/> **Why?** Has a fix available, CVSS 4.7 | Access Restriction Bypass <br/>[SNYK-PYTHON-NOTEBOOK-2928995](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2928995) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **696/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-1086606](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1086606) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-PYGMENTS-1088505](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1088505) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""med",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:4405,Access,Access,4405,https://hail.is,https://github.com/hail-is/hail/pull/13717,2,['Access'],['Access']
Security,"BCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **434/1000** <br/> **Why?** Has a fix available, CVSS 4.4 | Open Redirect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **449/1000** <br/> **Why?** Has a fix available, CVSS 4.7 | Access Restriction Bypass <br/>[SNYK-PYTHON-NOTEBOOK-2928995](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2928995) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **399/1000** <br/> **Why?** Has a fix available, CVSS 3.7 | Race Condition <br/>[SNYK-PYTHON-PROMPTTOOLKIT-6141120](https://snyk.io/vuln/SNYK-PYTHON-PROMPTTOOLKIT-6141120) | `prompt-toolkit:` <br> `1.0.18 -> 3.0.13` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **696/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-1086606](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1086606) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:5097,Access,Access,5097,https://hail.is,https://github.com/hail-is/hail/pull/14205,1,['Access'],['Access']
Security,"Based on conversation in Zulip: https://hail.zulipchat.com/#narrow/stream/123000-general/topic/Server.20hail.20version.20through.20API/near/226462327. Add version endpoint to ~~auth~~ query API. As suggested, I've added the the `make python-version-info` to generate the `hail_version`, but this requires the git history within the docker, as the short commit hash is added to the end. I've just cherry-picked the [merge commit](https://github.com/populationgenomics/hail/commit/700a0cf9d6e05827feca6bdd9c455e2b261e72db) from our populationgenomics fork.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10085:360,hash,hash,360,https://hail.is,https://github.com/hail-is/hail/pull/10085,1,['hash'],['hash']
Security,"Basically, I had no idea how RBAC worked. Now I have some idea. I now feel a bit uneasy about having the test namespace destroyed and recreated by batch deploy. Maybe when I better understand k8s security, I'll change to that. For now, we just grant the minimal permissions to delete any PVCs (i.e. hard drives, i.e. expensive shit) that are sitting around before we deploy a new batch system. I tested that this will succeed with `kubectl can-i --as system:serviceaccount:batch-pods:deploy-svc delete pvc -n test` and `-n batch-pods`. Don't ask my how I found out that the syntax to refer to the deploy-svc service account was that. I don't even remember where I stumbled across that.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5502:196,secur,security,196,https://hail.is,https://github.com/hail-is/hail/pull/5502,1,['secur'],['security']
Security,"Batch threads are closed after at most 30 minutes (meaning no more jobs may be submitted in that batch; ergo, crucially, no more jobs may depend on the output of jobs in the batch). The user can specify a shorter time-to-live via the `ttl` parameter. The batch server achieves this via a [scheduler](https://docs.python.org/3/library/sched.html) thread which runs scheduled events. When a batch is created a close event is scheduled for its TTL. This also exposes `is_open` in the JSON response to `GET /batches/<batch_id>` which the tests use to verify a batch has been closed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5233:456,expose,exposes,456,https://hail.is,https://github.com/hail-is/hail/pull/5233,1,['expose'],['exposes']
Security,"Because in every application I know of, I want the binding not the top-level type. In `str` those coincide, but in the other applications, they don't. For example:. Example 1: From cseed/ordrdd2rb, I needed the type we're aggregating over to copy. I used your idiom, but my solution, it looks like:. ```; registerDependentAggregator(""take"", () => {; val t = TT.t; (n: Int) => new TakeAggregator(t, n); }, ...)(; aggregableHr(TTHr), int32Hr, arrayHr(TTHr)); ```. Yours would look like:. ```; registerDependentAggregator(""take"", (aggt: Type, argt: Type) => (n: Int) => new TakeAggregator(aggt.asInstanceOf[TAggregable].elementType, n), ...)(...); ```; Which do you prefer?. Example 2: this was motivated by the need to access the genome reference in operations on types like Variant, etc. Here's an example, my way:. ```; registerDependentMethod(""inXPar"", () => {; val gr = GR.gr; (x: Variant) => gr.inXPar(x); }, ...)(variantHr(GR), boolHr); ```. and your way:. ```; registerDependentMethod(""inXPar"", (vt: Type) => (x: Variant) => vt.asInstanceOf[Variant].gr.inXPar(v) }, ...)(variantHr(GR), boolHr); ```. This is what I mean by ""digging"". It gets worse, for example, with something like Variant unsplit: `unsplit(Array[Variant(GR)]): Variant(GR)` (assuming unsplit is implemented on the reference, which wouldn't necessarily be the case). I'll reiterate, the main point is that, in all the examples I'm aware of, we actually want the value of the binding directly and not the substituted type.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2226#issuecomment-334160156:717,access,access,717,https://hail.is,https://github.com/hail-is/hail/pull/2226#issuecomment-334160156,1,['access'],['access']
Security,"Both of these were noted by Bernick as a part of his security review. 1. `local_infile`: if this is on, a client could in theory read any file on the instance by loading it into a table.; 2. `skip_show_database`: this disables `SHOW DATABASES` by default; we can still grant certain users (e.g. the admin-pod) the `SHOW DATABASES` privilege. A bit of security by obscurity, IMO, but it does not bother me much. I can always see the list of databases via the GCP console.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12835:53,secur,security,53,https://hail.is,https://github.com/hail-is/hail/pull/12835,2,['secur'],['security']
Security,"Brought up by TJ in a recent conversation. He wants to not use the browser to work on Jupyter notebooks for performance / IDE convenience reasons. From a brief look, there appear to be two issues in getting this to work. First, VS Code will need to be started with proxy flags. As its runtime is Electron, all Chromium flags will work, so could almost specify HAILCTL_CHROME=code hailctl connect ... , but this doesn't directly work because VS Code also needs a workspace (so the cli invocation will need to be slightly different). Second, password-less may not work without `disable_xsrf_check`. Relevant issue: https://github.com/microsoft/vscode-python/issues/7137. There may be ways to hijack a proxied localhost connection, so unless we fully understand those issues, if disable_xsrf_check is necessary to enable password-less, it would be better to generate a token.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9067:540,password,password-less,540,https://hail.is,https://github.com/hail-is/hail/issues/9067,2,['password'],['password-less']
Security,"Builds on #3500 . This PR introduces support for sparse block matrices. The only new command exposed in Python is `sparsify_row_intervals`. Matrix product currently always results in a dense block matrix. Sparse block matrices also support transpose, diagonal, and all non-mathematical operations except filtering. Element-wise mathematical operations are currently supported if and only if they cannot transform zeroed blocks to non-zero blocks. For example, all forms of element-wise multiplication are supported,; and element-wise multiplication results in a sparse block matrix with block support equal to the intersection of that of the operands. On the other hand, scalar addition is not supported, and matrix addition is supported only between block matrices with the same block sparsity. Once this is in, I'll expose a couple more sparsifiers (rectangles, band) and also bring in parallel export of many rectangles to TSV from another branch, so that users can proceed with LD / fine mapping applications. Down the line I plan to support for all operations by expanding to union of block support, or to all blocks, for some operations. And matrix multiplication ought to return the minimal number of blocks as well.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3501:93,expose,exposed,93,https://hail.is,https://github.com/hail-is/hail/pull/3501,2,['expose'],"['expose', 'exposed']"
Security,Builds on: https://github.com/hail-is/hail/pull/2825. added RVD (should be UnpartitionedRVD) and OrderedRVD; allows to add new rvd types (HashedRVD); added list of partition files to current specs (to support safe object storage write strategy in presence of failure),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2828:138,Hash,HashedRVD,138,https://hail.is,https://github.com/hail-is/hail/pull/2828,1,['Hash'],['HashedRVD']
Security,"Bumps [aiohttp-session](https://github.com/aio-libs/aiohttp_session) from 2.7.0 to 2.11.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp_session/releases"">aiohttp-session's releases</a>.</em></p>; <blockquote>; <h2>v2.11.0</h2>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h2>v2.10.0</h2>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp-session/blob/master/CHANGES.txt"">aiohttp-session's changelog</a>.</em></p>; <blockquote>; <h1>2.11.0 (2021-01-31)</h1>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h1>2.10.0 (2021-12-30)</h1>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; <h1>2.9.0 (2019-11-04)</h1>; <ul>; <li>Fix memcached expiring time (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/398"">#398</a>)</li>; </ul>; <h1>2.8.0 (2019-09-17)</h1>; <ul>; <li>Make this compatible with Python 3.7+. Import from collections.abc, instead; of from collections. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/373"">#373</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/af0560812d3dc2043565de1108ac41b65caac7d0""><code>af05608</code></a> Release 2.11 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/673"">#673</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11544:331,Encrypt,EncryptedCookieStorage,331,https://hail.is,https://github.com/hail-is/hail/pull/11544,2,['Encrypt'],['EncryptedCookieStorage']
Security,"Bumps [aiohttp-session](https://github.com/aio-libs/aiohttp_session) from 2.7.0 to 2.12.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp_session/releases"">aiohttp-session's releases</a>.</em></p>; <blockquote>; <h2>v2.12.0</h2>; <ul>; <li>Migrated from <code>aioredis</code> to <code>redis</code> (if using redis without installing; <code>aiohttp-session[aioredis]</code> then it will be necessary to manually install <code>redis</code>).</li>; </ul>; <h2>v2.11.0</h2>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h2>v2.10.0</h2>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp-session/blob/master/CHANGES.txt"">aiohttp-session's changelog</a>.</em></p>; <blockquote>; <h1>2.12.0 (2022-10-28)</h1>; <ul>; <li>Migrated from <code>aioredis</code> to <code>redis</code> (if using redis without installing; <code>aiohttp-session[aioredis]</code> then it will be necessary to manually install <code>redis</code>).</li>; </ul>; <h1>2.11.0 (2021-01-31)</h1>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h1>2.10.0 (2021-12-30)</h1>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; <h1>2.9.0 (2019-11-04)</h1>; <ul>; <li>Fix memcached expiring time (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/398"">#398</a>)</li>; </ul>; <h1>2.8.0 (2019-09-17)</h1>; <ul>; <li>Make this compatible with Python 3.7+. Import from collections.abc, instead; of",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12499:572,Encrypt,EncryptedCookieStorage,572,https://hail.is,https://github.com/hail-is/hail/pull/12499,1,['Encrypt'],['EncryptedCookieStorage']
Security,"Bumps [aiohttp](https://github.com/aio-libs/aiohttp) from 3.8.4 to 3.8.5.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/releases"">aiohttp's releases</a>.</em></p>; <blockquote>; <h2>3.8.5</h2>; <h2>Security bugfixes</h2>; <ul>; <li>; <p>Upgraded the vendored copy of llhttp_ to v8.1.1 -- by :user:<code>webknjaz</code>; and :user:<code>Dreamsorcerer</code>.</p>; <p>Thanks to :user:<code>sethmlarson</code> for reporting this and providing us with; comprehensive reproducer, workarounds and fixing details! For more; information, see; <a href=""https://github.com/aio-libs/aiohttp/security/advisories/GHSA-45c4-8wx5-qw6w"">https://github.com/aio-libs/aiohttp/security/advisories/GHSA-45c4-8wx5-qw6w</a>.</p>; <p>.. _llhttp: <a href=""https://llhttp.org"">https://llhttp.org</a></p>; <p>(<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7346"">#7346</a>)</p>; </li>; </ul>; <h2>Features</h2>; <ul>; <li>; <p>Added information to C parser exceptions to show which character caused the error. -- by :user:<code>Dreamsorcerer</code></p>; <p>(<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7366"">#7366</a>)</p>; </li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>; <p>Fixed a transport is :data:<code>None</code> error -- by :user:<code>Dreamsorcerer</code>.</p>; <p>(<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/3355"">#3355</a>)</p>; </li>; </ul>; <hr />; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/blob/v3.8.5/CHANGES.rst"">aiohttp's changelog</a>.</em></p>; <blockquote>; <h1>3.8.5 (2023-07-19)</h1>; <h2>Security bugfixes</h2>; <ul>; <li>; <p>Upgraded the vendored copy of llhttp_ to v8.1.1 -- by :user:<code>webknjaz</code>; and :user:<code>Dreamsorcerer</code>.</p>; <p>Thanks to :user:<code>sethmlarson</code> for reporting this and providing us with; comprehensive reproducer, workarounds and fixing details! For mo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13270:263,Secur,Security,263,https://hail.is,https://github.com/hail-is/hail/pull/13270,15,"['Secur', 'secur']","['Security', 'security']"
Security,"Bumps [authlib](https://github.com/lepture/authlib) from 0.11 to 0.15.5.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/lepture/authlib/releases"">authlib's releases</a>.</em></p>; <blockquote>; <h2>Version 0.15.5</h2>; <ul>; <li>Make Authlib compatible with latest httpx</li>; <li>Make Authlib compatible with latest werkzeug</li>; <li>Allow customize RFC7523 <code>alg</code> value</li>; </ul>; <h2>Version 0.15.4</h2>; <p>Security fix when JWT claims is None.</p>; <p>For example, JWT payload has <code>iss=None</code>:</p>; <pre><code>{; &quot;iss&quot;: None,; ...; }; </code></pre>; <p>But we need to decode it with claims:</p>; <pre><code>claims_options = {; 'iss': {'essential': True, 'values': ['required']}; }; jwt.decode(token, key, claims_options=claims_options); </code></pre>; <p>It didn't raise an error before this fix.</p>; <h2>Version 0.15.3</h2>; <p>Fixed <code>.authorize_access_token</code> for OAuth 1.0 services, via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/308"">lepture/authlib#308</a></p>; <h2>Version 0.15.2</h2>; <p>Fixed httpx authentication bug via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/283"">#283</a></p>; <h2>Version 0.15.1</h2>; <p>Backward compitable fix for using JWKs in JWT, via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/280"">#280</a>.</p>; <h2>Version 0.15</h2>; <p>This is the last release before v1.0. In this release, we added more RFCs; implementations and did some refactors for JOSE:</p>; <ul>; <li>RFC8037: CFRG Elliptic Curve Diffie-Hellman (ECDH) and Signatures in JSON Object Signing and Encryption (JOSE)</li>; <li>RFC7638: JSON Web Key (JWK) Thumbprint</li>; </ul>; <p>We also fixed bugs for integrations:</p>; <ul>; <li>Fixed support for HTTPX&gt;=0.14.3</li>; <li>Added OAuth clients of HTTPX back via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/270"">#270</a></li>; <li>Fixed parallel t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11483:471,Secur,Security,471,https://hail.is,https://github.com/hail-is/hail/pull/11483,1,['Secur'],['Security']
Security,"Bumps [avro](https://github.com/apache/avro) from 1.11.0 to 1.11.1.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/apache/avro/compare/release-1.11.0...release-1.11.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=avro&package-manager=pip&previous-version=1.11.0&new-version=1.11.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12069:497,secur,security-vulnerabilities,497,https://hail.is,https://github.com/hail-is/hail/pull/12069,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [azure-identity](https://github.com/Azure/azure-sdk-for-python) from 1.6.0 to 1.8.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/Azure/azure-sdk-for-python/releases"">azure-identity's releases</a>.</em></p>; <blockquote>; <h2>azure-identity_1.8.0</h2>; <h2>1.8.0 (2022-03-01)</h2>; <h3>Bugs Fixed</h3>; <ul>; <li>; <p>Handle injected &quot;tenant_id&quot; and &quot;claims&quot; (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23138"">#23138</a>)</p>; <p>&quot;tenant_id&quot; argument in get_token() method is only supported by:</p>; <ul>; <li><code>AuthorizationCodeCredential</code></li>; <li><code>AzureCliCredential</code></li>; <li><code>AzurePowerShellCredential</code></li>; <li><code>InteractiveBrowserCredential</code></li>; <li><code>DeviceCodeCredential</code></li>; <li><code>EnvironmentCredential</code></li>; <li><code>UsernamePasswordCredential</code></li>; </ul>; <p>it is ignored by other types of credentials.</p>; </li>; </ul>; <h3>Other Changes</h3>; <ul>; <li>Python 2.7 is no longer supported. Please use Python version 3.6 or later.</li>; </ul>; <h2>azure-identity_1.8.0b1</h2>; <h2>1.8.0b1 (2022-02-08)</h2>; <h3>Features Added</h3>; <ul>; <li>Added <code>validate_authority</code> support for msal client <a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22625"">#22625</a></li>; <li>Added <code>resource_id</code> support for user-assigned managed identity <a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22329"">#22329</a></li>; <li>Added <code>ClientAssertionCredential</code> support <a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22328"">#22328</a></li>; </ul>; <h3>Other Changes</h3>; <ul>; <li>Python 2.7 is no longer supported. Please use Python version 3.6 or later.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11493:380,inject,injected,380,https://hail.is,https://github.com/hail-is/hail/pull/11493,4,"['Authoriz', 'inject']","['AuthorizationCodeCredential', 'injected']"
Security,"Bumps [azure-storage-blob](https://github.com/Azure/azure-sdk-for-python) from 12.11.0 to 12.13.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/Azure/azure-sdk-for-python/releases"">azure-storage-blob's releases</a>.</em></p>; <blockquote>; <h2>azure-storage-blob_12.13.1</h2>; <h2>12.13.1 (2022-08-04)</h2>; <h3>Bugs Fixed</h3>; <ul>; <li>Fixed two rare issues with ranged blob download when using client-side encryption V1 or V2.</li>; </ul>; <h2>azure-storage-blob_12.13.0</h2>; <h2>12.13.0 (2022-07-07)</h2>; <h3>Bugs Fixed</h3>; <ul>; <li>Stable release of features from 12.13.0b1.</li>; <li>Added support for deleting versions in <code>delete_blobs</code> by supplying <code>version_id</code>.</li>; </ul>; <h2>azure-storage-blob_12.13.0b1</h2>; <h2>12.13.0b1 (2022-06-15)</h2>; <h3>Features Added</h3>; <ul>; <li>Added support for service version 2021-08-06.</li>; <li>Added a new version of client-side encryption for blobs (version 2.0) which utilizes AES-GCM-256 encryption.; If you are currently using client-side encryption, it is <strong>highly recommended</strong> to switch to a form of server-side; encryption (Customer-Provided Key, Encryption Scope, etc.) or version 2.0 of client-side encryption. The encryption; version can be specified on any client constructor via the <code>encryption_version</code> keyword (<code>encryption_version='2.0'</code>).</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/13989b5b1253e26f3f3ee24013a3013fea1bdf73""><code>13989b5</code></a> [Storage] Fix ranged download for client-side encryption (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25522"">#25522</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e90af4374bfd7c139737ad2888fcd269b3023520""><code>e90af43</code></a> DataLake funny dependency (<a href=""https://github-redirect.depen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12109:459,encrypt,encryption,459,https://hail.is,https://github.com/hail-is/hail/pull/12109,2,['encrypt'],['encryption']
Security,"Bumps [azure-storage-blob](https://github.com/Azure/azure-sdk-for-python) from 12.8.1 to 12.10.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/Azure/azure-sdk-for-python/releases"">azure-storage-blob's releases</a>.</em></p>; <blockquote>; <h2>azure-storage-blob_12.10.0</h2>; <h2>12.10.0 (2022-03-08)</h2>; <p>This version and all future versions will require Python 3.6+. Python 2.7 is no longer supported.</p>; <h3>Stable release of preview features</h3>; <ul>; <li>Added support for service version 2021-02-12, 2021-04-10.</li>; <li>Account level SAS tokens now supports two new permissions:; <ul>; <li><code>permanent_delete</code></li>; <li><code>set_immutability_policy</code></li>; </ul>; </li>; <li>Encryption Scope is now supported for Sync Blob Copy (<code>copy_from_url()</code>).</li>; <li>Encryption Scope is now supported as a SAS permission.</li>; <li>Added support for blob names containing invalid XML characters.; Previously \uFFFE and \uFFFF would fail if present in blob name.</li>; <li>Added support for listing system containers with get_blob_containers().</li>; <li>Added support for <code>find_blobs_by_tags()</code> on a container.</li>; <li>Added support for <code>Find (f)</code> container SAS permission.</li>; </ul>; <h3>Bugs Fixed</h3>; <ul>; <li>Added all missing Service SAS permissions.</li>; <li>Fixed a bug that prevented <code>upload_blob()</code> from working with an OS pipe; reader stream on Linux. (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23131"">#23131</a>)</li>; </ul>; <h2>azure-storage-blob_12.10.0b4</h2>; <h2>12.10.0b4 (2022-02-24)</h2>; <h3>Features Added</h3>; <ul>; <li>Updated clients to support both SAS and OAuth together.</li>; <li>Updated OAuth implementation to use the AAD scope returned in a Bearer challenge.</li>; </ul>; <h3>Bugs Fixed</h3>; <ul>; <li>Addressed a few <code>mypy</code> typing hint errors.</li>; </ul>; <h2>azure-storage-blob_12.10.0b3<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11610:756,Encrypt,Encryption,756,https://hail.is,https://github.com/hail-is/hail/pull/11610,2,['Encrypt'],['Encryption']
Security,"Bumps [boto3](https://github.com/boto/boto3) from 1.26.6 to 1.26.8.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/boto/boto3/blob/develop/CHANGELOG.rst"">boto3's changelog</a>.</em></p>; <blockquote>; <h1>1.26.8</h1>; <ul>; <li>api-change:<code>glue</code>: [<code>botocore</code>] Added links related to enabling job bookmarks.</li>; <li>api-change:<code>iot</code>: [<code>botocore</code>] This release add new api listRelatedResourcesForAuditFinding and new member type IssuerCertificates for Iot device device defender Audit.</li>; <li>api-change:<code>license-manager</code>: [<code>botocore</code>] AWS License Manager now supports onboarded Management Accounts or Delegated Admins to view granted licenses aggregated from all accounts in the organization.</li>; <li>api-change:<code>marketplace-catalog</code>: [<code>botocore</code>] Added three new APIs to support tagging and tag-based authorization: TagResource, UntagResource, and ListTagsForResource. Added optional parameters to the StartChangeSet API to support tagging a resource while making a request to create it.</li>; <li>api-change:<code>rekognition</code>: [<code>botocore</code>] Adding support for ImageProperties feature to detect dominant colors and image brightness, sharpness, and contrast, inclusion and exclusion filters for labels and label categories, new fields to the API response, &quot;aliases&quot; and &quot;categories&quot;</li>; <li>api-change:<code>securityhub</code>: [<code>botocore</code>] Documentation updates for Security Hub</li>; <li>api-change:<code>ssm-incidents</code>: [<code>botocore</code>] RelatedItems now have an ID field which can be used for referencing them else where. Introducing event references in TimelineEvent API and increasing maximum length of &quot;eventData&quot; to 12K characters.</li>; </ul>; <h1>1.26.7</h1>; <ul>; <li>api-change:<code>autoscaling</code>: [<code>botocore</code>] This release adds a new price capacity optimized al",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12458:566,Audit,Audit,566,https://hail.is,https://github.com/hail-is/hail/pull/12458,2,"['Audit', 'authoriz']","['Audit', 'authorization']"
Security,"Bumps [boto3](https://github.com/boto/boto3) from 1.26.7 to 1.26.15.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/boto/boto3/blob/develop/CHANGELOG.rst"">boto3's changelog</a>.</em></p>; <blockquote>; <h1>1.26.15</h1>; <ul>; <li>bugfix:Endpoints: [<code>botocore</code>] Resolve endpoint with default partition when no region is set</li>; <li>bugfix:s3: [<code>botocore</code>] fixes missing x-amz-content-sha256 header for s3 object lambda</li>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] Adding support for Amazon AppFlow to transfer the data to Amazon Redshift databases through Amazon Redshift Data API service. This feature will support the Redshift destination connector on both public and private accessible Amazon Redshift Clusters and Amazon Redshift Serverless.</li>; <li>api-change:<code>kinesisanalyticsv2</code>: [<code>botocore</code>] Support for Apache Flink 1.15 in Kinesis Data Analytics.</li>; </ul>; <h1>1.26.14</h1>; <ul>; <li>api-change:<code>route53</code>: [<code>botocore</code>] Amazon Route 53 now supports the Asia Pacific (Hyderabad) Region (ap-south-2) for latency records, geoproximity records, and private DNS for Amazon VPCs in that region.</li>; </ul>; <h1>1.26.13</h1>; <ul>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] AppFlow provides a new API called UpdateConnectorRegistration to update a custom connector that customers have previously registered. With this API, customers no longer need to unregister and then register a connector to make an update.</li>; <li>api-change:<code>auditmanager</code>: [<code>botocore</code>] This release introduces a new feature for Audit Manager: Evidence finder. You can now use evidence finder to quickly query your evidence, and add the matching evidence results to an assessment report.</li>; <li>api-change:<code>chime-sdk-voice</code>: [<code>botocore</code>] Amazon Chime Voice Connector, Voice Connector Group and PSTN Audio Service APIs ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12498:766,access,accessible,766,https://hail.is,https://github.com/hail-is/hail/pull/12498,1,['access'],['accessible']
Security,"Bumps [boto3](https://github.com/boto/boto3) from 1.26.7 to 1.26.17.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/boto/boto3/blob/develop/CHANGELOG.rst"">boto3's changelog</a>.</em></p>; <blockquote>; <h1>1.26.17</h1>; <ul>; <li>bugfix:dynamodb: Fixes duplicate serialization issue in DynamoDB BatchWriter</li>; <li>api-change:<code>backup</code>: [<code>botocore</code>] AWS Backup introduces support for legal hold and application stack backups. AWS Backup Audit Manager introduces support for cross-Region, cross-account reports.</li>; <li>api-change:<code>cloudwatch</code>: [<code>botocore</code>] Update cloudwatch client to latest version</li>; <li>api-change:<code>drs</code>: [<code>botocore</code>] Non breaking changes to existing APIs, and additional APIs added to support in-AWS failing back using AWS Elastic Disaster Recovery.</li>; <li>api-change:<code>ecs</code>: [<code>botocore</code>] This release adds support for ECS Service Connect, a new capability that simplifies writing and operating resilient distributed applications. This release updates the TaskDefinition, Cluster, Service mutation APIs with Service connect constructs and also adds a new ListServicesByNamespace API.</li>; <li>api-change:<code>efs</code>: [<code>botocore</code>] Update efs client to latest version</li>; <li>api-change:<code>iot-data</code>: [<code>botocore</code>] This release adds support for MQTT5 properties to AWS IoT HTTP Publish API.</li>; <li>api-change:<code>iot</code>: [<code>botocore</code>] Job scheduling enables the scheduled rollout of a Job with start and end times and a customizable end behavior when end time is reached. This is available for continuous and snapshot jobs. Added support for MQTT5 properties to AWS IoT TopicRule Republish Action.</li>; <li>api-change:<code>iotwireless</code>: [<code>botocore</code>] This release includes a new feature for customers to calculate the position of their devices by adding three new APIs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12507:503,Audit,Audit,503,https://hail.is,https://github.com/hail-is/hail/pull/12507,1,['Audit'],['Audit']
Security,"Bumps [certifi](https://github.com/certifi/python-certifi) from 2022.9.24 to 2022.12.7.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/certifi/python-certifi/commit/9e9e840925d7b8e76c76fdac1fab7e6e88c1c3b8""><code>9e9e840</code></a> 2022.12.07</li>; <li>See full diff in <a href=""https://github.com/certifi/python-certifi/compare/2022.09.24...2022.12.07"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=certifi&package-manager=pip&previous-version=2022.9.24&new-version=2022.12.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12549:675,secur,security-vulnerabilities,675,https://hail.is,https://github.com/hail-is/hail/pull/12549,6,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [certifi](https://github.com/certifi/python-certifi) from 2023.5.7 to 2023.7.22.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/certifi/python-certifi/commit/8fb96ed81f71e7097ed11bc4d9b19afd7ea5c909""><code>8fb96ed</code></a> 2023.07.22</li>; <li><a href=""https://github.com/certifi/python-certifi/commit/afe77220e0eaa722593fc5d294213ff5275d1b40""><code>afe7722</code></a> Bump actions/setup-python from 4.6.1 to 4.7.0 (<a href=""https://redirect.github.com/certifi/python-certifi/issues/230"">#230</a>)</li>; <li><a href=""https://github.com/certifi/python-certifi/commit/2038739ad56abec7aaddfa90ad2ce6b3ed7f5c7b""><code>2038739</code></a> Bump dessant/lock-threads from 3.0.0 to 4.0.1 (<a href=""https://redirect.github.com/certifi/python-certifi/issues/229"">#229</a>)</li>; <li><a href=""https://github.com/certifi/python-certifi/commit/44df761f4c09d19f32b3cc09208a739043a5e25b""><code>44df761</code></a> Hash pin Actions and enable dependabot (<a href=""https://redirect.github.com/certifi/python-certifi/issues/228"">#228</a>)</li>; <li>See full diff in <a href=""https://github.com/certifi/python-certifi/compare/2023.05.07...2023.07.22"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=certifi&package-manager=pip&previous-version=2023.5.7&new-version=2023.7.22)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will rec",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13298:936,Hash,Hash,936,https://hail.is,https://github.com/hail-is/hail/pull/13298,6,['Hash'],['Hash']
Security,"Bumps [cffi](http://cffi.readthedocs.org) from 1.15.0 to 1.15.1. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cffi&package-manager=pip&previous-version=1.15.0&new-version=1.15.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12004:296,secur,security-vulnerabilities,296,https://hail.is,https://github.com/hail-is/hail/pull/12004,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [cryptography](https://github.com/pyca/cryptography) from 38.0.4 to 39.0.1.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pyca/cryptography/blob/main/CHANGELOG.rst"">cryptography's changelog</a>.</em></p>; <blockquote>; <p>39.0.1 - 2023-02-07</p>; <pre><code>; * **SECURITY ISSUE** - Fixed a bug where ``Cipher.update_into`` accepted Python; buffer protocol objects, but allowed immutable buffers. **CVE-2023-23931**; * Updated Windows, macOS, and Linux wheels to be compiled with OpenSSL 3.0.8.; <p>.. _v39-0-0:</p>; <p>39.0.0 - 2023-01-01; </code></pre></p>; <ul>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for OpenSSL 1.1.0 has been removed.; Users on older version of OpenSSL will need to upgrade.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Dropped support for LibreSSL &lt; 3.5. The new; minimum LibreSSL version is 3.5.0. Going forward our policy is to support; versions of LibreSSL that are available in versions of OpenBSD that are; still receiving security support.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Removed the <code>encode_point</code> and; <code>from_encoded_point</code> methods on; :class:<code>~cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicNumbers</code>,; which had been deprecated for several years.; :meth:<code>~cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicKey.public_bytes</code>; and; :meth:<code>~cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicKey.from_encoded_point</code>; should be used instead.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for using MD5 or SHA1 in; :class:<code>~cryptography.x509.CertificateBuilder</code>, other X.509 builders, and; PKCS7 has been removed.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Dropped support for macOS 10.10 and 10.11, macOS; users must upgrade to 10.12 or newer.</li>; <li><strong>ANNOUNCEMENT:</strong> The next version of <code>cryptography</code> (40.0) will change;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12668:314,SECUR,SECURITY,314,https://hail.is,https://github.com/hail-is/hail/pull/12668,8,"['SECUR', 'secur']","['SECURITY', 'security']"
Security,"Bumps [cryptography](https://github.com/pyca/cryptography) from 40.0.2 to 41.0.0.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pyca/cryptography/blob/main/CHANGELOG.rst"">cryptography's changelog</a>.</em></p>; <blockquote>; <p>41.0.0 - 2023-05-30</p>; <pre><code>; * **BACKWARDS INCOMPATIBLE:** Support for OpenSSL less than 1.1.1d has been; removed. Users on older version of OpenSSL will need to upgrade.; * **BACKWARDS INCOMPATIBLE:** Support for Python 3.6 has been removed.; * **BACKWARDS INCOMPATIBLE:** Dropped support for LibreSSL &lt; 3.6.; * Updated the minimum supported Rust version (MSRV) to 1.56.0, from 1.48.0.; * Updated Windows, macOS, and Linux wheels to be compiled with OpenSSL 3.1.1.; * Added support for the :class:`~cryptography.x509.OCSPAcceptableResponses`; OCSP extension.; * Added support for the :class:`~cryptography.x509.MSCertificateTemplate`; proprietary Microsoft certificate extension.; * Implemented support for equality checks on all asymmetric public key types.; * Added support for ``aes256-gcm@openssh.com`` encrypted keys in; :func:`~cryptography.hazmat.primitives.serialization.load_ssh_private_key`.; * Added support for obtaining X.509 certificate signature algorithm parameters; (including PSS) via; :meth:`~cryptography.x509.Certificate.signature_algorithm_parameters`.; * Support signing :class:`~cryptography.hazmat.primitives.asymmetric.padding.PSS`; X.509 certificates via the new keyword-only argument ``rsa_padding`` on; :meth:`~cryptography.x509.CertificateBuilder.sign`.; * Added support for; :class:`~cryptography.hazmat.primitives.ciphers.aead.ChaCha20Poly1305`; on BoringSSL.; <p>.. _v40-0-2:; </code></pre></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/c4d494fd3ee907316bd846e90cbf4a8df75a25ac""><code>c4d494f</code></a> 41.0.0 version bump (<a href=""https://redirect.github.com/pyca/cryptography/issues/8991"">#8",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13141:942,certificate,certificate,942,https://hail.is,https://github.com/hail-is/hail/pull/13141,3,['certificate'],['certificate']
Security,"Bumps [cryptography](https://github.com/pyca/cryptography) from 40.0.2 to 41.0.1.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pyca/cryptography/blob/main/CHANGELOG.rst"">cryptography's changelog</a>.</em></p>; <blockquote>; <p>41.0.1 - 2023-06-01</p>; <pre><code>; * Temporarily allow invalid ECDSA signature algorithm parameters in X.509; certificates, which are generated by older versions of Java.; * Allow null bytes in pass phrases when serializing private keys.; <p>.. _v41-0-0:</p>; <p>41.0.0 - 2023-05-30; </code></pre></p>; <ul>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for OpenSSL less than 1.1.1d has been; removed. Users on older version of OpenSSL will need to upgrade.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for Python 3.6 has been removed.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Dropped support for LibreSSL &lt; 3.6.</li>; <li>Updated the minimum supported Rust version (MSRV) to 1.56.0, from 1.48.0.</li>; <li>Updated Windows, macOS, and Linux wheels to be compiled with OpenSSL 3.1.1.</li>; <li>Added support for the :class:<code>~cryptography.x509.OCSPAcceptableResponses</code>; OCSP extension.</li>; <li>Added support for the :class:<code>~cryptography.x509.MSCertificateTemplate</code>; proprietary Microsoft certificate extension.</li>; <li>Implemented support for equality checks on all asymmetric public key types.</li>; <li>Added support for <code>aes256-gcm@openssh.com</code> encrypted keys in; :func:<code>~cryptography.hazmat.primitives.serialization.load_ssh_private_key</code>.</li>; <li>Added support for obtaining X.509 certificate signature algorithm parameters; (including PSS) via; :meth:<code>~cryptography.x509.Certificate.signature_algorithm_parameters</code>.</li>; <li>Support signing :class:<code>~cryptography.hazmat.primitives.asymmetric.padding.PSS</code>; X.509 certificates via the new keyword-only argument <code>rsa_padding</code> on; :meth:<code>~cryptography.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13146:385,certificate,certificates,385,https://hail.is,https://github.com/hail-is/hail/pull/13146,1,['certificate'],['certificates']
Security,"Bumps [cryptography](https://github.com/pyca/cryptography) from 41.0.1 to 41.0.2.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pyca/cryptography/blob/main/CHANGELOG.rst"">cryptography's changelog</a>.</em></p>; <blockquote>; <p>41.0.2 - 2023-07-10</p>; <pre><code>; * Fixed bugs in creating and parsing SSH certificates where critical options; with values were handled incorrectly. Certificates are now created correctly; and parsing accepts correct values as well as the previously generated; invalid forms with a warning. In the next release, support for parsing these; invalid forms will be removed.; <p>.. _v41-0-1:; </code></pre></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/7431db737cf0407560fac689d24f1d2e5efc349d""><code>7431db7</code></a> bump for 41.0.2 (<a href=""https://redirect.github.com/pyca/cryptography/issues/9215"">#9215</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/e190ef190525999d1f599cf8c3aef5cb7f3a8bc4""><code>e190ef1</code></a> Backport ssh cert fix (<a href=""https://redirect.github.com/pyca/cryptography/issues/9211"">#9211</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/bb204c8ca7bc0df0c24b6f6c1f59ed5f5bee9226""><code>bb204c8</code></a> Backport: Added PyPy 3.10 to CI (<a href=""https://redirect.github.com/pyca/cryptography/issues/8933"">#8933</a>) (<a href=""https://redirect.github.com/pyca/cryptography/issues/9210"">#9210</a>)</li>; <li>See full diff in <a href=""https://github.com/pyca/cryptography/compare/41.0.1...41.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=41.0.1&new-version=41.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-score",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13244:351,certificate,certificates,351,https://hail.is,https://github.com/hail-is/hail/pull/13244,6,"['Certificate', 'certificate']","['Certificates', 'certificates']"
Security,"Bumps [cryptography](https://github.com/pyca/cryptography) from 41.0.5 to 41.0.6.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pyca/cryptography/blob/main/CHANGELOG.rst"">cryptography's changelog</a>.</em></p>; <blockquote>; <p>41.0.6 - 2023-11-27</p>; <pre><code>; * Fixed a null-pointer-dereference and segfault that could occur when loading; certificates from a PKCS#7 bundle. Credit to **pkuzco** for reporting the; issue. **CVE-2023-49083**; <p>.. _v41-0-5:; </code></pre></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/f09c261ca10a31fe41b1262306db7f8f1da0e48a""><code>f09c261</code></a> 41.0.6 release (<a href=""https://redirect.github.com/pyca/cryptography/issues/9927"">#9927</a>)</li>; <li>See full diff in <a href=""https://github.com/pyca/cryptography/compare/41.0.5...41.0.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=41.0.5&new-version=41.0.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14046:389,certificate,certificates,389,https://hail.is,https://github.com/hail-is/hail/pull/14046,3,['certificate'],['certificates']
Security,"Bumps [docutils](https://docutils.sourceforge.io/) from 0.16 to 0.19. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=docutils&package-manager=pip&previous-version=0.16&new-version=0.19)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12528:301,secur,security-vulnerabilities,301,https://hail.is,https://github.com/hail-is/hail/pull/12528,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [flask-cors](https://github.com/corydolphin/flask-cors) from 3.0.8 to 3.0.9.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/corydolphin/flask-cors/releases"">flask-cors's releases</a>.</em></p>; <blockquote>; <h2>Release 3.0.9</h2>; <h3>Security</h3>; <ul>; <li>Escape path before evaluating resource rules (thanks <a href=""https://github.com/praetorian-colby-morgan""><code>@​praetorian-colby-morgan</code></a>). Prior to this, flask-cors incorrectly; evaluated CORS resource matching before path expansion. E.g. &quot;/api/../foo.txt&quot; would incorrectly match resources for; &quot;/api/*&quot; whereas the path actually expands simply to &quot;/foo.txt&quot;</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/corydolphin/flask-cors/blob/master/CHANGELOG.md"">flask-cors's changelog</a>.</em></p>; <blockquote>; <h2>3.0.9</h2>; <h3>Security</h3>; <ul>; <li>Escape path before evaluating resource rules (thanks to Colby Morgan). Prior to this, flask-cors incorrectly; evaluated CORS resource matching before path expansion. E.g. &quot;/api/../foo.txt&quot; would incorrectly match resources for; &quot;/api/*&quot; whereas the path actually expands simply to &quot;/foo.txt&quot;</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/corydolphin/flask-cors/commit/91babb941e07a1f45636bdcb75675f13ce1503a2""><code>91babb9</code></a> Update Api docs for credentialed requests (<a href=""https://github-redirect.dependabot.com/corydolphin/flask-cors/issues/221"">#221</a>)</li>; <li><a href=""https://github.com/corydolphin/flask-cors/commit/522d98936f3995480fe3132b55415d74298d6790""><code>522d989</code></a> Release version 3.0.9 (<a href=""https://github-redirect.dependabot.com/corydolphin/flask-cors/issues/273"">#273</a>)</li>; <li><a href=""https://github.com/corydolphin/flask-cors/commit/67c4b2cc98ae87cf1fa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10464:289,Secur,Security,289,https://hail.is,https://github.com/hail-is/hail/pull/10464,1,['Secur'],['Security']
Security,"Bumps [follow-redirects](https://github.com/follow-redirects/follow-redirects) from 1.14.7 to 1.14.8.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/3d81dc3237b4ffe8b722bb3d1c70a7866657166e""><code>3d81dc3</code></a> Release version 1.14.8 of the npm package.</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/62e546a99c07c3ee5e4e0718c84a6ca127c5c445""><code>62e546a</code></a> Drop confidential headers across schemes.</li>; <li>See full diff in <a href=""https://github.com/follow-redirects/follow-redirects/compare/v1.14.7...v1.14.8"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=follow-redirects&package-manager=npm_and_yarn&previous-version=1.14.7&new-version=1.14.8)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependab",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11364:482,confidential,confidential,482,https://hail.is,https://github.com/hail-is/hail/pull/11364,6,"['confidential', 'secur']","['confidential', 'security-updates', 'security-vulnerabilities']"
Security,"Bumps [gidgethub](https://github.com/brettcannon/gidgethub) from 4.2.0 to 5.2.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/brettcannon/gidgethub/releases"">gidgethub's releases</a>.</em></p>; <blockquote>; <h2>5.2.1</h2>; <ul>; <li>; <p>Fix cgi and importlib_resources deprecations.; [PR <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/185"">#185</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/pull/185"">brettcannon/gidgethub#185</a>)</p>; </li>; <li>; <p>Add support for Python 3.11 and drop EOL Python 3.6; [PR <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/184"">#184</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/pull/184"">brettcannon/gidgethub#184</a>)</p>; </li>; </ul>; <h2>5.2.0</h2>; <ul>; <li>Make the minimum version of PyJWT be v2.4.0.</li>; </ul>; <h2>5.1.0</h2>; <ul>; <li>; <p>Use <code>X-Hub-Signature-256</code> header for webhook validation when available.; ([PR <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/160"">#160</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/pull/160"">brettcannon/gidgethub#160</a>)).</p>; </li>; <li>; <p>The documentation is now built using Sphinx v&gt;= 4.0.0.; ([Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/143"">#143</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/143"">brettcannon/gidgethub#143</a>))</p>; </li>; <li>; <p><code>gidgethub.abc.GitHubAPI.getiter</code> now accepts <code>iterable_key</code> parameter; in order to support the Checks API.; ([Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/164"">#164</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/164"">brettcannon/gidgethub#164</a>))</p>; </li>; <li>; <p>Accept HTTP 202 ACCEPTED as successful.; ([PR <a href=""https://github",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:1013,validat,validation,1013,https://hail.is,https://github.com/hail-is/hail/pull/12328,1,['validat'],['validation']
Security,"Bumps [htsjdk](https://github.com/samtools/htsjdk) from 2.24.1 to 3.0.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/samtools/htsjdk/releases"">htsjdk's releases</a>.</em></p>; <blockquote>; <h2>3.0.1</h2>; <p>Fix for a long standing vulnerability around temporary directory creation which could expose data to malicious users with access to a shared system. See for more information <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1617"">#1617</a></p>; <p>4a4024a97 Fix temporary directory hijacking or temporary directory information disclosure (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1621"">#1621</a>); 9fd0ecf21 Disable codecov until we can fix the uploader (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1622"">#1622</a>); 347c0ac57 Fix EdgeReadIterator (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1616"">#1616</a>); d15a5bacb Added ULTIMA and ELEMENT as valid value for RG-PL according to SAM spec. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1619"">#1619</a>)</p>; <h2>3.0.0</h2>; <p>Htsjdk 3.0.0: Revenge of the Simple Allele</p>; <p>This is the first htsjdk with a major version increase in a long time. We bumped it to indicate there are some breaking changes that will potentially require downstream code changes. Notably, <code>Allele</code> became an interface instead of a concrete class. <code>SimpleAllele</code> may be used as a replacement if you have classes which previously subclassed allele.</p>; <p>New Plugin Infrastructure:; 6a60de7c2 Move API marker annotations into new annotation package. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1558"">#1558</a>); 7ac95d5f7 Plugin framework and interfaces for versioned file format codecs (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1525"">#1525</a>); d40fe5412 Beta implementation of Bundles. (<a hre",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:345,expose,expose,345,https://hail.is,https://github.com/hail-is/hail/pull/12229,2,"['access', 'expose']","['access', 'expose']"
Security,"Bumps [jinja2](https://github.com/pallets/jinja) from 3.1.2 to 3.1.3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/jinja/releases"">jinja2's releases</a>.</em></p>; <blockquote>; <h2>3.1.3</h2>; <p>This is a fix release for the 3.1.x feature branch.</p>; <ul>; <li>Fix for <a href=""https://github.com/pallets/jinja/security/advisories/GHSA-h5c8-rqwp-cp95"">GHSA-h5c8-rqwp-cp95</a>. You are affected if you are using <code>xmlattr</code> and passing user input as attribute keys.</li>; <li>Changes: <a href=""https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-3"">https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-3</a></li>; <li>Milestone: <a href=""https://github.com/pallets/jinja/milestone/15?closed=1"">https://github.com/pallets/jinja/milestone/15?closed=1</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/jinja/blob/main/CHANGES.rst"">jinja2's changelog</a>.</em></p>; <blockquote>; <h2>Version 3.1.3</h2>; <p>Released 2024-01-10</p>; <ul>; <li>Fix compiler error when checking if required blocks in parent templates are; empty. :pr:<code>1858</code></li>; <li><code>xmlattr</code> filter does not allow keys with spaces. GHSA-h5c8-rqwp-cp95</li>; <li>Make error messages stemming from invalid nesting of <code>{% trans %}</code> blocks; more helpful. :pr:<code>1918</code></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/jinja/commit/d9de4bb215fd1cc8092a410fb834c7c4060b1fc1""><code>d9de4bb</code></a> release version 3.1.3</li>; <li><a href=""https://github.com/pallets/jinja/commit/50124e16561f17f6c1ec85a692f6551418971cdc""><code>50124e1</code></a> skip test pypi</li>; <li><a href=""https://github.com/pallets/jinja/commit/9ea7222ef3f184480be0d0884e30ccfb4172b17b""><code>9ea7222</code></a> use trusted publishing</li>; <li><a href=""https://github.c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14144:371,secur,security,371,https://hail.is,https://github.com/hail-is/hail/pull/14144,3,['secur'],['security']
Security,"Bumps [jinja2](https://github.com/pallets/jinja) from 3.1.3 to 3.1.4.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/jinja/releases"">jinja2's releases</a>.</em></p>; <blockquote>; <h2>3.1.4</h2>; <p>This is the Jinja 3.1.4 security release, which fixes security issues and bugs but does not otherwise change behavior and should not result in breaking changes.</p>; <p>PyPI: <a href=""https://pypi.org/project/Jinja2/3.1.4/"">https://pypi.org/project/Jinja2/3.1.4/</a>; Changes: <a href=""https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-4"">https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-4</a></p>; <ul>; <li>The <code>xmlattr</code> filter does not allow keys with <code>/</code> solidus, <code>&gt;</code> greater-than sign, or <code>=</code> equals sign, in addition to disallowing spaces. Regardless of any validation done by Jinja, user input should never be used as keys to this filter, or must be separately validated first. GHSA-h75v-3vvj-5mfj</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/jinja/blob/main/CHANGES.rst"">jinja2's changelog</a>.</em></p>; <blockquote>; <h2>Version 3.1.4</h2>; <p>Released 2024-05-05</p>; <ul>; <li>The <code>xmlattr</code> filter does not allow keys with <code>/</code> solidus, <code>&gt;</code>; greater-than sign, or <code>=</code> equals sign, in addition to disallowing spaces.; Regardless of any validation done by Jinja, user input should never be used; as keys to this filter, or must be separately validated first.; :ghsa:<code>h75v-3vvj-5mfj</code></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/jinja/commit/dd4a8b5466d8790540c181590b14db4d4d889d57""><code>dd4a8b5</code></a> release version 3.1.4</li>; <li><a href=""https://github.com/pallets/jinja/commit/0668239dc6b44ef38e7a6c9f91f312fd4ca581cb""><",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14526:278,secur,security,278,https://hail.is,https://github.com/hail-is/hail/pull/14526,12,"['secur', 'validat']","['security', 'validated', 'validation']"
Security,"Bumps [jna](https://github.com/java-native-access/jna) from 5.6.0 to 5.12.1.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/java-native-access/jna/blob/master/CHANGES.md"">jna's changelog</a>.</em></p>; <blockquote>; <h1>Release 5.12.1</h1>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1447"">#1447</a>: Null-check cleanable in <code>c.s.j.Memory#close</code> - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; </ul>; <h1>Release 5.12.0</h1>; <h2>Features</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1433"">#1433</a>: Add <code>CFEqual</code>, <code>CFDictionaryRef.ByReference</code>, <code>CFStringRef.ByReference</code> to <code>c.s.j.p.mac.CoreFoundation</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/978"">#978</a>: Remove use of finalizers in JNA and improve concurrency for <code>Memory</code>, <code>CallbackReference</code> and <code>NativeLibrary</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1440"">#1440</a>: Support for LoongArch64 - <a href=""https://github.com/Panxuefeng-loongson""><code>@​Panxuefeng-loongson</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1444"">#1444</a>: Update embedded libffi to 1f14b3fa92d4442a60233e9596ddec428a985e3c and rebuild native libraries - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1438"">#1438</a>: Handle arrays in structures with differing size - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:43,access,access,43,https://hail.is,https://github.com/hail-is/hail/pull/12438,4,['access'],['access']
Security,"Bumps [jupyter-lsp](https://github.com/jupyter-lsp/jupyterlab-lsp) from 2.2.1 to 2.2.2.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter-lsp/jupyterlab-lsp/blob/main/CHANGELOG.md"">jupyter-lsp's changelog</a>.</em></p>; <blockquote>; <h3><code>jupyter-lsp 2.2.2</code></h3>; <ul>; <li>bug fixes:; <ul>; <li>address warning about renamed <code>extension_points</code> (<a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1035"">#1035</a>)</li>; <li>fix compatibility with jupyter server 1.x</li>; <li>fix an authentication-related security vulnerability (see <a href=""https://github.com/jupyter-lsp/jupyterlab-lsp/security/advisories/GHSA-4qhp-652w-c22x"">the advisory</a> for details)</li>; </ul>; </li>; <li>enhancements:; <ul>; <li>add authorization support (<code>lsp</code> resource, jupyter-server v2+ only) - this allows server operators for fine grained access control, e.g. in case if specific users (such as guest or read-only users) should not be allowed to access LSP; this is in addition to authentication fixes</li>; </ul>; </li>; </ul>; <h3><code>@jupyter-lsp/jupyterlab-lsp 5.0.1</code></h3>; <ul>; <li>bug fixes:; <ul>; <li>fix false “undefined name” in <code>%%time</code> and <code>%%capture</code> magics <a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1007"">#1007</a> (thanks <a href=""https://github.com/i-aki-y""><code>@​i-aki-y</code></a>!)</li>; <li>fix completion items for paths and other long items being cut off <a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1025"">#1025</a></li>; <li>workaround issue with markdown lost on edit <a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1016"">#1016</a></li>; <li>fix latex/Greek letters insertion and other completions which do not match prefix (do not pre-filter completions from kernel) <a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1022"">#1022</a></li>; <li>fix completion",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14171:573,authenticat,authentication-related,573,https://hail.is,https://github.com/hail-is/hail/pull/14171,5,"['access', 'authenticat', 'authoriz', 'secur']","['access', 'authentication-related', 'authorization', 'security']"
Security,"Bumps [jupyterlab](https://github.com/jupyterlab/jupyterlab) from 4.0.9 to 4.0.11.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/jupyterlab/jupyterlab/releases"">jupyterlab's releases</a>.</em></p>; <blockquote>; <h2>v4.0.11</h2>; <h2>4.0.11</h2>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/compare/v4.0.10...0708330843fd087134a239d2ad6005b1d543e246"">Full Changelog</a>)</p>; <h3>Security fixes</h3>; <ul>; <li>Potential authentication and CSRF tokens leak in JupyterLab (<a href=""https://github.com/jupyterlab/jupyterlab/security/advisories/GHSA-44cc-43rp-5947"">GHSA-44cc-43rp-5947</a>)</li>; <li>SXSS in Markdown Preview (<a href=""https://github.com/jupyterlab/jupyterlab/security/advisories/GHSA-4m77-cmpx-vjc4"">GHSA-4m77-cmpx-vjc4</a>)</li>; </ul>; <h3>Bugs fixed</h3>; <ul>; <li>Fixes focus indicator on input checkbox for Firefox <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15612"">#15612</a> (<a href=""https://github.com/alden-ilao""><code>@​alden-ilao</code></a>)</li>; </ul>; <h3>Documentation improvements</h3>; <ul>; <li>Fix link to yarn docs in extension migration guide <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15640"">#15640</a> (<a href=""https://github.com/krassowski""><code>@​krassowski</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/graphs/contributors?from=2023-12-29&amp;to=2024-01-19&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Abrichet+updated%3A2023-12-29..2024-01-19&amp;type=Issues""><code>@​brichet</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Afcollonval+updated%3A2023-12-29..2024-01-19&amp;type=Issues""><code>@​fcollonval</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Agithub-actions+updated%3A2023-12-29..2024-01",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14184:438,Secur,Security,438,https://hail.is,https://github.com/hail-is/hail/pull/14184,4,"['Secur', 'authenticat', 'secur']","['Security', 'authentication', 'security']"
Security,"Bumps [keyrings-alt](https://github.com/jaraco/keyrings.alt) from 3.5.2 to 4.2.0.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jaraco/keyrings.alt/blob/main/CHANGES.rst"">keyrings-alt's changelog</a>.</em></p>; <blockquote>; <h1>v4.2.0</h1>; <p><a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/46"">#46</a>: EncryptedFileKeyring now supports both pycryptodome and; pycryptodomex (preferring the latter).</p>; <h1>v4.1.2</h1>; <p>Updated to work with keyring 23.9+ (no longer depending on properties; module).</p>; <h1>v4.1.1</h1>; <p>Refresh package metadata.</p>; <p>Enrolled with Tidelift.</p>; <h1>v4.1.0</h1>; <p><a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/44"">#44</a>: Bump upper bound on pyfs.</p>; <p>Refresh package metadata.</p>; <h1>v4.0.2</h1>; <p><a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/43"">#43</a>: Tests are no longer included in the install.</p>; <h1>v4.0.1</h1>; <p>Package refresh and minor cleanup.</p>; <h1>v4.0.0</h1>; <p><a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/41"">#41</a>: Instead of PyCrypto or PyCryptodome, the encrypting backend; now relies on PyCryptodomex.</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/a2ef1a8e15859bb90f499e6be88c14468f246f8e""><code>a2ef1a8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/46"">#46</a> from TheChymera/cryptodome</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/dfab9b2846f7a19bebe788046b167a19a579fb45""><code>dfab9b2</code></a> 👹 Feed the hobgoblins (delint).</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/757afb5d5f3ada3d954eff981e9279f4e348f1e9""><code>757afb5</code></a> ⚫ Fade to black.</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/1614724e27124672f723735ff208a59a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12448:377,Encrypt,EncryptedFileKeyring,377,https://hail.is,https://github.com/hail-is/hail/pull/12448,1,['Encrypt'],['EncryptedFileKeyring']
Security,"Bumps [minimist](https://github.com/substack/minimist) from 1.2.5 to 1.2.6.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/substack/minimist/commit/7efb22a518b53b06f5b02a1038a88bd6290c2846""><code>7efb22a</code></a> 1.2.6</li>; <li><a href=""https://github.com/substack/minimist/commit/ef88b9325f77b5ee643ccfc97e2ebda577e4c4e2""><code>ef88b93</code></a> security notice for additional prototype pollution issue</li>; <li><a href=""https://github.com/substack/minimist/commit/c2b981977fa834b223b408cfb860f933c9811e4d""><code>c2b9819</code></a> isConstructorOrProto adapted from PR</li>; <li><a href=""https://github.com/substack/minimist/commit/bc8ecee43875261f4f17eb20b1243d3ed15e70eb""><code>bc8ecee</code></a> test from prototype pollution PR</li>; <li>See full diff in <a href=""https://github.com/substack/minimist/compare/1.2.5...1.2.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=minimist&package-manager=npm_and_yarn&previous-version=1.2.5&new-version=1.2.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and blo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11653:382,secur,security,382,https://hail.is,https://github.com/hail-is/hail/pull/11653,1,['secur'],['security']
Security,"Bumps [mistune](https://github.com/lepture/mistune) from 0.8.4 to 2.0.3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/lepture/mistune/releases"">mistune's releases</a>.</em></p>; <blockquote>; <h2>Version 2.0.2</h2>; <p>Fix <code>escape_url </code> via <a href=""https://github-redirect.dependabot.com/lepture/mistune/pull/295"">lepture/mistune#295</a></p>; <h2>Version 2.0.1</h2>; <p>Fix XSS for image link syntax.</p>; <h2>Version 2.0.0</h2>; <p>First release of Mistune v2.</p>; <h2>Version 2.0.0 RC1</h2>; <p>In this release, we have a <strong>Security Fix</strong> for harmful links.</p>; <h2>Version 2.0.0 Alpha 1</h2>; <p>This is the first release of v2. An alpha version for users to have a preview of the new mistune.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/lepture/mistune/blob/master/docs/changes.rst"">mistune's changelog</a>.</em></p>; <blockquote>; <h2>Changelog</h2>; <p>Here is the full history of mistune v2.</p>; <p>Version 2.0.4</p>; <pre><code>; Released on Jul 15, 2022; <ul>; <li>Fix <code>url</code> plugin in <code>&amp;lt;a&amp;gt;</code> tag</li>; <li>Fix <code>*</code> formatting</li>; </ul>; <p>Version 2.0.3; </code></pre></p>; <p>Released on Jun 27, 2022</p>; <ul>; <li>Fix <code>table</code> plugin</li>; <li>Security fix for CVE-2022-34749</li>; </ul>; <p>Version 2.0.2</p>; <pre><code>; Released on Jan 14, 2022; <p>Fix <code>escape_url</code></p>; <p>Version 2.0.1; </code></pre></p>; <p>Released on Dec 30, 2021</p>; <p>XSS fix for image link syntax.</p>; <p>Version 2.0.0</p>; <pre><code>; Released on Dec 5, 2021; <p>This is the first non-alpha release of mistune v2.</p>; <p>Version 2.0.0rc1; </code></pre></p>; <p>Released on Feb 16, 2021</p>; <p>Version 2.0.0a6</p>; <pre><code>; &lt;/tr&gt;&lt;/table&gt; ; </code></pre>; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""ht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12064:435,XSS,XSS,435,https://hail.is,https://github.com/hail-is/hail/pull/12064,2,"['Secur', 'XSS']","['Security', 'XSS']"
Security,"Bumps [mistune](https://github.com/lepture/mistune) from 0.8.4 to 2.0.4.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/lepture/mistune/releases"">mistune's releases</a>.</em></p>; <blockquote>; <h2>Version 2.0.2</h2>; <p>Fix <code>escape_url </code> via <a href=""https://github-redirect.dependabot.com/lepture/mistune/pull/295"">lepture/mistune#295</a></p>; <h2>Version 2.0.1</h2>; <p>Fix XSS for image link syntax.</p>; <h2>Version 2.0.0</h2>; <p>First release of Mistune v2.</p>; <h2>Version 2.0.0 RC1</h2>; <p>In this release, we have a <strong>Security Fix</strong> for harmful links.</p>; <h2>Version 2.0.0 Alpha 1</h2>; <p>This is the first release of v2. An alpha version for users to have a preview of the new mistune.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/lepture/mistune/blob/master/docs/changes.rst"">mistune's changelog</a>.</em></p>; <blockquote>; <h2>Changelog</h2>; <p>Here is the full history of mistune v2.</p>; <p>Version 2.0.4</p>; <pre><code>; Released on Jul 15, 2022; <ul>; <li>Fix <code>url</code> plugin in <code>&amp;lt;a&amp;gt;</code> tag</li>; <li>Fix <code>*</code> formatting</li>; </ul>; <p>Version 2.0.3; </code></pre></p>; <p>Released on Jun 27, 2022</p>; <ul>; <li>Fix <code>table</code> plugin</li>; <li>Security fix for CVE-2022-34749</li>; </ul>; <p>Version 2.0.2</p>; <pre><code>; Released on Jan 14, 2022; <p>Fix <code>escape_url</code></p>; <p>Version 2.0.1; </code></pre></p>; <p>Released on Dec 30, 2021</p>; <p>XSS fix for image link syntax.</p>; <p>Version 2.0.0</p>; <pre><code>; Released on Dec 5, 2021; <p>This is the first non-alpha release of mistune v2.</p>; <p>Version 2.0.0rc1; </code></pre></p>; <p>Released on Feb 16, 2021</p>; <p>Version 2.0.0a6</p>; <pre><code>; &lt;/tr&gt;&lt;/table&gt; ; </code></pre>; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""ht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12066:435,XSS,XSS,435,https://hail.is,https://github.com/hail-is/hail/pull/12066,4,"['Secur', 'XSS']","['Security', 'XSS']"
Security,"Bumps [msal-extensions](https://github.com/AzureAD/microsoft-authentication-extensions-for-python) from 0.3.1 to 1.0.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/releases"">msal-extensions's releases</a>.</em></p>; <blockquote>; <h2>MSAL Extensions for Python, 1.0.0</h2>; <p>This package is now considered stable and production-ready.</p>; <ul>; <li>New: Add a new platform-independent <code>build_encrypted_persistence()</code> API. (<a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/87"">#87</a>, <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/110"">#110</a>)</li>; <li>Remove: Old TokenCache API which has been deprecated for 2 years. (<a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/110"">#110</a>)</li>; <li>Enhancement: Make all platform-dependent parameters optional (<a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/103"">#103</a>)</li>; <li>Enhancement: Provide <code>PersistenceEncryptError</code> and <code>PersistenceDecryptError</code>, currently raised when encryption on Windows fails. (<a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/108"">#108</a>)</li>; <li>Enhancement: The data file will be created with <code>600</code> permission when running in Unix-like systems. (<a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/107"">#107</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/a88fa673af3602fe7c8c922314599b0c245e7add""><code>a88fa67</code></a> Merge branch 'release-1.0.0'</li",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:61,authenticat,authentication-extensions-for-python,61,https://hail.is,https://github.com/hail-is/hail/pull/11992,4,['authenticat'],['authentication-extensions-for-python']
Security,"Bumps [msrest](https://github.com/Azure/msrest-for-python) from 0.6.21 to 0.7.1.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/Azure/msrest-for-python/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=msrest&package-manager=pip&previous-version=0.6.21&new-version=0.7.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11965:491,secur,security-vulnerabilities,491,https://hail.is,https://github.com/hail-is/hail/pull/11965,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [nbformat]() from 5.6.1 to 5.7.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=nbformat&package-manager=pip&previous-version=5.6.1&new-version=5.7.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12306:273,secur,security-vulnerabilities,273,https://hail.is,https://github.com/hail-is/hail/pull/12306,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [net.java.dev.jna:jna](https://github.com/java-native-access/jna) from 5.12.1 to 5.13.0.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/java-native-access/jna/blob/master/CHANGES.md"">net.java.dev.jna:jna's changelog</a>.</em></p>; <blockquote>; <h1>Release (5.13.0)</h1>; <h2>Features</h2>; <ul>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1454"">#1454</a>: Add <code>c.s.j.p.win32.Psapi.QueryWorkingSetEx</code> and associated Types - <a href=""https://github.com/Crain-32""><code>@​crain-32</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1459"">#1459</a>: Add <code>VirtualLock</code> and <code>VirtualUnlock</code> in <code>c.s.j.p.win32.Kernel32</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1471"">#1471</a>: Add <code>c.s.j.p.win32.Advapi32Util#isCurrentProcessElevated</code> and associated Types - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1474"">#1474</a>: Add <code>c.s.j.p.win32.WbemCli#IWbemClassObject.IWbemQualifierSet</code>, <code>IWbemServices.GetObject</code>, <code>IWbemContext.SetValue</code> and associated methods - <a href=""https://github.com/rchateauneu""><code>@​rchateauneu</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1482"">#1482</a>: Add multilingual support of <code>Kernel32Util.formatMessage</code> - <a href=""https://github.com/overpathz""><code>@​overpathz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1490"">#1490</a>: Adds support for a custom <code>SymbolProvider</code> in <code>NativeLibrary</code> &amp; <code>Library</code> - <a href=""https://github.com/soywiz""><code>@​soywiz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:60,access,access,60,https://hail.is,https://github.com/hail-is/hail/pull/12886,5,['access'],['access']
Security,"Bumps [notebook](http://jupyter.org) from 6.4.11 to 6.4.12. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=notebook&package-manager=pip&previous-version=6.4.11&new-version=6.4.12)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/ale",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11926:295,secur,security-vulnerabilities,295,https://hail.is,https://github.com/hail-is/hail/pull/11926,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [org.slf4j:slf4j-api](https://github.com/qos-ch/slf4j) from 1.7.25 to 2.0.7.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/qos-ch/slf4j/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.slf4j:slf4j-api&package-manager=gradle&previous-version=1.7.25&new-version=2.0.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12804:498,secur,security-vulnerabilities,498,https://hail.is,https://github.com/hail-is/hail/pull/12804,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [path-parse](https://github.com/jbgutierrez/path-parse) from 1.0.6 to 1.0.7.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/jbgutierrez/path-parse/commits/v1.0.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=path-parse&package-manager=npm_and_yarn&previous-version=1.0.6&new-version=1.0.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11288:511,secur,security-vulnerabilities,511,https://hail.is,https://github.com/hail-is/hail/pull/11288,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [pkginfo](https://code.launchpad.net/~tseaver/pkginfo/trunk) from 1.8.2 to 1.8.3. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pkginfo&package-manager=pip&previous-version=1.8.2&new-version=1.8.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11966:320,secur,security-vulnerabilities,320,https://hail.is,https://github.com/hail-is/hail/pull/11966,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [prometheus-async](https://github.com/hynek/prometheus-async) from 19.2.0 to 22.1.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/hynek/prometheus-async/releases"">prometheus-async's releases</a>.</em></p>; <blockquote>; <h2>22.1.0</h2>; <h2>Highlights</h2>; <p><em>prometheus-async</em> now is fully typed and the optional <em>aiohttp</em> endpoint exposes the metrics in the OpenMetrics format if the client supports it.</p>; <h2>Full Changelog</h2>; <h3>Removed</h3>; <ul>; <li>Support for Python 2.7, 3.5, and 3.6 has been dropped.</li>; <li>The <em>loop</em> argument has been removed from <code>prometheus_async.aio.start_http_server()</code>.</li>; </ul>; <h3>Added</h3>; <ul>; <li>Added type hints for all APIs.; <a href=""https://github-redirect.dependabot.com/hynek/prometheus-async/pull/21"">#21</a></li>; <li>Added support for <a href=""https://openmetrics.io"">OpenMetrics</a> exposition in <code>prometheus_async.aio.web.server_stats()</code> and thus <code>prometheus_async.aio.web.start_http_server_in_thread()</code>.; <a href=""https://github-redirect.dependabot.com/hynek/prometheus-async/issues/23"">#23</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/hynek/prometheus-async/blob/main/CHANGELOG.md"">prometheus-async's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/hynek/prometheus-async/compare/19.2.0...22.1.0"">22.1.0</a> - 2022-02-15</h2>; <h3>Removed</h3>; <ul>; <li>Support for Python 2.7, 3.5, and 3.6 has been dropped.</li>; <li>The <em>loop</em> argument has been removed from <code>prometheus_async.aio.start_http_server()</code>.</li>; </ul>; <h3>Added</h3>; <ul>; <li>Added type hints for all APIs.; <a href=""https://github-redirect.dependabot.com/hynek/prometheus-async/pull/21"">#21</a></li>; <li>Added support for <a href=""https://openmetrics.io"">OpenMetrics</a> exposition in <code>prometheus_async.aio.web.ser",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11536:404,expose,exposes,404,https://hail.is,https://github.com/hail-is/hail/pull/11536,1,['expose'],['exposes']
Security,"Bumps [protobuf](https://github.com/protocolbuffers/protobuf) from 3.20.1 to 3.20.2.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/protocolbuffers/protobuf/releases"">protobuf's releases</a>.</em></p>; <blockquote>; <h2>Protocol Buffers v3.20.2</h2>; <h1>C++</h1>; <ul>; <li>Reduce memory consumption of MessageSet parsing</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf"">Security Advisory for C++ and Python users</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/a20c65f2cd549445fda907f7b83894c8eb7427d6""><code>a20c65f</code></a> Updating changelog</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/c49fe79af9c295960477b7568f1765b202093143""><code>c49fe79</code></a> Updating version.json and repo version numbers to: 20.2</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/806d7e4ce6f1fd0545cae226b94cb0249ea495c7""><code>806d7e4</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10544"">#10544</a> from deannagarcia/3.20.x</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/ae718b39020ae6e6f8f5568e357d6893fd0fd29c""><code>ae718b3</code></a> Add missing includes</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b4c395aaedfacb32e2414d361fa85968c0991b34""><code>b4c395a</code></a> Apply patch</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/6439c5c01349e74d4deb57c844a7ad4b7b13a302""><code>6439c5c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10531"">#10531</a> from protocolbuffers/deannagarcia-patch-7</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/22c79e6e4ca8be2bc2f700b2cdddca84d84659ce""><code>22c79e6</code></a> Update v",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12223:458,secur,security,458,https://hail.is,https://github.com/hail-is/hail/pull/12223,6,"['Secur', 'secur']","['Security', 'security']"
Security,"Bumps [protobuf](https://github.com/protocolbuffers/protobuf) from 3.20.1 to 4.21.5.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=4.21.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more fo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12082:499,secur,security-vulnerabilities,499,https://hail.is,https://github.com/hail-is/hail/pull/12082,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [protobuf](https://github.com/protocolbuffers/protobuf) from 3.20.1 to 4.21.6.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/protocolbuffers/protobuf/releases"">protobuf's releases</a>.</em></p>; <blockquote>; <h2>Protocol Buffers v3.20.2</h2>; <h1>C++</h1>; <ul>; <li>Reduce memory consumption of MessageSet parsing</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf"">Security Advisory for C++ and Python users</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=4.21.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You ca",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12227:458,secur,security,458,https://hail.is,https://github.com/hail-is/hail/pull/12227,4,"['Secur', 'secur']","['Security', 'security']"
Security,"Bumps [psutil](https://github.com/giampaolo/psutil) from 5.8.0 to 5.9.0.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/giampaolo/psutil/blob/master/HISTORY.rst"">psutil's changelog</a>.</em></p>; <blockquote>; <h1>5.9.0</h1>; <p>2021-12-29</p>; <p><strong>Enhancements</strong></p>; <ul>; <li>1851_, [Linux]: <code>cpu_freq()</code>_ is slow on systems with many CPUs. Read current; frequency values for all CPUs from <code>/proc/cpuinfo</code> instead of opening many; files in <code>/sys</code> fs. (patch by marxin)</li>; <li>1992_: <code>NoSuchProcess</code>_ message now specifies if the PID has been reused.</li>; <li>1992_: error classes (<code>NoSuchProcess</code><em>, <code>AccessDenied</code></em>, etc.) now have a better; formatted and separated <code>__repr__</code> and <code>__str__</code> implementations.</li>; <li>1996_, [BSD]: add support for MidnightBSD. (patch by Saeed Rasooli)</li>; <li>1999_, [Linux]: <code>disk_partitions()</code>_: convert <code>/dev/root</code> device (an alias; used on some Linux distros) to real root device path.</li>; <li>2005_: <code>PSUTIL_DEBUG</code> mode now prints file name and line number of the debug; messages coming from C extension modules.</li>; <li>2042_: rewrite HISTORY.rst to use hyperlinks pointing to psutil API doc.</li>; </ul>; <p><strong>Bug fixes</strong></p>; <ul>; <li>1456_, [macOS], <strong>[critical]</strong>: <code>cpu_freq()</code>_ <code>min</code> and <code>max</code> are set to; 0 if can't be determined (instead of crashing).</li>; <li>1512_, [macOS]: sometimes <code>Process.connections()</code>_ will crash with; <code>EOPNOTSUPP</code> for one connection; this is now ignored.</li>; <li>1598_, [Windows]: <code>disk_partitions()</code>_ only returns mountpoints on drives; where it first finds one.</li>; <li>1874_, [SunOS]: swap output error due to incorrect range.</li>; <li>1892_, [macOS]: <code>cpu_freq()</code>_ broken on Apple M1.</li>; <li>1901_, [macOS]: diff",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11459:727,Access,AccessDenied,727,https://hail.is,https://github.com/hail-is/hail/pull/11459,1,['Access'],['AccessDenied']
Security,"Bumps [pyjwt](https://github.com/jpadilla/pyjwt) from 1.7.1 to 2.4.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/jpadilla/pyjwt/releases"">pyjwt's releases</a>.</em></p>; <blockquote>; <h2>2.4.0</h2>; <h2>Security</h2>; <ul>; <li>[CVE-2022-29217] Prevent key confusion through non-blocklisted public key formats. <a href=""https://github.com/jpadilla/pyjwt/security/advisories/GHSA-ffqj-6fqr-9h24"">https://github.com/jpadilla/pyjwt/security/advisories/GHSA-ffqj-6fqr-9h24</a></li>; </ul>; <h2>What's Changed</h2>; <ul>; <li>Add support for Python 3.10 by <a href=""https://github.com/hugovk""><code>@​hugovk</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/699"">jpadilla/pyjwt#699</a></li>; <li>Don't use implicit optionals by <a href=""https://github.com/rekyungmin""><code>@​rekyungmin</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/705"">jpadilla/pyjwt#705</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/708"">jpadilla/pyjwt#708</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/710"">jpadilla/pyjwt#710</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/711"">jpadilla/pyjwt#711</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/712"">jpadilla/pyjwt#712</a></li>; <li>documentation fix: show correct scope for decode_complete() by <a href=""https://github.com/sseering""><code>@​ss",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11866:255,Secur,Security,255,https://hail.is,https://github.com/hail-is/hail/pull/11866,3,"['Secur', 'secur']","['Security', 'security']"
Security,"Bumps [pymysql](https://github.com/PyMySQL/PyMySQL) from 0.9.2 to 1.0.2.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/PyMySQL/PyMySQL/blob/main/CHANGELOG.md"">pymysql's changelog</a>.</em></p>; <blockquote>; <h2>v1.0.2</h2>; <p>Release date: 2021-01-09</p>; <ul>; <li>Fix <code>user</code>, <code>password</code>, <code>host</code>, <code>database</code> are still positional arguments.; All arguments of <code>connect()</code> are now keyword-only. (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/941"">#941</a>)</li>; </ul>; <h2>v1.0.1</h2>; <p>Release date: 2021-01-08</p>; <ul>; <li>Stop emitting DeprecationWarning for use of <code>db</code> and <code>passwd</code>.; Note that they are still deprecated. (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/939"">#939</a>)</li>; <li>Add <code>python_requires=&quot;&gt;=3.6&quot;</code> to setup.py. (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/936"">#936</a>)</li>; </ul>; <h2>v1.0.0</h2>; <p>Release date: 2021-01-07</p>; <p>Backward incompatible changes:</p>; <ul>; <li>Python 2.7 and 3.5 are not supported.</li>; <li><code>connect()</code> uses keyword-only arguments. User must use keyword argument.</li>; <li><code>connect()</code> kwargs <code>db</code> and <code>passwd</code> are now deprecated; Use <code>database</code> and <code>password</code> instead.</li>; <li>old_password authentication method (used by MySQL older than 4.1) is not supported.</li>; <li>MySQL 5.5 and MariaDB 5.5 are not officially supported, although it may still works.</li>; <li>Removed <code>escape_dict</code>, <code>escape_sequence</code>, and <code>escape_string</code> from <code>pymysql</code>; module. They are still in <code>pymysql.converters</code>.</li>; </ul>; <p>Other changes:</p>; <ul>; <li>Connection supports context manager API. <code>__exit__</code> closes the connection. (<a href=""https://github-redirect.dependabot.com/PyMySQL",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11595:341,password,password,341,https://hail.is,https://github.com/hail-is/hail/pull/11595,1,['password'],['password']
Security,"Bumps [pymysql](https://github.com/PyMySQL/PyMySQL) from 1.1.0 to 1.1.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/PyMySQL/PyMySQL/releases"">pymysql's releases</a>.</em></p>; <blockquote>; <h2>v1.1.1</h2>; <blockquote>; <p>[!WARNING]; This release fixes a vulnerability (CVE-2024-36039).; All users are recommended to update to this version.</p>; <p>If you can not update soon, check the input value from untrusted source has an expected type.; Only dict input from untrusted source can be an attack vector.</p>; </blockquote>; <h2>What's Changed</h2>; <ul>; <li>Prohibit dict parameter for <code>Cursor.execute()</code>. It didn't produce valid SQL; and might cause SQL injection. (CVE-2024-36039)</li>; <li>Added ssl_key_password param by <a href=""https://github.com/svaskov""><code>@​svaskov</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1145"">PyMySQL/PyMySQL#1145</a></li>; </ul>; <h2>Merged PRs</h2>; <ul>; <li>Add support for Python 3.12 by <a href=""https://github.com/hugovk""><code>@​hugovk</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1134"">PyMySQL/PyMySQL#1134</a></li>; <li>chore(deps): update actions/checkout action to v4 by <a href=""https://github.com/renovate""><code>@​renovate</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1136"">PyMySQL/PyMySQL#1136</a></li>; <li>Update codecov/codecov-action action to v4 by <a href=""https://github.com/renovate""><code>@​renovate</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1137"">PyMySQL/PyMySQL#1137</a></li>; <li>ci: use codecov@v3 by <a href=""https://github.com/methane""><code>@​methane</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1142"">PyMySQL/PyMySQL#1142</a></li>; <li>chore(deps): update dessant/lock-threads action to v5 by <a href=""https://github.com/renovate""><code>@​renovate</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1141"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14556:545,attack,attack,545,https://hail.is,https://github.com/hail-is/hail/pull/14556,2,"['attack', 'inject']","['attack', 'injection']"
Security,"Bumps [requests](https://github.com/psf/requests) from 2.28.2 to 2.31.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/psf/requests/releases"">requests's releases</a>.</em></p>; <blockquote>; <h2>v2.31.0</h2>; <h2>2.31.0 (2023-05-22)</h2>; <p><strong>Security</strong></p>; <ul>; <li>; <p>Versions of Requests between v2.3.0 and v2.30.0 are vulnerable to potential; forwarding of <code>Proxy-Authorization</code> headers to destination servers when; following HTTPS redirects.</p>; <p>When proxies are defined with user info (<a href=""https://user:pass@proxy:8080"">https://user:pass@proxy:8080</a>), Requests; will construct a <code>Proxy-Authorization</code> header that is attached to the request to; authenticate with the proxy.</p>; <p>In cases where Requests receives a redirect response, it previously reattached; the <code>Proxy-Authorization</code> header incorrectly, resulting in the value being; sent through the tunneled connection to the destination server. Users who rely on; defining their proxy credentials in the URL are <em>strongly</em> encouraged to upgrade; to Requests 2.31.0+ to prevent unintentional leakage and rotate their proxy; credentials once the change has been fully deployed.</p>; <p>Users who do not use a proxy or do not supply their proxy credentials through; the user information portion of their proxy URL are not subject to this; vulnerability.</p>; <p>Full details can be read in our <a href=""https://github.com/psf/requests/security/advisories/GHSA-j8r2-6x86-q33q"">Github Security Advisory</a>; and <a href=""https://nvd.nist.gov/vuln/detail/CVE-2023-32681"">CVE-2023-32681</a>.</p>; </li>; </ul>; <h2>v2.30.0</h2>; <h2>2.30.0 (2023-05-03)</h2>; <p><strong>Dependencies</strong></p>; <ul>; <li>; <p>⚠️ Added support for urllib3 2.0. ⚠️</p>; <p>This may contain minor breaking changes so we advise careful testing and; reviewing <a href=""https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html"">https://urll",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13091:298,Secur,Security,298,https://hail.is,https://github.com/hail-is/hail/pull/13091,30,"['Authoriz', 'Secur', 'authenticat']","['Authorization', 'Security', 'authenticate']"
Security,"Bumps [requests](https://github.com/psf/requests) from 2.31.0 to 2.32.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/psf/requests/releases"">requests's releases</a>.</em></p>; <blockquote>; <h2>v2.32.0</h2>; <h2>2.32.0 (2024-05-20)</h2>; <h2>🐍 PYCON US 2024 EDITION 🐍</h2>; <p><strong>Security</strong></p>; <ul>; <li>Fixed an issue where setting <code>verify=False</code> on the first request from a; Session will cause subsequent requests to the <em>same origin</em> to also ignore; cert verification, regardless of the value of <code>verify</code>.; (<a href=""https://github.com/psf/requests/security/advisories/GHSA-9wx4-h78v-vm56"">https://github.com/psf/requests/security/advisories/GHSA-9wx4-h78v-vm56</a>)</li>; </ul>; <p><strong>Improvements</strong></p>; <ul>; <li><code>verify=True</code> now reuses a global SSLContext which should improve; request time variance between first and subsequent requests. It should; also minimize certificate load time on Windows systems when using a Python; version built with OpenSSL 3.x. (<a href=""https://redirect.github.com/psf/requests/issues/6667"">#6667</a>)</li>; <li>Requests now supports optional use of character detection; (<code>chardet</code> or <code>charset_normalizer</code>) when repackaged or vendored.; This enables <code>pip</code> and other projects to minimize their vendoring; surface area. The <code>Response.text()</code> and <code>apparent_encoding</code> APIs; will default to <code>utf-8</code> if neither library is present. (<a href=""https://redirect.github.com/psf/requests/issues/6702"">#6702</a>)</li>; </ul>; <p><strong>Bugfixes</strong></p>; <ul>; <li>Fixed bug in length detection where emoji length was incorrectly; calculated in the request content-length. (<a href=""https://redirect.github.com/psf/requests/issues/6589"">#6589</a>)</li>; <li>Fixed deserialization bug in JSONDecodeError. (<a href=""https://redirect.github.com/psf/requests/issues/6629"">#6629</a>)</li>; <li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14555:334,Secur,Security,334,https://hail.is,https://github.com/hail-is/hail/pull/14555,3,"['Secur', 'secur']","['Security', 'security']"
Security,"Bumps [types-chardet](https://github.com/python/typeshed) from 4.0.4 to 5.0.1.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-chardet&package-manager=pip&previous-version=4.0.4&new-version=5.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this depen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12001:487,secur,security-vulnerabilities,487,https://hail.is,https://github.com/hail-is/hail/pull/12001,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-chardet](https://github.com/python/typeshed) from 5.0.4 to 5.0.4.1.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-chardet&package-manager=pip&previous-version=5.0.4&new-version=5.0.4.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12537:491,secur,security-vulnerabilities,491,https://hail.is,https://github.com/hail-is/hail/pull/12537,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-chardet](https://github.com/python/typeshed) from 5.0.4.5 to 5.0.4.6.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-chardet&package-manager=pip&previous-version=5.0.4.5&new-version=5.0.4.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13034:495,secur,security-vulnerabilities,495,https://hail.is,https://github.com/hail-is/hail/pull/13034,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-python-dateutil](https://github.com/python/typeshed) from 2.8.17 to 2.8.19.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-python-dateutil&package-manager=pip&previous-version=2.8.17&new-version=2.8.19)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12172:507,secur,security-vulnerabilities,507,https://hail.is,https://github.com/hail-is/hail/pull/12172,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-requests](https://github.com/python/typeshed) from 2.27.30 to 2.28.0.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-requests&package-manager=pip&previous-version=2.27.30&new-version=2.28.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11967:495,secur,security-vulnerabilities,495,https://hail.is,https://github.com/hail-is/hail/pull/11967,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-requests](https://github.com/python/typeshed) from 2.28.11.1 to 2.28.11.2.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-requests&package-manager=pip&previous-version=2.28.11.1&new-version=2.28.11.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any m",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12297:505,secur,security-vulnerabilities,505,https://hail.is,https://github.com/hail-is/hail/pull/12297,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-requests](https://github.com/python/typeshed) from 2.28.11.2 to 2.28.11.3.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-requests&package-manager=pip&previous-version=2.28.11.2&new-version=2.28.11.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any m",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12437:505,secur,security-vulnerabilities,505,https://hail.is,https://github.com/hail-is/hail/pull/12437,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-setuptools](https://github.com/python/typeshed) from 57.4.17 to 65.3.0.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-setuptools&package-manager=pip&previous-version=57.4.17&new-version=65.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more fo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12181:499,secur,security-vulnerabilities,499,https://hail.is,https://github.com/hail-is/hail/pull/12181,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-six](https://github.com/python/typeshed) from 1.16.15 to 1.16.18.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-six&package-manager=pip&previous-version=1.16.15&new-version=1.16.18)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this depen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12114:487,secur,security-vulnerabilities,487,https://hail.is,https://github.com/hail-is/hail/pull/12114,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-six](https://github.com/python/typeshed) from 1.16.15 to 1.16.19.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-six&package-manager=pip&previous-version=1.16.15&new-version=1.16.19)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this depen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12131:487,secur,security-vulnerabilities,487,https://hail.is,https://github.com/hail-is/hail/pull/12131,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-six](https://github.com/python/typeshed) from 1.16.21.20240301 to 1.16.21.20240311.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-six&package-manager=pip&previous-version=1.16.21.20240301&new-version=1.16.21.20240311)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (un",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14491:523,secur,security-vulnerabilities,523,https://hail.is,https://github.com/hail-is/hail/pull/14491,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-six](https://github.com/python/typeshed) from 1.16.21.20240301 to 1.16.21.20240425.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-six&package-manager=pip&previous-version=1.16.21.20240301&new-version=1.16.21.20240425)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (un",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14501:523,secur,security-vulnerabilities,523,https://hail.is,https://github.com/hail-is/hail/pull/14501,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-urllib3](https://github.com/python/typeshed) from 1.26.15 to 1.26.20.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-urllib3&package-manager=pip&previous-version=1.26.15&new-version=1.26.20)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12068:495,secur,security-vulnerabilities,495,https://hail.is,https://github.com/hail-is/hail/pull/12068,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-urllib3](https://github.com/python/typeshed) from 1.26.15 to 1.26.21.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-urllib3&package-manager=pip&previous-version=1.26.15&new-version=1.26.21)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12072:495,secur,security-vulnerabilities,495,https://hail.is,https://github.com/hail-is/hail/pull/12072,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-urllib3](https://github.com/python/typeshed) from 1.26.15 to 1.26.22.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-urllib3&package-manager=pip&previous-version=1.26.15&new-version=1.26.22)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12077:495,secur,security-vulnerabilities,495,https://hail.is,https://github.com/hail-is/hail/pull/12077,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [urllib3](https://github.com/urllib3/urllib3) from 1.26.9 to 1.26.12.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/urllib3/urllib3/releases"">urllib3's releases</a>.</em></p>; <blockquote>; <h2>1.26.12</h2>; <ul>; <li>Deprecated the <code>urllib3[secure]</code> extra and the <code>urllib3.contrib.pyopenssl</code> module. Both will be removed in v2.x. See this <a href=""https://github-redirect.dependabot.com/urllib3/urllib3/issues/2680"">GitHub issue</a> for justification and info on how to migrate.</li>; </ul>; <h2>1.26.11</h2>; <p><strong>If you or your organization rely on urllib3 consider supporting us via <a href=""https://github.com/sponsors/urllib3"">GitHub Sponsors</a>.</strong></p>; <p>:warning: <strong>urllib3 v2.0 will drop support for Python 2</strong>: <a href=""https://urllib3.readthedocs.io/en/latest/v2-roadmap.html"">Read more in the v2.0 Roadmap</a></p>; <ul>; <li>Fixed an issue where reading more than 2 GiB in a call to HTTPResponse.read would raise an OverflowError on Python 3.9 and earlier.</li>; </ul>; <h2>1.26.10</h2>; <p><strong>If you or your organization rely on urllib3 consider supporting us via <a href=""https://github.com/sponsors/urllib3"">GitHub Sponsors</a>.</strong></p>; <p>:warning: <strong>urllib3 v2.0 will drop support for Python 2</strong>: <a href=""https://urllib3.readthedocs.io/en/latest/v2-roadmap.html"">Read more in the v2.0 Roadmap</a></p>; <p>:closed_lock_with_key: <strong>This is the first release to be signed with Sigstore!</strong> You can verify the distributables using the <code>.sig</code> and <code>.crt</code> files included on this release.</p>; <ul>; <li>Removed support for Python 3.5</li>; <li>Fixed an issue where a <code>ProxyError</code> recommending configuring the proxy as HTTP instead of HTTPS could appear even when an HTTPS proxy wasn't configured.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://gi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12140:301,secur,secure,301,https://hail.is,https://github.com/hail-is/hail/pull/12140,1,['secur'],['secure']
Security,"Bumps [werkzeug](https://github.com/pallets/werkzeug) from 2.2.2 to 2.2.3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/werkzeug/releases"">werkzeug's releases</a>.</em></p>; <blockquote>; <h2>2.2.3</h2>; <p>This is a fix release for the 2.2.x release branch.</p>; <ul>; <li>Changes: <a href=""https://werkzeug.palletsprojects.com/en/2.2.x/changes/#version-2-2-3"">https://werkzeug.palletsprojects.com/en/2.2.x/changes/#version-2-2-3</a></li>; <li>Milestone: <a href=""https://github.com/pallets/werkzeug/milestone/26?closed=1"">https://github.com/pallets/werkzeug/milestone/26?closed=1</a></li>; </ul>; <p>This release contains security fixes for:</p>; <ul>; <li><a href=""https://github.com/pallets/werkzeug/security/advisories/GHSA-xg9f-g7g7-2323"">https://github.com/pallets/werkzeug/security/advisories/GHSA-xg9f-g7g7-2323</a></li>; <li><a href=""https://github.com/pallets/werkzeug/security/advisories/GHSA-px8h-6qxv-m22q"">https://github.com/pallets/werkzeug/security/advisories/GHSA-px8h-6qxv-m22q</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/werkzeug/blob/main/CHANGES.rst"">werkzeug's changelog</a>.</em></p>; <blockquote>; <h2>Version 2.2.3</h2>; <p>Released 2023-02-14</p>; <ul>; <li>Ensure that URL rules using path converters will redirect with strict slashes when; the trailing slash is missing. :issue:<code>2533</code></li>; <li>Type signature for <code>get_json</code> specifies that return type is not optional when; <code>silent=False</code>. :issue:<code>2508</code></li>; <li><code>parse_content_range_header</code> returns <code>None</code> for a value like <code>bytes */-1</code>; where the length is invalid, instead of raising an <code>AssertionError</code>. :issue:<code>2531</code></li>; <li>Address remaining <code>ResourceWarning</code> related to the socket used by <code>run_simple</code>.; Remove <code>prepare_socket</code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12703:681,secur,security,681,https://hail.is,https://github.com/hail-is/hail/pull/12703,4,['secur'],['security']
Security,"Bumps [widgetsnbextension](http://jupyter.org) from 3.6.0 to 4.0.3. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=widgetsnbextension&package-manager=pip&previous-version=3.6.0&new-version=4.0.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12167:311,secur,security-vulnerabilities,311,https://hail.is,https://github.com/hail-is/hail/pull/12167,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps asm from 7.3.1 to 9.4. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.ow2.asm:asm&package-manager=gradle&previous-version=7.3.1&new-version=9.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12516:270,secur,security-vulnerabilities,270,https://hail.is,https://github.com/hail-is/hail/pull/12516,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps com.github.johnrengelman.shadow from 6.1.0 to 7.1.2. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.johnrengelman.shadow&package-manager=gradle&previous-version=6.1.0&new-version=7.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12500:318,secur,security-vulnerabilities,318,https://hail.is,https://github.com/hail-is/hail/pull/12500,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps com.github.johnrengelman.shadow from 6.1.0 to 8.1.1. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.johnrengelman.shadow&package-manager=gradle&previous-version=6.1.0&new-version=8.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>> **Note**; > Automatic rebases have been disabled on this pull request as it has been open for over 30 days.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12897:318,secur,security-vulnerabilities,318,https://hail.is,https://github.com/hail-is/hail/pull/12897,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps commons-io from 2.5 to 2.11.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=commons-io:commons-io&package-manager=gradle&previous-version=2.5&new-version=2.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12469:285,secur,security-vulnerabilities,285,https://hail.is,https://github.com/hail-is/hail/pull/12469,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps commons-lang3 from 3.5 to 3.12.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.commons:commons-lang3&package-manager=gradle&previous-version=3.5&new-version=3.12.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12363:299,secur,security-vulnerabilities,299,https://hail.is,https://github.com/hail-is/hail/pull/12363,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps freemarker from 2.3.14 to 2.3.31. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.freemarker:freemarker&package-manager=gradle&previous-version=2.3.14&new-version=2.3.31)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12443:295,secur,security-vulnerabilities,295,https://hail.is,https://github.com/hail-is/hail/pull/12443,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps hadoop-client from 2.7.1 to 3.3.4. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.hadoop:hadoop-client&package-manager=gradle&previous-version=2.7.1&new-version=3.3.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12377:300,secur,security-vulnerabilities,300,https://hail.is,https://github.com/hail-is/hail/pull/12377,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps org.ow2.asm:asm-util from 7.3.1 to 9.5. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.ow2.asm:asm-util&package-manager=gradle&previous-version=7.3.1&new-version=9.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13636:292,secur,security-vulnerabilities,292,https://hail.is,https://github.com/hail-is/hail/pull/13636,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps org.ow2.asm:asm-util from 7.3.1 to 9.6. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.ow2.asm:asm-util&package-manager=gradle&previous-version=7.3.1&new-version=9.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>. > **Note**; > Automatic rebases have been disabled on this pull request as it has been open ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13761:292,secur,security-vulnerabilities,292,https://hail.is,https://github.com/hail-is/hail/pull/13761,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,By setting a secret on the callback in Github and verifying the request hash.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4473:72,hash,hash,72,https://hail.is,https://github.com/hail-is/hail/issues/4473,1,['hash'],['hash']
Security,"BytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.603 : ERROR: SocketException: Connection reset; From javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:104); 	at is.hail.relocated.com.google.cloud.stora",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:24141,secur,security,24141,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,"BytesReadable=129.00 KiB, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.560 : INFO: RegionPool: FREE: 129.0K allocated (129.0K blocks / 0 chunks), regions.size = 3, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.561 : ERROR: error while applying lowering 'LowerAndExecuteShuffles'; 2023-05-04 01:04:37.600 : INFO: RegionPool: initialized for thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=0, peakBytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.603 : ERROR: SocketException: Connection reset; From javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:23646,secur,security,23646,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,"C$.apply(SampleQC.scala:221); at is.hail.methods.SampleQC.apply(SampleQC.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:745)is.hail.utils.HailException: invalid allele ""<DEL>""; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:29); at is.hail.methods.SampleQCCombiner$.alleleIndices(SampleQC.scala:44); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:178); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:175); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:175); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:170); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterat",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:7585,validat,validate,7585,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['validat'],['validate']
Security,CHANGELOG: Add `hl.die` function that can be used to generate errors. Useful in data validation.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8865:85,validat,validation,85,https://hail.is,https://github.com/hail-is/hail/pull/8865,1,['validat'],['validation']
Security,"CHANGELOG: BatchPoolExecutor now raises an informative error message for a variety of ""system"" errors, such as missing container images. If the main container fails for reasons beyond BatchPoolExecutor's control, such; as a missing container image, we previously did not report these errors. In; fact, we encountered errors when trying to load the output file that cannot; exist if the main container errors. Smaller included changes:; - directly use the asynchronous, low-level client instead of the synchronous,; low-level client; - introduce an `async_cancel` now that we have access to the async client.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9543:580,access,access,580,https://hail.is,https://github.com/hail-is/hail/pull/9543,1,['access'],['access']
Security,"CHANGELOG: Evaluating hail expressions in python will now return `frozendict`, an immutable dictionary type. Sets will return python's `frozenset`. This is necessary because hail supports hashable dicts, but python does not. Same with sets.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10105:188,hash,hashable,188,https://hail.is,https://github.com/hail-is/hail/pull/10105,1,['hash'],['hashable']
Security,"CHANGELOG: Fix #14089, which makes `hailctl dataproc connect` work in Windows Subsystem for Linux. 1. Non 64-bit Windows uses ""Program Files"" not ""Program Files (x86)"". 2. Windows Subsystem for Linux looks like GNU/Linux but will not have chromium on its path. 3. The removed arguments are no longer supported. They produce a warning message in my version of Chrome and appear to not work in the version of Chrome that this user was using. Instead, I bind to 0.0.0.0 and access the Notebook using the machine DNS name. This is how Google recommend accessing the Spark UI anyway.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14090:471,access,access,471,https://hail.is,https://github.com/hail-is/hail/pull/14090,2,['access'],"['access', 'accessing']"
Security,"CHANGELOG: Fix long-standing bug wherein `hl.agg.collect_as_set` and `hl.agg.counter` error when applied to types which, in Python, are unhashable. For example, `hl.agg.counter(t.list_of_genes)` will not error when `t.list_of_genes` is a list. Instead, the counter dictionary will use `FrozenList` keys from the `frozenlist` package. Hey @iris-garden ! I figured this was good reviewing practice for you and also a chance to see how we convert data to/from JSON and to/from the JVM (by way of this ""encoded"" representation which is a binary one). The details of that are not super important to this PR, but you might take a peek to understand the change. The main issue here is that in Python, you can't write:; ```; {[1]}; ```; Because sets must contain ""hashable"" data. Python lists are not hashable because they're mutable. This is transitively a problem. For example, the following also fails with the same error because the list inside the tuple is mutable thus the tuple is not (safely) hashable.; ```; {(""tuples"", ""are"", ""immutable"", [""lists"", ""are"", ""not""])}; ```. Hail's internal language is fully immutable, so every type can be placed inside a set (or used as the keys of a dict). When we convert from Hail's internal representation to Python, we cannot use mutable types in hashable positions. Unfortunately, we also need to maintain backwards compatibility with the way the code currently works. You can see this pretty clearly in the difference between `hl.agg.collect` and `hl.agg.collect_as_set`:; ```; t = hl.utils.range_table(1); t = t.annotate(ls = [1, 2, 3]); collected_ls = t.aggregate(hl.agg.collect(t.ls)); collected_as_set_ls = t.aggregate(hl.agg.collect_as_set(t.ls)); ```; `collected_ls` should be `[[1, 2, 3]]` whereas `collected_as_set_ls` necessarily uses hashable types: `{frozenlist([1, 2, 3])}`. Things are particularly subtle with dictionaries whose keys must always be hashable and whose values need only be hashable if the dictionary itself must be hashable. For exa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12265:756,hash,hashable,756,https://hail.is,https://github.com/hail-is/hail/pull/12265,3,['hash'],['hashable']
Security,"CHANGELOG: Fixed issue where accessing an element of an ndarray in a call to Table.transmute would fail. Because `_indices` was not being set, transmute would fail when it tried to see which row fields to delete.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8845:29,access,accessing,29,https://hail.is,https://github.com/hail-is/hail/pull/8845,1,['access'],['accessing']
Security,"CHANGELOG: Fixes #13697, a long standing issue with QoB, in which a failing partition job or driver job is not failed in the Batch UI. I am not sure why we did not do this this way in the first place. If a JVMJob raises an exception, Batch will mark the job as failed. Ergo, we should raise an exception when a driver or a worker fails!. Here's an example: I used a simple pipeline that write to a bucket to which I have read-only access. You can see an example Batch (where every partition fails): https://batch.hail.is/batches/8046901. [1]. ```python3; import hail as hl; hl.utils.range_table(3, n_partitions=3).write('gs://neale-bge/foo.ht'); ```. NB: I removed the `log.error` in `handleForPython` because that log is never necessary. That function converts a stack of exceptions into a triplet of the short message, the full exception with stack trace, and a Hail error id (if present). That triplet is always passed along to someone else who logs the exception. (FWIW, the error id indicates a Python source location that is associated with the error. On the Python-side, we can look up that error id and provide a better stack trace.). [1] You'll notice the logs are missing. I noticed this as well, it's a new bug. I fixed it in https://github.com/hail-is/hail/pull/13729.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13715:431,access,access,431,https://hail.is,https://github.com/hail-is/hail/pull/13715,1,['access'],['access']
Security,"CHANGELOG: MatrixTable.aggregate_cols no longer forces a distributed computation. This should be what you want in the majority of cases. In case you know the aggregation is very slow and should be parallelized, use mt.cols().aggregate instead. Most of the time, `aggregate_cols` will be much faster performing the aggregation locally. Currently, we generate a `TableAggregate` over a `TableParallelize` of the columns. We shouldn't try to optimize that to a local computation during compilation; `TableParallelize` should express the intent that the computation is expensive and really should be parallelized. This should be considered part of the semantics the compiler must preserve. This PR changes `aggregate_cols` to explicitly generate a local computation using `StreamAgg` (which was only exposed in Python relatively recently, which is why we haven't made this change sooner). Longer term, aggregating columns should probably get its own IR node, especially once we start partitioning along columns.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13405:796,expose,exposed,796,https://hail.is,https://github.com/hail-is/hail/pull/13405,1,['expose'],['exposed']
Security,"CI testing needs GitHub tokens. We should be able to use OAuth and username/password credentials to create these tokens. CI testing also needs some GCP service accounts. We can use `kubectl` to create these. We can store the root secrets (a YAML with username/password pairs for the hail users) on the Broad servers. Then we use the developer's latent Broad credentials to retrieve the GitHub credentials and re-generate all of the necessary secrets in a fresh k8s cluster. One issue is that we have 2FA enabled for all hail accounts and the CI committer account needs to be in this org in order to use the ""merge button"". We should probably disable 2FA for the org and disable it on that account (hail-hephaestus). cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4556:76,password,password,76,https://hail.is,https://github.com/hail-is/hail/issues/4556,2,['password'],['password']
Security,"CI was getting 422s from GitHub. Using a; `raise_for_status=True` ClientSession circumvented gidgethubs native; error handling logic smothering the HTTP response body where github; places critical debugging information. Aiohttp is aware that; `raise_for_status` provides no access to the response body. They addressed; this in https://github.com/aio-libs/aiohttp/pulls/3892, but that has not; been released because 4.0.0 has not yet been released. Moreover, `gidgethub` incorrectly handles the too many statuses response. I'll PR a fix into their repo. For now, I've added a bit more information the logs and fixed the main issue, the missing `['status']`. Another relevant issue: https://github.com/aio-libs/aiohttp/issues/4600.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8480:274,access,access,274,https://hail.is,https://github.com/hail-is/hail/pull/8480,1,['access'],['access']
Security,"Came across this while doing #13307. The `AuthClient` decorators are used by services like Batch and CI to protect endpoints behind an authentication/authorization check. Those decorators might make a network request to the auth service to see who the user is and whether they're a developer. I realized that these decorators are also used to protect some endpoints on the auth service too, which albeit uniform felt silly to me (make a network request back to yourself instead of just making a function call). Creating new decorators to use within the auth service is a bit more code, but I personally think it's a much easier code path to follow. Only the last commit is this PR, as it's stacked.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13330:135,authenticat,authentication,135,https://hail.is,https://github.com/hail-is/hail/pull/13330,2,"['authenticat', 'authoriz']","['authentication', 'authorization']"
Security,Can we expose a HailContext.setEnv then? That seems like the right thing to do,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8050#issuecomment-583464027:7,expose,expose,7,https://hail.is,https://github.com/hail-is/hail/pull/8050#issuecomment-583464027,1,['expose'],['expose']
Security,"Can we make it a job and/or batch level configuration? The user obviously can do whatever they like with their tokens. However, since most users don't need them, I prefer our default to be to not expose them. I think we just need a new method and attribute on `Job` and `Batch` that mirrors, say, `image` or `memory`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9907#issuecomment-767739020:196,expose,expose,196,https://hail.is,https://github.com/hail-is/hail/pull/9907#issuecomment-767739020,1,['expose'],['expose']
Security,"Can you verify; 1. Batch has access to the hail-query bucket; 2. Our terraform correctly grants permissions for that? And if it currently doesn’t, we should ping AUS to make sure they’re aware of this change",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11870#issuecomment-1138729334:29,access,access,29,https://hail.is,https://github.com/hail-is/hail/pull/11870#issuecomment-1138729334,1,['access'],['access']
Security,Can't access global within filtergenotypes expression.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/844:6,access,access,6,https://hail.is,https://github.com/hail-is/hail/issues/844,1,['access'],['access']
Security,"Caveats:; * the copy-to-GS at the end is crashing without a good error message,; but probably permissions, even though I've given my service account; access to that bucket.; * this runs all benchmarks in replicate. We should split them up; in a randomized (deterministic?) way so that the wall time is; shorter.; * needs to dump into a database instead of json files on GS.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6908:150,access,access,150,https://hail.is,https://github.com/hail-is/hail/pull/6908,1,['access'],['access']
Security,"Changes:; - added monitoring setup (Prometheus, Grafana) to monitoring namespace; - I'm considering monitoring part of ""infrastructure"", no automated tests, gateway and router-resolver changes already deployed; - authenticated_users_only always passes userdata as second argument; - added authenticated_developers_only decorator to hailjwt, no userdata; - gateway forwards to internal namespaces: internal.hail.is/namespace proxies to router.namespace, so in general you'll go to internal.hail.is/namespace/service/the/real/url; - proxy only if namespace has router service and authorized developer; - add router to monitoring namespace that proxies for prometheus and grafana; - restrict ci to authorized developers. monitoring/grafana-cluster.json is an export of an initial Grafana monitoring dashboard that I constructed through the UI. If you're logged in as a developer, you can see Grafana at internal.hail.is/monitoring/grafana. The admin password is in the usual place.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6242:578,authoriz,authorized,578,https://hail.is,https://github.com/hail-is/hail/pull/6242,3,"['authoriz', 'password']","['authorized', 'password']"
Security,"Changes:; - create a custom job spec schema for what a job means to us; - hand-rolled validator; - use in bath_client, /jobs/create endpoints in batch, batch2; - slightly changed create_job interface around volumes, docker socket and secrets, update usage; - wrote route to convert this to a k8s pod spec, use when actually creating jobs. The secret has a namespace, but it is ignored by the servers. Eventually, batch should be able to pull secrets from wherever, but needs to enforce permissions on who can use what secrets. This was a long-standing issue that I think now has a clearer path. We can get rid of the mount docker socket option by making the worker support a build (rather than run) task. The validator should really go in the server code, but it needs to be shared between batch and batch2 for now. Plan is to push this through batch2 to remove the dependence on the k8s pod serialization. When that's done, the job to pod spec routine can go into batch (and go away when CI uses batch2). Will be interested to benchmark my validator vs. the previous cerberus + k8s validation/serialization.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7313:86,validat,validator,86,https://hail.is,https://github.com/hail-is/hail/pull/7313,4,['validat'],"['validation', 'validator']"
Security,ClassLoader$1.run(URLClassLoader.java:365); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.OutOfMemoryError: GC ov,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:2533,Hash,HashTable,2533,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Hash'],['HashTable']
Security,Closes https://github.com/hail-is/hail-tasks/issues/6. Stacked on #11353. This PR does everything necessary to give the user the CPU and memory statistics except expose them on the jobs UI page.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11368:162,expose,expose,162,https://hail.is,https://github.com/hail-is/hail/pull/11368,1,['expose'],['expose']
Security,"Closes https://github.com/hail-is/hail/issues/14652. See https://github.com/populationgenomics/hail/pull/346. Thanks for the contribution @illusional!. Gives Dataproc clusters started via `hailctl dataproc start` internet access by default, since we need it to install some of our dependencies, per the error message in the linked issue.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14653:222,access,access,222,https://hail.is,https://github.com/hail-is/hail/pull/14653,1,['access'],['access']
Security,Closing because ; 1. The change is purely cosmetic; 2. Breaking previously-run migration checksums feels like a bad idea,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14669#issuecomment-2317996498:89,checksum,checksums,89,https://hail.is,https://github.com/hail-is/hail/pull/14669#issuecomment-2317996498,1,['checksum'],['checksums']
Security,"Closing in favor of https://github.com/hail-is/hail/pull/12386, which uses my fork since (I think?) CI only lets authorized users run pipelines.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11800#issuecomment-1294024957:113,authoriz,authorized,113,https://hail.is,https://github.com/hail-is/hail/pull/11800#issuecomment-1294024957,1,['authoriz'],['authorized']
Security,Closing until ExposedPorts goes in.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7780#issuecomment-568618504:14,Expose,ExposedPorts,14,https://hail.is,https://github.com/hail-is/hail/pull/7780#issuecomment-568618504,1,['Expose'],['ExposedPorts']
Security,"Closing with recommended solution hashCode=0, long term plan: eliminate Spark.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5564#issuecomment-471050878:34,hash,hashCode,34,https://hail.is,https://github.com/hail-is/hail/issues/5564#issuecomment-471050878,1,['hash'],['hashCode']
Security,Commandline:. ```; hail-new -l /home/unix/gtiao/hail.rename.log \; read -i /user/gtiao/37k/germline_cancer_joint_calling.no_restricted.GQ20_AB.split.VEP.vds \; renamesamples -i file:///xchip/cga_home/gtiao/37k/Hail/germline_cancer_joint_calling.no_restricted.GQ20_AB.split.VEP.sample_id_map.txt \; write -o /user/gtiao/37k/germline_cancer_joint_calling.no_restricted.GQ20_AB.split.VEP.no_spaces.vds. ```. Error message:. ```; hail: info: running: read -i /user/gtiao/37k/germline_cancer_joint_calling.no_restricted.GQ20_AB.split.VEP.vds; [Stage 0:=============================> (1 + 1) / 2]hail: info: running: renamesamples -i file:///xchip/cga_home/gtiao/37k/Hail/germline_cancer_joint_calling.no_restricted.GQ20_AB.split.VEP.sample_id_map.txt; hail: renamesamples: caught exception: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/xchip/cga_home/gtiao/37k/Hail/germline_cancer_joint_calling.no_restricted.GQ20_AB.split.VEP.sample_id_map.txt at 175616 exp: -1352655701 got: 441984571. ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/347:807,Checksum,ChecksumException,807,https://hail.is,https://github.com/hail-is/hail/issues/347,2,['Checksum'],"['Checksum', 'ChecksumException']"
Security,Confirmed that the hashCode solution works for Danfeng.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5564#issuecomment-471047536:19,hash,hashCode,19,https://hail.is,https://github.com/hail-is/hail/issues/5564#issuecomment-471047536,1,['hash'],['hashCode']
Security,"Consider this:. ```scala; class Foo {; def bar(): (Long, Long) = (3, 4). def destructure(): Unit = {; val (x, y) = bar(); }. def accessors(): Unit = {; val zz = bar(); val x = zz._1; val y = zz._2; }; }; ```. ![image](https://github.com/hail-is/hail/assets/106194/532dc7ea-8027-461d-8e12-3217f5451713). These should be exactly equivalent, right? There's no way Scala would compile the match into something horrible. Right? Right?. ```; public void destructure();; Code:; 0: aload_0; 1: invokevirtual #27 // Method bar:()Lscala/Tuple2;; 4: astore_3; 5: aload_3; 6: ifnull 35; 9: aload_3; 10: invokevirtual #33 // Method scala/Tuple2._1$mcJ$sp:()J; 13: lstore 4; 15: aload_3; 16: invokevirtual #36 // Method scala/Tuple2._2$mcJ$sp:()J; 19: lstore 6; 21: new #13 // class scala/Tuple2$mcJJ$sp; 24: dup; 25: lload 4; 27: lload 6; 29: invokespecial #21 // Method scala/Tuple2$mcJJ$sp.""<init>"":(JJ)V; 32: goto 47; 35: goto 38; 38: new #38 // class scala/MatchError; 41: dup; 42: aload_3; 43: invokespecial #41 // Method scala/MatchError.""<init>"":(Ljava/lang/Object;)V; 46: athrow; 47: astore_2; 48: aload_2; 49: invokevirtual #33 // Method scala/Tuple2._1$mcJ$sp:()J; 52: lstore 8; 54: aload_2; 55: invokevirtual #36 // Method scala/Tuple2._2$mcJ$sp:()J; 58: lstore 10; 60: return. public void accessors();; Code:; 0: aload_0; 1: invokevirtual #27 // Method bar:()Lscala/Tuple2;; 4: astore_1; 5: aload_1; 6: invokevirtual #33 // Method scala/Tuple2._1$mcJ$sp:()J; 9: lstore_2; 10: aload_1; 11: invokevirtual #36 // Method scala/Tuple2._2$mcJ$sp:()J; 14: lstore 4; 16: return; ```. Yeah, so, it extracts the first and second elements of the primitive-specialized tuple, ~~constructs a `(java.lang.Long, java.lang.Long)` Tuple~~ constructs another primitive-specialized tuple (for no reason???), then does the match on that. sigh.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13794:129,access,accessors,129,https://hail.is,https://github.com/hail-is/hail/pull/13794,2,['access'],['accessors']
Security,"Consider, for example, this deploy: https://ci.hail.is/batches/7956812. `test-dataproc-37` succeeded but `test-dataproc-38` failed (it timed out b/c the master failed to come online). You can see the error logs for the cluster here: https://cloudlogging.app.goo.gl/t1ux8oqy11Ba2dih7. It states a certain file either did not exist or we did not have permission to access it. [`test_dataproc-37`](https://batch.hail.is/batches/7956812/jobs/193) and [`test_dataproc-38`](https://batch.hail.is/batches/7956812/jobs/194) started around the same time and both uploaded four files into:. gs://hail-30-day/hailctl/dataproc/ci_test_dataproc/0.2.121-7343e9c368dc/. And then set it to public read/write. The public read/write means that permissions are not the issue. Instead, the issue is that there must be some sort of race condition in GCS which means that if you ""patch"" (aka overwrite) an existing file, it is possible that a concurrent reader will see the file as not existing. Unfortunately, I cannot confirm this with audit logs of the writes and read because [public objects do not generate audit logs](https://cloud.google.com/logging/docs/audit#data-access).; > Publicly available resources that have the Identity and Access Management policies [allAuthenticatedUsers](https://cloud.google.com/iam/docs/overview#allauthenticatedusers) or [allUsers](https://cloud.google.com/iam/docs/overview#allusers) don't generate audit logs. Resources that can be accessed without logging into a Google Cloud, Google Workspace, Cloud Identity, or Drive Enterprise account don't generate audit logs. This helps protect end-user identities and information.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13573:363,access,access,363,https://hail.is,https://github.com/hail-is/hail/pull/13573,9,"['Access', 'access', 'audit']","['Access', 'access', 'accessed', 'audit']"
Security,"Context from Tim's scribblings:; """"""; Why are we adding this node?; The hl.balding_nichols_model node is implemented as; >>> ht = hl.utils.range_table(N); >>> ht = ht.key_by(locus = hl.locus('chr1', ht.idx + 1)) // or something. This requires us to do an extra pass over the data in order to key `ht` by this new key 'locus' we track information about keys statically -- need to know that tables are sorted by their key we also need to know partition intervals statically. So, when we implement key_by, we have to do extra work to compute this information before generating the rest of the query. This is a super common tutorial example and it's currently slow because it an extra pass over the data! We need to implmement balding_nichols_model without a key_by, which means we need to inject the information we need to know about the key into the IR directly. This means passing the key that's sorted and the partition intervals.; """""". This change just implements the new TableIR node in Scala. Exposure to Python will come in a subsequent change.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12725:786,inject,inject,786,https://hail.is,https://github.com/hail-is/hail/pull/12725,1,['inject'],['inject']
Security,"Copied over from the Zulip thread:. Dan and I still have work to figure out the authentication strategy for browser-based REST requests, but as a workaround I've added a tiny aiohttp proxy that uses the python client library to fulfill the requests, which could enable local frontend work while we figure out the right way to do authentication and streaming data through websockets. Implementing the polling and separating it logically from the view components was actually a nice little case study in how to do this in React/Svelte, but is far from an honest or thorough comparison. If you want to run it for yourself, you can pull down the branch in that PR and then do the following (which I'll write dev docs for if this is something that we actually want to check in):. Install node if you do not have it; Run npm install in the $HAIL, $HAIL/js_common, and $HAIL/batch2/react-batch (or svelte-batch) directories; In one terminal in $HAIL/batch2, run python proxy.py; In another terminal in one of the react-batch or svelte-batch directories, run npm run dev; Go to localhost:3000 in your browser if it didn't pop up automatically",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10504:80,authenticat,authentication,80,https://hail.is,https://github.com/hail-is/hail/pull/10504,2,['authenticat'],['authentication']
Security,Core.java:941) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.AESCipher.engineDoFinal(AESCipher.java:491) ~[sunjce_provider.jar:1.8.0_392]; 	at javax.crypto.CipherSpi.bufferCrypt(CipherSpi.java:779) ~[?:1.8.0_392]; 	at javax.crypto.CipherSpi.engineDoFinal(CipherSpi.java:730) ~[?:1.8.0_392]; 	at javax.crypto.Cipher.doFinal(Cipher.java:2463) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLCipher$T12GcmReadCipherGenerator$GcmReadCipher.decrypt(SSLCipher.java:1606) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:262) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteC,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:9023,access,access,9023,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352,1,['access'],['access']
Security,"Create a filter alleles command. The interface should be modeled off the current filter commands (variant, sample, genotype). One wrinkle is that to update the variant annotations, which must be done by the user, they must have access to information about what alleles were filtered. Rough sketch of the interface:. ```; ... filteralleles; --keep; -c 'va.alleleQuality[aIndex] > 0.8'; -a 'va.info.AC = aIndices.map(i => va.info.AC[i]), va.info.AN = ...'; ```. where `va.alleleQuality` is a hypothetical annotation of type `Array[Double]`. It also has a `--remove` option. `-c` is the filter condition. It has type `Boolean` and `v`, `va`, and `aIndex` in scope, where `aIndex` is the index of the allele being evaluated. `-a` is an annotation expression which updates variant annotations analogous to the `-c` argument of `annotatevariants expr`. It has `v`, `va` and `aIndices`, where `v` is the _new_ variant (so `v.altAlleles.size` is the number of alleles being kept), `va` is the old variant annotations which are being updated, and `aIndices` is a map from the new to old allele indices. Only alternate alleles should be filtered, although all indices should be 0-based, counting the reference. If no alternate alleles remain, the variant should be filtered (no monomorphic variants). Step one should be to sketch the command docs so we can get feedback on the interface. We should work with @konradjk and Monkol to make examples that handle the ExACv2 use case.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/551:228,access,access,228,https://hail.is,https://github.com/hail-is/hail/issues/551,1,['access'],['access']
Security,"Current State; ---. When a commit is merged into a deployable target branch, the [CI deploys that commit](https://github.com/hail-is/hail/blob/master/ci/ci/prs.py#L166-L242). If the deploy job fails, we just [log the failure and change nothing](https://github.com/hail-is/hail/blob/master/ci/ci/prs.py#L295-L313). Since `PRS.latest_deployed` for the given target ref is not changed, the CI will attempt to deploy the latest SHA at the next heal point. We heal periodically, when master changes, when review statuses change, and probably elsewhere. Anywhere we call `PRS.heal_target`. Desired State; ---. Instead, we should track the last successful deploy as well as all the failing deploys since then. This enables us to a) not redeploy a failing deploy and b) find the most recent successful deploy and re-deploy that one. If the most recent successful deploy fails again, we should probably error very loudly. Note that when the CI first comes up there will be no most recent successful deploy. The possible situations are:. - most recent deploy succeeded. - no deploy has ever succeeded. - a deploy has succeeded, but some number of SHAs since then have all failed . Motivation; ---. We want to ensure there is a deployed artifact. For some projects a deploy failure does not leave the universe in a bad state. For example, hail itself updates the latest-hash file after all artifact uploads have succeed. For some projects, a half-way passing deployment will interrupt our users.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4435:1359,hash,hash,1359,https://hail.is,https://github.com/hail-is/hail/issues/4435,1,['hash'],['hash']
Security,Currently only `va` is exposed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1201:23,expose,exposed,23,https://hail.is,https://github.com/hail-is/hail/issues/1201,1,['expose'],['exposed']
Security,"Currently pruning dependencies, forking NextJS to remove poly fills for older browsers, and focusing on bundle size. Investigated using Inferno.js as a lighter alternative to React. Saves ~20-30KB bundle size, and is somewhat faster. However, main Inferno dev moved to React core team, and React is focusing on the optimizations present in Inferno for 2019 (DOM: move to native events where possible), as well as introducing optimizations not found in Inferno (compile time targets: initially inlining, future maybe web assembly binaries; move rendering work to separate thread / concurrent rendering). Furthermore, React ecosystem is orders of magnitude larger, so we can save a huge amount of dev time by avoiding Inferno (N modules * time to develop bespoke module avg), and have greater likelihood of LTS. Notably, I realized that most of my bundle size was coming from inefficient bundling of Material UI and due to Apollo's insanely large graphQL bundle. Removing these now. Lastly, React is actually very efficient. jQuery is ~31.1KB minified. React is 3KB, while React DOM is 33.8KB. In 2019 React DOM will shrink. In any case, given that React is both faster than jQuery, dramatically simplifies development, and introduces development structure, 4KB cost is imo worth it. Related issues:; https://github.com/zeit/next.js/issues/5923. Bundle (with header, authentication logic including jks-rsa verification of token, styles). Index.js is 336 B, _app is 2.89, and that is all that is needed for first page render. _app amortized over all other pages. Scorecard template w/fetch logic is 1.67KB. <img width=""341"" alt=""screen shot 2018-12-19 at 3 43 23 pm"" src=""https://user-images.githubusercontent.com/5543229/50247084-f3202200-03a4-11e9-8232-f1cd2a35958c.png"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-448652812:1365,authenticat,authentication,1365,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-448652812,1,['authenticat'],['authentication']
Security,"Currently spawn one kube watcher per authorized user, with the benefit that each kube watch is light. We could use a one (or a handful) of kube watchers for many users, but this is much more complicated, unless we just have 1 kube watcher watching all pods.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5378:37,authoriz,authorized,37,https://hail.is,https://github.com/hail-is/hail/issues/5378,1,['authoriz'],['authorized']
Security,"Currently the auth service uses its own authentication decorators instead of using those that the other services do (because those make a request to auth which feels a bit circular), but now we have two sets of decorators which we want to mostly keep in step aside from where they get their `UserData` from. This PR creates a small abstraction with an `Authenticator` base class and a `AuthServiceAuthenticator` subclass that extends it and fetches userdata from the auth service. The auth service instead uses a `LocalAuthenticator` which instead of making an rpc directly fetches the userdata from its database. (I would recommend using the split diff)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13672:40,authenticat,authentication,40,https://hail.is,https://github.com/hail-is/hail/pull/13672,2,"['Authenticat', 'authenticat']","['Authenticator', 'authentication']"
Security,"Currently we use the `10.0.0.0/15` range to assign local IPs to jobs on a worker. This is problematic if other resources in our infrastructure collide with this range. Since these are low address ranges it is quite likely that this could happen, and indeed has happened to me in a dev project where the database was assigned a `10.1.x.x` ip and CI jobs that require database access could not run. I don't have a particularly good reason to pick `10.150.0.0/15` as the new range other than I have not seen anything else use it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11051:375,access,access,375,https://hail.is,https://github.com/hail-is/hail/pull/11051,1,['access'],['access']
Security,"Currently, jobs in hail batch can only be run on n1 machines but with the rise of deep learning in bioinformatics, the ability to run jobs on g2 machines, as well as other GPU supported machines, is an important and exciting addition to hail batch. This PR highlights the steps needed to add new machine types into hail batch and could be used as a template for further development support. . The changes in this PR can broadly be divided into additions to the job crun container and insertion of g2 resources (CPU, RAM, L4 Accelerator) into the resources table for billing. This PR uses the NVIDIA Container Toolkit, which allows the creation of GPU accelerated containers. This toolkit is integrated with docker via the parameters —runtime=nvidia and the specification of GPUs is made through —gpus all. The toolkit is installed in the batch worker VM startup script and the corresponding docker parameters are configured if the machine type is g2, so there is no change to the docker configuration for n1 machines. For the toolkit to work there is a nvidia hook that needs to be injected into the crun config. These modifications are also done based on machine type. On the billing side, the existing pricing setup was expanded to include g2 machines. The g2 instance cores and RAM are inserted into the database, and the SKUs are hard coded. For future machine type incorporation or updates, [https://cloud.google.com/skus/?currency=USD&filter=](https://cloud.google.com/skus/?currency=USD&filter=) may serve as a useful resource to identify relevant SKU ids. A new resource type was also added for the accelerator, including preemptible and non-preemtible. Finally, g2 machines mount the worker data disk under the name nvme0n2 so the code is updated to reflect this. Future work may want to investigate a way to automatically detect what the proper disk name is or make the disk naming logic more robust.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13430:1082,inject,injected,1082,https://hail.is,https://github.com/hail-is/hail/pull/13430,1,['inject'],['injected']
Security,"Currently, the Grafana service deployed with the Hail environment is behind two layers of authentication, since the Grafana NGINX configuration proxies requests to it through the `/auth` route, and the login screen built into Grafana also displays. This change removes the second login screen. Demo at https://internal.hail.is/irademac/grafana.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12192:90,authenticat,authentication,90,https://hail.is,https://github.com/hail-is/hail/pull/12192,1,['authenticat'],['authentication']
Security,"Currently, the `_csrf` cookie is made available to all subdomains of `.hail.is`. This means that if I first visit `batch.hail.is` I get a `_csrf` cookie set for `.hail.is`. That cookie is then reused if I visit `ci.hail.is`. Even more awkward, the same value of the cookie will get reused if I then visit `batch.azure.hail.is`. This isn't that big of a deal, these can all be considered part of the same application that the hail team delivers and secures, but it is very little work to set stricter bounds on where this cookie is sent. By removing the `domain` attribute and using `samesite='strict'`, the cookie's domain will be set by the browser to the domain of the request whose response included the `Set-Cookie` header, e.g. `batch.hail.is` or `internal.hail.is`. `Strict` mode then ensures that the cookie will only be sent to that exact domain, meaning that each application is guaranteed to receive the `_csrf` token that it itself delivered, and a `_csrf` token from CI cannot be used to take actions against Batch. This should not have an adverse impact on existing users' browser sessions. In `render_template` we preserve the value of an existing `_csrf` cookie so this change should do the following:; - Logged in user visits a page with an existing widely scoped (`.hail.is`) `_csrf` cookie; - The server returns a `Set-Cookie` header with a new `_csrf` cookie for strictly the `batch.hail.is` domain but with the same token value as the original `_csrf` cookie; - The user now has two cookies and the browser could send either one on a given request, but it does not matter because they have the same value; - If the user logs out and back in, their old widely scoped cookie will be cleared and they only get the strict cookie from now on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14180:448,secur,secures,448,https://hail.is,https://github.com/hail-is/hail/pull/14180,1,['secur'],['secures']
Security,"Currently, the boolean versions aren't being used because there's no equivalent in the function registry. I removed the int and float versions because the Python interface didn't use them. Happy for feedback on what we want to expose. If we want to support booleans now, I'll add new Aggregators that work on annotations (not RV).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3535:227,expose,expose,227,https://hail.is,https://github.com/hail-is/hail/pull/3535,1,['expose'],['expose']
Security,"Currently, the router-resolver returns 500 if the session id is invalid. Instead,; it should return 401. This collapses two states: not authorized due to not being; a developer and not authorized due to not being logged in. This is unfortunate, but; we should avoid leaking information as to *why* this endpoint is unauthorized to; an attacker. Developers, presumably, are knowledgable enough to figure out why; they cannot log in on their own.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8583:136,authoriz,authorized,136,https://hail.is,https://github.com/hail-is/hail/pull/8583,3,"['attack', 'authoriz']","['attacker', 'authorized']"
Security,"Currently, there is no way to use `hailctl dataproc describe` on a table in a [requester pays](https://cloud.google.com/storage/docs/requester-pays) bucket. Accessing files in requester pays buckets requires adding a `-u` flag to `gsutil` with the project to bill for operation, network, and data retrieval charges. https://cloud.google.com/storage/docs/using-requester-pays#using",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9520:157,Access,Accessing,157,https://hail.is,https://github.com/hail-is/hail/pull/9520,1,['Access'],['Accessing']
Security,"Currently, this is set inside GCP, but if anyone were to apply this service.yaml file,; it would reset the global access to `false`. This change ensures that the service.yaml; for internal-gateway reflects the actual desired state. This annotation was added in GKE 1.16 which we now have.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8947:114,access,access,114,https://hail.is,https://github.com/hail-is/hail/pull/8947,1,['access'],['access']
Security,"DS INCOMPATIBLE:** Support for OpenSSL less than 1.1.1d has been; removed. Users on older version of OpenSSL will need to upgrade.; * **BACKWARDS INCOMPATIBLE:** Support for Python 3.6 has been removed.; * **BACKWARDS INCOMPATIBLE:** Dropped support for LibreSSL &lt; 3.6.; * Updated the minimum supported Rust version (MSRV) to 1.56.0, from 1.48.0.; * Updated Windows, macOS, and Linux wheels to be compiled with OpenSSL 3.1.1.; * Added support for the :class:`~cryptography.x509.OCSPAcceptableResponses`; OCSP extension.; * Added support for the :class:`~cryptography.x509.MSCertificateTemplate`; proprietary Microsoft certificate extension.; * Implemented support for equality checks on all asymmetric public key types.; * Added support for ``aes256-gcm@openssh.com`` encrypted keys in; :func:`~cryptography.hazmat.primitives.serialization.load_ssh_private_key`.; * Added support for obtaining X.509 certificate signature algorithm parameters; (including PSS) via; :meth:`~cryptography.x509.Certificate.signature_algorithm_parameters`.; * Support signing :class:`~cryptography.hazmat.primitives.asymmetric.padding.PSS`; X.509 certificates via the new keyword-only argument ``rsa_padding`` on; :meth:`~cryptography.x509.CertificateBuilder.sign`.; * Added support for; :class:`~cryptography.hazmat.primitives.ciphers.aead.ChaCha20Poly1305`; on BoringSSL.; <p>.. _v40-0-2:; </code></pre></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/c4d494fd3ee907316bd846e90cbf4a8df75a25ac""><code>c4d494f</code></a> 41.0.0 version bump (<a href=""https://redirect.github.com/pyca/cryptography/issues/8991"">#8991</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/8708245ccdeaff21d65eea68a4f8d2a7c5949a22""><code>8708245</code></a> new openssl day (<a href=""https://redirect.github.com/pyca/cryptography/issues/8990"">#8990</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/31436a486661cd863d4c77",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13141:1315,Certificate,Certificate,1315,https://hail.is,https://github.com/hail-is/hail/pull/13141,3,['Certificate'],['Certificate']
Security,"Dan thanks for the comments, some great suggestions. I've addressed some, will get to the rest by Monday. I owe you at least one unit test. You can check the app out at app.hail.is (no SSL yet). Let me know if you have a problem logging in. Currently no one knows the workshop password but me (we can set this to whatever needed), but all team members, besides maybe Dan Goldstein should have access through the normal login. . Login will appear a bit slow because we've decided to not go the popup route, so there's an extra 2 apparent redirects. Also, safari causes some issues if ""Cross-site tracking"" protection is on. A satisfactory solution will be made in time, until then, either another browser, or disable that protection.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215#issuecomment-460040036:277,password,password,277,https://hail.is,https://github.com/hail-is/hail/pull/5215#issuecomment-460040036,2,"['access', 'password']","['access', 'password']"
Security,"Dan, I went down a rabbit hole with this one. Updated bootstrap (XSS exploit protection, not EOL), jQuery (a bunch of security patches), focused on using flex box for layout, and fixed many of the inconsistencies I found on the docs page (the way the header was laid out, namely lack of element alignment with rest of docs and odd centering, the weirdness of having two home buttons named Hail, Annotation Database didn't scope styles so changed docs nav layout, broken navbar menu, etc).; - Also removes navbar code duplication in docs. Also after speaking with Jackie, restored fixed navbar on docs (so that it stays in place during scrolling). This may cause issues with (especially older) mobile devices, but those probably aren't spending much time on the docs page anyway. Works great on narrow views as well. Since 0.1 doesn't appear to be built, if these changes can affect that will need to be addressed. Before: https://youtu.be/I-Awgx3spnQ; After: https://youtu.be/ff1387vDsQ8. cc @cseed",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6789#issuecomment-522140293:65,XSS,XSS,65,https://hail.is,https://github.com/hail-is/hail/pull/6789#issuecomment-522140293,2,"['XSS', 'secur']","['XSS', 'security']"
Security,"Database idempotency is easy, use `IF NOT EXISTS`. User cleanup is hard because; the job isn't deterministic. Each attempt will produce a different password. You; cannot retrieve a password of an extant user. The bulk of the changes are in service of creating a job whose attempts will; race to create the password. Only one attempt will win that race and pass its; password on to the `create_database_job`. Those jobs will race to create; databases and users and secrets, but all those operations are now; idempotent (`CREATE USER` uses `IF NOT EXISTS`; the secret is always the same).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8833:148,password,password,148,https://hail.is,https://github.com/hail-is/hail/pull/8833,4,['password'],['password']
Security,"Dataproc does have an option to tag all nodes (`--tags`), but we purposely intend to prevent SSH connections from the outside world to the worker nodes. If you need to access the worker machines, you can still connect to them from the master node (because, due to Spark/Dataproc, we must permit all TCP/IP connections between all Dataproc nodes). I realize this is annoying, but I have only needed to do this once in my three years of working on Hail.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7978#issuecomment-578973470:168,access,access,168,https://hail.is,https://github.com/hail-is/hail/pull/7978#issuecomment-578973470,1,['access'],['access']
Security,Dataproc submission bash script: https://gist.github.com/mcovarr/06eaecad849e979d608adf43e2118f5a; Python script: https://github.com/broadinstitute/gatk/blob/ah_var_store/scripts/variantstore/wdl/extract/filter_VDS_and_shard_by_contig.py. A few things 0.2.123 introduced:; - new gradle (which has caused other dataproc issues); - SemanticHash. My guess is the combination of semantic hash and large JSON literals is pushing us past the 50GiB limit.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13712#issuecomment-1757862008:384,hash,hash,384,https://hail.is,https://github.com/hail-is/hail/issues/13712#issuecomment-1757862008,1,['hash'],['hash']
Security,"Default mysql port is 3306, should probably stick with that for default CLOUD_SQL_PORT, especially since google doesn't expose way to override the default",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5726:120,expose,expose,120,https://hail.is,https://github.com/hail-is/hail/pull/5726,1,['expose'],['expose']
Security,"Delay merging until https://github.com/broadinstitute/install-gcs-connector/pull/6 is merged. Without that PR, users will not have access to a version of the GCS Hadoop connector that does not use tons of memory in JVM 11.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14158#issuecomment-1931024352:131,access,access,131,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1931024352,1,['access'],['access']
Security,"Deploying grafana in our GKE cluster gives us instant and easy access to the stackdriver backend with the same querying capabilities of our current front-end, but without the clutter and insanely slow load times. See [here](https://internal.hail.is/dgoldste/grafana/d/TVkleyLMk/detailed-service-resource-utilization?orgId=1) for some example dashboards I set up to look at resources across our services (credentials are the default admin/admin). This alleviates the immediate pain of using the console (for metrics only, not logging), but my longer aim is that getting more regular use out of our metrics can reveal deeper pain points of our monitoring stack and if/where we need to eat up more responsibility from google monitoring. This is a StatefulSet, so configuration through the UI will persist and is done manually. If we find that our dashboards are stable and boilerplate enough, I'd like to move to a code-based dashboard configuration. Sadly, `check-yaml` does not appreciate our jinja templating in yaml, so I've removed it for now. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10013:63,access,access,63,https://hail.is,https://github.com/hail-is/hail/pull/10013,1,['access'],['access']
Security,Deprecate and remove hail API tokens in favor of OAuth access tokens,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13531:55,access,access,55,https://hail.is,https://github.com/hail-is/hail/issues/13531,1,['access'],['access']
Security,"Deprecate hail-minted API keys in favor of using access tokens from the identity providers already associated with user identities. For more context and a high-level overview of the implementation, see [this RFC](https://github.com/hail-is/hail-rfcs/pull/2)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13131:49,access,access,49,https://hail.is,https://github.com/hail-is/hail/pull/13131,1,['access'],['access']
Security,"Dev certificates expire in 30 days, and rerunning `kubectl create secret` doesn't update the secret if it already exists. So adding a `kubectl delete secret` line to make sure the new secret will be added. Though I'm not familiar with the `test` scope and not sure if it will break something for it?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10188:4,certificate,certificates,4,https://hail.is,https://github.com/hail-is/hail/pull/10188,1,['certificate'],['certificates']
Security,"Did a few things here:. - Specifying a namespace is necessary to run the script, and must be supplied as `default` if you want to change the production images; - Explicitly specify the `subnet` in the VM creation. This was optional before but BITS changed some settings in GCP such that you *have* to specify subnets when creating a VM.; - I hard-coded the ubuntu image. I think this is better for reproducibility/auditing, but this actually broke because the `gcloud` query that used to return one image now returns two (they added an ARM ubuntu).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13404:414,audit,auditing,414,https://hail.is,https://github.com/hail-is/hail/pull/13404,1,['audit'],['auditing']
Security,Do I have to do anything else to get BatchPoolExecutor exposed in the Batch docs?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9156:55,expose,exposed,55,https://hail.is,https://github.com/hail-is/hail/pull/9156,1,['expose'],['exposed']
Security,Docs for accessing ith char of string not rendering code block correctly.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1614:9,access,accessing,9,https://hail.is,https://github.com/hail-is/hail/issues/1614,1,['access'],['accessing']
Security,"Don't use ADD with URL because it hashes the contents for caching; Back off ADD --chown, doesn't work on my version of docker; install kubectl; added batch, ci environments, create in build image; mv Dockerfile.pr-builder, Makefile to toplevel (will be shared); change pip version to conda version; rebuilt and updated build image",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4377:34,hash,hashes,34,https://hail.is,https://github.com/hail-is/hail/pull/4377,1,['hash'],['hashes']
Security,"Done. {Matrix}Table._schema is now private. ttable/tmatrix are exposed, but not documented.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4995#issuecomment-448336466:63,expose,exposed,63,https://hail.is,https://github.com/hail-is/hail/pull/4995#issuecomment-448336466,1,['expose'],['exposed']
Security,Draft of hashcodes for SValues,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10680:9,hash,hashcodes,9,https://hail.is,https://github.com/hail-is/hail/pull/10680,1,['hash'],['hashcodes']
Security,"ECENT_DATE</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/6dd01c74102db0d608687953e351e31df3f31d9f""><code>6dd01c7</code></a> [1.26] Update docs for re-using HTTP connections after streaming</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/2049c91f732ae4fec0216c0697dee7822c25db10""><code>2049c91</code></a> Adds changing branches for installing from git docs for 1.26.x</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/cb4950545be4d427557ce863539c08655c9bdd6e""><code>cb49505</code></a> [1.26] Improve testing for IPv6 scoped addresses</li>; <li>Additional commits viewable in <a href=""https://github.com/urllib3/urllib3/compare/1.26.9...1.26.11"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.9&new-version=1.26.11)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12104:4442,secur,security-vulnerabilities,4442,https://hail.is,https://github.com/hail-is/hail/pull/12104,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Edit: Ready for a look, besides google sa key secret creation, because I'm not completely sure what the use case is, and whether it should be a namespaced secret. Since speaking with Cotton, I've moved to using our cloud mysql instance to track user resources, to ensure that a single user id results in a single resource. We can use auth0, but that would add complexity, and would really only make sense in the context of notebook (or whatever we end up managing users) I think: while auth0 allows you to add custom claims, I believe you need to first get the user's access token (via authentication), then call (server side, no user input needed) the /management api endpoint to check the existence of the claims, and update if they do not exist. So this requires user interaction. Would need to confirm this, if proven true, we will eventually be able to circumvent this by connecting our own database to their service ([they allow this](https://auth0.com/docs/connections/database/custom-db)). Still separately tracking mapping between user id and our resources feels relatively natural, and simpler. . Right now you could supply any identifier for the user_id, as long as its globally unique. I think using the auth0 id makes the most sense, since that is a guaranteed-unique id. I will need to provide you a way to get those ids if you want to use this outside of notebook2. edit: I opted not to separate user table from resources the user owns, because I expect one row per user, so not denormalized. Also, still needs some tests written (mysql related). cc @jigold, @cseed, @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5618:568,access,access,568,https://hail.is,https://github.com/hail-is/hail/pull/5618,2,"['access', 'authenticat']","['access', 'authentication']"
Security,Enable access to annotations previously computed within the same expression,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/634:7,access,access,7,https://hail.is,https://github.com/hail-is/hail/issues/634,1,['access'],['access']
Security,"Envoy by default responds with a 403 if it fails to make an authorization check. We should treat the failure to contact `auth` as a transient error, so that clients can know to retry whatever request they were trying to make instead of failing. In particular, in dev namespaces the current behavior can trigger a QoB client to cancel an ongoing pipeline while polling for completion. [status_on_error](https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/filters/http/ext_authz/v3/ext_authz.proto#extensions-filters-http-ext-authz-v3-extauthz) allows us to configure that default behavior to return a 503 unavailable. I deployed this in Azure by running `make -C gateway deploy NAMESPACE=default`. I poked around to see that I could access my dev namespace and production pages through the browser but did not otherwise try to prove that this failure mode no longer exists.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13735:60,authoriz,authorization,60,https://hail.is,https://github.com/hail-is/hail/pull/13735,2,"['access', 'authoriz']","['access', 'authorization']"
Security,"Erm. There's an interface issue here. I need an output stream that can tell me the file position, but I don't know of any standard library interface that exposes that, so I just hardcoded the `FSDataOutputStream`. Is this going to be a problem? Are all `FS` implementations Hadoop file systems? cc: @akotlar",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6333#issuecomment-501732176:154,expose,exposes,154,https://hail.is,https://github.com/hail-is/hail/pull/6333#issuecomment-501732176,1,['expose'],['exposes']
Security,Error getting access token from metadata server at: http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.Exec,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:1095,access,access,1095,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699,2,['access'],['access']
Security,"Error message is this:. ```; org.apache.spark.SparkException: Task not serializable. Caused by: java.io.NotSerializableException: htsjdk.samtools.reference.FastaSequenceIndex; Serialization stack:; 	- object not serializable (class: htsjdk.samtools.reference.FastaSequenceIndex, value: htsjdk.samtools.reference.FastaSequenceIndex@e7b265e); 	- writeObject data (class: java.util.HashMap); 	- object (class is.hail.io.reference.FastaReader$$anon$1, {}); 	- field (class: is.hail.io.reference.FastaReader, name: cache, type: class java.util.LinkedHashMap); 	- object (class is.hail.io.reference.FastaReader, is.hail.io.reference.FastaReader@5a0e0886); 	- field (class: is.hail.variant.GenomeReference, name: fastaReader, type: class is.hail.io.reference.FastaReader); 	- object (class is.hail.variant.GenomeReference, test); 	- field (class: is.hail.expr.FunctionRegistry$$anonfun$160$$anonfun$apply$94, name: gr$13, type: class is.hail.variant.GRBase); 	- object (class is.hail.expr.FunctionRegistry$$anonfun$160$$anonfun$apply$94, <function2>). plus many more lines; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2881:379,Hash,HashMap,379,https://hail.is,https://github.com/hail-is/hail/pull/2881,1,['Hash'],['HashMap']
Security,"Error message starting up Batch:. ```; raise ApiException(http_resp=r); kubernetes.client.rest.ApiException: (403); Reason: Forbidden; HTTP response headers: HTTPHeaderDict({'Audit-Id': 'fc886821-4fc7-4697-b8d2-a4bc656b45f6', 'Content-Type': 'application/json', 'X-Content-Type-Options': 'nosniff', 'Date': 'Thu, 25 Apr 2019 22:18:26 GMT', 'Content-Length': '252'}); HTTP response body: b'{""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""pods is forbidden: User \\""system:serviceaccount:batch-pods:default\\"" cannot watch pods in the namespace \\""test\\"""",""reason"":""Forbidden"",""details"":{""kind"":""pods""},""code"":403}\n'; ```. Going to retest, but it seems like this was a one time thing...",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5956#issuecomment-487075273:175,Audit,Audit-Id,175,https://hail.is,https://github.com/hail-is/hail/pull/5956#issuecomment-487075273,1,['Audit'],['Audit-Id']
Security,"Existing tables and matrix tables that we don't own/didn't create but are accessible via the datasets API are not always available on both GCS and S3 (e.g. pan UKB datasets are only on AWS S3), or are not available in an `eu` bucket on GCS (e.g. gnomAD datasets). . This just adds a column `cloud: [regions]` to the tables on the datasets API and annotation DB docs pages to be more explicit about what datasets/versions are available on which cloud platform. . So, for example, if a version of a dataset is in `gs://hail-datasets-us`, `gs://hail-datasets-eu`, and `s3://hail-datasets-us-east-1`, then under `cloud: [regions]` we would see `gcp: [eu,us], aws: [us]`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10358:74,access,accessible,74,https://hail.is,https://github.com/hail-is/hail/pull/10358,1,['access'],['accessible']
Security,Expose 'array_elements_required' in 'import_vcf',MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3503:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/pull/3503,1,['Expose'],['Expose']
Security,Expose Genome Reference as global variable,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1789:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/pull/1789,1,['Expose'],['Expose']
Security,Expose RVDContext in RVD.treeAggregate,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3424:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/pull/3424,1,['Expose'],['Expose']
Security,Expose RowMatrix Python API,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3466:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/pull/3466,1,['Expose'],['Expose']
Security,Expose Scala uniroot in expression language,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1717:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/issues/1717,1,['Expose'],['Expose']
Security,Expose VSM interface in python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1153:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/issues/1153,1,['Expose'],['Expose']
Security,Expose a range bounds calculator,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6577:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/pull/6577,1,['Expose'],['Expose']
Security,Expose dtype on Expression,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2713:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/pull/2713,1,['Expose'],['Expose']
Security,Expose filtermulti doc,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/960:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/pull/960,1,['Expose'],['Expose']
Security,"Expose gIsDefined, isLinearScale.; Expose PX for TGenotypeView.; Fixed some offset bugs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2296:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/pull/2296,2,['Expose'],['Expose']
Security,Expose group_by aggregator in Python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4004:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/pull/4004,1,['Expose'],['Expose']
Security,Expose in front end; Currently unused,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9285:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/pull/9285,1,['Expose'],['Expose']
Security,Expose ipynb as primary tutorial (not copy-paste!),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1815:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/issues/1815,1,['Expose'],['Expose']
Security,Expose recode contigs on import methods,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2503:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/pull/2503,1,['Expose'],['Expose']
Security,Expose spark context,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3048:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/pull/3048,1,['Expose'],['Expose']
Security,Expose unpersist VDS in python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1845:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/issues/1845,1,['Expose'],['Expose']
Security,Expose unpersist keytable in python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1852:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/issues/1852,1,['Expose'],['Expose']
Security,Expose v in annotate_variants_table,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1201:0,Expose,Expose,0,https://hail.is,https://github.com/hail-is/hail/issues/1201,1,['Expose'],['Expose']
Security,FS$$anon$2.close(GoogleStorageFS.scala:306); 		at java.io.FilterOutputStream.close(FilterOutputStream.java:159); 		... 27 more; 	Suppressed: is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-6BO4gZ18Lheigp3ir9RSOh&uploadType=resumable&upload_id=ADPycduiXx2Jtiy_0Ll131_pPeEYKnnA23Hlk28_9TFESUMaubA9OqLK_n8Td5rPhTXnlpssGo796Q4bJxUeblhmSaYcCSWAMg2k; chunkOffset: 16777216; chunkLength: 0; localOffset: 1325400064; remoteOffset: 1342177280; lastChunk: false. 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:267); 		at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 		at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103); 		at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 		at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.flushBuffer(BlobWriteChannel.java:189); 		at is.hail.relocated.com.google.cloud.BaseWriteChannel.flush(BaseWriteChannel.java:112); 		at is.hail.relocated.com.google.cloud.BaseWriteChannel.write(BaseWriteChannel.java:139); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$flush$1(GoogleStorageFS.scala:297); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:279); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.flush(GoogleStorageFS.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756:7727,access,access,7727,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756,1,['access'],['access']
Security,"FailedMount 36s (x5 over 9m46s) kubelet, gke-vdc-preemptible-pool-9c7148b2-4gq2 Unable to mount volumes for pod ""batch-2554-job-4-main-vsk7h_batch-pods(f1d2b3ad-9745-11e9-8aa3-42010a80015f)"": timeout expired waiting for volumes to attach or mount for pod ""batch-pods""/""batch-2554-job-4-main-vsk7h"". list of unmounted volumes=[batch-2554-job-4-8vvgl]. list of unattached volumes=[gsa-key batch-2554-job-4-8vvgl default-token-8h99c]; + kubectl describe pvc -n batch-pods batch-2554-job-4-8vvgl; Name: batch-2554-job-4-8vvgl; Namespace: batch-pods; StorageClass: batch; Status: Bound; Volume: pvc-32804669-96f6-11e9-8aa3-42010a80015f; Labels: app=batch-job; hail.is/batch-instance=cd50b95a89914efb897965a5e982a29d; Annotations: pv.kubernetes.io/bind-completed: yes; pv.kubernetes.io/bound-by-controller: yes; volume.beta.kubernetes.io/storage-provisioner: kubernetes.io/gce-pd; Finalizers: [kubernetes.io/pvc-protection]; Capacity: 1Gi; Access Modes: RWO; VolumeMode: Filesystem; Events: <none>; Mounted By: batch-2554-job-4-main-vsk7h; ```; The events; ```; + kubectl get events -n batch-pods --sort-by=.metadata.creationTimestamp; + grep 2554; 12m Warning FailedMount Pod Unable to mount volumes for pod ""batch-2554-job-4-main-cc8d4_batch-pods(968b4ba5-96f6-11e9-8aa3-42010a80015f)"": timeout expired waiting for volumes to attach or mount for pod ""batch-pods""/""batch-2554-job-4-main-cc8d4"". list of unmounted volumes=[batch-2554-job-4-8vvgl]. list of unattached volumes=[gsa-key batch-2554-job-4-8vvgl default-token-8h99c]; 11m Normal Scheduled Pod Successfully assigned batch-pods/batch-2554-job-4-main-vsk7h to gke-vdc-preemptible-pool-9c7148b2-4gq2; 36s Warning FailedMount Pod Unable to mount volumes for pod ""batch-2554-job-4-main-vsk7h_batch-pods(f1d2b3ad-9745-11e9-8aa3-42010a80015f)"": timeout expired waiting for volumes to attach or mount for pod ""batch-pods""/""batch-2554-job-4-main-vsk7h"". list of unmounted volumes=[batch-2554-job-4-8vvgl]. list of unattached volumes=[gsa-key batch-2554-job",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649:20145,Access,Access,20145,https://hail.is,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649,1,['Access'],['Access']
Security,"First cut: https://github.com/broadinstitute/hail/commit/f5e93963844656449259ad893ec3ce7ddcef2f3c. Still needed: testing, implicit option manipulation, access to INFO field and QC results.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/16#issuecomment-156226289:152,access,access,152,https://hail.is,https://github.com/hail-is/hail/issues/16#issuecomment-156226289,1,['access'],['access']
Security,"First of 3 changes, I think:; - batch2 secret field now requires namespace and it is used for lookup (it was required before in validation, but ignored); - CI now sets namespace consistently. Since batch1 pods can only mount secrets from batch-pods, it only sets this to batch-pods. The one exception is when the secretes come from a runImage step. Then the namespace is taken from the runImage step if it is present, and otherwise defaults to batch-pods. Two more PRs:; 1. Set the namespace in all runImage step secrets; 2. Make the namespace required in runImage steps. Then, when we switch CI from batch1 => batch2, we can create runImage steps that use secrets from namespaces other than batch-pods.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7470:128,validat,validation,128,https://hail.is,https://github.com/hail-is/hail/pull/7470,1,['validat'],['validation']
Security,"First, I'm seeing transient (but common, maybe 10% of the time?! Have you seen this before, Jackie?) gsutil errors in the setup/cleanup containers that look like: [Errno 2] No such file or directory. I ran with -DD, the file is there in gs://, something is going wrong in the container. It happens with and without -m. I tried to upgrade google/cloud-sdk, but ran into a problem: after updating the instance base image, the worker container can no longer get credentials from the metadata server and therefore gets permission denied when trying to copy out the logs. Upon reflection, in our setup, containers being able to access the metadata server seems very insecure! So we should (1) make sure containers we run can't access the metadata service, (2) run the instance as no service account, or an account with no privileges. Then we need to figure out how to get the credentials to to the worker to copy out logs. I also added a retry (3x) to the setup/cleanup scripts. I think ultimately using the client libraries directly instead of gsutil might ultimately be the way to go (and it makes it easier for us to see what errors we're getting and which we want to retry). Changes:; - retry in setup/cleanup; - fix ""make deploy"" in batch2 (build worker image); - I fixed up the worker Google image builder logic. There was a race condition with the step command. I broke it into two manual steps. The instance steps itself in the first step. The user should verify the instance is stopped and then run the second step. This can be automated later.; - Fixed bug in mark_jobs_complete updating ready_cores. It counted all children, not just children that are going to transition to ready.; - fixed bug in delete tables script: batch => batches",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7445:623,access,access,623,https://hail.is,https://github.com/hail-is/hail/pull/7445,2,['access'],['access']
Security,Fix mistakenly committed access modifier change,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2125:25,access,access,25,https://hail.is,https://github.com/hail-is/hail/pull/2125,1,['access'],['access']
Security,"Fix python methods, expose samples_to_pandas, integrate logging",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1085:20,expose,expose,20,https://hail.is,https://github.com/hail-is/hail/pull/1085,1,['expose'],['expose']
Security,Fix this issue:. ```; XMLHttpRequest cannot load https://github.com/hail-is/hail/blob/master/www/navbar.html. Origin http://discuss.hail.is is not allowed by Access-Control-Allow-Origin.; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1024:158,Access,Access-Control-Allow-Origin,158,https://hail.is,https://github.com/hail-is/hail/issues/1024,1,['Access'],['Access-Control-Allow-Origin']
Security,"Fixes #12540. CHANGELOG: When using Query-on-Batch, hl.hadoop* methods now properly support creation and modification time. Creation time is supported by modern Linuxes but only through a new statx API which is not exposed by the Python standard library. There is a 0.1 version library from 2021 which exposes statx including the ""birth time"". I chose to raise an exception for now. Each cloud does support a ""modification time"" but it generally refers to changes to metadata or is just the creation time:; - https://cloud.google.com/storage/docs/json_api/v1/objects#resource (see updated); - https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html#API_GetObject_ResponseSyntax (""Last-Modified"", is always creation time); - https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadObject.html#API_HeadObject_ResponseSyntax same as above; - https://learn.microsoft.com/en-us/rest/api/storageservices/get-blob (see Last-Modified and x-ms-creation-time)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12571:215,expose,exposed,215,https://hail.is,https://github.com/hail-is/hail/pull/12571,2,['expose'],"['exposed', 'exposes']"
Security,"Fixes #13346. Another user was confused by this: https://github.com/hail-is/hail/issues/14102. Unfortunately, the world appears to have embraced missing values in VCF array fields even though the single element case is ambiguous. In #13346, I proposed a scheme by which we can disambiguate many of the cases, but implementing it ran into challenges because LoadVCF.scala does not expose whether or not an INFO field was a literal ""."" or elided entirely from that line. Anyway, this error message actually points users to the fix. I also changed some method names such that every method is ArrayType and never TypeArray.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14105:380,expose,expose,380,https://hail.is,https://github.com/hail-is/hail/pull/14105,1,['expose'],['expose']
Security,Fixes #14635. Logout is only possible from `auth` pages due to per-subdomain CRSF tokens. Security/design thought process as documented in a comment on the issue: https://github.com/hail-is/hail/issues/14635#issuecomment-2253086187,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14639:90,Secur,Security,90,https://hail.is,https://github.com/hail-is/hail/pull/14639,1,['Secur'],['Security']
Security,Fixes `bash: line 10: yum: command not found` failures in `delete_azure_batch_instances`. ### Security Assessment; This change has no security impact,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14720:94,Secur,Security,94,https://hail.is,https://github.com/hail-is/hail/pull/14720,2,"['Secur', 'secur']","['Security', 'security']"
Security,Fixes https://github.com/hail-is/hail/security/dependabot/168,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14532:38,secur,security,38,https://hail.is,https://github.com/hail-is/hail/pull/14532,1,['secur'],['security']
Security,Fixes issue #844 global not accessible from filtergenotypes and exportgenotypes.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/847:28,access,accessible,28,https://hail.is,https://github.com/hail-is/hail/pull/847,1,['access'],['accessible']
Security,Fixing with a change to dataproc image version requires a cloud tools upgrade form all our users. Perhaps we should start a new latest-hash file and push a cloud tools update that looks there and uses `1.2-deb9`?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4239#issuecomment-417436405:135,hash,hash,135,https://hail.is,https://github.com/hail-is/hail/pull/4239#issuecomment-417436405,1,['hash'],['hash']
Security,"For Ricopili, Stephan creates a file in the user's home directory that records the exact command line used, the current working directory, the timestamp, and the task name plus the number of jobs submitted to the cluster. Example:; my_working_directory/pca pcaer_20 --noproject --prefercase --preferfam --out muhammad_pakistani_4pop pop_4pop_mix_SEQ.bim scz_ayub1_sas_jg-qc.bim prune2.000001 Fri_Dec_18_17:55:29_2015; my_working_directory/pca pcaer_20 --noproject --prefercase --preferfam --out muhammad_pakistani_4pop pop_4pop_mix_SEQ.bim scz_ayub1_sas_jg-qc.bim genome.000013 Fri_Dec_18_17:57:12_2015; my_working_directory/pca pcaer_20 --noproject --prefercase --preferfam --out muhammad_pakistani_4pop pop_4pop_mix_SEQ.bim scz_ayub1_sas_jg-qc.bim epca.000001 Fri_Dec_18_17:57:53_2015; my_working_directory/pca pcaer_20 --noproject --prefercase --preferfam --out muhammad_pakistani_4pop pop_4pop_mix_SEQ.bim scz_ayub1_sas_jg-qc.bim qqpl.000020 Fri_Dec_18_18:26:43_2015; my_working_directory/pca pcaer_20 --noproject --prefercase --preferfam --out muhammad_pakistani_4pop pop_4pop_mix_SEQ.bim scz_ayub1_sas_jg-qc.bim pcaplot.000001 Fri_Dec_18_18:28:15_2015; my_working_directory/pca pcaer_20 --noproject --prefercase --preferfam --out muhammad_pakistani_4pop pop_4pop_mix_SEQ.bim scz_ayub1_sas_jg-qc.bim finished Fri_Dec_18_18:32:17_2015. I think it would be good to record a timestamp, the command line used, possibly the working directory, and an identifier for the version of hail used (hash code) in one place (maybe ~/.hail_history??) that way someone can easily grep the file to figure out what they did for a particular dataset in the past.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/196:1491,hash,hash,1491,https://hail.is,https://github.com/hail-is/hail/issues/196,1,['hash'],['hash']
Security,For feedback - a couple of potential templates for capturing security impacts at either the issue or PR level.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14666:61,secur,security,61,https://hail.is,https://github.com/hail-is/hail/pull/14666,1,['secur'],['security']
Security,For some reason either artifact registry or aiodocker returns a 500 instead of a 403 when a service account does not have access to pull an image. Had to add another special case for handling this error. https://console.cloud.google.com/logs/query;query=%22ys6od%22;pinnedLogId=2022-10-03T13:09:09.430766581Z%2Fyw46w2divo5eqk0vv;cursorTimestamp=2022-10-03T13:09:09.430766581Z?project=hail-vdc,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12257:122,access,access,122,https://hail.is,https://github.com/hail-is/hail/pull/12257,1,['access'],['access']
Security,"For terra I currently have the front-end and driver running in the same pod, so I can't have the front-end listening on port 443 since it's in use by something else in the pod. Seemed like a reasonable enough change on its own. There will be an entirely separate `deployment.yaml` for terra so better to expose small options like these there than in the python code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12613:304,expose,expose,304,https://hail.is,https://github.com/hail-is/hail/pull/12613,1,['expose'],['expose']
Security,Forgot to authorize when I did dev deploy.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6645:10,authoriz,authorize,10,https://hail.is,https://github.com/hail-is/hail/pull/6645,1,['authoriz'],['authorize']
Security,Forgot to authorize with gcloud so that I could copy JARs to GCS.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4275:10,authoriz,authorize,10,https://hail.is,https://github.com/hail-is/hail/pull/4275,1,['authoriz'],['authorize']
Security,From Cotton:. Items to be address:. - [ ] Recursively make push the jupyter image and embed its entire hash in your Docker image or deployment; - [ ] Remove unused stuff for building images. cc @cseed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5822:103,hash,hash,103,https://hail.is,https://github.com/hail-is/hail/issues/5822,1,['hash'],['hash']
Security,"From Grace:; > I've run a sample sites-only VCF through vcftools's vcf-validator tool, and it is complaining that there's nothing in the FORMAT column and that the VCF has a lot of trailing tabs on the variant lines (which it interprets as empty columns). Is there an easy way to remove the FORMAT column from the header and to cut off the trailing tabs without going in to do post-hoc VCF surgery?. > Also, I think we want to drop the GL contigs from the header that automatically get appended. Can I do that in the vcf export command?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4338:71,validat,validator,71,https://hail.is,https://github.com/hail-is/hail/issues/4338,1,['validat'],['validator']
Security,"From the under development R interface, we want to call this method definition in `is.hail.expr.ir.IRParser`:. ```; def parse_table_ir(s: String, refMap: java.util.HashMap[String, String], irMap: java.util.HashMap[String, BaseIR]); ```. But the method signature is using `java.util.HashMap` instead of `java.util.Map` and the sparklyr JVM layer translates the R map equivalent (an environment) to a different implementation of `java.util.Map`, so dispatch fails. Since the conversion is transparent, there is no way to _force_ a particular implementation of `java.util.Map`. Is there any reason to require `java.util.HashMap` there, or could the signature be generalized? There are cases like this throughout the Hail API, for all collection types.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5340:164,Hash,HashMap,164,https://hail.is,https://github.com/hail-is/hail/issues/5340,4,['Hash'],['HashMap']
Security,"Further pruned. Removed all GraphQL libraries, besides graphql-tag, which I like, because 1) simple hash-based cache: no need to walk complex graph to normalize cache, because in most cases I'm perfectly fine with not re-using cache across different queries (that may have some shared fields). Apollo does something ""smarter"", but much slower: walks a query, checks that the requested fields for a node are the same, and that the node's id is the same, as some other query. 2) no runtime validation of query shape via graphql-tag...uses simple template strings, which are free. We don't care about schema validation in the client...because the server will error when schema is invalid. This should be compile time validated instead, in this case via integration tests. Also removed react-icons... I was going to use this in place of material-design-icons, because I thought loading the full font, when I needed only a few icons, would be unnecessarily expensive. It turns out that I cannot find a library where a single icon import (react-icons or MaterialUI) is smaller than Google's entire material design font: a single font (there are several needed to cover all icons) is ~500B. A single react-icons icon is ~2KB on dev (production may be smaller due to tree shaking). Also, am opposed to CSS-in-JS: slower, worse tooling, larger. Benefits are dynamic selectors, which are really no advantage that I can see (without them can still dynamically apply classes, as in the yee ol days of pleb vanilla js). Home page down to <2kb when not logged in, and 3.1KB logged in. This includes header, simple body, and dark mode button.; <img width=""2636"" alt=""screen shot 2018-12-19 at 11 49 59 pm"" src=""https://user-images.githubusercontent.com/5543229/50264482-ed4c3000-03e8-11e9-80d1-81d195a7b37a.png"">; <img width=""2636"" alt=""screen shot 2018-12-19 at 11 50 33 pm"" src=""https://user-images.githubusercontent.com/5543229/50264483-ed4c3000-03e8-11e9-8180-1409ca16573f.png"">. edit: Further .1KB shaved (gzipp",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-448868665:100,hash,hash-based,100,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-448868665,4,"['hash', 'validat']","['hash-based', 'validated', 'validation']"
Security,Gateway: use cookies instead of query string to pass access token,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5253:53,access,access,53,https://hail.is,https://github.com/hail-is/hail/pull/5253,1,['access'],['access']
Security,GatewayConnection.run(GatewayConnection.java:238); at java.lang.Thread.run(Thread.java:745). java.io.FileNotFoundException: /scratch/.writeBlocksRDD-l5om7fTy3akZKCYbLDY4AD.crc (Too many open files); at java.io.FileOutputStream.open0(Native Method); at java.io.FileOutputStream.open(FileOutputStream.java:270); at java.io.FileOutputStream.<init>(FileOutputStream.java:213); at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:222); at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209); at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307); at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296); at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328); at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:402); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:778); at is.hail.io.fs.HadoopFS.createNoCompression(HadoopFS.scala:60); at is.hail.io.fs.FS$class.create(FS.scala:151); at is.hail.io.fs.HadoopFS.create(HadoopFS.scala:56); at is.hail.linalg.WriteBlocksRDD$$anonfun$62.apply(BlockMatrix.scala:1838); at is.hail.linalg.WriteBlocksRDD$$anonfun$62.apply(BlockMatrix.scala:1829); at scala.Array$.tabulate(Array.scala:331); at is.hail.linalg.WriteBlocksRDD.compute(BlockMatrix.scala:1829); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403:18413,Checksum,ChecksumFileSystem,18413,https://hail.is,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403,1,['Checksum'],['ChecksumFileSystem']
Security,"Generic: computation of split values is done in expression language.; Support HTS-like split of generic schema.; Removed fakeRef, which I don't think anyone ever used. If anyone wants it, can be added through expression language once that is exposed. @tpoterba FYI I removed fakeRef.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2359:242,expose,exposed,242,https://hail.is,https://github.com/hail-is/hail/pull/2359,1,['expose'],['exposed']
Security,"Getting this with current master on the cloud:. ```; Use of uninitialized value in hash element at /vep/ensembl-tools-release-85/scripts/variant_effect_predictor/Bio/EnsEMBL/Variation/Utils/VEP.pm line 4255, <VARS> line 1.; [Stage 18:=> (273 + 410) / 13592]Traceback (most recent call last):; File ""/tmp/7ff73b01-6ea1-4254-a49d-01e9075ab5b0/subset.py"", line 75, in <module>; main(args, pops); File ""/tmp/7ff73b01-6ea1-4254-a49d-01e9075ab5b0/subset.py"", line 51, in main; 'va.rf').write(args.output + "".autosomes.vds"", overwrite=True); File ""/tmp/7ff73b01-6ea1-4254-a49d-01e9075ab5b0/utils.py"", line 452, in post_process_vds; vds = vds.vep(config=vep_config, csq=True, root='va.info.CSQ', force=True); File ""<decorator-gen-110>"", line 2, in vep; File ""/tmp/7ff73b01-6ea1-4254-a49d-01e9075ab5b0/pyhail-attr.zip/hail/java.py"", line 93, in handle_py4j; hail.java.FatalError: NoSuchElementException: None.get; [Stage 18:=> (277 + 409) / 13592]java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@2a632cbb rejected from java.util.concurrent.ThreadPoolExecutor@974d518[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 2913]; ```. Lmk if you need more log.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1518:83,hash,hash,83,https://hail.is,https://github.com/hail-is/hail/issues/1518,1,['hash'],['hash']
Security,"Good questions:. > How does Terraform know to import the module gsa_k8s_secret? I assume it just scans the directory. In short, yes. Every module is defined by a `main.tf`, `variables.tf`, and `outputs.tf`, and it finds it through the `source` path in the module blocks. When you run `terraform init` in the `infra` directory, it scans `main.tf`, sees that there are module references to the local filesystem, and sets up a watch on that directory (you can still make changes to `gsa_k8s_secret` without re-running `init`). > What does ${module.ci_gsa_secret....} do? Does module refer to that terraform file?. The way references work in terraform is a little bizarre. There are basically three classes of value that we use right now in terraform: resources, modules and variables. You declare instances of them like so (note that I'm using class and instance colloquially):. ```; resource <resource_class_name> <resource_instance_name> {; …; }. # I like to think of modules as being essentially unnamed collections of resources; module <module_instance_name> {; source = '/path/to/module'; …; }. variable <variable_name> {; …; }; ```. and then reference them like so:. ```; <resource_class_name>.<resource_instance_name>; module.<module_instance_name>; var.<variable_name>; ```. So module.ci_gsa_secret.... is how you would access `output`s of the module instance called `ci_gsa_secret`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10785#issuecomment-900398381:1325,access,access,1325,https://hail.is,https://github.com/hail-is/hail/pull/10785#issuecomment-900398381,1,['access'],['access']
Security,"Got it! You need to add the loop device. Now how to parse the correct thing from the xfs_info output is another story... ```; jigold@jg-file-cache:~$ xfs_info /mnt/test_xfs; meta-data=/dev/loop2 isize=512 agcount=4, agsize=65536 blks; = sectsz=512 attr=2, projid32bit=1; = crc=1 finobt=1 spinodes=0 rmapbt=0; = reflink=1; data = bsize=4096 blocks=262144, imaxpct=25; = sunit=0 swidth=0 blks; naming =version 2 bsize=4096 ascii-ci=0 ftype=1; log =internal bsize=4096 blocks=2560, version=2; = sectsz=512 sunit=0 blks, lazy-count=1; realtime =none extsz=4096 blocks=0, rtextents=0; ```. ```; jigold@jg-file-cache:~$ sudo docker run --rm --mount type=bind,source=/mnt/test_xfs,target=/host --cap-add SYS_ADMIN --security-opt apparmor:unconfined --device ""/dev/loop2:/dev/loop2:rwm"" test-xfs /bin/bash -c 'xfs_quota -x -c ""report -h"" /host'; Project quota on /host (/dev/loop2); Blocks; Project ID Used Soft Hard Warn/Grace; ---------- ---------------------------------; #0 4K 0 0 00 [------]; #200 0 0 0 00 [------]; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9076#issuecomment-662462004:709,secur,security-opt,709,https://hail.is,https://github.com/hail-is/hail/pull/9076#issuecomment-662462004,1,['secur'],['security-opt']
Security,Great. I don't think I have write access to merge,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1423#issuecomment-281823930:34,access,access,34,https://hail.is,https://github.com/hail-is/hail/pull/1423#issuecomment-281823930,1,['access'],['access']
Security,"Great. So what I'm also interested in comparing is, if I just need, say, hail/pipeline/test, what's the download full tar and extract (of just hail/pipeline/test) vs download just hail/pipeline/test tar with full extract?. > There's something to be said for tar'ing everything except for .git, but I didn't carefully check which steps need it and which steps do not. I would have hoped no downstream steps need .git, but some build steps do trivially (e.g. look at the hash). Hrm.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7626#issuecomment-560458090:469,hash,hash,469,https://hail.is,https://github.com/hail-is/hail/pull/7626#issuecomment-560458090,1,['hash'],['hash']
Security,"Great; I was debating whether to suggest that. I think we'll need sanitize the docker and k8s issues eventually, but for now, the more information the better.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7484#issuecomment-551259023:66,sanitiz,sanitize,66,https://hail.is,https://github.com/hail-is/hail/pull/7484#issuecomment-551259023,1,['sanitiz'],['sanitize']
Security,"Hail Version: `0.2.53-8140f17d9262`. I've got a matrix table where I have added a row and col index to, and am trying to select a field from the table using the following syntax and getting the following error:. `mt[1, 1].GT`. ```; The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last); <ipython-input-65-47ed69d0881f> in <module>; 1 for header in headers:; ----> 2 ext = ext.annotate(newHeader = filtered[header.row_idx, ext.idx].GT); 3 ext = ext.rename({ 'newHeader': header.header }). /usr/local/lib/python3.6/site-packages/hail/matrixtable.py in __getitem__(self, item); 626 return self.index_entries(row_key, col_key); 627 except TypeError as e:; --> 628 raise invalid_usage from e; 629 raise invalid_usage; 630. TypeError: MatrixTable.__getitem__: invalid index argument(s); Usage 1: field selection: mt['field']; Usage 2: Entry joining: mt[mt2.row_key, mt2.col_key]. To join row or column fields, use one of the following:; rows:; mt.index_rows(mt2.row_key); mt.rows().index(mt2.row_key); mt.rows()[mt2.row_key]; cols:; mt.index_cols(mt2.col_key); mt.cols().index(mt2.col_key); mt.cols()[mt2.col_key]; ```. Please let me know if you need any further information. The zulip topic name is `Error accessing entry by row/col key`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9704:1261,access,accessing,1261,https://hail.is,https://github.com/hail-is/hail/issues/9704,1,['access'],['accessing']
Security,Hail defaults to logging to `hail.log` in the working directory of the Spark process. Apparently the user running spark doesn't have permission to create files in its working directory. You might try ; ```python; hc = hail.HailContext(log='/tmp/hail.log'); ```. Or any other file to which you have write access.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-337912555:304,access,access,304,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337912555,1,['access'],['access']
Security,"Hail doesn't have a conda package -- the bioconda package there was not uploaded by the Hail Team (could even be malware -- we don't know). It's certainly a very old version. If you install Hail with pip, you should pick up the latest version 0.2.100 and have access to hl.vds, which is somewhat recent functionality.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6762#issuecomment-1262357111:260,access,access,260,https://hail.is,https://github.com/hail-is/hail/issues/6762#issuecomment-1262357111,1,['access'],['access']
Security,Hail fails on write to HDFS Encryption Zone,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10087:28,Encrypt,Encryption,28,https://hail.is,https://github.com/hail-is/hail/issues/10087,1,['Encrypt'],['Encryption']
Security,"Hail fails when trying to filter a MatrixTable based on locus position; -----------------------------------------------------------------------------; To reproduce; ```python; import hail as hl; mt = hl.import_vcf(""http://hgdownload.cse.ucsc.edu/gbdb/hg19/1000Genomes/phase3/ALL.chrY.phase3_integrated_v1a.20130502.genotypes.vcf.gz"", force_bgz=True); ----------------------------------------------------------------------; Initializing Hail with default parameters...; 2022-10-06 15:56:03 WARN Utils:69 - Your hostname, nid resolves to a loopback address: 127.0.1.1; using 192.168.248.80 instead (on interface wlp0s20f3); 2022-10-06 15:56:03 WARN Utils:69 - Set SPARK_LOCAL_IP if you need to bind to another address; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/med/.local/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.3.jar) to constructor java.nio.DirectByteBuffer(long,int); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 2022-10-06 15:56:03 WARN NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 3.1.3; SparkUI available at http://192.168.248.80:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.100-2ea2615a797a; LOGGING: writing to /; --------------------------------------------------------------------------; mt.filter_rows(mt.locus.position==2867101).count_rows(); ```; ### Expected ; Return a count of rows with that condition. ### Error ; ```; FatalError: Assertio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12280:748,access,access,748,https://hail.is,https://github.com/hail-is/hail/issues/12280,2,['access'],['access']
Security,"Hail tries to do a lot of data integrity checks and warn the user about problems. We've found a number of bugs in upstream tools and workflows that were arguably incorrect. But generating warnings when importing a 2TB file is a challenge in Spark. Right now we use Spark's Accumulators to accumulate classes of error messages and write them out at the end of the pipeline run (see the VCFReport object). However, we use them in non-actions and get incorrect reports (due to job restarts or reused stages in the pipeline). I have an idea about how to fix this by accumulating only at the end of a successful mapPartitions operation and recording the stageId and taskAttemptId from the TaskContext. The accumulator should only accumulate one of the reports from a successful mapPartitions. Using this, I wanted to build an abstraction for reporting warnings and other messages reliably on large import steps. If this works, we plan to float it up to the Spark mailing list to see if it can be of use, or at least write a nice blog post explaining how to get reliable accumulators in Spark. See the discussion here for the current situation:. http://stackoverflow.com/questions/29494452/when-are-accumulators-truly-reliable. Closed as won't fix:. https://issues.apache.org/jira/browse/SPARK-732. Of course, I might be missing something obvious and this won't work.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/371#issuecomment-240550289:31,integrity,integrity,31,https://hail.is,https://github.com/hail-is/hail/issues/371#issuecomment-240550289,1,['integrity'],['integrity']
Security,"Hello, when I test hail in the spark cluster, there is an error:. bash-4.2$ spark-submit --executor-memory 16g --executor-cores 4 --class org.broadinstitute.hail.driver.Main ***/hail-all-spark.jar --master yarn-client importvcf /user/hail/sample.vcf splitmulti write -o /user/hail/sample_1.vds exportvcf -o /user/hail/sample_1.vcf. Exception in thread ""main"" java.lang.UnsupportedClassVersionError: org/apache/solr/client/solrj/SolrClient : Unsupported major.minor version 52.0; at java.lang.ClassLoader.defineClass1(Native Method); at java.lang.ClassLoader.defineClass(ClassLoader.java:800); at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142); at java.net.URLClassLoader.defineClass(URLClassLoader.java:449); at java.net.URLClassLoader.access$100(URLClassLoader.java:71); at java.net.URLClassLoader$1.run(URLClassLoader.java:361); at java.net.URLClassLoader$1.run(URLClassLoader.java:355); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:354); at java.lang.ClassLoader.loadClass(ClassLoader.java:425); at java.lang.ClassLoader.loadClass(ClassLoader.java:358); at org.broadinstitute.hail.driver.ToplevelCommands$.<init>(Command.scala:62); at org.broadinstitute.hail.driver.ToplevelCommands$.<clinit>(Command.scala); at org.broadinstitute.hail.driver.Main$.main(Main.scala:205); at org.broadinstitute.hail.driver.Main.main(Main.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deplo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/825:601,secur,security,601,https://hail.is,https://github.com/hail-is/hail/issues/825,6,"['Access', 'Secur', 'access', 'secur']","['AccessController', 'SecureClassLoader', 'access', 'security']"
Security,"Hey @tpoterba I tried, but am getting ; `remote: Permission to broadinstitute/hail.git denied to bw2.; fatal: unable to access 'https://github.com/broadinstitute/hail/': The requested URL returned error: 403`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/805#issuecomment-248072411:120,access,access,120,https://hail.is,https://github.com/hail-is/hail/pull/805#issuecomment-248072411,1,['access'],['access']
Security,"Hi @pettyalex, thank you for the detailed and thoughtful issue. Hopefully I can shed some light and address all your concerns. I think the assertion on Java 8 and 11 was an overly defensive precaution put in place some time ago, as hail uses some unsafe JVM APIs that have been deprecated for a while. But as you noted, the world goes on in Java 17 and I don't see a reason Hail shouldn't be compatible. Since most of our closest users use Hail on GCP Dataproc, we generally keep in lock-step with their platform which is unfortunately still on Java 11 so that is what we test against and officially support. Nevertheless, we should remove the restriction and add some light validation in CI against Java 17 and advertise it as unofficially supported until such a time that Dataproc moves to Java 17. Hopefully Spark 3.6 will force their hand. The release process for 0.2.129 is already underway but expect this to be resolved in 0.2.130. Thanks for your suggestions regarding bundling the JRE and the GC options, we'll definitely consider them. Regarding the `module-info.class` nonsense, my apologies. That just seems like a bug we should fix. I will create a separate tracking issue for that but I'm not yet sure where that will get prioritized. If it is more than an annoyance for you, please let us know. Regarding conda-forge, I don't think we currently have the bandwidth or demand (that we know of) to add more distribution systems. Again, this is something where hearing from the community is the best way to figure out how to direct our efforts. Hopefully this addresses your concerns. Please do follow up if I've missed anything or open more issues if you encounter new problems.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14433#issuecomment-2030358704:675,validat,validation,675,https://hail.is,https://github.com/hail-is/hail/issues/14433#issuecomment-2030358704,1,['validat'],['validation']
Security,"Hi folks,. In evaluating Hail to see whether it fits my use case (a variant frequency database) I ran into an issue with importing VCF files from GIAB. It turns out that these use type `String` for the `PS` `##FORMAT` entry. Subsequently, Hail fails to import these with the error:; ```; is.hail.utils.HailException: HG001.vcf.gz:column 492: invalid character 'P' in integer literal; ```; This is because of the default behaviour of `htsjdk` to ""repair"" these according to the VCF ""standard"". `htsjdk` exposes `codec.disableOnTheFlyModifications` to toggle this behaviour which can be called from somewhere around https://github.com/hail-is/hail/blob/master/hail/src/main/scala/is/hail/io/vcf/LoadVCF.scala#L1143. Ideally I would like to expose this toggle also at the `import_vcf` method of Hail.; I'll create a PR to do so accordingly ASAP. Comments/questions?. Thanks!. Regards,. Mark",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6012:502,expose,exposes,502,https://hail.is,https://github.com/hail-is/hail/issues/6012,2,['expose'],"['expose', 'exposes']"
Security,"Hi there @BioDCH, I reformatted your comment using [markdown code blocks](https://guides.github.com/features/mastering-markdown/#syntax). It looks like the unix user running `hail` does not have permission to edit `hail.log` file, this likely caused the other two errors. Please add `--log-file PATH` where `PATH` is a file path to which you have write access. For example:. ```; spark-submit --executor-memory 16g --executor-cores 4 --class org.broadinstitute.hail.driver.Main ******/hail-all-spark.jar ; --master yarn-client importvcf --log-file /user/hail/hail.log /user/hail/split_test.vcf splitmulti write -o /user/hail/split_test_1_1.vds exportvcf -o /user/hail/split_test_1_1.vcf; ```. Assuming you have write access to `/user/hail/hail.log`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/825#issuecomment-250746848:353,access,access,353,https://hail.is,https://github.com/hail-is/hail/issues/825#issuecomment-250746848,2,['access'],['access']
Security,"Hi, I'm getting the same error trying to build Hail on Amazon Linux on an EMR cluster.; The suggested fix from issue #454 did not work. To reproduce:; - Create EMR cluster (using default Amazon Linux AMI ami-044cb769); - Install git (`sudo yum install git`); - Install gradle . > #!/bin/bash; > cd /root; > gradle_package=`curl -s http://services.gradle.org/distributions --list-only | sed -n 's/.*\(gradle-.*.all.zip\).*/\1/p' | egrep -v ""milestone|rc"" | head -1`; > gradle_version=`ls ${gradle_package} | cut -d ""-"" -f 1,2`; > mkdir /opt/gradle; > wget -N http://services.gradle.org/distributions/${gradle_package}; > unzip -oq ./${gradle_package} -d /opt/gradle; > ln -sfnv ${gradle_version} /opt/gradle/latest; > printf ""export GRADLE_HOME=/opt/gradle/latest\nexport PATH=\$PATH:\$GRADLE_HOME/bin"" > /etc/profile.d/gradle.sh; > . /etc/profile.d/gradle.sh; > hash -r ; sync; > gradle -v; - gradle -v. > [...]; > Gradle 2.6; > [...]; > Build time: 2015-08-10 13:15:06 UTC; > Build number: none; > Revision: 233bbf8e47c82f72cb898b3e0a96b85d0aad166e; > Groovy: 2.3.10; > Ant: Apache Ant(TM) version 1.9.3 compiled on December 23 2013; > JVM: 1.7.0_101 (Oracle Corporation 24.95-b01); > OS: Linux 4.4.11-23.53.amzn1.x86_64 amd64; - Clone hail from commit 6382678846a9c187d448713f26a2c38f21a683db; - `$ gradle installDist`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/453#issuecomment-229750270:862,hash,hash,862,https://hail.is,https://github.com/hail-is/hail/issues/453#issuecomment-229750270,1,['hash'],['hash']
Security,"Hi, danking, @danking I tried two log file pathes ,all had access permission, but the error still appeared. （1）HDFS file path ：/user/hail/hail.log， have access permission; -rwxrwxrwx 3 hdfs supergroup 0 2016-10-08 10:54 /user/hail/hail.log; （2）log file：local PATH， hava access permission; -rwxrwxrwx 1 root root 48523 Oct 8 11:42 hail.log. The error message was attached as follows ; [splitmulti_1_1.txt](https://github.com/hail-is/hail/files/517467/splitmulti_1_1.txt)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/825#issuecomment-252404979:59,access,access,59,https://hail.is,https://github.com/hail-is/hail/issues/825#issuecomment-252404979,3,['access'],['access']
Security,"Hi,. I have an issue where hail fails when writing to an HDFS encryption zone. HDFS writes to a non-encrypted HDFS work OK. Here is the stacktrace:; java.io.IOException: Stream closed; at org.apache.hadoop.crypto.CryptoOutputStream.checkStream(CryptoOutputStream.java:270); at org.apache.hadoop.crypto.CryptoOutputStream.flush(CryptoOutputStream.java:257); at java.io.FilterOutputStream.flush(FilterOutputStream.java:140); at java.io.DataOutputStream.flush(DataOutputStream.java:123); at is.hail.io.fs.HadoopFS$$anon$1.flush(HadoopFS.scala:35); at java.io.DataOutputStream.flush(DataOutputStream.java:123); at java.io.FilterOutputStream.close(FilterOutputStream.java:158); at is.hail.utils.package$.using(package.scala:620); at is.hail.io.RichContextRDDRegionValue$.writeSplitRegion(RichContextRDDRegionValue.scala:106); at is.hail.rvd.RVD$$anonfun$29.apply(RVD.scala:938); at is.hail.rvd.RVD$$anonfun$29.apply(RVD.scala:936); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18.apply(ContextRDD.scala:259); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18.apply(ContextRDD.scala:259); at is.hail.utils.richUtils.RichContextRDD$$anonfun$cleanupRegions$1$$anonfun$2.apply(RichContextRDD.scala:62); at is.hail.utils.richUtils.RichContextRDD$$anonfun$cleanupRegions$1$$anonfun$2.apply(RichContextRDD.scala:62); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at is.hail.utils.richUtils.RichContextRDD$$anonfun$cleanupRegions$1$$anon$1.hasNext(RichContextRDD.scala:71); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mut",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10087:62,encrypt,encryption,62,https://hail.is,https://github.com/hail-is/hail/issues/10087,2,['encrypt'],"['encrypted', 'encryption']"
Security,"Hi,; While loading a plink binary file generated by plink2, I receive the following error in my hail.log: . hail: info: running: importplink --bfile plinktest_chr21 --delimiter ' '; hail: info: Found 152249 samples in fam file.; hail: info: Found 982854 variants in bim file.; ^M[Stage 0:> (0 + 0) / 279]^M[Stage 0:> (0 + 31) / 279]hail: importplink: caught exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 18 in stage 0.0 failed 4 times, most recent failure: Lost task 18.3 in stage 0.0 (TID 60, 10.93.109.80): java.io.EOFException: Cannot seek to a negative offset; at org.apache.hadoop.fs.FSInputChecker.seek(FSInputChecker.java:399); at org.apache.hadoop.fs.FSDataInputStream.seek(FSDataInputStream.java:62); at org.apache.hadoop.fs.ChecksumFileSystem$FSDataBoundedInputStream.seek(ChecksumFileSystem.java:325); at org.apache.hadoop.fs.FSDataInputStream.seek(FSDataInputStream.java:62); at org.broadinstitute.hail.io.HadoopFSDataBinaryReader.seek(HadoopFSDataBinaryReader.scala:17); at org.broadinstitute.hail.io.plink.PlinkBlockReader.seekToFirstBlockInSplit(PlinkBlockReader.scala:34); at org.broadinstitute.hail.io.plink.PlinkBlockReader.<init>(PlinkBlockReader.scala:23); at org.broadinstitute.hail.io.plink.PlinkInputFormat.getRecordReader(PlinkInputFormat.scala:11); at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:237); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); at org.apache.spark.rdd.RDD",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/715:771,Checksum,ChecksumFileSystem,771,https://hail.is,https://github.com/hail-is/hail/issues/715,2,['Checksum'],['ChecksumFileSystem']
Security,"Hmm, actually GKE seems to vary in how quickly it gets new versions out. It [supported k8s 1.11](https://cloud.google.com/kubernetes-engine/release-notes) for Early Access Partners (EAPs) within about a month. 1.12 was released a little less than a month ago. The first generally available GKE k8s 1.10 release was May 15, and k8s 1.10 was released on March 26th, so that's less than two months from k8s to GKE.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4624#issuecomment-432726145:165,Access,Access,165,https://hail.is,https://github.com/hail-is/hail/pull/4624#issuecomment-432726145,1,['Access'],['Access']
Security,"Hmm. This means every dev deploy will generate a new root key. I'm worried about the derived keys and trust lists. After this runs, any service which was not dev deployed needs to know to reload the trust list and start using the new key. For example, if you dev deploy batch, then separately dev deploy query, the new query will get cert errors when talking to batch, I think. I will give some thought this week to the right long-term certificate strategy.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10188#issuecomment-804338199:436,certificate,certificate,436,https://hail.is,https://github.com/hail-is/hail/pull/10188#issuecomment-804338199,1,['certificate'],['certificate']
Security,"How are you running Spark? Are you running in local mode, or in cluster mode? In local mode, you won't have access to the HDFS file scheme.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-320923206:108,access,access,108,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-320923206,1,['access'],['access']
Security,"Hub:</em>; <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8014"">#8014</a>.</p>; </li>; <li>; <p>Added runtime type check for <code>ClientSession</code> <code>timeout</code> parameter.</p>; <p><em>Related issues and pull requests on GitHub:</em>; <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8021"">#8021</a>.</p>; </li>; <li>; <p>Fixed an unhandled exception in the Python HTTP parser on header lines starting with a colon -- by :user:<code>pajod</code>.</p>; <p>Invalid request lines with anything but a dot between the HTTP major and minor version are now rejected.; Invalid header field names containing question mark or slash are now rejected.; Such requests are incompatible with :rfc:<code>9110#section-5.6.2</code> and are not known to be of any legitimate use.</p>; <p><em>Related issues and pull requests on GitHub:</em>; <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8074"">#8074</a>.</p>; </li>; <li>; <p>Improved validation of paths for static resources requests to the server -- by :user:<code>bdraco</code>.</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/blob/master/CHANGES.rst"">aiohttp's changelog</a>.</em></p>; <blockquote>; <h1>3.9.2 (2024-01-28)</h1>; <h2>Bug fixes</h2>; <ul>; <li>; <p>Fixed server-side websocket connection leak.</p>; <p><em>Related issues and pull requests on GitHub:</em>; :issue:<code>7978</code>.</p>; </li>; <li>; <p>Fixed <code>web.FileResponse</code> doing blocking I/O in the event loop.</p>; <p><em>Related issues and pull requests on GitHub:</em>; :issue:<code>8012</code>.</p>; </li>; <li>; <p>Fixed double compress when compression enabled and compressed file exists in server file responses.</p>; <p><em>Related issues and pull requests on GitHub:</em>; :issue:<code>8014</code>.</p>; </li>; <li>; <p>Added runtime type check for <code>ClientSession<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14212:1854,validat,validation,1854,https://hail.is,https://github.com/hail-is/hail/pull/14212,6,['validat'],['validation']
Security,"I added `user` and `userdata` to the jobs and batch table. I also added `user` as a secondary index, which @danking also did. . I used the `ksa_name` in the jwt for now. @akotlar We should figure out what this should be instead. . This does not check authentication for `get_recent_events`. I also am concerned about the case where we can't access jobs, batches easily as there's no support for a super user who can view everything. Stacked on #5934",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5942:251,authenticat,authentication,251,https://hail.is,https://github.com/hail-is/hail/pull/5942,2,"['access', 'authenticat']","['access', 'authentication']"
Security,"I added support for order by as well, but didn't expose it yet. We can get to that later when we add sorting to tables.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6572:49,expose,expose,49,https://hail.is,https://github.com/hail-is/hail/pull/6572,1,['expose'],['expose']
Security,"I addressed some comments. I still need to:; - expose hts_genotype_schema in python, and; - figure out what to rewrite instead of ""genotype"" in the VariantDataset docs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2480#issuecomment-347072699:47,expose,expose,47,https://hail.is,https://github.com/hail-is/hail/pull/2480#issuecomment-347072699,1,['expose'],['expose']
Security,"I agree users should have `storage.buckets.get` only to their own folder, and not `storage.buckets.get`. However, it looks like it is trying to create a bucket with the new folder name, and failing against that (non-existent) bucket:. > exceptions.from_http_response(response) google.api_core.exceptions.Forbidden: 403 GET https://www.googleapis.com/storage/v1/b/untitled-folder?projection=noAcl: user-nrru16jaxrwmnzkv5f35xfibg@hail-vdc.iam.gserviceaccount.com does not have storage.buckets.get access to untitled-folder. That's untitled-folder. Maybe the error is not permissions at all, but it is using the wrong base directory to create the folder?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5788#issuecomment-480380482:495,access,access,495,https://hail.is,https://github.com/hail-is/hail/pull/5788#issuecomment-480380482,1,['access'],['access']
Security,"I agree. I'll study up on testing this stuff. Scorecard isn't tested, either. A few thoughts:; - I don't feel quite so bad having some of this untested (scorecard, etc.) while we get up to speed since they are internal tools (and not too complicated, unlike ci), but at the very least we need to test hl.upload_log() since that's the user facing bit.; - It will get easier to run tests if we can deploy the service in a test namespace to mirror the production namespace. I'll bump up the priority on looking into this.; - We need authentication without oauth2 for the tests. I'm at a total loss about how to automate testing of oauth2 login. The internet has some thoughts: https://stackoverflow.com/questions/39180008/automated-api-testing-of-oauth2-openid-connect-protected-api, including using headless automation: https://medium.com/@vicusbass/api-testing-with-rest-assured-oauth2-flow-with-redirect-uri-ba48b5953823; - Flask has a test fixture, so at least I can write local tests: http://flask.pocoo.org/docs/1.0/testing/; - Created an issue to track these: https://github.com/hail-is/hail/issues/4539",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4509#issuecomment-429338595:530,authenticat,authentication,530,https://hail.is,https://github.com/hail-is/hail/pull/4509#issuecomment-429338595,1,['authenticat'],['authentication']
Security,"I also changed the highlight color for the GitHub icon because it was too dark to clearly see. The username and password for our Font Awesome account are in the usual place. I also had a bit too much fun using ""GIPHY CAPTURE"", Giphy's Mac video capture app to create this gif of my change:; ![highlighticon](https://user-images.githubusercontent.com/106194/112545998-4147db00-8d8f-11eb-893e-6f01ea76b79b.gif)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10228:112,password,password,112,https://hail.is,https://github.com/hail-is/hail/pull/10228,1,['password'],['password']
Security,"I am using a cluster with a PBS scheduler. Hail and my files are located in my home directory which is on a mounted NFS. The same NFS is mounted, and accessible, on the worker nodes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/902#issuecomment-251762194:150,access,accessible,150,https://hail.is,https://github.com/hail-is/hail/issues/902#issuecomment-251762194,1,['access'],['accessible']
Security,I authorized it.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6432#issuecomment-507093890:2,authoriz,authorized,2,https://hail.is,https://github.com/hail-is/hail/pull/6432#issuecomment-507093890,1,['authoriz'],['authorized']
Security,I avoid printing the full exception into the body in most cases. Seems prudent to not expose too much about our internals. CI already uses a broad except and prints the full message when building PRs so I adopted that for building the branch (`unwatched_branch.deploy`) in dev deploy.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8828:86,expose,expose,86,https://hail.is,https://github.com/hail-is/hail/pull/8828,1,['expose'],['expose']
Security,"I believe I addressed all the comments from #2431. The one thing I couldn't quite figure out is that you suggested testing using a randomly generated vsm and then calling make_table().export() (which in Scala, best as I can figure, is makeKT().export(f)). This does some things that makes re-importing using LoadMatrix non-identical:; - the exported header includes a header entry for the row ID column also, which the data we were looking at before didn't (n entries in the first line, n + 1 entries in subsequent lines), which seems like a reasonable thing to want to deal with---I added a flag in LoadMatrix called hasRowKeyLabel which drops the first item of the header line if that's the case, although it's not exposed to HailContext/the Python interface.; - the exported sample IDs somehow get "".g""s tacked on the ends (presumably because they came from the ""g"" struct), so the sample IDs would never match.; I ended up writing my own export function for the test (since I assume we don't really want to be exporting to this format IRL)---please let me know if I should handle that differently.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2440:717,expose,exposed,717,https://hail.is,https://github.com/hail-is/hail/pull/2440,1,['expose'],['exposed']
Security,"I believe we are encountering this known Kryo limitation: https://github.com/EsotericSoftware/kryo/issues/497, https://github.com/EsotericSoftware/kryo/issues/382 (also see related GATK issue: https://github.com/broadinstitute/gatk/issues/1524). Danfeng saw the referenced stack trace when trying to broadcast the variants for Plink (see: [LoadPlink.scala:202](https://github.com/hail-is/hail/blob/master/hail/src/main/scala/is/hail/io/plink/LoadPlink.scala#L202). She was running a import_plink, count. The details in EsotericSoftware/kryo#382 indicate that a bad interaction between the data and a hash function can cause this integer map to exceed its size limitations at a load factor of 5%. Even a 20x increase in footprint puts us at 400 million. Each element of that array has 6 entries, so we're at 1.2 billion. That definitely feels like the danger zone. Maybe there's more variants than Danfeng expects, maybe there's more overhead than we've accounted for. The GATK folks have been chasing down the fix. Kryo [released 4.0.0](https://github.com/EsotericSoftware/kryo/issues/431) which should fix this issue. Spark [upgraded to Kryo 4.0.0](https://github.com/apache/spark/pull/22179) on September 8th of 2018. (resolving [Spark-20389](https://issues.apache.org/jira/browse/SPARK-20389)). This change made it to 2.4.0, but it was not back ported to other versions of Spark. GATK [references a temporary fix via JVM options](; https://github.com/broadinstitute/gatk/issues/1524#issuecomment-189368808), which apparently forces the JVM to use an alternative hash function with better behavior in this specific case:; ```; spark.executor.extraJavaOptions -XX:hashCode=0; spark.driver.extraJavaOptions -XX:hashCode=0; ```; A [generally interesting blog post on Java's hashCode](https://srvaroa.github.io/jvm/java/openjdk/biased-locking/2017/01/30/hashCode.html), which I haven't fully read, claims that the JVM previously defaulted to a PRNG draw for an object's hash code. In JDK 8 it uses some ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5564:600,hash,hash,600,https://hail.is,https://github.com/hail-is/hail/issues/5564,1,['hash'],['hash']
Security,"I broke my previous PR into littler pieces some of which has already merged. This PR adds developers from production to test namespaces (only programmatic access, browser OAuth flow does not work yet for test namespaces) and makes it easier to add developers to dev namespaces.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13331:155,access,access,155,https://hail.is,https://github.com/hail-is/hail/pull/13331,1,['access'],['access']
Security,"I can't `git pull` at the moment, but as of `c2508f35dc41` this is still an issue. Small example that you guys should have access to:. ```; mutation_ht = hl.import_table('gs://gnomad-resources/constraint/source/fordist_1KG_mutation_rate_table.txt',; delimiter=' ', impute=True); mutation_ht = mutation_ht.transmute(context=mutation_ht['from'], ref=mutation_ht['from'][1],; alt=mutation_ht.to[1]).key_by('context', 'ref', 'alt'); mu = mutation_ht.aggregate(hl.agg.group_by(; hl.struct(context=mutation_ht.context, ref=mutation_ht.ref, alt=mutation_ht.alt),; hl.agg.collect(mutation_ht.mu_snp))); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4215#issuecomment-423534766:123,access,access,123,https://hail.is,https://github.com/hail-is/hail/issues/4215#issuecomment-423534766,1,['access'],['access']
Security,"I can't figure out why I'm getting an error in one test. But I also am not sure what to do with the `/batches` endpoint. I want the UI default to only show you your batches with the default query string 'user:jigold`. However, what should the REST endpoint be? All batches in all billing projects you have access for?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9954#issuecomment-770063101:306,access,access,306,https://hail.is,https://github.com/hail-is/hail/pull/9954#issuecomment-770063101,1,['access'],['access']
Security,"I changed ci.hail.is to point to kubernetes, so this won't work any more. The new web site is ready to go (live at test.hail.is) and I will switch it over hail.is over late tonight. It needs to go down for a short while to get new Let's Encrypt credentials.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4399:237,Encrypt,Encrypt,237,https://hail.is,https://github.com/hail-is/hail/pull/4399,1,['Encrypt'],['Encrypt']
Security,"I created @hail-ci-robot, created a personal access token with the ""resource owner"" set to ""hail-is"". It has permission to read and write pull requests and statuses. The token expires in just under a year. I created a calendar event on Hail General Calendar to remind us to rotate it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14384:45,access,access,45,https://hail.is,https://github.com/hail-is/hail/pull/14384,1,['access'],['access']
Security,I debated whether to have this option on a batch which would require a database migration to add a new field to the batches table or just have it in the job spec for all jobs (same for all jobs). What I did is the easiest thing. It assumes all requester pay accesses are billed to the same project.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9096:258,access,accesses,258,https://hail.is,https://github.com/hail-is/hail/pull/9096,1,['access'],['accesses']
Security,"I decided to break off this chunk from another PR that has stalled. That PR will ultimately build on this to add all developers automatically to dev AND test namespaces, but this should be an improvement for now. A few things in here:. - Deleted all the `DatabaseResource` stuff in the auth driver. Since databases now are created and destroyed with the namespace and not the developer, this is basically dead code.; - Added the ability to add a user for an existing hail identity. This is only permitted in dev namespaces and serves as a way for developers to use the same hail identity across namespaces. There is one caveat here: `create_initial_account.py` tries to copy the `<dev-name>-gsa-key` secret from default into the developer namespace and this code will *not* do that anymore. For the developer to submit jobs to the namespace, they must first manually copy in the secret from `default` if it does not already exist inside the namespace. This is awkward, but IMO acceptable because:; - the copying code in `create_initial_account.py` is already broken anyway because when that script is run in a dev deploy it does not have access to production secrets; - I hope that when we eventually go keyless we can delete the gsa key secrets and this whole problem goes away.; - I feel like it's not too bad to do this manual one time copy as opposed to maintaining code that is privileged enough to reach across namespaces. Seems error prone and like a security headache.; - Deletes `create_initial_account.py` in favor of using our actual API to create the dev user.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13180:1138,access,access,1138,https://hail.is,https://github.com/hail-is/hail/pull/13180,2,"['access', 'secur']","['access', 'security']"
Security,I develop accross a couple of OSes and my username isn't always the same. I'd like to expose this make variable so that I can push images to the same location.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12846:86,expose,expose,86,https://hail.is,https://github.com/hail-is/hail/pull/12846,1,['expose'],['expose']
Security,"I did this and then realized unfilterEntries is only used in a test. @tpoterba, did you intend to expose this in Python?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3528:98,expose,expose,98,https://hail.is,https://github.com/hail-is/hail/pull/3528,1,['expose'],['expose']
Security,I didn't test this yet -- do you want me to try the updated docs or should we wait until we redeploy the infrastructure next? Documentation is [here](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/network_security_group).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11027:190,hash,hashicorp,190,https://hail.is,https://github.com/hail-is/hail/pull/11027,1,['hash'],['hashicorp']
Security,"I do not understand how this passed the PR tests, but this fix makes regenie not; use the metadata server to authenticate itself.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9390:109,authenticat,authenticate,109,https://hail.is,https://github.com/hail-is/hail/pull/9390,1,['authenticat'],['authenticate']
Security,"I don't believe I have access to look at the test failures. If you let me know what failed, I'll do my best to fix it!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13129#issuecomment-1581212490:23,access,access,23,https://hail.is,https://github.com/hail-is/hail/pull/13129#issuecomment-1581212490,1,['access'],['access']
Security,"I don't have access to Laurent's repo, so I can't push to address comments on his PR. Opening a new one instead",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3954:13,access,access,13,https://hail.is,https://github.com/hail-is/hail/pull/3954,1,['access'],['access']
Security,"I don't think the last comment checks out. Access tokens aren't refreshable, right? So you'd have very short-lived access.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13934#issuecomment-1785490774:43,Access,Access,43,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1785490774,2,"['Access', 'access']","['Access', 'access']"
Security,"I don't think this keeps too much garbage in memory. Your next method extracts exactly the data it needs from its producer. No garbage there, you asked for only data you absolutely need. You stated (via `addReferenceTo`) that your region references these child regions, so that memory must be accessible at least as long as your region is accessible. Whoever is consuming your data can release all this memory by clearing the region you're using. The only nodes which should be clearing are folks who call `next` multiple times *and don't need that data to have the same lifetime*. This is true for filter, only surviving values must live, other values' lifetimes may end when we discover they fail the filter condition. It's also true for `write` because after one value is dumped into a file, it is no longer needed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7952#issuecomment-578798366:293,access,accessible,293,https://hail.is,https://github.com/hail-is/hail/pull/7952#issuecomment-578798366,2,['access'],['accessible']
Security,"I don't think we should merge this until we make dataproc jupyter notebooks have tokens. We set it to the empty string / no-token because we knew that you could only access the jupyter notebook if you had SSH credentials. I think this approach still left open CSRF attacks (random website tries to POST to localhost, so if people browse untrusted HTML/JS from their SSH tunneled web browsers that's not great). I think we should probably be setting tokens on the jupyter servers in general, but if you also intend to make the leader node's `connect_port` public, then we _definitely_ need to do that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6173#issuecomment-496762764:166,access,access,166,https://hail.is,https://github.com/hail-is/hail/pull/6173#issuecomment-496762764,2,"['access', 'attack']","['access', 'attacks']"
Security,"I don't want to add a larger test to scala, since we're ripping it all out of scala soon. Currently this functionality isn't exposed to Python, and it should be tested when it's exposed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2884#issuecomment-365378540:125,expose,exposed,125,https://hail.is,https://github.com/hail-is/hail/pull/2884#issuecomment-365378540,2,['expose'],['exposed']
Security,I feel I may have complicated things slightly. It's probably not relevant that its running on a cluster. I'm essentially just using a node on the cluster as a workstation as I can easily access the VCFs from there. At the moment I'm trying out basic functionality of hail. I'm just using a single node and running a single instance of hail. All I have done so far is import a VCF and filter out some samples. Then when trying to annotate variants using a bed file I ran into the above issue.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/902#issuecomment-251802552:187,access,access,187,https://hail.is,https://github.com/hail-is/hail/issues/902#issuecomment-251802552,1,['access'],['access']
Security,"I figure we should keep this up to date with our supported python images. AFAIK, we currently only use the mirror of python:3.7. We don't expose any of them as publicly available images, but perhaps we should due to dockerhub rate limits? I suppose that's a question for another day. We probably want to base our python-dill images on these so that docker hub can't just force push a new version of a tag and break our builds.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12255:138,expose,expose,138,https://hail.is,https://github.com/hail-is/hail/pull/12255,1,['expose'],['expose']
Security,"I finally figured out how to get the authorization bearer token for the Grafana robot into Grafana automatically. The problem I'm running into right now is when we load a datasource from a configuration file, we can not edit any of the settings in the UI. We'd want to make sure all the prometheus settings we want are inside the new config file. I also don't want to accidentally overwrite any of the existing configuration.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10772:37,authoriz,authorization,37,https://hail.is,https://github.com/hail-is/hail/pull/10772,1,['authoriz'],['authorization']
Security,I got a timeout!; ```; SocketTimeoutException: connect timed out. Java stack trace:; java.io.IOException: Error getting access token from metadata server at: http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:120,access,access,120,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699,1,['access'],['access']
Security,"I got an email saying the activity logs are no longer supported after September 30th. Here's the [migration instructions](https://cloud.google.com/compute/docs/logging/migrating-from-activity-logs-to-audit-logs#log_entry_field_mappings). I figured out how to map the fields mostly by trial and error looking at the JSON for an event. The only thing that didn't map at all was the operationType. I hardcoded that as 'insert'. There are different event_subtype names such as 'v1.compute.instances.insert' or 'beta.compute.instances.insert'. So I did what they suggested and looked for a partial match such as 'compute.instances.insert'. I can send you the full JSON for the events if you want to double check anything. I also double checked that the activity logs aren't used anywhere else in the repo, but it might be good for you to confirm that since you wrote a lot of this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9439:200,audit,audit-logs,200,https://hail.is,https://github.com/hail-is/hail/pull/9439,1,['audit'],['audit-logs']
Security,"I got pretty fatigued from **hours** of iterating on `gradle doctest` and copy-paste after the ~25th iteration. I started sprinkling the NOTEST stuff in then. There are some places that seem unavoidable -- things that return dicts whose order may vary, for instance. I also added NOTEST directives sometimes when we print string representations of objects, because this was easier at the time and made the unit of work more manageable. I do want to fully audit the ones I've added, and have reasons for including each NOTEST. But I'd prefer to do that separately.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4808#issuecomment-440499564:455,audit,audit,455,https://hail.is,https://github.com/hail-is/hail/pull/4808#issuecomment-440499564,1,['audit'],['audit']
Security,"I guess I was afraid of somebody copying and pasting from the README. But if they're going to do that, they're not going to get right version anyway. You don't know the release hash until it goes in, which is annoying.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5915#issuecomment-484732538:177,hash,hash,177,https://hail.is,https://github.com/hail-is/hail/pull/5915#issuecomment-484732538,1,['hash'],['hash']
Security,I guess it looks like you're still intending to use the proxy? I guess I'm just not sure what's going on and you're making changes (like the change to `c.NotebookApp.allow_remote_access`) that make me very uncomfortable security-wise.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6173#issuecomment-496763057:220,secur,security-wise,220,https://hail.is,https://github.com/hail-is/hail/pull/6173#issuecomment-496763057,1,['secur'],['security-wise']
Security,"I had to rip out the SQLContext because its deprecated, but it does not appear to be used and was never exposed in our public python API. It's been replaced with SparkSession.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5951#issuecomment-486458681:104,expose,exposed,104,https://hail.is,https://github.com/hail-is/hail/pull/5951#issuecomment-486458681,1,['expose'],['exposed']
Security,I have a little reading list I still haven't gotten to yet about approximate median and the like:; - http://info.prelert.com/blog/q-digest-an-algorithm-for-computing-approximate-quantiles-on-a-collection-of-integers; - https://www.quora.com/Is-there-an-online-algorithm-to-calculate-the-median-of-a-stream-of-numbers-if-stream-elements-can-be-added-or-removed-at-any-point; - http://link.springer.com/chapter/10.1007/978-3-642-40273-9_7?no-access=true,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1083#issuecomment-260091875:440,access,access,440,https://hail.is,https://github.com/hail-is/hail/issues/1083#issuecomment-260091875,1,['access'],['access']
Security,"I have a partial setup of the website in k8s, will poll for a new hash and update the docs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4375:66,hash,hash,66,https://hail.is,https://github.com/hail-is/hail/pull/4375,1,['hash'],['hash']
Security,"I have not tested this, though I faithfully copied the commands from existing; deploy scripts (except for creating a github release). A change that I think is valuable regardless of automation is the conversion of; deploy from a series of Makefile targets to a bash script. I also add a deploy build.yaml step which simply calls the deploy script,; setting up appropriate credentials. I only had to add one set of credentials: the PyPI credentials. I've already; created that secret in the cluster. Hand deploys are still very easy. You need curl >=7.55.0 (that version; implemented reading headers from a file). You need to set up two things:; 1. create $HOME/.pypirc and put this there:; ```; [pypi]; username: hailteam; password: GET_THIS_FROM_THE_USUAL_PLACE; ```; 2. get a github access token with repo; privileges (https://github.com/settings/tokens), create; $HOME/.github-oauth-header, and put this there:; ```; Authorization: token YOUR_ACCESS_TOKEN_HERE; ```; Now, to do a hand deploy run:; ```; make deploy GITHUB_OAUTH_HEADER_FILE=$HOME/.github-oauth-header DEPLOY_REMOTE=THE_REMOTE_FOR_hail-is/hail; ```. The github credentials are used to create a GitHub release.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8533:723,password,password,723,https://hail.is,https://github.com/hail-is/hail/pull/8533,3,"['Authoriz', 'access', 'password']","['Authorization', 'access', 'password']"
Security,"I know I said I thought this was a reasonable approach a while ago, but I’ve been thinking hard about this change since last week, and I think I want us to explore a larger set of designs before committing to this strategy. The approach in this PR doubles down on the functional Code[T] structure, which is something we’re trying to move away from with CodeBuilder. I think if I could choose an interface for injecting line numbers from IR in emit it would look something like:. ```scala; class Emit[C](; val ctx: ExecuteContext,; val cb: EmitClassBuilder[C]) { emitSelf =>. val methods: mutable.Map[(String, Seq[Type], Seq[PType], PType), EmitMethodBuilder[C]] = mutable.Map(). private[ir] def emitVoid(cb: EmitCodeBuilder, ir: IR, mb: EmitMethodBuilder[C], region: StagedRegion, env: E, container: Option[AggContainer], loopEnv: Option[Env[LoopRef]]): Unit = {; cb.startLine(ir.lineNumber); ... implementaiton; cb.endLine(ir.lineNumber); ```. How could we make something like this work? Can we get away without every Code[T] knowing the source line? The JVM represents line numbers as an array of (line start bytecode index, line bytecode length) tuples, and I think it will be possible to produce this more easily. I think part of my concern is that I’m not entirely sold by the need to have a whole stack of IR printouts and associated line numbers — right now, the option to get debug information by LIR line number or IR (fully lowered, compile-ready) seems plenty sufficient. Part of my pushback is that I'm hesitant to use Scala implicits pervasively without a careful cost/benefit consideration — they’ve been a source of confusion and frustration in the past, and the intentional paucity of implicits in our current codebase reflects that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9770#issuecomment-742027249:409,inject,injecting,409,https://hail.is,https://github.com/hail-is/hail/pull/9770#issuecomment-742027249,1,['inject'],['injecting']
Security,"I liked your diff idea, so I added a new file: batch/sql/estimated-current.txt. This is meant to be the SQL we'd use for initial.sql if we recreated the batch database. It should have collective migrations applied to it. So when we add a new migration, we should update the estimated current which will give informative documentation for the current change. I use ""estimated"" and ""txt"" because it isn't tested or validated in any way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7916:413,validat,validated,413,https://hail.is,https://github.com/hail-is/hail/pull/7916,1,['validat'],['validated']
Security,"I loaded gcc 4.9 and java 1.8 and now getting a new error while compiling.This is strange as earlier I dint face any issues.Is there some major changes that happened for code compilation. mkdir -p lib/linux-x86-64; g++ -fvisibility=hidden -rdynamic -shared -fPIC -ggdb -O3 -march=native -g -std=c++11 -Ilibsimdpp-2.0-rc2 -Wall -Werror ibs.cpp -o lib/linux-x86-64/libibs.so; :compileScala; missing or invalid dependency detected while loading class file 'package.class'.; Could not access type SparkSession in package org.apache.spark.sql,; because it (or its dependencies) are missing. Check your build definition for; missing or conflicting dependencies. (Re-run with `-Ylog-classpath` to see the problematic classpath.); A full rebuild may help if 'package.class' was compiled against an incompatible version of org.apache.spark.sql.; /gpfs/home/tpathare/haillatest/hail/src/main/scala/is/hail/driver/package.scala:25: overloaded method value save with alternatives:; (javaRDD: org.apache.spark.api.java.JavaRDD[org.bson.Document])Unit <and>; (dataFrameWriter: org.apache.spark.sql.DataFrameWriter[_])Unit <and>; [D](dataset: org.apache.spark.sql.Dataset[D])Unit <and>; [D](rdd: org.apache.spark.rdd.RDD[D])(implicit evidence$5: scala.reflect.ClassTag[D])Unit; cannot be applied to (org.apache.spark.sql.DataFrameWriter); MongoSpark.save(kt.toDF(sqlContext); ^; /gpfs/home/tpathare/haillatest/hail/src/main/scala/is/hail/sparkextras/OrderedRDD.scala:382: class PartitionCoalescer in package rdd cannot be accessed in package org.apache.spark.rdd; override def coalesce(maxPartitions: Int, shuffle: Boolean = false, partitionCoalescer: Option[PartitionCoalescer] = Option.empty); ^; missing or invalid dependency detected while loading class file 'package.class'.; Could not access type DataFrame in package org.apache.spark.sql.package,; because it (or its dependencies) are missing. Check your build definition for; missing or conflicting dependencies. (Re-run with `-Ylog-classpath` to see the pro",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1327#issuecomment-277494831:481,access,access,481,https://hail.is,https://github.com/hail-is/hail/issues/1327#issuecomment-277494831,1,['access'],['access']
Security,"I looked over the code and it looks fine, but I'm having trouble understanding the bigger picture of what you're trying to accomplish. I see that you have a new step that creates a test database in the default namespace in the test scope. Then you create the database config secret from this new database. And then deploy_ci depends on it, which makes sense because it needs the secret to be able to create new databases. And this is all only in the test scope. It looks like you cleaned up the build database in the case of dev deploy, which is fine too. > we also create a ""test_instance"" database that will be used as the database instance inside the tests. I don't understand what you wrote here because test_instance database doesn't seem to be used at all. Aren't we still creating the same batch and ci databases? I don't see what the test_instance database is buying you except to be able to make the database config secret that doesn't have the root username and password. I also don't quite understand what's going on in the build_cant_create_database build step. Shouldn't those secrets already exist? Won't this fail?. I'm sorry if I'm missing something obvious.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7683#issuecomment-562887906:972,password,password,972,https://hail.is,https://github.com/hail-is/hail/pull/7683#issuecomment-562887906,1,['password'],['password']
Security,I made some changes. I had to rewrite the audits to not fill up the temp disk space and account for a bug in billing that was fixed for job private instances #10069. I'll test this afternoon after I figure out how to revert my first attempt.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11996#issuecomment-1201421379:42,audit,audits,42,https://hail.is,https://github.com/hail-is/hail/pull/11996#issuecomment-1201421379,1,['audit'],['audits']
Security,"I made these updates to Scala LocalMatrix as I was building the Python interface, to more closely mirror NumPy functions and name the symbolic operators. I no longer intend to expose LocalMatrix in Python in its current form, but rather to localize BlockMatrix ""directly"" to NumPy and vice versa. Still, LocalMatrix in Scala is a useful local model for how I'll update BlockMatrix to be more NumPy like (e.g. broadcasting), and a step toward building a region-value based ndarray. I think these are good changes, isolated to LocalMatrix, so my preference is to merge them in now.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3071:176,expose,expose,176,https://hail.is,https://github.com/hail-is/hail/pull/3071,1,['expose'],['expose']
Security,"I manually added a `hail_test_gcs_bucket` field to the k8s global config and use that value wherever we have our current test bucket hard coded. I also added the necessary terraform to make that in a new cluster, though I have not done a new terraform run in my project. Once this and a couple more refactoring PRs go in I'll be able to run ci tests in a separate cluster and validate that the terraform is working correctly. cc: @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10807:376,validat,validate,376,https://hail.is,https://github.com/hail-is/hail/pull/10807,1,['validat'],['validate']
Security,"I must have broken this during a recent refactor of the decorators. When making requests to an internal namespace, the default namespace's auth token is set in the `X-Hail-Internal-Authorization` header and the dev namespace's token is in the `Authorization` header. The dev namespace needs to know *not* to pick up the `X-Hail-Internal-Authorization` header.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13515:181,Authoriz,Authorization,181,https://hail.is,https://github.com/hail-is/hail/pull/13515,3,['Authoriz'],['Authorization']
Security,"I need access to the users' GCP SA key file, which I think is most naturally stored as a k8s secret.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5633#issuecomment-477341107:7,access,access,7,https://hail.is,https://github.com/hail-is/hail/pull/5633#issuecomment-477341107,1,['access'],['access']
Security,"I picked the name since Cronus is the father of Zeus. Perhaps Saturn is more appropriate. Open to suggestions here. The UX flow:. 1. User loads up `https://hail.is/cronus` and sees a form with a button.; 2. Pressing the button starts a pod running Jupyter for the user that no one else has access to; 3. refreshing the page or going to `https://hail.is/cronus` again redirects to the Jupiter instance; 4. to get a fresh Jupyter instance, the user can clear their cookies. The components:. - a flask app (`cronus/cronus.py`) which launches pods and handles authentication (via cookies); - an nginx reverse proxy which uses `auth_request` to check the permissions with the flask app; - a pod running `Jupyter notebook` with hail `pip` installed. TODO:. - [x] add make targets to generate the `cronus-job` image (the jupyter notebook image); - [ ] maybe simplify the directives used in nginx? I kept throwing shit at it until it worked; - [ ] figure out how to teach flask url_for to use a root other than `/`. I don't know what HTTP proxy headers to set to inform it that it lives at a subdirectory of `hail.is`; - [ ] get rid of the button? creating a new pod needs to be a `POST` so that the web browser doesn't access twice or eagerly access it, etc. maybe I can use javascript on the root page to make the post request and redirect the page.; - [ ] testing? I could add some basic things, but the most time consuming and annoying thing was getting the reverse proxy settings right and testing that requires an nginx instance. @cseed I randomly assigned, should I be picking from you and Tim? What's the plan for review on these new things?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4576:290,access,access,290,https://hail.is,https://github.com/hail-is/hail/pull/4576,4,"['access', 'authenticat']","['access', 'authentication']"
Security,"I picked this refactor off of my terra branch and took it the last ten yards such that now you can run `make batch-db` and get a full local instance of the batch database that you can access through `mysql -h 127.0.0.1 -u root -ppw` or. ```ipython; (hail) dgoldste@wmce3-cb7 hail % HAIL_SQL_DATABASE=local-batch ipython; Python 3.9.17 (main, Jul 5 2023, 16:17:03); Type 'copyright', 'credits' or 'license' for more information; IPython 8.15.0 -- An enhanced Interactive Python. Type '?' for help. In [1]: from gear import Database; ...: db = Database(); ...: await db.async_init(); ...: await db.select_and_fetchone('SELECT * FROM globals'); ...:; ...:; Out[1]:; {'instance_id': 'XXXXXXXX',; 'internal_token': 'XXXXXXX',; 'n_tokens': 200,; 'frozen': 0}; ```. If you add a migration, just run `make batch-db` again.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13670:184,access,access,184,https://hail.is,https://github.com/hail-is/hail/pull/13670,1,['access'],['access']
Security,"I plan to move this to `hl.dnd.DNDArray`. I had to make a couple changes to RVD and Table to make this work. They all; revolve around convincing Hail not to elide *critical* `key_by`s. The critical insight is that 1:1 partitioners (partitioners where each range; bound interval contains exactly one key) are special: permuting their keys is; free. I can take advantage of this by combining two changes:; 1. `RVD.enforceKey` is aware of these partitioners and avoids scans in that case; 2. Defeat the optimizer, which is unaware of these partitioners and misoptimizes; to operations that require shuffles. The first change is easy. I added `RVDPartitioner.keysIfOneToOne` which looks; for these kinds of partitioners in the special case of keys consisting of 32-; and 64-bit integers. The second change eluded me for a long time. Finally, I discovered; `isSorted=true` and realized the optimizer refuses to modify such; `TableKeyBy`s. I exposed this field in Python as: `Table._key_by_assert_sorted`. With this infrastructure in place, I was able to implement read, write, and; matrix-multiply for DNDArray!. In addition, to the arguable hacks above, a couple pain points remain:; 1. I do not know how to rename keys in Python without triggering shuffles. If I; write `key_by(x=t.y, y=t.x)`, Hail implements this as; `TableKeyBy(TableMapRows(TableKeyBy(Array(), ...)`. The inner key by throws; the keys away so that they can be modified with TableMapRows. Unfortunately,; this completely defeats my attempts to avoid shuffles. I avoid this issue by; not using fixed names for the x and y block coordinates (their names are; stored in `x_field` and `y_field`).; 2. Hail lacks `ndarray_sum`. Instead, I convert from ndarray to array so that I; can use `array_sum`. Unfortunately, this operation seems to completely; dominate all of my time. It takes about 10x as much time as the matrix; multiplies take. I do not understand this. I should be reading the entries in; column-major order. Performance; ----",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8864:936,expose,exposed,936,https://hail.is,https://github.com/hail-is/hail/pull/8864,1,['expose'],['exposed']
Security,"I played with a few options. I liked this one the best. Downside to `Value[T] extends Code[T]`:; - A bunch of code (using Array) assumes Code[T] is monomorphic. Either way I fixed those here (by switching to polymorphic IndexedSeq[T]); - Can't use the analogous setup for PValue since the hierarchy is more complicated. This is why I picked this solution. Downside to this solution: ; - Scala won't apply stacked implicits, so need to add additional implicits for e.g. Value[Int] to CodeInt. I do that here. In the end, `Value[T]` is a thing that can produce multiple `Code[T]`, which can then only be emitted once. I used `Value.get: Code[T]` over `load()` and renamed a few field accessors get => getField. If we like how this goes I can rip out `load()`. I fixed some know multiple emission of Code[T] in ETypes buildEncoder. I will slowly convert over the necessary stuff to `Value[T]` in later PRs. `Code.markEmitted` (not called) can be used to find Code[T] that are emitted multiple times.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8229:682,access,accessors,682,https://hail.is,https://github.com/hail-is/hail/pull/8229,1,['access'],['accessors']
Security,"I pushed some addition changes: push requestedType into TableRead, expose (private) in Python for performance testing. On a chunk of gnomAD sites file, read count went from 19s (all fields) to 12s (keys + 1 int field). The Python changes should get removed once prune dead fields goes in. MatrixRead will require a bit more work (with the recent unification of matrix read/import IR nodes).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3667#issuecomment-392303741:67,expose,expose,67,https://hail.is,https://github.com/hail-is/hail/pull/3667#issuecomment-392303741,1,['expose'],['expose']
Security,"I realize I forgot to update the latest-hash lines, I'll fix that now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4220#issuecomment-416617372:40,hash,hash,40,https://hail.is,https://github.com/hail-is/hail/pull/4220#issuecomment-416617372,1,['hash'],['hash']
Security,I really do not think this should be necessary. The ADC is my *user* credentials. If I can; access the given project then I do not see why I need to regenerate my ADC creds.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11403:92,access,access,92,https://hail.is,https://github.com/hail-is/hail/pull/11403,1,['access'],['access']
Security,"I reverted the `gcp` changes entirely. Let's just get to work on having tracked infrastructure in GCP. We'll resolve the differences between `gcp` and `gcp-broad` (as much as possible) at some later date. In the short term, we need to get these security changes in.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12882#issuecomment-1520905705:245,secur,security,245,https://hail.is,https://github.com/hail-is/hail/pull/12882#issuecomment-1520905705,1,['secur'],['security']
Security,"I saw this again today in a fairly simple and isolated test. I'm beginning to wonder if this is just a new form of transient error. We pick 22 random characters from a 62 character alphabet. Odds of collision are minuscule:; ```; In [2]: (1/62)**22; Out[2]: 3.693029961058969e-40; ```; I verified `SecureRandom` with no constructor uses a randomly chosen seed. There's three exceptions there (all the same one). The deepest one came during a write. The next two came during closes. The outermost exception is from the `using` cleaning up. I'm not sure where the middle exception comes from, I can't imagine who would try to `close` the stream other than `using`. Regardless, it appears that the upload fails in some unrecoverable way. We're writing 2GiB in 256 8MiB chunks in this test, so we have more chances for something to go wrong. Maybe we just have to retry the entire partition when this happens?. https://ci.hail.is/batches/7404773/jobs/145; ```; starting test is.hail.fs.gs.GoogleStorageFSSuite.testSeekMoreThanMaxInt...; Exception:; is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-6BO4gZ18Lheigp3ir9RSOh&uploadType=resumable&upload_id=ADPycduiXx2Jtiy_0Ll131_pPeEYKnnA23Hlk28_9TFESUMaubA9OqLK_n8Td5rPhTXnlpssGo796Q4bJxUeblhmSaYcCSWAMg2k; chunkOffset: 16777216; chunkLength: 8388608; localOffset: 1325400064; remoteOffset: 1342177280; lastChunk: false. 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel$1.run",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756:298,Secur,SecureRandom,298,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756,1,['Secur'],['SecureRandom']
Security,"I see, here's the bit that does suggest the prefix:. > Use a naming convention that distributes load evenly across key ranges; > Auto-scaling of an index range can be slowed when using sequential names, such as object keys based on a sequence of numbers or timestamp. This occurs because requests are constantly shifting to a new index range, making redistributing the load harder and less effective. > In order to maintain a high request rate, avoid using sequential names. Using completely random object names gives you the best load distribution. If you want to use sequential numbers or timestamps as part of your object names, introduce randomness to the object names by adding a hash value before the sequence number or timestamp.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10836#issuecomment-914242680:685,hash,hash,685,https://hail.is,https://github.com/hail-is/hail/pull/10836#issuecomment-914242680,1,['hash'],['hash']
Security,"I see, so you receive an access denied when there are no artifacts. The build log has a long list of commands, starting with a git clone. It sounds like this isn't an issue then.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5546#issuecomment-472479806:25,access,access,25,https://hail.is,https://github.com/hail-is/hail/issues/5546#issuecomment-472479806,1,['access'],['access']
Security,"I suppose this is where I started getting entangled with the domain issue. If the Australians run a workshop, what should happen if their users run `hailctl batch init`? Should they have to supply some additional argument so that _if_ they're not authenticated they get sent somewhere other than `hail.is`? Maybe that's ok, seems kind of awkward though. While it doesn't work this way today, I imagine that we should ultimately configure `hailctl auth login` to accept a domain. I feel like that would make the AUS scenario slightly less awkward, and the tool more consistent, though I admit it is conceding some of our own convenience.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13279#issuecomment-1663110567:247,authenticat,authenticated,247,https://hail.is,https://github.com/hail-is/hail/pull/13279#issuecomment-1663110567,1,['authenticat'],['authenticated']
Security,"I suspect some of the inconsistent behavior we're seeing could be due to memory corruption. So I put in another debugging allocator. What does this do? It makes sure all memory accesses in `Memory` are valid. Also, for each allocation, it puts a sentinel values before and after the allocation, and verifies they are undisturbed on free. How will this work normally? Obviously, this will slow things down. This checked `Memory` will be stored outside the main source, and can be copied over `Memory` to run with checked memory. Once this is passing, I will organize it that way. We should probably always run a version of the tests with memory checking enabled. Am I seeing failures? Yes, a handful. Unfortunately, the failures themselves don't seem context dependent, and when I run all the tests things fail, but when I run the isolated test, they pass. Getting this on the board while we debug it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8878:177,access,accesses,177,https://hail.is,https://github.com/hail-is/hail/pull/8878,1,['access'],['accesses']
Security,I tested the commands by creating a service account with 0 permissions and making sure that I could give it access and could read/write to the bucket and gcr.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8840#issuecomment-631733744:108,access,access,108,https://hail.is,https://github.com/hail-is/hail/pull/8840#issuecomment-631733744,1,['access'],['access']
Security,"I think it's useful if you want to write something like:. ```; hl.if_else(x < y, ...., hl.die(""Error: x must be less than y"")); ```. Otherwise you can't do input validation on expressions.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8865#issuecomment-641495584:162,validat,validation,162,https://hail.is,https://github.com/hail-is/hail/pull/8865#issuecomment-641495584,1,['validat'],['validation']
Security,"I think now that ci-agent lives in batch-pods, but has access to default, the ci-agent currently in batch-pods with cluster wide access is fine, and this should just be able to merged in as is.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7466#issuecomment-551108566:55,access,access,55,https://hail.is,https://github.com/hail-is/hail/pull/7466#issuecomment-551108566,2,['access'],['access']
Security,"I think that's right, though we serialize other potentially private information. I think we ought to have a per-organization (Hail billing project?) cache, but also not very high priority. I'd be pretty chuffed to learn we're running important enough stuff that people are attempting timing attacks on our cache to learn what queries other people are executing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10309#issuecomment-821250865:291,attack,attacks,291,https://hail.is,https://github.com/hail-is/hail/pull/10309#issuecomment-821250865,1,['attack'],['attacks']
Security,"I think the answer is that we can't treat the separate namespace as a security boundary. i.e. all internal traffic should be authenticated, encrypted, and authorized by the receiver",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7623#issuecomment-559183070:70,secur,security,70,https://hail.is,https://github.com/hail-is/hail/issues/7623#issuecomment-559183070,4,"['authenticat', 'authoriz', 'encrypt', 'secur']","['authenticated', 'authorized', 'encrypted', 'security']"
Security,I think the docs you're referencing aren't the Compute Engine API docs: https://cloud.google.com/compute/docs/api-rate-limits. The audit logs also show 403s: https://console.cloud.google.com/logs/query;query=%22403%22%0A%22Rate%20Limit%20Exceeded%22;timeRange=2021-05-04T00:05:00.000Z%2F2021-05-04T01:06:00.000Z;pinnedLogId=2021-05-04T00:40:25.985091Z%2F-1xc71ve6z9k6;cursorTimestamp=2021-05-04T00:40:31.308803Z?project=hail-vdc&query=%0A,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10432#issuecomment-833010496:131,audit,audit,131,https://hail.is,https://github.com/hail-is/hail/pull/10432#issuecomment-833010496,1,['audit'],['audit']
Security,I think the only additions I would need to use this in #2423 for summarize are `getNAlleles: Int` and `getAltAlleles: Array[AltAllele]` accessors.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2428#issuecomment-344269060:136,access,accessors,136,https://hail.is,https://github.com/hail-is/hail/pull/2428#issuecomment-344269060,1,['access'],['accessors']
Security,"I think the only two things I'm stuck on are:; (a) Do we want users to pass a VEPConfig instead of a `config` dictionary (and add documentation)?; (b) What is the best way to expose the VEP command interface so a user can customize it to their setup? I wanted to do something like this, but I don't see how to do this with the bash script being called with an argument `/bin/bash -c ""...."" csq` or `/bin/bash -c ""..."" vep`. ```python3; vep_85_grch37_command = '''; #!/bin/bash. if [ $VEP_CONSEQUENCE -ne 0 ]; then; vcf_or_json=""--vcf""; else; vcf_or_json=""--json""; fi. export VEP_COMMAND=/vep/vep \; ${VEP_INPUT_FILE:+--input_file $VEP_INPUT_FILE} \; --format vcf \; ${vcf_or_json} \; --everything \; --allele_number \; --no_stats \; --cache \; --offline \; --minimal \; --assembly GRCh37 \; --dir=${VEP_DATA_DIR} \; --plugin LoF,human_ancestor_fa:${VEP_DATA_DIR}/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:${VEP_DATA_DIR}/loftee_data/phylocsf_gerp.sql,gerp_file:${VEP_DATA_DIR}/loftee_data/GERP_scores.final.sorted.txt.gz \; -o STDOUT. exec vep.py ""$@""; '''. supported_vep_configs = {; ('GRCh37', 'gcp', 'us-central1', 'hail.is'): VEPConfig(; 'hail-qob-vep-grch37-us-central1',; ['us-central1'],; HAIL_GENETICS_QOB_VEP_GRCH37_IMAGE,; '/vep_data/',; {},; VEPConfig.default_vep_json_typ,; [""/bin/bash"", ""-c"", vep_85_grch37_command, ""vep""],; [""/bin/bash"", ""-c"", vep_85_grch37_command, ""csq_header""],; True,; 'gcp',; ),; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12428#issuecomment-1498124947:175,expose,expose,175,https://hail.is,https://github.com/hail-is/hail/pull/12428#issuecomment-1498124947,1,['expose'],['expose']
Security,"I think the takeaway is: notebook's ability to create pods makes it a security risk, so we gotta treat all this code with care.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5753#issuecomment-479641018:70,secur,security,70,https://hail.is,https://github.com/hail-is/hail/pull/5753#issuecomment-479641018,1,['secur'],['security']
Security,"I think this is a good change, but we should keep in eye out, it is going to increase preemptions and restarts, and will almost certainly expose issues. Poor man's chaos. I will add an option to the batch interface to disable this for longer-running jobs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6210:138,expose,expose,138,https://hail.is,https://github.com/hail-is/hail/pull/6210,1,['expose'],['expose']
Security,I think this is dependent on the authorization PR going in so I can test it's working.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6719#issuecomment-514341053:33,authoriz,authorization,33,https://hail.is,https://github.com/hail-is/hail/pull/6719#issuecomment-514341053,1,['authoriz'],['authorization']
Security,"I think this is ready. Adds a createDatabase2 step that adds database migrations. What's a database migration? The idea is that a database starts as an empty database and is built up or modified over time by a series of patches or migrations. The database has a version which is the number of migrations applied (starting from 1). This is stored in the table `{database_name}_migration_version`. Each migration involves running a `.sql` or `.py` script. The logic that applies migrations computes a checksum of these scripts and stores them in the database in table `{database_name}_migrations`. When applying migrations again in the future, these checksums are verified. A create database step now looks like (from the CI tests):. ```; - kind: createDatabase2; name: hello2_database; databaseName: hello2; migrations:; - name: create-tables; script: /io/sql/create-hello2-tables.sql; - name: insert; script: /io/sql/insert.py; inputs:; - from: /repo/ci/test/resources/sql; to: /io/; namespace:; valueFrom: default_ns.name; dependsOn:; - default_ns; - copy_files; ```. migrations is a the list of migrations that need to be applied to get the current version. So the idea is, if you want to change the schema of the database, you just add another migration at the end to make the changes you want. After this goes in, I'll make a separate PR to switch everything to this new createDatabase2 step.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7674#issuecomment-562891346:499,checksum,checksum,499,https://hail.is,https://github.com/hail-is/hail/pull/7674#issuecomment-562891346,2,['checksum'],"['checksum', 'checksums']"
Security,I think this is the correct fix. The batch in default needs to access service accounts in other namespaces.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8169:63,access,access,63,https://hail.is,https://github.com/hail-is/hail/pull/8169,1,['access'],['access']
Security,"I think this may fix it:. ```yaml; apiVersion: v1; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: test; name: list-test-pvc; rules:; - apiGroups: [""""]; resources: [""persistentvolumeclaims""]; verbs: [""list""]; ---; apiVersion: v1; kind: RoleBinding; apiVersion: rbac.authorization.k8s.io/v1; metadata:; name: deploy-svc-list-test-pvc; namespace: test; subjects:; - kind: ServiceAccount; name: deploy-svc; namespace: batch-pods; roleRef:; kind: Role; name: list-test-pvc; apiGroup: ""rbac.authorization.k8s.io""; ```. I don't have permissions to create the role however. Another solution would be to modify the existing role to include ""list"" permissions. ```yaml; ---; apiVersion: v1; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: test; name: delete-test-pvc; rules:; - apiGroups: [""""]; resources: [""persistentvolumeclaims""]; verbs: [""list"", ""delete""]; ---; ```. `""get""` may also be needed",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5503#issuecomment-468958060:80,authoriz,authorization,80,https://hail.is,https://github.com/hail-is/hail/pull/5503#issuecomment-468958060,4,['authoriz'],['authorization']
Security,"I think we should have the following design that runs the benchmarks in k8s because then we are using google's internal network to transmit data (compared to running on my local computer via a cloud proxy):. - Have a `db-benchmark` namespace in k8s specifically for this. 1. create_db.py; a. This will take the parameters needed for `gcloud sql instances create` including database flags, disk space, cores, etc. and create an instance; b. Get the IP address of the instance (hopefully the REST API works for this); c. Create a database; d. Create user and password for the database; e. Create config file; f. Create secret in the db-benchmark namespace from the config file; ; 2. run.py; a. Build the docker image with the benchmark.py code and installs aiomysql, etc.; b. Create pod which mounts the correct secret with the sql config for the instance to use. Environment variables specify the n_replicates, etc. Print out the pod name.; c. Wait for the pod to complete (you have code in CI that does this); d. Download logs; e. Delete the pod. 3. cleanup.py; a. Delete mysql instance; b. Delete kubernetes secret in db-benchmark namespace. Thoughts? . I tried to think about how to use the current build system and what I would do is add a new CreateSQLInstance step, CreateDatabase takes the instance name and IP address as a parameter, and have CI take a path to the build.yaml file to build from. But this wasn't straightforward with how to do this, so I thought the above was simpler to reason about.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7181#issuecomment-538453887:557,password,password,557,https://hail.is,https://github.com/hail-is/hail/pull/7181#issuecomment-538453887,1,['password'],['password']
Security,"I thought about porting some of the typechecker stuff from hail, but they don't serve quite the same purpose, and the functions themselves are pretty simple. This does move the schema definitions to the bottom of the file rather than at the top, but this way we have a schema description that includes requiredness and is guaranteed to be the thing we're actually validating on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9861:364,validat,validating,364,https://hail.is,https://github.com/hail-is/hail/pull/9861,1,['validat'],['validating']
Security,"I thought that pulling with no auth would use the credential helper to use the machine's; credentials. AFAICT, the Docker HTTP API has no way to use the credential helper. You *must* provide; authentication in the HTTP request which means the HTTP client must obtain the credentials; themselves. The Docker docs note [""Authentication for registries is handled client side. The client; has to send authentication details to various endpoints that need to communicate with; registries""](https://docs.docker.com/engine/api/v1.41/#section/Authentication). I request a short-lived oauth2 access token from the Google metadata endpoint. The google; [documentation obliquely notes that the username should be; `oauth2accesstoken`](https://cloud.google.com/container-registry/docs/advanced-authentication). I; use this only for retrieving a ""public gcr image"" which I fix in this PR to be images whose; ""repository"" [1] is one of these:; - gcr.io/PROJECT/query; - gcr.io/PROJECT/hail; - gcr.io/PROJECT/python-dill. A previous Shuffler PR taught worker.py to translate our `hailgenetics` Docker image names to; `gcr.io/PROJECT` image names. I had to move the docker-worker into a new Docker network which allows it to access the metadata server. I think this is safe because we trust our own code. From a relevant Docker worker log:. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 359, in ensure_image_is_pulled; docker.images.get, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/im",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9902:192,authenticat,authentication,192,https://hail.is,https://github.com/hail-is/hail/pull/9902,6,"['Authenticat', 'access', 'authenticat']","['Authentication', 'access', 'authentication']"
Security,I use these functions to monitor the k8s cluster. These are useful in the interim while we; move towards more robust monitoring solutions. To make these accessible modify your ~/.bashrc; or ~/.zshrc to have this line:. source /path/to/hail-repository/devbin/functions.sh. cc: services-team: @jigold @CDiaz96 @catoverdrive @cseed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10049:153,access,accessible,153,https://hail.is,https://github.com/hail-is/hail/pull/10049,1,['access'],['accessible']
Security,"I used `RegionValueVariant` to clean up some of the code, and fixed a couple of bugs from #2451 in the process. I also replaced the `aggregatePartitions` method I wrote in e5f87c3 following @danking's comment, which was defined on `OrderedRDD2`, with `aggregateWithContext`, which is defined on a rich wrapper around `RDD`. I put it in the spark package to get access to private methods, making the implementation cleaner. It is now a simple modification of the implementation of `RDD.aggregate`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2423#issuecomment-347624179:361,access,access,361,https://hail.is,https://github.com/hail-is/hail/pull/2423#issuecomment-347624179,1,['access'],['access']
Security,"I verified this manually. The deploy account didn't exist when I started this PR, but it still had a role grant in the project's IAM policy. Now the account still does not exist *and* the role grant is gone. The `login` forces you to switch to your account since we're deleting the service account (as which you're probably authenticated).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8178:324,authenticat,authenticated,324,https://hail.is,https://github.com/hail-is/hail/pull/8178,1,['authenticat'],['authenticated']
Security,"I wanted to get this feature done quickly for Michael. But I do think we should think about having consistency in route names across services. Like when do we have `/delete` in the route name versus a 'DELETE' request or both?. Another question is whether to add the polling / waiting for the user to be created and if so, where should the polling go? I put it in the auth service for now rather than the CLI because I don't think we expose the state of the user in our API. I tested this as much as I could in my namespace. The most important thing is to make sure the decorators are correct and only developers can create / delete users. I want to add auth tests that make sure the routes are protected, but that's more work than I wanted to do in this PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11249:434,expose,expose,434,https://hail.is,https://github.com/hail-is/hail/pull/11249,1,['expose'],['expose']
Security,I will run lets encrypt now.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9246#issuecomment-671463155:16,encrypt,encrypt,16,https://hail.is,https://github.com/hail-is/hail/pull/9246#issuecomment-671463155,1,['encrypt'],['encrypt']
Security,"I wonder if, using a consistent template, we could have CI do this, either by looking at the first comment, or by looking at the commit. Look for ""depends on: #hash"" string, much like GitHub does with ""closes #hash"" in commits.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7417#issuecomment-548480282:160,hash,hash,160,https://hail.is,https://github.com/hail-is/hail/issues/7417#issuecomment-548480282,2,['hash'],['hash']
Security,"I would also suggest the following as necessary for an upcoming release:. * #13728. Google's gcsfuse APT repository currently produces 502 Bad Gateway errors when accessed via http, which shows no sign of being resolved any time soon. I've commented on #13728 noting how this PR can work around the problem. At present (since early October), the `batch_worker_image` job always fails with 502 during a hail deployment.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13806#issuecomment-1763650602:163,access,accessed,163,https://hail.is,https://github.com/hail-is/hail/issues/13806#issuecomment-1763650602,1,['access'],['accessed']
Security,"I'd argue that it's broadly useful, but rather the issue is that it's useful at a lower level of abstraction (e.g. how it's used in `ld_prune`, composed with `sparsify_row_intervals`). So I see why the `hl` namespace is may be too high level, but it's also strange to put in experimental a function that is used in non-experimental (as well as experimental) methods. One option is to underscore the method for use outside experimental, but expose through the experimental module. Another is to put it in a submodule, like genetics. I'd like to expose more high-level applications directly (e.g. an `ld_matrix` function that takes an optional `radius` and `coord_expr` and returns the sparse block matrix), and we can think about re-implementing in terms of scans once they come online (deriving the stops from the starts) and zipping the intervals and blocks without ever localizing should memory or performance be an issue.; I don't want to hide it entirely in the meantime as several groups want to make use of it already.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3873#issuecomment-401468652:440,expose,expose,440,https://hail.is,https://github.com/hail-is/hail/pull/3873#issuecomment-401468652,2,['expose'],['expose']
Security,"I'd like to be able to export genotypes that have genotype calls but have AD=0 in order to investigate what's going on which these calls. (Also to have something to show Laura Gauthier when I complain to her about this.). Currently, exportgenotypes does not print homref or missing genotypes. Unfortunately, genotypes with AD=0 are treated as ""missing"" (at least in the filtering module), so I can't print these out. Cotton has suggested adding an -f flag in the exportgenotypes module that would allow me to access these genotypes -- e.g., . `exportgenotypes -f 'g.gq >= 20 && isMissing(g.fractionReadsRef)' -c 'sample=s, …'``",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/404:509,access,access,509,https://hail.is,https://github.com/hail-is/hail/issues/404,1,['access'],['access']
Security,"I'd like to give the user the ability to authenticate to our services from within a batch job. The specific use case I need it for is for the query service to be able to cache things with the memory service, but it seems like it could be more broadly applicable. I'm unsure whether this is the correct way to do it. This is currently not exposed in the python user interface (only in BatchClient), but I can pipe the option through in this PR if we want to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9437:41,authenticat,authenticate,41,https://hail.is,https://github.com/hail-is/hail/pull/9437,2,"['authenticat', 'expose']","['authenticate', 'exposed']"
Security,"I'd love feedback, especially on:; * How/whether to test these things; * How to organize a growing collection of hash families, with different speed/power tradeoffs, and different key and hash word-lengths. (These will be used in inner-most loops, so performance matters, and I don't have a good sense of what Scala abstractions hurt performance.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2288:113,hash,hash,113,https://hail.is,https://github.com/hail-is/hail/pull/2288,2,['hash'],['hash']
Security,"I'd propose to do an implicit dependency audit every time you push a new commit. You can still pin versions on published packages, but use unpinned dependencies for CI testing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7299#issuecomment-542208997:41,audit,audit,41,https://hail.is,https://github.com/hail-is/hail/issues/7299#issuecomment-542208997,1,['audit'],['audit']
Security,I'll PR a fix to the artifacts page that exposes the docs directly,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5063#issuecomment-451556932:41,expose,exposes,41,https://hail.is,https://github.com/hail-is/hail/pull/5063#issuecomment-451556932,1,['expose'],['exposes']
Security,"I'll do a performance test, but there's still foreign key constraints on these rows. They're just redundant. We don't need a check on both `batches` and `attempts`. The rows in `attempts` wouldn't have been inserted without the check in `batches`. All of these proposed changes don't change anything about data integrity.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11938#issuecomment-1163224811:311,integrity,integrity,311,https://hail.is,https://github.com/hail-is/hail/pull/11938#issuecomment-1163224811,1,['integrity'],['integrity']
Security,I'll prefix the thing with an underscore. I mostly want to expose this as an option so Chris can turn it back to 1 on the combiner,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5862#issuecomment-483878748:59,expose,expose,59,https://hail.is,https://github.com/hail-is/hail/pull/5862#issuecomment-483878748,1,['expose'],['expose']
Security,"I'll start reviewing functions based on ""High Speed Hashing for Integers and Strings"" so you can assign that PR to me.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2288#issuecomment-336538490:52,Hash,Hashing,52,https://hail.is,https://github.com/hail-is/hail/pull/2288#issuecomment-336538490,1,['Hash'],['Hashing']
Security,I'm a little confused. The snippet in the PR body gives impression that the sphinx injection happens after inserting the headers/footers. Should the raw blocks be the other way around?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10278#issuecomment-813632797:83,inject,injection,83,https://hail.is,https://github.com/hail-is/hail/pull/10278#issuecomment-813632797,1,['inject'],['injection']
Security,"I'm currently running this branch of CI on a pull request of itself on my own fork of hail, and it nearly passes all tests except for hailtop_batch_* because of requester pays permissions issues and monitoring, because I don't have a service account in my project with all the permissions for broad-ctsa. So unfortunately haven't fully validated that it will _not_ merge a passing PR, but this seemed good enough that we can push it through for azure (since both of these errors are gcp-dependent). If this goes through I can put in a follow-up PR that mirrors the infra resources that CI needs in azure (blob storage, acr permissions, etc.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11053#issuecomment-964437539:336,validat,validated,336,https://hail.is,https://github.com/hail-is/hail/pull/11053#issuecomment-964437539,1,['validat'],['validated']
Security,"I'm generalizing the CI's deploy system. https://github.com/hail-is/ci/pull/77. In particular, I no longer assume you need to authorize from to a gcloud account. Instead, I just mount you a volume. Each repo will have some secrets that it can authorize with. This is safe to merge now because before the CI changes go in, this just re-authorizes. When the CI changes merge, we'll go back to authorizing once, except that the command is in `hail-ci-deploy.sh` instead of baked into the CI system.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4261:126,authoriz,authorize,126,https://hail.is,https://github.com/hail-is/hail/pull/4261,4,['authoriz'],"['authorize', 'authorizes', 'authorizing']"
Security,"I'm going to close this PR because its so old. I've bumped the priority of certificates in my todo list. Sincere apologies @vladsaveliev , just too many things to do these days :|.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10188#issuecomment-1050025851:75,certificate,certificates,75,https://hail.is,https://github.com/hail-is/hail/pull/10188#issuecomment-1050025851,1,['certificate'],['certificates']
Security,I'm not going to read 7000 lines of deletions. Fine with me if it passes! And fine to delete tests conditional on audit soon.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3990#issuecomment-407914682:114,audit,audit,114,https://hail.is,https://github.com/hail-is/hail/pull/3990#issuecomment-407914682,1,['audit'],['audit']
Security,"I'm not gonna do the BinaryIntHeap stuff. For graphs smaller than 2^13, the cost is dominated by non-heap-things. For fully connected graphs of 2^13 or larger, representing the full graph in memory (you'll note in my examples I cheated by never reifying the graph) is rather difficult because you've got 2^26 nodes. I can't reify a 2^13 fully connected graph on my laptop with 4GB of RAM. The edge array alone is gonna be about 2^26 / 2 * 8 positions long, which is like 130 MB already, then each pair is probably about 100 bytes, so like a gig, and all I did was create an array of edges. Then I'd have to manipulate that to get an array of all the vertex set, and a hash map from vertex to its integer. I don't see this being so great for fully connected graphs. Perhaps there's some investigation needed for less fully connected graphs. But in that case the quadratic behavior is less relevant.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2148#issuecomment-326124085:668,hash,hash,668,https://hail.is,https://github.com/hail-is/hail/pull/2148#issuecomment-326124085,1,['hash'],['hash']
Security,"I'm not sure where these should live, but I wanted to move them off my laptop and into a place where people can access them, and the repo seems as good of a place as any. There are svgs for a bunch of icons in both blue and white, as well as high-ish resolution images of both versions of the logo and 32x32 icon pngs. I haven't started integrating them into website stuff yet, but I figured that raw images should have a central-ish place to live anyways. All of the images in the PR are as below:; ![all](https://user-images.githubusercontent.com/19789871/91755326-ece1d180-eb98-11ea-83ce-eec6b13ab18f.png)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9382:112,access,access,112,https://hail.is,https://github.com/hail-is/hail/pull/9382,1,['access'],['access']
Security,"I'm not sure whether we should add this proactively or not, and to be clear I don't intend users to generally use this, but this is the best solution I can think of so far for @illusional's question about what to do when we have removed support for the old hail access tokens but users still are forced to run a pipeline on an old hail version. Old hail access tokens are stored in JSON in `~/.hail/tokens.json`, so I believe (though have not yet tested, that the following should allow a user to use an old version of hail against a version of batch that only supports cloud access tokens:. On the *new* version of hail, run. ```; hailctl auth login; hailctl auth print-access-token | jq -R -c '{ default: . }' > ~/.hail/tokens.json; ```. Then switch to an old version and proceed as usual (but don't run `hailctl auth login`!).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528:262,access,access,262,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528,4,['access'],"['access', 'access-token']"
Security,"I've added some more information. I haven't quite figured out a good way to present all this. There seems to be three distinct things:; - the mounting of secrets to paths in the pods (documented as code in `deployment.yaml`s); - the name of k8s secrets, their contents, and the meaning of the contents (specifically what the applications expect of it). The latter would be best documented with scripts that regenerate the secrets from some root secret. We can [programmatically generate oauth tokens](https://developer.github.com/v3/oauth_authorizations/) (which are different from personal access tokens) with username and password authentication. A recreation script could use one privileged key that has access to username/password for each hail test user. That is used to generate auth-tokens (we might need to adapt our code to use oauth tokens instead of personal access tokens). GCP service account keys can be generated programmatically. Unfortunately, there seems to be a little bit of work involved in using OAuth instead of personal access tokens. We have to register our ""app"". I can look into this sometime soon. I'll create an issue.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4552#issuecomment-430432141:591,access,access,591,https://hail.is,https://github.com/hail-is/hail/pull/4552#issuecomment-430432141,7,"['access', 'authenticat', 'password']","['access', 'authentication', 'password']"
Security,I've authorized another test of this PR.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6825#issuecomment-521290991:5,authoriz,authorized,5,https://hail.is,https://github.com/hail-is/hail/pull/6825#issuecomment-521290991,1,['authoriz'],['authorized']
Security,I've authorized sha `600826710afb8dfef5fcbf19f440a43f263ec0ee` in CI so we should get a test run through soon.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14700#issuecomment-2407899242:5,authoriz,authorized,5,https://hail.is,https://github.com/hail-is/hail/pull/14700#issuecomment-2407899242,1,['authoriz'],['authorized']
Security,"I've been working on an R interface to Hail through the sparklyr package, with some minor success. However, a recent commit (e7552fd55a9d) is somehow causing Spark to stop prematurely when R calls the `is.hail.table.Table.count()` method. Any clues as to why this might be happening?. <details>; <summary>Stack trace</summary>. 	Error: org.apache.spark.SparkException: Job 3 cancelled because SparkContext was shut down; 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:820); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:818); 	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); 	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:818); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1732); 	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:83); 	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1651); 	at org.apache.spark.SparkContext$$anonfun$stop$8.apply$mcV$sp(SparkContext.scala:1921); 	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317); 	at org.apache.spark.SparkContext.stop(SparkContext.scala:1920); 	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581); 	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216); 	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188); 	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188); 	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); 	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.sc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:674,Hash,HashSet,674,https://hail.is,https://github.com/hail-is/hail/issues/4513,2,['Hash'],['HashSet']
Security,"I've changed BlockMatrix.from(lm: BDM[Double]) so that each executor is transmitted only the blocks it needs (~num_blocks/num_executors) rather than all of them: ""[TorrentBroadcast](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-TorrentBroadcast.html) uses a BitTorrent-like protocol for block distribution (that only happens when tasks access broadcast variables on executors)."". In another branch, I've verified on GCP that distributing and then localizing a 10k x 10k matrix is twice as fast (about 15s vs 30s). Distributing and then writing a 25k by 25k matrix (5GB) with 10+2 standard 8-core workers takes about 30s with the new method but fails for every partition with the old method (months ago I believe I sometimes got the old method to work at this scale using high mem. It's needed for LMM). Note the matrix only has 49 partitions at the new default blockSize so I had more cores than needed for the experiment. I've also added a method to write a local matrix as a block matrix. I use ParRange to parallelize writing from master. Writing and then reading should be the safest way to distribute a big local matrix at the beginning of complex pipelines, and I think it avoids some of the memory overhead associated with broadcast.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2848:354,access,access,354,https://hail.is,https://github.com/hail-is/hail/pull/2848,1,['access'],['access']
Security,"I've removed the Python `tempfile` approach in favor of adding `new_local_temp_file` to utils and a corresponding function to HailContext in Scala, which currently hardcodes `file:///temp` as the local temp directory. It may be more natural to have a localTmpDir on HailContext like we have tmpDir. ; I see there is a notion of local temp files on TempDir on the Scala side, but it doesn't seem to be used on the Python side. I also don't see if/where we wipe temp files on exit. In any case, I've tested that now it all works nicely on GCP, so ready for feedback/review. I think factoring through `tofile` and `fromfile` is useful for wider interoperability for the same reason that NumPy exposes them, but it's also good if you don’t want to actually load the NumPy array into driver memory but just save it to read/copy later, or to load it multiple time without recomputing the BlockMatrix. And I've provided the simpler interface of `to_numpy` and `from_numpy` for the common case. I suspect that (de)serializing over the network and building the local matrix dominates local read/write, so that using a socket isn't going to do much better. I can profile more closely if/when we feel it's high priority to make this faster still.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3114#issuecomment-372165433:690,expose,exposes,690,https://hail.is,https://github.com/hail-is/hail/pull/3114#issuecomment-372165433,1,['expose'],['exposes']
Security,"I've repurposed the `TIterable` class so that ""Iterable"" means something you can iterate over (containers and streams) and ""Container"" means something with elements that you can access by index/out of order (arrays, sets, dicts). This should make typing IRs easier if we intend to have a `ToStream` IR to enforce non-instantiation.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5610#issuecomment-473423764:178,access,access,178,https://hail.is,https://github.com/hail-is/hail/pull/5610#issuecomment-473423764,1,['access'],['access']
Security,"I've validated correctness for haploid calls manually, and confirmed that results for diploid calls don't change.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10251#issuecomment-818810396:5,validat,validated,5,https://hail.is,https://github.com/hail-is/hail/pull/10251#issuecomment-818810396,1,['validat'],['validated']
Security,I've validated our setup has those requirements and we're just hitting a FatalError from a commit a few weeks ago. https://github.com/hail-is/hail/blob/a0e8eb81e0f4d7ad446723e7cc04d4c6ac4ad066/hail/python/hail/context.py#L59-L67. If I revert this file we're able to pass in the existing SparkContext with the expected `hl.init(sc=sc)`. As general feedback it may be better to warn here than force exit. I may be wrong but I don't see a way around this for people using remote notebooks to talk to Spark via Livy.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7080#issuecomment-537048154:5,validat,validated,5,https://hail.is,https://github.com/hail-is/hail/issues/7080#issuecomment-537048154,1,['validat'],['validated']
Security,IJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZJJJZJZIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZJJJZJZJIJZJJIJZZJJIJZZJZJZJZJZJZJZJZJZJIJJIJJZJZJZJZLis/hail/io/OutputBuffer;; 	at scala.Predef$.require(Predef.scala:281); 	at is.hail.asm4s.MethodBuilder.<init>(ClassBuilder.scala:531); 	at is.hail.asm4s.ClassBuilder.newMethod(ClassBuilder.scala:324); 	at is.hail.expr.ir.EmitClassBuilder.newEmitMethod(EmitClassBuilder.scala:584); 	at is.hail.expr.ir.EmitClassBuilder.genEmitMethod(EmitClassBuilder.scala:754); 	at is.hail.expr.ir.EmitClassBuilder.$anonfun$getOrGenEmitMethod$1(EmitClassBuilder.scala:747); 	at scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:86); 	at is.hail.expr.ir.EmitClassBuilder.getOrGenEmitMethod(EmitClassBuilder.scala:746); 	at is.hail.types.encoded.EType.buildEncoderMethod(EType.scala:57); 	at is.hail.types.encoded.EType.buildEncoder(EType.scala:49); 	at is.hail.expr.ir.PartitionNativeWriter$StreamConsumer.consumeElement(TableWriter.scala:294); 	at is.hail.expr.ir.PartitionNativeWriter.$anonfun$consumeStream$1(TableWriter.scala:334); 	at is.hail.expr.ir.PartitionNativeWriter.$anonfun$consumeStream$1$adapted(TableWriter.scala:332); 	at is.hail.expr.ir.streams.StreamProducer.$anonfun$memoryManagedConsume$1(EmitStream.scala:113); 	at is.hail.expr.ir.streams.StreamProducer.$anonfun$memoryManagedConsume$1$adapted(EmitStream.scala:112); 	at is.hail.expr.ir.streams.StreamProducer.unmanagedConsume(EmitStream.scala:100); 	at is.hail.expr.ir.streams.StreamProducer.memoryManagedConsume(EmitStream.scala:112); 	at is.hail.expr.ir.PartitionNativeWriter.consumeStream(TableWriter.scala:332); 	at is.hail.expr.ir.Em,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12533:5120,Hash,HashMap,5120,https://hail.is,https://github.com/hail-is/hail/issues/12533,1,['Hash'],['HashMap']
Security,"IMHO, I'd just merge it if you're happy with everything else. Breaking the build results page only affects developers and it doesn't even really break anything since we can use `gsutil` to directly access the results.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4551#issuecomment-431459832:198,access,access,198,https://hail.is,https://github.com/hail-is/hail/pull/4551#issuecomment-431459832,1,['access'],['access']
Security,"IR entropy and doc, expose sign doc, NaN to nan",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3793:20,expose,expose,20,https://hail.is,https://github.com/hail-is/hail/pull/3793,1,['expose'],['expose']
Security,"Ideally, I should be able to work directly from an `AltAlleleView`. But then I would have to copy all of the `isInsertion`, `isDeletion`, etc., methods from `AltAllele`, which feels wrong. As it's only a per-variant allocation, I think allocating `AltAllele` objects to get access to those methods is the right compromise currently, though I'm certainly open to alternatives.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2428#issuecomment-344369282:274,access,access,274,https://hail.is,https://github.com/hail-is/hail/pull/2428#issuecomment-344369282,1,['access'],['access']
Security,"Identities in test namespaces cannot share the same underlying cloud identity if we want to identify requests with cloud access tokens. This also means the `test` account does not need to have the union of roles of the other robot accounts, but pruning of the `test` account's roles is left until after this PR merges so we can properly assess which roles are still in use by the `test` account.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13202:121,access,access,121,https://hail.is,https://github.com/hail-is/hail/pull/13202,1,['access'],['access']
Security,"If I'm understanding the example at the end correctly, it sounds like you really only need a hash of `(batch id, job id, attempt id)` (though hash functions and PRNGs are very closely related).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13502#issuecomment-1693664506:93,hash,hash,93,https://hail.is,https://github.com/hail-is/hail/issues/13502#issuecomment-1693664506,2,['hash'],['hash']
Security,"If a batch contains a job who lists the same parent twice, Batch will encounter; [integrity errors from; MySQL](https://hail.zulipchat.com/#narrow/stream/127527-team/topic/ci.20broken/near/195236580). For; example, this error was raised when I duplicated a parent in build.yaml:. pymysql.err.IntegrityError: (1062, ""Duplicate entry '35921-13-1' for key 'PRIMARY'"")""}. This change catches the integrity error and raises a more useful 400 bad request; error message.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8830:82,integrity,integrity,82,https://hail.is,https://github.com/hail-is/hail/pull/8830,3,"['Integrity', 'integrity']","['IntegrityError', 'integrity']"
Security,"If a user writes a map over a local array or stream value, which they know is large, they should be able to force scratch memory to be cleared after each row. This can be an underscored parameter for expert use only. We would need to add a `requires_memory_management_per_row` flag to the `StreamMap` node, and expose it in user facing methods which generate a `StreamMap` like `ArrayExpression.map`. Then the rule in `EmitStream` would need to combine this with the child stream's `requiresMemoryManagementPerRow`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14383:311,expose,expose,311,https://hail.is,https://github.com/hail-is/hail/issues/14383,1,['expose'],['expose']
Security,"If we cannot authenticate the user, we should send them to a publicly accessible page where the error message can be presented.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12401:13,authenticat,authenticate,13,https://hail.is,https://github.com/hail-is/hail/pull/12401,2,"['access', 'authenticat']","['accessible', 'authenticate']"
Security,"If we go through route (2), this project can serve as a prototype C or C++ interface to Hail. This interface could take multiple forms. For example, we could actually re-build our memory representation implementations in C++ and compile SAIGE, at Hail-Query-compile-time (i.e. when we are compiling a *user's* query), to use whatever SType/PType that Hail has decided is the ideal. A simpler approach is to implement one canonical implementation of the Hail types in C++, fork & slightly modify SAIGE to accept these memory representations, compile SAIGE at Java compile time (i.e. in CI or when you run `make` on your laptop) against these mem reps, ship the compiled library with the Hail JAR, and expose it, via JNI, into the Hail Query language. This requires that the Query compiler can call a function which only supports arguments using one particular SType/PType.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13442#issuecomment-1679739816:700,expose,expose,700,https://hail.is,https://github.com/hail-is/hail/issues/13442#issuecomment-1679739816,1,['expose'],['expose']
Security,Implement 5-independent tabulation hash,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2311:35,hash,hash,35,https://hail.is,https://github.com/hail-is/hail/pull/2311,1,['hash'],['hash']
Security,Implement old interface using expression language.; New interface is not yet exposed in Python (like split_multi). This will come in a later PR. This should use SplitMulti.unionMovedVariants from https://github.com/hail-is/hail/pull/2381. I will make this change as a separate PR after they both go in.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2382:77,expose,exposed,77,https://hail.is,https://github.com/hail-is/hail/pull/2382,1,['expose'],['exposed']
Security,"Implements a basic GCP metadata server for user jobs as described in https://github.com/hail-is/hail-rfcs/pull/12. It implements only so much as is needed for `hail` and `gcloud` to get access tokens for hail GSAs so they can then make API calls to GCS or Hail Batch. With this in place user jobs should no longer require GSA key files, but removing them is future work and requires a well-communicated deprecation and removal process.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14019:186,access,access,186,https://hail.is,https://github.com/hail-is/hail/pull/14019,1,['access'],['access']
Security,"Implements a more involved tabulation based hash function which achieves 5-independence (which will be needed in one of the basic primitives for randomized linear algebra). This method is described in [Tabulation-Based 5-Independent Hashing with Applications to Linear Probing and Second Moment Estimation](http://www.cs.utexas.edu/~yzhang/papers/5-indep-sicomp12.pdf), which provides C code in section A.7.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2311:44,hash,hash,44,https://hail.is,https://github.com/hail-is/hail/pull/2311,2,"['Hash', 'hash']","['Hashing', 'hash']"
Security,"Implements simple tabulation and twisted tabulation hash methods. See [Fast and Powerful Hashing using Tabulation](http://arxiv.org/abs/1505.01523v5): simple tabulation is described in Section 2, twisted tabulation is described in Section 3, and Figure 1 on p.9 has C code for both.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2304:52,hash,hash,52,https://hail.is,https://github.com/hail-is/hail/pull/2304,2,"['Hash', 'hash']","['Hashing', 'hash']"
Security,"Implements the two ""multiply-shift"" hash functions, as described in [High Speed Hashing for Integers and Strings](http://arxiv.org/abs/1504.06804v3), sections 2.3 and 3.3. They have the weakest still useful distributional properties, but are often sufficient, and very very fast.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2303:36,hash,hash,36,https://hail.is,https://github.com/hail-is/hail/pull/2303,2,"['Hash', 'hash']","['Hashing', 'hash']"
Security,"In addition to setting up SSL access to TeamCity (see #674), we should harden the TeamCity instance against attacks:; 1. change the user running and owning TeamCity to a new user called `teamcity`; 2. review the [Security Notes](https://confluence.jetbrains.com/pages/viewpage.action?pageId=74845225#HowTo...-TeamCitySecurityNotes) to ensure we don't have any other remaining security holes",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/675:30,access,access,30,https://hail.is,https://github.com/hail-is/hail/issues/675,4,"['Secur', 'access', 'attack', 'secur']","['Security', 'access', 'attacks', 'security']"
Security,"In order to start using Google or AAD access tokens instead of hail-minted tokens, we need to be able to identify a service account in the system by its UID at their identity provider. In Google, this UID is the `uniqueId` field of the Service Account. In AAD, it is the Service Principal Object ID. In an upcoming change, we'll update the user creation process to add this ID upon user creation, at which point we will be able to safely remove this code that updates existing records. I've marked this PR as `full-deploy` so the AUS folks can roll this commit out specifically before this column is relied on. This way we can safely remove the loop in a follow-up PR and know they will have run this code to populate the column.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13207:38,access,access,38,https://hail.is,https://github.com/hail-is/hail/pull/13207,1,['access'],['access']
Security,"In particular, struct field names which clash with methods on `StructExpression`. close #13495. CHANGELOG: Fix a bug where field names can shadow methods on the StructExpression class, e.g. ""items"", ""keys"", ""values"". Now the only way to access such fields is through the getitem syntax, e.g. ""some_struct['items']"". It's possible this could break existing code that uses such field names.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13498:237,access,access,237,https://hail.is,https://github.com/hail-is/hail/pull/13498,1,['access'],['access']
Security,"In particular, the design of the Broad GCP Security Best Practices is to disable everything by default and then selectively enable. The master tag enables SSH access for the master node.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7978#issuecomment-578973978:43,Secur,Security,43,https://hail.is,https://github.com/hail-is/hail/pull/7978#issuecomment-578973978,2,"['Secur', 'access']","['Security', 'access']"
Security,"In the spirit of getting everyone talking with the same authentication mechanism. The communication between batch and batch-driver isn't really a big deal, but we are basically storing a password as plaintext with this `internal_token`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13642:56,authenticat,authentication,56,https://hail.is,https://github.com/hail-is/hail/pull/13642,2,"['authenticat', 'password']","['authentication', 'password']"
Security,"In the spirit of shrinking the `Backend` functionality to a core set of functions, move code cache access via execute context.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14691:99,access,access,99,https://hail.is,https://github.com/hail-is/hail/pull/14691,1,['access'],['access']
Security,"In the worst case of a fully connected graph it's O(n) insertions, at an average cost of O(1), followed by O(n) `extractMax` which are O(log n) each. For each `extractMax` we have to decrease priority on every other node, so thats O(n^2) decreasePriority which is O(log n) each. So the dominating factor is O(n^2 log(n)). We should almost never see fully connected graphs. I suspect we'll usually have disconnected graphs of fully connected subgraphs. Then the runtime is O(m * n^2 log(n)) where `m` is the number of families and `n` is the average family size. `n` should be rather small, probably not higher than 20? probably smaller. `m` could be quite large, but we're linear in `m`. Some timings for fully connected graphs of size `n`:. | `n` | time (minutes) |; |-|-|; | 1024 | 0.0051 |; | 8192 | 0.13 |; | 32767 | 3.0 |; | 65535 | 12.5 |. According to the profiler, the vast majority of the time is spent interacting with the hash table. We could probably get the constants a lot lower by using an array instead of a hash table (since we have a perfect hash function: sample index). ---. ```; def fullyConnected(n: Int) {; val biggestFirst = new BinaryHeap[Int](). var i = 0; while (i <= n) {; biggestFirst.insert(i, n); i += 1; }. val g = (i: Int) => 0 to n. while (biggestFirst.maxPriority() > 0) {; val current = biggestFirst.extractMax(); val neighbors = g(current); neighbors.foreach { x =>; if (biggestFirst.contains(x)); biggestFirst.decreasePriority(x, _ - 1); }; }. val actual = biggestFirst.toArray; assert(actual.length === 1); }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2148#issuecomment-326072568:933,hash,hash,933,https://hail.is,https://github.com/hail-is/hail/pull/2148#issuecomment-326072568,3,['hash'],['hash']
Security,"In-cluster I have the ability to create a pod, including the secret, which is slightly surprising to me. Does the ability create a pod give ability to mount any secret? Surely not. At the same time, my rbac for notebook clearly defines the only secret it can access:. ```; (base) alex:~/projects/hail/notebook2:$ k get role read-get-user-secret -o json; {; ""apiVersion"": ""rbac.authorization.k8s.io/v1"",; ""kind"": ""Role"",; ""rules"": [; {; ""apiGroups"": [; """"; ],; ""resourceNames"": [; ""get-users""; ],; ""resources"": [; ""secrets""; ],; ""verbs"": [; ""get""; ]; }; ]; }; ```. The other permissions are for service and pod resources. These pods are bound to the user's service account. I also don't appear to need to give that service account that is bound (SA ""B"") permission to read the mounted secret. This makes sense to me: the container should be able to access anything on its file system. The notebook leader defines what that is. cc @cseed, thought you may want to know. The following was from a manual in-cluster test:; <img width=""940"" alt=""Screenshot 2019-04-02 15 55 39"" src=""https://user-images.githubusercontent.com/5543229/55432272-78989e00-5560-11e9-960e-1362d277d759.png"">. Partial description of a recently created pod (sans status); ```sh; (base) alex:~/projects/hail/notebook2:$ k get pod notebook2-worker-d4snh -o yaml; apiVersion: v1; kind: Pod; metadata:; creationTimestamp: ""2019-04-02T19:50:21Z""; generateName: notebook2-worker-; labels:; app: notebook2-worker; hail.is/notebook2-instance: f4dc8213468f4799a3c7f94cb6969309; jupyter_token: 484b71e2c12d42c79b169b1991602d45; name: a_notebook; user_id: e7e7b9c420f0b0ff503ab6711355f27748522a8a37d9d22b2c8e0af4; uuid: 84873cf540014e128cce18f5481fb682; name: notebook2-worker-d4snh; namespace: default; resourceVersion: ""41241284""; selfLink: /api/v1/namespaces/default/pods/notebook2-worker-d4snh; uid: 8cb3c1c2-5580-11e9-bcd4-42010a8000c9; spec:; containers:; - command:; - jupyter; - notebook; - --NotebookApp.token=484b71e2c12d42c79b169b199",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5753#issuecomment-479174611:259,access,access,259,https://hail.is,https://github.com/hail-is/hail/pull/5753#issuecomment-479174611,3,"['access', 'authoriz']","['access', 'authorization']"
Security,IncompleteReadError is exported from asyncio and has been since python; 3.6 (as far back as I checked). At some point (checked with python 3.10); it stopped being accessible from asyncio.streams,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11737:163,access,accessible,163,https://hail.is,https://github.com/hail-is/hail/pull/11737,1,['access'],['accessible']
Security,"Instead of creating a hail context, I've exposed the top level `init` and `stop` methods in hail2. . Env.hc() will call init if it's not been called yet, and print a message about initializing with default params.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2820#issuecomment-360908387:41,expose,exposed,41,https://hail.is,https://github.com/hail-is/hail/pull/2820#issuecomment-360908387,1,['expose'],['exposed']
Security,Internal communication within the Hail Batch system uses TLS using self-signed certificates except the Batch Driver -> Worker communication and Worker -> Internal Gateway communication. This PR fixes the former to use TLS.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14581:79,certificate,certificates,79,https://hail.is,https://github.com/hail-is/hail/pull/14581,1,['certificate'],['certificates']
Security,"Investigate whether possible to invert menu inclusion, such that each project injects its own menu alongside a common menu section (e.g login).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7276:78,inject,injects,78,https://hail.is,https://github.com/hail-is/hail/issues/7276,1,['inject'],['injects']
Security,"Issue I ran into: I need to pass each child IR's ptype to the join point loop body. There isn't a very easy way to get one PType out of an IndexedSeq[PType] of ptypes. For instance, even though srvb.advance() runs inside the body of the JoinPoint loop, its staticIdx does not update (since the loop only iterates at runtime). I want to pass Code[IndexedSeq[PType]] but that isn't possible. Will work on tomorrow. . edit:. I think I need to do something like this to access individual ptypes (but within toEmitTriplet loop body): . ```scala; case x@MakeStream(elements, t) =>; val e = coerce[PStreamable](x.pType).elementType; implicit val eP = TypedTriplet.pack(e); sequence(elements.map { ir => TypedTriplet(e, emitIR(ir, env)) }); .map(_.untyped); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8063#issuecomment-583963692:466,access,access,466,https://hail.is,https://github.com/hail-is/hail/pull/8063#issuecomment-583963692,1,['access'],['access']
Security,Issue: #14718. ### Change Description. Adding permissions for grohli. ### Security Assessment; Covered in issue,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14717:74,Secur,Security,74,https://hail.is,https://github.com/hail-is/hail/pull/14717,1,['Secur'],['Security']
Security,Issue: #14728. ## Change Description. Adds new Hail team member Karen Sittig (ksittig) to AUTHORIZED_USERS in `ci/ci/constants.py`. ## Security Assessment. Delete all except the correct answer:; - This change has a high security impact; - [x] Required: The impact has been assessed and approved by appsec. ### Impact Description. Adds a new developer / administrator to the Hail project.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14727:135,Secur,Security,135,https://hail.is,https://github.com/hail-is/hail/pull/14727,2,"['Secur', 'secur']","['Security', 'security']"
Security,"It exists on LoadVCF in Scala, but isn't exposed in Python.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3341:41,expose,exposed,41,https://hail.is,https://github.com/hail-is/hail/issues/3341,1,['expose'],['exposed']
Security,It is no longer the case that VCF does not support phased haploid calls. Make a note of this in the code. ## Security Assessment; - This change has no security impact. ### Impact Description; Change error messages only.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14742:109,Secur,Security,109,https://hail.is,https://github.com/hail-is/hail/pull/14742,2,"['Secur', 'secur']","['Security', 'security']"
Security,"It is not free and we get emails about having too many page views pretty frequently. I suspect this is due to the jobs page having a download icon. The font provided by Google with its material design icons seems to be free to access at any scale. I got the GitHub octocat from GitHub's website. It's a bit bigger. <img width=""1130"" alt=""this PR"" src=""https://github.com/hail-is/hail/assets/106194/31e1cc67-ce9f-4e1f-a6b2-64258a8596c0"">; <img width=""1130"" alt=""main"" src=""https://github.com/hail-is/hail/assets/106194/ce9cc44d-3332-4b88-b733-4ac46a9f8e16"">. I didn't actually dev deploy batch to check the other assets but I suspect they're fine enough. This is what the question mark in a circle looks like: https://fonts.google.com/icons?selected=Material%20Symbols%20Outlined%3Ahelp%3AFILL%400%3Bwght%40400%3BGRAD%400%3Bopsz%4024 And this is what the download icon looks like: https://fonts.google.com/icons?selected=Material%20Symbols%20Outlined%3Adownload%3AFILL%400%3Bwght%40400%3BGRAD%400%3Bopsz%4024",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14302:227,access,access,227,https://hail.is,https://github.com/hail-is/hail/pull/14302,1,['access'],['access']
Security,"It seems that it does happen after the header is inserted but the footers are inserted after the Sphinx injection for the main block. So, will we need to create a separate CSS file for when the website runs through a second time it is pulling the most up-to-date styling changes?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10278#issuecomment-813640189:104,inject,injection,104,https://hail.is,https://github.com/hail-is/hail/pull/10278#issuecomment-813640189,1,['inject'],['injection']
Security,"It seems that sessions sometimes become inaccessible to auth. Using some; logging, I realized that `/login` will set some session parameters that do not; reappear in `/oauth2callback`. While trying to debug this, I deleted my cookie; and everything started working again. Luckily, my phone was still borked. The; fix is to use `new_session` which I discovered with a big red warning in; aiohttp-session's docs: [Always use new_session() instead of get_session() in; your login views to guard against Session Fixation; attacks!](https://aiohttp-session.readthedocs.io/en/stable/reference.html#aiohttp_session.new_session). If nothing else, we are now safe from session fixation attacks. I do not; understand why this is necessary for correctness.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8052:518,attack,attacks,518,https://hail.is,https://github.com/hail-is/hail/pull/8052,2,['attack'],['attacks']
Security,"It seems the biggest remaining issue is that CI doesn't have access to hail imports when testing hailtop. Could we address this? Do you want a PR?. edit: nvm, patched here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9194#issuecomment-670044799:61,access,access,61,https://hail.is,https://github.com/hail-is/hail/pull/9194#issuecomment-670044799,1,['access'],['access']
Security,"It would need BigQuery access to broad-ctsa, since that's where the data for the monitoring service lives. You can also look at the billing-monitor service account. I'm not sure much beyond that because I don't seem to be able to see broad-ctsa anymore in the console? And I only have IAM permissions in hail-vdc.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11053#issuecomment-964628523:23,access,access,23,https://hail.is,https://github.com/hail-is/hail/pull/11053#issuecomment-964628523,1,['access'],['access']
Security,"It's a shame that we have to restart a whole job just because GCP's authentication servers hiccuped. This change retries the auth once if it fails after a random wait of [5, 10) seconds.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6797:68,authenticat,authentication,68,https://hail.is,https://github.com/hail-is/hail/pull/6797,1,['authenticat'],['authentication']
Security,"It's an edge case, largely in the case of a network partition where a worker node becomes unreachable. I believe that the batch driver will at some point declare the node dead and reschedule its jobs even if the machine is still running. This might not be hard to change given that the batch driver subscribes to the audit log and can use the vm api to verify a worker's state. I also think this barely ever happens except in the case of actual bugs on the worker",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14460#issuecomment-2427210749:317,audit,audit,317,https://hail.is,https://github.com/hail-is/hail/issues/14460#issuecomment-2427210749,1,['audit'],['audit']
Security,JJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZJJJZJZIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZJJJZJZJIJZJJIJZZJJIJZZJZJZJZJZJZJZJZJZJIJJIJJZJZJZJZLis/hail/io/OutputBuffer;; 	at scala.Predef$.require(Predef.scala:281); 	at is.hail.asm4s.MethodBuilder.<init>(ClassBuilder.scala:531); 	at is.hail.asm4s.ClassBuilder.newMethod(ClassBuilder.scala:324); 	at is.hail.expr.ir.EmitClassBuilder.newEmitMethod(EmitClassBuilder.scala:584); 	at is.hail.expr.ir.EmitClassBuilder.genEmitMethod(EmitClassBuilder.scala:754); 	at is.hail.expr.ir.EmitClassBuilder.$anonfun$getOrGenEmitMethod$1(EmitClassBuilder.scala:747); 	at scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:86); 	at is.hail.expr.ir.EmitClassBuilder.getOrGenEmitMethod(EmitClassBuilder.scala:746); 	at is.hail.types.encoded.EType.buildEncoderMethod(EType.scala:57); 	at is.hail.types.encoded.EType.buildEncoder(EType.scala:49); 	at is.hail.expr.ir.PartitionNativeWriter$StreamConsumer.consumeElement(TableWriter.scala:294); 	at is.hail.expr.ir.PartitionNativeWriter.$anonfun$consumeStream$1(TableWriter.scala:334); 	at is.hail.expr.ir.PartitionNativeWriter.$anonfun$consumeStream$1$adapted(TableWriter.scala:332); 	at is.hail.expr.ir.streams.StreamProducer.$anonfun$memoryManagedConsume$1(EmitStream.scala:113); 	at is.hail.expr.ir.streams.StreamProducer.$anonfun$memoryManagedConsume$1$adapted(EmitStream.scala:112); 	at is.hail.expr.ir.streams.StreamProducer.unmanagedConsume(EmitStream.scala:100); 	at is.hail.expr.ir.streams.StreamProducer.memoryManagedConsume(EmitStream.scala:112); 	at is.hail.expr.ir.PartitionNativeWriter.consumeStream(TableWriter.scala:332); 	at is,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12533:5096,Hash,HashMap,5096,https://hail.is,https://github.com/hail-is/hail/issues/12533,1,['Hash'],['HashMap']
Security,"Jobs that are configured with `mount_tokens=True` will have their Hail tokens mounted into the main container. However, now that we are using access tokens from cloud identities, the tokens are no longer used. This removes the default behavior of mounting the `tokens.json` files since they aren't used by our codebase anyway.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14059:142,access,access,142,https://hail.is,https://github.com/hail-is/hail/pull/14059,1,['access'],['access']
Security,"Jupyter notebook by default uses random tokens to secure itself against public attackers. Let's just use that token and expose jupyter publicly. cloudtools can open the port:; ```; gcloud compute instances add-tags CLUSTER_NAME-m \; --zone [ZONE] \; --tags cloudtools-CLUSTER_NAME-jupyter; gcloud compute firewall-rules create CLUSTER_NAME-expose-jupyter \; --action allow \; --direction ingress \; --rules tcp:8123 \; --priority 1 \; --target-tags cloudtools-CLUSTER_NAME-jupyter; ```. Then cloudtools can ssh there and read the token from the jupyter logs, then it can direct the user to the instance's public IP (look at `gcloud compute instances describe CLUSTER_NAME-m`) with the appropriate token.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5236:50,secur,secure,50,https://hail.is,https://github.com/hail-is/hail/issues/5236,5,"['attack', 'expose', 'firewall', 'secur']","['attackers', 'expose', 'expose-jupyter', 'firewall-rules', 'secure']"
Security,Just need to expose `InbreedingCombiner` in expr language. Needed for GnomAD QC. Related issue: https://github.com/hail-is/hail/issues/501,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/918:13,expose,expose,13,https://hail.is,https://github.com/hail-is/hail/issues/918,1,['expose'],['expose']
Security,"K-PYTHON-CRYPTOGRAPHY-6092044](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6092044) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0Yzg3NGFkNy01NjNmLTQ5Y2QtOTc3My04YjlmMTA5NWUzNmMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjRjODc0YWQ3LTU2M2YtNDljZC05NzczLThiOWYxMDk1ZTM2YyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""4c874ad7-563f-49cd-9773-8b9f1095e36c"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:9340,access,access,9340,https://hail.is,https://github.com/hail-is/hail/pull/14148,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"K-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5ZjJhMGZlMy1kYmVkLTQ2YzAtYmQyMC0yMjM3NzFiYzE0OTciLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjlmMmEwZmUzLWRiZWQtNDZjMC1iZDIwLTIyMzc3MWJjMTQ5NyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""9f2a0fe3-dbed-46c0-bd20-223771bc1497"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:10483,access,access,10483,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"K-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxM2UyYzQ2MC1mZTA2LTQwOTktYWRhYi1lMWY4ZmE5MzFkZTAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjEzZTJjNDYwLWZlMDYtNDA5OS1hZGFiLWUxZjhmYTkzMWRlMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""13e2c460-fe06-4099-adab-e1f8fa931de0"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14329:10471,access,access,10471,https://hail.is,https://github.com/hail-is/hail/pull/14329,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"Keeping in mind Cotton's queries last week, researched and found much lighter alternative to ExprsesJS for the server api. A few years ago, Express had low impact on node performance; it has become bloated. Found a light (~200 LOC) ""framework"" called Polka, that is small enough to maintain ourselves. It mainly adds light route-matching capabilities, to avoid repeating boilerplate when writing the Node server. Easy to follow. It's also the fastest ""framework"" available, outside of C/Go/Rust. Matches Falcon, and allows 1 language for server/web. (Also Node has a far larger ecosystem).; * https://github.com/the-benchmarker/web-frameworks ; * Polka also nearly compatible with Express's middleware api, so many existing packages are either directly usable, or with minor modifications. This was a desire of mine, since nearly everything server-y for node is really written for Express. Last commit removes all Express, adds a rewritten express-jwt for access token verification, and shows client credential exchange, backed by Redis cache, for <=4ms fetching of",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-447583569:956,access,access,956,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-447583569,1,['access'],['access']
Security,"L. This will only impact users who build; <code>cryptography</code> from source (i.e., not from a <code>wheel</code>), and specify their; own version of OpenSSL. For those users, the <code>CFLAGS</code>, <code>LDFLAGS</code>,; <code>INCLUDE</code>, <code>LIB</code>, and <code>CRYPTOGRAPHY_SUPPRESS_LINK_FLAGS</code> environment; variables will no longer be respected. Instead, users will need to; configure their builds <code>as documented here</code>_.</li>; <li>Added support for; :ref:<code>disabling the legacy provider in OpenSSL 3.0.x&lt;legacy-provider&gt;</code>.</li>; <li>Added support for disabling RSA key validation checks when loading RSA; keys via; :func:<code>~cryptography.hazmat.primitives.serialization.load_pem_private_key</code>,; :func:<code>~cryptography.hazmat.primitives.serialization.load_der_private_key</code>,; and; :meth:<code>~cryptography.hazmat.primitives.asymmetric.rsa.RSAPrivateNumbers.private_key</code>.; This speeds up key loading but is :term:<code>unsafe</code> if you are loading potentially; attacker supplied keys.</li>; <li>Significantly improved performance for; :class:<code>~cryptography.hazmat.primitives.ciphers.aead.ChaCha20Poly1305</code></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/d6951dca25de45abd52da51b608055371fbcde4e""><code>d6951dc</code></a> changelog + security fix backport (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8231"">#8231</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/138da90c8450446b19619e3faa77b9da54c34be3""><code>138da90</code></a> workaround scapy bug in downstream tests (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8218"">#8218</a>) (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8228"">#8228</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/69527bc7",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12668:3060,attack,attacker,3060,https://hail.is,https://github.com/hail-is/hail/pull/12668,4,['attack'],['attacker']
Security,"LTRjZjJhNTdhZDkzOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""d384d00e-b18b-41bc-871f-4cf2a57ad938"",""prPublicId"":""d384d00e-b18b-41bc-871f-4cf2a57ad938"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,509,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13718:5565,validat,validation,5565,https://hail.is,https://github.com/hail-is/hail/pull/13718,3,"['Access', 'access', 'validat']","['Access', 'access-control', 'validation']"
Security,"LWJmMWY5Mzc1NTVhYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""759202b1-ae50-4125-b3a5-bf1f937555ac"",""prPublicId"":""759202b1-ae50-4125-b3a5-bf1f937555ac"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,509,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13836:5633,validat,validation,5633,https://hail.is,https://github.com/hail-is/hail/pull/13836,3,"['Access', 'access', 'validat']","['Access', 'access-control', 'validation']"
Security,"LWY3ZGM4YjIwOTVhNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""6e02a47f-633e-4605-b359-f7dc8b2095a6"",""prPublicId"":""6e02a47f-633e-4605-b359-f7dc8b2095a6"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,509,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13933:5633,validat,validation,5633,https://hail.is,https://github.com/hail-is/hail/pull/13933,3,"['Access', 'access', 'validat']","['Access', 'access-control', 'validation']"
Security,"Large trees of union_cols have to concatenate entries arrays pairwise, creating a lot of junk in memory. A `MatrixMultiWayUnionCols` IR node should be straightforward to lower to `TableMultiWayZipJoin`, such that concatenating the entries arrays is completely deforested. We could then optimize nested `MatrixUnionCols` to a single `MatrixMultiWayUnionCols`, and/or expose a `multi_way_union_cols` method in python. https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/how.20does.20union_cols.20work/near/165089884",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6066:366,expose,expose,366,https://hail.is,https://github.com/hail-is/hail/issues/6066,1,['expose'],['expose']
Security,Let's expose this. The peak memory usage on a region pool is between `allocationEchoThreshold / 2` and `allocationEchoThreshold`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10233#issuecomment-812071559:6,expose,expose,6,https://hail.is,https://github.com/hail-is/hail/pull/10233#issuecomment-812071559,1,['expose'],['expose']
Security,"Let's keep a list of things that need to be exposed in FilterOptions with high priority. From a chat yesterday with Andrea about info.ANN fields, we need string splitting. I've gone ahead and added this, but we should continue to iterate and keep a list open",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/121:44,expose,exposed,44,https://hail.is,https://github.com/hail-is/hail/issues/121,1,['expose'],['exposed']
Security,"Load VCF PP as Hail PL. Load GT and GQ normally, but for the purpose of input validation, interpret them with respect to PP rather than PL.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/349:78,validat,validation,78,https://hail.is,https://github.com/hail-is/hail/issues/349,1,['validat'],['validation']
Security,"LocalMatrix follows NumPy's broadcast rules (restricted to two-dimensional ndarrays), and I've tried to mirror the Numpy interface for all functions where it's reasonable to do so. I still need time to add a bunch of Python tests of the interface, but I'd be glad for feedback/review in the meantime. In a subsequent PR, I'll expose the rest of BlockMatrix's binary ops in Python with the similar syntax and rules. These changes will provide the matrix functionality needed for a clean mixed models pipeline (modulo a few Scala black boxes that I can return to once I have something working) and will hopefully be generally useful for adding/porting more methods in Python. Current longer-term plan is to expose RowMatrix as well, and consider how to best unify the interfaces. And one day LocalMatrix will actually be a NumPy array...",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3064:326,expose,expose,326,https://hail.is,https://github.com/hail-is/hail/pull/3064,2,['expose'],['expose']
Security,"Looking at the `…/Packages` URL in the previous comment, 1.2.0 is now available (and 1.1.0 does not appear to be there). In our recent local hail update deployment, the `batch_worker_image` job failed repeatedly due to GoogleCloudPlatform/gcsfuse#1424. We worked around this as initially suggested on that issue with populationgenomics/hail@607408bee752dabca48d9a2732b14d32813ace9f, but later comments on the issue suggest that the better approach would be this PR with an additional change to access the apt repo via https:. ```diff; - echo ""deb http://packages.cloud.google.com/apt $GCSFUSE_REPO main"" | tee /etc/apt/sources.list.d/gcsfuse.list && \; + echo ""deb https://packages.cloud.google.com/apt $GCSFUSE_REPO main"" | tee /etc/apt/sources.list.d/gcsfuse.list && \; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13728#issuecomment-1763644502:494,access,access,494,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1763644502,1,['access'],['access']
Security,Looks like this has been removed: https://registry.terraform.io/providers/hashicorp/kubernetes/latest/docs/guides/v2-upgrade-guide#changes-in-v200. #assign services,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11698:74,hash,hashicorp,74,https://hail.is,https://github.com/hail-is/hail/pull/11698,1,['hash'],['hashicorp']
Security,Lowercase characters and no github password request in release script,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7536:35,password,password,35,https://hail.is,https://github.com/hail-is/hail/pull/7536,1,['password'],['password']
Security,"Made a more robust authentication library. One outstanding issue due to auth0js library, that we can solve by checking for and clearing wildcard auth0-prefixed cookies and startup, but this may have side-effects. Created an issue to track:; https://github.com/auth0/auth0.js/issues/897",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162#issuecomment-455907662:19,authenticat,authentication,19,https://hail.is,https://github.com/hail-is/hail/pull/5162#issuecomment-455907662,1,['authenticat'],['authentication']
Security,"Made changes to clean up/add to the documentation for the datasets API and annotation DB. Changes to documentation:. - Moved raw html in `annotation_database_ui.rst` into `hail/python/hail/docs/_static/annotationdb/annotationdb.html`.; - Added html table to bottom of datasets doc page to show all available datasets, similar to what is currently on annotation DB doc page. Added relevant files to `hail/python/hail/docs/_static/datasets`.; - Moved schemas currently on datasets doc page to their own page. Datasets doc page links to this new page.; - Moved some minor styling from html files to `annotationdb.css`, and cleaned up formatting of html.; - Added doc page for the `DB` class, referenced on the Python API doc page for the experimental module. Only exposes the `available_datasets` attribute and `annotate_rows_db` method, as I didn't think most users need to see any internal methods or the `Dataset` and `DatasetVersion` classes/methods. Most of diff is just formatting changes to `db.py` and `datasets.py` for consistency/readability that did not change functionality. Also added docstrings to methods in `db.py` that were missing them. Added a check in `DB` constructor to make sure the cloud and region combination is valid. To prevent an empty annotation DB instance from being created if user specifies `db = hl.experimental.DB(region='eu', cloud='aws')`, since we don't have an EU bucket on AWS.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9663:761,expose,exposes,761,https://hail.is,https://github.com/hail-is/hail/pull/9663,1,['expose'],['exposes']
Security,Made relevant field and function names pythonic and consistent along the way. I've ported the TDT python implementation and test quite literally. The implementation should use sum on arrays but isn't yet properly exposed in api2. I'm confused why -1 is used as a ploidy but will leave further improvements for later.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2768:213,expose,exposed,213,https://hail.is,https://github.com/hail-is/hail/pull/2768,1,['expose'],['exposed']
Security,"Made types final. @tpoterba I think you should rebase GenotypeView on this and use the new accessors there. We shouldn't be trying to optimize the traversal of types or the field access code now. The way to optimize these things is to make the types compile-time objects (as they should be) and these accessors will become code generators that turn lookups into things like `byteOffsets` into a compile-time constant. At some point I think we should go ""full unsafe"" by using off-heap allocation and change the (region, offset) pair into a Long. However, this makes error checking harder. I'll think about when to do that. I still think getting rid of the triple in VSM is the right next step.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2093:91,access,accessors,91,https://hail.is,https://github.com/hail-is/hail/pull/2093,3,['access'],"['access', 'accessors']"
Security,"Main change: add `var mark: Int` to `BaseIR`.; On profiling the benchmark `matrix_multi_write_nothing`, I noticed a significant amount of time was spent ; - iterating through zipped arrays in requiredness ; - Adding and removing elements from `HashSet`s.; In fact, half the time spent in requiredness was removing ir nodes from the `HashSet` set used as the queue! With this change, requiredness runs like a stabbed rat!. Explanation of `mark`:; This field acts as a flag that analyses can set. For example:; - `HasSharing` can use the field to see if it has visited a node before.; - `Requiredness` uses this field to tell if a node is currently enqueued. The `nextFlag` method in `IrMetadata` allows for analyses to get a fresh value they can set the `mark` field. ; This removes the need to traverse the IR after analyses to re-zero every `mark` field.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13991:244,Hash,HashSet,244,https://hail.is,https://github.com/hail-is/hail/pull/13991,2,['Hash'],['HashSet']
Security,Make a safer implementation of this transformation. The best solution is probably a hash.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5377:84,hash,hash,84,https://hail.is,https://github.com/hail-is/hail/issues/5377,1,['hash'],['hash']
Security,"Matrix can be promoted to a KeyedBlockMatrix even if it's dimensions exceed Int.MaxValue; the simple rule is that you can't set keys on a dimension that is too large. This is convenient if you have a matrix where one dimension is huge but you still want keys on the other dimension. Checking keys helps ensure correctness, and I think the ability to set/drop keys on keyed matrices should be useful for linear algebra where a matrix operand comes un-keyed or you don't care about the keys on that operand. This key persistence is also natural when thinking about operations that add (unkeyed) scalars or vectors to keyed matrices (We'd later add optionally-keyed vectors as well, where keys are checked in vector addition, matrix/vector mult, vectorAddToEveryRow, etc). Keys are stored and checked on master, so for large dimensions users may want to rekey with simpler keys, via a map on the python side or with just indices. For simplicity, and since there's basically no additional overhead using an unkeyed KeyedBlockMatrix versus its underlying BlockMatrix, I think we should consider only having (optionally) keyed matrices exposed on the Python side (so a Python BlockMatrix is a Scala KeyedBlockMatrix, and you can do linear algebra numpy-style by just having no keys set). I plan to add writeKeyedBlockMatrix to MatrixTable in next step, with parameters to on whether to retain the keys (e.g., key_rows = true). On the Python side, this could then replace write_block_matrix rather than being in addition to it. Later, LocalMatrix and RowMatrix would follow the same pattern of optionally keyed versions in Scala, with a common Matrix and KeyedMatrix abstraction. And in Python users would just have Matrix backed by KeyedMatrix on the Scala side. PS. In the filters, I switched to names keepRows and keepCols in KeyedBlockMatrix instead of rowsToKeep and colsToKeep, so the changes in BlockMatrix and BlockMatrixSuite are just renaming for consistency (as well as removing one unused line).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2718:1634,expose,exposed,1634,https://hail.is,https://github.com/hail-is/hail/pull/2718,1,['expose'],['exposed']
Security,Method.java:498); 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:105); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:464); 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:237); 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:14714,secur,security,14714,https://hail.is,https://github.com/hail-is/hail/issues/12982,3,['secur'],['security']
Security,"Minrep (in split multi) throwing:; ```; hail.utils.java.FatalError: HailException: invalid allele ""GN"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 9 in stage 10.0 failed 20 times, most recent failure: Lost task 9.19 in stage 10.0 (TID 1997, exomes-w-1.c.broad-mpg-gnomad.internal, executor 15): is.hail.utils.HailException: invalid allele ""GN""; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); 	at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:28); 	at is.hail.variant.AltAlleleMethods$.isStar(AltAlleleMethods.scala:73); 	at is.hail.variant.VariantMethods$$anonfun$minRep$1.apply(VariantMethods.scala:43); 	at is.hail.variant.VariantMethods$$anonfun$minRep$1.apply(VariantMethods.scala:43); 	at scala.collection.IndexedSeqOptimized$class.prefixLengthImpl(IndexedSeqOptimized.scala:38); 	at scala.collection.IndexedSeqOptimized$class.forall(IndexedSeqOptimized.scala:43); 	at scala.collection.mutable.WrappedArray.forall(WrappedArray.scala:35); 	at is.hail.variant.VariantMethods$.minRep(VariantMethods.scala:43); 	at is.hail.methods.SplitMultiPartitionContext$$anonfun$2.apply(SplitMulti.scala:196); 	at is.hail.methods.SplitMultiPartitionContext$$anonfun$2.apply(SplitMulti.scala:192); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.Tra",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3480:551,validat,validate,551,https://hail.is,https://github.com/hail-is/hail/issues/3480,1,['validat'],['validate']
Security,"Moreover, the deploy jobs keep trying to access things in the batch-pods namespace, but the things they need to deploy are in the regular batch namespace.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4592#issuecomment-431594049:41,access,access,41,https://hail.is,https://github.com/hail-is/hail/issues/4592#issuecomment-431594049,1,['access'],['access']
Security,"Most of the technical details of how our authentication/authorization works is in the linked RFCs, but I thought there should be a brief overview of just how to think about identity across the system and a place that links to the deeper details.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14606:41,authenticat,authentication,41,https://hail.is,https://github.com/hail-is/hail/pull/14606,2,"['authenticat', 'authoriz']","['authentication', 'authorization']"
Security,"Mostly small, straightforward stuff. /auth must only return 2xx, 401 or 403, or nginx returns 500. Redirect auth failures connecting to instance to /error, too. Changed ""Create/Open Notebook"" to ""Launch/Open Jupyter"" and associated language throughout. I'll run through the whole test playbook again after these go in. Note to self, some improvements to consider:; - Validate image, memory, cpu values in workshop-admin. Right now, if you enter invalid values, you get a 500 on launch Jupyter with invalid pod spec.; - Could change notebook.hail.is/notebook URL to notebook.hail.is/jupyter now.; - A background loop to kill any notebook workers associated to inactive workshops. Then if you just inactivate the workshop at the end, everything gets cleaned up.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7162:367,Validat,Validate,367,https://hail.is,https://github.com/hail-is/hail/pull/7162,1,['Validat'],['Validate']
Security,"Move full time test suite into python, audit coverage",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7806:39,audit,audit,39,https://hail.is,https://github.com/hail-is/hail/issues/7806,1,['audit'],['audit']
Security,Much OOM. Related to #2108?. ```; Java stack trace:; java.lang.OutOfMemoryError: Java heap space; 	at java.util.HashMap.resize(HashMap.java:703); 	at java.util.HashMap.putVal(HashMap.java:662); 	at java.util.HashMap.put(HashMap.java:611); 	at htsjdk.variant.vcf.VCFHeader.buildVCFReaderMaps(VCFHeader.java:164); 	at htsjdk.variant.vcf.VCFHeader.<init>(VCFHeader.java:146); 	at htsjdk.variant.vcf.VCFStandardHeaderLines.repairStandardHeaderLines(VCFStandardHeaderLines.java:75); 	at htsjdk.variant.vcf.AbstractVCFCodec.parseHeaderFromLines(AbstractVCFCodec.java:223); 	at htsjdk.variant.vcf.VCFCodec.readActualHeader(VCFCodec.java:111); 	at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:83); 	at is.hail.io.vcf.LoadVCF$.parseHeader(LoadVCF.scala:162); 	at is.hail.io.vcf.LoadVCF$$anonfun$4.apply(LoadVCF.scala:205); 	at is.hail.io.vcf.LoadVCF$$anonfun$4.apply(LoadVCF.scala:205); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.io.vcf.LoadVCF$.apply(LoadVCF.scala:205); 	at is.hail.HailContext.importVCFsGeneric(HailContext.scala:528); 	at is.hail.HailContext.importVCFs(HailContext.scala:484); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2136:112,Hash,HashMap,112,https://hail.is,https://github.com/hail-is/hail/issues/2136,6,['Hash'],['HashMap']
Security,"My first approach was to populate an error.html template and return that. I could get the title to be ""Error"", but none of the content was showing up. I couldn't figure out why, so I switched to raising HTTPErrorFound with the traceback message. This works fine, but it won't work if we need the decorator above the authentication decorators. This decorator has to be the furthest down the call stack.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10503:316,authenticat,authentication,316,https://hail.is,https://github.com/hail-is/hail/pull/10503,1,['authenticat'],['authentication']
Security,"My guess is the launched pod is the one accessing the secret, with its service account. You could check this by removing the user can read secret binding and try launching a pod.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5753#issuecomment-479298393:40,access,accessing,40,https://hail.is,https://github.com/hail-is/hail/pull/5753#issuecomment-479298393,1,['access'],['accessing']
Security,"My motivation here is that in Terra we aren't going to be using hail authentication tokens, rather an authentication from gcloud or az. So I want our batch client to be able to use a `CloudCredentials` just as easily as it uses the hail auth token that we store on the user's machine. So I introduce HailCredentials which subclasses CloudCredentials but the behavior is the same. It also lets us re-use some of the retry logic that we have baked into `aiocloud.common.Session`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12642:69,authenticat,authentication,69,https://hail.is,https://github.com/hail-is/hail/pull/12642,2,['authenticat'],['authentication']
Security,"My team is pretty excited about hail being released with support for Spark 3.5. One thing I noticed is that it looks like the plan is to [restrict to Spark 3.5.0](https://github.com/hail-is/hail/pull/14158/files#diff-7e9fff5f09cc109665f7fe9baa107affaac24f5dc5a0aa8bc3769221a4c6c328R53) - would it be possible to allow some wiggle room for minor releases? Spark has been beginning to release upgrades much more often than in the past, so restricting to 3.5.0 will prevent access to bug fixes, feature enhancements, etc.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14158#issuecomment-1900997582:471,access,access,471,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1900997582,1,['access'],['access']
Security,"NB, this is a stacked PR. To see just these changes see [this commit](https://github.com/hail-is/hail/pull/12883/commits/ae51e0a9af12e4c89a44e7ce3235f3f665ff4830). ---. [VPC Flow Logs](https://cloud.google.com/vpc/docs/flow-logs):. > VPC Flow Logs records a sample of network flows sent from and received by VM instances, including; > instances used as Google Kubernetes Engine nodes. These logs can be used for network monitoring,; > forensics, real-time security analysis, and expense optimization. I found the collection process the most elucidating part of the documentation. My summary of that; process follows:. 1. Packets are sampled on the network interface of a VM. Google claims an average sampling rate of; 1/30. This rate reduces if the VM is under load. This rate is immutable to us. 2. Within an ""aggregation interval"", packets are aggregated into ""records"" which are keyed (my term); by source & destination. There are currently six choices for aggregation interval: 5s, 30s, 1m,; 5m, 10m, and 15m. 3. Records are sampled. The sampling rate is a user configured floating point number (precision; unclear) between 0 and 1. 4. Metadata is optionally added to the records. The metadata captures information about the source; and destination VM such as project id, VM name, zone, region, GKE pod, GKE service, and geographic; information of external parties. The user may elect to receive all metadata, no metadata, or a; specific set of metadata fields. 5. The records are written to Google Cloud Logging. The pricing of VPC Flow Logs is described at the [network pricing page](https://cloud.google.com/vpc/network-pricing#network-telemetry). Notice that, if logs are only sent to Cloud Logging (not to BigQuery, Pub/Sub, or Cloud Storage):. > If you store your logs in Cloud Logging, logs generation charges are waived, and only Logging charges apply. I believe in this phrase ""logs generation charges"" refers to *VPC Flow logs* generation charges. The Google Cloud Logging [pricing page]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12883:456,secur,security,456,https://hail.is,https://github.com/hail-is/hail/pull/12883,1,['secur'],['security']
Security,"New new failure mode:. AccessDeniedException: 403 hail-ci-0-1@broad-ctsa.iam.gserviceaccount.com does not have storage.objects.list access to hail-ci-test. Failing here in test-ci.py:. ```; deploy_artifact = run(['gsutil', 'cat', f'gs://hail-ci-test/{second_target_sha}'], stdout=subprocess.PIPE); deploy_artifact = deploy_artifact.stdout.decode('utf-8').strip(); assert f'commit {second_target_sha}' in deploy_artifact; ```. I don't know who's authorizing gcloud for hail-ci-0-1. Anyway, I gave hail-ci-0-1 permissions on hail-ci-test and am re-running.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4509#issuecomment-429196114:23,Access,AccessDeniedException,23,https://hail.is,https://github.com/hail-is/hail/pull/4509#issuecomment-429196114,3,"['Access', 'access', 'authoriz']","['AccessDeniedException', 'access', 'authorizing']"
Security,"New test failure:. ```; + ./gradlew shadowJar archiveZip; Exception in thread ""main"" javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:192); ```; Still not sure what to do about transient external dependency failures in the tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4536#issuecomment-429360417:171,secur,security,171,https://hail.is,https://github.com/hail-is/hail/pull/4536#issuecomment-429360417,1,['secur'],['security']
Security,Next steps seem to be:; - [ ] try master SKAT in a debian docker image (i.e. is this a *nix issue?); - [ ] find a hash that SKAT succeeds in the cloud,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5565#issuecomment-472066037:114,hash,hash,114,https://hail.is,https://github.com/hail-is/hail/issues/5565#issuecomment-472066037,1,['hash'],['hash']
Security,"No, only step 1 up there has been completed. We currently accept both the old and new authentication tokens. We need to decide what kind of deprecation approach is appropriate here and then do it. Also as it currently stands copy-paste tokens require the old-style of authentication (I think because of an implementation detail that internally these tokens reference `session_id`s instead of users), so those either need to be migrated to be compatible with a user not having any `session_id`s in the database or removed entirely. A useful bit of context though, the only thing users need to do to get off the old tokens is `hailctl auth login` on a hail version with the changes in #13131.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13531#issuecomment-1766798562:86,authenticat,authentication,86,https://hail.is,https://github.com/hail-is/hail/issues/13531#issuecomment-1766798562,2,['authenticat'],['authentication']
Security,"Non-daemon threads [keep a JVM alive](https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.html):. > When a Java Virtual Machine starts up, there is usually a single non-daemon thread (which typically calls the method named main of some designated class). The Java Virtual Machine continues to execute threads until either of the following occurs:; >; > The exit method of class Runtime has been called and the security manager has permitted the exit operation to take place.; >; > All threads that are not daemon threads have died, either by returning from the call to the run method or by throwing an exception that propagates beyond the run method. Spark appears to wait for the JVM to terminate before it considers a job complete.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13916:417,secur,security,417,https://hail.is,https://github.com/hail-is/hail/pull/13916,1,['secur'],['security']
Security,"Not quite sure why this was re-marked WIP. Anyway, switching to AR meant users lost access to `gcr.io/hail-vdc/python-dill` anyway so this PR is no longer the source of a breaking change and now a fix so that users can use `hailgenetics/python-dill`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12230#issuecomment-1265436386:84,access,access,84,https://hail.is,https://github.com/hail-is/hail/pull/12230#issuecomment-1265436386,1,['access'],['access']
Security,"Not sure how this affects the Python interface, but it seems to be working via sparklyr. It generalizes `ArrayList` to `List` and `HashMap` to `Map` in every place I could find. Fixes #5340.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5485:131,Hash,HashMap,131,https://hail.is,https://github.com/hail-is/hail/pull/5485,1,['Hash'],['HashMap']
Security,"Not sure why crossorigin is necessary to make authenticated imports work, but it works. No information at MDN: https://developer.mozilla.org/en-US/docs/Web/HTML/Element/script. https://internal.hail.is/dking/site/ demonstrates this working.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8928:46,authenticat,authenticated,46,https://hail.is,https://github.com/hail-is/hail/pull/8928,1,['authenticat'],['authenticated']
Security,"Not yet deployed by default. Builds Jupyter image that runs against apiserver by default. This will be used by the notebook service to spin up a demo notebook. The make target `run-hail-jupyter-pod` launches a single pod running the image by hand. Image includes Hadoop Google Storage connector. Deployment mounts a secret with a service account key to access files which can access the bucket gs://haas-scratch. This completes the backend work for the Feb 5 data meeting demo. Round trip for a trivial job is about 80ms. From the Jupyter notebook running agains the apiserver:. ```; %%time; hl.utils.range_matrix_table(346, 100).count(); CPU times: user 20.6 ms, sys: 5.17 ms, total: 25.8 ms; Wall time: 81.2 ms; ```. For a job that hits Spark, around 300ms:. ```; mt = hl.utils.range_matrix_table(346, 100); mt = mt.annotate_rows(x = mt.row_idx*mt.row_idx); t = mt.rows(). %%time; t.aggregate(hl.agg.sum(t.x)); CPU times: user 12.6 ms, sys: 1.21 ms, total: 13.8 ms; Wall time: 304 ms; 13747445; ```. Things that hit Google storage are noticeably slower:. ```; %%time; mt = hl.read_matrix_table('gs://haas-scratch/sample.mt'); mt.aggregate_rows(hl.agg.sum(hl.len(mt.alleles))); CPU times: user 28.3 ms, sys: 2.63 ms, total: 30.9 ms; Wall time: 1.58 s; ```. I think we can speed this up by caching read IR. Also, the RVD metadata is stored in a separate file, so executing the read requires an additional read besides reading the actual data file. We might want to rethink our directory layout.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5213:353,access,access,353,https://hail.is,https://github.com/hail-is/hail/pull/5213,2,['access'],['access']
Security,"Note this PR replaces the previous [Feature/sas token merge](https://github.com/hail-is/hail/pull/12877) because the original PR branch got jacked up beyond repair. All the comments on the earlier PR are responded to there and addressed in the code for this one. This PR is to enable `hail-az/https` Azure file references to contain SAS tokens to enable bearer-auth style file access to Azure storage. Basic summary of the changes:; - Update `AzureAsyncFS` url parsing function to look for and separate out a SAS-token-like query string. Note: made fairly specific to SAS tokens - generic detection of query string syntax interferes with glob support and '?' characters in file names; - Added `generate_sas_token` convenience function to `AzureAsyncFS`. Adds new azure-mgmt-storage package requirement.; - Updated `AzureAsyncFS` to use `(account, container, credential)` tuple as internal `BlobServiceClient` cache key; - Updated `AzureAsyncFSURL` and `AzureFileListEntry` to track the token separately from the name, and extend the base classes to allow returning url with or without a token; - Update `RouterFS.ls` function and associated listfiles function to allow for trailing query strings during path traversal; - Update `AsyncFS.open_from` function to handle query-string urls in zero-length case; - Change to existing behavior: `LocalAsyncFSURL.__str__` no longer returns 'file:' prefix. Done to make `str()` output be appropriate for input to `fs` functions across all subclasses; - Updated `InputResource` to not include the SAS token as part of the destination file name; - Updated `inter_cloud/test_fs.py` to generically use query-string-friendly file path building functions to respect the new model, where it is no longer safe to extend URLs by just appending new segments with `+ ""/""` because there may be a query string, and added `'sas/azure-https'` test case to the fixture. Running tests for the SAS case requires some new test variables to allow the test code to generate SAS toke",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13140:377,access,access,377,https://hail.is,https://github.com/hail-is/hail/pull/13140,1,['access'],['access']
Security,Note to self that the audit should test for equality here.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12761#issuecomment-1458597618:22,audit,audit,22,https://hail.is,https://github.com/hail-is/hail/pull/12761#issuecomment-1458597618,1,['audit'],['audit']
Security,Notebook2 access token,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5448:10,access,access,10,https://hail.is,https://github.com/hail-is/hail/pull/5448,1,['access'],['access']
Security,"Noticed these during other work. - For `local_to_global`, we already check for number being `A`, `G`, or `R` in typecheck, and it's not good python style to have an else clause after a return. ; - For `lgt_to_gt`, the case type matching is cleaner than the explicit conversion methods. ## Security Assessment. - This change has no security impact. ### Impact Description; Query only changes that have identical functionality to previous code",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14740:289,Secur,Security,289,https://hail.is,https://github.com/hail-is/hail/pull/14740,2,"['Secur', 'secur']","['Security', 'security']"
Security,"Now that user emails are granted read/write access, lets expose the link. Also removes the errant span.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6184:44,access,access,44,https://hail.is,https://github.com/hail-is/hail/pull/6184,2,"['access', 'expose']","['access', 'expose']"
Security,"OK, I figured out what was happening. The problem wasn't with cerberus (although I'm happy to with my change), it is that json.dump always converts a dictionary key into a string. I had with a key None, and it got turned into the string 'null' in json, because json object values must string keys:. ```; >>> import json; >>> d = {None: 5, 'foo': None}; >>> json.loads(json.dumps(d)); {'null': 5, 'foo': None}; ```. I remove the broken test. Note, I pushed two more changes that probably need a proper review:; - moved jobs validation to batch (from batch_client), I'd been meaning to do that,; - and I wrote the batch validator explicit in the style of the jobs validator (I'd be meaning to do that, too).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7915#issuecomment-575944836:523,validat,validation,523,https://hail.is,https://github.com/hail-is/hail/pull/7915#issuecomment-575944836,3,['validat'],"['validation', 'validator']"
Security,"OK, I gave you maximum spicy. I don't think it's so bad, but let me know if you want me to cut it up. Some remarks:; - This PR successfully tests (and it passes!) and then cleans up this branch: https://github.com/hail-is/hail/pull/5842. See `build.yaml`. It's a thing of beauty (I think).; - That branch has everything but Scala tests and dataproc/cloudtools tests. The latter are easy, the former are a little messy since I want to test against a test jar, and I've decided to switch to maven for that.; - No support for publish or deploy yet.; - There are synchronous calls it `git` in various places which can make the UI sluggish. I'll fix those in another PR.; - Work remains to validate build.yaml and the deploy step yaml.; - I currently run jinja2 if the file (Dockerfile or deployment yaml) ends in `.in`, but I think I'm going to make it unconditional. `.in` just seem error prone.; - In CreateDatabaseStep, I put secret credentials in the pod configuration. That's not ideal, but I don't think it is a serious problem, because nobody who isn't privileged can read the pods, and I can fix it in a later PR (the create database step should generate the passwords, not ci2).; - I disabled the fixme pylint message (on # FIXME comments), since are fixmes are longer lived than a single change sometimes.; - I'm slightly confused about runImage (which generates a batch job) and deploy of a pod spec (which runs kubectl apply as a batch job). Right now, runImage always runs in batch-pods, and a deploy job runs in whatever namespace you specify. Fixes https://github.com/hail-is/hail/issues/5903",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5891:685,validat,validate,685,https://hail.is,https://github.com/hail-is/hail/pull/5891,2,"['password', 'validat']","['passwords', 'validate']"
Security,"OK, I think this is actually ready for a real review. Almost everything was spurious (I marked as such, so hopefully we won't have to do that on every PR). There were a few real things:; 1. use integrity checks for CDN javascript libraries; 2. don't let edits to the search textbox modify the URL arbitrarily; 3. don't let the target pages of anchor tags mutate the source page's DOM (wtf, how is this the default behavior???); 4. don't send the IntegrityError from mysql back to the users. I think this is basically safe because of how restrictive we are with which error is printed, but it's also not necessary.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12269#issuecomment-1268879860:194,integrity,integrity,194,https://hail.is,https://github.com/hail-is/hail/pull/12269#issuecomment-1268879860,2,"['Integrity', 'integrity']","['IntegrityError', 'integrity']"
Security,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787:425,secur,security,425,https://hail.is,https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787,510,['secur'],['security']
Security,"OK, code is stable again, scale tests are working. Run with:. ```; ~/hail/notebook $ PYTHONPATH=../hail/python:../gear python3 scale-test.py 10 <workshop> <password>; ```. ```; successes: 10 / 10 = 1.0; mean time: 2.3504347085952757; max time: 3.135228157043457; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7112#issuecomment-534603185:156,password,password,156,https://hail.is,https://github.com/hail-is/hail/pull/7112#issuecomment-534603185,1,['password'],['password']
Security,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:1715,hash,hash,1715,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385,1,['hash'],['hash']
Security,"OK, so that was way more pain than I expected. Apparently when you're importing a JS module which needs authentication, you must specify the `crossorigin` attribute to the `script` tag. If you lack that attribute, no headers are sent. Since dev deploys are limited to developer access only (even though there is no in-dev-namespace authentication), this obviously doesn't work. Why does the word `crossorigin` mean send headers to the same origin? Who knows! Anyway. I don't think that bug should block this PR. That bug is an underlying issue with dev deploy. The fix for the module import bug is here: https://github.com/hail-is/hail/pull/8928",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8923#issuecomment-639135078:104,authenticat,authentication,104,https://hail.is,https://github.com/hail-is/hail/pull/8923#issuecomment-639135078,3,"['access', 'authenticat']","['access', 'authentication']"
Security,"OK, so the big insight is that ""InstanceConfig"" is really just ""ResourcesForAParticularInstance"" (well, and, sometimes, ""ResourcesOfARepresentativeInstance""). I trimmed the InstanceConfig down *significantly* removing the ""vm_config"". Now the InstanceConfig is cheap and easy to create and there's no circularity between vm_config and instance config. I pushed that through everywhere and then abstracted the common create_instance logic for pool and job-private into InstanceCollection. With both of those changes, I was able to modify the ResourceManager's API to expose methods for constructing instance configs. However, the instance config isn't critical to the operation of the ResourceManager. It's just an interface for communicating an instance's resources to the rest of the code base.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10920#issuecomment-956500279:566,expose,expose,566,https://hail.is,https://github.com/hail-is/hail/pull/10920#issuecomment-956500279,1,['expose'],['expose']
Security,"OK, so the current solution addresses the problem, but:; - if MathJax changes the vertical layout of the page, we might have scrolled too far or not far enough to have the anchor located just below the header; - if we navigate to a new URL using any means other than clicking on an anchor tag, our history will have the URL with the special hash",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7334#issuecomment-544684545:341,hash,hash,341,https://hail.is,https://github.com/hail-is/hail/pull/7334#issuecomment-544684545,1,['hash'],['hash']
Security,"OK, so, this really feels like bad data. We just merged https://github.com/hail-is/hail/commit/98adcce1d07001995b0819fd6afe161bf34ba840 which fixed https://github.com/hail-is/hail/issues/13979 . Google Cloud Storage's Java library was very rarely returning just flat-out bad data. The frequency of occurrence on one particularly large pipeline appears to be 1/30000 tasks (0.003% or 3 in 100,000). The tasks were reading two files, the larger of which was 131MiB. The Java library reads in 8MiB chunks so that's at least 17 network requests per partition. That puts the frequency of this closer to 1 in 1,000,000 requests or 1 in 10TiB of data read. Before we had Zstandard, it seems that this data corruption either (a) was unnoticed (b) caused a rare decoding error or (c) caused segfaults. After we added Zstandard (0.2.119), decompression often failed due to corrupt data. It seems to me that Zstandard more aggressively verifies integrity than LZ4 does. OK, so, when was this bug introduced in Hail? As far as I can tell, this new code path was added in google-cloud-storage 2.17.0 almost one year ago: https://github.com/googleapis/java-storage/commit/94cd2887f22f6d1bb82f9929b388c27c63353d77 . We upgraded to 2.17.1 (😭 ) in Hail 0.2.109 https://github.com/hail-is/hail/commit/fec0cc2263c04c00e02cef5dda8ec46916717152 . All of the attempts above could have been plagued by this rare transient data corruption error. OK, action items:. - [ ] Ask Cal and Lindo to try their pipelines again with the next release of Hail 0.2.127.; - [x] Hail must introduce large-scale testing before releases. We, sadly, cannot assume our underlying storage libraries are reliable. https://github.com/hail-is/hail/issues/14082. Once the first action item is successfully completed, I will close this issue. For the second action item, I have created a separate ticket.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114:934,integrity,integrity,934,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114,1,['integrity'],['integrity']
Security,"OK, so. - 401 unauthorized when you don't have a valid oauth2 token; - set env var in notebook indicating hail token location (we can't mount to user's home dir because we do not know which user name the image will run as); - rebased. @akotlar we seem to be down to one key difference of opinion:. > The less information reveled the better: as you mentioned, do you want foreign agents who don't already know of your endpoint to learn that you serve it? I'd argue that your API is made public through documentation and web links, not through your error code. The people who don't read those shouldn't have an easier time learning of them. agree: api is in GH, ergo public, so only point of contention is:. > The less information reveled the better: as you mentioned, do you want foreign agents who don't already know of your endpoint to learn that you serve it? ... The people who don't read those shouldn't have an easier time learning of them. Point: its not just foreign agents but anyone who hits the API, including us making mistakes, ergo, I reformulate:. > ... do you want [someone] who [forgot about or is unaware] of your endpoint to learn that you serve it? ... The people who don't read those shouldn't have an easier time learning of them. Yes, because I know I will make mistakes (and users will make config mistakes) and I want an easily debuggable system. The risk is that an attacker may learn `/jobs` exists. If that knowledge substantially improves an attacker's ability to infiltrate batch, then we've made a severe error in securing batch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5844#issuecomment-483791146:1391,attack,attacker,1391,https://hail.is,https://github.com/hail-is/hail/pull/5844#issuecomment-483791146,3,"['attack', 'secur']","['attacker', 'securing']"
Security,"OK, the story is more complicated than I imagined. uniroot was added in post-0.1 devel and made available in the expression language. It hasn't been exposed in the Python interface, but I don't know why. It is straightforward now, but I don't think the IR story has been sorted out yet. I'm going to reopen until it is available in Python.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1717#issuecomment-388854826:149,expose,exposed,149,https://hail.is,https://github.com/hail-is/hail/issues/1717#issuecomment-388854826,1,['expose'],['exposed']
Security,"OS]: different functions, especially <code>Process.open_files()</code>_ and; <code>Process.connections()</code><em>, could randomly raise <code>AccessDenied</code></em> because the; internal buffer of <code>proc_pidinfo(PROC_PIDLISTFDS)</code> syscall was not big enough.; We now dynamically increase the buffer size until it's big enough instead of; giving up and raising <code>AccessDenied</code>_, which was a fallback to avoid crashing.</li>; <li>1904_, [Windows]: <code>OpenProcess</code> fails with <code>ERROR_SUCCESS</code> due to; <code>GetLastError()</code> called after <code>sprintf()</code>. (patch by alxchk)</li>; <li>1913_, [Linux]: <code>wait_procs()</code>_ should catch <code>subprocess.TimeoutExpired</code>; exception.</li>; <li>1919_, [Linux]: <code>sensors_battery()</code>_ can raise <code>TypeError</code> on PureOS.</li>; <li>1921_, [Windows]: <code>swap_memory()</code>_ shows committed memory instead of swap.</li>; <li>1940_, [Linux]: psutil does not handle <code>ENAMETOOLONG</code> when accessing process; file descriptors in procfs. (patch by Nikita Radchenko)</li>; <li>1948_, <strong>[critical]</strong>: <code>memoize_when_activated</code> decorator is not thread-safe.; (patch by Xuehai Pan)</li>; <li>1953_, [Windows], <strong>[critical]</strong>: <code>disk_partitions()</code>_ crashes due to; insufficient buffer len. (patch by MaWe2019)</li>; <li>1965_, [Windows], <strong>[critical]</strong>: fix &quot;Fatal Python error: deallocating None&quot;; when calling <code>users()</code>_ multiple times.</li>; <li>1980_, [Windows]: 32bit / WoW64 processes fails to read <code>Process.name()</code>_ longer</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/giampaolo/psutil/commit/f1a54ad88527e0706fb8a88ad7daae80686acc62""><code>f1a54ad</code></a> pre-release</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/d81e75e94a1dd2b8d64caa0e7",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11459:3010,access,accessing,3010,https://hail.is,https://github.com/hail-is/hail/pull/11459,1,['access'],['accessing']
Security,"Obviously, look forward to feedback on the UI and let me know if you run into any UI bugs. Another todo that I've started:; - write a UI testing playbook to enumerate all the UI interactions we want to test (by hand) to validate this code.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7112#issuecomment-534267706:220,validat,validate,220,https://hail.is,https://github.com/hail-is/hail/pull/7112#issuecomment-534267706,1,['validat'],['validate']
Security,"Oh, and the app is meant to operate behind HTTPS; when deployed, running the web app with ; `npm run start` instead of `npm run prod-test` will enable secureOnly cookies.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-454272121:151,secur,secureOnly,151,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-454272121,1,['secur'],['secureOnly']
Security,"Ok, figured out why Dan's image wasn't wholly working; the auth_request works, but then there are series of other requests, which lose the access_token. Will figure this out; Ideally once the initial authorization is made, requests for the nth css file don't require it. I've also enabled ssl for app.hail.is, and notebook-api.hail.is, so any issues due to crossing https to http (and vice versa boundaries), won't crop up (if they didn't exist in an existing implementation, since all existing hail services are behind ssl).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5243#issuecomment-460094726:200,authoriz,authorization,200,https://hail.is,https://github.com/hail-is/hail/pull/5243#issuecomment-460094726,1,['authoriz'],['authorization']
Security,"One final comment, the goal here was separate the normal user notebook flow from the workshop guest notebook flow, while sharing the main logic without impacting logic outside notebook. I think that was largely successful. I think the only impact outside was to layout.html in web_common, it checks a `workshop` variable to load the workshop header instead of the default one. This is necessary because you can't override a block in a included file from the file that includes it. The other design I considered was have auth support a guest user for workshops which was represented just like any other user, but this seemed both more complicated and more error prone from the security perspective. As we have other use cases for guest users (e.g. free tier), let's revisit this decision.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7112#issuecomment-534276842:676,secur,security,676,https://hail.is,https://github.com/hail-is/hail/pull/7112#issuecomment-534276842,1,['secur'],['security']
Security,"Oof, good catch! The thing we're trying to avoid is `e^x` overflowing for large positive `x`. In double precision, the smallest `x` that overflows is 710. So to test that we handle overflow correctly, you can check `sigmoid(710) == 1.0` and `sigmoid(-710) == 0.0` (using approximate equality). Actually, after playing with this, if you just use the simple definition `sigmoid(x) = 1 / (1 + np.exp(-x))`, then `sigmoid(-710)` does overflow, but it returns the right answer since `np.exp(710)` returns `inf`, and `1 / inf == 0.0`. But `math.exp(710)` throws an exception. `hl.exp` seems to have the numpy behavior, so I think the simple version actually works. But we should add the above test. I think wrapping this in an exposed function is a good idea. I agree it should be called `expit`, both for consistency with scipy, and because as you say, `sigmoid` really just means an S shaped function. And if we do expose `expit`, we should probably expose its inverse `logit` too.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10606#issuecomment-866034244:721,expose,exposed,721,https://hail.is,https://github.com/hail-is/hail/pull/10606#issuecomment-866034244,3,['expose'],"['expose', 'exposed']"
Security,"Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2ZTAyYTQ3Zi02MzNlLTQ2MDUtYjM1OS1mN2RjOGIyMDk1YTYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjZlMDJhNDdmLTYzM2UtNDYwNS1iMzU5LWY3ZGM4YjIwOTVhNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""6e02a47f-633e-4605-b359-f7dc8b2095a6"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13933:3563,access,access,3563,https://hail.is,https://github.com/hail-is/hail/pull/13933,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3NTkyMDJiMS1hZTUwLTQxMjUtYjNhNS1iZjFmOTM3NTU1YWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6Ijc1OTIwMmIxLWFlNTAtNDEyNS1iM2E1LWJmMWY5Mzc1NTVhYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""759202b1-ae50-4125-b3a5-bf1f937555ac"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13836:3563,access,access,3563,https://hail.is,https://github.com/hail-is/hail/pull/13836,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4ZjJmN2FlNC0wY2VjLTQ3ZTYtODIyZi1lODFiMTA2N2RhMjIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjhmMmY3YWU0LTBjZWMtNDdlNi04MjJmLWU4MWIxMDY3ZGEyMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""8f2f7ae4-0cec-47e6-822f-e81b1067da22"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13871:4644,access,access,4644,https://hail.is,https://github.com/hail-is/hail/pull/13871,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkMzg0ZDAwZS1iMThiLTQxYmMtODcxZi00Y2YyYTU3YWQ5MzgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImQzODRkMDBlLWIxOGItNDFiYy04NzFmLTRjZjJhNTdhZDkzOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""d384d00e-b18b-41bc-871f-4cf2a57ad938"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13718:3495,access,access,3495,https://hail.is,https://github.com/hail-is/hail/pull/13718,2,"['access', 'authoriz']","['access', 'authorized']"
Security,Other to-do items are to make sure the stack has tests for authorization for all new endpoints in `test_batch.py` in the corresponding PR.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14170#issuecomment-1898818963:59,authoriz,authorization,59,https://hail.is,https://github.com/hail-is/hail/pull/14170#issuecomment-1898818963,1,['authoriz'],['authorization']
Security,Otherwise all numeric SHAs will be treated as numbers which breaks k8s input validation,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4580:77,validat,validation,77,https://hail.is,https://github.com/hail-is/hail/pull/4580,1,['validat'],['validation']
Security,"PHY-6050294](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6050294) | `cryptography:` <br> `41.0.7 -> 42.0.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **402/1000** <br/> **Why?** Proof of Concept exploit, CVSS 5.9 | Information Exposure <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6126975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6126975) | `cryptography:` <br> `41.0.7 -> 42.0.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkYWIzNjU3Mi1hNTUwLTQwY2EtYThjZi0zN2ZjODljOWI1OGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImRhYjM2NTcyLWE1NTAtNDBjYS1hOGNmLTM3ZmM4OWM5YjU4YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""dab36572-a550-40ca-a8cf-37fc89c9b58a"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14201:2151,access,access,2151,https://hail.is,https://github.com/hail-is/hail/pull/14201,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"PkZ97PM0WGsCMWwupSOuEk/NsFe69cZwbElYZJeqeA/bKKsmRsJ/tjzyYMLUlj4L++4GQIwPHgtjmQ9kUEeaw== dgoldste@wmce3-cb7\n"",; ""path"": ""/home/batch-worker/.ssh/authorized_keys""; }; ]; }; },; ""requireGuestProvisionSignal"": true,; ""secrets"": [],; ""windowsConfiguration"": null; },; ""plan"": null,; ""platformFaultDomain"": null,; ""priority"": ""Spot"",; ""provisioningState"": ""Succeeded"",; ""proximityPlacementGroup"": null,; ""resourceGroup"": ""dgoldste"",; ""resources"": null,; ""scheduledEventsProfile"": null,; ""securityProfile"": null,; ""storageProfile"": {; ""dataDisks"": [],; ""imageReference"": {; ""exactVersion"": ""0.0.12"",; ""id"": ""/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/dgoldste/providers/Microsoft.Compute/galleries/dgoldste_batch/images/batch-worker/versions/0.0.12"",; ""offer"": null,; ""publisher"": null,; ""resourceGroup"": ""dgoldste"",; ""sharedGalleryImageId"": null,; ""sku"": null,; ""version"": null; },; ""osDisk"": {; ""caching"": ""ReadOnly"",; ""createOption"": ""FromImage"",; ""deleteOption"": ""Delete"",; ""diffDiskSettings"": null,; ""diskSizeGb"": 30,; ""encryptionSettings"": null,; ""image"": null,; ""managedDisk"": {; ""diskEncryptionSet"": null,; ""id"": ""/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/dgoldste/providers/Microsoft.Compute/disks/batch-worker-pr-11144-default-nbthv8fduvd6-highmem-13t6m-os"",; ""resourceGroup"": ""dgoldste"",; ""storageAccountType"": ""Standard_LRS""; },; ""name"": ""batch-worker-pr-11144-default-nbthv8fduvd6-highmem-13t6m-os"",; ""osType"": ""Linux"",; ""vhd"": null,; ""writeAcceleratorEnabled"": null; }; },; ""tags"": {; ""batch-worker"": ""1"",; ""namespace"": ""pr-11144-default-nbthv8fduvd6""; },; ""type"": ""Microsoft.Compute/virtualMachines"",; ""userData"": null,; ""virtualMachineScaleSet"": null,; ""vmId"": ""2612958c-ef4e-4678-8482-29726290ae20"",; ""zones"": null; },; {; ""additionalCapabilities"": null,; ""applicationProfile"": null,; ""availabilitySet"": null,; ""billingProfile"": {; ""maxPrice"": -1.0; },; ""capacityReservation"": null,; ""diagnosticsProfile"": null,; ""evictionPolicy"": ""Delete"",",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11144#issuecomment-990039686:9117,encrypt,encryptionSettings,9117,https://hail.is,https://github.com/hail-is/hail/pull/11144#issuecomment-990039686,1,['encrypt'],['encryptionSettings']
Security,Polynomial-based hashes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2452:17,hash,hashes,17,https://hail.is,https://github.com/hail-is/hail/pull/2452,1,['hash'],['hashes']
Security,"Possibly related: https://github.com/erdewit/nest_asyncio/issues/22#issuecomment-1300570745. If Ben W is using asyncio in *his* code, it seems likely we'll end up with unpatched tasks. If this is the problem, we should expose an async implementation of hailtop.batch that he can use.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14051#issuecomment-1833938619:219,expose,expose,219,https://hail.is,https://github.com/hail-is/hail/issues/14051#issuecomment-1833938619,1,['expose'],['expose']
Security,Problem with py4j conversion of Python dict to `java.util.HashMap` instead of `scala.collection.immutable.Map`. Tested locally.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4073#issuecomment-410049172:58,Hash,HashMap,58,https://hail.is,https://github.com/hail-is/hail/pull/4073#issuecomment-410049172,1,['Hash'],['HashMap']
Security,Protectes from (unlikely) man in the middle attacks on our infrastructure.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8510:44,attack,attacks,44,https://hail.is,https://github.com/hail-is/hail/pull/8510,1,['attack'],['attacks']
Security,"Proxy from gateway to router. Logic for proxying web sockets came from here: https://stackoverflow.com/a/15198581/431282. The Let's Encrypt stuff here isn't used anymore, not since we put letsencrypt in its own subproject. I tested this by hand and then live on the cluster (!) and it's working fine.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5873:132,Encrypt,Encrypt,132,https://hail.is,https://github.com/hail-is/hail/pull/5873,1,['Encrypt'],['Encrypt']
Security,"Pulled out `command`, `image` and `mount_docker_socket` as docker-job-specific keys that don't apply to non-docker jobs. Also pushed handling of deprecated keys into schema validation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9857:173,validat,validation,173,https://hail.is,https://github.com/hail-is/hail/pull/9857,1,['validat'],['validation']
Security,"Pushed some more changes:; - first foray into RBAC; - created service account for batch; - batch run jobs in batch-pods namespace; - authorize with role binding; - hand-tested, batch is working. batch will now be found at `batch.default` instead of `batch` when running from batch-jobs namespace. I updated the batch Client to reflect this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4545#issuecomment-429681232:133,authoriz,authorize,133,https://hail.is,https://github.com/hail-is/hail/pull/4545#issuecomment-429681232,1,['authoriz'],['authorize']
Security,"Put **Notes** after example. Suggested rewrite:. ""This method registers new global annotations in the VDS. These annotations can then be accessed through expressions in downstream operations. The Hail data type must be provided and match the type of the Python object.""",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1501#issuecomment-284859085:137,access,accessed,137,https://hail.is,https://github.com/hail-is/hail/pull/1501#issuecomment-284859085,1,['access'],['accessed']
Security,"Python 3.6 has been EOL for over three months, and around that time we dropped support in the docs but silently kept support in the code. I'd like to drop support for 3.6 but our stance seems inconsistent on how long we support something after EOL (I would like to not ever) so I wanted to double check. Regardless we should support new versions of python. I pushed these into our internal registry but I don't believe I have access to dockerhub's hailgenetics, so haven't been able to push them there yet.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11749:426,access,access,426,https://hail.is,https://github.com/hail-is/hail/pull/11749,1,['access'],['access']
Security,"Python 3.8 [added a validate parameter](https://docs.python.org/3/library/logging.html#logging.Formatter) to the stdlib Formatter which is on by default and doesn't like our format strings, which I guess python 3.7 is just too lenient about? Anyway I updated the format string to match the docs' recommendation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11839:20,validat,validate,20,https://hail.is,https://github.com/hail-is/hail/pull/11839,1,['validat'],['validate']
Security,R uses `ymin` and `ymax`. This was added after last release so isn't a user exposed bug yet.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11362:76,expose,exposed,76,https://hail.is,https://github.com/hail-is/hail/pull/11362,1,['expose'],['exposed']
Security,"Re-implement export vcf in generated code. There is a fair amount of 'duplicated' code here between table export; and vcf export, however, I belive this to be fine. We can always; refactor VCFPartitionWriter to be a subclass of SimplePartitionWriter,; but that would require a little special casing as VCF export needs; access to the column values and SimplePartitionWriter assumes such; a thing is not necessary. As far as VCF export itself, we simply duplicate the logic present in; ExportVCF but with generated code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11450:320,access,access,320,https://hail.is,https://github.com/hail-is/hail/pull/11450,1,['access'],['access']
Security,"Realized that the notebook python app should in fact speak https because it is exposed on the pod even though it does not have a service in front of it. For example, prometheus scrapes all visible ports on a pod and it anticipates https. This was triggering the deluge of errors from notebook and deploying this into default seems to have stopped them.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10250:79,expose,exposed,79,https://hail.is,https://github.com/hail-is/hail/pull/10250,1,['expose'],['exposed']
Security,"Ref:; kind: Role; name: create-services; apiGroup: """"; ---; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: create-services-and-pods; rules:; - apiGroups: [""""]; resources: [""services""]; verbs: [""*""]; - apiGroups: [""""]; resources: [""pods""]; verbs: [""*""]; ---; kind: RoleBinding; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: notebook-create-services-and-pods; subjects:; - kind: ServiceAccount; name: notebook; namespace: default; roleRef:; kind: Role; name: create-services #this was causing the error, and of course the create-services role is superseded by the the create-services-and-pods role; apiGroup: """"; ---; ```. After:; ```yaml; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: create-services-and-pods; rules:; - apiGroups: [""""]; resources: [""services""]; verbs: [""*""]; - apiGroups: [""""]; resources: [""pods""]; verbs: [""*""]; ---; kind: RoleBinding; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: notebook-create-services-and-pods; subjects:; - kind: ServiceAccount; name: notebook; namespace: default; roleRef:; kind: Role; name: create-services-and-pods; apiGroup: """"; ---; ```. ### Results of test runs. Before:. ```sh; kubectl apply -f k8s-config.yaml; ERROR: (gcloud.compute.addresses.describe) Could not fetch resource:; - Required 'compute.addresses.get' permission for 'projects/hail-vdc-staging/regions/us-central1/addresses/site'. namespace/batch-pods unchanged; ...; The RoleBinding ""notebook-create-services-and-pods"" is invalid: roleRef: Invalid value: rbac.RoleRef{APIGroup:""rbac.authorization.k8s.io"", Kind:""Role"", Name:""create-services""}: cannot change roleRef; make: *** [k8s-config] Error 1; ```. After:; ```sh; ERROR: (gcloud.compute.addresses.describe) Could not fetch resource:; - Required 'compute.addresses.get' permission for 'projects/hail-vdc-staging/regions/us-central1/addresses/site'. ...; role.rbac.authorization",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5746:2087,authoriz,authorization,2087,https://hail.is,https://github.com/hail-is/hail/pull/5746,1,['authoriz'],['authorization']
Security,Reference Genome #5: Exposed GenomeReference on Import methods,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2096:21,Expose,Exposed,21,https://hail.is,https://github.com/hail-is/hail/pull/2096,1,['Expose'],['Exposed']
Security,"Reference</code> and <code>NativeLibrary</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1440"">#1440</a>: Support for LoongArch64 - <a href=""https://github.com/Panxuefeng-loongson""><code>@​Panxuefeng-loongson</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1444"">#1444</a>: Update embedded libffi to 1f14b3fa92d4442a60233e9596ddec428a985e3c and rebuild native libraries - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1438"">#1438</a>: Handle arrays in structures with differing size - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>: Handle race condition in <code>c.s.j.p.win32.PdhUtil#PdhEnumObjectItems</code> - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; </ul>; <h2>Important Changes</h2>; <ul>; <li><code>Memory#dispose</code>, <code>CallbackReference#dispose</code> and <code>NativeLibrary#dispose</code>; were called by the <code>Object#finalize</code> override. These calls were replaced by; the use of a cleaner. It is not guaranteed anymore, that <code>dispose</code> is called; on subclasses on finalization.</li>; </ul>; <h1>Release 5.11.0</h1>; <h2>Features</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1398"">#1398</a>: Increase <code>c.s.j.p.win32.Sspi#MAX_TOKEN_SIZE</code> on Windows 8/Server 2012 and later - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1403"">#1403</a>: Rebuild AIX binaries with libffi 3.4.2 (other archite",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:2082,access,access,2082,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,"Regarding history and fake pages: I’m confused as to why fake pages would be used, since upon refresh that fake page wouldn’t correspond to a real page, but this shouldn’t interfere. The behavior without this solution should be the same: the url is updated with a hash. If you’ve noticed a concrete issue, please share it, because I may not understand the specific use (e.g. RTD). Haven’t seen any issues in testing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7334#issuecomment-544675789:264,hash,hash,264,https://hail.is,https://github.com/hail-is/hail/pull/7334#issuecomment-544675789,1,['hash'],['hash']
Security,"Regarding permissions. No problems except when creating folders. It appears to me that the folder is being created as separate bucket, rather than as an object in the bucket:. """"""; ...; exceptions.from_http_response(response) google.api_core.exceptions.Forbidden: 403 GET https://www.googleapis.com/storage/v1/b/untitled-folder?projection=noAcl: user-nrru16jaxrwmnzkv5f35xfibg@hail-vdc.iam.gserviceaccount.com does not have storage.buckets.get access to **untitled-folder**.; """""". There is an open issue describing this problem: https://github.com/src-d/jgscm/issues/13. I found an interesting ""solution"": first click on an already-created folder (an `.ipynb_checkpoints` folder is created when you create a python file, that works); this populates the path with /bucket_name/folder. Back up to ../ and create a new folder, voila. . <img width=""1226"" alt=""Screenshot 2019-04-04 22 50 30"" src=""https://user-images.githubusercontent.com/5543229/55601098-1640c880-572d-11e9-8afb-ac000040962d.png"">. So this seems like something that could be fixed in jgscm, or potentially by setting ""--notebook-dir"" in addition to ""GoogleStorageContentManager.default_path"". (""default_path"" is used, because apparently setting [""--notebook-dir"" to set the root directory to the chosen bucket doesn't work])(https://github.com/src-d/jgscm#usage).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5788#issuecomment-480132253:444,access,access,444,https://hail.is,https://github.com/hail-is/hail/pull/5788#issuecomment-480132253,1,['access'],['access']
Security,RegionValueBuilder: Enable a random access pattern for arrays of non-required types,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4630:36,access,access,36,https://hail.is,https://github.com/hail-is/hail/pull/4630,1,['access'],['access']
Security,"Relatedly, the auth system and the front end are not in this pull request (and AFACIT aren't in master yet?), which makes it harder to reason about the overall system. The auth system make sense as an independent PR (is that what https://github.com/hail-is/hail/pull/5162 is?). The changes that expose / use this new API (i.e. the UI component) should be a part of this PR so we can reason about the entire proposed change.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215#issuecomment-459893784:295,expose,expose,295,https://hail.is,https://github.com/hail-is/hail/pull/5215#issuecomment-459893784,1,['expose'],['expose']
Security,"Remarkable, thank you! Is this exposed in the most recent version of Hail , 0.2.128 ?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14297#issuecomment-1967660767:31,expose,exposed,31,https://hail.is,https://github.com/hail-is/hail/pull/14297#issuecomment-1967660767,1,['expose'],['exposed']
Security,"Remove AST hierarchy, FunctionRegistry, AST parser, dependencies (tests) and any other dead code I could find. > 4 additions and 6,710 deletions. Aw, yiss. Full disclosure: this deletes some tests (SKAT, PCRelate, etc.) that currently have no corresponding tests in Python. My plan is to do a ""test audit"" and assign out tests to make sure we have a complete set of tests for the current functionality (including stuff that was deleted here and things that are simply missing tests, e.g. the MatrixIR parser, some IR nodes, etc.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3990:299,audit,audit,299,https://hail.is,https://github.com/hail-is/hail/pull/3990,1,['audit'],['audit']
Security,"Remove linked issue requirement, we will try using issue/pr templates to capture security impact instead.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14665:81,secur,security,81,https://hail.is,https://github.com/hail-is/hail/pull/14665,1,['secur'],['security']
Security,"Remove the setup of Jupyter/JupyterLab from hailctl to enable use of Dataproc's [Component Gateway](https://cloud.google.com/dataproc/docs/concepts/accessing/dataproc-gateways) feature, which eliminates the need to use an ssh tunnel to reach the various web UIs on the Dataproc cluster. To test this pull request:; 1. run `hailctl dataproc start` as usual, but add parameters `--enable-component-gateway --optional-components JUPYTER --dry-run` to generate the `gcloud dataproc clusters create` command that will setup JupyterLab and eliminate the need for an ssh tunnel. For example:; ```; hailctl dataproc start my-cluster-name \; --region us-central1 \; --enable-component-gateway \; --optional-components JUPYTER \; --bucket name-of-my-staging-gcs-bucket-where-notebook-files-will-live \; --temp-bucket name-of-my-gcs-bucket-with-a-lifecycle-rule-to-autodelete-cruft-after-two-weeks \; --max-idle 60m \; --dry-run; ```; 2. In the generated `gcloud dataproc clusters create` command, replace the value of `--initialization-actions` with the path of the GCS location to the script in this pull request. Also replace the value of `--temp-bucket`, since hailctl appears to stomp on the user specified value. Then run the command to create your cluster with component gateway enabled.; 3. To obtain the URL to JupyterLab, run `gcloud dataproc clusters describe my-cluster-name --region=us-central1 --format=""yaml(config.endpointConfig.httpPorts)""`; 4. Run Hail notebooks to test the setup of JupyterLab provided by Dataproc!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12788:148,access,accessing,148,https://hail.is,https://github.com/hail-is/hail/pull/12788,1,['access'],['accessing']
Security,Remove the various schema accessors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3060:26,access,accessors,26,https://hail.is,https://github.com/hail-is/hail/pull/3060,1,['access'],['accessors']
Security,"Resource groups are permitted to use dashes, underscores, uppercase letters,; and probably other characters not permitted in storage account names. This; PR cahanges `bootstrap.sh` to:. 1. Ignore invalid characters in the resouce group. 2. Ensure (via randomness) that the generated name is unique. 3. Do not try to create a new storage account if `backend-config.tfvars` exists. I lightly tested this. Here is an example of how it sanitizes a resource group name:. ```; RESOURCE_GROUP=bu__ild-batch-worker-i32mage; possibly_invalid_storage_account_name=""$(cat /dev/urandom | LC_ALL=C tr -dc 0-9 | head -c 4)${RESOURCE_GROUP}""; STORAGE_ACCOUNT_NAME=$(LC_ALL=C tr -dc a-z0-9 <<< ""${possibly_invalid_storage_account_name}"" | head -c 24); echo $STORAGE_ACCOUNT_NAME; 7241buildbatchworkeri32m; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11313:432,sanitiz,sanitizes,432,https://hail.is,https://github.com/hail-is/hail/pull/11313,1,['sanitiz'],['sanitizes']
Security,"Reverts hail-is/hail#14461. We're hitting [github rate limits](https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aresource.labels.namespace_name%3D%22default%22%0Aresource.labels.container_name%3D%22ci%22%0A--%20severity%3DERROR%20OR%20WARNING;pinnedLogId=2024-04-18T15:42:12.920462831Z%2Fvdlhscspn377olu0;cursorTimestamp=2024-04-18T15:42:14.785330871Z;duration=P1D?project=hail-vdc) which is preventing actions like dev deploys. The limit is apparently [5,000 requests/hour](https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api?apiVersion=2022-11-28#primary-rate-limit-for-authenticated-users). This feels excessive to me, and I feel like we most be using the API poorly, but I want to just revert this before investigating further so CI doesn't get stuck.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14476:638,authenticat,authenticated-users,638,https://hail.is,https://github.com/hail-is/hail/pull/14476,1,['authenticat'],['authenticated-users']
Security,"Right I understand, so Hail value refers to something Hail needs to access, with the modifier ""off-heap"". If a PType always places its items into one region, that doesn't seem problematic.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7826#issuecomment-575731116:68,access,access,68,https://hail.is,https://github.com/hail-is/hail/issues/7826#issuecomment-575731116,1,['access'],['access']
Security,"Right now the Grafana is exposed as a k8s service speaking http with only the grafana auth. This puts an nginx sidecar in front of Grafana to bring TLS all the way through the the Grafana pod and perform dev authentication. This required adding an api endpoint to auth that can verify a connection based on the session and not an Authorization header. Other services like `router-resolver` have gotten away with not having this since they construct the Authorization header in python before hitting the `userinfo` endpoint, but this seems like a straightforward addition that will make it easier for internal authentication such as this case. This does another deviant thing which is using a `runImage` step to template the nginx config instead of templating inside the container at container start time (like router and site currently do). It is a little janky, because there are essentially two jinja passes, one in CI to render the shell script for the job, and then the jinja line in the job itself to render the nginx config. But this looks to be the most straightforward way I could figure out without adding another `build.py` Step type and even in that case it would have to be some sort of no-op job.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10139:25,expose,exposed,25,https://hail.is,https://github.com/hail-is/hail/pull/10139,5,"['Authoriz', 'authenticat', 'expose']","['Authorization', 'authentication', 'exposed']"
Security,"Right now, we perform a full scan in `to_dense_mt`, we have information to do less work and densify in a single pass. - [ ] Expose partitioning in python; - [ ] For each partition in the variants table, use `ref_block_max_length` to determine the full reference interval necessary to densify that partition; - [ ] Use `map_partitions` of the variants and `query_table` on the reference to get two streams with all information necessary to densify.; - [ ] Join the streams and use the current algorithm/scan to do the work.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14499:124,Expose,Expose,124,https://hail.is,https://github.com/hail-is/hail/issues/14499,1,['Expose'],['Expose']
Security,"Right, but my concern is that relies on access to the original dataset. And who knows if columns got filtered or what now. I think something that preserves the state in the directory is the right thing to do.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5208#issuecomment-457761043:40,access,access,40,https://hail.is,https://github.com/hail-is/hail/pull/5208#issuecomment-457761043,1,['access'],['access']
Security,"Rs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1NDBhNTVlYS05Y2JkLTRlZWEtYmJmZi00ZWU2NjlhZWJmYWQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjU0MGE1NWVhLTljYmQtNGVlYS1iYmZmLTRlZTY2OWFlYmZhZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""540a55ea-9cbd-4eea-bbff-4ee669aebfad"",""prPublicId"":""540a55ea-9cbd-4eea-bbff-4ee669aebfad"",""dependencies"":[{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-SETUPTOOLS-3180412""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,509],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13516:4087,Access,Access,4087,https://hail.is,https://github.com/hail-is/hail/pull/13516,2,"['Access', 'access']","['Access', 'access-control']"
Security,"Rs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhZWIyYjAwNS1lYjhhLTRiMzgtYjkwMS04YzRmNTY2OGM3ZDYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFlYjJiMDA1LWViOGEtNGIzOC1iOTAxLThjNGY1NjY4YzdkNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""aeb2b005-eb8a-4b38-b901-8c4f5668c7d6"",""prPublicId"":""aeb2b005-eb8a-4b38-b901-8c4f5668c7d6"",""dependencies"":[{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-SETUPTOOLS-3180412""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,509],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13517:3911,Access,Access,3911,https://hail.is,https://github.com/hail-is/hail/pull/13517,2,"['Access', 'access']","['Access', 'access-control']"
Security,"SEC; ----. - Web Application Security, A Beginner's Guide https://www.amazon.com/Web-Application-Security-Beginners-Guide/dp/0071776168; - The Web Application Hacker's Handbook: Finding and Exploiting Security Flaws https://www.amazon.com/Web-Application-Hackers-Handbook-Exploiting/dp/1118026470; - http://cryto.net/~joepie91/blog/2016/06/13/stop-using-jwt-for-sessions/; - http://cryto.net/~joepie91/blog/2016/06/19/stop-using-jwt-for-sessions-part-2-why-your-solution-doesnt-work/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6720#issuecomment-514358731:29,Secur,Security,29,https://hail.is,https://github.com/hail-is/hail/issues/6720#issuecomment-514358731,3,['Secur'],"['Security', 'Security-Beginners-Guide']"
Security,"SHOT]; 		at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		... 48 more; Caused by: com.google.api.client.http.HttpResponseException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 	at com.google.api.client.http.HttpResponseException$Builder.build(HttpResponseException.java:293) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ResumableMedia.lambda$startUploadForBlobInfo$0(ResumableMedia.java:40) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(Direc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:27621,access,access,27621,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['access'],['access']
Security,"Saves memory on the master but has an unfortunate side effect of; drastically multiplying the number of times a tabix file is read, as it; is read once per partition per vcf rather than once per vcf. This change places tabix reading in a more critical path of the gVCF; merger, I would appreciate a more detailed performance audit of that; code, in addition to looking over this change. From my measurements it looks like we pay a 20-30 second cost per partition of 100 gVCFs. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5596:325,audit,audit,325,https://hail.is,https://github.com/hail-is/hail/pull/5596,1,['audit'],['audit']
Security,"Scala's reflective access warning refers to referencing a member of an anonymous class that is not also a member of the implemented int.rface / super-class. Because there is no concrete, non-anonymous type that contains that member, there is no normal means to access / call that member. Scala hacks around this issue by inserting a use of Java's reflection library to look up the member at run-time. The solution is simple: make the class named / non-anonymous/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3624:19,access,access,19,https://hail.is,https://github.com/hail-is/hail/pull/3624,2,['access'],['access']
Security,"Security Impact: No exploits possible, but this does make us look slightly better, and removes a small risk of incorrect component re-use in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14669:0,Secur,Security,0,https://hail.is,https://github.com/hail-is/hail/pull/14669,1,['Secur'],['Security']
Security,"See #6370 . > Could you open an issue, to explore changing this to a header-specified token, or randomizing the name field.; > ; > https://security.stackexchange.com/questions/211352/does-owasp-recommend-to-include-a-csrf-token-in-a-header-or-to-use-it-as-a-param; > ; > Need to take care with logging in this case.; > https://github.com/OWASP/CheatSheetSeries/blob/master/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.md; > ; > To further enhance the security of this proposed design, consider randomizing the CSRF token parameter name and/or value for each request. Implementing this approach results in the generation of per-request tokens as opposed to per-session tokens.; > doing both seems identical to implementing 2 CSRF tokens",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6417:139,secur,security,139,https://hail.is,https://github.com/hail-is/hail/issues/6417,2,['secur'],['security']
Security,"See [discussion](https://hail.zulipchat.com/#narrow/stream/127527-team/topic/CI.20Deploy.20Failure/near/241944633). spring.io no; longer supports [direct, unauthenticated access to its repository](https://spring.io/blog/2020/10/29/notice-of-permissions-changes-to-repo-spring-io-fall-and-winter-2020).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10567:171,access,access,171,https://hail.is,https://github.com/hail-is/hail/pull/10567,1,['access'],['access']
Security,See https://cloud.google.com/sdk/docs/install#deb . ### Security Assessment. - [x] This change has a low security impact,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14708:56,Secur,Security,56,https://hail.is,https://github.com/hail-is/hail/pull/14708,2,"['Secur', 'secur']","['Security', 'security']"
Security,"See the separate document in `team` about firewall-rules. In particular, the default network will block all connections.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7978#issuecomment-578967196:42,firewall,firewall-rules,42,https://hail.is,https://github.com/hail-is/hail/pull/7978#issuecomment-578967196,1,['firewall'],['firewall-rules']
Security,"Simply enables CORS from all domains. This would be insecure, but our endpoints are read-only operations on public GitHub resources, against a fixed list of users, there is no database to inject, and there are no cookies or local storage entries to steal. I think it's safe enough for the time being, but open to suggestions. Also expose /json endpoint to return all index.html data without rendering a page.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4945:188,inject,inject,188,https://hail.is,https://github.com/hail-is/hail/pull/4945,4,"['expose', 'inject']","['expose', 'inject']"
Security,"Since #10648, public jobs use external DNS and are prohibited from accessing the metadata server to resolve names such as `batch.hail` or `internal.hail`. This broke the ability to submit batches from within a job, since the batch client, recognizing it is in GCE, would attempt to use the fore-mentioned domains. This opens that communication channel by adding an `/etc/hosts` entry for the appropriate batch domain that points to the internal gateway. Relatedly, we currently have this iptables rule https://github.com/hail-is/hail/blob/81f4b1fbedfac288c717ae65664c3cd82b25ac2f/batch/batch/worker/worker.py#L210. for every job's network namespace that `ACCEPT`s packets leaving the worker. This includes packets destined for the internet but can also include those going to internal gateway, or other GCE nodes in our internal network (so maybe `internet_interface` is a slight misnomer). This means that public jobs can currently send requests to any ip address on our internal network (they cannot use our internal DNS, however). I removed this line and instead added more explicit rules (note the order is important):; - Allow packets to the internal gateway; - Allow packets looping back to the same worker the job is on; - Allow packets from public jobs leaving the worker and NOT destined for our internal network; - Allow packets NOT from public jobs leaving the worker destined anywhere. Since the default policy is to drop packets, this should forbid public jobs from talking to **other** addresses on the network with the exception of internal gateway.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10796:67,access,accessing,67,https://hail.is,https://github.com/hail-is/hail/pull/10796,1,['access'],['accessing']
Security,"Since the batch workers will ultimately need to communicate with the database for CI jobs, it seems asymmetrical to put the private database connection in the k8s subnet. I've created a third small subnet just for the private database connection. Traffic across subnets is allowed by default so VMs in k8s and the batch workers should be able to access the database IP. This way we can put more restrictive rules in later (like batch workers should not be able to address VMs in the k8s subnet) without interfering with the database connection. I've applied this change to the azure instance and verified that auth and the admin pod work with the new IP.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11030:346,access,access,346,https://hail.is,https://github.com/hail-is/hail/pull/11030,1,['access'],['access']
Security,Site update latest hash path,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4771:19,hash,hash,19,https://hail.is,https://github.com/hail-is/hail/pull/4771,1,['hash'],['hash']
Security,"Small amount of preliminary work #6673. I made a PR trying to address this issue already, but ended up reverting it because it broke CI and we don't test that well. To minimize frustration, I'm making some initial changes here first. . Namely:. - Steps have an equality and hash method based solely on their name (I'm going to want to build a hash map of steps when coming up with dependencies for the cleanup jobs. ; - Cleanup now takes a list of parents, instead of just the sink job (useful for when there are more parents than just the sink job).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6782:274,hash,hash,274,https://hail.is,https://github.com/hail-is/hail/pull/6782,2,['hash'],['hash']
Security,Snyk is failing because it suddenly realized that we have dependencies (#security 🤦 ). I will fix those issue separately.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13551#issuecomment-1707206872:73,secur,security,73,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1707206872,1,['secur'],['security']
Security,"Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""92bcf51f-c710-4a85-9af1-5ae170a8797a"",""prPublicId"":""92bcf51f-c710-4a85-9af1-5ae170a8797a"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""41.0.5""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13938:10219,Access,Access,10219,https://hail.is,https://github.com/hail-is/hail/pull/13938,1,['Access'],['Access']
Security,"So I did some simple formatting on the ""Filter loci by a list of locus intervals"" example. . The cloud sphinx theme you mentioned on zulip has toggleable sections that look a bit nicer. I could emulate that formatting by writing a sphinx extension if we wanted to get fancier, but what do you think of this layout?. IMAGE 1. <img width=""720"" alt=""screen shot 2018-08-22 at 11 23 34 am"" src=""https://user-images.githubusercontent.com/35241112/44473344-1eb11c80-a5fe-11e8-954d-41440a031d24.png"">. IMAGE 2; clicking on `show` would expose more content:. <img width=""699"" alt=""screen shot 2018-08-22 at 11 23 46 am"" src=""https://user-images.githubusercontent.com/35241112/44473350-2375d080-a5fe-11e8-98e9-31f1c3bb825c.png"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4089#issuecomment-415074240:529,expose,expose,529,https://hail.is,https://github.com/hail-is/hail/pull/4089#issuecomment-415074240,1,['expose'],['expose']
Security,"So I'm going to insist on the classical loop interface I described above, since it is strictly more powerful than the interfaces you've proposed. I don't have a strong feeling if you want to also add a Python-inspired while loop (although I personally would find the similarities misleading given the required differences, I understand others might feel differently). Your while loop should be naturally implementable in terms of mine, so I also suggest we focus on that first. Giving each loop a name seems natural. Apart from the wrapping issue (the greatest existential threat our generation faces) I don't see any problem calling an outer loop from an inner loop. Is Patrick's proposal for extra types written up anywhere? I don't like the idea of complicating the type hierarchy for internal bookkeeping like this. So I'm going to remark that in the code generator it is often natural to build data structures to aid the organization of the code generator, and those data structures need not need to be types/IRs. Given that Recur has to be in tail position, and you know exactly when you're existing the loop (branches that don't contain recur nodes). So the compilation looks like:. ```; set initial loop variables; # fall through into loop; Lloop:; ...; # recur; loop variables = new values; goto Lloop; Lan_exit_branch:; result = compile(branch); goto Lafter; Lanother_exit_branch:; result = compile(other_branch); goto Lafter; Lafter:; use result ...; ```. What I would do is ""peel"" off the ifs and lets (anything else?) that can sit in tail position and build a separate data structure for those nodes which I then traverse to emit the above code. Using the stream interface seems wrong to me also. What's the type of the stream the loop turns into? Since loops carry multiple values (by design), memory allocating these to create a tuple stream is going to be a performance non-starter. I'll comment more once I've looked over the code.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7614#issuecomment-558699125:573,threat,threat,573,https://hail.is,https://github.com/hail-is/hail/pull/7614#issuecomment-558699125,1,['threat'],['threat']
Security,"So then, loadLength would take instead of a Long, a RegionOwnedAddress, which would say be a (region, Int) tuple correct? Because I'm not exactly sure what Hail values we are referring to in this context, unless we mean ""a Scala value that points to some data that the Hail program needs to access"" (since currently we pass around memory addresses that are Scala primitives, and call methods on PTypes...so I thought the proposal was to give the PType management of regions, so that the caller would not need to think about this, which is closer to what I had envisioned).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7826#issuecomment-575729333:291,access,access,291,https://hail.is,https://github.com/hail-is/hail/issues/7826#issuecomment-575729333,1,['access'],['access']
Security,"So we can pull out the necessary reference genomes (in python) to execute a given IR, or to parse a given type, and pass them in to the Scala execution context which will not have access to the reference genomes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6935:180,access,access,180,https://hail.is,https://github.com/hail-is/hail/pull/6935,1,['access'],['access']
Security,"Some more comments on this array casting business:; - We could have made Array{Ref, Len} work on any container. That would fix most uses of CastToArray, but it would still leave out the cast that we genuinely want to convert a set/dict to an array. I don't think we ever do that, but a user could with hl.array.; - It is partially an accident that dict, set and array use the same representation. We could imagine others, e.g. a hashtable for set. In which case, the cast wouldn't work, the ArrayLen probably would, and ArrayRef might or might not.; - Array{Ref, Len} could apply to streams, too (they'll need custom codegen tho).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8171#issuecomment-592220580:429,hash,hashtable,429,https://hail.is,https://github.com/hail-is/hail/pull/8171#issuecomment-592220580,1,['hash'],['hashtable']
Security,"Some, if not most of the delay in reaching a running notebook server appears to be due to the use of services. Services provide little apparent benefit at the moment, esp. since we're already managing these pods using a deployment controller. Remove them in favor of accessing pods directly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5379:267,access,accessing,267,https://hail.is,https://github.com/hail-is/hail/issues/5379,1,['access'],['accessing']
Security,"Somehow our CI server started using 8-char hashes in some places, and 7 in others. Should have this fixed later today!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2217#issuecomment-328882377:43,hash,hashes,43,https://hail.is,https://github.com/hail-is/hail/issues/2217#issuecomment-328882377,1,['hash'],['hashes']
Security,"Somewhat unrelatedly though, this seems like it would be a natural replacement for our copy-paste token (or identity delegation as the AUS folks do), as you could do the following:. 1. `hailctl auth print-access-token | pbcopy`; 2. On some notebook where you don't have access to your hail identity for some reason, do `hl.init_batch(token=…)` or `hl.ServiceBackend(token=…)`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13934#issuecomment-1785471404:205,access,access-token,205,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1785471404,2,['access'],"['access', 'access-token']"
Security,"Soon, I will add certificates and keys to the secrets and I want; to add configuration parameters that specify the paths to those; certificates and keys. Therefore, the mount locations of the; secrets must be the same everywhere so the paths are valid.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8416:17,certificate,certificates,17,https://hail.is,https://github.com/hail-is/hail/pull/8416,2,['certificate'],['certificates']
Security,"Sorry I missed your message! The code as written now is plainly wrong: we access a mutable map from two threads without synchronization. We need this change regardless of how it affects error messages. If the tests pass, I'm confident this is fine. Are there components of the system you don't think are well tested by our tests?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13546#issuecomment-1724475471:74,access,access,74,https://hail.is,https://github.com/hail-is/hail/pull/13546#issuecomment-1724475471,1,['access'],['access']
Security,"Sorry in advance for the spicy meatball and rebase pain. the entries! [hash] is now gone!. Added Symbol hierarchy in Scala and Python. Symbols have 3 types: user-level identifiers, generated symbols and ""internal"" symbols like :row and :entries. Generated and internal symbols are printed with a leading colon (with no backtick quotes). Internal symbols are never visible to the user. On the Scala side, symbols are all `Sym` but there is implicit conversions from String to Sym so client code can just write strings. On the Python side, symbols are `str` or `Symbol`. I didn't change Python gen_uid to produce Generated symbols yet. I will do that in a second PR. Generally, we pass strings through the py-j boundary and parse on either side. I turned off color on testPython because it leaves the logs full of unreadable escape codes. There is one user-visible change: the JSON exporter now escapes strings in structs so we will have ```{""`$foo`"": 5}``` instead of `{""$foo"": 5}`. This is necessary to disambiguate complex names and internal symbols.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5080:71,hash,hash,71,https://hail.is,https://github.com/hail-is/hail/pull/5080,1,['hash'],['hash']
Security,"Sorry this got missed! We should have responded, at least. This is generally intended -- scientific notation is one of the least error-prone way to represent floating-point values, and the format we use is a standard one that most tools should handle. However, we do intend to expose an option to parameterize the format of floating point values in export_vcf (though scientific notation will probably always be the default).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6963#issuecomment-563994619:277,expose,expose,277,https://hail.is,https://github.com/hail-is/hail/issues/6963#issuecomment-563994619,1,['expose'],['expose']
Security,Stacked on #10097. - Expose `machine_type` and `preemptible` in hailtop.batch; - Sets default storage when specifying the machine type to 100Gi; - Selects the cheapest machine type automatically for the user when they want a nonpreemptible worker,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10283:21,Expose,Expose,21,https://hail.is,https://github.com/hail-is/hail/pull/10283,1,['Expose'],['Expose']
Security,"Stacked on #11057. I tested the query string and made sure the list commands worked. However, I did not test the actual delete with xargs. This was copied almost verbatim from the gcp delete instances step. I'm pretty sure by not adding the `-x` flag at the top of the script, the password won't be printed to the command line output in the logs, but I'm not 100% sure. Also, for this to work, the test-gsa-key needs to be able to delete VM and network resources. Do we have this in GCP as well? I guess we must in order for Batch to be able to remove its instances.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11058:281,password,password,281,https://hail.is,https://github.com/hail-is/hail/pull/11058,1,['password'],['password']
Security,"Stacked on #11995 . This PR creates all of the new `aggregated_*_resources_by_date` tables that will be used for real time billing and making our billing queries fast and also populates them! It will probably run for ~7-8 hours (online migration) and add an estimated 200 GB to the database. It will take around 5-6 hours to populate the tables and the remainder of the time is doing an audit. I think we should whiteboard what is going on in person, but the general idea is as follows:; 1. Revert any previous work and set the trigger back to the original state (idempotent); 2. Find the latest complete or open batch id. We know that a complete batch will not have updates to the attempts table. This is extremely important because the next steps can be done in parallel rather than serially.; 3. Find offsets for complete batches up to the batch id from Step 1 in groups of 100 attempts; 4. Randomize the offsets and have a burn in period of 5000 to avoid the birthday problem where we populate the `aggregated_*_resources_by_date` tables.; 5. In 10-way parallelism (maxes out a 4 core database), randomly populate the tables for each chunk.; 6. From the last offset (original first running batch id), we sequentially process attempts in groups of 100. We take note of where we are at with tracking any updates to the attempts table (`attempts_time_msecs_diff`), populate the `aggregated_*_resources_by_date` tables, and then do a final catchup step where we apply any updates from `attempts_time_msecs_diff` for any attempts that we have already processed.; 7. Once we have reached the ""end"" of the attempts table, we lock all tables of interest especially the `attempts` table, and do one last final processing step before we add the new triggers that will auto-populate the `aggregated_*_resources_by_date` tables.; 8. Then we perform an audit and make sure things look correct. (I might need to change or eliminate the billing_project audit query because there are 5 batches with ~20 jobs that ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11996:387,audit,audit,387,https://hail.is,https://github.com/hail-is/hail/pull/11996,1,['audit'],['audit']
Security,"Stacked on #12120 . This PR implements open batches. Future PRs will expose the functionality to users in the Query Service and hailtop.batch. There's a [design document](https://docs.google.com/document/d/168Mq5nNATmSrwzL4h1oYGBIFmcNlgFyHr_Vwjx59Zss/edit#heading=h.ghe60pdzl3mv) that specified all of the changes. To briefly summarize, there are now the concept of batch updates. Each job belongs inside an ""update"". The BatchClient has two types of builders now: UpdateBatchBuilder and CreateBatchBuilder. I play some tricks with the job ids being allowed to be negative numbers denoting relative to an offset to make things more efficient when updating a batch because you don't have to make multiple API calls to get the current job offset in the batch. There are only two batch states in the database: `running` and `complete`. A batch starts out as `complete` until an update is committed at which point if the n_jobs > 0, it will change to `running`. The main thing to look at implementation-wise is the new stored procedure `commit_batch_update` with a nasty update that will block progress on the batch while the update is in progress. I added the updates to the UI. We can get rid of it if it's too confusing. There's also a `Time Updated` column now in the UI instead of `Time Closed`.; <img width=""1573"" alt=""Screen Shot 2022-07-07 at 5 33 50 PM"" src=""https://user-images.githubusercontent.com/1693348/177875516-5f48e9a7-7fc2-4344-b3d2-c9560a846abe.png"">. <img width=""786"" alt=""Screen Shot 2022-07-07 at 5 34 07 PM"" src=""https://user-images.githubusercontent.com/1693348/177875535-e9b3a99f-bdc9-4a3b-8a53-5d20df05f161.png"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12010:69,expose,expose,69,https://hail.is,https://github.com/hail-is/hail/pull/12010,1,['expose'],['expose']
Security,"Stacked on #12757. - This PR gets the ranges of existing rows from the attempt_resources, aggregated_*_resources_v2 tables in bunches of 100 and then migrates each bunch by triggering an after update trigger for those rows that haven't been migrated. The triggers were added in #12757. ; - There's an audit at the end to make sure the new v3 tables give the same answer as the old v2 tables with duplicate resources.; - We use the same trick with a burn-in period to avoid the birthday problem with deadlocks.; - I added a function that generates the where statements programmatically based on looking at the where statement from previous migrations where we wrote out the where statement by hand. I think this way is less error-prone than writing out the where statement for each table, but it might be harder to reason about. Let me know if this way is too confusing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12761:301,audit,audit,301,https://hail.is,https://github.com/hail-is/hail/pull/12761,1,['audit'],['audit']
Security,Stacked on #14016. This PR needs to have the client/server protocol for creating job groups for the four types of creation/update events hashed out and implemented. Basic tests are there. We still need tests for billing and cancellation to make sure the aggregation and cancellation operations work properly.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14018:137,hash,hashed,137,https://hail.is,https://github.com/hail-is/hail/pull/14018,1,['hash'],['hashed']
Security,"Stacked on #7000. Adds a new IR renderer in Python which integrates a CSE pass. It would be easy to argue that a CSE pass should be separate from the renderer. But we can't easily make the Python IR mutable, because a given IR tree might be used in multiple larger IR (which is exactly what this pass is taking advantage of!) so mutation which depends on the larger context won't work. So rather than rebuild the entire IR every time we print, I decided for now this is best integrated into the renderer. I think longer term this should be ported to scala as a full CSE pass (which first does hash-consing/value-numbering to find all repeated subexpressions). This is not a simple algorithm, but I did my best to make it understandable. If anything feels harder to follow than it should be, I'd like to try to improve it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7009:593,hash,hash-consing,593,https://hail.is,https://github.com/hail-is/hail/pull/7009,1,['hash'],['hash-consing']
Security,"Stacked on: https://github.com/hail-is/hail/pull/7031. Changes:; - primary change was to add `Tokens.namespace_token_or_error` which prints a friendly error of the user doesn't have the necessary authentication; - added `hailctl auth list`, and made `hailctl dev config` with no options print out the current configuration; - implemented @danking's suggestion: change some natural entrypoints (BatchClient, get_userinfo, etc.) to take optional `deploy_config` argument and load the default config if not given",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7035:196,authenticat,authentication,196,https://hail.is,https://github.com/hail-is/hail/pull/7035,1,['authenticat'],['authentication']
Security,"Stacked on: https://github.com/hail-is/hail/pull/7440. Changes:; - start the instance with a 1-time use activation token in the metadata; - on activation, clear the activation token, send the worker the normal token and batch-gsa-key; - upgrade the worker image to -6 which has the latest cloud-sdk (v269). As far as I can tell, the metadata server is still available from within the worker container after the upgrade, so I'm not 100% sure why this change was necessary. However, it will make things easier to lock down later. I think the picture we want is:; - store the worker and batch logs in different buckets,; - the worker instance service account only has instance.delete* and object.insert on the worker log bucket,; - the service account used by the worker only has object.insert on the batch logs bucket,; - we block access to the metdata srever from within the docker containers.Leaving this for reference:. https://stackoverflow.com/questions/32512597/block-docker-access-to-specific-ip. This isn't 100% trivial because the metadata server is also the DNS server. We could try blocking everything except udp/53. I think ideally, we'd put the docker containers on a different network that could only route to the outside and use a public DNS server like 8.8.8.8. *An instance doesn't need extra permissions to shut itself down, so we could just do `shutdown -h now` on the worker and have the batch driver actually delete the instance. I think once this goes in we can try scale up tests again.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7447:829,access,access,829,https://hail.is,https://github.com/hail-is/hail/pull/7447,2,['access'],"['access', 'access-to-specific-ip']"
Security,"Stacks on #5430. Once #5430 is in, the changes here will be limited to: 1) notebook.py: login/logout routes, the provision of authorized users, auth0 lib, 2) index.html 3) header.html: update lines 12 and 13 to read user from session. Provides basic login page. Below are a few images of it in action. Looks like app.hail.is. Handles authorized and workshop-only login. Handles login only; future PR will extend to checking, refreshing the session. cc @cseed . screenshots (notebook create button not yet PR'd , auth0 page not yet styled). <img width=""1141"" alt=""screen shot 2019-02-25 at 11 17 37 pm"" src=""https://user-images.githubusercontent.com/5543229/53387218-d62f3e80-3953-11e9-8653-e4c6b0e8294a.png"">; <img width=""1139"" alt=""screen shot 2019-02-25 at 11 18 00 pm"" src=""https://user-images.githubusercontent.com/5543229/53387219-d62f3e80-3953-11e9-8595-d7f1ea58a243.png"">; <img width=""1139"" alt=""screen shot 2019-02-25 at 11 18 18 pm"" src=""https://user-images.githubusercontent.com/5543229/53387220-d62f3e80-3953-11e9-9fba-e4a93b0374ee.png"">; <img width=""1141"" alt=""screen shot 2019-02-25 at 11 18 33 pm"" src=""https://user-images.githubusercontent.com/5543229/53387221-d62f3e80-3953-11e9-9527-7c4589846a29.png"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5437:126,authoriz,authorized,126,https://hail.is,https://github.com/hail-is/hail/pull/5437,2,['authoriz'],['authorized']
Security,"Starting to break out changes from #6480. This adds the ability to access sub-regions of a region by index. @patrick-schultz I know I misnamed these---they should be child references, not parent references---I can change if you prefer, but might like to hold off until afterwards since the names of the functions are threaded through the rest of the stack :(. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6499:67,access,access,67,https://hail.is,https://github.com/hail-is/hail/pull/6499,1,['access'],['access']
Security,Starving auth of the cycles to complete authentication requests causes cascading failures in the system.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12658:40,authenticat,authentication,40,https://hail.is,https://github.com/hail-is/hail/pull/12658,1,['authenticat'],['authentication']
Security,Stored under notebook-secrets : data.authorized-users,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6265#issuecomment-499142882:37,authoriz,authorized-users,37,https://hail.is,https://github.com/hail-is/hail/pull/6265#issuecomment-499142882,1,['authoriz'],['authorized-users']
Security,"Summary of changes:; - Add S3AsyncFS which is implemented in terms of the AWS Python client library, boto3. boto3 is sync (there is an in-progress async version but I decided not to use it to start). The operations are nearly identical to GCS, except S3 supports explicit API requests for multi-part uploads (unlike GCS, where we implement it in terms of compose).; - The only tricky bit is `create`, which needs an async stream writer, but a synchronous stream reader that is passed to boto3.; - I split up test_aiogoogle.py. The GCS specific tests stay there, and AsyncFS tests move to test_fs.py.; - Add S3 to the AsyncFS and copy tests. I created an S3 bucket (hail-test-dy5rg) and test user credentials (added to K8s as test-aws-key). I'm still trying to figure out how to give the rest of the services team admin access to the AWS project, I might have to go through BITS.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10498:819,access,access,819,https://hail.is,https://github.com/hail-is/hail/pull/10498,1,['access'],['access']
Security,"Summary of changes:; - Overhaul tmpdir handling. Remove most of the old code. Added local_tmpdir to `init`. tmpdir is the networked tmpdir. local_tmpdir is the tmpdir used for local files on both the driver and the executors. Added tmpdir and localTmpdir to ExecuteContext. ExecuteContext removes tmp files on close. Tmp file base is now required, try to give good base names. Tmp file names are now generated by being sufficiently random.; - Removed fs from HailContext. This involved threading ctx and fs through lots of code (most of the changes).; - Added ExecuteContext to EmitModuleBuilder and friends. This is necessary because EmitMethodBuilder gives generated code access to backend, fs, etc. which are carried by the ctx.; - Some IR (mostly readers, but also VEP, which needs to load the VEP configuration to determine its type) have overall parameters that control their behavior (e.g. the VCF reader path) but have to do IO to determine other state (like the matrix type, determined from the VCF header). This complicates pretty printing, serialization, and equality. I clarified this. In particular, I seperate the parameters (see, for example, MatrixVCFReaderParameters) which are specified on creation and used for serialization and equality from other derived state. IR no longer close over ctx or fs and they don't need to do IO after their intiial construction.; - MatrixSpec has subspecs for the marginal tables, and TableSpec has the global and rows RVD. These are now loaded on construction, so lowering no longer neesd to do IO.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8581:674,access,access,674,https://hail.is,https://github.com/hail-is/hail/pull/8581,1,['access'],['access']
Security,"Summary of changes:; - removed TStreamable; - All IR inputs must be TStream or TArray, statically; - renamed Array* nodes to be Stream* (e.g. ArrayMap to StreamMap, etc.); - ToArray, ToDict and ToSet take TStream only; - LowerArrayToStream is gone. This effectively happens in the front end. Most of the code is peppering ToArray and ToStream in the right places. I think this is a nice improvement in two ways:. I makes the IR more transparent by making ToArray, a potentially expensive operation, completely explicit. (Uses of ToArray should probably be audited.). Second, I think it cleans up the flow in Emit/Stream. Now, streams are always compiled by EmitStream, and non-stream values that correspond to EmitTriplets in the code are compiled by Emit only. Finally, I fixed a bug in array sorter that would throw an assert on sets with NaNs (compare false to themselves). I'm a little surprised this isn't failing any tests in master.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8171:556,audit,audited,556,https://hail.is,https://github.com/hail-is/hail/pull/8171,1,['audit'],['audited']
Security,"Summary of changes:; - rip out method wrapping from Emit level; - Emit now uses locals everywhere instead of fields; - improved SimplifyControl; - Changed CodeRegion to call Memory directly, instead of calling Region methods. This saves a bytecode on native memory accesses.; - add lir.SplitMethod to break up methods. For large methods, this breaks the body of each basic block into one (or more) external functions and spills locals to fields. Splitting is controlled by SplitMethod.TargetMethodSize, currently set to 2000. PR'ing for testing. I have a few more improvements and then I will performance test. Here are the method sizes after splitting for the large `MakeStruct` example:. ```; is/hail/codegen/generated/C8; <init> 4; apply 235; apply 19; setPartitionIndex 11; addPartitionRegion 5; __wrapped16 30; __wrapped17 2003; __wrapped18 2008; __wrapped19 2006; __wrapped20 2008; __wrapped21 2006; __wrapped22 2008; __wrapped23 2006; __wrapped24 2008; __wrapped25 2006; ... you get the picture, remaining 100 methods elided ...; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8333:265,access,accesses,265,https://hail.is,https://github.com/hail-is/hail/pull/8333,1,['access'],['accesses']
Security,"Support bokeh<3.5 and fix deprecation warnings about using `circe(size=...)`.; Note that `maker=""cicle""` is the default for `scatter`. Resolves #14706. ### Security Assessment; This change has a low security impact from minor dependence changes. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14724:156,Secur,Security,156,https://hail.is,https://github.com/hail-is/hail/pull/14724,3,"['Secur', 'secur']","['Security', 'security']"
Security,Support passing an authorization token to the ServiceBackend.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11435:19,authoriz,authorization,19,https://hail.is,https://github.com/hail-is/hail/pull/11435,1,['authoriz'],['authorization']
Security,"TODO. Goal is all non-stretch items done by late tomorrow night/early Friday morning. Friday - Sunday testing, Cotton takes a closer look on Monday. - [x] No SQL; store user / svc / token labels (all things that need to be validated before redirect); - [x] Websockets; - [x] Service, pod definitions, makefile updates => notebook-v2 service name; - [x] Deploy notebook service, Deploy web service ( say web service name, mapping to web.hail.is ); - [x] Direct modification of gateway: check site service for breaks after each change to prevent user ; - [x] Test in cluster; - [x] Make sure Notebook v1 still works; - [ ] Stretch, and only in v3 so Feb 5 entropy minimized: asynchttp + uvloop; - [ ] Stretch ?: route by pod ip instead of svc name: DNS propagation latency significantly longer than pod instantiation time, which sucks for users, both because notebook instances will look broken when they're not, and because if we mask that the apparent latency to first useful operation is multiples of that needed. new: ; Cotton is right, mysql is adding too much complexity for the minimal use case, esp. with gevent conflicting with PyMySQL, necessitating per route handler connection. old:; Not ready to be merged, would like to improve SQL connection handling. 6a4599df5dfe0affdb5e367dd9cdc70cca59fd17 onward dependent on this. MySQL use is unoptimized because PyMySQL doesn't play well with gevent in the following way: initial impression from reading was that monkey.patch_all() before creation of global connection should result in connection spawned for each new request, or to at least private to a greenlet. Doesn't appear to be the case, plenty of connection errors. So establishing connection within each request, which is slow. . Python C library also out, because it does not play well with Python threading/greenlet/monkey patch implementations. MySQL Connector is an option, provides thread pools, but is also slowest option, by up to 10x, for small requests, like our are likely to be",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215:223,validat,validated,223,https://hail.is,https://github.com/hail-is/hail/pull/5215,1,['validat'],['validated']
Security,TeamCity Security Issues,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/675:9,Secur,Security,9,https://hail.is,https://github.com/hail-is/hail/issues/675,1,['Secur'],['Security']
Security,"Thanks @vladsaveliev, I'll authorize this so we can run it through CI and try to get it through.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10382#issuecomment-831338774:27,authoriz,authorize,27,https://hail.is,https://github.com/hail-is/hail/pull/10382#issuecomment-831338774,1,['authoriz'],['authorize']
Security,"Thanks Tim!. It is easy to fix the Kryo serializers, but the function we need (require) is protected, so we need to use reflection or put something in the Kryo package to access it. Java serializers are trickier. Best I can think of is to have a thread-local pool of something like 8KB blocks to copy to/from.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2218#issuecomment-332209074:171,access,access,171,https://hail.is,https://github.com/hail-is/hail/pull/2218#issuecomment-332209074,1,['access'],['access']
Security,"Thanks for working on this!. Would it be possible to keep the logout button on every page but add a step where it takes the user to the Auth UI to make it work? Specifically, I'm thinking we could add logic to the `/user` route in `auth/auth/auth.py` such that if we pass in the query parameter `logout`, it calls the same code as the `/logout` endpoint, and then replace the `form` and `button` with something like:. ```html; <a href=""https://auth.hail.is/user?logout"">Log out</a>; ```. The tricky part of that might be getting the CSRF token, but since the `/user` page is only accessible by logged in users (because of the `authenticated_users_only` decorator), I *think* there should always be a CSRF token accessible via `request.cookies[""_csrf""]` (e.g. https://github.com/hail-is/hail/blob/main/web_common/web_common/web_common.py#L93).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14639#issuecomment-2258267657:580,access,accessible,580,https://hail.is,https://github.com/hail-is/hail/pull/14639#issuecomment-2258267657,2,['access'],['accessible']
Security,"Thanks guys. Does using cloudtools get the latest build from master, or how can I access this to use?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5436#issuecomment-468746637:82,access,access,82,https://hail.is,https://github.com/hail-is/hail/pull/5436#issuecomment-468746637,1,['access'],['access']
Security,Thanks! That helped. There a couple of other issues that came up that required some tinkering. I list them below in case any one runs into them also. 1. curl failed when trying to download the ibsimdpp lib. The workaround was to download it with wget and move it to the Make Directory. ```; wget --no-check-certificate https://storage.googleapis.com/hail-common/libsimdpp-2.0-rc2.tar.gz; mv libsimdpp-2.0-rc2.tar.gz src/main/c; ```. 2. Needed to compile with newer version of gcc; ```; module load gcc/7.2.0; ./gradlew -Dspark.version=2.2.1 -Dpy4j.version=0.10.4 -Dbreeze.version=0.13.1 shadowJar archiveZip. ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3001#issuecomment-375979411:307,certificate,certificate,307,https://hail.is,https://github.com/hail-is/hail/issues/3001#issuecomment-375979411,1,['certificate'],['certificate']
Security,"Thanks, added with one tweak. Sadly I don't know how to convince your code analyser that using `randint` to make test cases in test code is not a security issue…. Feel free to push to PR branches directly, or just to add things while merging. You folks are the Hail maintainers after all!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14700#issuecomment-2400960303:146,secur,security,146,https://hail.is,https://github.com/hail-is/hail/pull/14700#issuecomment-2400960303,1,['secur'],['security']
Security,"Thanks. @zaczap has a branch with a function exposed that uses it, so may want him in this to comment.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1717#issuecomment-388877364:45,expose,exposed,45,https://hail.is,https://github.com/hail-is/hail/issues/1717#issuecomment-388877364,1,['expose'],['exposed']
Security,The GCP terraform got into a bit of an invalid state during an ambitious but ultimately fragmented migration I was trying to make to modularize the terraform code. The `sql_config` module assumed by the terraform code no longer exists (!) and I've reinstated the database server config resource for the time being until the GCP terraform code is ready to use the new `infra/k8s` module. This also includes the following fixes/cleanup:. - A GSA key/secret for grafana that is required for grafana/create_accounts to work correctly; - Deleting resources related to the `gcr_pull` service account that no longer exists since it isn't used in our codebase.; - Added the cluster role/binding for batch that it needs to use to access developer/test namespaces. This will become relevant soon when I introduce the rest of the changes from #10866 that I now intend to do more gradually. I tested this by applying my changes to my own cluster and restarting auth/auth-driver to validate that the sql config works as intended and using the admin-pod to verify that the `sql-config.cnf` is also correct.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11009:721,access,access,721,https://hail.is,https://github.com/hail-is/hail/pull/11009,2,"['access', 'validat']","['access', 'validate']"
Security,"The Google docs aren't clear about whether the hash needs to be a suffix or prefix: . > add the hash of the sequence number as part of the object name to make it non-sequential. I'm somewhat hesitant to make this change since it means our part outputs are no longer sorted lexicographically, and this property has been very useful in the past.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10836#issuecomment-914241609:47,hash,hash,47,https://hail.is,https://github.com/hail-is/hail/pull/10836#issuecomment-914241609,2,['hash'],['hash']
Security,The Hail source code should have an easy way to expose JVM functions to the expression language,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/763:48,expose,expose,48,https://hail.is,https://github.com/hail-is/hail/issues/763,1,['expose'],['expose']
Security,"The Table ones are kinda broken because they get reordered because the `Struct` constructor hash-orders the fields. This means that `df.row.dtype != df.schema`, which is bad. We can fix this by moving to python 3",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2787#issuecomment-359798042:92,hash,hash-orders,92,https://hail.is,https://github.com/hail-is/hail/pull/2787#issuecomment-359798042,1,['hash'],['hash-orders']
Security,"The VDS combiner is flaky on query on batch on GCP due to issues reading VCFs with intervals. Errors observed:. - BGZ validation errors; - Unexpected end of input. Both of these point to issues in the interface between the `FSSeekableInputStream` that underpins GoogleFS and the `BGZipInputStream` that contains it at least in the presence of more than one seek. Unfortunately, the conditions that reproduce this are rare, and when our clusters are quieter (nighttime) the errors are even less frequent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13356:118,validat,validation,118,https://hail.is,https://github.com/hail-is/hail/issues/13356,1,['validat'],['validation']
Security,"The `*` means that route will be triggered for any request matching the specified URL for any method, be it GET or POST, etc. The reason I needed to make that change is that when envoy makes an authentication request to that endpoint, it uses the HTTP method of the original request. E.g. If I make a POST to https://internal.hail.is/dgoldste/batch/batches/create envoy will authenticate me with a POST request to auth:443/api/v1alpha/verify_dev_credentials. So I can't set that endpoint to be any one method.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12094#issuecomment-1282998946:194,authenticat,authentication,194,https://hail.is,https://github.com/hail-is/hail/pull/12094#issuecomment-1282998946,2,['authenticat'],"['authenticate', 'authentication']"
Security,"The altAllele.nMismatch field isn't accessible trough AST. Given the current implementation, it probably shouldn't be and should be removed from the docs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/730:36,access,accessible,36,https://hail.is,https://github.com/hail-is/hail/issues/730,1,['access'],['accessible']
Security,"The assumption is that the default_ns namespace has a database-server-config that has credentials for the database instance which can be used to create various databases. This is present in default. We will require this is also present for dev namespaces, database-server-config will be the user's private database. devs shouldn't have access to the root database credentials. When we create a test default_ns when running the tests, we also create a ""test_instance"" database that will be used as the database instance inside the tests. database-server-config is only used by CI. Also, there's no reason to use the credentials from batch-pods anymore, so I use the one from default. This will need to go in before I can finish https://github.com/hail-is/hail/pull/7674",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7683:336,access,access,336,https://hail.is,https://github.com/hail-is/hail/pull/7683,1,['access'],['access']
Security,The correct thing is to expose the entrypoint in pipeline/batch_client and add it to the config for a job.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7558:24,expose,expose,24,https://hail.is,https://github.com/hail-is/hail/issues/7558,1,['expose'],['expose']
Security,"The current execution of ; ```; mt.group_rows_by(mt.gene); .aggregate(...); ```; will be emitted as a `MatrixMapRows` (to re-key) followed by a `MatrixAggregateRowsByKey`. This means that the dataset will be shuffled _in full_ to re-sort by gene, before doing the efficient collapsing in `MatrixAggregateRowsByKey`. This is really bad. We need to be doing map-side combines. The preferred execution would be one of two options:; 1. scan to compute the OrderedPartitioner for the new key. Aggregate to this partitioner.; 2. Aggregate to a HashPartitioner. Both of these things involve new map-side combiner architecture which we haven't built yet, but this is important.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3645#issuecomment-391497730:538,Hash,HashPartitioner,538,https://hail.is,https://github.com/hail-is/hail/issues/3645#issuecomment-391497730,1,['Hash'],['HashPartitioner']
Security,"The current main version of the Query Service uses a fresh class loader for every query. This means each driver job and worker job starts with uncompiled classes for any class in Hail. This change uses a shared class loader for all jobs with the same SHA. This enables use of previously JIT'ed Hail classes. This noticeably improves no-op performance from ~8 seconds to ~3 seconds. Most of that remaining 3 seconds is due to Query-on-Batch and Batch, not Query. Currently, Hail generates classes using a counter. When a driver or worker re-uses an old class loader, it would mistakenly re-use classes generated by a previous Hail Query-on-Batch job because they share the same name. This PR avoids that entirely by using a fresh class loader per job for *generated* classes. This PR parameterizes the entire Hail Query system by a class loader. This class loader is passed in from the initiator of the driver or worker job. We could, eventually, re-use class loaders:; - across jobs for a single batch; - across jobs for a single user; - across jobs for a single billing project; - across all jobs. I think the first three are somewhat uncontroversial but we need to fix the class naming problem. The fourth introduces a new security risk. I think we have a lot of performance to squeeze out of QoB before we need to take that step.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11212:1225,secur,security,1225,https://hail.is,https://github.com/hail-is/hail/pull/11212,1,['secur'],['security']
Security,"The default OS for dataproc instances is based on debian8, which uses g++-4.9.x; That has a libstdc++ with an old-ABI implementation of std::list and std::string. To build; a libhail.so which can link against the default libstdc++ on g++-4.x systems, we need to; avoid the use of std::string inside libhail.so (but it's ok to use it in dynamic-generated code,; which will be built with a compiler which matches the libstdc++). This commit introduces a minimal hail::hstring and hail::hstringstream with the necessary; functionality for NativeModule.cpp. Since these don't have a std::hash, I also imported the source code for the (free and uncopyrighted); MurmurHash3, a fast high-quality (but non-crypto) hash function which can give a 128bit hash. ; This simplifies the calculation of the 80bit hash used for module-keys. In addition to using these prebuilt libraries, we also need to get g++ installed on the dataproc; master node, which could be done with ""sudo apt-get install build-essential"". But I'm not yet sure where; that initialization step needs to go.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4422:584,hash,hash,584,https://hail.is,https://github.com/hail-is/hail/pull/4422,4,['hash'],['hash']
Security,"The default is to put the modules in ${HOME}/hail_modules, which in many; environments; would indeed be an NFS directory. It only goes to /tmp/hail_modules if; ${HOME} is undefined. The thinking behind this is that there's a huge amount of re-use of code; for an individual; from one Hail analysis to the next, but probably much less overlap between; different users.; And while multi-user sharing ought to work, it raises potential issues; about file access; permissions which seemed like trouble without a clear benefit. On Fri, Aug 3, 2018 at 10:49 AM Patrick Schultz <notifications@github.com>; wrote:. > *@patrick-schultz* commented on this pull request.; > ------------------------------; >; > In src/main/c/NativeModule.cpp; > <https://github.com/hail-is/hail/pull/3973#discussion_r207567962>:; >; > > +#include <string>; > +#include <vector>; > +; > +#if 0; > +#define D(fmt, ...) { \; > + char buf[1024]; \; > + sprintf(buf, fmt, ##__VA_ARGS__); \; > + fprintf(stderr, ""DEBUG: %s,%d: %s"", __FILE__, __LINE__, buf); \; > +}; > +#else; > +#define D(fmt, ...) { }; > +#endif; > +; > +namespace hail {; > +; > +namespace {; >; > The anonymous namespace can't be named, so no names introduced in an; > anonymous namespace can be referenced from outside the namespace. The; > exception is that on closing an anonymous namespace, it is automatically; > opened into the enclosing namespace. The typical use is to make things; > file-local.; >; > —; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/hail-is/hail/pull/3973#discussion_r207567962>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AJzExuxprnaVF62eonAgCjSmqAERvBJiks5uNGLtgaJpZM4VbZpP>; > .; >",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-410321049:452,access,access,452,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410321049,1,['access'],['access']
Security,"The failure here:; ```; E org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 2.0 failed 1 times, most recent failure: Lost task 6.0 in stage 2.0 (TID 8) (hostname-c5956f6f02 executor driver): java.io.EOFException: Invalid seek offset: position value (6) must be between 0 and 6 for 'gs://hail-services-requester-pays/hello'; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageReadChannel.validatePosition(GoogleCloudStorageReadChannel.java:665); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageReadChannel.position(GoogleCloudStorageReadChannel.java:546); E 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFSInputStream.seek(GoogleHadoopFSInputStream.java:178); E 	at org.apache.hadoop.fs.FSDataInputStream.seek(FSDataInputStream.java:65); ```. I hit this same error in Avro/GVS work recently -- I think the Google Hadoop API connector is wrong in that you cannot seek to the end of a file (N where N is the number of bytes in the file).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12133#issuecomment-1245585700:462,validat,validatePosition,462,https://hail.is,https://github.com/hail-is/hail/pull/12133#issuecomment-1245585700,1,['validat'],['validatePosition']
Security,"The first few lines of a hail log look like:; ```; 2019-12-02 13:20:36 Hail: WARN: This Hail JAR was compiled for Spark 2.4.0, running with Spark 2.4.1.; Compatibility is not guaranteed.; 2019-12-02 13:20:36 SparkContext: INFO: Running Spark version 2.4.1; 2019-12-02 13:20:36 SparkContext: INFO: Submitted application: Hail; 2019-12-02 13:20:36 SparkContext: INFO: Spark configuration:; spark.app.name=Hail; spark.driver.extraClassPath=//miniconda3/envs/hail/lib/python3.7/site-packages/hail/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jar; spark.hadoop.io.compression.codecs=org.apache.hadoop.io.compress.DefaultCodec,is.hail.io.compress.BGzipCodec,is.hail.io.compress.BGzipCodecTbi,org.apache.hadoop.io.compress.GzipCodec; spark.hadoop.mapreduce.input.fileinputformat.split.minsize=0; spark.jars=file:///miniconda3/envs/hail/lib/python3.7/site-packages/hail/hail-all-spark.jar; spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator; spark.logConf=true; spark.master=local[*]; spark.repl.local.jars=file:///miniconda3/envs/hail/lib/python3.7/site-packages/hail/hail-all-spark.jar; spark.serializer=org.apache.spark.serializer.KryoSerializer; spark.submit.deployMode=client; spark.ui.showConsoleProgress=false; ```. But the hail version string isn't here! That would be helpful. The full one with the hash. Rolled the dice, came up John.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7644:1327,hash,hash,1327,https://hail.is,https://github.com/hail-is/hail/issues/7644,1,['hash'],['hash']
Security,"The fix for Notebook is on line 242. Copying from my Zulip post:. > I made a mistake when I implemented TLS.; >; > In the following code snippet we use ssl_client_session which should probably be; > called in_cluster_ssl_client_session. It's supposed to be used to communicate; > with other services in the cluster. That needs to be changed back to; > aiohttp.ClientSession which loads the normal system certificates (including the; > VeriSign root certs that signed the public certs that gateway uses, different; > from the internal certs that our services use).; >; > In particular, note that the error says ""unable to get local issuer; > certificate."" That means that the local trust store lacks a certificate that; > trusts the remote server's certificate. In Dania's case, the default python on; > OS X lacks all certificates, so every remote server is untrusted. In notebook's; > case, ssl_client_session creates an SSL/TLS session that only trusts Hail; > internal services (in particular, it does not trust the certificates that; > gateway uses for incoming public traffic). The error also says that the server; > in question is workshop.hail.is which is a public domain (note the hail.is), so; > that traffic is going through the public gateway with its public certificates.; >; > ```; > # don't have dev credentials to connect through internal.hail.is; > ready_url = deploy_config.external_url(; > service,; > f'/instance/{notebook[""notebook_token""]}/?token={notebook[""jupyter_token""]}'); > try:; > async with ssl_client_session(; > timeout=aiohttp.ClientTimeout(total=1),; > headers=headers,; > cookies=cookies) as session:; > async with session.get(ready_url) as resp:; > ```. I also changed the names and functionality of the functions in tls. Now; `in_cluster_ssl_context` will error if there is no ssl configuration found; instead of silently (and confusingly) using an SSLContext suited for public; communication (and wrong for in-cluster communication). I added `get_context_specific_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9120:404,certificate,certificates,404,https://hail.is,https://github.com/hail-is/hail/pull/9120,6,['certificate'],"['certificate', 'certificates']"
Security,The fix landed after the tagged 0.2.65 release. Can you share the git commit hash that's failing?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10352#issuecomment-829188311:77,hash,hash,77,https://hail.is,https://github.com/hail-is/hail/issues/10352#issuecomment-829188311,1,['hash'],['hash']
Security,"The following command always fails at the write stage:; ```; hail read test.in.vds annotatevariants expr -c 'va = {}' write -o test.out.vds; ```. The traceback is huge, but I've copied what I think is the relevant parts:; ```; log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.lib.MutableMetricsFactory).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 17/01/17 09:24:46 INFO SparkContext: Running Spark version 2.0.2; 17/01/17 09:24:46 INFO SecurityManager: Changing view acls to: marpin; 17/01/17 09:24:46 INFO SecurityManager: Changing modify acls to: marpin; 17/01/17 09:24:46 INFO SecurityManager: Changing view acls groups to:; 17/01/17 09:24:46 INFO SecurityManager: Changing modify acls groups to:; 17/01/17 09:24:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(marpin); groups with view permissions: Set(); users with modify permissions: Set(marpin); groups with modify permissions: Set(); 17/01/17 09:24:46 INFO Utils: Successfully started service 'sparkDriver' on port 37801.; 17/01/17 09:24:46 INFO SparkEnv: Registering MapOutputTracker; 17/01/17 09:24:46 INFO SparkEnv: Registering BlockManagerMaster; 17/01/17 09:24:46 INFO DiskBlockManager: Created local directory at ; /tmp/hail/blockmgr-522fbeb1-5053-4884-9115-5f2af7bd912a; 17/01/17 09:24:46 INFO MemoryStore: MemoryStore started with capacity 15.8 GB; 17/01/17 09:24:46 INFO SparkEnv: Registering OutputCommitCoordinator; 17/01/17 09:24:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.; 17/01/17 09:24:46 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://129.94.72.55:4040; 17/01/17 09:24:46 INFO Executor: Starting executor ID driver on host localhost; 17/01/17 09:24:46 INFO Utils: Successfully started service 'org.apache.s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1260:646,Secur,SecurityManager,646,https://hail.is,https://github.com/hail-is/hail/issues/1260,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,The functions expose Field attributes (useful for VCF header); - Annotations generated using annotate_alleles_expr now have 'Number=A'; - VEP now parses the Description when using csq=True option (required to know the fields stored in the |-delimited field),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1557:14,expose,expose,14,https://hail.is,https://github.com/hail-is/hail/pull/1557,1,['expose'],['expose']
Security,"The goal of this PR is to have all of the JVM container logs available where all the worker logs are. I tagged the entries with ""worker.log"" so they show up with the other worker log entries. However, it's plain text with no timestamp. We can improve the formatting as a separate project. Notice the two entries with ""*"" on the left instead of the normal ""I"". The design choice I made is to have the JVM containers write to a location that is static. We cannot easily change the fluentd configuration dynamically. It requires restarting the daemon which takes 1.5 seconds. Furthermore, the configuration for fluentd is on /etc/ on the host which the batch worker container cannot access. Hence, why I took the approach of specifying it in the startup script at known locations. . Before we merge this, I'd like to confirm that (a) we want these logs and (b) they don't contain any secrets.; <img width=""1585"" alt=""Screenshot 2023-06-16 at 4 06 43 PM"" src=""https://github.com/hail-is/hail/assets/1693348/0ce9f7dc-1188-4c66-ae6f-83fcc3744f95"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13190:680,access,access,680,https://hail.is,https://github.com/hail-is/hail/pull/13190,1,['access'],['access']
Security,"The grafana image runs with user 472, so that user needs access to the `grafana-storage` persistent volume. Setting the `fsGroup` to 472 mounts the volume under that group.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10162:57,access,access,57,https://hail.is,https://github.com/hail-is/hail/pull/10162,1,['access'],['access']
Security,The hashes are appended to the end of the filename. Shouldn't that be enough to ensure distinct names?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13502#issuecomment-1693813463:4,hash,hashes,4,https://hail.is,https://github.com/hail-is/hail/issues/13502#issuecomment-1693813463,1,['hash'],['hashes']
Security,"The interface needs some work, first, but this is probably a ~3 month timeline (the outstanding calls into java are for things like maximal_independent_set, the BlockMatrix linear algebra stuff, and a few utility functions). I'm also happy to take PRs now to change the java.util.HashMaps to java.util.Map",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5340#issuecomment-463827896:280,Hash,HashMaps,280,https://hail.is,https://github.com/hail-is/hail/issues/5340#issuecomment-463827896,1,['Hash'],['HashMaps']
Security,"The issue is we start billing for instances as soon as they're created with the API. However, if an instance is stuck in provisioning and never activates, we never update the start billing time to account for the lack of resource. This PR uses the `lastStartTimestamp` in the [Google REST API](https://cloud.google.com/compute/docs/reference/rest/v1/instances/get). This value is in RFC3339 format. I think this is the same format the timestamp in the activity logs, so I copied how we parse that value. If we delete the instance due to activation timeout, then we set the attempt start time to NULL so it's not billed. I couldn't find good documentation on this, but it seems like the `lastStartTimestamp` approximates what we care about for the purposes of checking for stuck workers. I checked it on an instance that was provisioning and the value was missing. Once the instance was in starting, the value was about 10 seconds after the `creationTimestamp`. . QUESTION: This does raise a question on whether we should be using the `lastStartTimestamp` when billing users if the difference is around 10 seconds. That will be a harder change, but is probably doable. We can't access the `lastStartTimestamp` through the metadata on the worker which would have been the easiest solution. We can get the compute client on the worker and access the `lastStartTimestamp` that way and set the job start time to the instance start time. I'd need to change the database for the attempts trigger to account for this. For the scenario where a job private job is cancelled while creating the instance, we would either need to make the additional API call or we just leave the time we created the instance. Thoughts?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10069:1177,access,access,1177,https://hail.is,https://github.com/hail-is/hail/pull/10069,2,['access'],['access']
Security,The logs you're seeing are the cloud audit logs.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10432#issuecomment-833644335:37,audit,audit,37,https://hail.is,https://github.com/hail-is/hail/pull/10432#issuecomment-833644335,1,['audit'],['audit']
Security,"The main point of this is to isolate the accessors in one place to make changing them easier, e.g. if we want to move the missing bits in structs to pack them more tightly, or make fields required, which is now almost trivial.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2093#issuecomment-321729305:41,access,accessors,41,https://hail.is,https://github.com/hail-is/hail/pull/2093#issuecomment-321729305,1,['access'],['accessors']
Security,The missing permission is `storage.buckets.get` though? It seems reasonable for a user to [be able to read metadata](https://cloud.google.com/storage/docs/access-control/iam-permissions) about their own bucket. I'd wager that jgscm was designed for use with the `roles/storage.legacyBucketWriter` role granted on their bucket. What role are we currently granting?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5788#issuecomment-480372530:155,access,access-control,155,https://hail.is,https://github.com/hail-is/hail/pull/5788#issuecomment-480372530,1,['access'],['access-control']
Security,The old `Table.index` used the `RDD` route which forced a shuffle because all partitioning information was lost. I exposed `zipWithIndex` on `RVD` and used it in both MatrixTable and Table.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3774:115,expose,exposed,115,https://hail.is,https://github.com/hail-is/hail/pull/3774,1,['expose'],['exposed']
Security,"The old bucket did not use uniform access control and also was multi-regional (us). I created a new bucket using the random suffix ger0g which has uniform access control. I also switched the location to us-central1 (not pictured here because that is a variable). I copied all the JARs from `gs://hail-query/jars` to `gs://hail-query-ger0g/jars` using a GCE VM. Again, global-config is not present in our terraform, so I'll have to manually edit that to reflect this new location: `gs://hail-query-ger0g`. The deployment process is:. 1. Edit global-config to reflect new bucket.; 2. Delete batch and batch-driver pods.; 3. Delete old workers. The rollback process (if necessary) is the same. Since this requires wiping the workers, I'll wait for a time when no one is on the cluster to do it. Any users using explicit JAR URLs will need to switch to `gs://hail-query-ger0g/...`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12969:35,access,access,35,https://hail.is,https://github.com/hail-is/hail/pull/12969,2,['access'],['access']
Security,"The only noticeable change after this PR is that devs will be able to access `internal.hail.is/<PR-namespace>/<service>` while it is running and see jobs submitted by tests. Well, that and you can add another developer to a dev namespace as a developer without destroying the developer's existing namespace. Subsequent PRs will introduce on-demand dev namespaces and the ability to suspend the deletion of a test namespace. New context added to the CI pipeline is treated as optional to be backward compatible with the current CI. So devs won't be able to log in to test namespaces on *this* PR but will be able to once this PR becomes main. ### What has changed; - All developers from default are now added to all test namespaces using the `add_users` build.yaml step and removed at the end of the PR run through the `delete_users` step. These use the normal create and delete API instead of copying the user's gsa from the production namespace. This relies on / tests that the delete user endpoint is properly deleting cloud identities when the users are deleted (previously broken in GCP but fixed in this PR.; - The developer role no longer implicitly deletes and recreates a corresponding namespace. I wanted adding developers to test namespaces not to have side-effects that leaked out of the namespace. A follow-up PR will incorporate the ability for a developer to request an on-demand dev namespace, which should be made a lot easier after these changes. I think this also means that we can remove some permissions from the auth K8s ServiceAccount since it no longer needs the ability to create and delete namespaces.; - A fixed-but-sufficient number of oauth2 callbacks are hard-coded into the oauth2 secret from GCP/azure and then allocated to a given namespace. This is fairly self-contained, all that needs to happen is to tell `auth` what callback to use and rewrite those callback urls in gateway to route back to the appropriate auth. This is done only for test namespaces, production ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12751:70,access,access,70,https://hail.is,https://github.com/hail-is/hail/pull/12751,1,['access'],['access']
Security,"The original goal of this PR was avoiding `Try` when we are not using the restartability provided by semantic hashing because I strongly suspect it is related to the loss of stacktraces in exceptions. Unrelatedly, we realized the semantic hash PR changed the semantics of Query-on-Spark even when semantic hash is disabled: previously we would abort RDD writing on the first exception. In Hail 0.2.123 through 0.2.126, the semantics were changed to only crash *after* we already ran every other partition. Two bad scenarios of which I can think:. 1. Suppose the first partition fails due to OOM. We now waste time/money on the rest of the partitions even though we cannot possibly get a valid output. 2. Suppose every partition hits a permission error. Users should get that feedback after paying for O(1) partitions run, not O(N). I created two Backend paths: the normal `parallelizeAndComputeWithIndex` with its pre-0.2.123 semantics as well as `parallelizeAndComputeWithIndexReturnAllErrors` which, as the name says, returns errors instead of raising them. While making this change, I think I found two other bugs in the ""return all errors"" path, only one of which I addressed in this PR:. 1. I'm pretty sure semantic-hash-enabled QoB batch submission is broken because it uses the logical partition ids as job indices. Suppose there are 10,000 partitions, but we only need to compute 1, 100, and 1543. 0.2.126 would try to submit a batch of size 3 but whose job indices are 1, 100, and 1543. 2. Likewise, the Query-on-Spark path returns an invalid `SparkTaskContext.partitionId` which, at best, produces confusing partition filenames. I only fixed the former because it was simple to fix. I wasn't exactly sure what to do about the latter. We should fix that separately because the changes in this PR need to urgently land in the next release to avoid unexpected cost when one partition fails.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14085:110,hash,hashing,110,https://hail.is,https://github.com/hail-is/hail/pull/14085,4,['hash'],"['hash', 'hash-enabled', 'hashing']"
Security,The primary use case I have in mind for this right now is to lower a BlockMatrixCollect node; I don't *think* this can be easily implemented in terms of other nodes. Currently I've only implemented this in Scala but I can expose it in python if necessary.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8073:222,expose,expose,222,https://hail.is,https://github.com/hail-is/hail/pull/8073,1,['expose'],['expose']
Security,"The reason that your original patch fixed the test you created is really the collision of unintended behaviors:. 1. the rebuilt MTs in the MatrixUnionRows in split_multi have different types because of the entry position; 2. the call to `upcast` for the rows was not checking that you were upcasting to a supertype, and was reordering struct fields. Adding an assertion to upcast caused failures elsewhere. I think the attack plan should be as follows:. 1. Add this assertion, and fix the failures caused by it (LD prune tests?); 2. Add the split_multi test, and fix the type violations created during PruneDeadFields rebuild. To make this easier, you can add a bunch of assertions about the type of the rebuilt MatrixIR nodes, which should cause debug-friendly errors.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4585#issuecomment-435486474:419,attack,attack,419,https://hail.is,https://github.com/hail-is/hail/pull/4585#issuecomment-435486474,1,['attack'],['attack']
Security,The reason we didn't expose the other parameters was what if we had 16 core jobs waiting to be scheduled and then we changed the worker pool size to 4 cores.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9285#issuecomment-674986845:21,expose,expose,21,https://hail.is,https://github.com/hail-is/hail/pull/9285#issuecomment-674986845,1,['expose'],['expose']
Security,"The reason we use `java.util.HashMap` there is that the [py4j](https://www.py4j.org/) library will automatically convert Python dicts to `java.util.HashMap` objects. . I don't think you should call this method, though. We are in the process of completely separating the front end Python from the back end execution engine. Soon, all IR execution from Python will be done by calling [`Backend.execute`](https://github.com/hail-is/hail/blob/master/hail/python/hail/backend/backend.py). The `SparkBackend.executeJSON` should be the target for IR execution right now, I think. *Edit: s/LocalBackend/SparkBackend/*",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5340#issuecomment-463308529:29,Hash,HashMap,29,https://hail.is,https://github.com/hail-is/hail/issues/5340#issuecomment-463308529,2,['Hash'],['HashMap']
Security,"The router resolver incorrectly assumed the contents of the `Authorization` header was a session; id. In fact, the structure of that header and X-Hail-Internal-Authorization is:. ```; Bearer SESSION_ID; ```. where `SESSION_ID` is a 44 base64 characters representing a 32 byte secret session id. I also took this opportunity to centralize the parsing of bearer headers as; `gear.maybe_parse_bearer_header`. ---. This caused a failure because router-resolver, when checking that a user is properly authenticated,; would send:. ```; Bearer Bearer SESSION_ID; ```. which failed the 44-byte length check in auth/front_end.py.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9919:61,Authoriz,Authorization,61,https://hail.is,https://github.com/hail-is/hail/pull/9919,3,"['Authoriz', 'authenticat']","['Authorization', 'authenticated']"
Security,The script in question is located at: gs://danking/1_Generate_Variant_Stats_NVXvC_v1.py . Ping me if you need access.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960#issuecomment-1791061741:110,access,access,110,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1791061741,1,['access'],['access']
Security,"The security issues with sharing CI pages is a bit frustrating for external committers like yourself. I've picked up this PR here: https://github.com/hail-is/hail/pull/10220 and I'll get it to tests passing. We'll keep working towards making the CI pages open to the public. Once that PR is done, I'll have you push the commits to this branch and get it merged.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10085#issuecomment-806046631:4,secur,security,4,https://hail.is,https://github.com/hail-is/hail/pull/10085#issuecomment-806046631,1,['secur'],['security']
Security,"The test `testMatrixUnionRowsMemo` is still failing with this change. The error that I am seeing is:; ```; java.util.NoSuchElementException: key not found: RefEquality(MatrixMapRows(MatrixMapRows(MatrixLiteral(...),InsertFields(SelectFields(Ref(va,struct{rk: int32, r2: struct{x: int32}, r3: array<struct{rr: int32}>, `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`: array<struct{e1: float64, e2: float64}>}),WrappedArray(rk, r2, r3)),List((the entries! [877f12a8827e18f61222c6c8c5fb04a8],GetField(Ref(va,struct{rk: int32, r2: struct{x: int32}, r3: array<struct{rr: int32}>, `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`: array<struct{e1: float64, e2: float64}>}),the entries! [877f12a8827e18f61222c6c8c5fb04a8]))))),InsertFields(SelectFields(Ref(va,struct{rk: int32, r2: struct{x: int32}, r3: array<struct{rr: int32}>, `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`: array<struct{e1: float64, e2: float64}>}),WrappedArray(rk, r2, r3)),List((the entries! [877f12a8827e18f61222c6c8c5fb04a8],GetField(Ref(va,struct{rk: int32, r2: struct{x: int32}, r3: array<struct{rr: int32}>, `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`: array<struct{e1: float64, e2: float64}>}),the entries! [877f12a8827e18f61222c6c8c5fb04a8])))))); 	at scala.collection.MapLike$class.default(MapLike.scala:228); 	at scala.collection.AbstractMap.default(Map.scala:59); 	at scala.collection.mutable.HashMap.apply(HashMap.scala:65); 	at is.hail.expr.ir.Memo.lookup(RefEquality.scala:32); 	at is.hail.expr.ir.PruneSuite$$anonfun$checkMemo$1.apply(PruneSuite.scala:47); 	at is.hail.expr.ir.PruneSuite$$anonfun$checkMemo$1.apply(PruneSuite.scala:46); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at is.hail.expr.ir.PruneSuite.checkMemo(PruneSuite.scala:46); 	at is.hail.expr.ir.PruneSuite.testMatrixUnionRowsMemo(PruneSuite.scala:412); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4891#issuecomment-444264952:1381,Hash,HashMap,1381,https://hail.is,https://github.com/hail-is/hail/pull/4891#issuecomment-444264952,2,['Hash'],['HashMap']
Security,"The test is fixed, we don't use encryption to talk to the internal gateway. I had to fix https.client_session to handle the gce case.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9862#issuecomment-758202690:32,encrypt,encryption,32,https://hail.is,https://github.com/hail-is/hail/pull/9862#issuecomment-758202690,1,['encrypt'],['encryption']
Security,"The tests need to install a previous version of Hail and verify that files written by the current version under test can be ready by older versions. That ""older version"" might be the change itself in the case that the file format version is being bumped. I'm not 100% sure how to specify that version because we won't know the hash on master until after merge. Hmm.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8249:327,hash,hash,327,https://hail.is,https://github.com/hail-is/hail/issues/8249,1,['hash'],['hash']
Security,"The to-do list is roughly. - [ ] Get genome reference type in Variant, Interval, and Locus constructors in function registry; - [ ] Add default reference to HailContext ; - [ ] Add default reference to a bunch of RDD methods; - [ ] Expose genome reference in Python interface with import methods and as an input argument to TVariant(), etc.; - [ ] Make sure #2226 solves the problem of variant, locus, and interval methods having the correct function generated dependent on the genome reference; - [ ] Double check that if a user adds a new genome reference, it is visible on all workers.; - [ ] Add GenomeReference python class to documentation; - [ ] Convert GenomeReference -> ReferenceGenome (Jon's request); - [ ] Remove methods from Variant that do not take a GenomeReference as a parameter (Right now, everything is still hardcoded as GRCh37). I vaguely remember some debate on whether these functions should be removed from Variant completely and instead only called from GenomeReference.; - [ ] At some point, we may want to change Variant etc. so they store the contigIndex rather than the contig.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2208#issuecomment-332347245:232,Expose,Expose,232,https://hail.is,https://github.com/hail-is/hail/pull/2208#issuecomment-332347245,1,['Expose'],['Expose']
Security,"There are many global config fields that CI needs in order to template build.yaml jobs that are threaded through to CI with environment variables. However, these variables are never actually used by CI and they introduce some needless dependencies to run CI (you need a GCP_PROJECT, for example, even though CI doesn't care at all). Instead of setting specific environment variables for each field that build.yaml steps need, I instead mount the global-config (read-only) to the CI container and read in the whole thing. This does potentially expose more variables to the build.yaml environment than there were previously, but I argue that none of those should be sensitive anyway or maybe don't belong in the global-config (which shouldn't be sensitive). This in part makes the process of adding global config fields easier, since right now you need separate PRs to 1) introduce the field to CI and then 2) use it in a new build.yaml step. It also makes the CI deployment.yaml cloud-agnostic. . cc @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10911:543,expose,expose,543,https://hail.is,https://github.com/hail-is/hail/pull/10911,1,['expose'],['expose']
Security,"There are three ways to represent a homogenous set of named values of type `T`.; 1. an `array<T>` and a `dict<str, int>`, the values are stored in the array and the names are stored in a separate dictionary mapping names to their indices; 2. a `dict<str, T>`, the name-value pairs are stored as dictionary key-value pairs; 3. a `struct{name1: T, name2: T, ... nameN: T}`, the name-value pairs are stored as field name, field string pairs. The third option is the most space efficient: the type stores the field names and there is no bookkeeping overhead per-set-of-named-values. The first two options repeat the field names for each occurrence (in particular, consider a Table field or MatrixTable entry-indexed field). The first two options needlessly encode the length (which is statically known). The third option is the most access-time-efficient: the offset of any named-value is known at hail compile time. The first two options require a logarithmic search of hail's dictionary tree representation. The third option is more user-friendly for accessing: `x.name`. The first is the least user-friendly: `x[indices[""name""]]`. The first and third options are the most cache-friendly for homogenous operations. The first uses `ArrayExpression.map`, so code size is `O(CODE)`. The third option's code size is `O(CODE * #VALUES)` because structs have no `map`-like primitive. The third option is also not user-friendly for homogenous operations (the user must repeat the code for each name-value pair). The third is the most self-documenting option. The number of fields and their names are visible in `ds.describe()`. The first is the next best because the dictionary is likely a global field that can be viewed with `x.indices.show()`. ---. ## Phase 1; Implement a new virtual type `tstaticdict<T, name1, name2, ..., nameN>` who's physical type is `PStruct` with N fields. These changes span Scala and Python. Implement `map` and `__getitem__` on `StaticDictExpression`s. `map` is implemented by cod",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6881:829,access,access-time-efficient,829,https://hail.is,https://github.com/hail-is/hail/issues/6881,1,['access'],['access-time-efficient']
Security,There is a function in scala to compute the global position of a locus along the reference genome. I'd like to expose it in python as a method on a LocusExpression so I can use it to make Manhattan plots.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3812:111,expose,expose,111,https://hail.is,https://github.com/hail-is/hail/pull/3812,1,['expose'],['expose']
Security,"There is no requirement to support many OSes. We only have to support two platforms: recent Linux and OSX. They have variants but should be mutually compatible. Testing on Dataproc + recent version of Ubuntu or Debian (which we do in the CI) seems fine. OSX has flags for version support, we can just pick a version (10.10, say) and build for that and beyond. As I've said before, we control what we support and there is no need to make this a burden on ourselves. > If you build your own compiler + library, then you risk becoming incompatible with other libraries. Yes, we should ship with all our C++ dependencies. You convinced me of this? Then there is no issue. BLAS is a C library, so no issue there. Right now I think that just means the compiler and the standard library. > Probably not something I could do in the limited time available. Fair. I'm happy with partial progress in in the above direction, but this seems like a step backwards and something we will want to revert soon. I'm not inclined to go in this direction. Not having access to the standard library seems problematic. > Confirmed that this prebuilt libhail.so can run tests with HAIL_ENABLE_CPP_CODEGEN=1 on a dataproc node with the default 1.2 image (debian8 and g++-4.9.2). Did you test submitting jobs to the cluster itself? This can be quite a different environment than the tests. Also, is there a plan about how users (or we) control this in the Dataproc setting? E.g. how do we submit cluster_sanity_check.py with and without C++ codegen enabled?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4422#issuecomment-424759448:1046,access,access,1046,https://hail.is,https://github.com/hail-is/hail/pull/4422#issuecomment-424759448,1,['access'],['access']
Security,There were no other open holes from the Security Notes.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/675#issuecomment-245383880:40,Secur,Security,40,https://hail.is,https://github.com/hail-is/hail/issues/675#issuecomment-245383880,1,['Secur'],['Security']
Security,"These actually all pass, much to my surprise, because we're; doing great IR sanitization in Python. I have some changes in; another branch that introduced bugs that tests like this will; make easier to debug. It's quite satisfying to add a PR with only tests and no code changes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5961:76,sanitiz,sanitization,76,https://hail.is,https://github.com/hail-is/hail/pull/5961,1,['sanitiz'],['sanitization']
Security,"These changes enable hailctl clusters to work correctly in an Broad GCP Security Best Practices configured project, with minor hail-specific set-up. See further details in team chat.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7978:72,Secur,Security,72,https://hail.is,https://github.com/hail-is/hail/pull/7978,1,['Secur'],['Security']
Security,"This PR adds support for Azure SAS tokens in QoB. A SAS token is basically a blob storage URI with a short-lived credential to access that resource appended as a URL query string. In such a scenario where the FS receives a blob URI with a SAS token, that token should be used instead of the latent credentials on the system. Most of the changes to the `AzureStorageFS.scala` are to parse out a SAS token from blob names. This change brings with it a couple caveats. Unfortunately it is not possible to truly disambiguate a SAS token from a glob pattern, or even just a normal blob filename. So we take what is probably a safe assumption and look to see if there exists a query-parameter style key-value pair after the last `?` in the blob name. If this is the case, we treat everything after the last `?` as a SAS token. If this condition is not satsified, we say there is no SAS token and treat the whole path as the blob name. This logic already exists in python, but I'm open to alternatives. Introducing SAS tokens also breaks the way globbing is currently implemented, where it is deemed safe to iteratively append components to the end of a blob URI string. I added an abstract type member to `FS` and instead of a `String` have `globWithPrefix` accept that associated URL type that can properly handle path updates. I'm unclear on the best way to do this w.r.t. the type system, and wasn't quite sure what to put as the associated type for `RouterFS`, which ideally would accept a union of the URL types for the filesystems that it wraps, so some guidance on that would be great if you have any.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13178:127,access,access,127,https://hail.is,https://github.com/hail-is/hail/pull/13178,1,['access'],['access']
Security,"This PR attempts to simplify the use of TLS and HTTP(S) in Hail. The big changes; are in `hail/python/hailtop`. In particular I removed several functions with; confusingly overlapping functionality in `tls.py`. Instead, we now have three; functions:. - `internal_server_ssl_context`; - `internal_client_ssl_context`; - `external_client_ssl_context`. The client context is configured to seek certificates from its peers. Both; internal contexts load the Hail certificate chain specified in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9554:391,certificate,certificates,391,https://hail.is,https://github.com/hail-is/hail/pull/9554,3,['certificate'],"['certificate', 'certificates']"
Security,"This PR begins to expose RowMatrix functions in Python.; - lots of docs; - fixed up parallel options in export; - added add_index option, useful for parallel export; - test of add_index. I broke this out from changes in sparse_block_matrix (v1 on its way, at which point I'll assign this and that) and lmm2. Three key uses for RowMatrix:; - BlockMatrix export; - class of inputs to per-variant LMM (see lmm2 branch); - BlockMatrix to MatrixTable conversion (once I add RowMatrix.toMatrixTable)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3466:18,expose,expose,18,https://hail.is,https://github.com/hail-is/hail/pull/3466,1,['expose'],['expose']
Security,"This PR begins to implement the infrastructure needed for reproducible randomness. The main components are:; * An implementation of the Threefish block cipher, reduced to 20 rounds as in Threefry [1], but keeping the tweak from Threefish (really just the first 64 bits, the second 64 bits are always 0). The specification for Threefish can be found in [2].; * An implementation of the `jdistlib.RandomEngine` interface using Threefish, so that we can continue using the `jdistlib` implementations of sampling from various distributions.; * This has some improvements over the standard Java RNG implementations of random floating point numbers, and of random integers from a specified interval. See comments in the code for details.; * The beginnings of a new type `(S/T)RNGState`. This implements a splittable RNG interface, similarly to [3], but instead of the cascade construction, we use a modification of PMAC [4] to build a psuedo-random function from a blockcipher. This allows us to reorder the processing of blocks of the input, in particular moving computation to compile time as much as possible.; * A simple test suite for the new RNG using a chi-square test. [1] ""Parallel random numbers: as easy as 1, 2, 3"", http://www.thesalmons.org/john/random123/papers/random123sc11.pdf; [2] ""The Skein Hash Function Family"", https://www.schneier.com/wp-content/uploads/2015/01/skein.pdf; [3] ""Splittable pseudorandom number generators using cryptographic hashing"", https://publications.lib.chalmers.se/records/fulltext/183348/local_183348.pdf; [4] ""Efficient Instantiations of Tweakable Blockciphers and Refinements to Modes OCB and PMAC"", https://www.cs.ucdavis.edu/~rogaway/papers/offsets.pdf",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11605:1304,Hash,Hash,1304,https://hail.is,https://github.com/hail-is/hail/pull/11605,2,"['Hash', 'hash']","['Hash', 'hashing']"
Security,"This PR defines a `ReadPartition` IR node which takes a file path, spec, and written/requested row types and reads in the rows in the file. I haven't supported/defined this IR node in either JVM Emit or in python, since for now this node can only exist after a TableRead gets lowered. In order to be able to read the file, I exposed some things to be able to pass in a (java) HadoopConfiguration and use it to create a (C++) InputStream for the decoder; The way these extra arguments are passed into Emit right now are a little hacky, but I've started tidying some stuff up in #5248 and was going to wait on that to write a better way to pipe around potentially unused arguments. Warning: Until #5248 goes in, the ReadPartition IR node will put all the rows into a single region. Since the SparkBackend lowerer/execution is not exposed at the python level, and we're only using it for some small Scala tests right now, I think that's ok; just wanted to note it here.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5326:325,expose,exposed,325,https://hail.is,https://github.com/hail-is/hail/pull/5326,2,['expose'],['exposed']
Security,"This PR enables shuffling in the service. It is stacked on several other PRs, so look only at the; most recent commit. Some highlights:; - Open the public network back up. We should probably make query jobs special so that they can; access the internal network. To do that, batch would need to accept a ""acting on behalf of"" user; account: Query submits the job using its account ""acting on behalf of"" the user. Batch allows; query to use the private network, but for all other purposes, the job is owned by the user. - Allow public access to some the `gcr.io/hail-vdc/query` Docker image. - Automatically rewrite uses of `hailgenetics/` Docker images to their `gcr.io` equivalents. - Move `deploy_address` above `deploy_query` so that query can depend on address (necessary for; shufles). - Fix logging configuration. Services team wants all logs all the time to go to stdout. - Implement lowerDistributedSort using the shuffler. - Allow shuffle ids to be encoded so they can be used in `Literal`.; Unified Split",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9848:233,access,access,233,https://hail.is,https://github.com/hail-is/hail/pull/9848,2,['access'],['access']
Security,"This PR enables users to combine results from multiple independent approx_cdf aggregators, for instance to allow updating quantile summaries when adding new samples. In more detail:; * Change the result type of the internal aggregator to be a lossless representation of the internal state.; * Add a registered function which expose the CombOp of the aggregator.; * Move the function which computes the old result type from the internal state to python.; * Add a flag `_raw` to `approx_cdf` which produces the internal result type, which supports combining; otherwise convert to the old result type.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13935:325,expose,expose,325,https://hail.is,https://github.com/hail-is/hail/pull/13935,1,['expose'],['expose']
Security,This PR exposes `StreamGrouped` IR node in python as a `grouped(group_size)` method on `ArrayExpression`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9278:8,expose,exposes,8,https://hail.is,https://github.com/hail-is/hail/pull/9278,1,['expose'],['exposes']
Security,"This PR exposes the `lower_tail` and `log_p` parameters in `hl.pnorm`, `hl.qnorm`, `hl.pchisqtail`, and `hl.qchisqtail`, per this [feature request](https://hail.zulipchat.com/#narrow/stream/127634-Feature-Requests/topic/log_p.20option.20for.20pnorm.2Fpchisqtail). . While I was at it I made a few other changes, including:; - Added `hl.dnorm` and `hl.dchisq` to allow for computation of normal and chi-squared probability densities.; - Exposed `mu` and `sigma` in `hl.dnorm`, `hl.pnorm`, and `hl.qnorm` so users can specify different mean/sd values if they wish. By default these functions will still use `mu=0` and `sigma=1` for standard normal densities/cumulative probabilities/quantiles if not otherwise specified by the user.; - Added `ncp` parameter to `hl.qchisqtail` to allow users to specify a non-centrality parameter when computing quantiles.; - Added tests for all of these functions to `test_expr.py`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11038:8,expose,exposes,8,https://hail.is,https://github.com/hail-is/hail/pull/11038,2,"['Expose', 'expose']","['Exposed', 'exposes']"
Security,"This PR improves and consolidates several that were pending. It does a few things:. - all values in the file formats are stored natively (encoded), not using json,; - in particular, the globals and cols are not stored in the json, and not loaded when the read is performed by the user (but when it is executed by the backend).; - MT parts (globals, rows, cols, entries) are all stored in separate directories and each is itself a valid Table file; - extensions for MT and Table are no longer enforced; - the metadata now stores an ""RVDSpec"" which is a recipe for reading an RVD. This gives us the flexibility to define new RVD types (e.g. HashedRVD) or modify the existing classes (by forking and adding additional parameters, etc.); - the rows and entries are stored separately and zipped together on read. If dropSamples = true, don't even load the entries.; - created UnpartitionedRVD, cleaned up the RVD interface. fixes: #2810",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2858:639,Hash,HashedRVD,639,https://hail.is,https://github.com/hail-is/hail/pull/2858,1,['Hash'],['HashedRVD']
Security,"This PR is the first iteration of an AsyncFS-based copy interface. It adds RouterAsyncFS.copy. The goal of these changes is to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the sour",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9822:754,checksum,checksum,754,https://hail.is,https://github.com/hail-is/hail/pull/9822,1,['checksum'],['checksum']
Security,"This PR is to enable `hail-az;` file references to contain SAS tokens to enable bearer-auth style file access to Azure storage. Basic summary of the changes:; 	- Update `AzureAsyncFS` url parsing function to look for and separate out a SAS-token-like query string. Note: made fairly specific to SAS tokens - generic detection of query string syntax interferes with glob support and '?' characters in file names; 	- Added `generate_sas_token` convenience function to `AzureAsyncFS`. Adds new `azure-mgmt-storage` package requirement.; 	- Updated `AzureAsyncFS` to use `(account, credential)` tuple as internal `BlobServiceClient` cache key; 	- Updated `AzureAsyncFSURL` and `AzureFileListEntry` to track the token separately from the name, and extend the base classes to allow returning url with or without a token ; 	- Update `RouterFS.ls` function and associated `listfiles` function to allow for trailing query strings during path traversal ; 	- Change to existing behavior: `LocalAsyncFSURL.__str__`no longer returns 'file:' prefix. Done to make `str()` output be appropriate for input to `fs` functions across all subclasses; 	- Updated `inter_cloud/test_fs.py` to generically use query-string-friendly file path building functions; - Updated InputResource to not include the SAS token as part of the destination file name . `test_fs.py` has been updated to respect the new model, where it is no longer safe to extend URLs by just appending new segments with + ""/"" because there may be a query string. But actually running those tests for the SAS case will require some new test variables to allow the test code to generate SAS tokens (`build.yaml/test_hail_python_fs`): ; ```; export HAIL_TEST_AZURE_ACCOUNT=hailtest; export HAIL_TEST_AZURE_CONTAINER=hail-test-4nxei; # Required for SAS testing on Azure; export HAIL_TEST_AZURE_RESGRP=hailms02; export HAIL_TEST_AZURE_SUBID=12ab51c6-da79-4a99-8dec-3d2decc97343; ```; So the SAS case is disabled for now (`test_fs.py`):; ```; @pytest.fixture(param",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12877:103,access,access,103,https://hail.is,https://github.com/hail-is/hail/pull/12877,1,['access'],['access']
Security,"This PR only adds support in the worker and exposes the functionality in the batch client. Another PR will be added to make these changes user facing in the user version of batch. I added the WIP tag because I want to make sure the test passes once before I comment it out. That's because when this PR deploys, the workers will still be the old workers.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8960:44,expose,exposes,44,https://hail.is,https://github.com/hail-is/hail/pull/8960,1,['expose'],['exposes']
Security,"This PR removes the JVM version of Pedigree in favor a Python based one, as a step towards removing unnecessary calls to the JVM altogether. There were already Pedigree python tests I added a few more, and the ones in Scala seem to mostly test functionality that was never exposed to the python interface anyway.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6438:273,expose,exposed,273,https://hail.is,https://github.com/hail-is/hail/pull/6438,1,['expose'],['exposed']
Security,"This PR should fail because the gsa key is not in the test namespace -- I think we should have a second user account for testing. Still to do is to expose all of the user key infrastructure in the batch `Makefile` and `test-locally` in pipeline and ci. At some point, we should consolidate the `google_storage.py` file so not duplicating with `ci`. . But first I wanted to get feedback. @danking @cseed @akotlar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5866:148,expose,expose,148,https://hail.is,https://github.com/hail-is/hail/pull/5866,1,['expose'],['expose']
Security,"This PR splits the old Container class into an Image class, a Task class, and a Container class. The Image class has all the code necessary for pulling, localizing, and extracting images. There are two public methods `pull` and `prune`. The Container class has all the code for setting up networks, ports, overlays, and running the container. The two important public methods are `run` and `get_logs` which subclasses can overwrite. The Task class is a subclass of the Container class. In the future I will add `JVMContainer` which is also a subclass of a Container. There is an open question about what the code is doing with `spec['network']` right now. The validator says it's an optional string, but our code allows booleans and doesn't handle the 'public' case. The last thing to make sure of is the `Timings` class is still correct. I had trouble with getting that right in earlier attempts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11396:660,validat,validator,660,https://hail.is,https://github.com/hail-is/hail/pull/11396,1,['validat'],['validator']
Security,"This PR teaches gear/database.py to respect four more MySQL configuration parameters: `ssl-mode`, `ssl-ca`, `ssl-cert`, `ssl-key`. In particular, we can now turn TLS on or off and rotate keys by simply changing secrets and restarting the services. Since all sql-config secrets (except those in my namespace) currently have no certs, no keys, and no ssl parameters, after this PR merges all services will still use plaintext communications to the database. After this PR merges, I will update the root secret as well as all the service secrets (e.g. sql-auth-user-config) to have a shared client cert/key and our sql database's cert. Moreover I will set `ssl-mode` to `VERIFY_CA` which means (in our world, at least) verify the server's certificate but not the hostname (we use IPs to connect to our sql server) and present your own certificate for verification. Then I will restart all the services. Then I will ban plaintext connections to the database. Then I will PR a change that raises errors if we try to start a service with plaintext connections or unverified connections. I also:; - updated `create_database.py` so that it will propagate these TLS settings, if present, to created secrets, and; - updated CI to use `gear/database.py` and standard sql-config locations. All these parameters are defined by MySQL. We only support three options for [`ssl-mode`](https://dev.mysql.com/doc/refman/5.7/en/connection-options.html#option_general_ssl-mode), the remainder are either unnecessary or not supported (e.g. we have no hostnames so `VERIFY_IDENTITY` is irrelevant).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8433:736,certificate,certificate,736,https://hail.is,https://github.com/hail-is/hail/pull/8433,2,['certificate'],['certificate']
Security,"This PR teaches most of our cluster how to exclusively speak HTTPS instead of; HTTP. The exceptions are:; - from batch-driver to batch workers; - from batch workers to internal-gateway; - to ukbb-rg; - from router to notebook workers; - letsencrypt (oh the irony). ## Changes from Original PR Proposal. ### Root Certificate. I added a secret to default named `ssl-config-hail-root` containing `hail-root-key.pem`, and `hail-root-cert.pem`. Every principal trusts this root. This root trusts every principal. This PR originally prevented clients from speaking to servers with certs they didn't trust. Now everyone trusts everyone. As long as the root key is not leaked this is OK. Only `create_certs` mounts this secret. The key is used to sign every certificate and the cert is included in each principal's incoming and outgoing trust lists. The root certificate and key are never re-created, so our deploys have no downtime and we avoid addressing the rotation problem. I removed all the trust specifications. A later PR will resolve rotation and mTLS. That PR will restore the trust specifications. I didn't change the structure of the secrets (they still have an incoming and outgoing trust list which only contains the root cert) because I need this structure for mTLS anyway. The original PR text follows. ---. ## HTTPS and TLS. HTTP is implemented on TCP/IP. HTTPS is also implemented on TCP/IP and differs; very mildly. After the socket is opened, a TLS [1] connection is established; over the socket. Thereafter, every HTTP message is encrypted and transported by; the TLS machinery. The HTTP protocol is unchanged. The default port fort HTTP is; 80 and the default port for HTTPS 443, however any port may be used. There are currently four versions of TLS, the latest is TLS 1.3. All versions of; SSL are considered insecure. The OpenSSL library implements TLS. There are other implementations, such as; LibreSSL, but they implement roughly the same interface as OpenSSL. The TLS protocol def",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:312,Certificate,Certificate,312,https://hail.is,https://github.com/hail-is/hail/pull/8561,3,"['Certificate', 'certificate']","['Certificate', 'certificate']"
Security,"This PR teaches most of our cluster how to exclusively speak HTTPS instead of; HTTP. The exceptions are:; - from batch-driver to batch workers; - from batch workers to internal-gateway; - to ukbb-rg; - from router to notebook workers; - letsencrypt (oh the irony). The major new build step is `create_certs` which creates a certificate, key, and; list of trusted ""principals"" for each ""principal"". ""Principal"" is a computer; security term referring to an authenticatable identity. In our system, the; services are each unique principals and every client (e.g. the test_batch CI; step) is also a principal. A principal's certificate is a unforgeable proof of; their identity. A principal's ""key"", in our system, is actually a public-private; (i.e. asymmetric) key pair which the client and server use to establish a; symmetric key for each new connection. A list of trusted principals is a list of; certificates. Every incoming connection must provide a certificate in the; trusted list or the server will drop the connection. Every service depends on the `create_certs` step because their deployment's load; secrets created by `create_certs`. The blog service is implemented by Ghost. Ghost only supports HTTP. As a result; we cannot make all network traffic in our cluster TLS-secured. However, we can; use an nginx sidecar on the blog pod which terminates TLS connections and sends; plaintext traffic on the loopback interface to Ghost. Thus, our goal is: no; plaintext traffic on non-loopback interfaces. Readiness and liveness probes cannot use HTTP. Although k8s supports HTTPS, it; does not support so-called ""mTLS"" or ""mutual TLS."" This is fancy verbiage for; servers that require clients to send trusted certificates. We require; this. There is a lot of information in GitHub issues and the Istio web pages; about this, but at the end of the day, kubernetes does not support this. TCP; probes are the best we can do. There [was a; PR](https://github.com/kubernetes/kubernetes/pull/61231) to al",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8513:324,certificate,certificate,324,https://hail.is,https://github.com/hail-is/hail/pull/8513,6,"['authenticat', 'certificate', 'secur']","['authenticatable', 'certificate', 'certificates', 'security']"
Security,"This PR will not be merged as-is, but split along the 3 commits contained within: ; - Add `Coalesce` IR node; - Expose pruning on FilterIntervals relational functions. These should be promoted to full IR nodes, especially after this PR.; - Add `ExtractIntervalFilters` optimizer pass. I also have yet to add tests for the last commit. What does this PR do?. ```python; In [2]: mt = hl.read_matrix_table('data/1kg.rep.mt'). In [3]: mt.filter_rows(mt.locus.contig == '16').count(); Hail: INFO: interval filter loaded 5 of 128 partitions; Out[3]: (384, 284). In [4]: mt.filter_rows(mt.locus.contig == '16').count_rows(); Hail: INFO: interval filter loaded 5 of 128 partitions; Out[4]: 384. In [5]: mt.filter_rows((mt.locus.contig == '16') | (mt.locus.contig == '19')).count(); Hail: INFO: interval filter loaded 10 of 128 partitions; Out[5]: (730, 284). In [6]: mt.filter_rows(hl.literal({'16', '19'}).contains(mt.locus.contig)).count_rows(); Hail: INFO: interval filter loaded 10 of 128 partitions; Out[6]: 730. In [7]: mt.filter_rows((mt.locus.contig == '16') & (mt.locus.position > 10_000_000)).count_rows(); Hail: INFO: interval filter loaded 2 of 128 partitions; Out[7]: 82. In [8]: mt.filter_rows((mt.locus.contig == '16') & (mt.locus.position > 10_000_000) & (mt.locus.position < 12_000_000)).count_rows(); Hail: INFO: interval filter loaded 5 of 128 partitions; Out[8]: 384. In [9]: mt.filter_rows(mt.locus == hl.parse_locus('1:3761547')).count(); Hail: INFO: interval filter loaded 1 of 128 partitions; Out[9]: (1, 284). In [10]: mt.filter_rows(hl.parse_locus_interval('16:20000000-30000000').contains(mt.locus)).count(); Hail: INFO: interval filter loaded 1 of 128 partitions; Out[10]: (35, 284); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5979:112,Expose,Expose,112,https://hail.is,https://github.com/hail-is/hail/pull/5979,1,['Expose'],['Expose']
Security,This PR:; - Replaces Fluentd with Filebeat (Filebeat config based on the recommended kubernetes filebeat config from elastic repo); - Increases elasticsearch storage. ; - Modifies Kibana's security context so that it doesn't run as root (Kibana will print an error message if it's running as root).; - Adds the `decode_json_fields` processor to filebeat so that it parse our structured log messages as json.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6659:189,secur,security,189,https://hail.is,https://github.com/hail-is/hail/pull/6659,1,['secur'],['security']
Security,"This adds `test_storage_uri` and `batch_logs_storage_uri` fields in the global config. In GCP, this meant just copying existing GCS bucket names and prepending `gs://`, which I've done in the terraform and manually in default. For azure, in the terraform I add two storage accounts, `batch` and `ci`, with `logs` and `test` containers, respectively. This felt like an intuitive consolidation of containers under storage accounts that would make permissioning cleaner. E.g. the batch service principal has access to the entire batch storage account, but only to the `test` container in the ci storage account. However, I've not thought about it deeper than that so it might be worth some looking into. Luckily this decision has no impact on application code. There's still more to be done in a follow-up PR to replace instances of `hail_test_gcs_bucket_name` with `test_storage_uri`, but I think this takes care of the batch deployment's dependency on GCS.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11014:505,access,access,505,https://hail.is,https://github.com/hail-is/hail/pull/11014,1,['access'],['access']
Security,"This adds a prometheus statefulset to track metrics like API request latency and uptime. It scrapes pods on a 15s interval and collects prometheus metrics from any container in a pod with `grafanak8sapp` label that exposes an https endpoint `/metrics`.; The batch front end was already exposing prometheus metrics, but I changed it up slightly. For any http endpoint there should be a single metric, `http_request_latency`. Prometheus adds app and namespace metrics so seeing latencies for batch in particular is just a filter applied to this single metric. You can track latency of an endpoint by adding the `@monitor_endpoint` decorator defined in `metrics.py`, which tracks latency as well as number of requests and status code per request, available in the `http_request_count` metric. I also added monitoring to all CI endpoints. This also includes an `up` metric for tracking uptime at the same 15s granularity. I'm not convinced prometheus will suit our finer-grained needs surrounding batch, but it should do well enough in the meantime for our more traditional SLIs and allows to focus on one problem at a time.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10165:215,expose,exposes,215,https://hail.is,https://github.com/hail-is/hail/pull/10165,1,['expose'],['exposes']
Security,This adds support for authenticating with multiple docker registries inside a `BuildImage` CI step instead of just one. This will be necessary for switching to Artifact Registry as we will temporarily be pushing images to both registries during the migration.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12210:22,authenticat,authenticating,22,https://hail.is,https://github.com/hail-is/hail/pull/12210,1,['authenticat'],['authenticating']
Security,"This adds terraform modules for CI azure resources and CI k8s resources. It also many roles to the test account that the batch account has so that we can run PR and test namespaces (internal batch instances use the test account for all the services so the test account needs tons of privilege. It looks scary, but this is the model we currently have). Thanks to #11053, which is the current version of the CI deployment in Azure, this required no change to the CI application code. ### Sidebar; It might look weird that I've added a block here for the kubernetes provider. That is because up until now I've kept all the k8s and azure terraform in separate root modules, so that they need to be `terraform apply`'d separately and therefore their provider blocks were separated as well. While keeping the code isolated is good (the k8s modules can be reused for GCP), putting them in separate apply's was purely because of [this bug](https://github.com/hashicorp/terraform-provider-kubernetes/issues/1028) in the kubernetes provider. I ran into it when experimenting tearing clusters down and putting them back up again. However, it has since proven very cumbersome to manage two different terraform states where one relies heavily on the other and I've changed my mind. The bug in question has a PR forthcoming and is really only a problem when tearing a K8s cluster down and rebuilding it while preserving other terraform state, which isn't something I see us dealing with often past initial development. Thus, I've added the k8s provider block so that I can directly invoke the CI k8s module. I'll follow up with a PR that moves the other k8s module invocations in here as well. If it would help, I can first start with a dev doc detailing our terraform structure (or where I want it to be).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11084:951,hash,hashicorp,951,https://hail.is,https://github.com/hail-is/hail/pull/11084,1,['hash'],['hashicorp']
Security,"This adds the Google Cloud Monitoring and Prometheus datasources to the grafana configuration. I had done this initially by hand in the UI but this is the first step toward reproducible monitoring, and I'll eventually follow up with dashboards as code. The one ""change"" I made is I exposed the prometheus port sitting behind nginx so that grafana can talk directly to prometheus. Currently, there's an nginx sitting in front of prometheus so that the prometheus UI can be exposed at prometheus.hail.is with https and dev authentication. This hasn't changed. Currently though, grafana is piggybacking on this flow by forwarding the user's session (which I set up in the UI), but I couldn't figure out an easy way to set that in the config and it seemed unnecessarily complicated. I ended up going the simpler route of just letting grafana talk to prometheus directly and not go through nginx. The 9090 endpoint is not reachable outside of the cluster. I considered namespacing the prometheus domain (`{{ default_ns.name }}` instead of `default`), but I pretty much never find it useful to spin up my own prometheus. In the rare case I run my own grafana I just point it to the data from default.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10627:282,expose,exposed,282,https://hail.is,https://github.com/hail-is/hail/pull/10627,3,"['authenticat', 'expose']","['authentication', 'exposed']"
Security,"This adds the following pieces of infrastructure:. - Fully scripted bootstrapping process, from creating a managed identity to run terraform through (instead of the current service principal), to creating a VM to run the bootstrap process off of, through all following steps until running bootstrap.py; - Adds the root CA certificate that azure uses to sign the MySQL server certificates so that we can connect to the database with `VERIFY_CA`. Unlike gcp, however, this still doesn't allow us to use mTLS since it doesn't look like we can request a client cert/key for our database. Still this is not so bad for now.; - Creates a separate k8s module for terraform. This currently just holds the global-config and sql-config resources, but establishes a boundary between the cloud-specific terraform and purely k8s terraform. Later on I'll refactor the GCP terraform to use the k8s module so that different clouds can use the same k8s configuration.; - Adds a pool of spot instances to the AKS cluster and adds the required toleration to all of our preemptible deployments. Part of the node selection process for a pod requires that exist a toleration on the pod for every taint on the node. In other words, it is ok for a pod to have redundant tolerations, so it's fine to have azure-specific tolerations even if we're running in gcp.; - Refactor the az-create-worker-image.sh script to complete the entire batch worker image creation process from start to finish. This involved sending a command over ssh that previously had to be executed by hand. This meant we could combine the two-script process into one shell script. This fully matches the google setup we have currently up until running `bootstrap.py`, which is still google-specific, mainly w.r.t. gcp service accounts. The next step is to adapt this to azure, but I think we need to come to a decision about exactly how we're representing application credentials (just service principals vs managed identities?). Once we have that figured o",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10919:322,certificate,certificate,322,https://hail.is,https://github.com/hail-is/hail/pull/10919,2,['certificate'],"['certificate', 'certificates']"
Security,This adds the following terraform capabilities:; - A reserved public IP for the k8s gateway; - A container registry and pull access for the k8s cluster; - A [private link](https://azure.microsoft.com/en-us/services/private-link/) for the mysql database that makes it accessible on the k8s subnet. I haven't set up the config to use the database yet but ensured that the hostname for the database was resolvable from a pod on the cluster. I think this covers most of the azure specific resources that we need. Most of the rest of our terraform for gcp creating k8s secrets for the database config and various service accounts. I'd like to approach that in a single chunk to find out how best to abstract those into modules.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10838:125,access,access,125,https://hail.is,https://github.com/hail-is/hail/pull/10838,2,['access'],"['access', 'accessible']"
Security,"This allows a developer with access inside of the batch worker container to examine currently running `asyncio` tasks inside the worker, get stack traces, examine locals, etc. E.g. ```; monitor >>> ps; 367 tasks running; +---------------------------------------------------------------------------------------------------------------------------------+; | Task ID State Name Coroutine Created Location Since |; +---------------------------------------------------------------------------------------------------------------------------------+; | 140063857549376 PENDING Task-755614 Worker.post_job_started() - - |; | 140063857549584 PENDING Task-755568 Worker.run_job() - - |; | 140063857549792 PENDING Task-755590 Worker.run_job() - - |; | 140063857550000 PENDING Task-755592 Worker.run_job() - - |; | 140063857550208 PENDING Task-755372 RequestHandler._handle_request() - - |; | 140063857550416 PENDING Task-755637 Worker.run_job() - - |; | 140063857550624 PENDING Task-755580 BaseSubprocessTransport._connect_pipes() - - |; | 140063857550832 PENDING Task-752239 Worker.run_job() - - |; | 140063857551040 PENDING Task-755612 Worker.post_job_started() - - |; | 140063857551248 PENDING Task-755610 Worker.post_job_started() - - |; | 140063857551456 PENDING Task-755589 Worker.run_job() - - |; | 140063857551664 PENDING Task-755613 BaseSubprocessTransport._connect_pipes() - - |; | 140063857552288 PENDING Task-755591 Worker.run_job() - - |; ```. Wondering do we want this for production or just to activate in test namespaces?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13439:29,access,access,29,https://hail.is,https://github.com/hail-is/hail/pull/13439,1,['access'],['access']
Security,"This allows the user to specify the cloud platform ('gcp' or 'aws') they are using when accessing datasets via the datasets API and annotation DB. A user running hail on AWS would read from the s3 bucket, and a user running on GCP would read from the gs bucket (can also still read locally from gs bucket with cloud storage connector installed). Not intended for cross-platform use like running a dataproc cluster and trying to access the s3 bucket, or trying to access the gs bucket on an EMR cluster. Will assume user on AWS has their configuration set with their credentials. . Did not have permissions to set up a cluster or EC2 instance on AWS to test, but was able to access all the datasets without issue on a dataproc cluster when using s3a:// prefixes and providing my AWS credentials in the spark config. So these changes should (hopefully) work fine on an EMR cluster with the s3:// client. Everything worked as expected on GCP. Overview of changes:; - Added missing type hints to `load_dataset()` function and methods in `db.py`.; - In `datasets.json`:; - Added AWS urls so now for each version of a dataset in dataset[""versions""], the url entry looks like:; ```; ""url"": {; ""aws"": {; ""us"": ""s3://hail-datasets-us-east-1/...""; },; ""gcp"": {; ""eu"": ""gs://hail-datasets-eu/..."",; ""us"": ""gs://hail-datasets-us/...; }; ```; - In `load_dataset()` function:; - Added `cloud` parameter, set default values to `region='us'` and `cloud='gcp`.; - In `DB` class:; - Added `cloud` parameter to constructor, set default values to `region='us'` and `cloud='gcp`.; - All datasets in `datasets.json` currently end up in the `_DB__by_name` dictionary, even if not annotation datasets. Added line 279 in `db.py` to fix this and filter out datasets that are not annotation datasets (datasets missing ""annotation_db"" key).; - In `Dataset` class:; - Added `cloud` and `custom_config` parameters to `Dataset.from_name_and_json()` to pass to `DatasetVersion.from_json()` to grab correct urls for platform.; - Refac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9605:88,access,accessing,88,https://hail.is,https://github.com/hail-is/hail/pull/9605,4,['access'],"['access', 'accessing']"
Security,"This allows us to not forcibly densify when doing map operations that would otherwise densify, e.g. bm + 1. . This behavior isn't exposed and I don't believe we want to expose it, since preserving the sparsity for functions where f(0) != 0 means we don't uniformly map all the elements of the matrix, but it can be useful in some cases. One thing to be careful about is that this only preserves sparsity at the block level---if any elements have been zeroed out in blocks during a sparsify operation, those will be mapped as usual. (This is because we don't currently preserve information about which elements have been zeroed out due to a sparsify operation.) As an illustration, we'd see:. ```; >>> bm = hl.linalg.BlockMatrix.fill(12, 12, 7, 3); >>> bm = bm.sparsify_band(-1, 1); >>> bm.to_numpy(); array([[7., 7., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],; [7., 7., 7., 0., 0., 0., 0., 0., 0., 0., 0., 0.],; [0., 7., 7., 7., 0., 0., 0., 0., 0., 0., 0., 0.],; [0., 0., 7., 7., 7., 0., 0., 0., 0., 0., 0., 0.],; [0., 0., 0., 7., 7., 7., 0., 0., 0., 0., 0., 0.],; [0., 0., 0., 0., 7., 7., 7., 0., 0., 0., 0., 0.],; [0., 0., 0., 0., 0., 7., 7., 7., 0., 0., 0., 0.],; [0., 0., 0., 0., 0., 0., 7., 7., 7., 0., 0., 0.],; [0., 0., 0., 0., 0., 0., 0., 7., 7., 7., 0., 0.],; [0., 0., 0., 0., 0., 0., 0., 0., 7., 7., 7., 0.],; [0., 0., 0., 0., 0., 0., 0., 0., 0., 7., 7., 7.],; [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 7., 7.]]); >>> bm._apply_map(lambda i: i + 1).to_numpy(); array([[8., 8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],; [8., 8., 8., 1., 1., 1., 1., 1., 1., 1., 1., 1.],; [1., 8., 8., 8., 1., 1., 1., 1., 1., 1., 1., 1.],; [1., 1., 8., 8., 8., 1., 1., 1., 1., 1., 1., 1.],; [1., 1., 1., 8., 8., 8., 1., 1., 1., 1., 1., 1.],; [1., 1., 1., 1., 8., 8., 8., 1., 1., 1., 1., 1.],; [1., 1., 1., 1., 1., 8., 8., 8., 1., 1., 1., 1.],; [1., 1., 1., 1., 1., 1., 8., 8., 8., 1., 1., 1.],; [1., 1., 1., 1., 1., 1., 1., 8., 8., 8., 1., 1.],; [1., 1., 1., 1., 1., 1., 1., 1., 8., 8., 8., 1.],; [1., 1., 1., 1.,",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7573:130,expose,exposed,130,https://hail.is,https://github.com/hail-is/hail/pull/7573,2,['expose'],"['expose', 'exposed']"
Security,"This also fixes the currently broken `delete_*_tables` steps. In the past, all dev and test databases shared the same MySQL Server (with production), so instead of each service getting its own dedicated database, there was one database per dev/test namespace with all the tables for all the services. This made it difficult to reset the database state of a particular service -- you needed to explicitly delete only the tables for that particular service. Nowadays, dev and test databases live on their own MySQL Servers, so each service gets its own database (like in production). This makes it a lot easier to reset a service's database, we just drop the MySQL database for that service. This PR makes that change, deletes all the now unused `delete-*-tables.sql` files, and adds a dev doc explaining how to reset a dev database. The reason these steps were broken is that the sql configs in dev/test namespaces use K8s DNS for the `host`, which does not work out of the box in batch jobs because they are not in the K8s network. There's code in `database.py` that uses the K8s API to resolve the database host to an IP address that the batch jobs can access. This is why I wrote a python script instead of just using `mysql`. I tested these with the following dev deploy, which scrapped everything and I was able to log in after it was done!. ```; hailctl dev deploy -b daniel-goldstein/hail:dev-ns-delete-db -s delete_auth_tables,delete_batch_tables,deploy_batch,add_developers; ```. cc: @sjparsa, @iris-garden given your recent dev namespace woes",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13456:1154,access,access,1154,https://hail.is,https://github.com/hail-is/hail/pull/13456,1,['access'],['access']
Security,"This also means all jobs need to be using a recent version of Hail so that they know how to use access tokens, right? Which version started supporting that?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14059#issuecomment-1836781021:96,access,access,96,https://hail.is,https://github.com/hail-is/hail/pull/14059#issuecomment-1836781021,1,['access'],['access']
Security,"This change anticipates the ContextRDD change wherein `RVD.rdd` will not; be an RDD. Moreover, enforcing an abstraction barrier at the level of; `RVD` will ease changes to the implementation of `RVD`. There are two remaining types of calls that I cannot eliminate:. - uses in BlockMatrix and OrderedRDD2: these two classes are building; new RDDs based on the RVD's rdd, these classes should be considered; within the implementation of the RVD abstraction. Because these two; classes are outside of `is.hail.rvd`, I cannot enforce an access; modifier on `RVD.rdd`. - uses by methods:. - LDPrune: it seems we need a ""GeneralRVD"". - Skat: it seems like some of this could be moved to python actually;; but there is some matrix math that cannot be moved until the expr; lang has efficient small-matrix ops. - MatrixTable.same: I could probably move this if I re-implemented; forall in terms of RVD.aggregate?. - MatrixTable.annotateRowsIntervalTable: really not sure about this; one, this seems like a performance optimization that purposely; reaches through the abstraction to do Smart Things",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3186:533,access,access,533,https://hail.is,https://github.com/hail-is/hail/pull/3186,1,['access'],['access']
Security,"This change combines cloud auth logic that was previously duplicated; between the various `FS` implementations and the `BatchClient`. . The main refactoring is to make the interface between the `ServiceBackend` more; high-level and leave json serialisation to the `BatchClient`. To do this, I've; added a bunch of case classes that resemble the python objects the batch service ; expects (or a subset of the data). To simplify the interface, I've split batch; creation from job submission (update). For QoB, the python client creates the ; batch before handing control to the query driver; batch creation is necessary; for testing only. This change has low security impact as there are minor changes to the creation; and scoping of service account credentials. Note that for each `FS`, credentials; are scoped to the default storage oauth2 scopes for each service.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14684:657,secur,security,657,https://hail.is,https://github.com/hail-is/hail/pull/14684,1,['secur'],['security']
Security,"This change exists as part of larger refactoring work. Herein, I've exchanged; hard-coded contextual strings passed to `ExecutionTimer.time` with implict; contexts, drawing inspiration from scalatest. These contexts are now supplied after entering functions like `Compile` and; `Emit` instead of before (see `ExecuteContext.time`). By sprinking calls to ; `time` throughout the codebase after entering functions, we obtain a nice trace; of the timings with `sourcecode.Enclosing`, minus the previous verbosity. See [1] for more information about what pre-built macros are available. We can; always build our own later. See comments in [pull request id] for example output.; Note that `ExectionTimer.time` still accepts a string to support uses like; `Optimise` and `LoweringPass` where those contexts are provided already.; It is also exception-safe now. This change exposed many similarities between the implementations of query; execution across all three backends. I've stopped short of full unification; which is a greater work, I've instead simplified and moved duplicated result; encoding into the various backend api implementations. More interesting changes are to `ExecuteContext`, which now supports; - `time`, as discussed above; - `local`, a generalisation for temporarily overriding properties of an ; `ExecuteContext` (inspired by [2]). While I've long wanted this for testing,; we were doing some questionable things when reporting timings back to python,; for which locally overriding the `timer` of a `ctx` has been very useful.; We also follow this pattern for local regions. [1] https://github.com/com-lihaoyi/sourcecode; [2] https://hackage.haskell.org/package/mtl-2.3.1/docs/Control-Monad-Reader.html#v:local",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14679:867,expose,exposed,867,https://hail.is,https://github.com/hail-is/hail/pull/14679,1,['expose'],['exposed']
Security,This change has no security impact as it modifies githib issue templates.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14739:19,secur,security,19,https://hail.is,https://github.com/hail-is/hail/pull/14739,1,['secur'],['security']
Security,"This change integrates the C++ code of libhail with the python code as; a python native extension exposed as _hail. It is extremely minimal for; now, containing only small wrappers for the C++ versions of hail virtual; types as python classes/objects. It is completely unused and introduces; python build time dependencies of a C++20 compiler and CMake. The LLVM dependencies should be optional for now as they add a lot to; the binary size without adding any functionality. They will still get; built if they are found. In the future, it may be easier or more desireable to maintain the _hail; module sources as Cython rather than C++, however, for both learning's; sake and ease of compilation, the module is pure C++.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10505:98,expose,exposed,98,https://hail.is,https://github.com/hail-is/hail/pull/10505,1,['expose'],['exposed']
Security,"This change is temporary. I do not intend to keep the extra hop to `auth` on all internal-gateway requests. Once all the TLS changes go in and everything in the cluster is TLS-secured, then I can switch the internal gateway to unconditionally use HTTPS and remove the router-resolver's extra endpoint. I've already deployed this (I need it to get batch tests to pass in my namespace.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8490:176,secur,secured,176,https://hail.is,https://github.com/hail-is/hail/pull/8490,1,['secur'],['secured']
Security,"This changes the Azure database from Azure database for MySQL Single Server to Azure database for MySQL Flexible Server. The major changes are:. - Fixed several small rots across the bootstrap code; - Altered the database module in terraform to use flexible server. This configuration mostly matches what we had with single server, importantly that it is only accessible on our vnet.; - Makes the client key/certificate in the SQLConfig optional (the current use of SQLConfig is a little repetitious and could probably use a refactor).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11423:360,access,accessible,360,https://hail.is,https://github.com/hail-is/hail/pull/11423,2,"['access', 'certificate']","['accessible', 'certificate']"
Security,"This command uploads the intermediate files that are carried between jobs in a batch. Our tests should be sufficient for finding cases where the downloads are not possible. The container that downloads files (the setup container) uses the google alpine sdk image:; ```; # docker run google/cloud-sdk:237.0.0-alpine gsutil version -l; Unable to find image 'google/cloud-sdk:237.0.0-alpine' locally; 237.0.0-alpine: Pulling from google/cloud-sdk; 6c40cc604d8e: Pull complete ; ef6547e2e20f: Pull complete ; Digest: sha256:fc5a5a88eb49e646adac05ac6a352219d3d676a122fca0b90a2ae2ab091222bb; Status: Downloaded newer image for google/cloud-sdk:237.0.0-alpine; gsutil version: 4.37; checksum: 4b1e288eec2f799d8d0022adccf678cb (OK); boto version: 2.49.0; python version: 2.7.15 (default, Jan 24 2019, 16:32:39) [GCC 8.2.0]; OS: Linux 4.9.125-linuxkit; multiprocessing available: False; using cloud sdk: True; pass cloud sdk credentials to gsutil: True; config path(s): No config found; gsutil path: /google-cloud-sdk/bin/gsutil; compiled crcmod: True; installed via package manager: False; editable install: False; ```. The upload container uses batch_image, which does not have crcmod. I'm not sure it's required, but I'll add it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7024#issuecomment-529589965:676,checksum,checksum,676,https://hail.is,https://github.com/hail-is/hail/pull/7024#issuecomment-529589965,1,['checksum'],['checksum']
Security,"This consolidates all the apt-get dependencies into one line and brings them into line with [Dockerfile best practices](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#run). It also sets the default user to a non-root user, thus limiting what can go wrong if we have security holes in the PR builder.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4221:293,secur,security,293,https://hail.is,https://github.com/hail-is/hail/pull/4221,1,['secur'],['security']
Security,"This copies all the artifacts into place, but doesn't update the latest hash. Once we verify the files look correct after one round of deploy, I'll comment in the code to update latest hash. This script is basically copied exactly from the old hail/hail-ci-deploy.sh.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6174:72,hash,hash,72,https://hail.is,https://github.com/hail-is/hail/pull/6174,2,['hash'],['hash']
Security,"This currently is exposed in `read_table` and `read_matrix_table` as; undocumented optional parameters `_intervals` and `_filter_intervals`; which takes a list of python `Interval`s that are used either as; a filter or a repartition. This adds an `IndexedRVDSpec` as the primary container format for; indexed data, and increments the file version to 1.1.0. One index file is written per partition. For matrix tables, the offset; to a particular key for the entries is stored in the `entries_offset`; field of the annotation that an index may contain. We use the new; `IndexSpec` to retrive the appropriate offset from the index so that we; can seek to the proper offset in the partition. When writing data with a blocked spec (like the default) we use virtual; index offsets similar to tabix. The high 48 bits are used to indicate; the file offset to the start of a block, and the low 16 bits are used to; indicate the offset from the start of the (possibly decompressed) block. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6266:18,expose,exposed,18,https://hail.is,https://github.com/hail-is/hail/pull/6266,1,['expose'],['exposed']
Security,"This exposed a problem with typecheck - you can't check arguments that need to be the class you're defining, like `concordance` or `join`. . I marked these as `anytype` for now. I will ruminate on this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1826#issuecomment-301944755:5,expose,exposed,5,https://hail.is,https://github.com/hail-is/hail/pull/1826#issuecomment-301944755,1,['expose'],['exposed']
Security,This exposes a bug in the pruner in test_tdt that I'm still investigating.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5132#issuecomment-454277066:5,expose,exposes,5,https://hail.is,https://github.com/hail-is/hail/pull/5132#issuecomment-454277066,1,['expose'],['exposes']
Security,"This exposes functionality previously present in the private `hail.expr.functions._allele_ints` and `hail.expr.functions._num_allele_type`, used to avoid strings in the query when determining allele type. Implement AlleleType as a python [IntEnum]. Replace `_num_allele_type` with the now public `numeric_allele_type`. As a note to developers of hail, it is _unlikely_ that the enum values of AlleleType will change, but they are documented as though they could. CHANGELOG: Exposed previously internal `_num_allele_type` as `numeric_allele_type` and deprecated it. Add new `AlleleType` enumeration for users to be able to easily use the values returned by `numeric_allele_type`. [IntEnum]: https://docs.python.org/3/library/enum.html#enum.IntEnum",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14360:5,expose,exposes,5,https://hail.is,https://github.com/hail-is/hail/pull/14360,2,"['Expose', 'expose']","['Exposed', 'exposes']"
Security,This fails currently. I want CI and eyes on this. Validation errors.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7803#issuecomment-571280175:50,Validat,Validation,50,https://hail.is,https://github.com/hail-is/hail/pull/7803#issuecomment-571280175,1,['Validat'],['Validation']
Security,"This fixes the notebook2 deployment permission issue that was resulting in CrashLoopBackoff (no permissions for the Table class to `read_namespaced_secret('get-users', 'default')`). Already tested, works (notebook2 back up). It also fixes an apparent error in the master branch RoleBinding. This diff looks slightly weird. I fixed the existing notebook Roles/RoleBindings by deleting the `create-services` `Role` and `notebook-create-services` `RoleBinding`, and then fixing the broken `notebook-create-servivces-and-pods` `RoleBiding`, by correctly updating the `roleRef` to read `create-services-and-pods`. When notebook1 totally goes away, we can probably remove the ""services"" permission. Before:; ```yaml; ---; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: create-services; rules:; - apiGroups: [""""]; resources: [""services""]; verbs: [""*""]; ---; kind: RoleBinding; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: notebook-create-services; subjects:; - kind: ServiceAccount; name: notebook; namespace: default; roleRef:; kind: Role; name: create-services; apiGroup: """"; ---; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: create-services-and-pods; rules:; - apiGroups: [""""]; resources: [""services""]; verbs: [""*""]; - apiGroups: [""""]; resources: [""pods""]; verbs: [""*""]; ---; kind: RoleBinding; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: notebook-create-services-and-pods; subjects:; - kind: ServiceAccount; name: notebook; namespace: default; roleRef:; kind: Role; name: create-services #this was causing the error, and of course the create-services role is superseded by the the create-services-and-pods role; apiGroup: """"; ---; ```. After:; ```yaml; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: create-services-and-pods; rules:; - apiGroups: [""""]; resources: [""services""]; verbs: [""*""]; - apiGrou",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5746:745,authoriz,authorization,745,https://hail.is,https://github.com/hail-is/hail/pull/5746,2,['authoriz'],['authorization']
Security,"This flag was once used when we used custom hail tokens for authenticating with Batch. Now, we use GCP or Azure access tokens to auth requests so this flag is no longer necessary.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14417:60,authenticat,authenticating,60,https://hail.is,https://github.com/hail-is/hail/pull/14417,2,"['access', 'authenticat']","['access', 'authenticating']"
Security,"This has been unused for a long time and I wanted to rid the world of it. This changes the client to no longer send the `mount_docker_socket` field, updates the validator so it's ok for that field to be missing, and explicitly rejects any requests where `mount_docker_socket` is set to true. The reason I couldn't remove `mount_docker_socket` entirely from the codebase is older clients would break if it was not at least optional in the validator spec, which is kind of annoying. Dev deployed this and successfully submitted jobs using the client from this branch and the client from main.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12973:161,validat,validator,161,https://hail.is,https://github.com/hail-is/hail/pull/12973,2,['validat'],['validator']
Security,"This inspect command prevents us from updating a tag, for example, if we need to replace an image with a security problem or if there is a bug like the one fixed by https://github.com/hail-is/hail/pull/13536.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13538:105,secur,security,105,https://hail.is,https://github.com/hail-is/hail/pull/13538,1,['secur'],['security']
Security,"This introduces a new version of the batch worker instance: one without `docker`. Instead we bring in `podman` to cover the functions of pulling images, extracting expanding filesystems from those images, and running the worker container. `podman` by default uses `crun` as its low-level runtime so we can get rid of the independent `crun` installation in the worker image. `podman` is daemonless and can be run rootless. For the most part you can't tell the difference, except this makes `podman` easy to run under multiple users with different caches per user. So if you ssh into a worker, be sure to `sudo` before any `podman` (or `crun`) command or else you might think nothing is running when in fact the worker is running under root's podman configuration. The podman/crun state directories are now shared between the host and the worker so `sudo crun list` on the worker should reveal the running job containers without having to exec into the worker first. For the most part, `podman` is a drop-in replacement for `docker`, but there are a handful of inconsistencies that comprise most of this PR. One notable change is that we no longer persist any GCR credentials in the worker VM image so we authenticate again on start up. cc: @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10693:1203,authenticat,authenticate,1203,https://hail.is,https://github.com/hail-is/hail/pull/10693,1,['authenticat'],['authenticate']
Security,"This is a name to IP address and port service. GKE exposes pod IPs onto our VDC; network. As such, regular Google Cloud VMs can access pods by IP. GKE cannot; expose our services as IPs on our VDC because the way services load balance; traffic is more complex than DNS can handle. We acknowledge and accept the; limitations of client-side load balancing. In particular, if there are not many; clients and clients re-use address-port-pairs traffic will likely be; unbalanced. This is not a problem for the planned Shuffle service because the; clients are intended to be numerous (consider all the workers in a Query or; Batch pipeline). The big change is that deploy config now has an `addresses` function which will; return a list of address-port pairs. Deploy config also now has `address` which; randomly chooses one of the address-port pairs. I have included a simple test. Please review both code and overall design, considering how it fits in the wider system.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9129:51,expose,exposes,51,https://hail.is,https://github.com/hail-is/hail/pull/9129,3,"['access', 'expose']","['access', 'expose', 'exposes']"
Security,"This is a prototype for just build 37. My plan is to add other genome builds, expose as variable in HailContext, and add support for reading JSON from a file not in the Java resources in subsequent PRs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1780:78,expose,expose,78,https://hail.is,https://github.com/hail-is/hail/pull/1780,1,['expose'],['expose']
Security,"This is all passing except check_batch is running in an image on python 3.6 and the worker is on python 3.7. The process initializer isn't exposed until 3.7. I think I need to change the base image, but am worried about breaking Hail and other dependencies. Otherwise, I can just pass the key file path and the project and create the credentials and gcs client each time a function is called rather than once per process. This will make it slower for small files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8368#issuecomment-607588305:139,expose,exposed,139,https://hail.is,https://github.com/hail-is/hail/pull/8368#issuecomment-607588305,1,['expose'],['exposed']
Security,"This is an initial implementation of the Scala Region as a reference to a C++ off-heap object. The C++ Region allocates ""small"" blocks out of 64KB chunks, and ""large"" blocks using; malloc() directly. There's a clear_but_keep_mem() which reuses all the 64KB chunks,; and the largest few individual allocations. The usefulness of this strategy is TBD. Currently all allocations are done with a JNI call to the C++, but fields of the object are; directly accessible so it's theoretically possible to try to write optimized Scala code; for the case of a small allocation which can fit in the current chunk. The other changes are mostly consequences of using absolute addresses rather than; offset-in-contiguous-buffer, and the change in the semantics of appendFoo() when a; Region's memory is in non-contiguous chunks - things which need to be located together,; such as the length of a string and its contents, now have to be within memory from a; single allocate() call.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3718:452,access,accessible,452,https://hail.is,https://github.com/hail-is/hail/pull/3718,1,['access'],['accessible']
Security,This is by design. The square bracket syntax is for joining two distinct matrix tables. To access a specific row and column do this:; ```; mt = mt.filter_rows(mt.row_key = 1); mt = mt.filter_cols(mt.col_key = 1); mt = mt.entry.collect()[0]; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9704#issuecomment-1145282437:91,access,access,91,https://hail.is,https://github.com/hail-is/hail/issues/9704#issuecomment-1145282437,1,['access'],['access']
Security,"This is caused by domain-by-domain CSRF tokens introduced in [#14180](https://github.com/hail-is/hail/issues/14180). An unfortunate side effect is that the tokens available on non-auth pages are no longer able to validate requests to the auth/logout API. Given the lack of apparent noise about this bug in our issues and zulip I suspect that this is not a common path for users, and that a fix along the lines of ""require add one button click to go to the User page first before logging out is acceptable"". On the other hand, the risk of a user clicking on the broken Logout button and believing themselves to be logged out when seeing a `401: Unauthorized` page (but actually still having logged-in state in their browser) raises this in my mind to a security bug rather than just a UX bug or an unfortunate user experience. Therefore my proposal is:; 1. To fix the bug as soon as possible; 2. Accept an additional redirect in a user flow which is rarely exercised; 3. To make the smallest number of potentially risky changes to the underlying security architecture; 4. Therefore: Remove the broken ""log out"" link in page headers and replace with a Log out button on the auth[...]/users page which is guaranteed to have the correct CSRF token in state.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14635#issuecomment-2253086187:213,validat,validate,213,https://hail.is,https://github.com/hail-is/hail/issues/14635#issuecomment-2253086187,3,"['secur', 'validat']","['security', 'validate']"
Security,"This is due to FSs in `hailtop.fs` never getting closed. Unfortunately we exposed functions on a module, not a context manager. Options include; 1. adding a `hailtop.fs.close` method; 2. Using a new `RouterFS` on every `hailtop.fs` method; 3. Have users instantiate a `RouterFS` as a context manager and use that. Among these options I prefer 2 and 3. I think using a standalone function instead of properly allocating a context manager can be a convenience/performance tradeoff. 3 could use a bit of thought though as it adds more user-facing API.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14280#issuecomment-1936521020:74,expose,exposed,74,https://hail.is,https://github.com/hail-is/hail/issues/14280#issuecomment-1936521020,1,['expose'],['exposed']
Security,"This is good. We should do the same thing with IntIterator, etc. (Maybe call it `SIterator` for specialized iterator?). A few remarks:. - Looking over the bytecode, making the members private[this] makes the bytecode much tighter since it doesn't generate accessor methods for b and size_. I'll make a quick PR for this. - Even tho ArrayBuilder is invariant, the specialized versions extend ArrayBuilder[Object] and implement all the generic, unspecialized methods. That worries me, but I don't know why it would ever get called. Maybe for backward compatibility to code compiled without specialization?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1549#issuecomment-287082175:256,access,accessor,256,https://hail.is,https://github.com/hail-is/hail/pull/1549#issuecomment-287082175,1,['access'],['accessor']
Security,"This is half code cleanup and half guardrail. The key assertion here is: if the request authenticates using a cookie and is attempting a state-changing HTTP method, it should pass a CSRF check. I tested this with the following:; 1. dev deployed and loaded the billing projects page; 2. Deleted the hidden csrf input from one of the forms; 3. Submitted the form; 4. Got a 401",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13604:88,authenticat,authenticates,88,https://hail.is,https://github.com/hail-is/hail/pull/13604,1,['authenticat'],['authenticates']
Security,This is helpful for running Dataproc with a service account without access to all buckets in a GCP project. #assign services,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12130:68,access,access,68,https://hail.is,https://github.com/hail-is/hail/pull/12130,1,['access'],['access']
Security,This is needed for future genome reference pull requests to be able to access the ordering from the GenomeReference after the variable GR has been substituted for.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2528:71,access,access,71,https://hail.is,https://github.com/hail-is/hail/pull/2528,1,['access'],['access']
Security,"This is part of a minor bug-fix for how CI tracks active namespaces in development environments. #12093 added a table in CI's database that tracks the namespaces that CI is currently aware exists and that it manages. Non-production CIs don't really use this table (dev CIs don't update gateway routing or anything), but it's useful in development to see that CI is properly updating its database tables as it would in prod. In #12093, the migration that adds the `active_namespaces` table explicitly adds entries for the `default` namespace. However, I'm now realizing that this is a mistake, because a CI in the `dgoldste` namespace shouldn't have an entry for `default`, it should instead have an entry for `dgoldste`. That migration should have been parametrized by the namespace the migration is happening in. To do this, I need to expose the current namespace to the migration scripts, hence this PR. This is unfortunately a change to CI that needs to be deployed before it can be used by migrations. If this seems good then I'll alert the australians that they should fully deploy this PR prior to the following ones.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12755:836,expose,expose,836,https://hail.is,https://github.com/hail-is/hail/pull/12755,1,['expose'],['expose']
Security,"This is the current state of the C++ support. If you look at the tests in src/test/is/hail/nativecode/NativeCodeSuite.scala that should give a; quick overview of how it works, viz. 1. Generate C++ source code as a Scala String, then create a NativeModule which handles; the grunt work of getting it compiled, linked, and loaded, and allows you to look up functions; by name, and get a callable Scala object corresponding to the C++ function. 2. The NativeModule also allows the binary of the DLL to be passed around and instantiated; on other cluster nodes (but note that those nodes will need to have the correct versions of; the C++ runtime shared libraries in the right directories to allow symbols in the DLL to be; correctly resolved). This is not tested yet. 3. I have been using llvm-6.0.0 on Mac, and llvm-5.0 on linux. It makes a half-hearted attempt; to use whatever other compiler you have, but that may not work. We probably need to figure; out a standardized and automated way to get the right tools installed in the right place (and; get the right shared libraries on worker nodes). 4. Data which needs to be accessible to both Scala and C++ is held in C++ objects inheriting; from NativeObj, with lifetimes managed by std::shared_ptr, i.e. reference-counted. There's; some dirty under-the-hood plumbing to allow a shared_ptr to be smuggled into a Scala; object derived from NativeBase. These Scala-side object references must be managed; carefully using copyAssign/moveAssign/close in order to maintain the off-heap ref-counts. 5. There are some gnarly differences between Linux and MacOSX in the linker and dynamic; loading. I think I'm converging on the right compile/link options for each, but in getting; Linux to work it's possible that Mac is temporarily broken ... Not really expecting that we'll merge this right away, but I wanted to put it out there to get the; review process started before it grows any bigger.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3461:1123,access,accessible,1123,https://hail.is,https://github.com/hail-is/hail/pull/3461,1,['access'],['accessible']
Security,"This is the final stop for now on our nginx tour. This builds on #10207, which altered `internal.hail.is` use k8s dns instead of router/router-resolver to proxy directly to services, and does so in default now as well. Unlike #10207, however, traffic coming in through `hail.is` is not necessarily authenticated, and we do not expose just any k8s service that happens to exist. Instead, I've altered `letsencrypt/domains.txt` to now be `letsencrypt/subdomains.txt` and templated the gateway config to generate explicit server blocks for each subdomain in `subdomains.txt`. This enforces that you cannot expose a service unless it is also listed in the `letsencrypt` directory (the dev must still remember to regenerate the certs). Now, the process for exposing a service is:; - Add a subdomain to `subdomains.txt`; - Make a k8s Service with the name of the subdomain that points to new app; - Regenerate certs and redeploy gateway. Also added a default server block that returns a 444 (no response) for invalid subdomains. Unfortunately this still presents to the user that the cert is invalid, since *.hail.is is registered in dns (I think?) and browsers will verify certificates before anything else, but users won't be able to click through and land at the website like they could before.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10247:298,authenticat,authenticated,298,https://hail.is,https://github.com/hail-is/hail/pull/10247,4,"['authenticat', 'certificate', 'expose']","['authenticated', 'certificates', 'expose']"
Security,"This is the initial version of the ATGU intranet service. Currently, it has a curated list of resources which can be created, viewed, edited and deleted. Resources can have attachments, which I store on Google storage. I used the async Google Storage client and it worked very nicely with aiohttp. Right now this developers only. I may give access to the admins to start curating resources. I'll follow up with roles and add roles for atgu-viewer and atgu-editor that I'll use in the service. I think the code is mostly straightforward, but a few remarks:. This is built on Bootstrap. It doesn't share the the styling with web common (which I probably want to convert). On the resources page, for client side search I use fuse.js: https://fusejs.io/ (so fast). For a rich text box (the resource content), I use quill.js: https://quilljs.com/. Quill doesn't allow you to post its contents in a form, so I use a JS event handler to populate a hidden input with the contents on submission. I tested it with dev deploy. I suggest you do the same before reviewing to get a sense of what's here. Feedback on the UI welcome.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9684:341,access,access,341,https://hail.is,https://github.com/hail-is/hail/pull/9684,1,['access'],['access']
Security,"This is the last change needed to enable authorized notebooks. Completely handles all N requests after redirect to Jupyter server, including all requests in subsequent within-Jupyter operations such as notebook creation (which still pass through our proxy)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5253:41,authoriz,authorized,41,https://hail.is,https://github.com/hail-is/hail/pull/5253,1,['authoriz'],['authorized']
Security,"This is the plan for the new Hail CI (tentatively: Hephaestus aka h8s [but Hodor is also in the running, see CI software name in Zulip for the real big questions of our time]). # Expected Repo Structure; Every repository to be tested has at least two files: `hail-ci-build-image` and `hail-ci-build.sh`. The former contains a docker image in a publicly accessible repository. The latter is a shell script that exits with 0 if this branch passes the tests, otherwise it exists with a non-zero code. The logs of this shell script will be shared publicly via the GH PR Status. This script will be executed in the image referenced by `hail-ci-build-image`. # Dockerfile.pr-builder; I carefully wrote a docker file to cache as much gradle crap as possible. # gitHash in Gradle; I pushed `gitHash`'s definition into the `doLast` blocks of the gradle steps that actually need it. `doLast` is only run when the task is actually requested. This allows me to run `downloadDependencies` without creating a dependency on the entire `.git` directory (which changes with each commit, thus invalidating the cache'd docker image).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4066:353,access,accessible,353,https://hail.is,https://github.com/hail-is/hail/pull/4066,1,['access'],['accessible']
Security,This is the setup for the website. Some remarks:; - We run a web server (nginx) in Kubernetes (service and deployment); - It has a volume (letsencrypt-certs) that stores our SSL certificates; - Those come from Let's Encrypt. Getting new certs is totally automated (see run-letsencrypt make target).; - certbot by default installs a cron job that runs daily to renew the certs.; - Other publicly exposed services are now encrypted and go through nginx. That's set up for ci and scorecard.; - The site pod (via a cron job) polls for a new deployment every 3m for new documentation. It's not yet integrated into the ci for automatic deployment (and testing?),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4403:178,certificate,certificates,178,https://hail.is,https://github.com/hail-is/hail/pull/4403,4,"['Encrypt', 'certificate', 'encrypt', 'expose']","['Encrypt', 'certificates', 'encrypted', 'exposed']"
Security,"This is what `hailctl` looks like:. ```. Usage: hailctl [OPTIONS] COMMAND [ARGS]... Manage and monitor hail deployments. ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────╮; │ --install-completion [bash|zsh|fish|powershell|pwsh] Install completion for the specified │; │ shell. │; │ [default: None] │; │ --show-completion [bash|zsh|fish|powershell|pwsh] Show completion for the specified │; │ shell, to copy it or customize the │; │ installation. │; │ [default: None] │; │ --help Show this message and exit. │; ╰──────────────────────────────────────────────────────────────────────────────────────────────────────╯; ╭─ Commands ───────────────────────────────────────────────────────────────────────────────────────────╮; │ batch Manage batches running on the batch service managed by the Hail team. │; │ config Manage Hail configuration. │; │ curl Issue authenticated curl requests to Hail infrastructure. │; │ version Print version information and exit. │; ╰──────────────────────────────────────────────────────────────────────────────────────────────────────╯; ```. This is what `hailctl batch submit --help` looks like:. ```. Usage: hailctl batch submit [OPTIONS] SCRIPT [ARGUMENTS]... Submit a batch with a single job that runs SCRIPT with the arguments ARGUMENTS. ╭─ Arguments ──────────────────────────────────────────────────────────────────────────────────────────╮; │ * script PATH Path to the script [default: None] [required] │; │ arguments [ARGUMENTS]... [default: None] │; ╰──────────────────────────────────────────────────────────────────────────────────────────────────────╯; ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────╮; │ --files PATH Files or directories to add to the working directory of the │; │ job. │; │ [default: None] │; │ --name TEXT The name of the batch. │; │ --image-name TEXT Name of Docker image for the job │; │ [default: (hailgenetics/hail)] │; │ --ou",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13109#issuecomment-1561081921:909,authenticat,authenticated,909,https://hail.is,https://github.com/hail-is/hail/pull/13109#issuecomment-1561081921,1,['authenticat'],['authenticated']
Security,"This is why copying is so slow:. ```; ==> NOTE: You are uploading one or more large file(s), which would run; significantly faster if you enable parallel composite uploads. This; feature can be enabled by editing the; ""parallel_composite_upload_threshold"" value in your .boto; configuration file. However, note that if you do this large files will; be uploaded as `composite objects; <https://cloud.google.com/storage/docs/composite-objects>`_,which; means that any user who downloads such objects will need to have a; compiled crcmod installed (see ""gsutil help crcmod""). This is because; without a compiled crcmod, computing checksums on composite objects is; so slow that gsutil disables downloads of composite objects. / [1/1 files][ 4.1 GiB/ 4.1 GiB] 100% Done 45.8 MiB/s ETA 00:00:00; Operation completed over 1 objects/4.1 GiB.; ```. We can also set this with -o GSUtil:parallel_composite_upload_threshold on the command line. https://cloud.google.com/storage/docs/gsutil/commands/cp. We currently use `-m` which is parallel per-file:. If you have a large number of files to transfer you might want to use the; gsutil -m option, to perform a parallel (multi-threaded/multi-processing); copy:. gsutil -m cp -r dir gs://my-bucket",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7024:627,checksum,checksums,627,https://hail.is,https://github.com/hail-is/hail/pull/7024,1,['checksum'],['checksums']
Security,"This isn't a hard change, but it is a big one. Let me know if you want me to break it up. OK, I think this is ready for a look. What I've tested:. - hand deploy new auth, router-resolver to default,; - tested login/logout flow on web (auth.hail.is/login, /logout) and hailctl (hailctl auth login/logout); - then deploy in my namespace:. ```; hailctl dev deploy -b cseed/hail:auth -s deploy_auth,deploy_router,deploy_notebook2; ```. - and test login/logout flow via notebook2 (internal.hail.is/cseed/notebook2, etc.) and hailctl, where access to internal is mediated by production (default namespace) credentials. Note, to do this I copied the production oauth2 key to my namespace. We shouldn't do this in general and should create a shared dev oauth2 key. Alternatively, we should create a separate login flow doesn't use oauth2 but uses production credentials.; - and interactively tested notebook2 creating notebooks (but haven't tested the config of the notebooks themselves). Summary of changes:; - auth service that handles login/logout flow via Google OAuth2 and user verification via /userdata endpoint. Web sessions are stored in the aiohttp_session cookie (encrypted), command line sessions are stored in tokens file: tokens.json. Token files potentially contain tokens for multiple namespaces (e.g. default and cseed in the example workflow above).; - sessions are now started in the database, table `users.sessions`, which have session_id (32 random bytes, base64-encoded), user_id, creation time and max_age (for expiry); - I write notebook2 to use our async stack; - added a notion of ""deploy config"" that has three parts: location (one of external, k8s or gce), default_namespace (the default namespace to find services), and service_namespace (of overrides for specific services ... so e.g. you can use the default auth with batch in cseed). deploy_config main function is to construct URLs to contact services.; - JWTs and the jwt secret key are gone.; - Simplified configuration/data",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6892#issuecomment-527970251:535,access,access,535,https://hail.is,https://github.com/hail-is/hail/pull/6892#issuecomment-527970251,1,['access'],['access']
Security,"This issue didn't manifest until I needed to re-authenticate in azure, at which point grafana tried to bring me to gcp auth and got hella confused.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11200:48,authenticat,authenticate,48,https://hail.is,https://github.com/hail-is/hail/pull/11200,1,['authenticat'],['authenticate']
Security,"This kind of does a lot of small things:. - Adds a table at the top of the page that is all the PRs that require the user's attention, meaning: a personally authored PR where the build has failed or there are changes requested, or a PR for review that the user has not yet reviewed. - Under PRs that require a review, a user now sees those where they are listed under `Assignees` *as well as* under `Reviewers`. We have been using assignees to assign reviews, but outside collaborators are unable to do so or dismiss reviews. This is because we don't really align with GitHub's semantics for these labels. Per GitHub, Assignees are organization members responsible for the supervision of a PR, whether the author or the final merge sign-off. Meanwhile, reviewers are what they suggest. If an outside contributor submits a PR, they can request a review from organization members in the `Reviewers` box, and then re-request review once they are ready for the PR to be looked at again. We should probably just abandon assignees given how we currently use them, but I just wanted to first get all of the information onto CI so nothing falls through the cracks. - Adds authorize SHA input. - Fixes some small cosmetic bugs like a repeated ""running"" statement in batch tables and enables '/' focus on the jobs table in a batch.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10142:1164,authoriz,authorize,1164,https://hail.is,https://github.com/hail-is/hail/pull/10142,1,['authoriz'],['authorize']
Security,"This leverages the Indeed LSM tree. It implements this API:; - `start(...)`; - `put(x1, ...)` (keys are extracted from the records themselves); - `get(l, r)` which takes two key records and retrieves the values in `[l, r)`. There's a server (`ShuffleServer.scala`) and a client (`ShuffleClient.scala`). They communicate over TLS-secured TCP/IP sockets on a configurable port. The server has one thread per client socket. The client is currently single-threaded. I had to add a `log4j.properties` because I don't start a HailContext and log4j gets upset when you don't configure it. Files; - `HailLSM.scala` - This wraps the Indeed LSM tree with some shims so that we encoders and decoders use `InputStream` and `OutputStream` instead of these were `Data...` interfaces.; - `HailSSLContext.scala` - This implements creation of an actually secure `SSLContext` from a key store and a trust store. It requires clients to identify themselves with a trusted certificate.; - `ShuffleClient.scala` - Self-explanatory.; - `ShuffleServer.scala` - Three classes: `Handler` corresponds to a client connection. It has its own thread. `Shuffle` owns the `Region` , the LSM tree, and the encoder/decoders. `ShuffleServer` waits for connections and spawns threads. It owns the executor service.; - `ShuffleUtils.scala` - Odds and ends.; - `Wire.scala` - Serializers and deserializers for various things. Includes renames that help me keep everything sensible (e.g. for every X I use, I have ""writeX"" and ""readX"").; - `ShuffleSuite.scala` - One test: write 1,000,000 randomly ordered numbers into the LSM tree and read them all back in order. Takes about 1 minute. Obviously we need to dramatically improve the performance of that (I think this should take not longer than one second).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8361:329,secur,secured,329,https://hail.is,https://github.com/hail-is/hail/pull/8361,3,"['certificate', 'secur']","['certificate', 'secure', 'secured']"
Security,"This looks like good start. A few comments:; - I prefer using MySQL over auth0 mainly because it simplifies our eventual backup/restore story. If you think that's simpler overall, great. I don't see how integrating our db with their service does anything for us.; - I assume you're planning to pull the user data from MySQL during the login flow and add it to cookie? I think @danking @jigold and I are interested in nailing down the format for the cookie and seeing an example.; - I agree with @danking we should have an internal id field that's an integer. I think we should use that everywhere, and just use the auth0 id to look up the user record during login. So the integer id would be the primary key and the auth0 id would be unique with a secondary index.; - You need to get the GCP service account key and store it in a secret.; - The GCP service account needs permissions on the bucket. It should be bucket writer.; - Name ""user_secrets"" seems overly specific (buckets and service accounts are not secrets). ""user_data""?; - Please don't give the database a public IP.; - From a usability perspective, for user-visible names I have to say I really dislike long uuids and like the k8s-style short random string at the end. For k8s resource, you get this for free with the `generate_name` argument. For other stuff, long-term, this will potentially require retry logic to make it robust.; - I don't like this create table logic (FYI @danking @jigold). Most database users should not have permissions to create databases. There should be a k8s secret with the database root and a secret for each specific database application that only has access to that database.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5618#issuecomment-473583731:1647,access,access,1647,https://hail.is,https://github.com/hail-is/hail/pull/5618#issuecomment-473583731,1,['access'],['access']
Security,"This makes it easy to send authenticated HTTP requests to our; infrastructure. When developing a new service, you might not have an; existing (or working) client yet and want to explore the HTTP endpoints with; cURL.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8408:27,authenticat,authenticated,27,https://hail.is,https://github.com/hail-is/hail/pull/8408,1,['authenticat'],['authenticated']
Security,"This method is useful for accessing functionality that exists in the aggregator library but not the basic expression library, for instance, `call_stats`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12988:26,access,accessing,26,https://hail.is,https://github.com/hail-is/hail/pull/12988,1,['access'],['accessing']
Security,"This only exposes the raw results to python. I still need to wrap that in some nice convenience functions like approximate_quantile, but I didn't want to let this PR get any longer.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5570:10,expose,exposes,10,https://hail.is,https://github.com/hail-is/hail/pull/5570,1,['expose'],['exposes']
Security,"This puts a local filesystem option that is at parity with the remote option, and is triggered by the absence of a gs:// prefix. A question: do we want to expose an rm?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6887:155,expose,expose,155,https://hail.is,https://github.com/hail-is/hail/pull/6887,1,['expose'],['expose']
Security,"This refers to setting up a fresh k8s cluster. In particular, when you're creating a k8s cluster from scratch, you need to create an access token to grant CI (or gateway, if gateway were to proxy requests to GitHub for CI) access to the PR ""merge"" endpoint. There are a couple other things like read access to our google buckets. These can all be generated by anyone with a sufficiently privileged GCP account and a broad login in the `hail` unix group (there are some credentials stored in cotton's home directory on the broad file system).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4556#issuecomment-449082131:133,access,access,133,https://hail.is,https://github.com/hail-is/hail/issues/4556#issuecomment-449082131,3,['access'],['access']
Security,"This replaces the `gcr-push-service-account-key` secret with a more general `container-registry-push-credentials` secret with username/password. Long term, it would be best to use the higher-level batch interface and just grant CI's credentials access to the container registry, but this is the smallest step I could think of to make the buildImage step able to work in azure (except for `cleanup`, as that relies on `gcloud`, but I'll have to address that later).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10984:135,password,password,135,https://hail.is,https://github.com/hail-is/hail/pull/10984,2,"['access', 'password']","['access', 'password']"
Security,This script helps run some of the steps from https://populationgenomics.readthedocs.io/en/latest/hail.html#updating-tls-https-certificates through an automatic script that can be fetched and run.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14667:126,certificate,certificates,126,https://hail.is,https://github.com/hail-is/hail/pull/14667,1,['certificate'],['certificates']
Security,"This secures the batch2 driver endpoints. The driver is called by workers on activate, deactivate and when a job is complete. It is also called by the front end to notify it when a batch is closed, cancelled or deleted. Workers have a random token stored in the database that is sent along with requests. The front end and driver share another random, internal token which is also placed in the authorization header. The driver has to decorators to protect request handlers: batch_only and instances_only.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7440:5,secur,secures,5,https://hail.is,https://github.com/hail-is/hail/pull/7440,2,"['authoriz', 'secur']","['authorization', 'secures']"
Security,"This seems like the right approach. The other option is to expose the password in the config which we are trying to avoid. So ... even this is not idempotent. The current version of batch doesn't guarantee that children (or multiple retries of the same child) get the same or consistent set of files from their parents. This is because, while an attempt may have succeeded, there may be another attempt that is pending that succeeds and overwrites the outputs of the original successful attempt. I fixed this in my google batch backend by storing attempt outputs in per-attempt directory: /path/to/scratch/files/job_id/attempt_id/file. Then each child got the successful attempt (there could be multiple, but the driver selected one and only one) for each parent and that was used to localize the inputs. So this good enough and we should plan to add attempt consistency to Batch in the future.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8833#issuecomment-631473428:59,expose,expose,59,https://hail.is,https://github.com/hail-is/hail/pull/8833#issuecomment-631473428,2,"['expose', 'password']","['expose', 'password']"
Security,"This seems tricky! I expected protected variables to be only accessible from child classes. Is the reason this works that adding [ir] hoists the variable to be top-level, when used from an object of type IR, thereby making it once again accessible to sub-packages?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6594#issuecomment-515071056:61,access,accessible,61,https://hail.is,https://github.com/hail-is/hail/pull/6594#issuecomment-515071056,2,['access'],['accessible']
Security,"This should be functioning (or very close) in GCP but is basically unimplemented in Azure. Azure needs a secret store like how we use Google Secret Manager that workers can access when they start up to load certificates. Azure Key Vault seems reasonable and can be created through terraform. The structure should mirror that in GCP, where we need a client that can upload the certs to Azure in `create_certs` and download them in the azure CloudWorkerAPI. I would leave this unimplemented in TerraAzure until an overall secrets story is established.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14581#issuecomment-2243030552:173,access,access,173,https://hail.is,https://github.com/hail-is/hail/pull/14581#issuecomment-2243030552,2,"['access', 'certificate']","['access', 'certificates']"
Security,"This should fully address the scroll-to artifact on docs, which had the item that was scrolled to (specified by a #id after the url) was hidden by the navbar. ### Background; Browsers interpret a hash after a url as being an element selector (id) to move the top of the page to. The browser will set the top of the browser to the top of the element, which is determined by its height, padding, and box-sizing rule (which determines whether padding and borders are taken into account when calculating the element's height and width). *The margin on the element is not taken into account*. This is incompatible with fixed navbars, because now the the top of the element should also take into account the height of the nabber. ### Solution; 2 solutions, one for the case where the element has a transparent background, and one for the case that it doesn't. In the transparent case (`.section`), we add padding to the element that is larger than the default by the height of the navbar, and a negative margin that is the negative height of the navbar. For `.section`, which doesn't have any padding, we simply use the height of the navbar. In the colored-background case (`dt`, the function blocks, which have 6px of padding, a blue background, and darker blue top-border) we need to use a different solution, because that padding will be the color of the background, making the element appear much taller than expected. The solution is to use a tall transparent border instead, along with the setting `background-clip: padding-box`. To handle the border we use a pseudo element that is absolutely positioned.; - background-clip is widely supported: https://caniuse.com/#search=background-clip. ### Before; <img width=""697"" alt=""Screenshot 2019-10-12 14 34 42"" src=""https://user-images.githubusercontent.com/5543229/66706171-960fa700-ecfd-11e9-9fa0-17a05da486a2.png"">. <img width=""701"" alt=""Screenshot 2019-10-12 14 34 53"" src=""https://user-images.githubusercontent.com/5543229/66706173-9740d400-ecfd-11e9",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7288:196,hash,hash,196,https://hail.is,https://github.com/hail-is/hail/pull/7288,1,['hash'],['hash']
Security,"This should now be passing tests. I had to make one LocalBackend test conditional on docker, because we do not have docker in docker (DiD), and there were historically some security considerations that felt out of scope to fully grapple with in this PR (out of scope to create a DiD image and have test_hailtop_batch and test_batch_dcos use this DiD image.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9219#issuecomment-670288861:173,secur,security,173,https://hail.is,https://github.com/hail-is/hail/pull/9219#issuecomment-670288861,1,['secur'],['security']
Security,"This should wait for #9184 . This PR adds fluentd support for streaming the logs to Logs Viewer. Things to Note:; - I didn't have to setup the authorization at all, so I believe it's using the service account on the worker which would be the batch2 service account. I had to give that service account Logs Writer permissions. This is the same service account regardless of the namespace.; - All namespaces have output written.; - I added some labels of the instance id and namespace to help with searching. Let me know if you think we need something else.; - I used a filter to parse the JSON in the worker log to get the right timestamp of the record rather than the publication of the log message in the Logs Viewer. Example Stackdriver Queries:. ```; resource.type=""gce_instance""; labels.namespace=""jigold""; logName=""projects/hail-vdc/logs/worker.log""; ```. ```; resource.type=""gce_instance""; labels.""compute.googleapis.com/resource_name""=""batch-worker-jigold-uyvo5""; logName=""projects/hail-vdc/logs/worker.log""; ```. I basically just followed this: https://cloud.google.com/logging/docs/agent. Will attempt to get dockerd logs in some other time.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9189:143,authoriz,authorization,143,https://hail.is,https://github.com/hail-is/hail/pull/9189,1,['authoriz'],['authorization']
Security,This was for a different purpose - it was to expose the globals as a separate one row table. But I don't think that's necessary and am happy to close,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2970#issuecomment-408638988:45,expose,expose,45,https://hail.is,https://github.com/hail-is/hail/issues/2970#issuecomment-408638988,1,['expose'],['expose']
Security,"This was to simplify the bytecode generated for unsafe memory access calls vs Scala objects. If there was an improvement, it was smaller than the benchmark measurement noise. Also added some object+offset variants.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2184:62,access,access,62,https://hail.is,https://github.com/hail-is/hail/pull/2184,1,['access'],['access']
Security,This was used a very long time ago for authentication (e.g. see notebook2 in commit aa937bd3414481998e522832336ab618a8cf756d).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11505:39,authenticat,authentication,39,https://hail.is,https://github.com/hail-is/hail/pull/11505,1,['authenticat'],['authentication']
Security,This works in the sense that I didn't get a 404 or 502 contacting the server in my namespace. I think we need to redeploy lets encrypt -- can't remember.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9711:127,encrypt,encrypt,127,https://hail.is,https://github.com/hail-is/hail/pull/9711,1,['encrypt'],['encrypt']
Security,"Tim, like we discussed, thanks for the suggestion. No login for workshop users, we skip auth0 altogether. Not quite as safe, but probably not a big deal provided https, a long-enough password. . I also removed the image picker, because it's I think more implementation detail than workshop users need (and it's not particularly styled). and uses ibg2019. cc @danking @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5556:183,password,password,183,https://hail.is,https://github.com/hail-is/hail/pull/5556,1,['password'],['password']
Security,"To allow users on GCP to access datasets that are only available on AWS (e.g. pan-ukb LD block matrices and tables). . If trying to read dataset from `s3` path throws `FatalError: UnsupportedFileSystemException: No FileSystem for scheme ""s3""`, then will read with the `s3a` prefix instead.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10527:25,access,access,25,https://hail.is,https://github.com/hail-is/hail/pull/10527,1,['access'],['access']
Security,"To come next:; * Expose in Python, add more tests of Python functionality",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9089:17,Expose,Expose,17,https://hail.is,https://github.com/hail-is/hail/pull/9089,1,['Expose'],['Expose']
Security,"To do this, expose the necessary methods to get the start and end bounds; of an interval queries position within the index. Then just add; a counter to the iterators.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11060:12,expose,expose,12,https://hail.is,https://github.com/hail-is/hail/pull/11060,1,['expose'],['expose']
Security,To make uber jar: `mvn assembly:single`. `compile` automatically runs `make` for the NativeLib stuff.; `clean` automatically runs `make clean` for NativeLib; Not sure if I needed to incorporate `nativeLibTest` or `nativeLibPrebuilt`. Added two test configurations. One is for all tests and the other is for the set of tests with HAIL_ENABLE_CPP_CODEGEN=1. I double checked the Python tests pass with the uber jar. The test output doesn't have the nice formatting that we have in Gradle. Would be some work with listeners and reporters to do that: http://maven.apache.org/surefire/maven-surefire-plugin/examples/testng.html#. There also isn't the `check` input and some other bells and whistles we have in Gradle. I had to add `com.google.inject:guice` to get rid of some compile warnings with the test-jar. Let me know if there's other things to add/enable or if this is good enough for ci2. We should probably add some CI tests for this in a makefile somewhere.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5906:738,inject,inject,738,https://hail.is,https://github.com/hail-is/hail/pull/5906,1,['inject'],['inject']
Security,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9849:871,access,access,871,https://hail.is,https://github.com/hail-is/hail/issues/9849,1,['access'],['access']
Security,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.2/devel hash eb1e04205793. ### What you did:; I'm trying to take PC loadings generated using Hail in one sample and project another sample into that PC space to generate scores for them. I've been using @danking's tricks developed for my PRS pipeline to speed things along and am now trying to feed the relevant inputs into gnomad Hail's [pc_project()](https://github.com/macarthur-lab/gnomad_hail/blob/master/utils/generic.py#L164) function. I've written out the function in script format for debugging purposes. Full code is below. . ```import hail as hl; import pickle; import time. generate_pcloadings_table = True; pcloadings_table_location = 'gs://ukbb_prs/sibdiff/keytables/ukb-pca-locus-allele-keyed.kt'; generate_contig_row_dict = True; contig_row_dict_location = 'gs://ukbb_prs/sibdiff/keytables/contig_row_dict-UKB'; output_location = 'gs://ukbb_prs/sibdiff/UKB_sibloadings.txt'; contigs = {'0{}'.format(x):str(x) for x in range(1, 10)}; bgen_files = 'gs://fc-7d5088b4-7673-45b5-95c2-17ae00a04183/imputed/ukb_imp_chr{1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22}_v3.bgen'. # large block size because we read very little data (due to filtering & ignoring genotypes); hl.init(branching_factor=10, min_block_size=2000). ### set up the pcloadings table; if (generate_pcloadings_table):; pcloadings = hl.import_table('gs://phenotype_31063/ukb31063.gwas.pca_loadings.tsv.gz', impute=True); pcloadings = pcloadings.annotate(locus=hl.parse_locus(hl.str(pcloadings.chr) + "":"" + hl.str(pcloadings.pos)),; alleles=[pcloadings.ref,pcloadings.alt]).key_by('locus','alleles'). pcloadings.write(pcloadings_table_location, overwrite=True). pcloadings = hl.read_table(pcloadings_table_location). ### determine the file locations of the pca ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3953:263,hash,hash,263,https://hail.is,https://github.com/hail-is/hail/issues/3953,1,['hash'],['hash']
Security,Topics:; https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/key.20not.20found.3A.20GRCh38/near/247317975; https://discuss.hail.is/t/potential-liftover-issue-error-summary-nosuchelementexception-key-not-found-grch37/2154. Stack trace:; ```; java.util.NoSuchElementException: key not found: GRCh37; 	at scala.collection.MapLike.default(MapLike.scala:235); 	at scala.collection.MapLike.default$(MapLike.scala:234); 	at scala.collection.AbstractMap.default(Map.scala:65); 	at scala.collection.mutable.HashMap.apply(HashMap.scala:69); 	at is.hail.variant.ReferenceGenome.getLiftover(ReferenceGenome.scala:412); 	at is.hail.variant.ReferenceGenome.liftoverLocus(ReferenceGenome.scala:423); 	at __C700Compiled.applyregion0_8(Emit.scala); 	at __C700Compiled.apply(Emit.scala); 	at is.hail.expr.ir.TableMapRows.$anonfun$execute$43(TableIR.scala:1936); ```. See Lindo's comment in the Zulip thread to replicate (hopefully),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10722:522,Hash,HashMap,522,https://hail.is,https://github.com/hail-is/hail/issues/10722,2,['Hash'],['HashMap']
Security,"Tried to run this code:. `vds.annotate_samples_expr('sa.variant1 = gs.filter(g => v == Variant(""1:55505447:C:T"")).collect()[0].gt')`. But the variant was not in the dataset at all, so got an out of bounds error, but it looked like this:. ```; [Stage 2:======================================================>(278 + 1) / 279]// class version 52.0 (52); // access flags 0x1; public class is/hail/codegen/generated/C0 implements java/io/Serializable scala/Function2 {. // access flags 0x1; public apply(Ljava/lang/Object;Ljava/lang/Object;)Ljava/lang/Object;; L0; ALOAD 1; CHECKCAST [Ljava/lang/Object;; LDC 0; AALOAD; INVOKEINTERFACE scala/Function0.apply ()Ljava/lang/Object;; CHECKCAST scala/collection/IndexedSeq; ASTORE 3; ALOAD 3; IFNULL L1; NEW java/lang/Integer; DUP; LDC 0; INVOKESPECIAL java/lang/Integer.<init> (I)V; ASTORE 4; ALOAD 4; IFNULL L2; ALOAD 4; INVOKEVIRTUAL java/lang/Number.intValue ()I; ISTORE 5; ALOAD 3; ILOAD 5; LDC 0; IF_ICMPGE L3; GOTO L4; L4; FRAME FULL [is/hail/codegen/generated/C0 java/lang/Object java/lang/Object scala/collection/IndexedSeq java/lang/Integer I] [scala/collection/IndexedSeq]; ILOAD 5; ALOAD 3; INVOKEINTERFACE scala/collection/IndexedSeq.size ()I; IADD; GOTO L5; L3; FRAME SAME1 scala/collection/IndexedSeq; ILOAD 5; L5; FRAME FULL [is/hail/codegen/generated/C0 java/lang/Object java/lang/Object scala/collection/IndexedSeq java/lang/Integer I] [scala/collection/IndexedSeq I]; INVOKEINTERFACE scala/collection/IndexedSeq.apply (I)Ljava/lang/Object;; GOTO L6; L2; FRAME CHOP 1; ACONST_NULL; L6; FRAME SAME1 java/lang/Object; GOTO L7; L1; FRAME CHOP 1; ACONST_NULL; L7; FRAME SAME1 java/lang/Object; CHECKCAST is/hail/variant/Genotype; ASTORE 6; ALOAD 6; IFNULL L8; ALOAD 6; INVOKEVIRTUAL is/hail/variant/Genotype.unboxedGT ()I; ISTORE 7; ILOAD 7; LDC -1; IF_ICMPEQ L9; GOTO L10; L10; FRAME FULL [is/hail/codegen/generated/C0 java/lang/Object java/lang/Object scala/collection/IndexedSeq T T is/hail/variant/Genotype I] []; NEW java/lang/Integer; DUP; I",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1705:354,access,access,354,https://hail.is,https://github.com/hail-is/hail/issues/1705,2,['access'],['access']
Security,"True); File ""<decorator-gen-502>"", line 2, in import_vcf; File ""/tmp/7417fcfbbeee44d0b3f4c0b3750121a7/hail-0.1-es-6.2.4-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, without-vep-520334-sw-rmwj.c.seqr-project.internal): java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:245); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrRead",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:1888,Checksum,ChecksumFileSystem,1888,https://hail.is,https://github.com/hail-is/hail/issues/3760,2,['Checksum'],"['ChecksumFSInputChecker', 'ChecksumFileSystem']"
Security,"True. I thought at least for the copy-paste tokens that this would be intentional. Looks like you can get access tokens from GCP that last up to 12 hours, but that could be insufficient for large workloads. If we need something arbitrarily long-lived, our current implementation might be our best bet short of some better integration with OIDC.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13934#issuecomment-1785516525:106,access,access,106,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1785516525,1,['access'],['access']
Security,"Trying to annotate a table with a reference genome creates tons of temp files, and ultimately fails with errors like:; ```; Mkdirs failed to create file:/tmp/hail.aHapwOHwB9LA (exists=false, cwd=file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1550247966765_0004/container_1550247966765_0004_02_000051). at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:441); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:929); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:910); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:807); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:796); at is.hail.utils.richUtils.RichHadoopConfiguration$.is$hail$utils$richUtils$RichHadoopConfiguration$$create$extension(RichHadoopConfiguration.scala:24); at is.hail.utils.richUtils.RichHadoopConfiguration$.writeFile$extension(RichHadoopConfiguration.scala:296); at is.hail.io.reference.FASTAReader$$anonfun$setup$1.apply(FASTAReader.scala:45); at is.hail.io.reference.FASTAReader$$anonfun$setup$1.apply(FASTAReader.scala:44); at is.hail.utils.package$.using(package.scala:587); at is.hail.utils.richUtils.RichHadoopConfiguration$.readFile$extension(RichHadoopConfiguration.scala:293); at is.hail.io.reference.FASTAReader$.setup(FASTAReader.scala:44); at is.hail.io.reference.FASTAReader$$anonfun$getLocalFastaFileName$1.apply(FASTAReader.scala:30); at is.hail.io.reference.FASTAReader$$anonfun$getLocalFastaFileName$1.apply(FASTAReader.scala:30); at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:901); at is.hail.io.reference.FASTAReader$.getLocalFastaFileName(FASTAReader.scala:30); at is.hail.io.reference.SerializableReferenceSequenceFile.value$lzycompute(FASTAReader.scala:18); at is.hail.io.reference.SerializableReferenceSequenceFile.value(FASTAReader.scala:17); at is.hail.io.reference.FASTAReader.<init>(FASTAReader.scala:77); at is.hai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5371:346,Checksum,ChecksumFileSystem,346,https://hail.is,https://github.com/hail-is/hail/issues/5371,4,['Checksum'],['ChecksumFileSystem']
Security,Turns out you need a key or a password. Closing this for now,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13653#issuecomment-1883522250:30,password,password,30,https://hail.is,https://github.com/hail-is/hail/pull/13653#issuecomment-1883522250,1,['password'],['password']
Security,"Typically, a CSRF attack can occur when `evil.com` tricks a user into requesting a state-changing URL at `batch.hail.is`. We use CSRF tokens to protect against such attacks, but there is an additional defense-in-depth cookie attribute that we can use called [SameSite](https://cheatsheetseries.owasp.org/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#samesite-cookie-attribute). The possible values for this attribute are:. - None => browser always sends this cookie in cross-site requests; - Strict => browser never sends this cookie in cross-site requests; - Lax => browser only sends this cookie in cross-site requests that use ""safe"" HTTP methods (GET, HEAD, OPTIONS). Both Lax and Strict protect against the most primitive forms of CSRF (a form on evil.com submitting a POST to batch.hail.is). Lax seems very reasonable, and still allows linking to, say, linking to jobs from Zulip's web app without the user needing to log in once they get there. Worth noting that this does not protect against [all forms of CSRF](https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis-02#section-5.3.7.1) attacks, so this does not replace CSRF tokens, just provides additional defense-in-depth.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13631:18,attack,attack,18,https://hail.is,https://github.com/hail-is/hail/pull/13631,3,['attack'],"['attack', 'attacks']"
Security,URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.mutable.List,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:2583,Hash,HashMap,2583,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Hash'],['HashMap']
Security,Unable to access entry in mt by row/col key,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9704:10,access,access,10,https://hail.is,https://github.com/hail-is/hail/issues/9704,1,['access'],['access']
Security,"Update Release Scripts (<a href=""https://redirect.github.com/jupyter/jupyter_core/issues/396"">#396</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_core/commit/1c5fa3720d3d6da1b5188072c24bac095082903b""><code>1c5fa37</code></a> Enforce pytest 7 (<a href=""https://redirect.github.com/jupyter/jupyter_core/issues/393"">#393</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_core/commit/dfed905e5ce3550e1bdae60e9e9242f0d0d2faae""><code>dfed905</code></a> chore: update pre-commit hooks (<a href=""https://redirect.github.com/jupyter/jupyter_core/issues/392"">#392</a>)</li>; <li>See full diff in <a href=""https://github.com/jupyter/jupyter_core/compare/v5.7.1...v5.7.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jupyter-core&package-manager=pip&previous-version=5.7.1&new-version=5.7.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14484:4482,secur,security-vulnerabilities,4482,https://hail.is,https://github.com/hail-is/hail/pull/14484,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Update the following docs:; annotatevariants_expr.md; HailExpressionLanguage.md; splitmulti.md, these lines:. ```; 108 filtervariants expr -c 'va.info.AC[va.aIndex] < 10' --remove; 118 annotatevariants expr -c 'va.info.AC = va.info.AC[va.aIndex]'; ```. Update error message in AST. ```; 1905 Hint: For accessing `A'-numbered info fields in split variants, `va.info.field[va.aIndex]' is correct"""""".stripMargin); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/663#issuecomment-242074915:302,access,accessing,302,https://hail.is,https://github.com/hail-is/hail/pull/663#issuecomment-242074915,1,['access'],['accessing']
Security,"Updated db.py to allow user to specify region as shown below. `db = hl.experimental.DB(region='us')`; `mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics')`. Data will be accessed from the requester pays bucket in the region specified by the user, available regions are `'us'` and `'eu'`. Modified the following to include region parameter:; - `DB` class ; - `Dataset.from_name_and_json()`. Added method `DatasetVersion.insert_region()` to replace `'{region}'` in `DatasetVersion.url` instance variable with the specified region.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9410:169,access,accessed,169,https://hail.is,https://github.com/hail-is/hail/pull/9410,1,['access'],['accessed']
Security,"Updated db.py to require user to specify region as shown below, so that data will be accessed from the requester pays bucket in the region specified by the user, available regions are `'us'` and `'eu'`. . `db = hl.experimental.DB(region='us')`; `mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics')`. Entries in the `annotation_db.json` file were modified to the following format:. ```; ""dataset_name"": { ""description"": ""some description here"",; ""key_properties"": [],; ""url"": ""https://www.someurlhere.com"",; ""versions"": [{""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""one_version""},; {""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""another_version""}]}; ```. The `annotation_db.json` file is now used by the `load_dataset()` function in `datasets.py` as well, any dataset in the JSON file should now be able to be loaded this way. Made changes to the following:; - `DB` class now requires a `region` parameter.; - `Dataset.from_name_and_json()` has had a `custom_config` parameter added that indicates whether or not the user has supplied their own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and rai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9496:85,access,accessed,85,https://hail.is,https://github.com/hail-is/hail/pull/9496,1,['access'],['accessed']
Security,"Updates the requirements on [aiohttp-session](https://github.com/aio-libs/aiohttp_session) to permit the latest version.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp_session/releases"">aiohttp-session's releases</a>.</em></p>; <blockquote>; <h2>v2.11.0</h2>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp-session/blob/master/CHANGES.txt"">aiohttp-session's changelog</a>.</em></p>; <blockquote>; <h1>2.11.0 (2021-01-31)</h1>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h1>2.10.0 (2021-12-30)</h1>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; <h1>2.9.0 (2019-11-04)</h1>; <ul>; <li>Fix memcached expiring time (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/398"">#398</a>)</li>; </ul>; <h1>2.8.0 (2019-09-17)</h1>; <ul>; <li>Make this compatible with Python 3.7+. Import from collections.abc, instead; of from collections. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/373"">#373</a>)</li>; </ul>; <h1>2.7.0 (2018-10-13)</h1>; <ul>; <li>; <p>Reset a session if the session age &gt; max_age (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/331"">#331</a>)</p>; </li>; <li>; <p>Reset a session on TTL expiration for EncryptedCookieStorage (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/326"">#326</a>)</p>; </li>; </ul>; <h1>2.6.0 (2018-09-12)</h1>; <ul>; <li>Create a new session if <code>NaCl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11577:361,Encrypt,EncryptedCookieStorage,361,https://hail.is,https://github.com/hail-is/hail/pull/11577,2,['Encrypt'],['EncryptedCookieStorage']
Security,"Updates the requirements on [google-cloud-storage](https://github.com/googleapis/python-storage) to permit the latest version.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/python-storage/releases"">google-cloud-storage's releases</a>.</em></p>; <blockquote>; <h2>v2.1.0</h2>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v2.0.0...v2.1.0"">2.1.0</a> (2022-01-19)</h2>; <h3>Features</h3>; <ul>; <li>add turbo replication support and samples (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/622"">#622</a>) (<a href=""https://github.com/googleapis/python-storage/commit/4dafc815470480ce9de7f0357e331d3fbd0ae9b7"">4dafc81</a>)</li>; <li>avoid authentication with storage emulator (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/679"">#679</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8789afaaa1b2bd6f03fae72e3d87ce004ec10129"">8789afa</a>)</li>; <li>remove python 3.6 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/689"">#689</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8aa4130ee068a1922161c8ca54a53a4a51d65ce0"">8aa4130</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/python-storage/blob/main/CHANGELOG.md"">google-cloud-storage's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v2.0.0...v2.1.0"">2.1.0</a> (2022-01-19)</h2>; <h3>Features</h3>; <ul>; <li>add turbo replication support and samples (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/622"">#622</a>) (<a href=""https://github.com/googleapis/python-storage/commit/4dafc815470480ce9de7f0357e331d3fbd0ae9b7"">4dafc81</a>)</li>; <li>avoid authentication with storage emulator (<a href=""https://github-redirect.dependabot.com/googleapis/p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11520:748,authenticat,authentication,748,https://hail.is,https://github.com/hail-is/hail/pull/11520,1,['authenticat'],['authentication']
Security,Usage and notes in the documentation for the new methods. Part of #14655. ## Security Assessment; - This change has no security impact. ### Impact Description; Does not increase attack surface. New methods only call into old ones.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14743:77,Secur,Security,77,https://hail.is,https://github.com/hail-is/hail/pull/14743,3,"['Secur', 'attack', 'secur']","['Security', 'attack', 'security']"
Security,Use 12 digits of git hash everywhere,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2216:21,hash,hash,21,https://hail.is,https://github.com/hail-is/hail/issues/2216,1,['hash'],['hash']
Security,Use only the minimum viable scopes when creating cloud access tokens,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13530:55,access,access,55,https://hail.is,https://github.com/hail-is/hail/issues/13530,1,['access'],['access']
Security,Use our `AccessLogger` in `router-resolver` too.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9911:9,Access,AccessLogger,9,https://hail.is,https://github.com/hail-is/hail/pull/9911,1,['Access'],['AccessLogger']
Security,"Used in the regenie implementation I'm referring to, and a useful/common ndarray function to expose.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9101:93,expose,expose,93,https://hail.is,https://github.com/hail-is/hail/pull/9101,1,['expose'],['expose']
Security,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9380:26,access,access,26,https://hail.is,https://github.com/hail-is/hail/pull/9380,2,['access'],['access']
Security,Validation code was not updated when adding azure https support. Made this check a bit more robust and tested locally. Resolves #13049,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13051:0,Validat,Validation,0,https://hail.is,https://github.com/hail-is/hail/pull/13051,1,['Validat'],['Validation']
Security,"Various changes:. 1. Locking is now done with a carefully restricted use of flock(), and the makefiles use; perl's rename command to get atomic rename, so they don't need to take locks. 2. The makefile conforms to the customary use-whatever-is-on-$PATH, with the slight wrinkle that; the full pathnames of the commands used will be visible in the build log - so if someone; picks up something weird we'll at least see it. 3. There is a cache of NativeModule objects, so that we won't do enormous numbers of; calls to dlopen/dlclose. This may help in shuffle code, which creates a new PackDecoder; for each RV. 4. The hash function on (options, source) is now beefed up to cope with having only a; few distinct values of options; and is modified with the output of ""$(CXX) --version"",; so that when you upgrade your compiler, you won't get hits on modules compiled with the old; compiler. 5. build.gradle has a new target ""nativeLibPrebuilt"", for updating the prebuilt/lib/linux-x86-64; or prebuilt/lib/darwin. 6. The committed prebuilt libraries are built thus:. darwin - On my MacOS laptop, with the default (clang-based) compiler, -march=sandybridge; From my reading, I believe this should be compatible withall MacBook Pro's; released since 2011, and all versions of MacOS since 10.9 (the first to use; libc++ rather than libstdc++ as the default C++ library) - we're now at 10.13,; with 10.14 arriving some time in the fall. linux-x86-64 - Built on my home desktop running Ubuntu-16.04 LTS, and g++-5.0.4, with; -fabi-version=9. In theory this should work with all systems based on g++5.x and; later. I made some effort to move std::string out of the interfaces between prebuilt; and dynamic code, which gives it some chance of working on systems based on; g++-4.x, but haven't tested that. I'm planning to fire up VM's either in cloud or under VirtualBox, to test this against Ubuntu-14.04,; Ubuntu-18.04, and the latest stable RHEL, which should cover most of the bases. In the interest of getti",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863:617,hash,hash,617,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863,1,['hash'],['hash']
Security,Very reasonable! I think that makes a lot of sense and am glad we'll have the extra security.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13607#issuecomment-1736214789:84,secur,security,84,https://hail.is,https://github.com/hail-is/hail/pull/13607#issuecomment-1736214789,1,['secur'],['security']
Security,"We are installing Hail's dependencies by injecting the requirements.txt dependencies into the deploy.yaml file. We don't have a way to grab the dependencies from the other wheel at the moment. I'd prefer to defer this change to modify -- The PR is big enough as-is, and fixes the modify semantics to be what they are in latest cloudtools. I think we should explore if there's a way to get pip to print the package dependencies from the wheel, and then grep out pyspark and install.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6297#issuecomment-500612048:41,inject,injecting,41,https://hail.is,https://github.com/hail-is/hail/pull/6297#issuecomment-500612048,1,['inject'],['injecting']
Security,"We are trying to setup hail `0.2.72` on spark `3.1.2` version. However, we are also facing similar error. * java version: `OpenJDK 64-Bit Server VM, 1.8.0_242`; * scala version: `2.12.10`; * py4j: `0.10.9`; * Python: `3.7.10`. <details>; <summary>Stacktrace</summary>. ```; Py4JJavaError: An error occurred while calling o126.exists.; : java.lang.NoClassDefFoundError: com/amazonaws/AmazonClientException; 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at org.apache.hadoop.conf.Configuration.getClassByNameOrNull(Configuration.java:2532); 	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2497); 	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2593); 	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3269); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3301); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3352); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3320); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:479); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:361); 	at is.hail.io.fs.HadoopFS.fileStatus(HadoopFS.scala:164); 	at is.hail.io.fs.FS.exists(FS.scala:183); 	at is.hail.io.fs.FS.exists$(FS.scala:181); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:70); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.Ca",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10590#issuecomment-899322610:932,access,access,932,https://hail.is,https://github.com/hail-is/hail/issues/10590#issuecomment-899322610,1,['access'],['access']
Security,We can decide the proper policy/procedure to update dependencies later. I think that we should find a way to be made aware of security issues in our dependencies so we can update them should an extraordinary circumstance arise.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4701#issuecomment-435204362:126,secur,security,126,https://hail.is,https://github.com/hail-is/hail/pull/4701#issuecomment-435204362,1,['secur'],['security']
Security,We changed the name of this function from `import_keytable` to `import_table` with the changes for the 0.1 stable build yesterday. Is your Hail code out of date? Try running:; ```python; >>> hc.version; ```; If it says `devel-<git hash>` instead of `0.1-<git hash>` it's out of date.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1818#issuecomment-301725415:231,hash,hash,231,https://hail.is,https://github.com/hail-is/hail/issues/1818#issuecomment-301725415,2,['hash'],['hash']
Security,We don't make it easy to copy the hail log off the driver when a spark job fails. We should make that as automatic as possible. One way to do this is to add a call to [`hl.copy_log`](https://hail.is/docs/0.2/utils/index.html#hail.utils.copy_log) in the `except` block of `SparkBackend.execute`. We would need to expose some configuration for where to copy logs.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14431:312,expose,expose,312,https://hail.is,https://github.com/hail-is/hail/issues/14431,1,['expose'],['expose']
Security,"We don't really have the infrastructure to create arbitrary values in c++ right (without translating into potentially large trees of IR). Since they already exist as Scala annotations in the IR, I decided that it was easier to serialize them in scala and decode them in the function rather than try to create logic and encode them in the function itself (we can't create them at compile-time and pass around naked hail-values, since they're region-backed and the functions can get serialized and shipped to workers, which don't have access to those). I put the decoded literals on a SparkFunctionContext in the hopes that it will be easier to plug in another literal broadcaster if/when the `Literal` IR no longer holds a Scala annotation, but in the meantime this was a reasonably straightforward way to get them into the c++ Emit code. I think we may not need to serialize literals like this for the `cxx.Compile.apply` methods, since they should all execute on the master node, but we don't currently enforce that so I was serializing there just to be safe. The alternative is to enforce execution of these functions on the master node, which I don't see a huge problem with off the top of my head? @cseed do you have feelings about this? All the distributed computation is going to go through `CollectDistributedArray` and friends, which should create their own entrypoints.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5617#issuecomment-474522874:533,access,access,533,https://hail.is,https://github.com/hail-is/hail/pull/5617#issuecomment-474522874,1,['access'],['access']
Security,"We got a [request in zulip](https://hail.zulipchat.com/#narrow/stream/127634-Feature-Requests/topic/String.20find) to add a function that works like the python [`str.find()`](https://docs.python.org/3/library/stdtypes.html#str.find) function. This should be straightforward. We just need to register a function in `StringFunctions` that calls the java `String.indexOf` method, and expose it in python.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14515:381,expose,expose,381,https://hail.is,https://github.com/hail-is/hail/issues/14515,1,['expose'],['expose']
Security,We have had a ton of recent issues with Google thinking we are anonymous; users. I want more information in the logs about authentication.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10958:123,authenticat,authentication,123,https://hail.is,https://github.com/hail-is/hail/pull/10958,1,['authenticat'],['authentication']
Security,"We now use an API token linked to hailgenetics instead of password auth. In order to do the org request, Daniel set up 2FA. There's no way to set up 2FA. There are recovery codes in the ""usual place"". No one besides Daniel can currently log into hailgenetics PyPI account as a result (other than using recovery codes).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13598#issuecomment-1808759767:58,password,password,58,https://hail.is,https://github.com/hail-is/hail/issues/13598#issuecomment-1808759767,1,['password'],['password']
Security,"We saw this error in production:; ```; pymysql.err.IntegrityError: (1062, ""Duplicate entry '7433-432443' for key 'PRIMARY'""); ```; hand deploy in progress already.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8014:51,Integrity,IntegrityError,51,https://hail.is,https://github.com/hail-is/hail/pull/8014,1,['Integrity'],['IntegrityError']
Security,"We should already have measures in place (like firewall rules) that prevent untrusted code from reaching the Batch Worker server, but this provides an extra layer of protection through which we can enforce that only the Batch front end and the Batch Driver can use the endpoints on the Batch Worker. This, along with #14581 are the final pieces to ensure that every endpoint in our system, both internal and external, uses HTTPS and performs the appropriate auth checks.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14622:47,firewall,firewall,47,https://hail.is,https://github.com/hail-is/hail/pull/14622,1,['firewall'],['firewall']
Security,"We spoke about this in person, but I had this mostly typed up in this buffer so I'll leave it here for future us. Some context on the docker build cache'ing situation. Originally, Docker would use any image layer it had as a cache source. This was noted as a severe security vulnerability because I could make an image that claims to be the result of `apt-get install curl` but actually was the result of `apt-get install virus`. In response, Docker banned the use of non-locally-built (i.e. from the Internet) image layers as cache sources. I believe there may have been other motivations as well, but I did not carefully investigate. https://github.com/moby/moby/issues/26065 documents the desire for a way to use non-locally-built images as a cache source. https://github.com/moby/moby/pull/26839 implements this. Unfortunately, and I cannot find documentation on this, `--cache-from X` means ""cache only from X"". If you pass multiple `--cache-from`s each one is used as a cache source, but it is not possible to say ""use all local images as a cache source"" (other than enumerating them all). [`--cache-from` was included in v1.13.0](https://github.com/moby/moby/releases/tag/v1.13.0), released January 2017. Another subtlety of `--cache-from` is that it does not pull the image in question if it is not found locally. I only found this documented [in a comment on the implementing PR](https://github.com/moby/moby/pull/26839#issuecomment-277383550). Docker seems to be in maintenance mode and all new development is going into Moby. The replacement for `docker build` is called [`buildkit`](https://github.com/moby/buildkit). Build Kit has a more reasonable cache'ing strategy wherein [one exports and imports ones cache](https://github.com/moby/buildkit#exportingimporting-build-cache-not-image-itself) to a trusted repository.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5623#issuecomment-474154073:266,secur,security,266,https://hail.is,https://github.com/hail-is/hail/pull/5623#issuecomment-474154073,1,['secur'],['security']
Security,"We use `nest_asyncio` to allow synchronous blocking on a coroutine execution inside an async context. For example, if a user is using the synchronous interface of hail inside a jupyter cell (which runs an event loop). `nest_asyncio` achieves this by patching the `asyncio` event loop to make it reentrant, and with that there are footguns. This allows us to do things like create 100 tasks that all concurrently invoke `run_until_complete`, each of which will add stack frames to the event loop stack that can pile up and trigger a cryptic `RecursionError`. But internally we never *need* to make concurrent calls to `run_until_complete`, and more broadly we should never have `async / sync / async` inside hail code. This change exposes an asynchronous `validate_file` so that asynchronous methods in `hailtop` can use it directly instead of inserting a synchronous layer (`async_to_blocking`) between them.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14576:730,expose,exposes,730,https://hail.is,https://github.com/hail-is/hail/pull/14576,1,['expose'],['exposes']
Security,"We've recently updated from 0.2.126ish to 0.2.130ish, and encountered some teething issues with the new (to us) metadata server. Jobs using `gsutil` failed as their attempts to get credentials from the server resulted in 404. There seems to have been two problems:. 1. As shown (also via `curl`) in [batch 454410](https://batch.hail.populationgenomics.org.au/batches/454410/jobs/1), our `gsutil` queried for `http://169.254.169.254/computeMetadata/v1/instance/service-accounts` (without a final `/`) which resulted in a 404. I don't know if there's a more elegant way for the server to accept both, rather than just adding a route with and without. 2. With that fixed, [batch 454418](https://batch.hail.populationgenomics.org.au/batches/454418/jobs/1) shows a failure within `GetInstanceScopes()`. This is failing because the metadata server does not implement the `…/scopes` endpoint. PR #14019 implemented only so much as is needed for `hail` and `gcloud` to get access tokens for hail GSAs so they can then make API calls to GCS or Hail Batch, but we seem to have needed a bit more. Not sure why you didn't encounter this yourselves: possibly sufficiently different versions of `gsutil` or the cloud SDK, or perhaps you are better at remembering to use `gcloud` rather than `gsutil` than we are!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14566#issuecomment-2132539331:965,access,access,965,https://hail.is,https://github.com/hail-is/hail/pull/14566#issuecomment-2132539331,1,['access'],['access']
Security,"What do you mean by validation? . For the 'annotation line' are you suggesting a general error-catching wrapper? I actually really like that, and I'll give it a go. > CNV work; > What I want to do with CNVs is something like ; > ; > ```; > val files: Array[String]; > sc.paralellize(files); > .map { f => readTable(f, config...) }; > .,map (convert to a hail better cnv representation); > ```; > ; > Can't do that if readTable gives you an RDD",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/462#issuecomment-233007740:20,validat,validation,20,https://hail.is,https://github.com/hail-is/hail/pull/462#issuecomment-233007740,1,['validat'],['validation']
Security,"What happens? I just tested it and it works fine for me. Although we probably shouldn't have spaces in workshop names, maybe I'll do that if/when I add validation.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7162#issuecomment-536317934:152,validat,validation,152,https://hail.is,https://github.com/hail-is/hail/pull/7162#issuecomment-536317934,1,['validat'],['validation']
Security,"What if all commands were proxied through the gateway api? We already have an authentication layer, with support for 2FA (though in an alpha state, doesn't handle fancier things like merging multiple social accounts). So permissions can be granted on a per-user basis. Currently we can define any scopes for our own APIs, or use Github's available API's (or pass both along to CI). . It may still be useful to have CI grab and validate a gateway-api generated token containing the necessary scopes, although this would add overhead, and may not be as necessary if CI is only available through the gateway api. Another alternative is that it validates against Auth0, but I'd like to reduce/remove that overhead if securely possible.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4556#issuecomment-449069425:78,authenticat,authentication,78,https://hail.is,https://github.com/hail-is/hail/issues/4556#issuecomment-449069425,4,"['authenticat', 'secur', 'validat']","['authentication', 'securely', 'validate', 'validates']"
Security,"When accessing two VDS files in `gs://hail-common/`, I got two errors. 1. gs://hail-common/all_coding_plus_minus_50bp_vep.vds. ```; File ""<decorator-gen-162>"", line 2, in read; File ""/home/ec2-user/BuildAgent/work/c38e75e72b769a7c/python/hail/java.py"", line 113, in handle_py4j; hail.java.FatalError: HailException: missing partitioner.json.gz when loading VDS, create with HailContext.write_partitioning. Java stack trace:; is.hail.utils.HailException: missing partitioner.json.gz when loading VDS, create with HailContext.write_partitioning.; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:20); 	at is.hail.variant.VariantDataset$.liftedTree1$1(VariantDataset.scala:89); 	at is.hail.variant.VariantDataset$.read(VariantDataset.scala:84); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:414); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:413); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.HailContext.readAll(HailContext.scala:413); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractC",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1683:5,access,accessing,5,https://hail.is,https://github.com/hail-is/hail/issues/1683,1,['access'],['accessing']
Security,"Which exposes the generic split_multi interface.; When we nuke Genotype, I will rename split_multi_generic => split_multi and split_multi => split_multi_hts.; Updated the interface slightly. The rule I'm using is: v, va, g, etc. all denote the old annotations and newV denotes the new, split variant.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2459:6,expose,exposes,6,https://hail.is,https://github.com/hail-is/hail/pull/2459,1,['expose'],['exposes']
Security,"While running QoB jobs, we observed some errors relating to compression validation or unexpected end of line/file. It was suggested that after certain errors, the reader may be in an unsuable state, so we recreate it after an error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13371:72,validat,validation,72,https://hail.is,https://github.com/hail-is/hail/pull/13371,1,['validat'],['validation']
Security,"With new aggregators, users could e.g. access Apache Math3 libraries to do arbitrary analyses based on case/control genotype counts.; Furthermore having ability to add new jars to classpath would allow flexible addition of new functions by users.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/359:39,access,access,39,https://hail.is,https://github.com/hail-is/hail/issues/359,1,['access'],['access']
Security,"With the new rng splitting design, each ApplySeeded node directly gets a unique fixed-length ID (similar to the seed currently), which gets combined into the RNGState immediately before generating random numbers. That allows us to simplify the SRNGState type. Abstractly, each `rand` result is the hash of a bitstring with one block corresponding to the static ID---which gets encrypted using the `staticTweak` tweak---and any number of blocks corresponding to the accumulated dynamic splits---which get encrypted using the block counter as tweak (except for the last block in normal PMAC fashion).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11668:298,hash,hash,298,https://hail.is,https://github.com/hail-is/hail/pull/11668,3,"['encrypt', 'hash']","['encrypted', 'hash']"
Security,"Without this change, we race against dockerd. If the chain does not exist; before we add the rules, then containers will be able to access the metadata server; other containers, etc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9975:132,access,access,132,https://hail.is,https://github.com/hail-is/hail/pull/9975,1,['access'],['access']
Security,Workers in terra batch need to use an actual azure bearer token in the authorization header to get through terra auth. I figured it's easiest to just not overload that header.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13071:71,authoriz,authorization,71,https://hail.is,https://github.com/hail-is/hail/pull/13071,1,['authoriz'],['authorization']
Security,"Working on the safe memory allocator that checks if we are accessing invalid memory, it's catching this 0 pointer. . There are already tests that hit `TableWriter`, and this should result in no functionality change.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8970:59,access,accessing,59,https://hail.is,https://github.com/hail-is/hail/pull/8970,1,['access'],['accessing']
Security,Would be great if we could hash this out. This PR / fix is blocking getting the PR in that uses the AsyncFS everywhere.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10771#issuecomment-904091995:27,hash,hash,27,https://hail.is,https://github.com/hail-is/hail/pull/10771#issuecomment-904091995,1,['hash'],['hash']
Security,"Would it make sense to expose the `a` parameter, to make it easier to move between the three examples you showed? The `mixture` parameter could just be floating point rather than boolean, treating the default `mixture=0` case specially.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3206#issuecomment-375313469:23,expose,expose,23,https://hail.is,https://github.com/hail-is/hail/pull/3206#issuecomment-375313469,1,['expose'],['expose']
Security,"XT Files or directories to add to the working directory of the job. [default: None] │; │ --name TEXT The name of the batch. │; │ --image-name TEXT Name of Docker image for the job (default: hailgenetics/hail) [default: None] │; │ --output -o [text|yaml|json] [default: text] │; │ --help Show this message and exit. │; ╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯. (base) dking@wm28c-761 hail % ; (base) dking@wm28c-761 hail % hailctl hdinsight submit --help ; ; Usage: hailctl hdinsight submit [OPTIONS] NAME STORAGE_ACCOUNT HTTP_PASSWORD ; SCRIPT [ARGUMENTS]... ; ; Submit a job to an HDInsight cluster configured for Hail. ; If you wish to pass option-like arguments you should use ""--"". For example: ; ; $ hailctl hdinsight submit name account password script.py --image-name docker.io/image my_script.py -- some-argument --animal dog ; ; ╭─ Arguments ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮; │ * name TEXT [default: None] [required] │; │ * storage_account TEXT Storage account in which the cluster's container exists. [default: None] [required] │; │ * http_password TEXT Web password for the cluster [default: None] [required] │; │ * script TEXT Path to script. [default: None] [required] │; │ arguments [ARGUMENTS]... You should use -- if you want to pass option-like arguments through. [default: None] │; ╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13447#issuecomment-1681403012:2583,password,password,2583,https://hail.is,https://github.com/hail-is/hail/pull/13447#issuecomment-1681403012,1,['password'],['password']
Security,"YAML has an arbitrary extension mechanism. pyYAML defines a python extension that lets you create arbitrary python objets. This is clearly a huge security vulnerability. Apparently, pyYAML, by default, enables this extension (rather than just parsing vanilla YAML, 🤦‍♀️). `safe_load` loads vanilla YAML without the gaping security hole. I was getting warnings about this when testing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5825:146,secur,security,146,https://hail.is,https://github.com/hail-is/hail/pull/5825,2,['secur'],['security']
Security,"Yeah, that error indicates that those are old format VDS's, so Hail won't load them unless someone with write access to hail-common uses the ""write_partioning"" method to update them. I'll handle that now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1683#issuecomment-295745615:110,access,access,110,https://hail.is,https://github.com/hail-is/hail/issues/1683#issuecomment-295745615,1,['access'],['access']
Security,"Yes - although would that ensure they're unique indices? I had using the variants in a feature vector in mind, which each index err...indexing the vector. (Could also work with samples.). When I did it outside of hail, I hashed the v.contig/v.start values and then used a String Indexer to get unique index values.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1785#issuecomment-300283835:221,hash,hashed,221,https://hail.is,https://github.com/hail-is/hail/issues/1785#issuecomment-300283835,1,['hash'],['hashed']
Security,"Yes I agree, this is something the user should not be exposed. . > On Sep 18, 2018, at 8:00 AM, Tim Poterba <notifications@github.com> wrote:; > ; > I think we need to hide partitioning and do more automatic resizing / partition combining.; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub <https://github.com/hail-is/hail/issues/445#issuecomment-422364795>, or mute the thread <https://github.com/notifications/unsubscribe-auth/ADIkAiuXQNQQSrESG44JjWYXH62FVg0Fks5ucOB2gaJpZM4I995P>.; >",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/445#issuecomment-422365142:54,expose,exposed,54,https://hail.is,https://github.com/hail-is/hail/issues/445#issuecomment-422365142,1,['expose'],['exposed']
Security,"Yes! I want `make deploy` to always mean ""`kubectl apply` this service's kubernetes configuration"" and/or ""push to appropriate public repository"" (c.f. hail's python lib). Cotton can comment more directly on lets encrypt, but there's an issue wrt sharing a volume between two pods that isn't easily resolved. I'm not exactly sure how `make run` is intended to be used.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5413#issuecomment-467103158:213,encrypt,encrypt,213,https://hail.is,https://github.com/hail-is/hail/issues/5413#issuecomment-467103158,1,['encrypt'],['encrypt']
Security,"Yes, for example:. ```; $ gsutil ls gs://hail-ci-0-1/deploy/3b20406ba582d5aebac0c71b6b41f3509e2e1887/; gs://hail-ci-0-1/deploy/3b20406ba582d5aebac0c71b6b41f3509e2e1887/index.html; gs://hail-ci-0-1/deploy/3b20406ba582d5aebac0c71b6b41f3509e2e1887/job.log; ```. where the hash is from master.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4437#issuecomment-438146859:269,hash,hash,269,https://hail.is,https://github.com/hail-is/hail/issues/4437#issuecomment-438146859,1,['hash'],['hash']
Security,You gave me a heart attack when I saw it was approved ;),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12193#issuecomment-1249710272:20,attack,attack,20,https://hail.is,https://github.com/hail-is/hail/pull/12193#issuecomment-1249710272,1,['attack'],['attack']
Security,You'll note that I in `query/Makefile` the JAR_LOCATION for `default` is *not* the normal location. I don't want developers accidentally uploading garbage JARs to publicly accessibly SHAs. We should probably be setting retention holds on the JARs uploaded by CI.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11645#issuecomment-1075853803:172,access,accessibly,172,https://hail.is,https://github.com/hail-is/hail/pull/11645#issuecomment-1075853803,1,['access'],['accessibly']
Security,"[""""]; resources: [""services""]; verbs: [""*""]; ---; kind: RoleBinding; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: notebook-create-services; subjects:; - kind: ServiceAccount; name: notebook; namespace: default; roleRef:; kind: Role; name: create-services; apiGroup: """"; ---; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: create-services-and-pods; rules:; - apiGroups: [""""]; resources: [""services""]; verbs: [""*""]; - apiGroups: [""""]; resources: [""pods""]; verbs: [""*""]; ---; kind: RoleBinding; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: notebook-create-services-and-pods; subjects:; - kind: ServiceAccount; name: notebook; namespace: default; roleRef:; kind: Role; name: create-services #this was causing the error, and of course the create-services role is superseded by the the create-services-and-pods role; apiGroup: """"; ---; ```. After:; ```yaml; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: create-services-and-pods; rules:; - apiGroups: [""""]; resources: [""services""]; verbs: [""*""]; - apiGroups: [""""]; resources: [""pods""]; verbs: [""*""]; ---; kind: RoleBinding; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: notebook-create-services-and-pods; subjects:; - kind: ServiceAccount; name: notebook; namespace: default; roleRef:; kind: Role; name: create-services-and-pods; apiGroup: """"; ---; ```. ### Results of test runs. Before:. ```sh; kubectl apply -f k8s-config.yaml; ERROR: (gcloud.compute.addresses.describe) Could not fetch resource:; - Required 'compute.addresses.get' permission for 'projects/hail-vdc-staging/regions/us-central1/addresses/site'. namespace/batch-pods unchanged; ...; The RoleBinding ""notebook-create-services-and-pods"" is invalid: roleRef: Invalid value: rbac.RoleRef{APIGroup:""rbac.authorization.k8s.io"", Kind:""Role"", Name:""create-services""}: cannot change roleRef; make: *** [k8s-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5746:1838,authoriz,authorization,1838,https://hail.is,https://github.com/hail-is/hail/pull/5746,1,['authoriz'],['authorization']
Security,"[#3126](https://github.com/urllib3/urllib3/issues/3126) &lt;https://github.com/urllib3/urllib3/issues/3126&gt;</code>__)</li>; <li>Fixed default <code>blocksize</code> of <code>HTTPConnection</code> classes to match high-level classes. Previously was 8KiB, now 16KiB. (<code>[#3066](https://github.com/urllib3/urllib3/issues/3066) &lt;https://github.com/urllib3/urllib3/issues/3066&gt;</code>__)</li>; </ul>; <h1>2.0.4 (2023-07-19)</h1>; <ul>; <li>Added support for union operators to <code>HTTPHeaderDict</code> (<code>[#2254](https://github.com/urllib3/urllib3/issues/2254) &lt;https://github.com/urllib3/urllib3/issues/2254&gt;</code>__)</li>; <li>Added <code>BaseHTTPResponse</code> to <code>urllib3.__all__</code> (<code>[#3078](https://github.com/urllib3/urllib3/issues/3078) &lt;https://github.com/urllib3/urllib3/issues/3078&gt;</code>__)</li>; <li>Fixed <code>urllib3.connection.HTTPConnection</code> to raise the <code>http.client.connect</code> audit event to have the same behavior as the standard library HTTP client (<code>[#2757](https://github.com/urllib3/urllib3/issues/2757) &lt;https://github.com/urllib3/urllib3/issues/2757&gt;</code>__)</li>; <li>Relied on the standard library for checking hostnames in supported PyPy releases (<code>[#3087](https://github.com/urllib3/urllib3/issues/3087) &lt;https://github.com/urllib3/urllib3/issues/3087&gt;</code>__)</li>; </ul>; <h1>2.0.3 (2023-06-07)</h1>; <ul>; <li>Allowed alternative SSL libraries such as LibreSSL, while still issuing a warning as we cannot help users facing issues with implementations other than OpenSSL. (<code>[#3020](https://github.com/urllib3/urllib3/issues/3020) &lt;https://github.com/urllib3/urllib3/issues/3020&gt;</code>__)</li>; <li>Deprecated URLs which don't have an explicit scheme (<code>[#2950](https://github.com/urllib3/urllib3/issues/2950) &lt;https://github.com/urllib3/urllib3/pull/2950&gt;</code>_)</li>; <li>Fixed response decoding with Zstandard when compressed data is made of several frames.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13768:9143,audit,audit,9143,https://hail.is,https://github.com/hail-is/hail/pull/13768,3,['audit'],['audit']
Security,[CI] Remove Iris and M Franklin from authorized users and teams lists,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14704:37,authoriz,authorized,37,https://hail.is,https://github.com/hail-is/hail/pull/14704,1,['authoriz'],['authorized']
Security,[DB] Remove redundant f-strings and validate ints,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14669:36,validat,validate,36,https://hail.is,https://github.com/hail-is/hail/pull/14669,1,['validat'],['validate']
Security,[Github] Security impact field in templates,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14666:9,Secur,Security,9,https://hail.is,https://github.com/hail-is/hail/pull/14666,1,['Secur'],['Security']
Security,[Snyk] Security upgrade aiohttp from 3.8.4 to 3.8.5,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13282:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/13282,5,['Secur'],['Security']
Security,[Snyk] Security upgrade aiohttp from 3.8.6 to 3.9.0,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14034:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/14034,11,['Secur'],['Security']
Security,[Snyk] Security upgrade aiohttp from 3.8.6 to 3.9.2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14220:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/14220,5,['Secur'],['Security']
Security,[Snyk] Security upgrade certifi from 2023.5.7 to 2023.7.22,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13294:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/13294,6,['Secur'],['Security']
Security,[Snyk] Security upgrade cryptography from 40.0.2 to 41.0.0,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13136:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/13136,3,['Secur'],['Security']
Security,[Snyk] Security upgrade cryptography from 41.0.1 to 41.0.2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13247:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/13247,1,['Secur'],['Security']
Security,[Snyk] Security upgrade cryptography from 41.0.2 to 41.0.3,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13365:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/13365,3,['Secur'],['Security']
Security,[Snyk] Security upgrade cryptography from 41.0.3 to 41.0.4,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13698:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/13698,3,['Secur'],['Security']
Security,[Snyk] Security upgrade cryptography from 41.0.7 to 42.0.0,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14200:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/14200,3,['Secur'],['Security']
Security,[Snyk] Security upgrade cryptography from 41.0.7 to 42.0.2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14230:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/14230,4,['Secur'],['Security']
Security,[Snyk] Security upgrade cryptography from 42.0.2 to 42.0.4,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14343:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/14343,2,['Secur'],['Security']
Security,[Snyk] Security upgrade jinja2 from 3.1.2 to 3.1.3,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14136:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/14136,3,['Secur'],['Security']
Security,[Snyk] Security upgrade jupyter-server from 1.24.0 to 2.11.2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14070:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/14070,1,['Secur'],['Security']
Security,[Snyk] Security upgrade msal from 1.24.0 to 1.24.1,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13753:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/13753,2,['Secur'],['Security']
Security,[Snyk] Security upgrade numpy from 1.21.3 to 1.22.2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12895:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/12895,1,['Secur'],['Security']
Security,[Snyk] Security upgrade orjson from 3.9.7 to 3.9.15,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14355:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/14355,2,['Secur'],['Security']
Security,[Snyk] Security upgrade pillow from 9.5.0 to 10.0.1,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13708:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/13708,1,['Secur'],['Security']
Security,[Snyk] Security upgrade requests from 2.28.2 to 2.31.0,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13097:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/13097,8,['Secur'],['Security']
Security,[Snyk] Security upgrade setuptools from 39.0.1 to 65.5.1,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12896:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/12896,1,['Secur'],['Security']
Security,[Snyk] Security upgrade tornado from 6.2 to 6.3.2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13066:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/13066,3,['Secur'],['Security']
Security,[Snyk] Security upgrade tornado from 6.2 to 6.3.3,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13436:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/13436,3,['Secur'],['Security']
Security,[Snyk] Security upgrade urllib3 from 1.26.16 to 1.26.17,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13770:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/13770,5,['Secur'],['Security']
Security,[Snyk] Security upgrade urllib3 from 1.26.17 to 1.26.18,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13847:7,Secur,Security,7,https://hail.is,https://github.com/hail-is/hail/pull/13847,5,['Secur'],['Security']
Security,"[`BlockMatrixIsDistributedMatrix`](https://github.com/hail-is/hail/blob/master/src/main/scala/is/hail/distributedmatrix/BlockMatrixIsDistributedMatrix.scala) implements the [`DistributedMatrix`](https://github.com/hail-is/hail/blob/master/src/main/scala/is/hail/distributedmatrix/DistributedMatrix.scala) API for Spark's `BlockMatrix` type. We should rewrite `BlockMatrix` from scratch to use Breeze matrices because the Spark `DenseMatrix` type doesn't provide a rich interface, in particular there are no exposed mutation primitives. I hope that an implementation on top of Breeze can more efficiently implement `vectorAddToEveryColumn` and `vectorPointwiseMultiplyEveryColumn` and `vectorPointwiseMultiplyEveryRow`. Also, we can move into `is.hail.distributedmatrix` `BetterBlockMatrix` which we, rather illicitly, shove into the apache package during jar creation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1979:507,expose,exposed,507,https://hail.is,https://github.com/hail-is/hail/issues/1979,1,['expose'],['exposed']
Security,[aiocloud] refresh access tokens after transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14083:19,access,access,19,https://hail.is,https://github.com/hail-is/hail/pull/14083,1,['access'],['access']
Security,[apiserver] authentication,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5893:12,authenticat,authentication,12,https://hail.is,https://github.com/hail-is/hail/pull/5893,1,['authenticat'],['authentication']
Security,[auth] Allow use of cloud access tokens for hail batch authorization,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13084:26,access,access,26,https://hail.is,https://github.com/hail-is/hail/pull/13084,4,"['access', 'authoriz']","['access', 'authorization']"
Security,[auth] maybe fix auth flow & close security hole,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8052:35,secur,security,35,https://hail.is,https://github.com/hail-is/hail/pull/8052,1,['secur'],['security']
Security,"[batch,ci] expose attempts to clients and ci",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8762:11,expose,expose,11,https://hail.is,https://github.com/hail-is/hail/pull/8762,1,['expose'],['expose']
Security,[batch/worker] retry access token request,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10234:21,access,access,21,https://hail.is,https://github.com/hail-is/hail/pull/10234,1,['access'],['access']
Security,[batch2] expose configuration in batch2 driver web UI,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7606:9,expose,expose,9,https://hail.is,https://github.com/hail-is/hail/pull/7606,1,['expose'],['expose']
Security,[batch2] fix instance_id integrity,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7443:25,integrity,integrity,25,https://hail.is,https://github.com/hail-is/hail/pull/7443,1,['integrity'],['integrity']
Security,[batch2] secure driver endpoints,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7440:9,secur,secure,9,https://hail.is,https://github.com/hail-is/hail/pull/7440,1,['secur'],['secure']
Security,[batch] Add batch-config to expose current batch id to user jobs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12246:28,expose,expose,28,https://hail.is,https://github.com/hail-is/hail/pull/12246,1,['expose'],['expose']
Security,[batch] Add special-casing for Artifact Registry access denied message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12257:49,access,access,49,https://hail.is,https://github.com/hail-is/hail/pull/12257,1,['access'],['access']
Security,[batch] CI needs access to the admin service account,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9728:17,access,access,17,https://hail.is,https://github.com/hail-is/hail/pull/9728,1,['access'],['access']
Security,[batch] Dont use the authorization header for worker tokens to the driver,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13071:21,authoriz,authorization,21,https://hail.is,https://github.com/hail-is/hail/pull/13071,1,['authoriz'],['authorization']
Security,[batch] Expose and test SQL table operations,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5784:8,Expose,Expose,8,https://hail.is,https://github.com/hail-is/hail/pull/5784,1,['Expose'],['Expose']
Security,[batch] Expose billing page to non-dev users,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10656:8,Expose,Expose,8,https://hail.is,https://github.com/hail-is/hail/pull/10656,2,['Expose'],['Expose']
Security,[batch] Expose idempotency token,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10101:8,Expose,Expose,8,https://hail.is,https://github.com/hail-is/hail/pull/10101,1,['Expose'],['Expose']
Security,[batch] Expose job group structure in the UI,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14600:8,Expose,Expose,8,https://hail.is,https://github.com/hail-is/hail/pull/14600,1,['Expose'],['Expose']
Security,[batch] Expose job private and nonpreemptible machines,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10283:8,Expose,Expose,8,https://hail.is,https://github.com/hail-is/hail/pull/10283,1,['Expose'],['Expose']
Security,[batch] Expose region variable to users,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12465:8,Expose,Expose,8,https://hail.is,https://github.com/hail-is/hail/pull/12465,1,['Expose'],['Expose']
Security,[batch] Fix access logger filters,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11901:12,access,access,12,https://hail.is,https://github.com/hail-is/hail/pull/11901,1,['access'],['access']
Security,[batch] Fix audit for the deduping bp user resources migration,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13117:12,audit,audit,12,https://hail.is,https://github.com/hail-is/hail/pull/13117,1,['audit'],['audit']
Security,[batch] Fix dedup billing project user resources audit,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13069:49,audit,audit,49,https://hail.is,https://github.com/hail-is/hail/pull/13069,1,['audit'],['audit']
Security,"[batch] Give users in billing project access to batches, jobs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9954:38,access,access,38,https://hail.is,https://github.com/hail-is/hail/pull/9954,1,['access'],['access']
Security,"[batch] Properly expose and document ""job-private instances""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14500:17,expose,expose,17,https://hail.is,https://github.com/hail-is/hail/issues/14500,1,['expose'],['expose']
Security,[batch] Tone down access log messages that are not helpful,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11897:18,access,access,18,https://hail.is,https://github.com/hail-is/hail/pull/11897,1,['access'],['access']
Security,[batch] add ability to fetch access tokens from instance metadata server,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10647:29,access,access,29,https://hail.is,https://github.com/hail-is/hail/pull/10647,1,['access'],['access']
Security,[batch] add port to ExposedPorts,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7785:20,Expose,ExposedPorts,20,https://hail.is,https://github.com/hail-is/hail/pull/7785,1,['Expose'],['ExposedPorts']
Security,[batch] authentication,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5844:8,authenticat,authentication,8,https://hail.is,https://github.com/hail-is/hail/pull/5844,1,['authenticat'],['authentication']
Security,[batch] billing project page should validate user names and reject invalid usernames,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13858:36,validat,validate,36,https://hail.is,https://github.com/hail-is/hail/issues/13858,1,['validat'],['validate']
Security,[batch] convert activity logs to audit logs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9439:33,audit,audit,33,https://hail.is,https://github.com/hail-is/hail/pull/9439,1,['audit'],['audit']
Security,"[batch] cookies, headers, authentication",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5605:26,authenticat,authentication,26,https://hail.is,https://github.com/hail-is/hail/pull/5605,1,['authenticat'],['authentication']
Security,[batch] expose ABC Resource to users,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9515:8,expose,expose,8,https://hail.is,https://github.com/hail-is/hail/pull/9515,1,['expose'],['expose']
Security,[batch] expose ABC Resource to users (previously #9515),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9575:8,expose,expose,8,https://hail.is,https://github.com/hail-is/hail/pull/9575,1,['expose'],['expose']
Security,[batch] expose Job.spot,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13396:8,expose,expose,8,https://hail.is,https://github.com/hail-is/hail/pull/13396,1,['expose'],['expose']
Security,[batch] expose gcsfuse to the user version of batch,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8980:8,expose,expose,8,https://hail.is,https://github.com/hail-is/hail/pull/8980,1,['expose'],['expose']
Security,[batch] expose gcsfuse to user,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8961:8,expose,expose,8,https://hail.is,https://github.com/hail-is/hail/pull/8961,2,['expose'],['expose']
Security,"[batch] expose job cloud location to input, main, and output containers",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14189:8,expose,expose,8,https://hail.is,https://github.com/hail-is/hail/issues/14189,1,['expose'],['expose']
Security,[batch] expose to the web UI the always_run status of a job,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14210:8,expose,expose,8,https://hail.is,https://github.com/hail-is/hail/issues/14210,1,['expose'],['expose']
Security,[batch] faster no access to metadata test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9416:18,access,access,18,https://hail.is,https://github.com/hail-is/hail/pull/9416,1,['access'],['access']
Security,[batch] fix batch create validation,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7915:25,validat,validation,25,https://hail.is,https://github.com/hail-is/hail/pull/7915,1,['validat'],['validation']
Security,[batch] introduce Support-Logs-Specs-and-Firewall fee,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13542:41,Firewall,Firewall,41,https://hail.is,https://github.com/hail-is/hail/pull/13542,1,['Firewall'],['Firewall']
Security,[batch] more information on integrity error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8632:28,integrity,integrity,28,https://hail.is,https://github.com/hail-is/hail/pull/8632,1,['integrity'],['integrity']
Security,[batch] rewrite schema validation so that schema description is working validation function,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9861:23,validat,validation,23,https://hail.is,https://github.com/hail-is/hail/pull/9861,2,['validat'],['validation']
Security,[batch] synchronize all access to QoBOutputStreamManager map,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13546:24,access,access,24,https://hail.is,https://github.com/hail-is/hail/pull/13546,1,['access'],['access']
Security,[batch] validate that gcsfuse bucket and local paths are not empty,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10543:8,validat,validate,8,https://hail.is,https://github.com/hail-is/hail/pull/10543,1,['validat'],['validate']
Security,[batch] validation errors should be 400 BAD REQUEST,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5032:8,validat,validation,8,https://hail.is,https://github.com/hail-is/hail/pull/5032,1,['validat'],['validation']
Security,[benchmark] Expose functionality to label batches (e.g. branch name),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8119:12,Expose,Expose,12,https://hail.is,https://github.com/hail-is/hail/pull/8119,1,['Expose'],['Expose']
Security,[benchmark] Expose running benchmarks with lowering,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9613:12,Expose,Expose,12,https://hail.is,https://github.com/hail-is/hail/pull/9613,1,['Expose'],['Expose']
Security,[benchmark] added authorization,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9153:18,authoriz,authorization,18,https://hail.is,https://github.com/hail-is/hail/pull/9153,1,['authoriz'],['authorization']
Security,"[bugfix] Fix entry filtering semantics in aggregation, expose unfilter",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5501:55,expose,expose,55,https://hail.is,https://github.com/hail-is/hail/pull/5501,1,['expose'],['expose']
Security,[ci] Add John C to authorized users,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6320:19,authoriz,authorized,19,https://hail.is,https://github.com/hail-is/hail/pull/6320,1,['authoriz'],['authorized']
Security,[ci] Add Vedant to Authorized Users,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11208:19,Authoriz,Authorized,19,https://hail.is,https://github.com/hail-is/hail/pull/11208,1,['Authoriz'],['Authorized']
Security,[ci] Add sjparsa as an authorized user,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13257:23,authoriz,authorized,23,https://hail.is,https://github.com/hail-is/hail/pull/13257,1,['authoriz'],['authorized']
Security,[ci] Cleanup authorized users and PR random assignments,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11880:13,authoriz,authorized,13,https://hail.is,https://github.com/hail-is/hail/pull/11880,1,['authoriz'],['authorized']
Security,[ci] Expose `HAIL_CI_STORAGE_URI` as `ci_storage_uri` in CI Steps,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14419:5,Expose,Expose,5,https://hail.is,https://github.com/hail-is/hail/pull/14419,1,['Expose'],['Expose']
Security,[ci] Expose batch user volumes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5897:5,Expose,Expose,5,https://hail.is,https://github.com/hail-is/hail/pull/5897,1,['Expose'],['Expose']
Security,[ci] Expose operator page to change internal-gateway rate limit,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14399:5,Expose,Expose,5,https://hail.is,https://github.com/hail-is/hail/issues/14399,1,['Expose'],['Expose']
Security,[ci] access denied to artifacts,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5546:5,access,access,5,https://hail.is,https://github.com/hail-is/hail/issues/5546,1,['access'],['access']
Security,[ci] add @cjllanwarne to authorized ci users,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14632:25,authoriz,authorized,25,https://hail.is,https://github.com/hail-is/hail/pull/14632,1,['authoriz'],['authorized']
Security,[ci] add Daniel Goldstein to authorized users,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9881:29,authoriz,authorized,29,https://hail.is,https://github.com/hail-is/hail/pull/9881,1,['authoriz'],['authorized']
Security,[ci] add authorize sha and action items table to user page,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10142:9,authoriz,authorize,9,https://hail.is,https://github.com/hail-is/hail/pull/10142,1,['authoriz'],['authorize']
Security,[ci] add nawatts as authorized user,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8905:20,authoriz,authorized,20,https://hail.is,https://github.com/hail-is/hail/pull/8905,1,['authoriz'],['authorized']
Security,[ci] authorized users cleanup,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12137:5,authoriz,authorized,5,https://hail.is,https://github.com/hail-is/hail/pull/12137,1,['authoriz'],['authorized']
Security,[ci] authorized users house keeping,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9815:5,authoriz,authorized,5,https://hail.is,https://github.com/hail-is/hail/pull/9815,1,['authoriz'],['authorized']
Security,[ci] csrf mitigation for sha authorization,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6420:29,authoriz,authorization,29,https://hail.is,https://github.com/hail-is/hail/pull/6420,1,['authoriz'],['authorization']
Security,[ci] fix retry and authorize sha links,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8527:19,authoriz,authorize,19,https://hail.is,https://github.com/hail-is/hail/pull/8527,1,['authoriz'],['authorize']
Security,[ci] support authorized shas for external PRs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6308:13,authoriz,authorized,13,https://hail.is,https://github.com/hail-is/hail/pull/6308,1,['authoriz'],['authorized']
Security,[ci] switch to a new personal access token,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14384:30,access,access,30,https://hail.is,https://github.com/hail-is/hail/pull/14384,1,['access'],['access']
Security,[compiler] Sort reference genomes by name in ModuleBuilder accessors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10709:59,access,accessors,59,https://hail.is,https://github.com/hail-is/hail/pull/10709,1,['access'],['accessors']
Security,[compiler] incremental hashing based on Threefry,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13317:23,hash,hashing,23,https://hail.is,https://github.com/hail-is/hail/pull/13317,1,['hash'],['hashing']
Security,[dev-docs] More detailed certificate rotation instructions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14734:25,certificate,certificate,25,https://hail.is,https://github.com/hail-is/hail/pull/14734,1,['certificate'],['certificate']
Security,[devbin] Automate cloning db and accessing it with a preconfigured VM,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12794:33,access,accessing,33,https://hail.is,https://github.com/hail-is/hail/pull/12794,1,['access'],['accessing']
Security,[devbin] do not authenticate everytime I change projects,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11403:16,authenticat,authenticate,16,https://hail.is,https://github.com/hail-is/hail/pull/11403,1,['authenticat'],['authenticate']
Security,[devdocs] Add instructions on giving a dev admin access to their dev namespace,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13347:49,access,access,49,https://hail.is,https://github.com/hail-is/hail/pull/13347,1,['access'],['access']
Security,[docs] Expose hailtop.fs and hailtop.batch in query docs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13114:7,Expose,Expose,7,https://hail.is,https://github.com/hail-is/hail/pull/13114,1,['Expose'],['Expose']
Security,[fs] Document and expose the AsyncFS interface,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14021:18,expose,expose,18,https://hail.is,https://github.com/hail-is/hail/issues/14021,1,['expose'],['expose']
Security,[fs] LocalAsyncFS: validate file URL,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10363:19,validat,validate,19,https://hail.is,https://github.com/hail-is/hail/pull/10363,1,['validat'],['validate']
Security,[fs] allows reading from public access buckets,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14292:32,access,access,32,https://hail.is,https://github.com/hail-is/hail/pull/14292,1,['access'],['access']
Security,[fs] expose hl.fast_stat and hl.hadoop_fast_stat to user,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13884:5,expose,expose,5,https://hail.is,https://github.com/hail-is/hail/pull/13884,1,['expose'],['expose']
Security,[fs] expose hl.fast_stat and hl.hadoop_fast_stat to users,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13886:5,expose,expose,5,https://hail.is,https://github.com/hail-is/hail/pull/13886,1,['expose'],['expose']
Security,[gateway] Include the X-Hail-Internal-Authorization header on interna…,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12451:38,Authoriz,Authorization,38,https://hail.is,https://github.com/hail-is/hail/pull/12451,1,['Authoriz'],['Authorization']
Security,[gear] Dont redirect to auth flow if authenticated but not authorized,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12021:37,authenticat,authenticated,37,https://hail.is,https://github.com/hail-is/hail/pull/12021,2,"['authenticat', 'authoriz']","['authenticated', 'authorized']"
Security,[grafana] Add grafana authorization token to prometheus requests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10772:22,authoriz,authorization,22,https://hail.is,https://github.com/hail-is/hail/pull/10772,1,['authoriz'],['authorization']
Security,[haas] support manual copy/paste authentication,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8158:33,authenticat,authentication,33,https://hail.is,https://github.com/hail-is/hail/issues/8158,1,['authenticat'],['authentication']
Security,[hail] update authorized users,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7179:14,authoriz,authorized,14,https://hail.is,https://github.com/hail-is/hail/pull/7179,1,['authoriz'],['authorized']
Security,[hail][bugfix] Fix IR hashing issues,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6978:22,hash,hashing,22,https://hail.is,https://github.com/hail-is/hail/pull/6978,1,['hash'],['hashing']
Security,[hail][combiner] expose vcf_combiner documentation,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7318:17,expose,expose,17,https://hail.is,https://github.com/hail-is/hail/pull/7318,1,['expose'],['expose']
Security,[hail][feature] Expose `binary_search` for numeric arrays.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6123:16,Expose,Expose,16,https://hail.is,https://github.com/hail-is/hail/pull/6123,1,['Expose'],['Expose']
Security,[hailctl/dataproc] Support Broad's GCP Security Best Practices Document,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7978:39,Secur,Security,39,https://hail.is,https://github.com/hail-is/hail/pull/7978,1,['Secur'],['Security']
Security,[hailctl] Add hailctl auth command to print a hail access token,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13934:51,access,access,51,https://hail.is,https://github.com/hail-is/hail/pull/13934,1,['access'],['access']
Security,[hailctl] Fix validation for remote_tmpdir to allow azure https scheme,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13051:14,validat,validation,14,https://hail.is,https://github.com/hail-is/hail/pull/13051,1,['validat'],['validation']
Security,[hailctl] authenticated curl,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8408:10,authenticat,authenticated,10,https://hail.is,https://github.com/hail-is/hail/pull/8408,1,['authenticat'],['authenticated']
Security,[hailctl] expose JSON unsafeDecode as a hailctl command,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6714:10,expose,expose,10,https://hail.is,https://github.com/hail-is/hail/issues/6714,1,['expose'],['expose']
Security,[hailctl] generate a friendly error message if not authenticated,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7035:51,authenticat,authenticated,51,https://hail.is,https://github.com/hail-is/hail/pull/7035,1,['authenticat'],['authenticated']
Security,[hailctl] improve accessibility of max age and expiration time,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9263:18,access,accessibility,18,https://hail.is,https://github.com/hail-is/hail/pull/9263,1,['access'],['accessibility']
Security,"[hailjwt,ci] fix authorized sha csrf",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6434:17,authoriz,authorized,17,https://hail.is,https://github.com/hail-is/hail/pull/6434,1,['authoriz'],['authorized']
Security,[hailtop.batch] expose batch pool executor docs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9156:16,expose,expose,16,https://hail.is,https://github.com/hail-is/hail/pull/9156,1,['expose'],['expose']
Security,[infra] Add batch worker network security group,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11027:33,secur,security,33,https://hail.is,https://github.com/hail-is/hail/pull/11027,1,['secur'],['security']
Security,[infra] SOPS-encrypt global.tfvars for Azure deployment,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14457:13,encrypt,encrypt,13,https://hail.is,https://github.com/hail-is/hail/issues/14457,1,['encrypt'],['encrypt']
Security,[infra] make all buckets created by TF uniform access,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14268:47,access,access,47,https://hail.is,https://github.com/hail-is/hail/pull/14268,1,['access'],['access']
Security,[infra] use uniform bucket level access,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13015:33,access,access,33,https://hail.is,https://github.com/hail-is/hail/pull/13015,1,['access'],['access']
Security,[internal-gateway] add allow global access to the yaml,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8947:36,access,access,36,https://hail.is,https://github.com/hail-is/hail/pull/8947,1,['access'],['access']
Security,[internal-gateway] disable access log,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11978:27,access,access,27,https://hail.is,https://github.com/hail-is/hail/pull/11978,1,['access'],['access']
Security,[k8s] Dont require access to default secrets when make deploying,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13338:19,access,access,19,https://hail.is,https://github.com/hail-is/hail/pull/13338,1,['access'],['access']
Security,[letsencrypt] add benchmark to hail.is certificate domains,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9246:39,certificate,certificate,39,https://hail.is,https://github.com/hail-is/hail/pull/9246,1,['certificate'],['certificate']
Security,[monitoring] Expose disk and instance counts to prometheus,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10650:13,Expose,Expose,13,https://hail.is,https://github.com/hail-is/hail/pull/10650,1,['Expose'],['Expose']
Security,[notebook] fix notebook service to expose nginx and use http with workers,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10292:35,expose,expose,35,https://hail.is,https://github.com/hail-is/hail/pull/10292,1,['expose'],['expose']
Security,[pip] Resolve security vulns in pymysql and requests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14558:14,secur,security,14,https://hail.is,https://github.com/hail-is/hail/pull/14558,1,['secur'],['security']
Security,[qob] use a regional bucket with uniform access control,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12969:41,access,access,41,https://hail.is,https://github.com/hail-is/hail/pull/12969,1,['access'],['access']
Security,[query/vds] Add ref_block_max_length check to VariantDataset.validate,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14405:61,validat,validate,61,https://hail.is,https://github.com/hail-is/hail/pull/14405,1,['validat'],['validate']
Security,[query] Expose Table._map_partitions in Python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9142:8,Expose,Expose,8,https://hail.is,https://github.com/hail-is/hail/pull/9142,1,['Expose'],['Expose']
Security,[query] Expose TableGen to Python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12737:8,Expose,Expose,8,https://hail.is,https://github.com/hail-is/hail/pull/12737,1,['Expose'],['Expose']
Security,"[query] Expose _calculate_new_partitions on MatrixTable, expose on read",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9887:8,Expose,Expose,8,https://hail.is,https://github.com/hail-is/hail/pull/9887,2,"['Expose', 'expose']","['Expose', 'expose']"
Security,[query] Expose _nd as nd,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9061:8,Expose,Expose,8,https://hail.is,https://github.com/hail-is/hail/pull/9061,1,['Expose'],['Expose']
Security,[query] Expose `hl.keyed_intersection` and `hl.keyed_union` in Python.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12512:8,Expose,Expose,8,https://hail.is,https://github.com/hail-is/hail/pull/12512,1,['Expose'],['Expose']
Security,[query] Expose hl.tmp_dir,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9890:8,Expose,Expose,8,https://hail.is,https://github.com/hail-is/hail/pull/9890,1,['Expose'],['Expose']
Security,[query] Expose references via `ExecuteContext`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14686:8,Expose,Expose,8,https://hail.is,https://github.com/hail-is/hail/pull/14686,1,['Expose'],['Expose']
Security,[query] Hash codes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10680:8,Hash,Hash,8,https://hail.is,https://github.com/hail-is/hail/pull/10680,1,['Hash'],['Hash']
Security,[query] Refactor lowering to expose ExecuteContext,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8614:29,expose,expose,29,https://hail.is,https://github.com/hail-is/hail/pull/8614,1,['expose'],['expose']
Security,[query] Throw a validation error for queries that read/write same path,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8327:16,validat,validation,16,https://hail.is,https://github.com/hail-is/hail/pull/8327,1,['validat'],['validation']
Security,[query] expose VDS docs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10998:8,expose,expose,8,https://hail.is,https://github.com/hail-is/hail/pull/10998,1,['expose'],['expose']
Security,[query] expose `lower_tail` and `log_p` parameters in normal and chi-squared statistical functions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11038:8,expose,expose,8,https://hail.is,https://github.com/hail-is/hail/pull/11038,1,['expose'],['expose']
Security,[query] freeze when necessary to avoid hashing issues,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12265:39,hash,hashing,39,https://hail.is,https://github.com/hail-is/hail/pull/12265,1,['hash'],['hashing']
Security,[query] logistic_regression_rows should expose the null model fit to the user as a global,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13789:40,expose,expose,40,https://hail.is,https://github.com/hail-is/hail/issues/13789,1,['expose'],['expose']
Security,[query] refactor BaseIR so children only exposes iterable interface,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13214:41,expose,exposes,41,https://hail.is,https://github.com/hail-is/hail/pull/13214,1,['expose'],['exposes']
Security,[query] refactor primitive SValue -> Value accessor,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11242:43,access,accessor,43,https://hail.is,https://github.com/hail-is/hail/pull/11242,1,['access'],['accessor']
Security,[query] secure query,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8746:8,secur,secure,8,https://hail.is,https://github.com/hail-is/hail/pull/8746,1,['secur'],['secure']
Security,"[query] use fs, not raw open to access resources",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10941:32,access,access,32,https://hail.is,https://github.com/hail-is/hail/pull/10941,1,['access'],['access']
Security,[query] validation system needs to gracefully handle public access buckets,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14291:8,validat,validation,8,https://hail.is,https://github.com/hail-is/hail/issues/14291,2,"['access', 'validat']","['access', 'validation']"
Security,[query][qob][hailtop/fs] Expose modification and creation time.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12571:25,Expose,Expose,25,https://hail.is,https://github.com/hail-is/hail/pull/12571,1,['Expose'],['Expose']
Security,[router-resolver] add access logger to router resolver,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9911:22,access,access,22,https://hail.is,https://github.com/hail-is/hail/pull/9911,1,['access'],['access']
Security,[security] bump cryptography again,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13375:1,secur,security,1,https://hail.is,https://github.com/hail-is/hail/pull/13375,1,['secur'],['security']
Security,"[security] delete after 5 days, ignore system managed, consider two special secrets",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13319:1,secur,security,1,https://hail.is,https://github.com/hail-is/hail/pull/13319,1,['secur'],['security']
Security,[security] enable CodeQL for main and PRs to main,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12269:1,secur,security,1,https://hail.is,https://github.com/hail-is/hail/pull/12269,1,['secur'],['security']
Security,[security] mitigate CVE-2022-1941,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12286:1,secur,security,1,https://hail.is,https://github.com/hail-is/hail/pull/12286,1,['secur'],['security']
Security,[security] update scipy pin to 1.11.1,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13259:1,secur,security,1,https://hail.is,https://github.com/hail-is/hail/pull/13259,2,['secur'],['security']
Security,"[shuffler] a TLS-secured, networked, out-of-core key-value store for RegionValues",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8361:17,secur,secured,17,https://hail.is,https://github.com/hail-is/hail/pull/8361,1,['secur'],['secured']
Security,[terraform] restore CI access to ci bucket after UBLA is applied,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14271:23,access,access,23,https://hail.is,https://github.com/hail-is/hail/pull/14271,1,['access'],['access']
Security,[vds] Add validate() method to verify assumptions about the VDS representation,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10896:10,validat,validate,10,https://hail.is,https://github.com/hail-is/hail/pull/10896,1,['validat'],['validate']
Security,"] Improve test suite handling of paths, temp ...</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/24a6d64966d99182e95f5d3a29541ef2fec397ad""><code>24a6d64</code></a> Release v3.9.2 (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8082"">#8082</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/9118a5831e8a65b8c839eb7e4ac983e040ff41df""><code>9118a58</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8079"">#8079</a>/1c335944 backport][3.9] Validate static paths (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8080"">#8080</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/435ad46e6c26cbf6ed9a38764e9ba8e7441a0e3b""><code>435ad46</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/3955"">#3955</a>/8960063e backport][3.9] Replace all tmpdir fixtures with tmp_path (...</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/d33bc21414e283c9e6fe7f6caf69e2ed60d66c82""><code>d33bc21</code></a> Improve validation in HTTP parser (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8074"">#8074</a>) (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8078"">#8078</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/0d945d1be08f2ba8475513216a66411f053c3217""><code>0d945d1</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7916"">#7916</a>/822fbc74 backport][3.9] Add more information to contributing page (...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.9.1...v3.9.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.9.1&new-version=3.9.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14219:5364,validat,validation,5364,https://hail.is,https://github.com/hail-is/hail/pull/14219,2,['validat'],['validation']
Security,"] enable mTLS for all services; - [security] disable TLS <1.3; - [security] comply with Mozilla's ""modern"" recommendations; - [batch][security] use a separate network for batch's callbacks. ### liveness probes. Ah, that's a good point. I'll rewrite to use curl and the client's own certificate and I'll make sure clients trust themselves. ### root cert. I don't think it is possible in aiohttp to both verify a certificate has a valid chain from a root cert and, separately, exists in a list of trusted certificates. The effect would be that every client would trust every server because every server certificate is signed by the same root certificate. I think using a root cert is quite secure (a big improvement over our current situation!). However, I endeavored in this PR to additionally prevent, for example, a compromised `notebook` from masquerading as `batch`. I agree that additionally verifying that the certificate came from a single root certificate (that we, perhaps, destroy after everything is signed) would additionally prevent a malicious user from inserting their certificates into the trusted certificates list. AFAICT, python's `ssl` module has no support for this verification strategy. We could probably build an SSLContext shim that contained two SSLContexts one with a root cert and one with the trusted certs and require certification verification to pass both. Seems easy to get wrong, so I'm inclined to not take this path. ### trusted cert lists. Yeah, it felt a little silly to duplicate the cert in each secret. However, this seems like the simplest approach if I require each principal to only trust a subset of incoming/outgoing principals. If I had one secret per principal, then I have to modify build.yaml or deployment.yamls if I modify the trust sets. That seemed error prone. If I had one secret with all the certs, then when a service starts up it has to select the trusted ones and only insert those into its certificate store. This seems OK, but a little har",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561#issuecomment-617428243:1007,certificate,certificate,1007,https://hail.is,https://github.com/hail-is/hail/pull/8561#issuecomment-617428243,4,['certificate'],"['certificate', 'certificates']"
Security,"_20/v1561977819/icon/c.png ""critical severity"") | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Arbitrary Code Execution <br/>[SNYK-PYTHON-IPYTHON-2348630](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-2348630) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-JINJA2-6150717](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `2.11.3 -> 3.1.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Improper Privilege Management <br/>[SNYK-PYTHON-JUPYTERCORE-3063766](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERCORE-3063766) | `jupyter-core:` <br> `4.6.3 -> 4.11.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-MISTUNE-2940625](https://snyk.io/vuln/SNYK-PYTHON-MISTUNE-2940625) | `mistune:` <br> `0.8.4 -> 2.0.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-NBCONVERT-2979829](https://snyk.io/vuln/SNYK-PYTHON-NBCONVERT-2979829) ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14257:2243,Cross-site Scripting,Cross-site Scripting,2243,https://hail.is,https://github.com/hail-is/hail/pull/14257,4,"['Cross-site Scripting', 'XSS']","['Cross-site Scripting', 'XSS']"
Security,"_From @cseed on August 26, 2015 14:51_. Waiting on suitable machines (Intel spark cluster, cloud access, etc.); - measure size of stored data; - compressed vs uncompressed (gzip parquet, lz4 in SparkyVSM, etc.); - compute cost (or at least compute-hrs); - compare best-case (e.g. `gzip -cd file.vcf.gz | wc -l` vs `LoadVCF`). _Copied from original issue: cseed/hail#18_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/19:97,access,access,97,https://hail.is,https://github.com/hail-is/hail/issues/19,1,['access'],['access']
Security,"_From @cseed on September 1, 2015 15:48_. Need general strategy for error reporting. We can't use asserts for input data validation (e.g., reading tsv files, command line flags, etc.) Need to generate good error messages with feedback about line numbers, etc. _Copied from original issue: cseed/hail#42_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/33:121,validat,validation,121,https://hail.is,https://github.com/hail-is/hail/issues/33,1,['validat'],['validation']
Security,"_NULL; L6; FRAME SAME1 java/lang/Object; GOTO L7; L1; FRAME CHOP 1; ACONST_NULL; L7; FRAME SAME1 java/lang/Object; CHECKCAST is/hail/variant/Genotype; ASTORE 6; ALOAD 6; IFNULL L8; ALOAD 6; INVOKEVIRTUAL is/hail/variant/Genotype.unboxedGT ()I; ISTORE 7; ILOAD 7; LDC -1; IF_ICMPEQ L9; GOTO L10; L10; FRAME FULL [is/hail/codegen/generated/C0 java/lang/Object java/lang/Object scala/collection/IndexedSeq T T is/hail/variant/Genotype I] []; NEW java/lang/Integer; DUP; ILOAD 7; INVOKESPECIAL java/lang/Integer.<init> (I)V; GOTO L11; L9; FRAME SAME; ACONST_NULL; L11; FRAME SAME1 java/lang/Integer; GOTO L12; L8; FRAME CHOP 1; ACONST_NULL; L12; FRAME SAME1 java/lang/Integer; CHECKCAST java/lang/Integer; ARETURN; L13; LOCALVARIABLE local3 Ljava/lang/Object; L0 L13 3; LOCALVARIABLE local4 Ljava/lang/Object; L0 L13 4; LOCALVARIABLE local5 I L0 L13 5; LOCALVARIABLE local6 Ljava/lang/Object; L0 L13 6; LOCALVARIABLE local7 I L0 L13 7; MAXSTACK = 3; MAXLOCALS = 8. // access flags 0x1; public <init>()V; ALOAD 0; INVOKESPECIAL java/lang/Object.<init> ()V; RETURN; MAXSTACK = 1; MAXLOCALS = 1; }; Traceback (most recent call last):; File ""/tmp/990e2e0c-f333-467e-b1fd-6cfe8f5d5645/fastlmmForJon.py"", line 6, in <module>; vds = vds.annotate_samples_expr('sa.variant1 = gs.filter(g => v == Variant(""1:15211:T:G"")).collect()[0].gt'); File ""<decorator-gen-65>"", line 2, in annotate_samples_expr; File ""/home/ec2-user/BuildAgent/work/c38e75e72b769a7c/python/hail/java.py"", line 113, in handle_py4j; hail.java.FatalError: IndexOutOfBoundsException: 0. Java stack trace:; java.lang.IndexOutOfBoundsException: 0; 	at scala.collection.mutable.ResizableArray$class.apply(ResizableArray.scala:43); 	at scala.collection.mutable.ArrayBuffer.apply(ArrayBuffer.scala:48); 	at is.hail.codegen.generated.C0.apply(Unknown Source); 	at is.hail.asm4s.Function2Builder$$anon$11.apply(FunctionBuilder.scala:441); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:72); 	at is.hail.expr.CM$$anonfun$runWithDelaye",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1705:2497,access,access,2497,https://hail.is,https://github.com/hail-is/hail/issues/1705,1,['access'],['access']
Security,"__6} --varianceRatioFile=${__RESOURCE_FILE__8}; --SAIGEOutputFile=${__RESOURCE_FILE__748} --groupFile=${__RESOURCE_FILE__20}; --sparseSigmaFile=${__RESOURCE_FILE__9} --IsSingleVarinGroupTest=TRUE --IsOutputAFinCaseCtrl=TRUE; 2>&1 | tee ${__RESOURCE_FILE__749}; env:; - name: POD_IP; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: status.podIP; - name: POD_NAME; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: metadata.name; image: konradjk/saige:0.35.8.2.2; imagePullPolicy: IfNotPresent; name: main; resources:; requests:; cpu: ""1""; memory: 500M; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /gsa-key; name: gsa-key; - mountPath: /io; name: batch-2554-job-4-8vvgl; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: default-token-8h99c; readOnly: true; dnsPolicy: ClusterFirst; enableServiceLinks: true; nodeName: gke-vdc-preemptible-pool-9c7148b2-4gq2; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: default; serviceAccountName: default; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: gsa-key; secret:; defaultMode: 420; secretName: konradk-gsa-key; - name: batch-2554-job-4-8vvgl; persistentVolumeClaim:; claimName: batch-2554-job-4-8vvgl; - name: default-token-8h99c; secret:; defaultMode: 420; secretName: default-token-8h99c; status:; conditions:; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; status: ""True""; type: Initialized; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6466:6257,secur,securityContext,6257,https://hail.is,https://github.com/hail-is/hail/issues/6466,1,['secur'],['securityContext']
Security,"__6} --varianceRatioFile=${__RESOURCE_FILE__8}; --SAIGEOutputFile=${__RESOURCE_FILE__748} --groupFile=${__RESOURCE_FILE__20}; --sparseSigmaFile=${__RESOURCE_FILE__9} --IsSingleVarinGroupTest=TRUE --IsOutputAFinCaseCtrl=TRUE; 2>&1 | tee ${__RESOURCE_FILE__749}; env:; - name: POD_IP; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: status.podIP; - name: POD_NAME; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: metadata.name; image: konradjk/saige:0.35.8.2.2; imagePullPolicy: IfNotPresent; name: main; resources:; requests:; cpu: ""1""; memory: 500M; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /gsa-key; name: gsa-key; - mountPath: /io; name: batch-2554-job-4-8vvgl; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: default-token-8h99c; readOnly: true; dnsPolicy: ClusterFirst; enableServiceLinks: true; nodeName: gke-vdc-preemptible-pool-9c7148b2-4gq2; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: default; serviceAccountName: default; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: gsa-key; secret:; defaultMode: 420; secretName: konradk-gsa-key; - name: batch-2554-job-4-8vvgl; persistentVolumeClaim:; claimName: batch-2554-job-4-8vvgl; - name: default-token-8h99c; secret:; defaultMode: 420; secretName: default-token-8h99c; status:; conditions:; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T12:37:07Z""; status: ""True""; type: Initialized; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T12:37:07Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: """,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649:14532,secur,securityContext,14532,https://hail.is,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649,1,['secur'],['securityContext']
Security,"_add_len is a no-op if LEN is already present; + reference_data = VariantDataset._add_len(reference_data); if _drop_end:; - reference_data = reference_data.drop('END'); + if 'END' in reference_data.entry:; + reference_data = reference_data.drop('END'); + else: # if END is missing, add it, _add_end is a no-op if END is already present; + reference_data = VariantDataset._add_end(reference_data); +; vds = VariantDataset(reference_data, variant_data); if VariantDataset.ref_block_max_length_field not in vds.reference_data.globals:; fs = hl.current_backend().fs; ```. There was nothing in the IR that stood out when I examined it, but I will admit that I'm not the best at digging into it. ### Version. https://github.com/chrisvittal/hail/tree/vds/repro-example. ### Relevant log output. ```shell; E hail.utils.java.FatalError: RuntimeException: invalid memory access: 140a68008/00000001: not in 140a58008/00010000; E; E Java stack trace:; E java.lang.RuntimeException: invalid memory access: 140a68008/00000001: not in 140a58008/00010000; E 	at is.hail.annotations.Memory.checkAddress(Memory.java:226); E 	at is.hail.annotations.Memory.loadByte(Memory.java:130); E 	at is.hail.annotations.Region$.loadByte(Region.scala:28); E 	at is.hail.annotations.Region$.loadBit(Region.scala:86); E 	at __C23148collect_distributed_array_matrix_native_writer.__m23333split_ToArray(Unknown Source); E 	at __C23148collect_distributed_array_matrix_native_writer.apply_region478_486(Unknown Source); E 	at __C23148collect_distributed_array_matrix_native_writer.apply_region16_503(Unknown Source); E 	at __C23148collect_distributed_array_matrix_native_writer.apply_region14_529(Unknown Source); E 	at __C23148collect_distributed_array_matrix_native_writer.apply(Unknown Source); E 	at __C23148collect_distributed_array_matrix_native_writer.apply(Unknown Source); E 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$10(BackendUtils.scala:90); E 	at is.hail.utils.package$.using(package.scala:673); E 	at is.hail.an",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14705:2430,access,access,2430,https://hail.is,https://github.com/hail-is/hail/issues/14705,1,['access'],['access']
Security,"_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main.main(Main.scala) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	... 12 more; 	Suppressed: is.hail.relocated.com.google.cloud.storage.StorageException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 		at is.hail.relocated.com.google.cloud.storage.StorageException.translate(StorageException.java:165) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:298) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1029) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.ResumableMedia.lambda$startUploadForBlobInfo$0(ResumableMedia.java:40) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at com.google.api.gax.retryin",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:17892,access,access,17892,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['access'],['access']
Security,"_per_month); ```. This works out to 143 USD to run a 10,000 VM cluster 24 hours a day for 30 days. I suspect our average VM count in a month is closer to 10 which is within the free tier (340 MiB). I; might be wrong abou the connections per vm per aggregation interval, but this is straightforward to; monitor once we have the logs. For a sense of the cost landscape, these are all free:. 1. 1000 VMs.; 2. 500 VMs, with a sampling rate of 1.; 3. 200 VMs, with a sampling rate of 1, with an interval of 5 minutes.; 4. 10 VMs, with a sampling rate of 1, with an interval of 30 seconds. It's all linear, so if we need to halve the interval we can either change the sampling rate, reasses; our expected number of VM-hours, or adjust the service fee accordingly. We can also assess the landscape of fees necessary to cover costs (ignoring the free 50 GiB):. 1. 15 minute intervals, 0.5 sampling rate, 100 expected connections per vm per interval: 0.0000008; USD per core per hour. 2. 30 second intervals, 1.0 sampling rate, 100 expected connections per vm per interval: 0.00005 USD; per core per hour. 2. 5 second intervals, 1.0 sampling rate, 100 expected connections per vm per interval: 0.0003 USD; per core per hour. 2. 5 second intervals, 1.0 sampling rate, 1000 expected connections per vm per interval (1000 unique; connections per second honestly seems to me quite remarkable performance): 0.003 USD per core per; hour. ```; USD_per_core_per_hour = bytes_per_hour / vms / 1024. / 1024 / 1024 * 0.5 / 16. print(USD_per_core_per_hour); ```. ---. # Conclusion. I think we're safe to enable this with the parameters in this PR (15 minute intervals, 50%; sampling). We can assess unknown parameters, like connections per vm, and get comfortable looking at; these logs. Security constraints or observability demands may push us towards desiring more logs. If that; occurs, we can assess the need for a new fee. Regardless, this fee appears to be small relative to; the current cost of preemptible cores.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12883:5054,Secur,Security,5054,https://hail.is,https://github.com/hail-is/hail/pull/12883,1,['Secur'],['Security']
Security,"_theme/issues/1521"">#1521</a>)</li>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/46f5307dbd32ebb339c3a76514ce5791826ec381""><code>46f5307</code></a> Release 2.0rc2 (<a href=""https://redirect.github.com/readthedocs/sphinx_rtd_theme/issues/1520"">#1520</a>)</li>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/5838e6aa545863fac10c08314f90feb6d7ac7757""><code>5838e6a</code></a> Add support for <code>docutils==0.20.x</code> (<a href=""https://redirect.github.com/readthedocs/sphinx_rtd_theme/issues/1517"">#1517</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/readthedocs/sphinx_rtd_theme/compare/1.3.0...2.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx-rtd-theme&package-manager=pip&previous-version=1.3.0&new-version=2.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14502:4177,secur,security-vulnerabilities,4177,https://hail.is,https://github.com/hail-is/hail/pull/14502,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"_user_resources_v3.resource_id; {where_statement}; - GROUP BY billing_project, `user`, resource_id; + GROUP BY billing_project, `user`, deduped_resource_id; LOCK IN SHARE MODE; -) AS new ON old.billing_project = new.billing_project AND old.`user` = new.`user` AND old.deduped_resource_id = new.resource_id; +) AS new ON old.billing_project = new.billing_project AND old.`user` = new.`user` AND old.deduped_resource_id = new.deduped_resource_id; WHERE new.`usage` != old.`usage`; LIMIT 100;; ''',; where_args + where_args); ; bad_bp_user_records = [record async for record in bad_bp_user_records]; - failing_bp_users = []; for record in bad_bp_user_records:; print(f'found bad bp user record {record}'); failing_bp_users.append((record['billing_project'], record['user'])); ; - if bad_bp_user_records:; - raise Exception(f'errors found in audit'); + if failing_bp_users:; + raise Exception(f'errors found in audit'); ; print(f'finished auditing bp user records in {time.time() - bp_user_audit_start}s'); ```; Manual audit succeeded:. ```; mysql> SELECT old.billing_project, old.`user`, old.deduped_resource_id, old.`usage`, new.`usage`, ABS(new.`usage` - old.`usage`) AS usage_diff; -> FROM (; -> SELECT billing_project, `user`, deduped_resource_id, CAST(COALESCE(SUM(`usage`), 0) AS SIGNED) AS `usage`; -> FROM aggregated_billing_project_user_resources_v2; -> LEFT JOIN resources ON resources.resource_id = aggregated_billing_project_user_resources_v2.resource_id; -> GROUP BY billing_project, `user`, deduped_resource_id; -> LOCK IN SHARE MODE; -> ) AS old; -> LEFT JOIN (; -> SELECT billing_project, `user`, deduped_resource_id, CAST(COALESCE(SUM(`usage`), 0) AS SIGNED) AS `usage`; -> FROM aggregated_billing_project_user_resources_v3; -> LEFT JOIN resources ON resources.resource_id = aggregated_billing_project_user_resources_v3.resource_id; -> GROUP BY billing_project, `user`, deduped_resource_id; -> LOCK IN SHARE MODE; -> ) AS new ON old.billing_project = new.billing_project AND old.`user` =",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13117:2114,audit,audit,2114,https://hail.is,https://github.com/hail-is/hail/pull/13117,1,['audit'],['audit']
Security,"_width</code> setting in basic theme to 360px</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9999"">#9999</a>: LaTeX: separate terms from their definitions by a CR (refs: <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9985"">#9985</a>)</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10062"">#10062</a>: Change the default language to <code>'en'</code> if any language is not set in; <code>conf.py</code></li>; </ul>; <p>5.0.0 final</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10474"">#10474</a>: :confval:<code>language</code> does not accept <code>None</code> as it value. The default; value of <code>language</code> becomes to <code>'en'</code> now.</li>; </ul>; <h2>Deprecated</h2>; <p>5.0.0 b1</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10028"">#10028</a>: jQuery and underscore.js will no longer be automatically injected into; themes from Sphinx 6.0. If you develop a theme or extension that uses the; <code>jQuery</code>, <code>$</code>, or <code>$u</code> global objects, you need to update your; JavaScript or use the mitigation below.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/953002e6261bdd9314ee0a3314aae19479a88c7e""><code>953002e</code></a> Bump to 5.0.0 final</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/3d3e93290bbddede9ce5824119120330b3800e5e""><code>3d3e932</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10463"">#10463</a> from AA-Turner/fix-css-docutils-0-18</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/9298b3e142d48420a8c1edbb353c5d9be3e69348""><code>9298b3e</code></a> Update message catalogs</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11871:3800,inject,injected,3800,https://hail.is,https://github.com/hail-is/hail/pull/11871,1,['inject'],['injected']
Security,"` all behave as expected. ```; import hail as hl. giab_gs_path = 'gs://xxxxxxxx'; giab_ds = hl.import_vcf(giab_gs_path, reference_genome='GRCh38'); giab_sm = hl.SplitMulti(giab_ds); giab_ds = giab_sm.result(); giab_ds.describe(); gaib_ds.count(); gaib_ds._force_count_rows(); # all good. sent_gs_path = 'gs://xxxxxxxxxxx'; sent_ds = hl.import_vcf(sent_gs_path, reference_genome='GRCh38'); sent_sm = hl.SplitMulti(sent_ds); sent_ds = sent_sm.result(); sent_ds.describe(); sent_ds.count(); sent_ds._force_count_rows(); # all good. # then this gives the stack trace below. giab_22_ds = hl.filter_intervals(giab_ds, [hl.parse_locus_interval('chr22', reference_genome='GRCh38')]); ```. Stack trace:. ```; FatalError: ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 20 times, most recent failure: Lost task 0.19 in stage 19.0 (TID 312, gilson-validation-test-2-w-4.c.perfect-atrium-179917.internal, executor 2): java.lang.ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5; 	at is.hail.expr.TableMapRows$$anonfun$execute$5.apply(Relational.scala:1641); 	at is.hail.expr.TableMapRows$$anonfun$execute$5.apply(Relational.scala:1637); 	at is.hail.sparkextras.ContextRDD$$anonfun$mapPartitions$1.apply(ContextRDD.scala:151); 	at is.hail.sparkextras.ContextRDD$$anonfun$mapPartitions$1.apply(ContextRDD.scala:151); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19$$anonfun$apply$20.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19$$anonfun$apply$20.apply(ContextRDD.scala:280); 	at scala.collection.It",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:1200,validat,validation-test-,1200,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410,1,['validat'],['validation-test-']
Security,"`), 0) AS SIGNED) AS `usage`; FROM aggregated_billing_project_user_resources_v3; + LEFT JOIN resources ON resources.resource_id = aggregated_billing_project_user_resources_v3.resource_id; {where_statement}; - GROUP BY billing_project, `user`, resource_id; + GROUP BY billing_project, `user`, deduped_resource_id; LOCK IN SHARE MODE; -) AS new ON old.billing_project = new.billing_project AND old.`user` = new.`user` AND old.deduped_resource_id = new.resource_id; +) AS new ON old.billing_project = new.billing_project AND old.`user` = new.`user` AND old.deduped_resource_id = new.deduped_resource_id; WHERE new.`usage` != old.`usage`; LIMIT 100;; ''',; where_args + where_args); ; bad_bp_user_records = [record async for record in bad_bp_user_records]; - failing_bp_users = []; for record in bad_bp_user_records:; print(f'found bad bp user record {record}'); failing_bp_users.append((record['billing_project'], record['user'])); ; - if bad_bp_user_records:; - raise Exception(f'errors found in audit'); + if failing_bp_users:; + raise Exception(f'errors found in audit'); ; print(f'finished auditing bp user records in {time.time() - bp_user_audit_start}s'); ```; Manual audit succeeded:. ```; mysql> SELECT old.billing_project, old.`user`, old.deduped_resource_id, old.`usage`, new.`usage`, ABS(new.`usage` - old.`usage`) AS usage_diff; -> FROM (; -> SELECT billing_project, `user`, deduped_resource_id, CAST(COALESCE(SUM(`usage`), 0) AS SIGNED) AS `usage`; -> FROM aggregated_billing_project_user_resources_v2; -> LEFT JOIN resources ON resources.resource_id = aggregated_billing_project_user_resources_v2.resource_id; -> GROUP BY billing_project, `user`, deduped_resource_id; -> LOCK IN SHARE MODE; -> ) AS old; -> LEFT JOIN (; -> SELECT billing_project, `user`, deduped_resource_id, CAST(COALESCE(SUM(`usage`), 0) AS SIGNED) AS `usage`; -> FROM aggregated_billing_project_user_resources_v3; -> LEFT JOIN resources ON resources.resource_id = aggregated_billing_project_user_resources_v3.resource_id",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13117:1937,audit,audit,1937,https://hail.is,https://github.com/hail-is/hail/pull/13117,3,['audit'],"['audit', 'auditing']"
Security,"`. This should be read as ""no DES"". It means that the private key is not; itself encrypted using DES and a password.; - `-subj /CN=example.com`. This certificate is valid for a server whose DNS name; is `example.com`. If ""hostname checking"" is enabled (web browsers always; enable it), then the client will reject the certificate if the hostname used; to open the socket does not match the certificate.; - `-addext subjectAltName = ...`. This specifies additional acceptable hostnames; for the aformentioned hostname check. #### Trust. An X.509 Certificate only proves that the principal has a private key. On the; world wide web, ownership of a particular domain, e.g. `example.com`, is; guaranteed by a Certificate Authority (CA). A Certificate Authority (like; letsencypt or VeriSign) digitally signs the certificate of a user that has; proven they own the domain name mentioned in the certificate (see above; discussion of `CN` and `subjectAltName`). Web browsers have a file of the ""root""; certificates of the public Certificate Authorities. They establish a ""chain of; trust"" from a root certificate to the server's certificate. Our system is simpler. We have no root certificate. Each principal has a; certificate which is given to all the principals to which it might; communicate. ### Encryption. TLS has many encryption schemes. I will focus on encryption using a *symmetric*; key because asymmetric schemes do not enable *forward secrecy* [2]. Under; forward secret schemes, the two parties share a private key unknown to all; adversaries. TLS 1.3 makes forward secrecy mandatory. I intend to eventually; require all our services to refuse to speak anything other than TLS 1.3. The shared private key is used to encrypt and decrypt messages sent over a; socket. This poses a problem: how do two parties who have never met each other; agree on a private key without revealing the key to the public? This is a; classic cryptography problem called [key; exchange](https://en.wikipedia.org/wik",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:4715,certificate,certificates,4715,https://hail.is,https://github.com/hail-is/hail/pull/8561,2,"['Certificate', 'certificate']","['Certificate', 'certificates']"
Security,"`; - name: site; domain: site; kind: nginx; incoming:; - admin-pod; - router; ```. A principal named ""site"" exists. Site's domain names are `site`,; `site.NAMESPACE`, `site.NAMESPACE.svc.cluster.local`. Site's configuration files; should be in NGINX configuration file format. Site accepts incoming requests; from the principals named admin-pod and router. Site is not permitted to make; any outgoing requests. `create_certs.py` will create a new secret named; `ssl-config-site` which contains five files:. - `site-config-http.conf`: an NGINX configuration file that configures TLS for; incoming requests.; - `site-config-proxy.conf`: an NGINX configuration file that configures TLS for; outgoing (proxy_pass) requests.; - `site-key.pem`: a private key.; - `site-cert.pem`: a certificate.; - `site-incoming.pem`: a list of certificates trusted for incoming requests.; - `site-outgoing.pem`: a list of certificates expected from outgoing requests. If site makes an HTTP request to a server and that server does not return a; certificate in `site-outgoing.pem`, it will immediately halt the connection. I; intend (though do not currently) site to also reject incoming requests that are; not accompanied by a certificate in `site-incoming.pem`. I describe the [trouble; with that later](#incoming-trust). There are two other kinds: `json` and `curl`. The former is for Hail Python; services. The later is for the admin-pod and image-fetcher. Deploy will run `create_certs` on every master deploy. Newly deployed services; will be unable to talk to not-yet-deployed services. I include the; one-deploy-ago certificates in the trust chains, but once incoming trust is; fixed, I am unsure how to smoothly upgrade services. I probably need to notify; old services to refresh their certificates after the secrets are updated. ### Incoming Trust. Mutual TLS (mTLS) refers to TLS connections wherein both sides are; authenticated. This is rare on the web. In our system, it means verifying that a; request made",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:7598,certificate,certificate,7598,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['certificate'],['certificate']
Security,`HailContext()` was an 0.1 phenomenon. At some point (when we've fully moved things over to using IRs probably) we can totally remove it from Python. It's definitely not meant to be user-exposed.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4987#issuecomment-448322113:187,expose,exposed,187,https://hail.is,https://github.com/hail-is/hail/pull/4987#issuecomment-448322113,1,['expose'],['exposed']
Security,"`IOUtils.toString(InputStream, Charset)` was only introduced in a later version of `commons-io` than we're stuck with because of Indeed's lsmtree. This workaround uses a method that we do have access to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10253:193,access,access,193,https://hail.is,https://github.com/hail-is/hail/pull/10253,1,['access'],['access']
Security,"`STRAIGHT_JOIN`s instead of `INNER JOIN` mades the optimiser start from; `batches` and read its index in reverse before considering other tables in ; subsequent joins. From the [documentation](https://dev.mysql.com/doc/refman/8.4/en/join.html):. > STRAIGHT_JOIN is similar to JOIN, except that the left table is always read; before the right table. This can be used for those (few) cases for which the; join optimizer processes the tables in a suboptimal order. This is advantageous for a couple of reasons:; - We want to list newer batches first; - For this query, the `batches` table has more applicables indexes; - We want the variable to order by to be in the primary key of the first; table so we can read the index in reverse. Before and after timings, collected by running the query 5 times, then using; profiles gathered by MySQL.; ```; +-------+---------------------------------------------------*; | query | description | ; +-------+---------------------------------------------------+; | 0 | All batches accessible to user `ci` |; | 1 | All batches accessible to user `ci` owned by `ci` |; +-------+---------------------------------------------------*. +-------+--------+--------------------------------------------------------+------------+------------+; | query | branch | timings | mean | stdev | ; +-------+--------+--------------------------------------------------------+------------+------------+; | 0 | main | 0.05894400,0.05207850,0.07067875,0.06281800,0.060250 | 0.06095385 | 0.00602255 |; | 1 | main | 14.1106150,12.2619323,13.8442850,12.0749633,14.0297822 | 13.2643156 | 0.90087263 |; +-------+--------+--------------------------------------------------------+------------+------------+; | 0 | PR | 0.04717375,0.04974350,0.04312150,0.04070850,0.04193650 | 0.04453675 | 0.00339069 |; | 1 | PR | 0.04423925,0.03967550,0.03935425,0.04056875,0.05286850 | 0.04334125 | 0.00507140 |; +-------+--------+--------------------------------------------------------+------------+------------",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14649:1704,access,accessible,1704,https://hail.is,https://github.com/hail-is/hail/pull/14649,2,['access'],['accessible']
Security,"`[:, :]` is used to access the globals of one thing in another context",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4027#issuecomment-408647882:20,access,access,20,https://hail.is,https://github.com/hail-is/hail/issues/4027#issuecomment-408647882,1,['access'],['access']
Security,"``; (py311) jigold@wm349-8c4 hail % hailctl batch init; Do you want to create a new bucket in project for temporary files generated by Hail? [y/n]: n; Enter a path to an existing remote temporary directory (ex: gs://my-bucket/batch/tmp): gs://my-bucket/foo/bar; ERROR: You do not have sufficient permissions to get information about bucket my-bucket or it does not exist. If the bucket exists, ask a project administrator to give you the permission ""storage.buckets.get"" or assign you the StorageAdmin role in Google Cloud Storage.; Aborted.; ```. Existing remote tmpdir in wrong region:; ```; (py311) jigold@wm349-8c4 hail % hailctl batch init; Do you want to create a new bucket in project for temporary files generated by Hail? [y/n]: n; Enter a path to an existing remote temporary directory (ex: gs://my-bucket/batch/tmp): gs://hail-batch-jigold-oxmmp/bar/foo; Do you want to give service account jigold-59hi5@hail-vdc.iam.gserviceaccount.com read/write access to bucket hail-batch-jigold-oxmmp? [y/n]: y; Granted service account jigold-59hi5@hail-vdc.iam.gserviceaccount.com read and write access to hail-batch-jigold-oxmmp.; Which region do you want your jobs to run in? [us-central1/us-east1/us-east4/us-west1/us-west2/us-west3/us-west4]: us-east1; WARNING: remote temporary directory ""gs://hail-batch-jigold-oxmmp/bar/foo"" is not located in the selected compute region for Batch jobs ""us-east1"".; Which backend do you want to use for Hail Query? [spark/batch/local]: batch; --------------------; FINAL CONFIGURATION:; --------------------; global/domain=hail.is; batch/remote_tmpdir=gs://hail-batch-jigold-oxmmp/bar/foo; batch/regions=us-east1; batch/backend=service; query/backend=batch; WARNING: Initialized Hail with warnings! The currently specified configuration will result in additional ingress and egress fees when using Hail Batch.; ```. Existing multiregional bucket:. ```; (py311) jigold@wm349-8c4 hail % hailctl batch init; Do you want to create a new bucket in project for tempor",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13279#issuecomment-1679133568:4760,access,access,4760,https://hail.is,https://github.com/hail-is/hail/pull/13279#issuecomment-1679133568,1,['access'],['access']
Security,"```; running: read -i /user/aganna/GPC.vcf.bgz; Exception in thread ""main"" org.apache.hadoop.security.AccessControlException: Permission denied: user=aganna, access=EXECUTE, inode=""/user/aganna/GPC.vcf.bgz"":aganna:supergroup:-rw-r--r—; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/90:93,secur,security,93,https://hail.is,https://github.com/hail-is/hail/issues/90,3,"['Access', 'access', 'secur']","['AccessControlException', 'access', 'security']"
Security,"`ci-test` is failing, and I don't have access to see why",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10058#issuecomment-781728668:39,access,access,39,https://hail.is,https://github.com/hail-is/hail/pull/10058#issuecomment-781728668,1,['access'],['access']
Security,"`h_sq_normalized_lkhd` is the final feature of LinearMixedRegression that should be exposed directly on LinearMixedModel. I also fixed a bug in the relationship of `h2 = s2 / (s2 + t2)` and `gamma = s2/t2` in `_estimate_h_sq_standard_error`, which didn't noticeably change the answer because of the symmetry of the left and right points about the max (curvature of fit parabola doesn't change when reflected over a vertical axis).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3936:84,expose,exposed,84,https://hail.is,https://github.com/hail-is/hail/pull/3936,1,['expose'],['exposed']
Security,"`hl.experimental.import_gtf` is documented as accepting either a string or a `ReferenceGenome` object for its `reference_genome` argument. However, it actually only works correctly with a string because it compares the `reference_genome` argument to the string ""GRCh37"" and calls `hl.get_reference` with the `reference_genome` argument.; https://github.com/hail-is/hail/blob/c9b2ddfa92d619d0e4e22a169157853dc391f29a/hail/python/hail/experimental/import_gtf.py#L162-L173. This changes `import_gtf` to accept a string or `ReferenceGenome` by using `typecheck` to cast the argument into a `ReferenceGenome`. This also corrects the docstring for `_load_gencode_gtf`, which only works with a `ReferenceGenome` because it accesses the `name` property of its `reference_genome` argument.; https://github.com/hail-is/hail/blob/c9b2ddfa92d619d0e4e22a169157853dc391f29a/hail/python/hail/experimental/import_gtf.py#L270-L273",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9034:716,access,accesses,716,https://hail.is,https://github.com/hail-is/hail/pull/9034,1,['access'],['accesses']
Security,"`hl.foo.bar.baz` looks at the __init__files, which work differently from imports. I think you could do `from hail.experimental.import_gtf import _load_gencode_gtf`. One of the tasks for 0.3 is a refactor that prevents everything from being imported and exposed as `hl.blah.blah.blah`, which leads to super long import times.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8264#issuecomment-597047221:253,expose,exposed,253,https://hail.is,https://github.com/hail-is/hail/pull/8264#issuecomment-597047221,1,['expose'],['exposed']
Security,"`network=private` is an escape hatch for CI so certain jobs can talk to internal endpoints on our network that we do not permit user jobs to reach. In `main`, all CI jobs are hard-coded to use `private` in `build.py`, but few jobs in the CI pipeline actually require these heightened privileges. The steps in the CI pipeline are of the following types:. - `BuildImageStep`: These do not need to use the private network and have now all been made to use the public network namespaces; - `CreateDatabaseStep`: These *do* need to use `network='private'` because all our DBs only have private IPs on our internal network; - `RunImageStep`: Those steps that contact the DB need the private network. This PR makes the network configurable for these steps but default to public, so steps that need DB access explicitly do `network: private`; - `DeployStep`: These do not need to use the private network because they use the public K8s API server endpoint. Whether they should is perhaps a different question. I'm open to keeping these on the private networks and creating an issue to use the internal API server endpoint instead. We definitely have a static internal IP in GKE but I don't believe we have one for AKS and that would involve some research.; - `CreateNamespaceStep`: I don't believe that this needs the private network because it is functionally the same as a `DeployStep` in that it just talks to K8s, but I am unable to test this step in `test_ci` so I am reluctant to make a change that could brick CI. I instead made it configurable and default to its current value ('private'). We could then make a follow-up PR that tries turning it public.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14294:794,access,access,794,https://hail.is,https://github.com/hail-is/hail/pull/14294,1,['access'],['access']
Security,"`tls.py` has many different functions with long names. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I push",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9862:849,password,password,849,https://hail.is,https://github.com/hail-is/hail/pull/9862,1,['password'],['password']
Security,"a homogenous set of named values of type `T`.; 1. an `array<T>` and a `dict<str, int>`, the values are stored in the array and the names are stored in a separate dictionary mapping names to their indices; 2. a `dict<str, T>`, the name-value pairs are stored as dictionary key-value pairs; 3. a `struct{name1: T, name2: T, ... nameN: T}`, the name-value pairs are stored as field name, field string pairs. The third option is the most space efficient: the type stores the field names and there is no bookkeeping overhead per-set-of-named-values. The first two options repeat the field names for each occurrence (in particular, consider a Table field or MatrixTable entry-indexed field). The first two options needlessly encode the length (which is statically known). The third option is the most access-time-efficient: the offset of any named-value is known at hail compile time. The first two options require a logarithmic search of hail's dictionary tree representation. The third option is more user-friendly for accessing: `x.name`. The first is the least user-friendly: `x[indices[""name""]]`. The first and third options are the most cache-friendly for homogenous operations. The first uses `ArrayExpression.map`, so code size is `O(CODE)`. The third option's code size is `O(CODE * #VALUES)` because structs have no `map`-like primitive. The third option is also not user-friendly for homogenous operations (the user must repeat the code for each name-value pair). The third is the most self-documenting option. The number of fields and their names are visible in `ds.describe()`. The first is the next best because the dictionary is likely a global field that can be viewed with `x.indices.show()`. ---. ## Phase 1; Implement a new virtual type `tstaticdict<T, name1, name2, ..., nameN>` who's physical type is `PStruct` with N fields. These changes span Scala and Python. Implement `map` and `__getitem__` on `StaticDictExpression`s. `map` is implemented by code duplication. ## Phase 2; Implem",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6881:1049,access,accessing,1049,https://hail.is,https://github.com/hail-is/hail/issues/6881,1,['access'],['accessing']
Security,"a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1834"">#1834</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/b8f43169a504080c55eadc3428d0d7966efdc3d4""><code>b8f4316</code></a> build(deps): update dependency org.apache.maven.plugins:maven-dependency-plug...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/e532a590fd351bb2020b571d21662fbee629038e""><code>e532a59</code></a> build(deps): update dependency org.apache.maven.plugins:maven-surefire-plugin...</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/java-storage/compare/v1.106.0...v2.17.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.cloud:google-cloud-storage&package-manager=gradle&previous-version=1.106.0&new-version=2.17.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12598:16452,secur,security-vulnerabilities,16452,https://hail.is,https://github.com/hail-is/hail/pull/12598,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/354"">spyder-ide/qtpy#354</a></li>; </ul>; <p><strong>Full commits list between this release and the previous one</strong>: <a href=""https://github.com/spyder-ide/qtpy/compare/v2.1.0...v2.2.0"">https://github.com/spyder-ide/qtpy/compare/v2.1.0...v2.2.0</a>; <strong>Full Changelog</strong>: <a href=""https://github.com/spyder-ide/qtpy/blob/master/CHANGELOG.md#version-220-2022-08-10"">CHANGELOG.md - Version 2.2.0 (2022-08-10)</a></p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/spyder-ide/qtpy/blob/master/CHANGELOG.md"">qtpy's changelog</a>.</em></p>; <blockquote>; <h2>Version 2.2.0 (2022-08-10)</h2>; <h3>Issues Closed</h3>; <ul>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/359"">Issue 359</a> - Release QtPy 2.2.0</li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/352"">Issue 352</a> - Deprecation Warning for Enum Access (<a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/353"">PR 353</a> by <a href=""https://github.com/CAM-Gerlach""><code>@​CAM-Gerlach</code></a>)</li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/351"">Issue 351</a> - <code>PySide6.QtSvgWidgets</code> not exposed</li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/302"">Issue 302</a> - Compat shiboken and sip like Qt.py (<a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/354"">PR 354</a> by <a href=""https://github.com/zjp""><code>@​zjp</code></a>)</li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/61"">Issue 61</a> - Add documentation for methods or helpers that are specific to qtpy (<a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/357"">PR 357</a> by <a href=""https://github.com/dalthviz""><code>@​dalthviz</code></a>)</li>; </ul>; <p>In this release 5 issues were closed.</p>; ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12194:3373,Access,Access,3373,https://hail.is,https://github.com/hail-is/hail/pull/12194,1,['Access'],['Access']
Security,"a href=""https://github.com/elastic/elasticsearch-hadoop/commit/712679f88772fb15184ad7c87dea220a87803f44""><code>712679f</code></a> Upgrade to Gradle 7.5 (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1980"">#1980</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/a4d14077a58ba3272469d48500ce007c725f1c73""><code>a4d1407</code></a> [DOCS] Added 8.3.2 RNs (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1978"">#1978</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/elastic/elasticsearch-hadoop/compare/v7.17.1...v8.4.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.elasticsearch:elasticsearch-spark-20_2.12&package-manager=gradle&previous-version=7.17.1&new-version=8.4.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12358:7708,secur,security-vulnerabilities,7708,https://hail.is,https://github.com/hail-is/hail/pull/12358,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"a href=""https://github.com/googleapis/python-storage/commit/8789afaaa1b2bd6f03fae72e3d87ce004ec10129"">8789afa</a>)</li>; <li>remove python 3.6 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/689"">#689</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8aa4130ee068a1922161c8ca54a53a4a51d65ce0"">8aa4130</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/python-storage/blob/main/CHANGELOG.md"">google-cloud-storage's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v2.0.0...v2.1.0"">2.1.0</a> (2022-01-19)</h2>; <h3>Features</h3>; <ul>; <li>add turbo replication support and samples (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/622"">#622</a>) (<a href=""https://github.com/googleapis/python-storage/commit/4dafc815470480ce9de7f0357e331d3fbd0ae9b7"">4dafc81</a>)</li>; <li>avoid authentication with storage emulator (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/679"">#679</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8789afaaa1b2bd6f03fae72e3d87ce004ec10129"">8789afa</a>)</li>; <li>remove python 3.6 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/689"">#689</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8aa4130ee068a1922161c8ca54a53a4a51d65ce0"">8aa4130</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v1.44.0...v2.0.0"">2.0.0</a> (2022-01-12)</h2>; <h3>⚠ BREAKING CHANGES</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/657"">#657</a>)</li>; </ul>; <h3>Features</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/657"">#657</a>) (<a href=""https://github.com/goo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11520:1903,authenticat,authentication,1903,https://hail.is,https://github.com/hail-is/hail/pull/11520,1,['authenticat'],['authentication']
Security,"a href=""https://github.com/tqdm/tqdm/releases"">tqdm's releases</a>.</em></p>; <blockquote>; <h2>tqdm v4.64.1 stable</h2>; <ul>; <li>support <code>ipywidgets&gt;=8</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1366"">#1366</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1361"">#1361</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1310"">#1310</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1359"">#1359</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1360"">#1360</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1364"">#1364</a>); <ul>; <li>fix jupyter lab display</li>; <li>update notebook tests</li>; </ul>; </li>; </ul>; <h2>tqdm v4.64.0 stable</h2>; <ul>; <li>add <code>contrib.slack</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1313"">#1313</a>)</li>; </ul>; <h2>tqdm v4.63.2 stable</h2>; <ul>; <li><code>rich</code>: expose <code>options</code> kwargs (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1282"">#1282</a>)</li>; <li><code>autonotebook</code>: re-enable VSCode (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1309"">#1309</a>)</li>; <li>misc docs typos (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1301"">#1301</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1299"">#1299</a>)</li>; <li>update dev dependencies (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1311"">#1311</a>)</li>; </ul>; <h2>tqdm v4.63.1 stable</h2>; <ul>; <li>fix stderr/stdout missing <code>flush()</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1248"">#1248</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1177"">#1177</a>)</li>; <li>misc speed improvements/optimisations</li>; </ul>; <h2>tqdm v4.63.0 stable</h2>; <ul>; <li>add <code>__reversed__()</code></li>; <li>add efficient <code>__contains__()</c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12260:1121,expose,expose,1121,https://hail.is,https://github.com/hail-is/hail/pull/12260,1,['expose'],['expose']
Security,"a regression in v1beta1 PodDisruptionBudget handling of &quot;strategic merge patch&quot;-type API requests for the <code>selector</code> field. Prior to 1.21, these requests would merge <code>matchLabels</code> content and replace <code>matchExpressions</code> content. In 1.21, patch requests touching the <code>selector</code> field started replacing the entire selector. This is consistent with server-side apply and the v1 PodDisruptionBudget behavior, but should not have been changed for v1beta1. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108139"">kubernetes/kubernetes#108139</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>) [SIG Auth and Testing]</li>; <li>Fix OpenAPI serialization of the x-kubernetes-validations field (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108030"">kubernetes/kubernetes#108030</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>) [SIG API Machinery]</li>; <li>A new field <code>omitManagedFields</code> has been added to both <code>audit.Policy</code> and <code>audit.PolicyRule</code>; so cluster operators can opt in to omit managed fields of the request and response bodies from; being written to the API audit log. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/94986"">kubernetes/kubernetes#94986</a>, <a href=""https://github.com/tkashem""><code>@​tkashem</code></a>) [SIG API Machinery, Auth, Cloud Provider and Testing]</li>; <li>A small regression in Service updates was fixed. The circumstances are so unlikely that probably nobody would ever hit it. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104601"">kubernetes/kubernetes#104601</a>, <a href=""https://github.com/thockin""><code>@​thockin</code></a>)</li>; <li>Added a feature gate <code>StatefulSetAutoDeletePVC</code>, which allows PVCs automatically created for StatefulSet pods to be automatically deleted. (<a href=""https://github-redirect.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:1720,audit,audit,1720,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['audit'],['audit']
Security,"a work in progress*. ### TL;DR; Use Kata + CRI-Containerd runtime to sandbox pods, at a low performance cost. [Jessie Frazelle’s Blog: Hard Multi-Tenancy in Kubernetes](https://blog.jessfraz.com/post/hard-multi-tenancy-in-kubernetes/). ### Roadmap; I would like to implement a test cluster that uses this system, and begin migrating our existing workloads to it asap. . *TODO*. ### Rationale; 1. We want resource preemption across users., running multiple user containers on a single cluster.; 2. This means sandboxing at the cluster level is out.; 3. Therefore we must sandbox at the pod (or container) level. Kata + CRI-Containerd chosen for performance and maturity reasons.; CRI-Containerd is much faster than CRI-O, and Kata is much faster than gVisor. Kata is a relatively mature product from Intel. Production users include JD.com. ### User-level access control ; An orthogonal issue that still needs to be addressed. [RBAC Authorization - Kubernetes](https://kubernetes.io/docs/reference/access-authn-authz/rbac/). *TODO*. ### Related: Firecracker; Interesting project, similar to Kata and gVisor in its isolation properties. Doesn’t work with Kubernetes, replicates some Kube functionality.; * [Announcing the Firecracker Open Source Technology: Secure and Fast microVM for Serverless Computing | AWS Open Source Blog](https://aws.amazon.com/blogs/opensource/firecracker-open-source-secure-fast-microvm-serverless/); * Potentially lower runtime cost that Kata; * Written in Rust :). ### Alternatives; [Nabla containers: a new approach to container isolation · Nabla Containers](https://nabla-containers.github.io); * Unclear how good containment is. Worth exploring. ### Performance; [Runtime performance benchmark result. containerd vs CRI-containerd vs CRI-O · GitHub](https://gist.github.com/kunalkushwaha/66629a90e0f8f5cc5dc512ef1c346f2f). [Measuring the Horizontal Attack Profile of Nabla Containers](https://outlookseries.com/A0784/Infrastructure/3868.htm); * 10-30% cost for networkin",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5111:1216,access,access-authn-authz,1216,https://hail.is,https://github.com/hail-is/hail/issues/5111,1,['access'],['access-authn-authz']
Security,"a""><code>b303c66</code></a> chore: update docfx minimum Python version (<a href=""https://redirect.github.com/GoogleCloudPlatform/google-auth-library-python-oauthlib/issues/316"">#316</a>)</li>; <li><a href=""https://github.com/googleapis/google-auth-library-python-oauthlib/commit/fc1fad5d7b9b7774273b379d52022a9b294f7619""><code>fc1fad5</code></a> chore: rename rst files to avoid conflict with service names (<a href=""https://redirect.github.com/GoogleCloudPlatform/google-auth-library-python-oauthlib/issues/315"">#315</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/GoogleCloudPlatform/google-auth-library-python-oauthlib/compare/v0.8.0...v1.2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-auth-oauthlib&package-manager=pip&previous-version=0.8.0&new-version=1.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14510:10849,secur,security-vulnerabilities,10849,https://hail.is,https://github.com/hail-is/hail/pull/14510,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,a.lang.Thread.run(Thread.java:745). java.io.FileNotFoundException: /scratch/.writeBlocksRDD-l5om7fTy3akZKCYbLDY4AD.crc (Too many open files); at java.io.FileOutputStream.open0(Native Method); at java.io.FileOutputStream.open(FileOutputStream.java:270); at java.io.FileOutputStream.<init>(FileOutputStream.java:213); at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:222); at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209); at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307); at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296); at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328); at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:402); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:778); at is.hail.io.fs.HadoopFS.createNoCompression(HadoopFS.scala:60); at is.hail.io.fs.FS$class.create(FS.scala:151); at is.hail.io.fs.HadoopFS.create(HadoopFS.scala:56); at is.hail.linalg.WriteBlocksRDD$$anonfun$62.apply(BlockMatrix.scala:1838); at is.hail.linalg.WriteBlocksRDD$$anonfun$62.apply(BlockMatrix.scala:1829); at scala.Array$.tabulate(Array.scala:331); at is.hail.linalg.WriteBlocksRDD.compute(BlockMatrix.scala:1829); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.ex,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403:18467,Checksum,ChecksumFileSystem,18467,https://hail.is,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403,1,['Checksum'],['ChecksumFileSystem']
Security,"a/pull/983"">python-jsonschema/jsonschema#983</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.10.3...v4.11.0"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.3...v4.11.0</a></p>; <h2>v4.10.3</h2>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.10.2...v4.10.3"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.2...v4.10.3</a></p>; <h2>v4.10.2</h2>; <ul>; <li>Fix a second place where subclasses may have added attrs attributes (<a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/issues/982"">#982</a>).</li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.10.1...v4.10.2"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.1...v4.10.2</a></p>; <h2>v4.10.1</h2>; <ul>; <li>Fix Validator.evolve (and APIs like <code>iter_errors</code> which call it) for cases; where the validator class has been subclassed. Doing so wasn't intended to be; public API, but given it didn't warn or raise an error it's of course; understandable. The next release however will make it warn (and a future one; will make it error). If you need help migrating usage of inheriting from a; validator class feel free to open a discussion and I'll try to give some; guidance (<a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/issues/982"">#982</a>).</li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.10.0...v4.10.1"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.0...v4.10.1</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/python-jsonschema/jsonschema/blob/main/CHANGELOG.rst"">jsonschema's changelog</a>.</em></p>; <blockquote>; <h1>v4.15.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12163:3181,validat,validator,3181,https://hail.is,https://github.com/hail-is/hail/pull/12163,1,['validat'],['validator']
Security,"a/pyjwt/commit/1f1fe15bb41846c602b3e106176b2c692b93a613&quot;&gt;&lt;code&gt;1f1fe15&lt;/code&gt;&lt;/a&gt; Add a deprecation warning when jwt.decode() is called with the legacy verify=...&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/jpadilla/pyjwt/commit/35fa28e59d99b99c6a780d2a029a74d6bbba8b1e&quot;&gt;&lt;code&gt;35fa28e&lt;/code&gt;&lt;/a&gt; [pre-commit.ci] pre-commit autoupdate (&lt;a href=&quot;https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/740&quot;&gt;#740&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;Additional commits viewable in &lt;a href=&quot;https://github.com/jpadilla/pyjwt/compare/1.7.1...2.4.0&quot;&gt;compare view&lt;/a&gt;&lt;/li&gt;; &lt;/ul&gt;; &lt;/details&gt;. &lt;br /&gt;; </code></pre>. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyjwt&package-manager=pip&previous-version=1.7.1&new-version=2.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11866:14861,secur,security-vulnerabilities,14861,https://hail.is,https://github.com/hail-is/hail/pull/11866,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"a59fed1ab4292c6576d800295f1""><code>16aa242</code></a> Bump pytest-mock from 3.6.1 to 3.7.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/674"">#674</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/72d199d40689cb0a83f2b911044ab0ed9f6cc08e""><code>72d199d</code></a> Fix error in example</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/44e60f51bdb1ecfc22fa8bc87e8d025f2f17cd90""><code>44e60f5</code></a> Minor changes to typing. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/672"">#672</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/bf9a5f0b87470dd145cff326b0b05f898f775d94""><code>bf9a5f0</code></a> Fix session resetting before expiry. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/671"">#671</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/36b8a0a5ed2caaaba9d5d3ece8aaf03ca45b6c34""><code>36b8a0a</code></a> Allow passing Fernet to Encrypted Cookie Storage (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/448"">#448</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/984decc496fe92e053c14949c8d3a60bacd62426""><code>984decc</code></a> Test on Python up to 3.10 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/634"">#634</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/936f76351450066903002d60286110007310a44f""><code>936f763</code></a> Bump aiomcache from 0.6.0 to 0.7.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/665"">#665</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/29ddff39290f4e2fbc7b9feb94eb622763e156e2""><code>29ddff3</code></a> Bump pytest-aiohttp from 0.3.0 to 1.0.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/668"">#668</a>)</li>; <li><a href=""https://github.com/aio-lib",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11544:3064,Encrypt,Encrypted,3064,https://hail.is,https://github.com/hail-is/hail/pull/11544,2,['Encrypt'],['Encrypted']
Security,"a822""><code>0d7499f</code></a> Release 5.12.0</li>; <li><a href=""https://github.com/java-native-access/jna/commit/fa86166d4f75ef4478de7ad9d7d6c0b6b6933ee0""><code>fa86166</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1445"">#1445</a> from matthiasblaesing/aix</li>; <li><a href=""https://github.com/java-native-access/jna/commit/4cca4405f7f6bc32d2a08495efb81c081b065279""><code>4cca440</code></a> Fix name mapping difference between AIX JDK 8 and Semeru JDK 18</li>; <li><a href=""https://github.com/java-native-access/jna/commit/f58b0f8f6b5c013adfe44a2cfb018ccb6ef6a688""><code>f58b0f8</code></a> Improve test stability on AIX (exclude tests that are expected to fail)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/c1565fb89469cbcba67b1cc305e16d520779b270""><code>c1565fb</code></a> Handle race condition in PdhUtil#PdhEnumObjectItems (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/99fcfa822db86b1f2ba5823dbf17efeb3d246ad5""><code>99fcfa8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1444"">#1444</a> from matthiasblaesing/update_libffi</li>; <li><a href=""https://github.com/java-native-access/jna/commit/9e473350a5ad5e04aab8b01e4018f973976e19f8""><code>9e47335</code></a> Update CHANGES.md</li>; <li>Additional commits viewable in <a href=""https://github.com/java-native-access/jna/compare/5.6.0...5.12.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=net.java.dev.jna:jna&package-manager=gradle&previous-version=5.6.0&new-version=5.12.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:7233,access,access,7233,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,"a931de0"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""42.0.2""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6050294"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-CRYPTOGRAPHY-6126975"",""SNYK-PYTHON-CRYPTOGRAPHY-6210214"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,509,454,616,584,479,509,509,509,509,589,509,691,399,479,399,539,479,479,616,616,489,519],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14329:13208,Access,Access,13208,https://hail.is,https://github.com/hail-is/hail/pull/14329,1,['Access'],['Access']
Security,"a> Fix typos in docs</li>; <li><a href=""https://github.com/ipython/ipython/commit/75ecfe932fc9ca3505efbebc016b046ffc7d0d68""><code>75ecfe9</code></a> capture_output does not respect trailing semicolon (<a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13940"">#13940</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/3edbe3bd10c434af6458bdbe02269880b10b9adf""><code>3edbe3b</code></a> Resurrect fast (non-highlighted) traceback code for long files. (<a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13947"">#13947</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12741:2438,secur,security-vulnerabilities,2438,https://hail.is,https://github.com/hail-is/hail/pull/12741,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7343"">#7343</a>/18057581 backport][3.8] Mention encoding in <code>yarl.URL</code> (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7355"">#7355</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/40874103ebfaa1007d47c25ecc4288af873a07cf""><code>4087410</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7346"">#7346</a>/346fd202 backport][3.8]  Bump vendored llhttp to v8.1.1 (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7352"">#7352</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.8.4...v3.8.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.8.4&new-version=3.8.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13270:6527,secur,security-vulnerabilities,6527,https://hail.is,https://github.com/hail-is/hail/pull/13270,10,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/075e68abfb5d4ebe596c8e97fce0327cd0c1f6c2""><code>075e68a</code></a> check content (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23496"">#23496</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/a82e1ea612a3d3e9542812b04930fc8d797fce51""><code>a82e1ea</code></a> expose async client assertion (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23474"">#23474</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-identity_1.8.0...azure-identity_1.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-identity&package-manager=pip&previous-version=1.8.0&new-version=1.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11752:5325,secur,security-vulnerabilities,5325,https://hail.is,https://github.com/hail-is/hail/pull/11752,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=minimist&package-manager=npm_and_yarn&previous-version=1.2.5&new-version=1.2.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11653:2757,secur,security,2757,https://hail.is,https://github.com/hail-is/hail/pull/11653,2,"['Secur', 'secur']","['Security', 'security']"
Security,"a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=svelte&package-manager=npm_and_yarn&previous-version=3.38.2&new-version=3.49.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12032:10471,secur,security,10471,https://hail.is,https://github.com/hail-is/hail/pull/12032,6,"['Secur', 'secur']","['Security', 'security']"
Security,aValueWriter.scala:50); 	at org.elasticsearch.spark.serialization.ScalaValueWriter$$anonfun$doWriteScala$3.apply(ScalaValueWriter.scala:78); 	at org.elasticsearch.spark.serialization.ScalaValueWriter$$anonfun$doWriteScala$3.apply(ScalaValueWriter.scala:77); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.elasticsearch.spark.serialization.ScalaValueWriter.doWriteScala(ScalaValueWriter.scala:77); 	at org.elasticsearch.spark.serialization.ScalaValueWriter.doWrite(ScalaValueWriter.scala:50); 	at org.elasticsearch.spark.serialization.ScalaValueWriter$$anonfun$doWriteScala$2.apply(ScalaValueWriter.scala:66); 	at org.elasticsearch.spark.serialization.ScalaValueWriter$$anonfun$doWriteScala$2.apply(ScalaValueWriter.scala:63); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.elasticsearch.spark.serialization.ScalaValueWriter.doWriteScala(ScalaValueWriter.scala:63); 	at org.elasticsearch.spark.serialization.ScalaValueWriter.write(ScalaValueWriter.scala:46); 	at org.elasticsearch.hadoop.serialization.builder.ContentBuilder.value(ContentBuilder.java:53); 	at org.elasticsearch.hadoop.serialization.bulk.TemplatedBulk.doWriteObject(TemplatedBulk.java:71); 	at org.elasticsearch.hadoop.serialization.bulk.TemplatedBulk.write(TemplatedBulk.java:58); 	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:168); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:4031,Hash,HashMap,4031,https://hail.is,https://github.com/hail-is/hail/issues/4250,2,['Hash'],['HashMap']
Security,"ab-probot+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​jupyterlab-probot</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Akrassowski+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​krassowski</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Alumberbot-app+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​lumberbot-app</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Ameeseeksmachine+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​meeseeksmachine</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Awelcome+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​welcome</code></a></p>; <h2>v4.0.11</h2>; <h2>4.0.11</h2>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/compare/v4.0.10...0708330843fd087134a239d2ad6005b1d543e246"">Full Changelog</a>)</p>; <h3>Security fixes</h3>; <ul>; <li>Potential authentication and CSRF tokens leak in JupyterLab (<a href=""https://github.com/jupyterlab/jupyterlab/security/advisories/GHSA-44cc-43rp-5947"">GHSA-44cc-43rp-5947</a>)</li>; <li>SXSS in Markdown Preview (<a href=""https://github.com/jupyterlab/jupyterlab/security/advisories/GHSA-4m77-cmpx-vjc4"">GHSA-4m77-cmpx-vjc4</a>)</li>; </ul>; <h3>Bugs fixed</h3>; <ul>; <li>Fixes focus indicator on input checkbox for Firefox <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15612"">#15612</a> (<a href=""https://github.com/alden-ilao""><code>@​alden-ilao</code></a>)</li>; </ul>; <h3>Documentation improvements</h3>; <ul>; <li>Fix link to yarn docs in extension migration guide <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15640"">#15640</a> (<a href=""https://github.com/krassowski""><code>@​krassowski</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/graphs/contributors?from=2023-12-29&amp;to",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14218:4546,Secur,Security,4546,https://hail.is,https://github.com/hail-is/hail/pull/14218,2,"['Secur', 'authenticat']","['Security', 'authentication']"
Security,able.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:235); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:234); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.TaskSchedulerImpl.cancelTasks(TaskSchedulerImpl.scala:234); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply$mcVI$sp(DAGScheduler.scala:1543); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doO,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:201422,Hash,HashSet,201422,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['Hash'],['HashSet']
Security,"able.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:235); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:234); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.TaskSchedulerImpl.cancelTasks(TaskSchedulerImpl.scala:234); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply$mcVI$sp(DAGScheduler.scala:1543); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1457); at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply$mcVI$sp(DAGScheduler.scala:723); at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:723); at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:723); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.doCancelAllJobs(DAGScheduler.scala:723); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onError(DAGScheduler.scala:1741); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:52); 2019-01-22 13:12:06 AbstractConnector: INFO: Stopped Spark@1433e9ec{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-01-22 13:12:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:205069,Hash,HashSet,205069,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['Hash'],['HashSet']
Security,"ad_namespaced_pod_log_with_http_info; collection_formats=collection_formats); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 334, in call_api; _return_http_data_only, collection_formats, _preload_content, _request_timeout); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 168, in __call_api; _request_timeout=_request_timeout); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 355, in request; headers=headers); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/rest.py"", line 231, in GET; query_params=query_params); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/rest.py"", line 222, in request; raise ApiException(http_resp=r); {""levelname"": ""INFO"", ""asctime"": ""2019-07-02 13:36:45,525"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""mark_complete:542"", ""message"": ""no logs for batch-278-job-6858-5879db due to previous error, rescheduling pod Error: (404)\nReason: Not Found\nHTTP response headers: HTTPHeaderDict({'Audit-Id': '891f2153-6a94-42ff-8fe1-edf644051234', 'Content-Type': 'application/json', 'Date': 'Tue, 02 Jul 2019 13:36:45 GMT', 'Content-Length': '218'})\nHTTP response body: {\""kind\"":\""Status\"",\""apiVersion\"":\""v1\"",\""metadata\"":{},\""status\"":\""Failure\"",\""message\"":\""pods \\\""batch-278-job-6858-5879db\\\"" not found\"",\""reason\"":\""NotFound\"",\""details\"":{\""name\"":\""batch-278-job-6858-5879db\"",\""kind\"":\""pods\""},\""code\"":404}\n\n""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-02 13:36:45,541"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""set_state:457"", ""message"": ""job (278, 6858, 'main') changed state: Running -> Ready""}; ```. Here are events that don't contain the string ""Successfully assigned batch-pods"": [events.log](https://github.com/hail-is/hail/files/3350320/events.log). There's a lot of issue with secrets getting mounted and a couple container creation failures, but nothing that obviously suggests a problem with reading logs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6545:2289,Audit,Audit-Id,2289,https://hail.is,https://github.com/hail-is/hail/issues/6545,1,['Audit'],['Audit-Id']
Security,"add authentication to apiserver. When both PRs are in I will abstract this duplicate code into hailjwt or somewhere else. cc: @cseed, I'm pretty sure we were never testing apiserver?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5893:4,authenticat,authentication,4,https://hail.is,https://github.com/hail-is/hail/pull/5893,1,['authenticat'],['authentication']
Security,add example to docs on how to access schemas,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1901:30,access,access,30,https://hail.is,https://github.com/hail-is/hail/issues/1901,1,['access'],['access']
Security,add hash to expr functions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2845:4,hash,hash,4,https://hail.is,https://github.com/hail-is/hail/issues/2845,1,['hash'],['hash']
Security,"adtac""><code>@​adtac</code></a>) [SIG Scheduling and Testing]</li>; <li>Resolve regression in <code>metadata.managedFields</code> handling in update/patch requests submitted by older API clients (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91748"">kubernetes/kubernetes#91748</a>, <a href=""https://github.com/apelisse""><code>@​apelisse</code></a>)</li>; <li>Scheduler: optionally check for available storage capacity before scheduling pods which have unbound volumes (alpha feature with the new <code>CSIStorageCapacity</code> feature gate, only works for CSI drivers and depends on support for the feature in a CSI driver deployment) (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92387"">kubernetes/kubernetes#92387</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>) [SIG API Machinery, Apps, Auth, Scheduling, Storage and Testing]</li>; <li>Seccomp support has graduated to GA. A new <code>seccompProfile</code> field is added to pod and container securityContext objects. Support for <code>seccomp.security.alpha.kubernetes.io/pod</code> and <code>container.seccomp.security.alpha.kubernetes.io/...</code> annotations is deprecated, and will be removed in v1.22. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91381"">kubernetes/kubernetes#91381</a>, <a href=""https://github.com/pjbgf""><code>@​pjbgf</code></a>) [SIG Apps, Auth, Node, Release, Scheduling and Testing]</li>; <li>ServiceAppProtocol feature gate is now beta and enabled by default, adding new AppProtocol field to Services and Endpoints. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/90023"">kubernetes/kubernetes#90023</a>, <a href=""https://github.com/robscott""><code>@​robscott</code></a>) [SIG Apps and Network]</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tomplus/kubernetes_a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:13380,secur,securityContext,13380,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['secur'],['securityContext']
Security,"aed services. In particular, batch pods cannot; communicate with batch-driver. After this PR is deployed and the unmanaged services have certificates, I can; enable mutual TLS. I've marked the tow lines that need to change with `# FIXME:; mTLS`. ### Batch Confused Deputy. The [confused deputy; problem](https://en.wikipedia.org/wiki/Confused_deputy_problem) is a classic; in computer security. It refers to a situation with two parties: the deputy and; the attacker. The deputy has authority that the attacker does not. For example,; the deputy can arrest people. A *confused deputy* is one which has been tricked; by the attacker into misusing its authority. In master, Batch has a confused deputy problem: it issues a callback in response; to a batch finishing. That callback is issued from within the cluster and; therefore can name many of our services which are not exposed to the; internet. With the introduction of TLS everywhere, a confused deputy callback; will fail because the victim will not receive a valid Batch certificate (batch; purposely does not send certificates with the callbacks). Batch only uses its; certificate to send a callback for CI. This is safe because we control CI and; ensure it is not compromised. In the long run, I want to fix batch to use an entirely different network for; callbacks. ### Notes of Annoyance. `aiohttp` silently ignores most invalid TLS requests, this makes debugging a TLS; issue difficult. `aiohttp`'s `raise_for_status` does not include the HTTP body in the; message. NGINX sometimes returns 400 in response to TLS issues with a proxy. It; includes crucial details in the HTTP body. I usually debug these issues by; sshing to the client pod and using curl to manually reproduce the error. Readiness and liveness probes cannot use HTTP. Although k8s supports HTTPS, it; does not support so-called ""mTLS"" or ""mutual TLS."" This is fancy verbiage for; servers that require clients to send trusted certificates. I will eventually require; this. Th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:9907,certificate,certificate,9907,https://hail.is,https://github.com/hail-is/hail/pull/8561,2,['certificate'],"['certificate', 'certificates']"
Security,"ah, annoying. It's hard to figure out when stuff is actually going to be executed in make. We can fix this by moving those definitions inside the target, I think:; ```; pypi-deploy: check-pypi wheel; 	 TWINE_USERNAME=$(shell cat $(HAIL_TWINE_CREDS_FOLDER)/pypi-username) \ ; 	 TWINE_PASSWORD=$(shell cat $(HAIL_TWINE_CREDS_FOLDER)/pypi-password) \; 	 twine upload build/deploy/dist/*; ```. mind making that change in a separate branch?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6318#issuecomment-501313676:336,password,password,336,https://hail.is,https://github.com/hail-is/hail/pull/6318#issuecomment-501313676,1,['password'],['password']
Security,aha it gets a push for every task end! Running even a 5000-partition short job is a denial of service attack against the extension,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7087#issuecomment-532900121:102,attack,attack,102,https://hail.is,https://github.com/hail-is/hail/pull/7087#issuecomment-532900121,1,['attack'],['attack']
Security,ail-jigold.; Which region do you want your jobs to run in? [us-central1/us-east1/us-east4/us-west1/us-west2/us-west3/us-west4]: us-central1; Which backend do you want to use for Hail Query? [spark/batch/local]: batch; --------------------; FINAL CONFIGURATION:; --------------------; global/domain=hail.is; batch/remote_tmpdir=gs://hail-batch-jigold-yrxul/batch/tmp; batch/regions=us-central1; batch/backend=service; query/backend=batch; ```. Use an existing bucket and give permissions:; ```; (py311) jigold@wm349-8c4 hail % hailctl batch init ; Do you want to create a new bucket in project for temporary files generated by Hail? [y/n]: n; Enter a path to an existing remote temporary directory (ex: gs://my-bucket/batch/tmp): gs://hail-batch-jigold-oxmmp/foo; Do you want to give service account jigold-59hi5@hail-vdc.iam.gserviceaccount.com read/write access to bucket hail-batch-jigold-oxmmp? [y/n]: y; Granted service account jigold-59hi5@hail-vdc.iam.gserviceaccount.com read and write access to hail-batch-jigold-oxmmp.; Which region do you want your jobs to run in? [us-central1/us-east1/us-east4/us-west1/us-west2/us-west3/us-west4]: us-central1; Which backend do you want to use for Hail Query? [spark/batch/local]: batch; --------------------; FINAL CONFIGURATION:; --------------------; global/domain=hail.is; batch/remote_tmpdir=gs://hail-batch-jigold-oxmmp/foo; batch/regions=us-central1; batch/backend=service; query/backend=batch; ```. User does not give permissions to existing remote tmpdir:; ```; (py311) jigold@wm349-8c4 hail % hailctl batch init; Do you want to create a new bucket in project for temporary files generated by Hail? [y/n]: n; Enter a path to an existing remote temporary directory (ex: gs://my-bucket/batch/tmp): gs://hail-batch-jigold-oxmmp; Do you want to give service account jigold-59hi5@hail-vdc.iam.gserviceaccount.com read/write access to bucket hail-batch-jigold-oxmmp? [y/n]: n ; WARNING: Please verify service account jigold-59hi5@hail-vdc.iam.gservicea,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13279#issuecomment-1679133568:2162,access,access,2162,https://hail.is,https://github.com/hail-is/hail/pull/13279#issuecomment-1679133568,1,['access'],['access']
Security,"ailKryoRegistrator \; --conf spark.serializer=org.apache.spark.serializer.KryoSerializer \; pyspark-shell '. from pyspark import SparkContext; sc=SparkContext.getOrCreate(). import hail as hl; hl.init(sc=sc); ```. - Error logs ; ```; 22/05/11 14:31:21 WARN Utils: Your hostname, spacerider.local resolves to a loopback address: 127.0.0.1; using 172.20.10.4 instead (on interface en6); 22/05/11 14:31:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/username/miniforge3/envs/hail/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 22/05/11 14:31:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel). ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Input In [2], in <cell line: 6>(); 3 sc = spark._sc; 5 import hail as hl; ----> 6 hl.init(sc=sc). File <decorator-gen-1703>:2, in init(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations, backend, driver_cores, driver_memory). File ~/miniforge3/envs/hail/lib/python3.9/site-packages/hail/typecheck/check.py:577, in _",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11827:1510,access,access,1510,https://hail.is,https://github.com/hail-is/hail/issues/11827,3,['access'],['access']
Security,"ails>; <summary>⚠️ <b>Warning</b></summary>. ```; msal-extensions 1.0.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Expected Behavior Violation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3314966](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3314966) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Use After Free <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315324](https://snyk.io/vuln/SNYK-PY",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14196:1364,Certificate,Certificate,1364,https://hail.is,https://github.com/hail-is/hail/pull/14196,1,['Certificate'],['Certificate']
Security,"ails>; <summary>⚠️ <b>Warning</b></summary>. ```; msal-extensions 1.1.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Expected Behavior Violation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3314966](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3314966) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Use After Free <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315324](https://snyk.io/vuln/SNYK-PY",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14296:1364,Certificate,Certificate,1364,https://hail.is,https://github.com/hail-is/hail/pull/14296,1,['Certificate'],['Certificate']
Security,"aiohttp/issues/7366"">#7366</a>)</p>; </li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>; <p>Fixed a transport is :data:<code>None</code> error -- by :user:<code>Dreamsorcerer</code>.</p>; <p>(<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/3355"">#3355</a>)</p>; </li>; </ul>; <hr />; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/blob/v3.8.5/CHANGES.rst"">aiohttp's changelog</a>.</em></p>; <blockquote>; <h1>3.8.5 (2023-07-19)</h1>; <h2>Security bugfixes</h2>; <ul>; <li>; <p>Upgraded the vendored copy of llhttp_ to v8.1.1 -- by :user:<code>webknjaz</code>; and :user:<code>Dreamsorcerer</code>.</p>; <p>Thanks to :user:<code>sethmlarson</code> for reporting this and providing us with; comprehensive reproducer, workarounds and fixing details! For more; information, see; <a href=""https://github.com/aio-libs/aiohttp/security/advisories/GHSA-45c4-8wx5-qw6w"">https://github.com/aio-libs/aiohttp/security/advisories/GHSA-45c4-8wx5-qw6w</a>.</p>; <p>.. _llhttp: <a href=""https://llhttp.org"">https://llhttp.org</a></p>; <p><code>[#7346](https://github.com/aio-libs/aiohttp/issues/7346) &lt;https://github.com/aio-libs/aiohttp/issues/7346&gt;</code>_</p>; </li>; </ul>; <h2>Features</h2>; <ul>; <li>; <p>Added information to C parser exceptions to show which character caused the error. -- by :user:<code>Dreamsorcerer</code></p>; <p><code>[#7366](https://github.com/aio-libs/aiohttp/issues/7366) &lt;https://github.com/aio-libs/aiohttp/issues/7366&gt;</code>_</p>; </li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>; <p>Fixed a transport is :data:<code>None</code> error -- by :user:<code>Dreamsorcerer</code>.</p>; <p><code>[#3355](https://github.com/aio-libs/aiohttp/issues/3355) &lt;https://github.com/aio-libs/aiohttp/issues/3355&gt;</code>_</p>; </li>; </ul>; <hr />; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/9c13a52c21c23dfd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13270:2145,secur,security,2145,https://hail.is,https://github.com/hail-is/hail/pull/13270,5,['secur'],['security']
Security,"air' as type Boolean (imputed); Loading column `CaffeineConsumption' as type Int (imputed); >>> common_vds = hc.read('/mnt/d/metistream/hail/data/1kg.vds'); >>> common_vds = common_vds.annotate_samples_table(table, root='sa'); SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; >>> common_vds = common_vds.sample_qc(); >>> common_vds = common_vds.filter_samples_expr('sa.qc.dpMean >= 4 && sa.qc.callRate >= 0.97'); >>> common_vds = common_vds.filter_genotypes('let ab = g.ad[1] / g.ad.sum() in ((g.isHomRef && ab <= 0.1) || (g.isHet && ab >= 0.25 && ab <= 0.75) ||(g.isHomVar && ab >= 0.9))'); // class version 52.0 (52); // access flags 0x1; public class is/hail/codegen/generated/C0 implements java/io/Serializable is/hail/asm4s/AsmFunction2 {. // access flags 0x1; public apply([Ljava/lang/Object;Lscala/collection/mutable/ArrayBuffer;)Ljava/lang/Object;; L0; ALOAD 2; LDC 2; INVOKEVIRTUAL scala/collection/mutable/ArrayBuffer.apply (I)Ljava/lang/Object;; CHECKCAST org/apache/spark/sql/Row; ASTORE 3; ALOAD 3; IFNULL L1; ALOAD 3; LDC 5; INVOKEINTERFACE org/apache/spark/sql/Row.get (I)Ljava/lang/Object;; CHECKCAST org/apache/spark/sql/Row; GOTO L2; L1; FRAME APPEND [org/apache/spark/sql/Row]; ACONST_NULL; L2; FRAME SAME1 org/apache/spark/sql/Row; ASTORE 4; ALOAD 4; IFNULL L3; ALOAD 4; LDC 12; INVOKEINTERFACE org/apache/spark/sql/Row.get (I)Ljava/lang/Object;; CHECKCAST java/lang/Double; GOTO L4; L3; FRAME APPEND [org/apache/spark/sql/Row]; ACONST_NULL; L4; FRAME SAME1 java/lang/Double; ASTORE 5; ALOAD 5; IFNULL L5; NEW java/lang/Integer; DUP; LDC 4; INVOKESPECIAL java/lang/Integer.<init> (I)V; ASTORE 6; ALOAD 6; IFNULL L6; ALOAD 1; LDC 0; AALOAD; ALOAD 5; ALOAD 6; INVOKEINTERFACE scala/Function2.apply (Ljava/lang/Object;Ljava/lang/Object;)Ljava/lang/Object;; GOTO L7; L6; FRAME APPEND [java/lang/Double java/lang/Integer]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2966:3685,access,access,3685,https://hail.is,https://github.com/hail-is/hail/issues/2966,1,['access'],['access']
Security,"al outlines a solution to this problem. *This is a work in progress*. ### TL;DR; Use Kata + CRI-Containerd runtime to sandbox pods, at a low performance cost. [Jessie Frazelle’s Blog: Hard Multi-Tenancy in Kubernetes](https://blog.jessfraz.com/post/hard-multi-tenancy-in-kubernetes/). ### Roadmap; I would like to implement a test cluster that uses this system, and begin migrating our existing workloads to it asap. . *TODO*. ### Rationale; 1. We want resource preemption across users., running multiple user containers on a single cluster.; 2. This means sandboxing at the cluster level is out.; 3. Therefore we must sandbox at the pod (or container) level. Kata + CRI-Containerd chosen for performance and maturity reasons.; CRI-Containerd is much faster than CRI-O, and Kata is much faster than gVisor. Kata is a relatively mature product from Intel. Production users include JD.com. ### User-level access control ; An orthogonal issue that still needs to be addressed. [RBAC Authorization - Kubernetes](https://kubernetes.io/docs/reference/access-authn-authz/rbac/). *TODO*. ### Related: Firecracker; Interesting project, similar to Kata and gVisor in its isolation properties. Doesn’t work with Kubernetes, replicates some Kube functionality.; * [Announcing the Firecracker Open Source Technology: Secure and Fast microVM for Serverless Computing | AWS Open Source Blog](https://aws.amazon.com/blogs/opensource/firecracker-open-source-secure-fast-microvm-serverless/); * Potentially lower runtime cost that Kata; * Written in Rust :). ### Alternatives; [Nabla containers: a new approach to container isolation · Nabla Containers](https://nabla-containers.github.io); * Unclear how good containment is. Worth exploring. ### Performance; [Runtime performance benchmark result. containerd vs CRI-containerd vs CRI-O · GitHub](https://gist.github.com/kunalkushwaha/66629a90e0f8f5cc5dc512ef1c346f2f). [Measuring the Horizontal Attack Profile of Nabla Containers](https://outlookseries.com/A0784/Infr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5111:1151,Authoriz,Authorization,1151,https://hail.is,https://github.com/hail-is/hail/issues/5111,1,['Authoriz'],['Authorization']
Security,"al support of <code>Kernel32Util.formatMessage</code> - <a href=""https://github.com/overpathz""><code>@​overpathz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1490"">#1490</a>: Adds support for a custom <code>SymbolProvider</code> in <code>NativeLibrary</code> &amp; <code>Library</code> - <a href=""https://github.com/soywiz""><code>@​soywiz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1491"">#1491</a>: Update libffi to v3.4.4 - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1487"">#1487</a>: Add 'uses' information to OSGI metadata in MANIFEST.MF to improve stability of package resolution - <a href=""https://github.com/sratz""><code>@​sratz</code></a>.</li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1452"">#1452</a>: Fix memory allocation/handling for error message generation in native library code (<code>dispatch.c</code>) - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1460"">#1460</a>: Fix win32 variant date conversion in DST offest window and with millisecond values - <a href=""https://github.com/eranl""><code>@​eranl</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1472"">#1472</a>: Fix incorrect bitmask in <code>c.s.j.Pointer#createConstant(int)</code> - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1481"">#1481</a>: Fix NPE in NativeLibrary when unpacking from classpath is disabled - <a href=""https://github.com/trespasserw""><code>@​trespasserw</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1489"">#1489</a>: Fixes typo in <code>OpenGL3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:2489,access,access,2489,https://hail.is,https://github.com/hail-is/hail/pull/12886,1,['access'],['access']
Security,"ally verifying that the certificate came from a single root certificate (that we, perhaps, destroy after everything is signed) would additionally prevent a malicious user from inserting their certificates into the trusted certificates list. AFAICT, python's `ssl` module has no support for this verification strategy. We could probably build an SSLContext shim that contained two SSLContexts one with a root cert and one with the trusted certs and require certification verification to pass both. Seems easy to get wrong, so I'm inclined to not take this path. ### trusted cert lists. Yeah, it felt a little silly to duplicate the cert in each secret. However, this seems like the simplest approach if I require each principal to only trust a subset of incoming/outgoing principals. If I had one secret per principal, then I have to modify build.yaml or deployment.yamls if I modify the trust sets. That seemed error prone. If I had one secret with all the certs, then when a service starts up it has to select the trusted ones and only insert those into its certificate store. This seems OK, but a little harder to inspect. Duplicating a cert for each trust list to which it belongs occupies what seems like a good spot to me from a developer ergonomics perspective:; - O(trusts) modifications necessary to update/revoke the cert; - O(1) configuration to load a trust list; - no pod-start-time configuration; - the trust list is on the container's file system, so its easy to inspect. Small point: I don't pin the incoming certs yet due to the mTLS challenges. ### create on each deploy. Only creating certs if they don't exist is an easy change. Seems fine, though leaves unresolved how to rotate the certs. I guess I'm inclined to always recreate because it makes rotation the common case, forcing us to make it work well. I think the only way to do a no-downtime rotation is:; 1. create fresh certs; 2. create the trust lists including a principal's fresh cert and previous generation cert; 3. up",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561#issuecomment-617428243:2042,certificate,certificate,2042,https://hail.is,https://github.com/hail-is/hail/pull/8561#issuecomment-617428243,1,['certificate'],['certificate']
Security,"als_to_index_meta=True,; File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 142, in export_vds_to_elasticsearch; verbose=verbose); File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 287, in export_kt_to_elasticsearch; kt.export_elasticsearch(self._host, int(self._port), index_name, index_type_name, block_size, config=elasticsearch_config); File ""<decorator-gen-143>"", line 2, in export_elasticsearch; File ""/hail/build/distributions/hail-python.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: EsHadoopIllegalArgumentException: Unsupported/Unknown Elasticsearch version 6.0.0. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 1 times, most recent failure: Lost task 0.0 in stage 12.0 (TID 20050, localhost): org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot detect ES version - typically this happens if the network/Elasticsearch cluster is not accessible or when targeting a WAN/Cloud instance without the proper setting 'es.nodes.wan.only'; 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:247); 	at org.elasticsearch.hadoop.rest.RestService.createWriter(RestService.java:545); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:58); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.elasticsearch.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:1745,access,accessible,1745,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['access'],['accessible']
Security,"als` delegates to `_parameterized_filter_intervals`. In that method, the intervals are collected into a local array:. ```python3; intervals = hl.literal(intervals.aggregate(hl.agg.collect(intervals.key[0]), _localize=False)); ```. Unfortunately, `hl.literal` will evaluate a Hail expression in order to produce a `Literal` IR node. As a result, this serializes a potentially large array of intervals from Scala to Python. This is usually fine, but when this array is serialized back to Java as a `Literal`, it is serialized as JSON. Our JSON representation of an Interval of Locus is particularly verbose:. ```ipython3; In [5]: import hail as hl; ...:; ...: hl.literal(hl.Interval(start=hl.Locus(contig='chr1', position=10001, reference_genome='GRCh38'), end=hl.Locus(contig='chr1', position=11001, reference_genome='GRCh38'), includes_start=True, includes_end=False))._ir.head_str(); Out[5]: 'Interval[Locus(GRCh38)] ""{\\""start\\"": {\\""contig\\"": \\""chr1\\"", \\""position\\"": 10001}, \\""end\\"": {\\""contig\\"": \\""chr1\\"", \\""position\\"": 11001}, \\""includeStart\\"": true, \\""includeEnd\\"": false}""'. In [6]: len(Out[5]); Out[6]: 183; ```. 183 bytes per locus interval. The binary representation is just a string and a 32-bit integer, both required. I suspect this fits in no more than 16 bytes. There are four more fundamental problems:; 1. `hl.literal` should probably be more careful about converting a Scala value into a Python value only to stick it inside a literal again.; 2. The Scala-Python communication should not use Py4J, a plain-text protocol. https://github.com/hail-is/hail/issues/13756; 3. Python->Scala should use a a compact binary encoding rather than the JSON encoding for literals. (Scala->Python already does this). https://github.com/hail-is/hail/issues/13757; 4. SemanticHash should not generate a JSON string just to compute a hash. (This becomes irrelevant if large literals are always `EncodedLiteral`, see (3)). ### Version. 0.2.117. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13748:2096,hash,hash,2096,https://hail.is,https://github.com/hail-is/hail/issues/13748,1,['hash'],['hash']
Security,"alt=""Supported Python versions"" /></a></p>; <p><a href=""https://github.com/ambv/black""><img src=""https://img.shields.io/badge/code%20style-black-000000.svg"" alt=""image"" /></a></p>; <p>pytest-asyncio is an Apache2 licensed library, written in Python, for; testing asyncio code with pytest.</p>; <p>asyncio code is usually written in the form of coroutines, which makes; it slightly more difficult to test using normal testing tools.; pytest-asyncio provides useful fixtures and markers to make testing; easier.</p>; <pre lang=""{.sourceCode"" data-meta="".python}""><code>@pytest.mark.asyncio; async def test_some_asyncio_code():; res = await library.do_something(); assert b&quot;expected result&quot; == res; </code></pre>; <p>pytest-asyncio has been strongly influenced by; <a href=""https://github.com/eugeniy/pytest-tornado"">pytest-tornado</a>.</p>; <h1>Features</h1>; <ul>; <li>fixtures for creating and injecting versions of the asyncio event; loop</li>; <li>fixtures for injecting unused tcp/udp ports</li>; <li>pytest markers for treating tests as asyncio coroutines</li>; <li>easy testing with non-default event loops</li>; <li>support for [async def]{.title-ref} fixtures and async generator; fixtures</li>; <li>support <em>auto</em> mode to handle all async fixtures and tests; automatically by asyncio; provide <em>strict</em> mode if a test suite; should work with different async frameworks simultaneously, e.g.; <code>asyncio</code> and <code>trio</code>.</li>; </ul>; <h1>Installation</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pytest-dev/pytest-asyncio/blob/master/CHANGELOG.rst"">pytest-asyncio's changelog</a>.</em></p>; <blockquote>; <h1>0.20.1 (22-10-21)</h1>; <ul>; <li>Fixes an issue that warned about using an old version of pytest, even though the most recent version was installed. <code>[#430](https://github.com/pytest-dev/pytest-asyncio/issues/430",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12390:1906,inject,injecting,1906,https://hail.is,https://github.com/hail-is/hail/pull/12390,2,['inject'],['injecting']
Security,"alt=""Supported Python versions"" /></a></p>; <p><a href=""https://github.com/ambv/black""><img src=""https://img.shields.io/badge/code%20style-black-000000.svg"" alt=""image"" /></a></p>; <p>pytest-asyncio is an Apache2 licensed library, written in Python, for; testing asyncio code with pytest.</p>; <p>asyncio code is usually written in the form of coroutines, which makes; it slightly more difficult to test using normal testing tools.; pytest-asyncio provides useful fixtures and markers to make testing; easier.</p>; <pre lang=""{.sourceCode"" data-meta="".python}""><code>@pytest.mark.asyncio; async def test_some_asyncio_code():; res = await library.do_something(); assert b&quot;expected result&quot; == res; </code></pre>; <p>pytest-asyncio has been strongly influenced by; <a href=""https://github.com/eugeniy/pytest-tornado"">pytest-tornado</a>.</p>; <h1>Features</h1>; <ul>; <li>fixtures for creating and injecting versions of the asyncio event; loop</li>; <li>fixtures for injecting unused tcp/udp ports</li>; <li>pytest markers for treating tests as asyncio coroutines</li>; <li>easy testing with non-default event loops</li>; <li>support for [async def]{.title-ref} fixtures and async generator; fixtures</li>; <li>support <em>auto</em> mode to handle all async fixtures and tests; automatically by asyncio; provide <em>strict</em> mode if a test suite; should work with different async frameworks simultaneously, e.g.; <code>asyncio</code> and <code>trio</code>.</li>; </ul>; <h1>Installation</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pytest-dev/pytest-asyncio/blob/master/CHANGELOG.rst"">pytest-asyncio's changelog</a>.</em></p>; <blockquote>; <h1>0.20.2 (22-11-11)</h1>; <ul>; <li>Fixes an issue with async fixtures that are defined as methods on a test class not being rebound to the actual test instance. <code>[#197](https://github.com/pytest-dev/pytest-asyncio/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12453:1906,inject,injecting,1906,https://hail.is,https://github.com/hail-is/hail/pull/12453,2,['inject'],['injecting']
Security,"alt=""Supported Python versions"" /></a></p>; <p><a href=""https://github.com/ambv/black""><img src=""https://img.shields.io/badge/code%20style-black-000000.svg"" alt=""image"" /></a></p>; <p>pytest-asyncio is an Apache2 licensed library, written in Python, for; testing asyncio code with pytest.</p>; <p>asyncio code is usually written in the form of coroutines, which makes; it slightly more difficult to test using normal testing tools.; pytest-asyncio provides useful fixtures and markers to make testing; easier.</p>; <pre lang=""{.sourceCode"" data-meta="".python}""><code>@pytest.mark.asyncio; async def test_some_asyncio_code():; res = await library.do_something(); assert b&quot;expected result&quot; == res; </code></pre>; <p>pytest-asyncio has been strongly influenced by; <a href=""https://github.com/eugeniy/pytest-tornado"">pytest-tornado</a>.</p>; <h1>Features</h1>; <ul>; <li>fixtures for creating and injecting versions of the asyncio event; loop</li>; <li>fixtures for injecting unused tcp/udp ports</li>; <li>pytest markers for treating tests as asyncio coroutines</li>; <li>easy testing with non-default event loops</li>; <li>support for [async def]{.title-ref} fixtures and async generator; fixtures</li>; <li>support <em>auto</em> mode to handle all async fixtures and tests; automatically by asyncio; provide <em>strict</em> mode if a test suite; should work with different async frameworks simultaneously, e.g.; <code>asyncio</code> and <code>trio</code>.</li>; </ul>; <h1>Installation</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/929608e60ec2c2643c7d0e7b0604cf186c158cd9""><code>929608e</code></a> docs: Prepare release 0.18.2. (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/304"">#304</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/2359807ec75a1a39c9f60fae715b3a39885c67cf""><co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11510:1906,inject,injecting,1906,https://hail.is,https://github.com/hail-is/hail/pull/11510,2,['inject'],['injecting']
Security,"ample_file=sample,entry_fields=['GT', 'GP','dosage']).write(mt). ### What went wrong (all error messages here, including the full java stack trace):; ```; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2-721af83bc30a; LOGGING: writing to /restricted/projectnb/ukbiobank/ad/analysis/ad.v1/hail-20181114-1827-0.2-721af83bc30a.log; Exception in thread ""dispatcher-event-loop-8"" Exception in thread ""refresh progress"" java.lang.OutOfMemoryError: GC overhead limit exceeded; at java.util.zip.ZipCoder.getBytes(ZipCoder.java:80); at java.util.zip.ZipFile.getEntry(ZipFile.java:310); at java.util.jar.JarFile.getEntry(JarFile.java:240); at java.util.jar.JarFile.getJarEntry(JarFile.java:223); at sun.misc.URLClassPath$JarLoader.getResource(URLClassPath.java:1042); at sun.misc.URLClassPath.getResource(URLClassPath.java:239); at java.net.URLClassLoader$1.run(URLClassLoader.java:365); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:1651,Access,AccessController,1651,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Access'],['AccessController']
Security,"analogous to gcloud auth login --no-launch-browser for authenticating on a remote server where we can't use localhost callback. We also need a Python interface that can be used from a Jupyter notebook, something like:. ```; hailtop.auth.login(); ==> returns URL to navigate to; hailtop.auth.complete_login('<verification ID>'); ```. where the verification ID is obtained from Google and pasted in. - [ ] hailctl auth login --no-launch-browser; - [ ] remote Python auth flow",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8158:55,authenticat,authenticating,55,https://hail.is,https://github.com/hail-is/hail/issues/8158,1,['authenticat'],['authenticating']
Security,"and give the user a warning that they might want to log in. Anonymous credentials will allow us to access public buckets without authenticating, which was not possible until now. I contemplated whether we should only suggest the login if they've received a 401 but I assume most everyone using this will want to be authenticated and we already log a warning as it is. This is reasonably testable, but I couldn't find where it should go. Does `test_fs` test credential-loading at all?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11207:99,access,access,99,https://hail.is,https://github.com/hail-is/hail/pull/11207,3,"['access', 'authenticat']","['access', 'authenticated', 'authenticating']"
Security,ang.IllegalArgumentException: null; at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:46); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:443); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:426); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:103); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:426); at org.apache.xbean.asm5.ClassReader.a(Unknown Source); at org.apache.xbean.asm5.ClassReader.b(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:257); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:256); at scala.collection.immutable.List.foreach(List.scala:381); at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:256); at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:156); at org.apache.spark.SparkContext.clean(SparkContext.scala:2294); ,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4896:1540,Hash,HashMap,1540,https://hail.is,https://github.com/hail-is/hail/issues/4896,1,['Hash'],['HashMap']
Security,"any different functions with long names. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I pushed all the; gr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9862:1039,authenticat,authentication,1039,https://hail.is,https://github.com/hail-is/hail/pull/9862,1,['authenticat'],['authentication']
Security,"ape &lt;/script&gt; tags in JSON data</li>; <li><a href=""https://github.com/spatialaudio/nbsphinx/commit/b34f3e41e9fbf821950ad9e7a0c2a1f2689aae1e""><code>b34f3e4</code></a> CSS: update for hiding copy button in prompts</li>; <li><a href=""https://github.com/spatialaudio/nbsphinx/commit/8bd255757ade0d072e5e13c9da706e002d6fa050""><code>8bd2557</code></a> Change internal representation of _BROKEN_THUMBNAIL</li>; <li><a href=""https://github.com/spatialaudio/nbsphinx/commit/4fc5c011f5d97b58485ffeb1b02c9f8bae58b657""><code>4fc5c01</code></a> CI: add -y flag to apt-get calls</li>; <li>Additional commits viewable in <a href=""https://github.com/spatialaudio/nbsphinx/compare/0.8.3...0.8.8"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=nbsphinx&package-manager=pip&previous-version=0.8.3&new-version=0.8.8)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11477:7347,secur,security-vulnerabilities,7347,https://hail.is,https://github.com/hail-is/hail/pull/11477,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"api server bits into CI (maybe should be prioritized earlier...I prefer to get draft of major functions done first; am new to writing tests for React/Node). ## Near-term goals (<= 6 mo); 1. Upload, download; 2. Launch clusters, pay for them; 3. ?. ## Longer-term goals; 1. Much simpler interface to Hail. I would like steps that can be performed without programming to be done so. I would prefer fasta->variant filtering to be done as in Bystro (at least from the interface standpoint), i.e without opening up a notebook. Common analyses pipelines should also be possible without any interaction with a python notebook: GWAS, rare-variant (SKAT) analyses have, it seems, relatively few permutations. Those should be behind UI primitives. At each stage of a ; 2. Social network bits: users should be able to share job state with other users (requested by Bystro users on 22q consortium project) at the least.; 3. Record job state using something like Merkle tree. Checkout state. Aka ""blockchain""; 4. Cooperative analysis: provide system for people to validate analyses; ; Basic idea: . 1) People donate computational resources for ad-hoc heterogenous clusters. ; 2) People donate intellectual capital. Re-run analyses without the full available code. See if they can replicate (not p-values, but order). Could generate multiple-hypothesis-test corrected aggregate. These users get publication credit as consortia; 3) People donate minor intellectual capital: Re-run analysis with full available code. Report on success. This will catch bugs, and non-deterministic results (for instance, if reported accuracy depends on local minima..similar or better minima may only occur once in a great while). Similar to 2. ## Timetables; 1-3a: 12/10/18; 3b: by 12/15/18; 4a-4b: by 12/12/18; 4c-d: by 12/15/18. This probably shouldn't be merged for a while. Still working on authentication handling for third party APIs. All first party APIs (our stuff) is well controlled, can be extended from existing codebase.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931:8861,validat,validate,8861,https://hail.is,https://github.com/hail-is/hail/pull/4931,2,"['authenticat', 'validat']","['authentication', 'validate']"
Security,apply(Graph.scala:54); 	at is.hail.utils.package$.using(package.scala:587); 	at is.hail.annotations.Region$.scoped(Region.scala:20); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2.apply(Graph.scala:54); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2.apply(Graph.scala:53); 	at is.hail.utils.BinaryHeap.isLeftFavoredTie(BinaryHeap.scala:16); 	at is.hail.utils.BinaryHeap.is$hail$utils$BinaryHeap$$bubbleUp(BinaryHeap.scala:161); 	at is.hail.utils.BinaryHeap.insert(BinaryHeap.scala:40); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:91); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:90); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:90); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:76); 	at is.hail.utils.Graph.maximalIndependentSet(Graph.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2-29fbaeaf265e; Error summary: MatchError: cmg_exomes ,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4857:4435,Hash,HashMap,4435,https://hail.is,https://github.com/hail-is/hail/issues/4857,1,['Hash'],['HashMap']
Security,"arams={'access_token': access_token},; + ); + if userinfo['aud'] != oauth2_client_audience and userinfo['aud'] != userinfo['sub']:; + return None; +; + email = userinfo['email']; + if email.endswith('iam.gserviceaccount.com'):; + return userinfo['sub']; + # We don't currently track user's unique GCP IAM ID (sub) in the database, just their email.; + return email; + except httpx.ClientResponseError as e:; + if e.status in (400, 401):; + return None; + raise; +; +; +class AadJwk(TypedDict):; + kid: str; + x5c: List[str]; +; ; class AzureFlow(Flow):; + _aad_keys: Optional[List[AadJwk]] = None; +; def __init__(self, credentials_file: str):; with open(credentials_file, encoding='utf-8') as f:; data = json.loads(f.read()); ; tenant_id = data['tenant']; authority = f'https://login.microsoftonline.com/{tenant_id}'; - client = msal.ConfidentialClientApplication(data['appId'], data['password'], authority); -; - self._client = client; + self._client = msal.ConfidentialClientApplication(data['appId'], data['password'], authority); self._tenant_id = tenant_id; ; def initiate_flow(self, redirect_uri: str) -> dict:; @@ -107,10 +170,31 @@ class AzureFlow(Flow):; ; return FlowResult(token['id_token_claims']['oid'], token['id_token_claims']['preferred_username'], token); ; -; -def get_flow_client(credentials_file: str) -> Flow:; - cloud = get_global_config()['cloud']; - if cloud == 'azure':; - return AzureFlow(credentials_file); - assert cloud == 'gcp'; - return GoogleFlow(credentials_file); + @staticmethod; + def perform_installed_app_login_flow(oauth2_client: Dict[str, Any]) -> Dict[str, Any]:; + tenant_id = oauth2_client['tenant']; + authority = f'https://login.microsoftonline.com/{tenant_id}'; + app = msal.PublicClientApplication(oauth2_client['appId'], authority=authority); + credentials = app.acquire_token_interactive([oauth2_client['userOauthScope']]); + return {**oauth2_client, 'refreshToken': credentials['refresh_token']}; +; + @staticmethod; + async def get_identity_uid_fro",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13131#issuecomment-1668558329:4943,Confidential,ConfidentialClientApplication,4943,https://hail.is,https://github.com/hail-is/hail/pull/13131#issuecomment-1668558329,2,"['Confidential', 'password']","['ConfidentialClientApplication', 'password']"
Security,arch.spark.serialization.ScalaValueWriter$$anonfun$doWriteScala$3.apply(ScalaValueWriter.scala:77); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.elasticsearch.spark.serialization.ScalaValueWriter.doWriteScala(ScalaValueWriter.scala:77); 	at org.elasticsearch.spark.serialization.ScalaValueWriter.doWrite(ScalaValueWriter.scala:50); 	at org.elasticsearch.spark.serialization.ScalaValueWriter$$anonfun$doWriteScala$2.apply(ScalaValueWriter.scala:66); 	at org.elasticsearch.spark.serialization.ScalaValueWriter$$anonfun$doWriteScala$2.apply(ScalaValueWriter.scala:63); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.elasticsearch.spark.serialization.ScalaValueWriter.doWriteScala(ScalaValueWriter.scala:63); 	at org.elasticsearch.spark.serialization.ScalaValueWriter.write(ScalaValueWriter.scala:46); 	at org.elasticsearch.hadoop.serialization.builder.ContentBuilder.value(ContentBuilder.java:53); 	at org.elasticsearch.hadoop.serialization.bulk.TemplatedBulk.doWriteObject(TemplatedBulk.java:71); 	at org.elasticsearch.hadoop.serialization.bulk.TemplatedBulk.write(TemplatedBulk.java:58); 	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:168); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at o,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:4189,Hash,HashMap,4189,https://hail.is,https://github.com/hail-is/hail/issues/4250,2,['Hash'],['HashMap']
Security,"arch` without a `config` argument works fine.; ```python; hl.export_elasticsearch(table, ""host"", 9200, ""someindex"", ""sometype"", 1000, config=None); ```. However, attempting to pass `config`, for example:; ```python; es_config = {""es.write.operation"": ""index""}; hl.export_elasticsearch(table, ""host"", 9200, ""someindex"", ""sometype"", 1000, config=es_config); ```; causes the following error:. ### What went wrong (all error messages here, including the full java stack trace):. ```; Traceback (most recent call last):; File ""/tmp/0ba8fc2c770d4b2ba96dc23c50fd6eab/load_clinvar_to_es.py"", line 105, in <module>; verbose=True,; File ""/tmp/0ba8fc2c770d4b2ba96dc23c50fd6eab/hail_v02_scripts.zip/hail_v02_scripts/utils/elasticsearch/client.py"", line 234, in export_table_to_elasticsearch; File ""/home/hail/hail.zip/hail/typecheck/check.py"", line 547, in wrapper; File ""/home/hail/hail.zip/hail/methods/impex.py"", line 1885, in export_elasticsearch; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/home/hail/hail.zip/hail/utils/java.py"", line 188, in deco; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py"", line 323, in get_return_value; py4j.protocol.Py4JError: An error occurred while calling z:is.hail.io.ElasticsearchConnector.export. Trace:; py4j.Py4JException: Method export([class is.hail.table.Table, class java.lang.String, class java.lang.Integer, class java.lang.String, class java.lang.String, class java.lang.Integer, class java.util.HashMap, class java.lang.Boolean]) does not exist; 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:339); 	at py4j.Gateway.invoke(Gateway.java:274); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4063:1834,Hash,HashMap,1834,https://hail.is,https://github.com/hail-is/hail/issues/4063,1,['Hash'],['HashMap']
Security,"are other implementations, such as; LibreSSL, but they implement roughly the same interface as OpenSSL. The TLS protocol defines both a scheme for the *encryption of messages* and for; the *authentication of parties*. The protocol defines authentication as; optional. In practice, at least one party presents authentication. For example,; public web servers authenticate themselves to clients but clients do not; reciprocate. ### Authentication; #### X.509 Certificates. TLS uses X.509 Certificates for authentication. X.509 is a rather complicated; standard. X.509 Certificates can be serialized in a variety of ways. We use the; Privacy-enhanced Electronic Mail (PEM) file format for serialization. PEM is; really simple. A file may contain multiple base64-encoded blobs each with a; header and footer of the form:. ```; -----BEGIN LABEL-----; ...; -----END LABEL-----; ```. where `LABEL` describes the data. We only use two labels: `CERTIFICATE` and; `PRIVATE KEY`. An X.509 Certificate is an unforgeable proof of identity. It usually is paired; with a private key that was used to digitally sign the certificate. In the; security literature, an authenticatable entity is usually called a; *principal*. Each principal should have a unique private key. In our system the; principals are both our services (e.g. `batch`, `batch-driver`) and any; non-serving clients (e.g. `test-batch`, `admin-pod`). A key and certificate are; generated ad nihilum by `openssl req -new`:. ```; openssl req -new \; -x509; -keyout key_file; -out cert_file; -newkey rsa:4096; -nodes; -subj /CN=example.com; -addext subjectAltName = DNS:www.example.com,DNS:foo.com; ```. The first three arguments are self-explanatory. I explain the rest:. - `-newkey rsa:4096`. TLS supports many different kinds of private keys. This; generates a 4096-bit private key.; - `-nodes`. This should be read as ""no DES"". It means that the private key is not; itself encrypted using DES and a password.; - `-subj /CN=example.com`. This certifi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:2855,Certificate,Certificate,2855,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['Certificate'],['Certificate']
Security,"are view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.8.4&new-version=3.8.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13270:8127,secur,security,8127,https://hail.is,https://github.com/hail-is/hail/pull/13270,10,"['Secur', 'secur']","['Security', 'security']"
Security,"are view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mistune&package-manager=pip&previous-version=0.8.4&new-version=2.0.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12064:5747,secur,security,5747,https://hail.is,https://github.com/hail-is/hail/pull/12064,2,"['Secur', 'secur']","['Security', 'security']"
Security,"are view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.22.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11939:6892,secur,security,6892,https://hail.is,https://github.com/hail-is/hail/pull/11939,6,"['Secur', 'secur']","['Security', 'security']"
Security,"are view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyspark&package-manager=pip&previous-version=3.1.3&new-version=3.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12452:4064,secur,security,4064,https://hail.is,https://github.com/hail-is/hail/pull/12452,2,"['Secur', 'secur']","['Security', 'security']"
Security,"are view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tornado&package-manager=pip&previous-version=6.3.1&new-version=6.3.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13120:4579,secur,security,4579,https://hail.is,https://github.com/hail-is/hail/pull/13120,4,"['Secur', 'secur']","['Security', 'security']"
Security,ark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 2019-01-22 13:12:06 YarnScheduler: INFO: Cancelling stage 0; 2019-01-22 13:12:06 DAGSchedulerEventProcessLoop: ERROR: DAGScheduler failed to cancel all jobs.; java.util.NoSuchElementException: key not found: 70; at scala.collection.MapLike$class.default(MapLike.scala:228); at scala.collection.AbstractMap.default(Map.scala:59); at scala.collection.mutable.HashMap.apply(HashMap.scala:65); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply$mcVJ$sp(TaskSchedulerImpl.scala:243); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:235); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:235); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:234); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.TaskSchedulerImpl.cancelTasks(TaskSchedulerImpl.scala:234); at o,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:203568,Hash,HashSet,203568,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['Hash'],['HashSet']
Security,artbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:170); at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:45); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:108); at scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:108); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:108); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at org.apache.spark.SparkStatusTracker.getActiveStageIds(SparkStatusTracker.scala:61); at org.apache.spark.ui.ConsoleProgressBar.org$apache$spark$ui$ConsoleProgressBar$$refresh(ConsoleProgressBar.scala:67); at org.apache.spark.ui.ConsoleProgressBar$$anon$1.run(ConsoleProgressBar.scala:55); at java.util.TimerThread.mainLoop(Timer.java:555); at java.util.TimerThread.run(Timer.java:505); ---------------------------------------------------------------------------; FatalError Traceback (most recent call las,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:3894,Hash,HashMap,3894,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Hash'],['HashMap']
Security,"ary>. ```; sphinx 5.3.0 has requirement docutils<0.20,>=0.14, but you have docutils 0.20.1.; sphinx-rtd-theme 1.3.0 has requirement docutils<0.19, but you have docutils 0.20.1.; matplotlib 3.5.3 requires pillow, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Arbitrary Code Execution <br/>[SNYK-PYTHON-IPYTHON-2348630](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-2348630) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Improper Privilege Management <br/>[SNYK-PYTHON-JUPYTERCORE-3063766](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERCORE-3063",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13866:1400,Certificate,Certificate,1400,https://hail.is,https://github.com/hail-is/hail/pull/13866,1,['Certificate'],['Certificate']
Security,"ase</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/977b08d160e81aaecebf871d2b8ba2f9a96ef9d6""><code>977b08d</code></a> [refactor] Create files for comparison checker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/ddfca0ca884d677e4eb0e6f53553b16e7a503157""><code>ddfca0c</code></a> [refactor] Create a file for _BasicChecker in pylint.checkers</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/be4699399904654ef4107a228817b4ef176d8999""><code>be46993</code></a> [refactor] Create a package in order to be able to burst base.py</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.12.2...v2.13.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.12.2&new-version=2.13.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11674:5710,secur,security-vulnerabilities,5710,https://hail.is,https://github.com/hail-is/hail/pull/11674,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"ashable"" data. Python lists are not hashable because they're mutable. This is transitively a problem. For example, the following also fails with the same error because the list inside the tuple is mutable thus the tuple is not (safely) hashable.; ```; {(""tuples"", ""are"", ""immutable"", [""lists"", ""are"", ""not""])}; ```. Hail's internal language is fully immutable, so every type can be placed inside a set (or used as the keys of a dict). When we convert from Hail's internal representation to Python, we cannot use mutable types in hashable positions. Unfortunately, we also need to maintain backwards compatibility with the way the code currently works. You can see this pretty clearly in the difference between `hl.agg.collect` and `hl.agg.collect_as_set`:; ```; t = hl.utils.range_table(1); t = t.annotate(ls = [1, 2, 3]); collected_ls = t.aggregate(hl.agg.collect(t.ls)); collected_as_set_ls = t.aggregate(hl.agg.collect_as_set(t.ls)); ```; `collected_ls` should be `[[1, 2, 3]]` whereas `collected_as_set_ls` necessarily uses hashable types: `{frozenlist([1, 2, 3])}`. Things are particularly subtle with dictionaries whose keys must always be hashable and whose values need only be hashable if the dictionary itself must be hashable. For example:; ```; t = hl.utils.range_table(1); # we're trying to create {[""hello""]: [""goodbye""]}, but that; # would fail because a python dictionary can't have a list; # as a key; t = t.annotate(x = hl.dict([([""hello""], [""goodbye""])])); in_list = t.aggregate(hl.agg.collect(t.x)); in_set = t.aggregate(hl.agg.collect_as_set(t.x)); ```; `in_list` will be `[{frozenlist([""hello""]): [""goodbye""]}]` (because we should be backwards compatible with the expectation that lists in value-position are mutable) but `in_set` will be `{{frozenlist([""hello""]): frozenlist([""goodbye""])}}` (because the dictionary is inside a set and therefore it, itself, must be hashable). ---. Aside: I also do an ugly subclass to put a type parameter on the `FrozenList` class from `frozenli",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12265:1785,hash,hashable,1785,https://hail.is,https://github.com/hail-is/hail/pull/12265,1,['hash'],['hashable']
Security,"associated Types - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1474"">#1474</a>: Add <code>c.s.j.p.win32.WbemCli#IWbemClassObject.IWbemQualifierSet</code>, <code>IWbemServices.GetObject</code>, <code>IWbemContext.SetValue</code> and associated methods - <a href=""https://github.com/rchateauneu""><code>@​rchateauneu</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1482"">#1482</a>: Add multilingual support of <code>Kernel32Util.formatMessage</code> - <a href=""https://github.com/overpathz""><code>@​overpathz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1490"">#1490</a>: Adds support for a custom <code>SymbolProvider</code> in <code>NativeLibrary</code> &amp; <code>Library</code> - <a href=""https://github.com/soywiz""><code>@​soywiz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1491"">#1491</a>: Update libffi to v3.4.4 - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1487"">#1487</a>: Add 'uses' information to OSGI metadata in MANIFEST.MF to improve stability of package resolution - <a href=""https://github.com/sratz""><code>@​sratz</code></a>.</li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1452"">#1452</a>: Fix memory allocation/handling for error message generation in native library code (<code>dispatch.c</code>) - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1460"">#1460</a>: Fix win32 variant date conversion in DST offest window and with millisecond values - <a href=""https://github.com/eranl""><code>@​eranl</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-ac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:2000,access,access,2000,https://hail.is,https://github.com/hail-is/hail/pull/12886,1,['access'],['access']
Security,at com.sun.crypto.provider.AESCipher.engineDoFinal(AESCipher.java:491) ~[sunjce_provider.jar:1.8.0_392]; 	at javax.crypto.CipherSpi.bufferCrypt(CipherSpi.java:779) ~[?:1.8.0_392]; 	at javax.crypto.CipherSpi.engineDoFinal(CipherSpi.java:730) ~[?:1.8.0_392]; 	at javax.crypto.Cipher.doFinal(Cipher.java:2463) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLCipher$T12GcmReadCipherGenerator$GcmReadCipher.decrypt(SSLCipher.java:1606) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:262) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dki,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:9081,secur,security,9081,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352,1,['secur'],['security']
Security,at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; 	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); 	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); 	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); 	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:245); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:11870,Checksum,ChecksumFileSystem,11870,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['Checksum'],['ChecksumFileSystem']
Security,at scala.collection.AbstractMap.default(Map.scala:59); at scala.collection.mutable.HashMap.apply(HashMap.scala:65); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply$mcVJ$sp(TaskSchedulerImpl.scala:243); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:235); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:235); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:234); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.TaskSchedulerImpl.cancelTasks(TaskSchedulerImpl.scala:234); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply$mcVI$sp(DAGScheduler.scala:1543); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndInde,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:200345,Hash,HashMap,200345,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['Hash'],['HashMap']
Security,"ata and a hash function can cause this integer map to exceed its size limitations at a load factor of 5%. Even a 20x increase in footprint puts us at 400 million. Each element of that array has 6 entries, so we're at 1.2 billion. That definitely feels like the danger zone. Maybe there's more variants than Danfeng expects, maybe there's more overhead than we've accounted for. The GATK folks have been chasing down the fix. Kryo [released 4.0.0](https://github.com/EsotericSoftware/kryo/issues/431) which should fix this issue. Spark [upgraded to Kryo 4.0.0](https://github.com/apache/spark/pull/22179) on September 8th of 2018. (resolving [Spark-20389](https://issues.apache.org/jira/browse/SPARK-20389)). This change made it to 2.4.0, but it was not back ported to other versions of Spark. GATK [references a temporary fix via JVM options](; https://github.com/broadinstitute/gatk/issues/1524#issuecomment-189368808), which apparently forces the JVM to use an alternative hash function with better behavior in this specific case:; ```; spark.executor.extraJavaOptions -XX:hashCode=0; spark.driver.extraJavaOptions -XX:hashCode=0; ```; A [generally interesting blog post on Java's hashCode](https://srvaroa.github.io/jvm/java/openjdk/biased-locking/2017/01/30/hashCode.html), which I haven't fully read, claims that the JVM previously defaulted to a PRNG draw for an object's hash code. In JDK 8 it uses some function of the current thread state. It appears this old strategy is preserved as JVM hashCode parameter value 0 and is less likely to trigger the bad behavior in Kryo. This `-XX:hashCode` option is undocumented [1](https://docs.oracle.com/javase/8/docs/technotes/tools/windows/java.html), [2](https://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html) 🤷‍♀️. Another suggested Kryo option is to disable reference tracking. This would cause duplicate objects in the object graph to be serialized twice:; ```java; Kryo kryo = new Kryo();; kryo.setReferences(false);; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5564:1665,hash,hashCode,1665,https://hail.is,https://github.com/hail-is/hail/issues/5564,7,['hash'],"['hash', 'hashCode']"
Security,"ataproc/bdutil/configure_docker.sh; /run/docker.sock; /tmp/dataproc/uninstall/docker-ce; /tmp/dataproc/components/uninstall/docker-ce.running; /tmp/dataproc/components/uninstall/docker-ce.done; /tmp/dataproc/components/pre-uninstall/docker-ce.running; /tmp/dataproc/components/pre-uninstall/docker-ce.done; /etc/apt/preferences.d/docker-ce.pref; /etc/apt/preferences.d/docker-ce-cli.pref; /etc/apt/sources.list.d/docker.list; /var/lib/apt/lists/download.docker.com_linux_debian_dists_buster_InRelease; /var/lib/apt/lists/download.docker.com_linux_debian_dists_buster_stable_binary-amd64_Packages; ```. </details>. There is a `/run/docker.sock` but notice it is not `/var/run/...`. However, if I install Docker by hand into this worker of a *non-Hail* Dataproc cluster, it just works. ---. I also tried to replicate the failure using an initialization action, but that also just worked.; ```; gcloud dataproc clusters create dk-test2 --initialization-actions=gs://hail-common/dk-test.sh; ```; `gs://hail-common/dk-test.sh`:; ```; apt-get update; apt-get -y install \; apt-transport-https \; ca-certificates \; curl \; gnupg2 \; software-properties-common \; tabix; curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -; sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable""; apt-get update; apt-get install -y --allow-unauthenticated docker-ce; ```. ---. Our users often report this error. In my experience, it has happened in 2/8 test_dataproc steps that I have run myself or seen run. The more workers you have, the higher the chance at least one worker fails. As @bpblanken suggested [here](https://github.com/hail-is/hail/issues/12936#issuecomment-1589956412), restarting docker on a failed worker works. Docker starts fine. However, I missed a subtlety: we must restart *after* installation but *before* we try to pull our VEP docker image. I also added a sleep in hopes that gives various things a chance to die off.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936#issuecomment-1709120751:13621,certificate,certificates,13621,https://hail.is,https://github.com/hail-is/hail/issues/12936#issuecomment-1709120751,1,['certificate'],['certificates']
Security,ataproc/deploy_metadata.py'; adding 'hailtop/hailctl/dataproc/diagnose.py'; adding 'hailtop/hailctl/dataproc/gcloud.py'; adding 'hailtop/hailctl/dataproc/modify.py'; adding 'hailtop/hailctl/dataproc/start.py'; adding 'hailtop/hailctl/dataproc/submit.py'; adding 'hailtop/hailctl/dataproc/utils.py'; adding 'hailtop/hailctl/dev/__init__.py'; adding 'hailtop/hailctl/dev/ci_client.py'; adding 'hailtop/hailctl/dev/cli.py'; adding 'hailtop/hailctl/dev/config.py'; adding 'hailtop/hailctl/hdinsight/__init__.py'; adding 'hailtop/hailctl/hdinsight/cli.py'; adding 'hailtop/hailctl/hdinsight/start.py'; adding 'hailtop/hailctl/hdinsight/submit.py'; adding 'hailtop/utils/__init__.py'; adding 'hailtop/utils/process.py'; adding 'hailtop/utils/rate_limiter.py'; adding 'hailtop/utils/rates.py'; adding 'hailtop/utils/rich_progress_bar.py'; adding 'hailtop/utils/serialization.py'; adding 'hailtop/utils/time.py'; adding 'hailtop/utils/utils.py'; adding 'hailtop/utils/validate/__init__.py'; adding 'hailtop/utils/validate/validate.py'; adding 'hail-0.2.120.dist-info/METADATA'; adding 'hail-0.2.120.dist-info/WHEEL'; adding 'hail-0.2.120.dist-info/entry_points.txt'; adding 'hail-0.2.120.dist-info/top_level.txt'; adding 'hail-0.2.120.dist-info/RECORD'; removing build/bdist.linux-x86_64/wheel; python3 -m pip install 'pip-tools==6.13.0' && bash ../check_pip_requirements.sh python; Requirement already satisfied: pip-tools==6.13.0 in /usr/local/lib/python3.8/site-packages (6.13.0); Requirement already satisfied: build in /usr/local/lib/python3.8/site-packages (from pip-tools==6.13.0) (0.10.0); Requirement already satisfied: click>=8 in /usr/local/lib/python3.8/site-packages (from pip-tools==6.13.0) (8.1.6); Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.8/site-packages (from pip-tools==6.13.0) (23.2.1); Requirement already satisfied: setuptools in /usr/lib/python3.8/site-packages (from pip-tools==6.13.0) (38.4.0); Requirement already satisfied: wheel in /usr/local/lib/python3.8,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13445:13065,validat,validate,13065,https://hail.is,https://github.com/hail-is/hail/issues/13445,2,['validat'],['validate']
Security,"atcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:170); at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:45); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:108); at scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:108); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:108); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at org.apache.spark.SparkStatusTracker.getActiveStageIds(SparkStatusTracker.scala:61); at org.apache.spark.ui.ConsoleProgressBar.org$apache$spark$ui$ConsoleProgressBar$$refresh(ConsoleProgressBar.scala:67); at org.apache.spark.ui.ConsoleProgressBar$$anon$1.run(ConsoleProgressBar.scala:55); at java.util.TimerThread.mainLoop(Timer.java:555); at java.util.TimerThread.run(Timer.java:505); ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); /restricted/projectnb/ukbiobank/ad/analysis/ad.v1/bgen2mt.py in <module>; 6 sample=""/project/ukbiobank/imp/uk.v3/bgen/ukb19416_imp_chr""+chr+""_v3_s487327.sample""; 7 mt=""/project/ukbiobank/imp/uk.v3/mt/ukbb_imp_chr""+chr+""_v3_s487327.mt""; ----> 8 hl.index_bgen(bgen); 9 hl.import_bgen(bgen,sample_file=sample,entry_fields=['GT', '",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:4243,Hash,HashMap,4243,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Hash'],['HashMap']
Security,"atibility_score?dependency-name=cryptography&package-manager=pip&previous-version=41.0.3&new-version=41.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13685:2829,secur,security,2829,https://hail.is,https://github.com/hail-is/hail/pull/13685,6,"['Secur', 'secur']","['Security', 'security']"
Security,"atibility_score?dependency-name=cryptography&package-manager=pip&previous-version=41.0.5&new-version=41.0.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14046:2930,secur,security,2930,https://hail.is,https://github.com/hail-is/hail/pull/14046,6,"['Secur', 'secur']","['Security', 'security']"
Security,"atibility_score?dependency-name=cryptography&package-manager=pip&previous-version=42.0.2&new-version=42.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14332:5179,secur,security,5179,https://hail.is,https://github.com/hail-is/hail/pull/14332,6,"['Secur', 'secur']","['Security', 'security']"
Security,"ative library code (<code>dispatch.c</code>) - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1460"">#1460</a>: Fix win32 variant date conversion in DST offest window and with millisecond values - <a href=""https://github.com/eranl""><code>@​eranl</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1472"">#1472</a>: Fix incorrect bitmask in <code>c.s.j.Pointer#createConstant(int)</code> - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1481"">#1481</a>: Fix NPE in NativeLibrary when unpacking from classpath is disabled - <a href=""https://github.com/trespasserw""><code>@​trespasserw</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1489"">#1489</a>: Fixes typo in <code>OpenGL32Util#wglGetProcAddress</code>, instead of parameter <code>procName</code> the hardcoded value <code>wglEnumGpusNV</code> was used - <a href=""https://github.com/soywiz""><code>@​soywiz</code></a>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/java-native-access/jna/commit/4962fd7758493b7395e86578705d8a32f6238872""><code>4962fd7</code></a> Release 5.13.0</li>; <li><a href=""https://github.com/java-native-access/jna/commit/a56504611b00cc7d90c165f924c3915cb7a6f759""><code>a565046</code></a> Adjust release directions</li>; <li><a href=""https://github.com/java-native-access/jna/commit/f7017c4f957d7fc13c7455efcae200e29407a729""><code>f7017c4</code></a> Remove artifacts classified as &quot;-jpms&quot;, there are the jna-jpms and jna-platfo...</li>; <li><a href=""https://github.com/java-native-access/jna/commit/a5f47cd359d5fe62a0e5d6c2bd9d649874be955d""><code>a5f47cd</code></a> Merge pull request <a href=""https://redirect.github.com/java-native-access/jna/issues/1494"">#1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:3488,access,access,3488,https://hail.is,https://github.com/hail-is/hail/pull/12886,1,['access'],['access']
Security,"attributes</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/27f05328d0369ad0db85c27935d52fdadf020f6b""><code>27f0532</code></a> Move <code>aside.topic</code> into the conditional blocks</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/5806f0af2788db40661d62e5e88c2c1560ae46b6""><code>5806f0a</code></a> Add <code>nav.contents</code> everywhere that <code>div.topic</code> is used</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/8da2efb1d71ab2d384ddc90cf4fdebe5d18e91cd""><code>8da2efb</code></a> Rename CSS files to CSS template files</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v5.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=5.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11925:6530,secur,security-vulnerabilities,6530,https://hail.is,https://github.com/hail-is/hail/pull/11925,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"authentication-extensions-for-python/commit/a88fa673af3602fe7c8c922314599b0c245e7add""><code>a88fa67</code></a> Merge branch 'release-1.0.0'</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/bd5b4074dbb7d03c9d91ce6a75378851be92552a""><code>bd5b407</code></a> Update README to reflect the new APIs</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6f77b1e70be086aae752dcf7e08d7f06bcabdcd7""><code>6f77b1e</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/109"">#109</a> from AzureAD/release-1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/50bf9674f9c65229a1573be39ef4ef507eee17fa""><code>50bf967</code></a> MSAL EX for Python 1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6b904af1a3d4fc0e28e3f090fa3dd8492f79e6bf""><code>6b904af</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/110"">#110</a> from AzureAD/persistence-factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/d0696aeb6f65168b1e0d405cd871b80bb101cd76""><code>d0696ae</code></a> Add build_encrypted_persistence() factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/289a94f694645c642ae67b2d5972d3f9fdadb928""><code>289a94f</code></a> Remove old classes that are deprecated for 2 years</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/fa1f45b556341b2c34e9bf63c06a5068571cd337""><code>fa1f45b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/108"">#108</a> from AzureAD/actionable-encryption-exceptions</",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:2788,authenticat,authentication-extensions-for-python,2788,https://hail.is,https://github.com/hail-is/hail/pull/11992,1,['authenticat'],['authentication-extensions-for-python']
Security,"autifulsoup4 4.12.2 requires soupsieve, which is not installed.; argon2-cffi-bindings 21.2.0 requires cffi, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low sever",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13836:1481,Access,Access,1481,https://hail.is,https://github.com/hail-is/hail/pull/13836,3,['Access'],['Access']
Security,"aving fundamental error against the OpenAPIv3 schema. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108859"">kubernetes/kubernetes#108859</a>, <a href=""https://github.com/cici37""><code>@​cici37</code></a>)</li>; <li>Support for gRPC probes is now in beta. GRPCContainerProbe feature gate is enabled by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108522"">kubernetes/kubernetes#108522</a>, <a href=""https://github.com/SergeyKanzhelev""><code>@​SergeyKanzhelev</code></a>)</li>; <li>Suspend job to GA. The feature gate <code>SuspendJob</code> is locked and will be removed in 1.26. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108129"">kubernetes/kubernetes#108129</a>, <a href=""https://github.com/ahg-g""><code>@​ahg-g</code></a>)</li>; <li>The AnyVolumeDataSource feature is now beta, and the feature gate is enabled by default. In order to provide user feedback on PVCs with data sources, deployers must install the VolumePopulators CRD and the data-source-validator controller. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108736"">kubernetes/kubernetes#108736</a>, <a href=""https://github.com/bswartz""><code>@​bswartz</code></a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/9ecc1143a8f7b34264b48dea12edd4d66230476f""><code>9ecc114</code></a> [chore] update version</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/ae5fd81a0fbea7d7fdac8d418876acaa288bcc0f""><code>ae5fd81</code></a> fix: config reader handles bool types (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/218"">#218</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/7bbb327cee0d4ed908a5deb28aaf5a9ccc1f4602""><code>7bbb327</code></a> [chore] update version</li>; <li><a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:13701,validat,validator,13701,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['validat'],['validator']
Security,"avro) to permit the latest version.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/apache/avro/releases"">avro's releases</a>.</em></p>; <blockquote>; <h2>Apache Avro 1.11.0</h2>; <p>The Apache Avro community is pleased to announce the release of Avro 1.11.0!</p>; <p>All signed release artifacts, signatures and verification instructions can; be found here: <a href=""https://avro.apache.org/releases.html"">https://avro.apache.org/releases.html</a></p>; <p>This release includes 120 Jira issues, including some interesting features:</p>; <p>Specification: AVRO-3212 Support documentation tags for FIXED types; C#: AVRO-2961 Support dotnet framework 5.0; C#: AVRO-3225 Prevent memory errors when deserializing untrusted data; C++: AVRO-2923 Logical type corrections; Java: AVRO-2863 Support Avro core on android; Javascript: AVRO-3131 Drop support for node.js 10; Perl: AVRO-3190 Fix error when reading from EOF; Python: AVRO-2906 Improved performance validating deep record data; Python: AVRO-2914 Drop Python 2 support; Python: AVRO-3004 Drop Python 3.5 support; Ruby: AVRO-3108 Drop Ruby 2.5 support</p>; <p>For the first time, the 1.11.0 release includes experimental support for; Rust. Work is continuing on this donated SDK, but we have not versioned and; published official artifacts for this release.</p>; <p>Python: The avro package fully supports Python 3. We will no longer publish a; separate avro-python3 package</p>; <p>And of course upgraded dependencies to latest versions, CVE fixes and more:; <a href=""https://issues.apache.org/jira/issues/?jql=project%3DAVRO%20AND%20fixVersion%3D1.11.0"">https://issues.apache.org/jira/issues/?jql=project%3DAVRO%20AND%20fixVersion%3D1.11.0</a></p>; <p>The link to all fixed JIRA issues and a brief summary can be found at:; <a href=""https://github.com/apache/avro/releases/tag/release-1.11.0"">https://github.com/apache/avro/releases/tag/release-1.11.0</a></p>; <p>In addition, language-specific release ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11475:1058,validat,validating,1058,https://hail.is,https://github.com/hail-is/hail/pull/11475,1,['validat'],['validating']
Security,"b/python3.10/site-packages/hailtop/utils/utils.py"", line 787, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 475, in _read_output; raise reconstructed_error.maybe_user_error(ir); hail.utils.java.FatalError: SocketException: Connection reset. Java stack trace:; javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:104); 	at is.hail.relocated.com.google.cloud.storage.UnbufferedReadableByteChannelSession$UnbufferedReadableByteChannel.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:3322,secur,security,3322,https://hail.is,https://github.com/hail-is/hail/issues/12982,1,['secur'],['security']
Security,"b/python3.10/site-packages/hailtop/utils/utils.py"", line 792, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 477, in _read_output; raise reconstructed_error.maybe_user_error(ir); hail.utils.java.FatalError: SocketException: Connection reset. Java stack trace:; javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:104); 	at is.hail.relocated.com.google.cloud.storage.UnbufferedReadableByteChannelSession$UnbufferedReadableByteChannel.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:4210,secur,security,4210,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,"b/python3.6/ssl.py"", line 874, in read; return self._sslobj.read(len, buffer); File ""/usr/lib/python3.6/ssl.py"", line 631, in read; v = self._sslobj.read(len, buffer); socket.timeout: The read operation timed out. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/lib/python3/dist-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/usr/lib/python3/dist-packages/pip/commands/install.py"", line 342, in run; requirement_set.prepare_files(finder); File ""/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 821, in unpack_url; hashes=hashes; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 659, in unpack_http_url; hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 882, in _download_http_url; _download_url(resp, link, content_file, hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 603, in _download_url; hashes.check_against_chunks(downloaded_chunks); File ""/usr/lib/python3/dist-packages/pip/utils/hashes.py"", line 46, in check_against_chunks; for chunk in chunks:; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 571, in written_chunks; for chunk in chunks:; File ""/usr/lib/python3/dist-packages/pip/utils/ui.py"", line 139, in iter; for x in it:; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 560, in resp_read; decode_content=False):; File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 436, in stream; data = self.read(amt=amt, decode_content=decode_content); File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 401, in read; raise IncompleteRead(self._fp_bytes_read, self.leng",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8390:1656,hash,hashes,1656,https://hail.is,https://github.com/hail-is/hail/issues/8390,1,['hash'],['hashes']
Security,"b00e398dadb5ed2bf0c49d8d5acfecd""><code>e32db24</code></a> chore(python): update .kokoro/requirements.txt (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/131"">#131</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/6026462f3b63b4df442a7f3e9214ee8ebfd7ffdb""><code>6026462</code></a> chore: fix path to requirements.txt in release script [autoapprove] (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/130"">#130</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-api-common-protos/compare/v1.56.4...v1.57.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=googleapis-common-protos&package-manager=pip&previous-version=1.56.4&new-version=1.57.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12514:7924,secur,security-vulnerabilities,7924,https://hail.is,https://github.com/hail-is/hail/pull/12514,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"b1.</li>; <li>Added support for deleting versions in <code>delete_blobs</code> by supplying <code>version_id</code>.</li>; </ul>; <h2>azure-storage-blob_12.13.0b1</h2>; <h2>12.13.0b1 (2022-06-15)</h2>; <h3>Features Added</h3>; <ul>; <li>Added support for service version 2021-08-06.</li>; <li>Added a new version of client-side encryption for blobs (version 2.0) which utilizes AES-GCM-256 encryption.; If you are currently using client-side encryption, it is <strong>highly recommended</strong> to switch to a form of server-side; encryption (Customer-Provided Key, Encryption Scope, etc.) or version 2.0 of client-side encryption. The encryption; version can be specified on any client constructor via the <code>encryption_version</code> keyword (<code>encryption_version='2.0'</code>).</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/13989b5b1253e26f3f3ee24013a3013fea1bdf73""><code>13989b5</code></a> [Storage] Fix ranged download for client-side encryption (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25522"">#25522</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e90af4374bfd7c139737ad2888fcd269b3023520""><code>e90af43</code></a> DataLake funny dependency (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25129"">#25129</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/cbec3383039ffeb46760268d1a8f81cf1b4d2219""><code>cbec338</code></a> [AutoRelease] t2-storagecache-2022-07-06-35884(Do not merge) (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25089"">#25089</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/dc7c5a16d39df8a8d4b838a7240e58f64fc824f2""><code>dc7c5a1</code></a> [Storage] API View Feedback For STG84 GA (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12109:1684,encrypt,encryption,1684,https://hail.is,https://github.com/hail-is/hail/pull/12109,1,['encrypt'],['encryption']
Security,"b359ad676dff97a35321976c19ca0f6c4fc44ad""><code>9b359ad</code></a> Fix <code>unhashable-member</code> crash when <code>lambda</code> used as a dict key (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7454"">#7454</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/5716ad10104a9553ef9d64404b044c04947889b2""><code>5716ad1</code></a> Bump pylint to 2.15.2, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/49b5d5dae6cc49d0572ffa35ae07f46ddc85fa61""><code>49b5d5d</code></a> Upgrade astroid version following 2.12.9 release</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.13.5...v2.15.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.13.5&new-version=2.15.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12240:2733,secur,security-vulnerabilities,2733,https://hail.is,https://github.com/hail-is/hail/pull/12240,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"b3750121a7/hail-0.1-es-6.2.4-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, without-vep-520334-sw-rmwj.c.seqr-project.internal): java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:245); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apach",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:1991,Checksum,ChecksumFileSystem,1991,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['Checksum'],['ChecksumFileSystem']
Security,"b53b06f5b02a1038a88bd6290c2846""><code>7efb22a</code></a> 1.2.6</li>; <li><a href=""https://github.com/substack/minimist/commit/ef88b9325f77b5ee643ccfc97e2ebda577e4c4e2""><code>ef88b93</code></a> security notice for additional prototype pollution issue</li>; <li><a href=""https://github.com/substack/minimist/commit/c2b981977fa834b223b408cfb860f933c9811e4d""><code>c2b9819</code></a> isConstructorOrProto adapted from PR</li>; <li><a href=""https://github.com/substack/minimist/commit/bc8ecee43875261f4f17eb20b1243d3ed15e70eb""><code>bc8ecee</code></a> test from prototype pollution PR</li>; <li>See full diff in <a href=""https://github.com/substack/minimist/compare/1.2.5...1.2.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=minimist&package-manager=npm_and_yarn&previous-version=1.2.5&new-version=1.2.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11653:1157,secur,security-vulnerabilities,1157,https://hail.is,https://github.com/hail-is/hail/pull/11653,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"b5dc1ae716e870873ac0b7d8b3369ca9896c38""><code>22b5dc1</code></a> Account for more node types in handling of except block homonyms with compreh...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/05990167978b3acbb1fbf37b079602a057ee4774""><code>0599016</code></a> <code>redefined-slots-in-subclass</code> crash when slot type is neither a string or c...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c48c45a88c74c0429f184c48334a513806c6a16c""><code>c48c45a</code></a> Fix E1102 / <code>not-callable</code> false positive for property that returns a lambd...</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.13.4...v2.13.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.13.4&new-version=2.13.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11739:5147,secur,security-vulnerabilities,5147,https://hail.is,https://github.com/hail-is/hail/pull/11739,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"bandedBlocks is used to write those blocks intersecting a band around diagonal, and rectangularBlocks (or a subsequent improvement leveraging symmetry) will be used to write out all blocks overlapping a set of pre-specified LD blocks. . In Python I've exposed the blocks_to_keep option on BlockMatrix write and added BlockMatrix.write_banded along with a simple interface check. I'm not yet sure how I want to expose rectangular blocks on the Python side. I also fixed a GridPartitioner bug to properly catch overflow, replacing; ```; assert(numPartitions >= nBlockRows && numPartitions >= nBlockCols); ```; with; ```; require(nBlockRows.toLong * nBlockCols <= Int.MaxValue); ```. For the record, I compared `rectangularBlocks` as written to the following alternate implementation under a variety of contexts and found the included version to be faster even with a large number of partitions and a small number of rectangles:; ```; def rectangularBlocks(rectangles: Array[Array[Long]]): Array[Int] = {; val blocks = rectangles.par.aggregate(Set[Int]())( { case (b, r) =>; assert(r.length == 4); b ++ rectangularBlocks(r(0), r(1), r(2), r(3)) },; _ ++ _); .toArray; ; scala.util.Sorting.quickSort(blocks); ; blocks; }; ```; Using `par` for parallel aggregate above does speed things up for large numbers of large rectangles, but the included implementation is still faster with good scaling by design.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2890:252,expose,exposed,252,https://hail.is,https://github.com/hail-is/hail/pull/2890,2,['expose'],"['expose', 'exposed']"
Security,"batch checks authentication for all endpoints except `/alive`. Two endpoints are now considered ""internal"" and must originate from the batch server itself. Summary of Changes; - hailjwt is used by batch to verify cookies; - all batch endpoints except `/alive` require a valid cookie or are internal; - a make target `test-deploy` and associated files for testing a deploy of batch; - update pipeline to use batch and users",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5844:13,authenticat,authentication,13,https://hail.is,https://github.com/hail-is/hail/pull/5844,1,['authenticat'],['authentication']
Security,"bc4acbe80537ea666506fa"">5d1cfd2</a>)</li>; <li>retry client side requests timeout (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/727"">#727</a>) (<a href=""https://github.com/googleapis/python-storage/commit/e0b3b354d51e4be7c563d7f2f628a7139df842c0"">e0b3b35</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>fixed download_blob_to_file example (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/704"">#704</a>) (<a href=""https://github.com/googleapis/python-storage/commit/2c94d98ed21cc768cfa54fac3d734254fc4d8480"">2c94d98</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v2.0.0...v2.1.0"">2.1.0</a> (2022-01-19)</h2>; <h3>Features</h3>; <ul>; <li>add turbo replication support and samples (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/622"">#622</a>) (<a href=""https://github.com/googleapis/python-storage/commit/4dafc815470480ce9de7f0357e331d3fbd0ae9b7"">4dafc81</a>)</li>; <li>avoid authentication with storage emulator (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/679"">#679</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8789afaaa1b2bd6f03fae72e3d87ce004ec10129"">8789afa</a>)</li>; <li>remove python 3.6 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/689"">#689</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8aa4130ee068a1922161c8ca54a53a4a51d65ce0"">8aa4130</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v1.44.0...v2.0.0"">2.0.0</a> (2022-01-12)</h2>; <h3>⚠ BREAKING CHANGES</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/657"">#657</a>)</li>; </ul>; <h3>Features</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/657"">#657</a>) (<a href=""https://github.com/goo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11578:4530,authenticat,authentication,4530,https://hail.is,https://github.com/hail-is/hail/pull/11578,1,['authenticat'],['authentication']
Security,"bd8d9d8a132f53""><code>d3fe031</code></a> Add comment about the compatibility factor.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/a4ae953dca38da768bcd1786aeba84bada32efb4""><code>a4ae953</code></a> Add xfail test capturing new expectation.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/e5b7d8759214feedd0c49a7859ebb124473bcfc3""><code>e5b7d87</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/390"">#390</a> from python/bugfix/noisy-coverage</li>; <li>Additional commits viewable in <a href=""https://github.com/python/importlib_metadata/compare/v3.10.1...v4.12.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=importlib-metadata&package-manager=pip&previous-version=3.10.1&new-version=4.12.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12000:4829,secur,security-vulnerabilities,4829,https://hail.is,https://github.com/hail-is/hail/pull/12000,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"berbot-app+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​lumberbot-app</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Ameeseeksmachine+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​meeseeksmachine</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Awelcome+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​welcome</code></a></p>; <h2>v4.0.11</h2>; <h2>4.0.11</h2>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/compare/v4.0.10...0708330843fd087134a239d2ad6005b1d543e246"">Full Changelog</a>)</p>; <h3>Security fixes</h3>; <ul>; <li>Potential authentication and CSRF tokens leak in JupyterLab (<a href=""https://github.com/jupyterlab/jupyterlab/security/advisories/GHSA-44cc-43rp-5947"">GHSA-44cc-43rp-5947</a>)</li>; <li>SXSS in Markdown Preview (<a href=""https://github.com/jupyterlab/jupyterlab/security/advisories/GHSA-4m77-cmpx-vjc4"">GHSA-4m77-cmpx-vjc4</a>)</li>; </ul>; <h3>Bugs fixed</h3>; <ul>; <li>Fixes focus indicator on input checkbox for Firefox <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15612"">#15612</a> (<a href=""https://github.com/alden-ilao""><code>@​alden-ilao</code></a>)</li>; </ul>; <h3>Documentation improvements</h3>; <ul>; <li>Fix link to yarn docs in extension migration guide <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15640"">#15640</a> (<a href=""https://github.com/krassowski""><code>@​krassowski</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/graphs/contributors?from=2023-12-29&amp;to=2024-01-19&amp;type=c"">GitHub contributors page for this release</a>)</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyterlab/jupyterlab/blob/@jupyterlab/lsp@4.0.12/CHANGELOG.md"">jupyterlab's changelog</a>.</em></p>; <blockq",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14218:4840,secur,security,4840,https://hail.is,https://github.com/hail-is/hail/pull/14218,1,['secur'],['security']
Security,"bf05e19b87efa8e35bf6""><code>763ff5f</code></a> Publish 7.4.5</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/d27c8a497c6cbb1a232fbbe75cb1fd0f53faa9b0""><code>d27c8a4</code></a> [7.x] Handle Jupyter Core Warning (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/875"">#875</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/46f3f8c34f272629c45beba9884053680f213cfd""><code>46f3f8c</code></a> Clean up 7.x workflows (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/865"">#865</a>)</li>; <li>See full diff in <a href=""https://github.com/jupyter/jupyter_client/compare/v7.4.4...v7.4.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jupyter-client&package-manager=pip&previous-version=7.4.4&new-version=7.4.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12459:3656,secur,security-vulnerabilities,3656,https://hail.is,https://github.com/hail-is/hail/pull/12459,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"bf05e19b87efa8e35bf6""><code>763ff5f</code></a> Publish 7.4.5</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/d27c8a497c6cbb1a232fbbe75cb1fd0f53faa9b0""><code>d27c8a4</code></a> [7.x] Handle Jupyter Core Warning (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/875"">#875</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/46f3f8c34f272629c45beba9884053680f213cfd""><code>46f3f8c</code></a> Clean up 7.x workflows (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/865"">#865</a>)</li>; <li>See full diff in <a href=""https://github.com/jupyter/jupyter_client/compare/v7.4.4...v7.4.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jupyter-client&package-manager=pip&previous-version=7.4.4&new-version=7.4.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12467:5798,secur,security-vulnerabilities,5798,https://hail.is,https://github.com/hail-is/hail/pull/12467,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"blaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1427"">#1427</a>: Rebuild all binaries with fix from <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1422"">#1422</a> and <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1323"">#1323</a> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; </ul>; <h1>Release 5.10.0</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/java-native-access/jna/commit/3705b849892aa3c37e5608e640eff19047811a5c""><code>3705b84</code></a> Release 5.12.1</li>; <li><a href=""https://github.com/java-native-access/jna/commit/2f919e56bad203494fe9589206d6d23f27ef4f26""><code>2f919e5</code></a> Null-check cleanable in Memory#close (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1447"">#1447</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/1eec7dd76830af97ed64ecb2d8d39a56db104dcd""><code>1eec7dd</code></a> Prepare next development iteration</li>; <li><a href=""https://github.com/java-native-access/jna/commit/0d7499f105e4495bdea15fc21f5b1046e81ca822""><code>0d7499f</code></a> Release 5.12.0</li>; <li><a href=""https://github.com/java-native-access/jna/commit/fa86166d4f75ef4478de7ad9d7d6c0b6b6933ee0""><code>fa86166</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1445"">#1445</a> from matthiasblaesing/aix</li>; <li><a href=""https://github.com/java-native-access/jna/commit/4cca4405f7f6bc32d2a08495efb81c081b065279""><code>4cca440</code></a> Fix name mapping difference between AIX JDK 8 and Semeru JDK 18</li>; <li><a href=""https://github.com/java-native-access/jna/commit/f58b0f8f6b5c013adfe44a2cfb018ccb6ef6a688""><code>f58b0f8</code></a> Improve test stability on AIX (exclude tests that are expected t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:5950,access,access,5950,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,"ble *forward secrecy* [2]. Under; forward secret schemes, the two parties share a private key unknown to all; adversaries. TLS 1.3 makes forward secrecy mandatory. I intend to eventually; require all our services to refuse to speak anything other than TLS 1.3. The shared private key is used to encrypt and decrypt messages sent over a; socket. This poses a problem: how do two parties who have never met each other; agree on a private key without revealing the key to the public? This is a; classic cryptography problem called [key; exchange](https://en.wikipedia.org/wiki/Key_exchange). The classic solution to; this problem is [Diffie-Hellman key; exchange](https://en.wikipedia.org/wiki/Diffie–Hellman_key_exchange). The; Wikipedia article has ""General overview"" which is quite clear. In addition to a key, the parties must agree on a cipher. There are many old,; insecure ciphers available. In the future I intend all our servers to refuse to; use insecure ciphers. Mozilla; [has a list of secure cipher suites](https://wiki.mozilla.org/Security/Server_Side_TLS#Recommended_configurations). ## New Hail Concepts. Every principal in our system has a secret: `ssl-config-NAME`. These secrets are; automatically created for a particular namespace by `tls/create_certs.py`. Who; trusts who (i.e. who is allowed to talk to whom) is defined by; `tls/config.yaml`. For example, `site` is defined in `config.yaml` as follows:. ```; - name: site; domain: site; kind: nginx; incoming:; - admin-pod; - router; ```. A principal named ""site"" exists. Site's domain names are `site`,; `site.NAMESPACE`, `site.NAMESPACE.svc.cluster.local`. Site's configuration files; should be in NGINX configuration file format. Site accepts incoming requests; from the principals named admin-pod and router. Site is not permitted to make; any outgoing requests. `create_certs.py` will create a new secret named; `ssl-config-site` which contains five files:. - `site-config-http.conf`: an NGINX configuration file that configu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:6143,secur,secure,6143,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['secur'],['secure']
Security,"blocks / 0 chunks), regions.size = 3, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.561 : ERROR: error while applying lowering 'LowerAndExecuteShuffles'; 2023-05-04 01:04:37.600 : INFO: RegionPool: initialized for thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=0, peakBytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.603 : ERROR: SocketException: Connection reset; From javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:23781,secur,security,23781,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,"bot.com/kubernetes/kubernetes/pull/92660"">kubernetes/kubernetes#92660</a>, <a href=""https://github.com/damemi""><code>@​damemi</code></a>) [SIG API Machinery]</li>; <li>Kubelet's --runonce option is now also available in Kubelet's config file as <code>runOnce</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89128"">kubernetes/kubernetes#89128</a>, <a href=""https://github.com/vincent178""><code>@​vincent178</code></a>) [SIG Node]</li>; <li>Kubelet: add '--logging-format' flag to support structured logging (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91532"">kubernetes/kubernetes#91532</a>, <a href=""https://github.com/afrouzMashaykhi""><code>@​afrouzMashaykhi</code></a>) [SIG API Machinery, Cluster Lifecycle, Instrumentation and Node]</li>; <li>Kubernetes is now built with golang 1.15.0-rc.1.; <ul>; <li>The deprecated, legacy behavior of treating the CommonName field on X.509 serving certificates as a host name when no Subject Alternative Names are present is now disabled by default. It can be temporarily re-enabled by adding the value x509ignoreCN=0 to the GODEBUG environment variable. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/93264"">kubernetes/kubernetes#93264</a>, <a href=""https://github.com/justaugustus""><code>@​justaugustus</code></a>) [SIG API Machinery, Auth, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation, Network, Node, Release, Scalability, Storage and Testing]</li>; </ul>; </li>; <li>Promote Immutable Secrets/ConfigMaps feature to Beta and enable the feature by default.; This allows to set <code>Immutable</code> field in Secrets or ConfigMap object to mark their contents as immutable. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89594"">kubernetes/kubernetes#89594</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>) [SIG Apps and Testing]</li>; <li>Remove <code>BindTimeoutSeconds</code> from schedule configur",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:10569,certificate,certificates,10569,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['certificate'],['certificates']
Security,"boto3 is the AWS Python client library. This is for the upcoming S3AsyncFS. FYI @tpoterba I also added it to the hail package requirements file because it will be exposed via `hailctl cp ...`, etc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10349:163,expose,exposed,163,https://hail.is,https://github.com/hail-is/hail/pull/10349,1,['expose'],['exposed']
Security,"br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **624/1000** <br/> **Why?** Has a fix available, CVSS 8.2 | Arbitrary Code Execution <br/>[SNYK-PYTHON-IPYTHON-2348630](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-2348630) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-JINJA2-6150717](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `2.11.3 -> 3.1.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **604/1000** <br/> **Why?** Has a fix available, CVSS 7.8 | Improper Privilege Management <br/>[SNYK-PYTHON-JUPYTERCORE-3063766](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERCORE-3063766) | `jupyter-core:` <br> `4.6.3 -> 4.11.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-MISTUNE-2940625](https://snyk.io/vuln/SNYK-PYTHON-MISTUNE-2940625) | `mistune:` <br> `0.8.4 -> 2.0.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **726/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:2919,Cross-site Scripting,Cross-site Scripting,2919,https://hail.is,https://github.com/hail-is/hail/pull/14205,2,"['Cross-site Scripting', 'XSS']","['Cross-site Scripting', 'XSS']"
